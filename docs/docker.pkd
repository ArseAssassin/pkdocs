---
name: Docker
slug: docker
text_format: markdown
generator: src:devdocs
version: ''
copyright: |-
  © 2019 Docker, Inc.
  Licensed under the Apache License, Version 2.0.
  Docker and the Docker logo are trademarks or registered trademarks of
  Docker, Inc. in the United States and/or other countries.
  Docker, Inc. and other parties may also have trademark rights in other
  terms used herein.
  https://docs.docker.com/
homepage: https://docker.com/
generator_command: doc src:devdocs use docker

---
- name: Access authorization plugin
  id: engine/extend/plugins_authorization/index
  summary: This document describes the Docker Engine plugins generally available in Docker Engine
  description: "# Access authorization plugin\n\nThis document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](../index).\n\nDocker’s out-of-the-box authorization model is all or nothing. Any user with permission to access the Docker daemon can run any Docker client command. The same is true for callers using Docker’s Engine API to contact the daemon. If you require greater access control, you can create authorization plugins and add them to your Docker daemon configuration. Using an authorization plugin, a Docker administrator can configure granular access policies for managing access to the Docker daemon.\n\nAnyone with the appropriate skills can develop an authorization plugin. These skills, at their most basic, are knowledge of Docker, understanding of REST, and sound programming knowledge. This document describes the architecture, state, and methods information available to an authorization plugin developer.\n\n## Basic principles\n\nDocker’s [plugin infrastructure](../plugin_api/index) enables extending Docker by loading, removing and communicating with third-party components using a generic API. The access authorization subsystem was built using this mechanism.\n\nUsing this subsystem, you don’t need to rebuild the Docker daemon to add an authorization plugin. You can add a plugin to an installed Docker daemon. You do need to restart the Docker daemon to add a new plugin.\n\nAn authorization plugin approves or denies requests to the Docker daemon based on both the current authentication context and the command context. The authentication context contains all user details and the authentication method. The command context contains all the relevant request data.\n\nAuthorization plugins must follow the rules described in [Docker Plugin API](../plugin_api/index). Each plugin must reside within directories described under the [Plugin discovery](../plugin_api/index#plugin-discovery) section.\n\n> **Note**\n>\n> The abbreviations `AuthZ` and `AuthN` mean authorization and authentication respectively.\n\n## Default user authorization mechanism\n\nIf TLS is enabled in the [Docker daemon](../../security/protect-access/index), the default user authorization flow extracts the user details from the certificate subject name. That is, the `User` field is set to the client certificate subject common name, and the `AuthenticationMethod` field is set to `TLS`.\n\n## Basic architecture\n\nYou are responsible for registering your plugin as part of the Docker daemon startup. You can install multiple plugins and chain them together. This chain can be ordered. Each request to the daemon passes in order through the chain. Only when all the plugins grant access to the resource, is the access granted.\n\nWhen an HTTP request is made to the Docker daemon through the CLI or via the Engine API, the authentication subsystem passes the request to the installed authentication plugin(s). The request contains the user (caller) and command context. The plugin is responsible for deciding whether to allow or deny the request.\n\nThe sequence diagrams below depict an allow and deny authorization flow:\n\nEach request sent to the plugin includes the authenticated user, the HTTP headers, and the request/response body. Only the user name and the authentication method used are passed to the plugin. Most importantly, no user credentials or tokens are passed. Finally, not all request/response bodies are sent to the authorization plugin. Only those request/response bodies where the `Content-Type` is either `text/*` or `application/json` are sent.\n\nFor commands that can potentially hijack the HTTP connection (`HTTP Upgrade`), such as `exec`, the authorization plugin is only called for the initial HTTP requests. Once the plugin approves the command, authorization is not applied to the rest of the flow. Specifically, the streaming data is not passed to the authorization plugins. For commands that return chunked HTTP response, such as `logs` and `events`, only the HTTP request is sent to the authorization plugins.\n\nDuring request/response processing, some authorization flows might need to do additional queries to the Docker daemon. To complete such flows, plugins can call the daemon API similar to a regular user. To enable these additional queries, the plugin must provide the means for an administrator to configure proper authentication and security policies.\n\n## Docker client flows\n\nTo enable and configure the authorization plugin, the plugin developer must support the Docker client interactions detailed in this section.\n\n### Setting up Docker daemon\n\nEnable the authorization plugin with a dedicated command line flag in the `--authorization-plugin=PLUGIN_ID` format. The flag supplies a `PLUGIN_ID` value. This value can be the plugin’s socket or a path to a specification file. Authorization plugins can be loaded without restarting the daemon. Refer to the [`dockerd` documentation](../../reference/commandline/dockerd/index#configuration-reload-behavior) for more information.\n\n``` \n$ dockerd --authorization-plugin=plugin1 --authorization-plugin=plugin2,...\n```\n\nDocker’s authorization subsystem supports multiple `--authorization-plugin` parameters.\n\n### Calling authorized command (allow)\n\n``` \n$ docker pull centos\n<...>\nf1b10cd84249: Pull complete\n<...>\n```\n\n### Calling unauthorized command (deny)\n\n``` \n$ docker pull centos\n<...>\ndocker: Error response from daemon: authorization denied by plugin PLUGIN_NAME: volumes are not allowed.\n```\n\n### Error from plugins\n\n``` \n$ docker pull centos\n<...>\ndocker: Error response from daemon: plugin PLUGIN_NAME failed with error: AuthZPlugin.AuthZReq: Cannot connect to the Docker daemon. Is the docker daemon running on this host?.\n```\n\n## API schema and implementation\n\nIn addition to Docker’s standard plugin registration method, each plugin should implement the following two methods:\n\n- `/AuthZPlugin.AuthZReq` This authorize request method is called before the Docker daemon processes the client request.\n\n- `/AuthZPlugin.AuthZRes` This authorize response method is called before the response is returned from Docker daemon to the client.\n\n#### /AuthZPlugin.AuthZReq\n\n**Request**:\n\n``` \n{\n    \"User\":              \"The user identification\",\n    \"UserAuthNMethod\":   \"The authentication method used\",\n    \"RequestMethod\":     \"The HTTP method\",\n    \"RequestURI\":        \"The HTTP request URI\",\n    \"RequestBody\":       \"Byte array containing the raw HTTP request body\",\n    \"RequestHeader\":     \"Byte array containing the raw HTTP request header as a map[string][]string \"\n}\n```\n\n**Response**:\n\n``` \n{\n    \"Allow\": \"Determined whether the user is allowed or not\",\n    \"Msg\":   \"The authorization message\",\n    \"Err\":   \"The error message if things go wrong\"\n}\n```\n\n#### /AuthZPlugin.AuthZRes\n\n**Request**:\n\n``` \n{\n    \"User\":              \"The user identification\",\n    \"UserAuthNMethod\":   \"The authentication method used\",\n    \"RequestMethod\":     \"The HTTP method\",\n    \"RequestURI\":        \"The HTTP request URI\",\n    \"RequestBody\":       \"Byte array containing the raw HTTP request body\",\n    \"RequestHeader\":     \"Byte array containing the raw HTTP request header as a map[string][]string\",\n    \"ResponseBody\":      \"Byte array containing the raw HTTP response body\",\n    \"ResponseHeader\":    \"Byte array containing the raw HTTP response header as a map[string][]string\",\n    \"ResponseStatusCode\":\"Response status code\"\n}\n```\n\n**Response**:\n\n``` \n{\n   \"Allow\":              \"Determined whether the user is allowed or not\",\n   \"Msg\":                \"The authorization message\",\n   \"Err\":                \"The error message if things go wrong\"\n}\n```\n\n### Request authorization\n\nEach plugin must support two request authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\n\n#### Daemon -\\> Plugin\n\n| Name                  | Type                | Description                                                               |\n|-----------------------|---------------------|---------------------------------------------------------------------------|\n| User                  | string              | The user identification                                                   |\n| Authentication method | string              | The authentication method used                                            |\n| Request method        | enum                | The HTTP method (GET/DELETE/POST)                                         |\n| Request URI           | string              | The HTTP request URI including API version (e.g., v.1.17/containers/json) |\n| Request headers       | map\\[string\\]string | Request headers as key value pairs (without the authorization header)     |\n| Request body          | \\[\\]byte            | Raw request body                                                          |\n\n#### Plugin -\\> Daemon\n\n| Name  | Type   | Description                                                                                                                                                                        |\n|-------|--------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Allow | bool   | Boolean value indicating whether the request is allowed or denied                                                                                                                  |\n| Msg   | string | Authorization message (will be returned to the client in case the access is denied)                                                                                                |\n| Err   | string | Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information) |\n\n### Response authorization\n\nThe plugin must support two authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\n\n#### Daemon -\\> Plugin\n\n| Name                  | Type                | Description                                                               |\n|-----------------------|---------------------|---------------------------------------------------------------------------|\n| User                  | string              | The user identification                                                   |\n| Authentication method | string              | The authentication method used                                            |\n| Request method        | string              | The HTTP method (GET/DELETE/POST)                                         |\n| Request URI           | string              | The HTTP request URI including API version (e.g., v.1.17/containers/json) |\n| Request headers       | map\\[string\\]string | Request headers as key value pairs (without the authorization header)     |\n| Request body          | \\[\\]byte            | Raw request body                                                          |\n| Response status code  | int                 | Status code from the docker daemon                                        |\n| Response headers      | map\\[string\\]string | Response headers as key value pairs                                       |\n| Response body         | \\[\\]byte            | Raw docker daemon response body                                           |\n\n#### Plugin -\\> Daemon\n\n| Name  | Type   | Description                                                                                                                                                                        |\n|-------|--------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Allow | bool   | Boolean value indicating whether the response is allowed or denied                                                                                                                 |\n| Msg   | string | Authorization message (will be returned to the client in case the access is denied)                                                                                                |\n| Err   | string | Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information) |\n\n[security](https://docs.docker.com/search/?q=security), [authorization](https://docs.docker.com/search/?q=authorization), [authentication](https://docs.docker.com/search/?q=authentication), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation), [plugin](https://docs.docker.com/search/?q=plugin), [extend](https://docs.docker.com/search/?q=extend)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/plugins_authorization/](https://docs.docker.com/engine/extend/plugins_authorization/)"
- name: Add nodes to the swarm
  id: engine/swarm/swarm-tutorial/add-nodes/index
  summary: Once you’ve created a swarm with a manager node, you’re ready to add worker nodes
  description: "# Add nodes to the swarm\n\nOnce you’ve [created a swarm](../create-swarm/index) with a manager node, you’re ready to add worker nodes.\n\n1.  Open a terminal and ssh into the machine where you want to run a worker node. This tutorial uses the name `worker1`.\n\n2.  Run the command produced by the `docker swarm init` output from the [Create a swarm](../create-swarm/index) tutorial step to create a worker node joined to the existing swarm:\n\n    ``` \n    $ docker swarm join \\\n      --token  SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n      192.168.99.100:2377\n\n    This node joined a swarm as a worker.\n    ```\n\n    If you don’t have the command available, you can run the following command on a manager node to retrieve the join command for a worker:\n\n    ``` \n    $ docker swarm join-token worker\n\n    To add a worker to this swarm, run the following command:\n\n        docker swarm join \\\n        --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n        192.168.99.100:2377\n    ```\n\n3.  Open a terminal and ssh into the machine where you want to run a second worker node. This tutorial uses the name `worker2`.\n\n4.  Run the command produced by the `docker swarm init` output from the [Create a swarm](../create-swarm/index) tutorial step to create a second worker node joined to the existing swarm:\n\n    ``` \n    $ docker swarm join \\\n      --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n      192.168.99.100:2377\n\n    This node joined a swarm as a worker.\n    ```\n\n5.  Open a terminal and ssh into the machine where the manager node runs and run the `docker node ls` command to see the worker nodes:\n\n    ``` \n    $ docker node ls\n    ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n    03g1y59jwfg7cf99w4lt0f662    worker2   Ready   Active\n    9j68exjopxe7wfl6yuxml7a7j    worker1   Ready   Active\n    dxn1zf6l61qsb1josjja83ngz *  manager1  Ready   Active        Leader\n    ```\n\n    The `MANAGER` column identifies the manager nodes in the swarm. The empty status in this column for `worker1` and `worker2` identifies them as worker nodes.\n\n    Swarm management commands like `docker node ls` only work on manager nodes.\n\n## What’s next?\n\nNow your swarm consists of a manager and two worker nodes. In the next step of the tutorial, you [deploy a service](../deploy-service/index) to the swarm.\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm](https://docs.docker.com/search/?q=swarm)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/](https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/)"
- name: Administer and maintain a swarm of Docker Engines
  id: engine/swarm/admin_guide/index
  summary: When you run a swarm of Docker Engines, manager nodes are the key components for managing the swarm and storing the swarm state
  description: "# Administer and maintain a swarm of Docker Engines\n\nWhen you run a swarm of Docker Engines, **manager nodes** are the key components for managing the swarm and storing the swarm state. It is important to understand some key features of manager nodes to properly deploy and maintain the swarm.\n\nRefer to [How nodes work](../how-swarm-mode-works/nodes/index) for a brief overview of Docker Swarm mode and the difference between manager and worker nodes.\n\n## Operate manager nodes in a swarm\n\nSwarm manager nodes use the [Raft Consensus Algorithm](../raft/index) to manage the swarm state. You only need to understand some general concepts of Raft in order to manage a swarm.\n\nThere is no limit on the number of manager nodes. The decision about how many manager nodes to implement is a trade-off between performance and fault-tolerance. Adding manager nodes to a swarm makes the swarm more fault-tolerant. However, additional manager nodes reduce write performance because more nodes must acknowledge proposals to update the swarm state. This means more network round-trip traffic.\n\nRaft requires a majority of managers, also called the quorum, to agree on proposed updates to the swarm, such as node additions or removals. Membership operations are subject to the same constraints as state replication.\n\n### Maintain the quorum of managers\n\nIf the swarm loses the quorum of managers, the swarm cannot perform management tasks. If your swarm has multiple managers, always have more than two. To maintain quorum, a majority of managers must be available. An odd number of managers is recommended, because the next even number does not make the quorum easier to keep. For instance, whether you have 3 or 4 managers, you can still only lose 1 manager and maintain the quorum. If you have 5 or 6 managers, you can still only lose two.\n\nEven if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.\n\nSee [Recovering from losing the quorum](#recover-from-losing-the-quorum) for troubleshooting steps if you do lose the quorum of managers.\n\n## Configure the manager to advertise on a static IP address\n\nWhen initiating a swarm, you must specify the `--advertise-addr` flag to advertise your address to other manager nodes in the swarm. For more information, see [Run Docker Engine in swarm mode](../swarm-mode/index#configure-the-advertise-address). Because manager nodes are meant to be a stable component of the infrastructure, you should use a *fixed IP address* for the advertise address to prevent the swarm from becoming unstable on machine reboot.\n\nIf the whole swarm restarts and every manager node subsequently gets a new IP address, there is no way for any node to contact an existing manager. Therefore the swarm is hung while nodes try to contact one another at their old IP addresses.\n\nDynamic IP addresses are OK for worker nodes.\n\n## Add manager nodes for fault tolerance\n\nYou should maintain an odd number of managers in the swarm to support manager node failures. Having an odd number of managers ensures that during a network partition, there is a higher chance that the quorum remains available to process requests if the network is partitioned into two sets. Keeping the quorum is not guaranteed if you encounter more than two network partitions.\n\n| Swarm Size | Majority | Fault Tolerance |\n|:----------:|:--------:|:---------------:|\n|     1      |    1     |        0        |\n|     2      |    2     |        0        |\n|   **3**    |    2     |      **1**      |\n|     4      |    3     |        1        |\n|   **5**    |    3     |      **2**      |\n|     6      |    4     |        2        |\n|   **7**    |    4     |      **3**      |\n|     8      |    5     |        3        |\n|   **9**    |    5     |      **4**      |\n\nFor example, in a swarm with *5 nodes*, if you lose *3 nodes*, you don’t have a quorum. Therefore you can’t add or remove nodes until you recover one of the unavailable manager nodes or recover the swarm with disaster recovery commands. See [Recover from disaster](#recover-from-disaster).\n\nWhile it is possible to scale a swarm down to a single manager node, it is impossible to demote the last manager node. This ensures you maintain access to the swarm and that the swarm can still process requests. Scaling down to a single manager is an unsafe operation and is not recommended. If the last node leaves the swarm unexpectedly during the demote operation, the swarm becomes unavailable until you reboot the node or restart with `--force-new-cluster`.\n\nYou manage swarm membership with the `docker swarm` and `docker node` subsystems. Refer to [Add nodes to a swarm](../join-nodes/index) for more information on how to add worker nodes and promote a worker node to be a manager.\n\n### Distribute manager nodes\n\nIn addition to maintaining an odd number of manager nodes, pay attention to datacenter topology when placing managers. For optimal fault-tolerance, distribute manager nodes across a minimum of 3 availability-zones to support failures of an entire set of machines or common maintenance scenarios. If you suffer a failure in any of those zones, the swarm should maintain the quorum of manager nodes available to process requests and rebalance workloads.\n\n| Swarm manager nodes | Repartition (on 3 Availability zones) |\n|:-------------------:|:-------------------------------------:|\n|          3          |                 1-1-1                 |\n|          5          |                 2-2-1                 |\n|          7          |                 3-2-2                 |\n|          9          |                 3-3-3                 |\n\n### Run manager-only nodes\n\nBy default manager nodes also act as a worker nodes. This means the scheduler can assign tasks to a manager node. For small and non-critical swarms assigning tasks to managers is relatively low-risk as long as you schedule services using **resource constraints** for *cpu* and *memory*.\n\nHowever, because manager nodes use the Raft consensus algorithm to replicate data in a consistent way, they are sensitive to resource starvation. You should isolate managers in your swarm from processes that might block swarm operations like swarm heartbeat or leader elections.\n\nTo avoid interference with manager node operation, you can drain manager nodes to make them unavailable as worker nodes:\n\n``` \n$ docker node update --availability drain <NODE>\n```\n\nWhen you drain a node, the scheduler reassigns any tasks running on the node to other available worker nodes in the swarm. It also prevents the scheduler from assigning tasks to the node.\n\n## Add worker nodes for load balancing\n\n[Add nodes to the swarm](../join-nodes/index) to balance your swarm’s load. Replicated service tasks are distributed across the swarm as evenly as possible over time, as long as the worker nodes are matched to the requirements of the services. When limiting a service to run on only specific types of nodes, such as nodes with a specific number of CPUs or amount of memory, remember that worker nodes that do not meet these requirements cannot run these tasks.\n\n## Monitor swarm health\n\nYou can monitor the health of manager nodes by querying the docker `nodes` API in JSON format through the `/nodes` HTTP endpoint. Refer to the [nodes API documentation](https://docs.docker.com/engine/api/v1.25/#tag/Node) for more information.\n\nFrom the command line, run `docker node inspect <id-node>` to query the nodes. For instance, to query the reachability of the node as a manager:\n\n``` \n$ docker node inspect manager1 --format \"{{ .ManagerStatus.Reachability }}\"\nreachable\n```\n\nTo query the status of the node as a worker that accept tasks:\n\n``` \n$ docker node inspect manager1 --format \"{{ .Status.State }}\"\nready\n```\n\nFrom those commands, we can see that `manager1` is both at the status `reachable` as a manager and `ready` as a worker.\n\nAn `unreachable` health status means that this particular manager node is unreachable from other manager nodes. In this case you need to take action to restore the unreachable manager:\n\n- Restart the daemon and see if the manager comes back as reachable.\n- Reboot the machine.\n- If neither restarting or rebooting work, you should add another manager node or promote a worker to be a manager node. You also need to cleanly remove the failed node entry from the manager set with `docker node demote <NODE>` and `docker node rm <id-node>`.\n\nAlternatively you can also get an overview of the swarm health from a manager node with `docker node ls`:\n\n``` \n$ docker node ls\nID                           HOSTNAME  MEMBERSHIP  STATUS  AVAILABILITY  MANAGER STATUS\n1mhtdwhvsgr3c26xxbnzdc3yp    node05    Accepted    Ready   Active\n516pacagkqp2xc3fk9t1dhjor    node02    Accepted    Ready   Active        Reachable\n9ifojw8of78kkusuc4a6c23fx *  node01    Accepted    Ready   Active        Leader\nax11wdpwrrb6db3mfjydscgk7    node04    Accepted    Ready   Active\nbb1nrq2cswhtbg4mrsqnlx1ck    node03    Accepted    Ready   Active        Reachable\ndi9wxgz8dtuh9d2hn089ecqkf    node06    Accepted    Ready   Active\n```\n\n## Troubleshoot a manager node\n\nYou should never restart a manager node by copying the `raft` directory from another node. The data directory is unique to a node ID. A node can only use a node ID once to join the swarm. The node ID space should be globally unique.\n\nTo cleanly re-join a manager node to a cluster:\n\n1.  To demote the node to a worker, run `docker node demote <NODE>`.\n2.  To remove the node from the swarm, run `docker node rm <NODE>`.\n3.  Re-join the node to the swarm with a fresh state using `docker swarm join`.\n\nFor more information on joining a manager node to a swarm, refer to [Join nodes to a swarm](../join-nodes/index).\n\n## Forcibly remove a node\n\nIn most cases, you should shut down a node before removing it from a swarm with the `docker node rm` command. If a node becomes unreachable, unresponsive, or compromised you can forcefully remove the node without shutting it down by passing the `--force` flag. For instance, if `node9` becomes compromised:\n\n``` \n$ docker node rm node9\n\nError response from daemon: rpc error: code = 9 desc = node node9 is not down and can't be removed\n\n$ docker node rm --force node9\n\nNode node9 removed from swarm\n```\n\nBefore you forcefully remove a manager node, you must first demote it to the worker role. Make sure that you always have an odd number of manager nodes if you demote or remove a manager.\n\n## Back up the swarm\n\nDocker manager nodes store the swarm state and manager logs in the `/var/lib/docker/swarm/` directory. This data includes the keys used to encrypt the Raft logs. Without these keys, you cannot restore the swarm.\n\nYou can back up the swarm using any manager. Use the following procedure.\n\n1.  If the swarm has auto-lock enabled, you need the unlock key to restore the swarm from backup. Retrieve the unlock key if necessary and store it in a safe location. If you are unsure, read [Lock your swarm to protect its encryption key](../swarm_manager_locking/index).\n\n2.  Stop Docker on the manager before backing up the data, so that no data is being changed during the backup. It is possible to take a backup while the manager is running (a “hot” backup), but this is not recommended and your results are less predictable when restoring. While the manager is down, other nodes continue generating swarm data that is not part of this backup.\n\n    > Note\n    >\n    > Be sure to maintain the quorum of swarm managers. During the time that a manager is shut down, your swarm is more vulnerable to losing the quorum if further nodes are lost. The number of managers you run is a trade-off. If you regularly take down managers to do backups, consider running a five manager swarm, so that you can lose an additional manager while the backup is running, without disrupting your services.\n\n3.  Back up the entire `/var/lib/docker/swarm` directory.\n\n4.  Restart the manager.\n\nTo restore, see [Restore from a backup](#restore-from-a-backup).\n\n## Recover from disaster\n\n### Restore from a backup\n\nAfter backing up the swarm as described in [Back up the swarm](#back-up-the-swarm), use the following procedure to restore the data to a new swarm.\n\n1.  Shut down Docker on the target host machine for the restored swarm.\n\n2.  Remove the contents of the `/var/lib/docker/swarm` directory on the new swarm.\n\n3.  Restore the `/var/lib/docker/swarm` directory with the contents of the backup.\n\n    > Note\n    >\n    > The new node uses the same encryption key for on-disk storage as the old one. It is not possible to change the on-disk storage encryption keys at this time.\n    >\n    > In the case of a swarm with auto-lock enabled, the unlock key is also the same as on the old swarm, and the unlock key is needed to restore the swarm.\n\n4.  Start Docker on the new node. Unlock the swarm if necessary. Re-initialize the swarm using the following command, so that this node does not attempt to connect to nodes that were part of the old swarm, and presumably no longer exist.\n\n    ``` \n    $ docker swarm init --force-new-cluster\n    ```\n\n5.  Verify that the state of the swarm is as expected. This may include application-specific tests or simply checking the output of `docker service ls` to be sure that all expected services are present.\n\n6.  If you use auto-lock, [rotate the unlock key](../swarm_manager_locking/index#rotate-the-unlock-key).\n\n7.  Add manager and worker nodes to bring your new swarm up to operating capacity.\n\n8.  Reinstate your previous backup regimen on the new swarm.\n\n### Recover from losing the quorum\n\nSwarm is resilient to failures and the swarm can recover from any number of temporary node failures (machine reboots or crash with restart) or other transient errors. However, a swarm cannot automatically recover if it loses a quorum. Tasks on existing worker nodes continue to run, but administrative tasks are not possible, including scaling or updating services and joining or removing nodes from the swarm. The best way to recover is to bring the missing manager nodes back online. If that is not possible, continue reading for some options for recovering your swarm.\n\nIn a swarm of `N` managers, a quorum (a majority) of manager nodes must always be available. For example, in a swarm with five managers, a minimum of three must be operational and in communication with each other. In other words, the swarm can tolerate up to `(N-1)/2` permanent failures beyond which requests involving swarm management cannot be processed. These types of failures include data corruption or hardware failures.\n\nIf you lose the quorum of managers, you cannot administer the swarm. If you have lost the quorum and you attempt to perform any management operation on the swarm, an error occurs:\n\n``` \nError response from daemon: rpc error: code = 4 desc = context deadline exceeded\n```\n\nThe best way to recover from losing the quorum is to bring the failed nodes back online. If you can’t do that, the only way to recover from this state is to use the `--force-new-cluster` action from a manager node. This removes all managers except the manager the command was run from. The quorum is achieved because there is now only one manager. Promote nodes to be managers until you have the desired number of managers.\n\nFrom the node to recover, run:\n\n``` \n$ docker swarm init --force-new-cluster --advertise-addr node01:2377\n```\n\nWhen you run the `docker swarm init` command with the `--force-new-cluster` flag, the Docker Engine where you run the command becomes the manager node of a single-node swarm which is capable of managing and running services. The manager has all the previous information about services and tasks, worker nodes are still part of the swarm, and services are still running. You need to add or re-add manager nodes to achieve your previous task distribution and ensure that you have enough managers to maintain high availability and prevent losing the quorum.\n\n## Force the swarm to rebalance\n\nGenerally, you do not need to force the swarm to rebalance its tasks. When you add a new node to a swarm, or a node reconnects to the swarm after a period of unavailability, the swarm does not automatically give a workload to the idle node. This is a design decision. If the swarm periodically shifted tasks to different nodes for the sake of balance, the clients using those tasks would be disrupted. The goal is to avoid disrupting running services for the sake of balance across the swarm. When new tasks start, or when a node with running tasks becomes unavailable, those tasks are given to less busy nodes. The goal is eventual balance, with minimal disruption to the end user.\n\nYou can use the `--force` or `-f` flag with the `docker service update` command to force the service to redistribute its tasks across the available worker nodes. This causes the service tasks to restart. Client applications may be disrupted. If you have configured it, your service uses a [rolling update](../swarm-tutorial/rolling-update/index).\n\nIf you use an earlier version and you want to achieve an even balance of load across workers and don’t mind disrupting running tasks, you can force your swarm to re-balance by temporarily scaling the service upward. Use `docker service inspect --pretty <servicename>` to see the configured scale of a service. When you use `docker service scale`, the nodes with the lowest number of tasks are targeted to receive the new workloads. There may be multiple under-loaded nodes in your swarm. You may need to scale the service up by modest increments a few times to achieve the balance you want across all the nodes.\n\nWhen the load is balanced to your satisfaction, you can scale the service back down to the original scale. You can use `docker service ps` to assess the current balance of your service across nodes.\n\nSee also [`docker service scale`](../../reference/commandline/service_scale/index) and [`docker service ps`](../../reference/commandline/service_ps/index).\n\n[docker](https://docs.docker.com/search/?q=docker), [container](https://docs.docker.com/search/?q=container), [swarm](https://docs.docker.com/search/?q=swarm), [manager](https://docs.docker.com/search/?q=manager), [raft](https://docs.docker.com/search/?q=raft)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/admin_guide/](https://docs.docker.com/engine/swarm/admin_guide/)"
- name: AppArmor security profiles for Docker
  id: engine/security/apparmor/index
  summary: AppArmor (Application Armor) is a Linux security module that protects an operating system and its applications from security threats
  description: "# AppArmor security profiles for Docker\n\nAppArmor (Application Armor) is a Linux security module that protects an operating system and its applications from security threats. To use it, a system administrator associates an AppArmor security profile with each program. Docker expects to find an AppArmor policy loaded and enforced.\n\nDocker automatically generates and loads a default profile for containers named `docker-default`. The Docker binary generates this profile in `tmpfs` and then loads it into the kernel.\n\n> **Note**: This profile is used on containers, *not* on the Docker Daemon.\n\nA profile for the Docker Engine daemon exists but it is not currently installed with the `deb` packages. If you are interested in the source for the daemon profile, it is located in [contrib/apparmor](https://github.com/moby/moby/tree/master/contrib/apparmor) in the Docker Engine source repository.\n\n## Understand the policies\n\nThe `docker-default` profile is the default for running containers. It is moderately protective while providing wide application compatibility. The profile is generated from the following [template](https://github.com/moby/moby/blob/master/profiles/apparmor/template.go).\n\nWhen you run a container, it uses the `docker-default` policy unless you override it with the `security-opt` option. For example, the following explicitly specifies the default policy:\n\n``` \n$ docker run --rm -it --security-opt apparmor=docker-default hello-world\n```\n\n## Load and unload profiles\n\nTo load a new profile into AppArmor for use with containers:\n\n``` \n$ apparmor_parser -r -W /path/to/your_profile\n```\n\nThen, run the custom profile with `--security-opt` like so:\n\n``` \n$ docker run --rm -it --security-opt apparmor=your_profile hello-world\n```\n\nTo unload a profile from AppArmor:\n\n``` \n# unload the profile\n$ apparmor_parser -R /path/to/profile\n```\n\n### Resources for writing profiles\n\nThe syntax for file globbing in AppArmor is a bit different than some other globbing implementations. It is highly suggested you take a look at some of the below resources with regard to AppArmor profile syntax.\n\n- [Quick Profile Language](https://gitlab.com/apparmor/apparmor/wikis/QuickProfileLanguage)\n- [Globbing Syntax](https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Core_Policy_Reference#AppArmor_globbing_syntax)\n\n## Nginx example profile\n\nIn this example, you create a custom AppArmor profile for Nginx. Below is the custom profile.\n\n``` \n#include <tunables/global>\n\n\nprofile docker-nginx flags=(attach_disconnected,mediate_deleted) {\n  #include <abstractions/base>\n\n  network inet tcp,\n  network inet udp,\n  network inet icmp,\n\n  deny network raw,\n\n  deny network packet,\n\n  file,\n  umount,\n\n  deny /bin/** wl,\n  deny /boot/** wl,\n  deny /dev/** wl,\n  deny /etc/** wl,\n  deny /home/** wl,\n  deny /lib/** wl,\n  deny /lib64/** wl,\n  deny /media/** wl,\n  deny /mnt/** wl,\n  deny /opt/** wl,\n  deny /proc/** wl,\n  deny /root/** wl,\n  deny /sbin/** wl,\n  deny /srv/** wl,\n  deny /tmp/** wl,\n  deny /sys/** wl,\n  deny /usr/** wl,\n\n  audit /** w,\n\n  /var/run/nginx.pid w,\n\n  /usr/sbin/nginx ix,\n\n  deny /bin/dash mrwklx,\n  deny /bin/sh mrwklx,\n  deny /usr/bin/top mrwklx,\n\n\n  capability chown,\n  capability dac_override,\n  capability setuid,\n  capability setgid,\n  capability net_bind_service,\n\n  deny @{PROC}/* w,   # deny write for all files directly in /proc (not in a subdir)\n  # deny write to files not in /proc/<number>/** or /proc/sys/**\n  deny @{PROC}/{[^1-9],[^1-9][^0-9],[^1-9s][^0-9y][^0-9s],[^1-9][^0-9][^0-9][^0-9]*}/** w,\n  deny @{PROC}/sys/[^k]** w,  # deny /proc/sys except /proc/sys/k* (effectively /proc/sys/kernel)\n  deny @{PROC}/sys/kernel/{?,??,[^s][^h][^m]**} w,  # deny everything except shm* in /proc/sys/kernel/\n  deny @{PROC}/sysrq-trigger rwklx,\n  deny @{PROC}/mem rwklx,\n  deny @{PROC}/kmem rwklx,\n  deny @{PROC}/kcore rwklx,\n\n  deny mount,\n\n  deny /sys/[^f]*/** wklx,\n  deny /sys/f[^s]*/** wklx,\n  deny /sys/fs/[^c]*/** wklx,\n  deny /sys/fs/c[^g]*/** wklx,\n  deny /sys/fs/cg[^r]*/** wklx,\n  deny /sys/firmware/** rwklx,\n  deny /sys/kernel/security/** rwklx,\n}\n```\n\n1.  Save the custom profile to disk in the `/etc/apparmor.d/containers/docker-nginx` file.\n\n    The file path in this example is not a requirement. In production, you could use another.\n\n2.  Load the profile.\n\n    ``` \n    $ sudo apparmor_parser -r -W /etc/apparmor.d/containers/docker-nginx\n    ```\n\n3.  Run a container with the profile.\n\n    To run nginx in detached mode:\n\n    ``` \n    $ docker run --security-opt \"apparmor=docker-nginx\" \\\n         -p 80:80 -d --name apparmor-nginx nginx\n    ```\n\n4.  Exec into the running container.\n\n    ``` \n    $ docker container exec -it apparmor-nginx bash\n    ```\n\n5.  Try some operations to test the profile.\n\n    ``` \n    root@6da5a2a930b9:~# ping 8.8.8.8\n    ping: Lacking privilege for raw socket.\n\n    root@6da5a2a930b9:/# top\n    bash: /usr/bin/top: Permission denied\n\n    root@6da5a2a930b9:~# touch ~/thing\n    touch: cannot touch 'thing': Permission denied\n\n    root@6da5a2a930b9:/# sh\n    bash: /bin/sh: Permission denied\n\n    root@6da5a2a930b9:/# dash\n    bash: /bin/dash: Permission denied\n    ```\n\nCongrats! You just deployed a container secured with a custom apparmor profile!\n\n## Debug AppArmor\n\nYou can use `dmesg` to debug problems and `aa-status` check the loaded profiles.\n\n### Use dmesg\n\nHere are some helpful tips for debugging any problems you might be facing with regard to AppArmor.\n\nAppArmor sends quite verbose messaging to `dmesg`. Usually an AppArmor line looks like the following:\n\n``` \n[ 5442.864673] audit: type=1400 audit(1453830992.845:37): apparmor=\"ALLOWED\" operation=\"open\" profile=\"/usr/bin/docker\" name=\"/home/jessie/docker/man/man1/docker-attach.1\" pid=10923 comm=\"docker\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=0\n```\n\nIn the above example, you can see `profile=/usr/bin/docker`. This means the user has the `docker-engine` (Docker Engine Daemon) profile loaded.\n\nLook at another log line:\n\n``` \n[ 3256.689120] type=1400 audit(1405454041.341:73): apparmor=\"DENIED\" operation=\"ptrace\" profile=\"docker-default\" pid=17651 comm=\"docker\" requested_mask=\"receive\" denied_mask=\"receive\"\n```\n\nThis time the profile is `docker-default`, which is run on containers by default unless in `privileged` mode. This line shows that apparmor has denied `ptrace` in the container. This is exactly as expected.\n\n### Use aa-status\n\nIf you need to check which profiles are loaded, you can use `aa-status`. The output looks like:\n\n``` \n$ sudo aa-status\napparmor module is loaded.\n14 profiles are loaded.\n1 profiles are in enforce mode.\n   docker-default\n13 profiles are in complain mode.\n   /usr/bin/docker\n   /usr/bin/docker///bin/cat\n   /usr/bin/docker///bin/ps\n   /usr/bin/docker///sbin/apparmor_parser\n   /usr/bin/docker///sbin/auplink\n   /usr/bin/docker///sbin/blkid\n   /usr/bin/docker///sbin/iptables\n   /usr/bin/docker///sbin/mke2fs\n   /usr/bin/docker///sbin/modprobe\n   /usr/bin/docker///sbin/tune2fs\n   /usr/bin/docker///sbin/xtables-multi\n   /usr/bin/docker///sbin/zfs\n   /usr/bin/docker///usr/bin/xz\n38 processes have profiles defined.\n37 processes are in enforce mode.\n   docker-default (6044)\n   ...\n   docker-default (31899)\n1 processes are in complain mode.\n   /usr/bin/docker (29756)\n0 processes are unconfined but have a profile defined.\n```\n\nThe above output shows that the `docker-default` profile running on various container PIDs is in `enforce` mode. This means AppArmor is actively blocking and auditing in `dmesg` anything outside the bounds of the `docker-default` profile.\n\nThe output above also shows the `/usr/bin/docker` (Docker Engine daemon) profile is running in `complain` mode. This means AppArmor *only* logs to `dmesg` activity outside the bounds of the profile. (Except in the case of Ubuntu Trusty, where some interesting behaviors are enforced.)\n\n## Contribute Docker’s AppArmor code\n\nAdvanced users and package managers can find a profile for `/usr/bin/docker` (Docker Engine Daemon) underneath [contrib/apparmor](https://github.com/moby/moby/tree/master/contrib/apparmor) in the Docker Engine source repository.\n\nThe `docker-default` profile for containers lives in [profiles/apparmor](https://github.com/moby/moby/tree/master/profiles/apparmor).\n\n[AppArmor](https://docs.docker.com/search/?q=AppArmor), [security](https://docs.docker.com/search/?q=security), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/apparmor/](https://docs.docker.com/engine/security/apparmor/)"
- name: Apply rolling updates to a service
  id: engine/swarm/swarm-tutorial/rolling-update/index
  summary: In a previous step of the tutorial, you scaled the number of instances of a service
  description: "# Apply rolling updates to a service\n\nIn a previous step of the tutorial, you [scaled](../scale-service/index) the number of instances of a service. In this part of the tutorial, you deploy a service based on the Redis 3.0.6 container tag. Then you upgrade the service to use the Redis 3.0.7 container image using rolling updates.\n\n1.  If you haven’t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n\n2.  Deploy your Redis tag to the swarm and configure the swarm with a 10 second update delay. Note that the following example shows an older Redis tag:\n\n    ``` \n    $ docker service create \\\n      --replicas 3 \\\n      --name redis \\\n      --update-delay 10s \\\n      redis:3.0.6\n\n    0u6a4s31ybk7yw2wyvtikmu50\n    ```\n\n    You configure the rolling update policy at service deployment time.\n\n    The `--update-delay` flag configures the time delay between updates to a service task or sets of tasks. You can describe the time `T` as a combination of the number of seconds `Ts`, minutes `Tm`, or hours `Th`. So `10m30s` indicates a 10 minute 30 second delay.\n\n    By default the scheduler updates 1 task at a time. You can pass the `--update-parallelism` flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\n\n    By default, when an update to an individual task returns a state of `RUNNING`, the scheduler schedules another task to update until all tasks are updated. If, at any time during an update a task returns `FAILED`, the scheduler pauses the update. You can control the behavior using the `--update-failure-action` flag for `docker service create` or `docker service update`.\n\n3.  Inspect the `redis` service:\n\n    ``` \n    $ docker service inspect --pretty redis\n\n    ID:             0u6a4s31ybk7yw2wyvtikmu50\n    Name:           redis\n    Service Mode:   Replicated\n     Replicas:      3\n    Placement:\n     Strategy:      Spread\n    UpdateConfig:\n     Parallelism:   1\n     Delay:         10s\n    ContainerSpec:\n     Image:         redis:3.0.6\n    Resources:\n    Endpoint Mode:  vip\n    ```\n\n4.  Now you can update the container image for `redis`. The swarm manager applies the update to nodes according to the `UpdateConfig` policy:\n\n    ``` \n    $ docker service update --image redis:3.0.7 redis\n    redis\n    ```\n\n    The scheduler applies rolling updates as follows by default:\n\n    - Stop the first task.\n    - Schedule update for the stopped task.\n    - Start the container for the updated task.\n    - If the update to a task returns `RUNNING`, wait for the specified delay period then start the next task.\n    - If, at any time during the update, a task returns `FAILED`, pause the update.\n\n5.  Run `docker service inspect --pretty redis` to see the new image in the desired state:\n\n    ``` \n    $ docker service inspect --pretty redis\n\n    ID:             0u6a4s31ybk7yw2wyvtikmu50\n    Name:           redis\n    Service Mode:   Replicated\n     Replicas:      3\n    Placement:\n     Strategy:      Spread\n    UpdateConfig:\n     Parallelism:   1\n     Delay:         10s\n    ContainerSpec:\n     Image:         redis:3.0.7\n    Resources:\n    Endpoint Mode:  vip\n    ```\n\n    The output of `service inspect` shows if your update paused due to failure:\n\n    ``` \n    $ docker service inspect --pretty redis\n\n    ID:             0u6a4s31ybk7yw2wyvtikmu50\n    Name:           redis\n    ...snip...\n    Update status:\n     State:      paused\n     Started:    11 seconds ago\n     Message:    update paused due to failure or early termination of task 9p7ith557h8ndf0ui9s0q951b\n    ...snip...\n    ```\n\n    To restart a paused update run `docker service update <SERVICE-ID>`. For example:\n\n    ``` \n    $ docker service update redis\n    ```\n\n    To avoid repeating certain update failures, you may need to reconfigure the service by passing flags to `docker service update`.\n\n6.  Run `docker service ps <SERVICE-ID>` to watch the rolling update:\n\n    ``` \n    $ docker service ps redis\n\n    NAME                                   IMAGE        NODE       DESIRED STATE  CURRENT STATE            ERROR\n    redis.1.dos1zffgeofhagnve8w864fco      redis:3.0.7  worker1    Running        Running 37 seconds\n     \\_ redis.1.88rdo6pa52ki8oqx6dogf04fh  redis:3.0.6  worker2    Shutdown       Shutdown 56 seconds ago\n    redis.2.9l3i4j85517skba5o7tn5m8g0      redis:3.0.7  worker2    Running        Running About a minute\n     \\_ redis.2.66k185wilg8ele7ntu8f6nj6i  redis:3.0.6  worker1    Shutdown       Shutdown 2 minutes ago\n    redis.3.egiuiqpzrdbxks3wxgn8qib1g      redis:3.0.7  worker1    Running        Running 48 seconds\n     \\_ redis.3.ctzktfddb2tepkr45qcmqln04  redis:3.0.6  mmanager1  Shutdown       Shutdown 2 minutes ago\n    ```\n\n    Before Swarm updates all of the tasks, you can see that some are running `redis:3.0.6` while others are running `redis:3.0.7`. The output above shows the state once the rolling updates are done.\n\n## What’s next?\n\nNext, learn about how to [drain a node](../drain-node/index) in the swarm.\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm](https://docs.docker.com/search/?q=swarm), [service](https://docs.docker.com/search/?q=service), [rolling-update](https://docs.docker.com/search/?q=rolling-update)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/](https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/)"
- name: Automation with content trust
  id: engine/security/trust/trust_automation/index
  summary: It is very common for Docker Content Trust to be built into existing automation systems
  description: "# Automation with content trust\n\nIt is very common for Docker Content Trust to be built into existing automation systems. To allow tools to wrap Docker and push trusted content, there are environment variables that can be passed through to the client.\n\nThis guide follows the steps as described [here](../index#signing-images-with-docker-content-trust) so please read that and understand its prerequisites.\n\nWhen working directly with the Notary client, it uses its [own set of environment variables](https://github.com/theupdateframework/notary/blob/master/docs/reference/client-config/#environment-variables-optional).\n\n## Add a delegation private key\n\nTo automate importing a delegation private key to the local Docker trust store, we need to pass a passphrase for the new key. This passphrase will be required everytime that delegation signs a tag.\n\n``` \n$ export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=\"mypassphrase123\"\n\n$ docker trust key load delegation.key --name jeff\nLoading key from \"delegation.key\"...\nSuccessfully imported key from delegation.key\n```\n\n## Add a delegation public key\n\nIf you initialising a repository at the same time as adding a Delegation public key, then you will need to use the local Notary Canonical Root Key’s passphrase to create the repositories trust data. If the repository has already been initiated then you only need the repositories passphrase.\n\n``` \n# Export the Local Root Key Passphrase if required.\n$ export DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE=\"rootpassphrase123\"\n\n# Export the Repository Passphrase\n$ export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=\"repopassphrase123\"\n\n# Initialise Repo and Push Delegation\n$ docker trust signer add --key delegation.crt jeff registry.example.com/admin/demo\nAdding signer \"jeff\" to registry.example.com/admin/demo...\nInitializing signed repository for registry.example.com/admin/demo...\nSuccessfully initialized \"registry.example.com/admin/demo\"\nSuccessfully added signer: registry.example.com/admin/demo\n```\n\n## Sign an image\n\nFinally when signing an image, we will need to export the passphrase of the signing key. This was created when the key was loaded into the local Docker trust store with `$ docker trust key load`.\n\n``` \n$ export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=\"mypassphrase123\"\n\n$ docker trust sign registry.example.com/admin/demo:1\nSigning and pushing trust data for local image registry.example.com/admin/demo:1, may overwrite remote trust data\nThe push refers to repository [registry.example.com/admin/demo]\n428c97da766c: Layer already exists\n2: digest: sha256:1a6fd470b9ce10849be79e99529a88371dff60c60aab424c077007f6979b4812 size: 524\nSigning and pushing trust metadata\nSuccessfully signed registry.example.com/admin/demo:1\n```\n\n## Build with content trust\n\nYou can also build with content trust. Before running the `docker build` command, you should set the environment variable `DOCKER_CONTENT_TRUST` either manually or in a scripted fashion. Consider the simple Dockerfile below.\n\n``` \n# syntax=docker/dockerfile:1\nFROM docker/trusttest:latest\nRUN echo\n```\n\nThe `FROM` tag is pulling a signed image. You cannot build an image that has a `FROM` that is not either present locally or signed. Given that content trust data exists for the tag `latest`, the following build should succeed:\n\n``` \n$  docker build -t docker/trusttest:testing .\nUsing default tag: latest\nlatest: Pulling from docker/trusttest\n\nb3dbab3810fc: Pull complete\na9539b34a6ab: Pull complete\nDigest: sha256:d149ab53f871\n```\n\nIf content trust is enabled, building from a Dockerfile that relies on tag without trust data, causes the build command to fail:\n\n``` \n$  docker build -t docker/trusttest:testing .\nunable to process Dockerfile: No trust data for notrust\n```\n\n## Related information\n\n- [Delegations for content trust](../trust_delegation/index)\n- [Content trust in Docker](../index)\n- [Manage keys for content trust](../trust_key_mng/index)\n- [Play in a content trust sandbox](../trust_sandbox/index)\n\n[trust](https://docs.docker.com/search/?q=trust), [security](https://docs.docker.com/search/?q=security), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation), [automation](https://docs.docker.com/search/?q=automation)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/trust/trust_automation/](https://docs.docker.com/engine/security/trust/trust_automation/)"
- name: Compose
  id: compose/index
  summary: Looking for Compose file reference? Find the latest version here
  description: "# Overview of Docker Compose\n\n> **Looking for Compose file reference?** [Find the latest version here](compose-file/index).\n\nCompose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration. To learn more about all the features of Compose, see [the list of features](#features).\n\nCompose works in all environments: production, staging, development, testing, as well as CI workflows. You can learn more about each case in [Common Use Cases](#common-use-cases).\n\nUsing Compose is basically a three-step process:\n\n1.  Define your app’s environment with a `Dockerfile` so it can be reproduced anywhere.\n\n2.  Define the services that make up your app in `docker-compose.yml` so they can be run together in an isolated environment.\n\n3.  Run `docker compose up` and the [Docker compose command](#compose-v2-and-the-new-docker-compose-command) starts and runs your entire app. You can alternatively run `docker-compose up` using the docker-compose binary.\n\nA `docker-compose.yml` looks like this:\n\n``` \nversion: \"3.9\"  # optional since v1.27.0\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:5000\"\n    volumes:\n      - .:/code\n      - logvolume01:/var/log\n    links:\n      - redis\n  redis:\n    image: redis\nvolumes:\n  logvolume01: {}\n```\n\nFor more information about the Compose file, see the [Compose file reference](compose-file/index).\n\nCompose has commands for managing the whole lifecycle of your application:\n\n- Start, stop, and rebuild services\n- View the status of running services\n- Stream the log output of running services\n- Run a one-off command on a service\n\n## Compose V2 and the new `docker compose` command\n\n> Important\n>\n> The new Compose V2, which supports the `compose` command as part of the Docker CLI, is now available.\n>\n> Compose V2 integrates compose functions into the Docker platform, continuing to support most of the previous `docker-compose` features and flags. You can run Compose V2 by replacing the hyphen (`-`) with a space, using `docker compose`, instead of `docker-compose`.\n\nIf you rely on using Docker Compose as `docker-compose` (with a hyphen), you can set up Compose V2 to act as a drop-in replacement of the previous `docker-compose`. Refer to the [Installing Compose](install/index) section for detailed instructions.\n\n## Context of Docker Compose evolution\n\nIntroduction of the [Compose specification](https://github.com/compose-spec/compose-spec) makes a clean distinction between the Compose YAML file model and the `docker-compose` implementation. Making this change has enabled a number of enhancements, including adding the `compose` command directly into the Docker CLI, being able to “up” a Compose application on cloud platforms by simply switching the Docker context, and launching of [Amazon ECS](https://docs.docker.com/cloud/ecs-integration/) and [Microsoft ACI](https://docs.docker.com/cloud/aci-integration/). As the Compose specification evolves, new features land faster in the Docker CLI.\n\nCompose V2 relies directly on the compose-go bindings which are maintained as part of the specification. This allows us to include community proposals, experimental implementations by the Docker CLI and/or Engine, and deliver features faster to users. Compose V2 also supports some of the newer additions to the specification, such as [profiles](profiles/index) and [GPU](gpu-support/index) devices.\n\nCompose V2 has been re-written in [Go](https://go.dev), which improves integration with other Docker command-line features, and allows it to run natively on [macOS on Apple silicon](https://docs.docker.com/desktop/mac/apple-silicon/), Windows, and Linux, without dependencies such as Python.\n\nFor more information about compatibility with the compose v1 command-line, see the [docker-compose compatibility list](cli-command-compatibility/index).\n\n## Features\n\nThe features of Compose that make it effective are:\n\n- [Multiple isolated environments on a single host](#multiple-isolated-environments-on-a-single-host)\n- [Preserve volume data when containers are created](#preserve-volume-data-when-containers-are-created)\n- [Only recreate containers that have changed](#only-recreate-containers-that-have-changed)\n- [Variables and moving a composition between environments](#variables-and-moving-a-composition-between-environments)\n\n### Multiple isolated environments on a single host\n\nCompose uses a project name to isolate environments from each other. You can make use of this project name in several different contexts:\n\n- on a dev host, to create multiple copies of a single environment, such as when you want to run a stable copy for each feature branch of a project\n- on a CI server, to keep builds from interfering with each other, you can set the project name to a unique build number\n- on a shared host or dev host, to prevent different projects, which may use the same service names, from interfering with each other\n\nThe default project name is the basename of the project directory. You can set a custom project name by using the [`-p` command line option](reference/index) or the [`COMPOSE_PROJECT_NAME` environment variable](reference/envvars/index#compose_project_name).\n\nThe default project directory is the base directory of the Compose file. A custom value for it can be defined with the `--project-directory` command line option.\n\n### Preserve volume data when containers are created\n\nCompose preserves all volumes used by your services. When `docker-compose up` runs, if it finds any containers from previous runs, it copies the volumes from the old container to the new container. This process ensures that any data you’ve created in volumes isn’t lost.\n\nIf you use `docker-compose` on a Windows machine, see [Environment variables](reference/envvars/index) and adjust the necessary environment variables for your specific needs.\n\n### Only recreate containers that have changed\n\nCompose caches the configuration used to create a container. When you restart a service that has not changed, Compose re-uses the existing containers. Re-using containers means that you can make changes to your environment very quickly.\n\n### Variables and moving a composition between environments\n\nCompose supports variables in the Compose file. You can use these variables to customize your composition for different environments, or different users. See [Variable substitution](compose-file/compose-file-v3/index#variable-substitution) for more details.\n\nYou can extend a Compose file using the `extends` field or by creating multiple Compose files. See [extends](extends/index) for more details.\n\n## Common use cases\n\nCompose can be used in many different ways. Some common use cases are outlined below.\n\n### Development environments\n\nWhen you’re developing software, the ability to run an application in an isolated environment and interact with it is crucial. The Compose command line tool can be used to create the environment and interact with it.\n\nThe [Compose file](compose-file/index) provides a way to document and configure all of the application’s service dependencies (databases, queues, caches, web service APIs, etc). Using the Compose command line tool you can create and start one or more containers for each dependency with a single command (`docker-compose up`).\n\nTogether, these features provide a convenient way for developers to get started on a project. Compose can reduce a multi-page “developer getting started guide” to a single machine readable Compose file and a few commands.\n\n### Automated testing environments\n\nAn important part of any Continuous Deployment or Continuous Integration process is the automated test suite. Automated end-to-end testing requires an environment in which to run tests. Compose provides a convenient way to create and destroy isolated testing environments for your test suite. By defining the full environment in a [Compose file](compose-file/index), you can create and destroy these environments in just a few commands:\n\n``` \n$ docker-compose up -d\n$ ./run_tests\n$ docker-compose down\n```\n\n### Single host deployments\n\nCompose has traditionally been focused on development and testing workflows, but with each release we’re making progress on more production-oriented features.\n\nFor details on using production-oriented features, see [compose in production](production/index) in this documentation.\n\n## Release notes\n\nTo see a detailed list of changes for past and current releases of Docker Compose, refer to the [CHANGELOG](https://github.com/docker/compose/blob/master/CHANGELOG/).\n\n## Getting help\n\nDocker Compose is under active development. If you need help, would like to contribute, or simply want to talk about the project with like-minded individuals, we have a number of open channels for communication.\n\n- To report bugs or file feature requests: use the [issue tracker on Github](https://github.com/docker/compose/issues).\n\n- To talk about the project with people in real time: join the `#docker-compose` channel on the Docker Community Slack.\n\n- To contribute code or documentation changes: submit a [pull request on Github](https://github.com/docker/compose/pulls).\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [orchestration](https://docs.docker.com/search/?q=orchestration), [containers](https://docs.docker.com/search/?q=containers)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/](https://docs.docker.com/compose/)"
- name: Compose CLI environment variables
  id: compose/reference/envvars/index
  summary: Several environment variables are available for you to configure the Docker Compose command-line behaviour
  description: "# Compose CLI environment variables\n\nSeveral environment variables are available for you to configure the Docker Compose command-line behaviour.\n\nVariables starting with `DOCKER_` are the same as those used to configure the Docker command-line client. If you’re using `docker-machine`, then the `eval \"$(docker-machine env my-docker-vm)\"` command should set them to their correct values. (In this example, `my-docker-vm` is the name of a machine you created.)\n\n> **Note**: Some of these variables can also be provided using an [environment file](../../env-file/index).\n\n## COMPOSE_PROJECT_NAME\n\nSets the project name. This value is prepended along with the service name to the container on start up. For example, if your project name is `myapp` and it includes two services `db` and `web`, then Compose starts containers named `myapp-db-1` and `myapp-web-1` respectively.\n\nSetting this is optional. If you do not set this, the `COMPOSE_PROJECT_NAME` defaults to the `basename` of the project directory. See also the `-p` [command-line option](../index).\n\n## COMPOSE_FILE\n\nSpecify the path to a Compose file. If not provided, Compose looks for a file named `docker-compose.yml` in the current directory and then each parent directory in succession until a file by that name is found.\n\nThis variable supports multiple Compose files separated by a path separator (on Linux and macOS the path separator is `:`, on Windows it is `;`). For example: `COMPOSE_FILE=docker-compose.yml:docker-compose.prod.yml`. The path separator can also be customized using `COMPOSE_PATH_SEPARATOR`.\n\nSee also the `-f` [command-line option](../index).\n\n## COMPOSE_PROFILES\n\nSpecify one or multiple active profiles to enable. Calling `docker-compose up` with `COMPOSE_PROFILES=frontend` will start the services with the profile `frontend` and services without specified profiles.\n\nYou can specify a list of profiles separated with a comma: `COMPOSE_PROFILES=frontend,debug` will enable the profiles `frontend` and `debug`.\n\nSee also [*Using profiles with Compose*](../../profiles/index) and the `--profile` [command-line option](../index#use---profile-to-specify-one-or-more-active-profiles).\n\n## COMPOSE_API_VERSION\n\nThe Docker API only supports requests from clients which report a specific version. If you receive a `client and server don't have same version` error using `docker-compose`, you can workaround this error by setting this environment variable. Set the version value to match the server version.\n\nSetting this variable is intended as a workaround for situations where you need to run temporarily with a mismatch between the client and server version. For example, if you can upgrade the client but need to wait to upgrade the server.\n\nRunning with this variable set and a known mismatch does prevent some Docker features from working properly. The exact features that fail would depend on the Docker client and server versions. For this reason, running with this variable set is only intended as a workaround and it is not officially supported.\n\nIf you run into problems running with this set, resolve the mismatch through upgrade and remove this setting to see if your problems resolve before notifying support.\n\n## DOCKER_HOST\n\nSets the URL of the `docker` daemon. As with the Docker client, defaults to `unix:///var/run/docker.sock`.\n\n## DOCKER_TLS_VERIFY\n\nWhen set to anything other than an empty string, enables TLS communication with the `docker` daemon.\n\n## DOCKER_CERT_PATH\n\nConfigures the path to the `ca.pem`, `cert.pem`, and `key.pem` files used for TLS verification. Defaults to `~/.docker`.\n\n## COMPOSE_HTTP_TIMEOUT\n\nConfigures the time (in seconds) a request to the Docker daemon is allowed to hang before Compose considers it failed. Defaults to 60 seconds.\n\n## COMPOSE_TLS_VERSION\n\nConfigure which TLS version is used for TLS communication with the `docker` daemon. Defaults to `TLSv1`. Supported values are: `TLSv1`, `TLSv1_1`, `TLSv1_2`.\n\n## COMPOSE_CONVERT_WINDOWS_PATHS\n\nEnable path conversion from Windows-style to Unix-style in volume definitions. Users of Docker Machine on Windows should always set this. Defaults to `0`. Supported values: `true` or `1` to enable, `false` or `0` to disable.\n\n## COMPOSE_PATH_SEPARATOR\n\nIf set, the value of the `COMPOSE_FILE` environment variable is separated using this character as path separator.\n\n## COMPOSE_FORCE_WINDOWS_HOST\n\nIf set, volume declarations using the [short syntax](../../compose-file/compose-file-v3/index#short-syntax-3) are parsed assuming the host path is a Windows path, even if Compose is running on a UNIX-based system. Supported values: `true` or `1` to enable, `false` or `0` to disable.\n\n## COMPOSE_IGNORE_ORPHANS\n\nIf set, Compose doesn’t try to detect orphaned containers for the project. Supported values: `true` or `1` to enable, `false` or `0` to disable.\n\n## COMPOSE_PARALLEL_LIMIT\n\nSets a limit for the number of operations Compose can execute in parallel. The default value is `64`, and may not be set lower than `2`.\n\n## COMPOSE_INTERACTIVE_NO_CLI\n\nIf set, Compose doesn’t attempt to use the Docker CLI for interactive `run` and `exec` operations. This option is not available on Windows where the CLI is required for the aforementioned operations. Supported: `true` or `1` to enable, `false` or `0` to disable.\n\n## COMPOSE_DOCKER_CLI_BUILD\n\nConfigure whether to use the Compose python client for building images or the native docker cli. By default, Compose uses the `docker` CLI to perform builds, which allows you to use [BuildKit](https://docs.docker.com/develop/develop-images/build_enhancements/#to-enable-buildkit-builds) to perform builds.\n\nSet `COMPOSE_DOCKER_CLI_BUILD=0` to disable native builds, and to use the built-in python client.\n\n## Related information\n\n- [User guide](../../index)\n- [Installing Compose](../../install/index)\n- [Compose file reference](../../compose-file/index)\n- [Environment file](../../env-file/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [cli](https://docs.docker.com/search/?q=cli), [reference](https://docs.docker.com/search/?q=reference)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/reference/envvars/](https://docs.docker.com/compose/reference/envvars/)"
- name: Compose command compatibility with docker-compose
  id: compose/cli-command-compatibility/index
  summary: The compose command in the Docker CLI supports most of the docker-compose commands and flags
  description: "# Compose command compatibility with docker-compose\n\nThe `compose` command in the Docker CLI supports most of the `docker-compose` commands and flags. It is expected to be a drop-in replacement for `docker-compose`.\n\nIf you see any Compose functionality that is not available in the `compose` command, create an issue in the [Compose](https://github.com/docker/compose/issues) GitHub repository, so we can prioritize it.\n\n## Commands or flags not yet implemented\n\nThe following commands have not been implemented yet, and may be implemented at a later time. Let us know if these commands are a higher priority for your use cases.\n\n`compose build --memory`: This option is not yet supported by buildkit. The flag is currently supported, but is hidden to avoid breaking existing Compose usage. It does not have any effect.\n\n## Flags that will not be implemented\n\nThe list below includes the flags that we are not planning to support in Compose in the Docker CLI, either because they are already deprecated in `docker-compose`, or because they are not relevant for Compose in the Docker CLI.\n\n- `compose ps --filter KEY-VALUE` Not relevant due to its complicated usage with the `service` command and also because it is not documented properly in `docker-compose`.\n- `compose rm --all` Deprecated in docker-compose.\n- `compose scale` Deprecated in docker-compose (use `compose up --scale` instead)\n\nGlobal flags:\n\n- `--compatibility` has been resignified Docker Compose V2. This now means that in the command running V2 will behave as V1 used to do.\n  - One difference is in the word separator on container names. V1 used to use `_` as separator while V2 uses `-` to keep the names more hostname friendly. So when using `--compatibility` Docker Compose should use `_` again. Just make sure to stick to one of them otherwise Docker Compose will not be able to recognize the container as an instance of the service.\n\n## Config command\n\nThe config command is intended to show the configuration used by Docker Compose to run the actual project. As we know, at some parts of the Compose file have a short and a long format. For example, the `ports` entry. In the example below we can see the config command expanding the `ports` section:\n\ndocker-compose.yml:\n\n``` \nservices:\n  web:\n    image: nginx\n    ports:\n      - 80:80\n```\n\nWith `$ docker compose config` the output turns into:\n\n``` \nservices:\n  web:\n    image: nginx\n    networks:\n      default: null\n    ports:\n    - mode: ingress\n      target: 80\n      published: 80\n      protocol: tcp\nnetworks:\n  default:\n    name: workspace_default\n```\n\nThe result above is a full size configuration of what will be used by Docker Compose to run the project.\n\n## New commands introduced in Compose v2\n\n### Copy\n\nThe `cp` command is intended to copy files or folders between service containers and the local filesystem.  \nThis command is a bidirectional command, we can copy **from** or **to** the service containers.\n\nCopy a file from a service container to the local filesystem:\n\n``` \n$ docker compose cp my-service:~/path/to/myfile ~/local/path/to/copied/file\n```\n\nWe can also copy from the local filesystem to all the running containers of a service:\n\n``` \n$ docker compose cp --all ~/local/path/to/source/file my-service:~/path/to/copied/file\n```\n\n### List\n\nThe ls command is intended to list the Compose projects. By default, the command only lists the running projects, we can use flags to display the stopped projects, to filter by conditions and change the output to `json` format for example.\n\n``` \n$ docker compose ls --all --format json\n[{\"Name\":\"dockergithubio\",\"Status\":\"exited(1)\",\"ConfigFiles\":\"/path/to/docker.github.io/docker-compose.yml\"}]\n```\n\n## Use `--project-name` with Compose commands\n\nWith the GA version of Compose, you can run some commands:\n\n- outside of directory containing the project compose file\n- or without specifying the path of the Compose with the `--file` flag\n- or without specifying the project directory with the `--project-directory` flag\n\nWhen a compose project has been loaded once, we can just use the `-p` or `--project-name` to reference it:\n\n``` \n$ docker compose -p my-loaded-project restart my-service\n```\n\nThis option works with the `start`, `stop`, `restart` and `down` commands.\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [containers](https://docs.docker.com/search/?q=containers)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/cli-command-compatibility/](https://docs.docker.com/compose/cli-command-compatibility/)"
- name: Compose file build reference
  id: compose/compose-file/build/index
  summary: Compose specification is a platform-neutral way to define multi-container applications
  description: "# Compose file build reference\n\nCompose specification is a platform-neutral way to define multi-container applications. A Compose implementation focusing on development use-case to run application on local machine will obviously also support (re)building application from sources. The Compose Build specification allows to define the build process within a Compose file in a portable way.\n\n## Definitions\n\nCompose Specification is extended to support an OPTIONAL `build` subsection on services. This section define the build requirements for service container image. Only a subset of Compose file services MAY define such a Build subsection, others being created based on `Image` attribute. When a Build subsection is present for a service, it is *valid* for a Compose file to miss an `Image` attribute for corresponding service, as Compose implementation can build image from source.\n\nBuild can be either specified as a single string defining a context path, or as a detailed build definition.\n\nIn the former case, the whole path is used as a Docker context to execute a docker build, looking for a canonical `Dockerfile` at context root. Context path can be absolute or relative, and if so relative path MUST be resolved from Compose file parent folder. As an absolute path prevent the Compose file to be portable, Compose implementation SHOULD warn user accordingly.\n\nIn the later case, build arguments can be specified, including an alternate `Dockerfile` location. This one can be absolute or relative path. If Dockerfile path is relative, it MUST be resolved from context path. As an absolute path prevent the Compose file to be portable, Compose implementation SHOULD warn user if an absolute alternate Dockerfile path is used.\n\n## Consistency with Image\n\nWhen service definition do include both `Image` attribute and a `Build` section, Compose implementation can’t guarantee a pulled image is strictly equivalent to building the same image from sources. Without any explicit user directives, Compose implementation with Build support MUST first try to pull Image, then build from source if image was not found on registry. Compose implementation MAY offer options to customize this behaviour by user request.\n\n## Publishing built images\n\nCompose implementation with Build support SHOULD offer an option to push built images to a registry. Doing so, it MUST NOT try to push service images without an `Image` attribute. Compose implementation SHOULD warn user about missing `Image` attribute which prevent image being pushed.\n\nCompose implementation MAY offer a mechanism to compute an `Image` attribute for service when not explicitly declared in yaml file. In such a case, the resulting Compose configuration is considered to have a valid `Image` attribute, whenever the actual raw yaml file doesn’t explicitly declare one.\n\n## Illustrative sample\n\nThe following sample illustrates Compose specification concepts with a concrete sample application. The sample is non-normative.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    build: ./webapp\n\n  backend:\n    image: awesome/database\n    build:\n      context: backend\n      dockerfile: ../backend.Dockerfile\n\n  custom:\n    build: ~/custom\n```\n\nWhen used to build service images from source, such a Compose file will create three docker images:\n\n- `awesome/webapp` docker image is build using `webapp` sub-directory within Compose file parent folder as docker build context. Lack of a `Dockerfile` within this folder will throw an error.\n- `awesome/database` docker image is build using `backend` sub-directory within Compose file parent folder. `backend.Dockerfile` file is used to define build steps, this file is searched relative to context path, which means for this sample `..` will resolve to Compose file parent folder, so `backend.Dockerfile` is a sibling file.\n- a docker image is build using `custom` directory within user’s HOME as docker context. Compose implementation warn user about non-portable path used to build image.\n\nOn push, both `awesome/webapp` and `awesome/database` docker images are pushed to (default) registry. `custom` service image is skipped as no `Image` attribute is set and user is warned about this missing attribute.\n\n## Build definition\n\nThe `build` element define configuration options that are applied by Compose implementations to build Docker image from source. `build` can be specified either as a string containing a path to the build context or a detailed structure:\n\n``` \nservices:\n  webapp:\n    build: ./dir\n```\n\nUsing this string syntax, only the build context can be configured as a relative path to the Compose file’s parent folder. This path MUST be a directory and contain a `Dockerfile`.\n\nAlternatively `build` can be an object with fields defined as follow\n\n### context (REQUIRED)\n\n`context` defines either a path to a directory containing a Dockerfile, or a url to a git repository.\n\nWhen the value supplied is a relative path, it MUST be interpreted as relative to the location of the Compose file. Compose implementations MUST warn user about absolute path used to define build context as those prevent Compose file for being portable.\n\n``` \nbuild:\n  context: ./dir\n```\n\n### dockerfile\n\n`dockerfile` allows to set an alternate Dockerfile. A relative path MUST be resolved from the build context. Compose implementations MUST warn user about absolute path used to define Dockerfile as those prevent Compose file for being portable.\n\n``` \nbuild:\n  context: .\n  dockerfile: webapp.Dockerfile\n```\n\n### args\n\n`args` define build arguments, i.e. Dockerfile `ARG` values.\n\nUsing following Dockerfile:\n\n``` \nARG GIT_COMMIT\nRUN echo \"Based on commit: $GIT_COMMIT\"\n```\n\n`args` can be set in Compose file under the `build` key to define `GIT_COMMIT`. `args` can be set a mapping or a list:\n\n``` \nbuild:\n  context: .\n  args:\n    GIT_COMMIT: cdc3b19\n```\n\n``` \nbuild:\n  context: .\n  args:\n    - GIT_COMMIT=cdc3b19\n```\n\nValue can be omitted when specifying a build argument, in which case its value at build time MUST be obtained by user interaction, otherwise build arg won’t be set when building the Docker image.\n\n``` \nargs:\n  - GIT_COMMIT\n```\n\n### ssh\n\n`ssh` defines SSH authentications that the image builder SHOULD use during image build (e.g., cloning private repository)\n\n`ssh` property syntax can be either:\n\n- `default` - let the builder connect to the ssh-agent.\n- `ID=path` - a key/value definition of an ID and the associated path. Can be either a [PEM](https://en.wikipedia.org/wiki/Privacy-Enhanced_Mail) file, or path to ssh-agent socket\n\nSimple `default` sample\n\n``` \nbuild:\n  context: .\n  ssh: \n    - default   # mount the default ssh agent\n```\n\nor\n\n``` \nbuild:\n  context: .\n  ssh: [\"default\"]   # mount the default ssh agent\n```\n\nUsing a custom id `myproject` with path to a local SSH key:\n\n``` \nbuild:\n  context: .\n  ssh: \n    - myproject=~/.ssh/myproject.pem\n```\n\nImage builder can then rely on this to mount SSH key during build. For illustration, [BuildKit extended syntax](#) can be used to mount ssh key set by ID and access a secured resource:\n\n`RUN --mount=type=ssh,id=myproject git clone ...`\n\n### cache_from\n\n`cache_from` defines a list of sources the Image builder SHOULD use for cache resolution.\n\nCache location syntax MUST follow the global format `[NAME|type=TYPE[,KEY=VALUE]]`. Simple `NAME` is actually a shortcut notation for `type=registry,ref=NAME`.\n\nCompose Builder implementations MAY support custom types, the Compose Specification defines canonical types which MUST be supported:\n\n- `registry` to retrieve build cache from an OCI image set by key `ref`\n\n``` \nbuild:\n  context: .\n  cache_from:\n    - alpine:latest\n    - type=local,src=path/to/cache\n    - type=gha\n```\n\nUnsupported caches MUST be ignored and not prevent user from building image.\n\n### cache_to\n\n`cache_to` defines a list of export locations to be used to share build cache with future builds.\n\n``` \nbuild:\n  context: .\n  cache_to: \n   - user/app:cache\n   - type=local,dest=path/to/cache\n```\n\nCache target is defined using the same `type=TYPE[,KEY=VALUE]` syntax defined by [`cache_from`](#cache_from).\n\nUnsupported cache target MUST be ignored and not prevent user from building image.\n\n### extra_hosts\n\n`extra_hosts` adds hostname mappings at build-time. Use the same syntax as [extra_hosts](../index#extra_hosts).\n\n``` \nextra_hosts:\n  - \"somehost:162.242.195.82\"\n  - \"otherhost:50.31.209.229\"\n```\n\nCompose implementations MUST create matching entry with the IP address and hostname in the container’s network configuration, which means for Linux `/etc/hosts` will get extra lines:\n\n``` \n162.242.195.82  somehost\n50.31.209.229   otherhost\n```\n\n### isolation\n\n`isolation` specifies a build’s container isolation technology. Like [isolation](../index#isolation) supported values are platform-specific.\n\n### labels\n\n`labels` add metadata to the resulting image. `labels` can be set either as an array or a map.\n\nreverse-DNS notation SHOULD be used to prevent labels from conflicting with those used by other software.\n\n``` \nbuild:\n  context: .\n  labels:\n    com.example.description: \"Accounting webapp\"\n    com.example.department: \"Finance\"\n    com.example.label-with-empty-value: \"\"\n```\n\n``` \nbuild:\n  context: .\n  labels:\n    - \"com.example.description=Accounting webapp\"\n    - \"com.example.department=Finance\"\n    - \"com.example.label-with-empty-value\"\n```\n\n### shm_size\n\n`shm_size` set the size of the shared memory (`/dev/shm` partition on Linux) allocated for building Docker image. Specify as an integer value representing the number of bytes or as a string expressing a [byte value](../index#specifying-byte-values).\n\n``` \nbuild:\n  context: .\n  shm_size: '2gb'\n```\n\n``` \nbuild:\n  context: .\n  shm_size: 10000000\n```\n\n### target\n\n`target` defines the stage to build as defined inside a multi-stage `Dockerfile`.\n\n``` \nbuild:\n  context: .\n  target: prod\n```\n\n## Implementations\n\n- [docker-compose](../../index)\n- [buildX bake](https://docs.docker.com/buildx/working-with-buildx/)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/compose-file/build/](https://docs.docker.com/compose/compose-file/build/)"
- name: Compose file deploy reference
  id: compose/compose-file/deploy/index
  summary: Compose specification is a platform-neutral way to define multi-container applications
  description: "# Compose file deploy reference\n\nCompose specification is a platform-neutral way to define multi-container applications. A Compose implementation supporting deployment of application model MAY require some additional metadata as the Compose application model is way too abstract to reflect actual infrastructure needs per service, or lifecycle constraints.\n\nCompose Specification Deployment allows users to declare additional metadata on services so Compose implementations get relevant data to allocate adequate resources on platform and configure them to match user’s needs.\n\n## Definitions\n\nCompose Specification is extended to support an OPTIONAL `deploy` subsection on services. This section define runtime requirements for a service.\n\n### endpoint_mode\n\n`endpoint_mode` specifies a service discovery method for external clients connecting to a service. Default and available values are platform specific, anyway the Compose specification define two canonical values:\n\n- `endpoint_mode: vip`: Assigns the service a virtual IP (VIP) that acts as the front end for clients to reach the service on a network. Platform routes requests between the client and nodes running the service, without client knowledge of how many nodes are participating in the service or their IP addresses or ports.\n\n- `endpoint_mode: dnsrr`: Platform sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses (DNS round-robin), and the client connects directly to one of these.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    ports:\n      - \"8080:80\"\n    deploy:\n      mode: replicated\n      replicas: 2\n      endpoint_mode: vip\n```\n\n### labels\n\n`labels` specifies metadata for the service. These labels MUST *only* be set on the service and *not* on any containers for the service. This assumes the platform has some native concept of “service” that can match Compose application model.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    deploy:\n      labels:\n        com.example.description: \"This label will appear on the web service\"\n```\n\n### mode\n\n`mode` define the replication model used to run the service on platform. Either `global` (exactly one container per physical node) or `replicated` (a specified number of containers). The default is `replicated`.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    deploy:\n      mode: global\n```\n\n### placement\n\n`placement` specifies constraints and preferences for platform to select a physical node to run service containers.\n\n#### constraints\n\n`constraints` defines a REQUIRED property the platform’s node MUST fulfill to run service container. Can be set either by a list or a map with string values.\n\n``` \ndeploy:\n  placement:\n    constraints:\n      - disktype=ssd\n```\n\n``` \ndeploy:\n  placement:\n    constraints:\n      disktype: ssd\n```\n\n#### preferences\n\n`preferences` defines a property the platform’s node SHOULD fulfill to run service container. Can be set either by a list or a map with string values.\n\n``` \ndeploy:\n  placement:\n    preferences:\n      - datacenter=us-east\n```\n\n``` \ndeploy:\n  placement:\n    preferences:\n      datacenter: us-east\n```\n\n### replicas\n\nIf the service is `replicated` (which is the default), `replicas` specifies the number of containers that SHOULD be running at any given time.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    deploy:\n      mode: replicated\n      replicas: 6\n```\n\n### resources\n\n`resources` configures physical resource constraints for container to run on platform. Those constraints can be configured as a:\n\n- `limits`: The platform MUST prevent container to allocate more\n- `reservations`: The platform MUST guarantee container can allocate at least the configured amount\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 50M\n          pids: 1\n        reservations:\n          cpus: '0.25'\n          memory: 20M\n```\n\n#### cpus\n\n`cpus` configures a limit or reservation for how much of the available CPU resources (as number of cores) a container can use.\n\n#### memory\n\n`memory` configures a limit or reservation on the amount of memory a container can allocate, set as a string expressing a [byte value](../index#specifying-byte-values).\n\n#### pids\n\n`pids` tunes a container’s PIDs limit, set as an integer.\n\n#### devices\n\n`devices` configures reservations of the devices a container can use. It contains a list of reservations, each set as an object with the following parameters: `capabilities`, `driver`, `count`, `device_ids` and `options`.\n\nDevices are reserved using a list of capabilities, making `capabilities` the only required field. A device MUST satisfy all the requested capabilities for a successful reservation.\n\n##### capabilities\n\n`capabilities` are set as a list of strings, expressing both generic and driver specific capabilities. The following generic capabilities are recognized today:\n\n- `gpu`: Graphics accelerator\n- `tpu`: AI accelerator\n\nTo avoid name clashes, driver specific capabilities MUST be prefixed with the driver name. For example, reserving an nVidia CUDA-enabled accelerator might look like this:\n\n``` \ndeploy:\n  resources:\n    reservations:\n      devices:\n        - capabilities: [\"nvidia-compute\"]\n```\n\n##### driver\n\nA different driver for the reserved device(s) can be requested using `driver` field. The value is specified as a string.\n\n``` \ndeploy:\n  resources:\n    reservations:\n      devices:\n        - capabilities: [\"nvidia-compute\"]\n          driver: nvidia\n```\n\n##### count\n\nIf `count` is set to `all` or not specified, Compose implementations MUST reserve all devices that satisfy the requested capabilities. Otherwise, Compose implementations MUST reserve at least the number of devices specified. The value is specified as an integer.\n\n``` \ndeploy:\n  resources:\n    reservations:\n      devices:\n        - capabilities: [\"tpu\"]\n          count: 2\n```\n\n`count` and `device_ids` fields are exclusive. Compose implementations MUST return an error if both are specified.\n\n##### device_ids\n\nIf `device_ids` is set, Compose implementations MUST reserve devices with the specified IDs providing they satisfy the requested capabilities. The value is specified as a list of strings.\n\n``` \ndeploy:\n  resources:\n    reservations:\n      devices:\n        - capabilities: [\"gpu\"]\n          device_ids: [\"GPU-f123d1c9-26bb-df9b-1c23-4a731f61d8c7\"]\n```\n\n`count` and `device_ids` fields are exclusive. Compose implementations MUST return an error if both are specified.\n\n##### options\n\nDriver specific options can be set with `options` as key-value pairs.\n\n``` \ndeploy:\n  resources:\n    reservations:\n      devices:\n        - capabilities: [\"gpu\"]\n          driver: gpuvendor\n          options:\n            virtualization: false\n```\n\n### restart_policy\n\n`restart_policy` configures if and how to restart containers when they exit. If `restart_policy` is not set, Compose implementations MUST consider `restart` field set by service configuration.\n\n- `condition`: One of `none`, `on-failure` or `any` (default: `any`).\n- `delay`: How long to wait between restart attempts, specified as a [duration](../index#specifying-durations) (default: 0).\n- `max_attempts`: How many times to attempt to restart a container before giving up (default: never give up). If the restart does not succeed within the configured `window`, this attempt doesn’t count toward the configured `max_attempts` value. For example, if `max_attempts` is set to ‘2’, and the restart fails on the first attempt, more than two restarts MUST be attempted.\n- `window`: How long to wait before deciding if a restart has succeeded, specified as a [duration](../index#specifying-durations) (default: decide immediately).\n\n``` \ndeploy:\n  restart_policy:\n    condition: on-failure\n    delay: 5s\n    max_attempts: 3\n    window: 120s\n```\n\n### rollback_config\n\n`rollback_config` configures how the service should be rollbacked in case of a failing update.\n\n- `parallelism`: The number of containers to rollback at a time. If set to 0, all containers rollback simultaneously.\n- `delay`: The time to wait between each container group’s rollback (default 0s).\n- `failure_action`: What to do if a rollback fails. One of `continue` or `pause` (default `pause`)\n- `monitor`: Duration after each task update to monitor for failure `(ns|us|ms|s|m|h)` (default 0s).\n- `max_failure_ratio`: Failure rate to tolerate during a rollback (default 0).\n- `order`: Order of operations during rollbacks. One of `stop-first` (old task is stopped before starting new one), or `start-first` (new task is started first, and the running tasks briefly overlap) (default `stop-first`).\n\n### update_config\n\n`update_config` configures how the service should be updated. Useful for configuring rolling updates.\n\n- `parallelism`: The number of containers to update at a time.\n- `delay`: The time to wait between updating a group of containers.\n- `failure_action`: What to do if an update fails. One of `continue`, `rollback`, or `pause` (default: `pause`).\n- `monitor`: Duration after each task update to monitor for failure `(ns|us|ms|s|m|h)` (default 0s).\n- `max_failure_ratio`: Failure rate to tolerate during an update.\n- `order`: Order of operations during updates. One of `stop-first` (old task is stopped before starting new one), or `start-first` (new task is started first, and the running tasks briefly overlap) (default `stop-first`).\n\n``` \ndeploy:\n  update_config:\n    parallelism: 2\n    delay: 10s\n    order: stop-first\n```\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/compose-file/deploy/](https://docs.docker.com/compose/compose-file/deploy/)"
- name: Compose file version 2 reference
  id: compose/compose-file/compose-file-v2/index
  summary: These topics describe version 2 of the Compose file format
  description: "# Compose file version 2 reference\n\n## Reference and guidelines\n\nThese topics describe version 2 of the Compose file format.\n\n## Compose and Docker compatibility matrix\n\nThere are several versions of the Compose file format – 1, 2, 2.x, and 3.x. The table below is a quick look. For full details on what each version includes and how to upgrade, see **[About versions and upgrading](../compose-versioning/index)**.\n\nThis table shows which Compose file versions support specific Docker releases.\n\n| **Compose file format** | **Docker Engine release** |\n|-------------------------|---------------------------|\n| Compose specification   | 19.03.0+                  |\n| 3.8                     | 19.03.0+                  |\n| 3.7                     | 18.06.0+                  |\n| 3.6                     | 18.02.0+                  |\n| 3.5                     | 17.12.0+                  |\n| 3.4                     | 17.09.0+                  |\n| 3.3                     | 17.06.0+                  |\n| 3.2                     | 17.04.0+                  |\n| 3.1                     | 1.13.1+                   |\n| 3.0                     | 1.13.0+                   |\n| 2.4                     | 17.12.0+                  |\n| 2.3                     | 17.06.0+                  |\n| 2.2                     | 1.13.0+                   |\n| 2.1                     | 1.12.0+                   |\n| 2.0                     | 1.10.0+                   |\n\nIn addition to Compose file format versions shown in the table, the Compose itself is on a release schedule, as shown in [Compose releases](https://github.com/docker/compose/releases/), but file format versions do not necessarily increment with each release. For example, Compose file format 3.0 was first introduced in [Compose release 1.10.0](https://github.com/docker/compose/releases/tag/1.10.0), and versioned gradually in subsequent releases.\n\nThe latest Compose file format is defined by the [Compose Specification](https://github.com/compose-spec/compose-spec/blob/master/spec/) and is implemented by Docker Compose **1.27.0+**.\n\n## Service configuration reference\n\nThe Compose file is a [YAML](https://yaml.org) file defining [services](#service-configuration-reference), [networks](#network-configuration-reference) and [volumes](#volume-configuration-reference). The default path for a Compose file is `./docker-compose.yml`.\n\n> **Tip**: You can use either a `.yml` or `.yaml` extension for this file. They both work.\n\nA service definition contains configuration that is applied to each container started for that service, much like passing command-line parameters to `docker run`. Likewise, network and volume definitions are analogous to `docker network create` and `docker volume create`.\n\nAs with `docker run`, options specified in the Dockerfile, such as `CMD`, `EXPOSE`, `VOLUME`, `ENV`, are respected by default - you don’t need to specify them again in `docker-compose.yml`.\n\nYou can use environment variables in configuration values with a Bash-like `${VARIABLE}` syntax - see [variable substitution](#variable-substitution) for full details.\n\nThis section contains a list of all configuration options supported by a service definition in version 2.\n\n### blkio_config\n\nA set of configuration options to set block IO limits for this service.\n\n``` \nversion: \"2.4\"\nservices:\n  foo:\n    image: busybox\n    blkio_config:\n      weight: 300\n      weight_device:\n        - path: /dev/sda\n          weight: 400\n      device_read_bps:\n        - path: /dev/sdb\n          rate: '12mb'\n      device_read_iops:\n        - path: /dev/sdb\n          rate: 120\n      device_write_bps:\n        - path: /dev/sdb\n          rate: '1024k'\n      device_write_iops:\n        - path: /dev/sdb\n          rate: 30\n```\n\n#### device_read_bps, device_write_bps\n\nSet a limit in bytes per second for read / write operations on a given device. Each item in the list must have two keys:\n\n- `path`, defining the symbolic path to the affected device\n- `rate`, either as an integer value representing the number of bytes or as a string expressing a [byte value](#specifying-byte-values).\n\n#### device_read_iops, device_write_iops\n\nSet a limit in operations per second for read / write operations on a given device. Each item in the list must have two keys:\n\n- `path`, defining the symbolic path to the affected device\n- `rate`, as an integer value representing the permitted number of operations per second.\n\n#### weight\n\nModify the proportion of bandwidth allocated to this service relative to other services. Takes an integer value between 10 and 1000, with 500 being the default.\n\n#### weight_device\n\nFine-tune bandwidth allocation by device. Each item in the list must have two keys:\n\n- `path`, defining the symbolic path to the affected device\n- `weight`, an integer value between 10 and 1000\n\n### build\n\nConfiguration options that are applied at build time.\n\n`build` can be specified either as a string containing a path to the build context:\n\n``` \nversion: \"2.4\"\nservices:\n  webapp:\n    build: ./dir\n```\n\nOr, as an object with the path specified under [context](#context) and optionally [Dockerfile](#dockerfile) and [args](#args):\n\n``` \nversion: \"2.4\"\nservices:\n  webapp:\n    build:\n      context: ./dir\n      dockerfile: Dockerfile-alternate\n      args:\n        buildno: 1\n```\n\nIf you specify `image` as well as `build`, then Compose names the built image with the `webapp` and optional `tag` specified in `image`:\n\n``` \nbuild: ./dir\nimage: webapp:tag\n```\n\nThis results in an image named `webapp` and tagged `tag`, built from `./dir`.\n\n#### context\n\n> Added in [version 2.0](../compose-versioning/index#version-2) file format.\n\nEither a path to a directory containing a Dockerfile, or a url to a git repository.\n\nWhen the value supplied is a relative path, it is interpreted as relative to the location of the Compose file. This directory is also the build context that is sent to the Docker daemon.\n\nCompose builds and tags it with a generated name, and uses that image thereafter.\n\n``` \nbuild:\n  context: ./dir\n```\n\n#### dockerfile\n\nAlternate Dockerfile.\n\nCompose uses an alternate file to build with. A build path must also be specified.\n\n``` \nbuild:\n  context: .\n  dockerfile: Dockerfile-alternate\n```\n\n#### args\n\n> Added in [version 2.0](../compose-versioning/index#version-2) file format.\n\nAdd build arguments, which are environment variables accessible only during the build process.\n\nFirst, specify the arguments in your Dockerfile:\n\n``` \n# syntax=docker/dockerfile:1\n\nARG buildno\nARG gitcommithash\n\nRUN echo \"Build number: $buildno\"\nRUN echo \"Based on commit: $gitcommithash\"\n```\n\nThen specify the arguments under the `build` key. You can pass a mapping or a list:\n\n``` \nbuild:\n  context: .\n  args:\n    buildno: 1\n    gitcommithash: cdc3b19\n```\n\n``` \nbuild:\n  context: .\n  args:\n    - buildno=1\n    - gitcommithash=cdc3b19\n```\n\n> Scope of build-args\n>\n> In your Dockerfile, if you specify `ARG` before the `FROM` instruction, `ARG` is not available in the build instructions under `FROM`. If you need an argument to be available in both places, also specify it under the `FROM` instruction. Refer to the [understand how ARGS and FROM interact](../../../engine/reference/builder/index#understand-how-arg-and-from-interact) section in the documentation for usage details.\n\nYou can omit the value when specifying a build argument, in which case its value at build time is the value in the environment where Compose is running.\n\n``` \nargs:\n  - buildno\n  - gitcommithash\n```\n\n> Tip when using boolean values\n>\n> YAML boolean values (`\"true\"`, `\"false\"`, `\"yes\"`, `\"no\"`, `\"on\"`, `\"off\"`) must be enclosed in quotes, so that the parser interprets them as strings.\n\n#### cache_from\n\n> Added in [version 2.2](../compose-versioning/index#version-22) file format\n\nA list of images that the engine uses for cache resolution.\n\n``` \nbuild:\n  context: .\n  cache_from:\n    - alpine:latest\n    - corp/web_app:3.14\n```\n\n#### extra_hosts\n\nAdd hostname mappings at build-time. Use the same values as the docker client `--add-host` parameter.\n\n``` \nextra_hosts:\n  - \"somehost:162.242.195.82\"\n  - \"otherhost:50.31.209.229\"\n```\n\nAn entry with the ip address and hostname is created in `/etc/hosts` inside containers for this build, e.g:\n\n``` \n162.242.195.82  somehost\n50.31.209.229   otherhost\n```\n\n#### isolation\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nSpecify a build’s container isolation technology. On Linux, the only supported value is `default`. On Windows, acceptable values are `default`, `process` and `hyperv`. Refer to the [Docker Engine docs](../../../engine/reference/commandline/run/index#specify-isolation-technology-for-container---isolation) for details.\n\nIf unspecified, Compose will use the `isolation` value found in the service’s definition to determine the value to use for builds.\n\n#### labels\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format\n\nAdd metadata to the resulting image using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nbuild:\n  context: .\n  labels:\n    com.example.description: \"Accounting webapp\"\n    com.example.department: \"Finance\"\n    com.example.label-with-empty-value: \"\"\n```\n\n``` \nbuild:\n  context: .\n  labels:\n    - \"com.example.description=Accounting webapp\"\n    - \"com.example.department=Finance\"\n    - \"com.example.label-with-empty-value\"\n```\n\n#### network\n\n> Added in [version 2.2](../compose-versioning/index#version-22) file format\n\nSet the network containers connect to for the `RUN` instructions during build.\n\n``` \nbuild:\n  context: .\n  network: host\n```\n\n``` \nbuild:\n  context: .\n  network: custom_network_1\n```\n\nUse `none` to disable networking during build:\n\n``` \nbuild:\n  context: .\n  network: none\n```\n\n#### shm_size\n\n> Added in [version 2.3](../compose-versioning/index#version-23) file format\n\nSet the size of the `/dev/shm` partition for this build’s containers. Specify as an integer value representing the number of bytes or as a string expressing a [byte value](#specifying-byte-values).\n\n``` \nbuild:\n  context: .\n  shm_size: '2gb'\n```\n\n``` \nbuild:\n  context: .\n  shm_size: 10000000\n```\n\n#### target\n\n> Added in [version 2.3](../compose-versioning/index#version-23) file format\n\nBuild the specified stage as defined inside the `Dockerfile`. See the [multi-stage build docs](https://docs.docker.com/develop/develop-images/multistage-build/) for details.\n\n``` \nbuild:\n  context: .\n  target: prod\n```\n\n### cap_add, cap_drop\n\nAdd or drop container capabilities. See `man 7 capabilities` for a full list.\n\n``` \ncap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n```\n\n### cgroup_parent\n\nSpecify an optional parent cgroup for the container.\n\n``` \ncgroup_parent: m-executor-abcd\n```\n\n### command\n\nOverride the default command.\n\n``` \ncommand: bundle exec thin -p 3000\n```\n\nThe command can also be a list, in a manner similar to [dockerfile](../../../engine/reference/builder/index#cmd):\n\n``` \ncommand: [\"bundle\", \"exec\", \"thin\", \"-p\", \"3000\"]\n```\n\n### container_name\n\nSpecify a custom container name, rather than a generated default name.\n\n``` \ncontainer_name: my-web-container\n```\n\nBecause Docker container names must be unique, you cannot scale a service beyond 1 container if you have specified a custom name. Attempting to do so results in an error.\n\n### cpu_rt_runtime, cpu_rt_period\n\n> Added in [version 2.2](../compose-versioning/index#version-22) file format\n\nConfigure CPU allocation parameters using the Docker daemon realtime scheduler.\n\n``` \ncpu_rt_runtime: '400ms'\ncpu_rt_period: '1400us'\n```\n\nInteger values will use microseconds as units:\n\n``` \ncpu_rt_runtime: 95000\ncpu_rt_period: 11000\n```\n\n### device_cgroup_rules\n\n> Added in [version 2.3](../compose-versioning/index#version-23) file format.\n\nAdd rules to the cgroup allowed devices list.\n\n``` \ndevice_cgroup_rules:\n  - 'c 1:3 mr'\n  - 'a 7:* rmw'\n```\n\n### devices\n\nList of device mappings. Uses the same format as the `--device` docker client create option.\n\n``` \ndevices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n```\n\n### depends_on\n\n> Added in [version 2.0](../compose-versioning/index#version-2) file format.\n\nExpress dependency between services. Service dependencies cause the following behaviors:\n\n- `docker-compose up` starts services in dependency order. In the following example, `db` and `redis` are started before `web`.\n- `docker-compose up SERVICE` automatically includes `SERVICE`’s dependencies. In the example below, `docker-compose up web` also creates and starts `db` and `redis`.\n- `docker-compose stop` stops services in dependency order. In the following example, `web` is stopped before `db` and `redis`.\n\nSimple example:\n\n``` \nversion: \"2.4\"\nservices:\n  web:\n    build: .\n    depends_on:\n      - db\n      - redis\n  redis:\n    image: redis\n  db:\n    image: postgres\n```\n\n> **Note**\n>\n> `depends_on` does not wait for `db` and `redis` to be “ready” before starting `web` - only until they have been started. If you need to wait for a service to be ready, see [Controlling startup order](../../startup-order/index) for more on this problem and strategies for solving it.\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nA healthcheck indicates that you want a dependency to wait for another container to be “healthy” (as indicated by a successful state from the healthcheck) before starting.\n\nExample:\n\n``` \nversion: \"2.4\"\nservices:\n  web:\n    build: .\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_started\n  redis:\n    image: redis\n  db:\n    image: postgres\n    healthcheck:\n      test: \"exit 0\"\n```\n\nIn the above example, Compose waits for the `redis` service to be started (legacy behavior) and the `db` service to be healthy before starting `web`.\n\nSee the [healthcheck section](#healthcheck) for complementary information.\n\n### dns\n\nCustom DNS servers. Can be a single value or a list.\n\n``` \ndns: 8.8.8.8\n```\n\n``` \ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n```\n\n### dns_opt\n\nList of custom DNS options to be added to the container’s `resolv.conf` file.\n\n``` \ndns_opt:\n  - use-vc\n  - no-tld-query\n```\n\n### dns_search\n\nCustom DNS search domains. Can be a single value or a list.\n\n``` \ndns_search: example.com\n```\n\n``` \ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n```\n\n### entrypoint\n\nOverride the default entrypoint.\n\n``` \nentrypoint: /code/entrypoint.sh\n```\n\nThe entrypoint can also be a list, in a manner similar to [dockerfile](../../../engine/reference/builder/index#entrypoint):\n\n``` \nentrypoint: [\"php\", \"-d\", \"memory_limit=-1\", \"vendor/bin/phpunit\"]\n```\n\n> **Note**\n>\n> Setting `entrypoint` both overrides any default entrypoint set on the service’s image with the `ENTRYPOINT` Dockerfile instruction, *and* clears out any default command on the image - meaning that if there’s a `CMD` instruction in the Dockerfile, it is ignored.\n\n### env_file\n\nAdd environment variables from a file. Can be a single value or a list.\n\nIf you have specified a Compose file with `docker-compose -f FILE`, paths in `env_file` are relative to the directory that file is in.\n\nEnvironment variables declared in the [environment](#environment) section *override* these values – this holds true even if those values are empty or undefined.\n\n``` \nenv_file: .env\n```\n\n``` \nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/runtime_opts.env\n```\n\nCompose expects each line in an env file to be in `VAR=VAL` format. Lines beginning with `#` are treated as comments and are ignored. Blank lines are also ignored.\n\n``` \n# Set Rails/Rack environment\nRACK_ENV=development\n```\n\n> **Note**\n>\n> If your service specifies a [build](#build) option, variables defined in environment files are *not* automatically visible during the build. Use the [args](#args) sub-option of `build` to define build-time environment variables.\n\nThe value of `VAL` is used as is and not modified at all. For example if the value is surrounded by quotes (as is often the case of shell variables), the quotes are included in the value passed to Compose.\n\nKeep in mind that *the order of files in the list is significant in determining the value assigned to a variable that shows up more than once*. The files in the list are processed from the top down. For the same variable specified in file `a.env` and assigned a different value in file `b.env`, if `b.env` is listed below (after), then the value from `b.env` stands. For example, given the following declaration in `docker-compose.yml`:\n\n``` \nservices:\n  some-service:\n    env_file:\n      - a.env\n      - b.env\n```\n\nAnd the following files:\n\n``` \n# a.env\nVAR=1\n```\n\nand\n\n``` \n# b.env\nVAR=hello\n```\n\n`$VAR` is `hello`.\n\n### environment\n\nAdd environment variables. You can use either an array or a dictionary. Any boolean values (true, false, yes, no) need to be enclosed in quotes to ensure they are not converted to True or False by the YML parser.\n\nEnvironment variables with only a key are resolved to their values on the machine Compose is running on, which can be helpful for secret or host-specific values.\n\n``` \nenvironment:\n  RACK_ENV: development\n  SHOW: 'true'\n  SESSION_SECRET:\n```\n\n``` \nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET\n```\n\n> **Note**\n>\n> If your service specifies a [build](#build) option, variables defined in `environment` are *not* automatically visible during the build. Use the [args](#args) sub-option of `build` to define build-time environment variables.\n\n### expose\n\nExpose ports without publishing them to the host machine - they’ll only be accessible to linked services. Only the internal port can be specified.\n\n``` \nexpose:\n  - \"3000\"\n  - \"8000\"\n```\n\n### extends\n\nExtend another service, in the current file or another, optionally overriding configuration.\n\nYou can use `extends` on any service together with other configuration keys. The `extends` value must be a dictionary defined with a required `service` and an optional `file` key.\n\n``` \nextends:\n  file: common.yml\n  service: webapp\n```\n\nThe `service` is the name of the service being extended, for example `web` or `database`. The `file` is the location of a Compose configuration file defining that service.\n\nIf you omit the `file` Compose looks for the service configuration in the current file. The `file` value can be an absolute or relative path. If you specify a relative path, Compose treats it as relative to the location of the current file.\n\nYou can extend a service that itself extends another. You can extend indefinitely. Compose does not support circular references and `docker-compose` returns an error if it encounters one.\n\nFor more on `extends`, see the [the extends documentation](../../extends/index#extending-services).\n\n### external_links\n\nLink to containers started outside this `docker-compose.yml` or even outside of Compose, especially for containers that provide shared or common services. `external_links` follow semantics similar to the legacy option `links` when specifying both the container name and the link alias (`CONTAINER:ALIAS`).\n\n``` \nexternal_links:\n  - redis_1\n  - project_db_1:mysql\n  - project_db_1:postgresql\n```\n\n> **Note**\n>\n> If you’re using the [version 2 or above file format](../compose-versioning/index#version-2), the externally-created containers must be connected to at least one of the same networks as the service that is linking to them. [Links](index#links) are a legacy option. We recommend using [networks](#networks) instead.\n\n### extra_hosts\n\nAdd hostname mappings. Use the same values as the docker client `--add-host` parameter.\n\n``` \nextra_hosts:\n  - \"somehost:162.242.195.82\"\n  - \"otherhost:50.31.209.229\"\n```\n\nAn entry with the ip address and hostname is created in `/etc/hosts` inside containers for this service, e.g:\n\n``` \n162.242.195.82  somehost\n50.31.209.229   otherhost\n```\n\n### group_add\n\nSpecify additional groups (by name or number) which the user inside the container should be a member of. Groups must exist in both the container and the host system to be added. An example of where this is useful is when multiple containers (running as different users) need to all read or write the same file on the host system. That file can be owned by a group shared by all the containers, and specified in `group_add`. See the [Docker documentation](../../../engine/reference/run/index#additional-groups) for more details.\n\nA full example:\n\n``` \nversion: \"2.4\"\nservices:\n  myservice:\n    image: alpine\n    group_add:\n      - mail\n```\n\nRunning `id` inside the created container shows that the user belongs to the `mail` group, which would not have been the case if `group_add` were not used.\n\n### healthcheck\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nConfigure a check that’s run to determine whether or not containers for this service are “healthy”. See the docs for the [HEALTHCHECK Dockerfile instruction](../../../engine/reference/builder/index#healthcheck) for details on how healthchecks work.\n\n``` \nhealthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n  interval: 1m30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n```\n\n`interval`, `timeout` and `start_period` are specified as [durations](#specifying-durations).\n\n> Added in [version 2.3](../compose-versioning/index#version-23) file format.\n>\n> The `start_period` option was added in file format 2.3.\n\n`test` must be either a string or a list. If it’s a list, the first item must be either `NONE`, `CMD` or `CMD-SHELL`. If it’s a string, it’s equivalent to specifying `CMD-SHELL` followed by that string.\n\n``` \n# Hit the local web app\ntest: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n```\n\nAs above, but wrapped in `/bin/sh`. Both forms below are equivalent.\n\n``` \ntest: [\"CMD-SHELL\", \"curl -f http://localhost || exit 1\"]\n```\n\n``` \ntest: curl -f https://localhost || exit 1\n```\n\nTo disable any default healthcheck set by the image, you can use `disable: true`. This is equivalent to specifying `test: [\"NONE\"]`.\n\n``` \nhealthcheck:\n  disable: true\n```\n\n### image\n\nSpecify the image to start the container from. Can either be a repository/tag or a partial image ID.\n\n``` \nimage: redis\n```\n\n``` \nimage: ubuntu:18.04\n```\n\n``` \nimage: tutum/influxdb\n```\n\n``` \nimage: example-registry.com:4000/postgresql\n```\n\n``` \nimage: a4bc65fd\n```\n\nIf the image does not exist, Compose attempts to pull it, unless you have also specified [build](#build), in which case it builds it using the specified options and tags it with the specified tag.\n\n### init\n\n> Added in [version 2.2](../compose-versioning/index#version-22) file format.\n\nRun an init inside the container that forwards signals and reaps processes. Set this option to `true` to enable this feature for the service.\n\n``` \nversion: \"2.4\"\nservices:\n  web:\n    image: alpine:latest\n    init: true\n```\n\n> The default init binary that is used is [Tini](https://github.com/krallin/tini), and is installed in `/usr/libexec/docker-init` on the daemon host. You can configure the daemon to use a custom init binary through the [`init-path` configuration option](../../../engine/reference/commandline/dockerd/index#daemon-configuration-file).\n\n### isolation\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nSpecify a container’s isolation technology. On Linux, the only supported value is `default`. On Windows, acceptable values are `default`, `process` and `hyperv`. Refer to the [Docker Engine docs](../../../engine/reference/commandline/run/index#specify-isolation-technology-for-container---isolation) for details.\n\n### labels\n\nAdd metadata to containers using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n```\n\n### links\n\nLink to containers in another service. Either specify both the service name and a link alias (`\"SERVICE:ALIAS\"`), or just the service name.\n\n> Links are a legacy option. We recommend using [networks](#networks) instead.\n\n``` \nweb:\n  links:\n    - \"db\"\n    - \"db:database\"\n    - \"redis\"\n```\n\nContainers for the linked service are reachable at a hostname identical to the alias, or the service name if no alias was specified.\n\nLinks are not required to enable services to communicate - by default, any service can reach any other service at that service’s name. (See also, the [Links topic in Networking in Compose](../../networking/index#links).)\n\nLinks also express dependency between services in the same way as [depends_on](#depends_on), so they determine the order of service startup.\n\n> **Note**\n>\n> If you define both links and [networks](#networks), services with links between them must share at least one network in common to communicate. We recommend using networks instead.\n\n### logging\n\nLogging configuration for the service.\n\n``` \nlogging:\n  driver: syslog\n  options:\n    syslog-address: \"tcp://192.168.0.42:123\"\n```\n\nThe `driver` name specifies a logging driver for the service’s containers, as with the `--log-driver` option for docker run ([documented here](https://docs.docker.com/config/containers/logging/configure/)).\n\nThe default value is json-file.\n\n``` \ndriver: \"json-file\"\n```\n\n``` \ndriver: \"syslog\"\n```\n\n``` \ndriver: \"none\"\n```\n\n> **Note**\n>\n> Only the `json-file` and `journald` drivers make the logs available directly from `docker-compose up` and `docker-compose logs`. Using any other driver does not print any logs.\n\nSpecify logging options for the logging driver with the `options` key, as with the `--log-opt` option for `docker run`.\n\nLogging options are key-value pairs. An example of `syslog` options:\n\n``` \ndriver: \"syslog\"\noptions:\n  syslog-address: \"tcp://192.168.0.42:123\"\n```\n\n### network_mode\n\n> Changed in [version 2](../compose-versioning/index#version-2) file format.\n\nNetwork mode. Use the same values as the docker client `--network` parameter, plus the special form `service:[service name]`.\n\n``` \nnetwork_mode: \"bridge\"\n```\n\n``` \nnetwork_mode: \"host\"\n```\n\n``` \nnetwork_mode: \"none\"\n```\n\n``` \nnetwork_mode: \"service:[service name]\"\n```\n\n``` \nnetwork_mode: \"container:[container name/id]\"\n```\n\n### networks\n\n> Changed in [version 2](../compose-versioning/index#version-2) file format.\n\nNetworks to join, referencing entries under the [top-level `networks` key](#network-configuration-reference).\n\n``` \nservices:\n  some-service:\n    networks:\n     - some-network\n     - other-network\n```\n\n#### aliases\n\nAliases (alternative hostnames) for this service on the network. Other containers on the same network can use either the service name or this alias to connect to one of the service’s containers.\n\nSince `aliases` is network-scoped, the same service can have different aliases on different networks.\n\n> **Note**\n>\n> A network-wide alias can be shared by multiple containers, and even by multiple services. If it is, then exactly which container the name resolves to is not guaranteed.\n\nThe general format is shown here.\n\n``` \nservices:\n  some-service:\n    networks:\n      some-network:\n        aliases:\n          - alias1\n          - alias3\n      other-network:\n        aliases:\n          - alias2\n```\n\nIn the example below, three services are provided (`web`, `worker`, and `db`), along with two networks (`new` and `legacy`). The `db` service is reachable at the hostname `db` or `database` on the `new` network, and at `db` or `mysql` on the `legacy` network.\n\n``` \nversion: \"2.4\"\n\nservices:\n  web:\n    image: \"nginx:alpine\"\n    networks:\n      - new\n\n  worker:\n    image: \"my-worker-image:latest\"\n    networks:\n      - legacy\n\n  db:\n    image: mysql\n    networks:\n      new:\n        aliases:\n          - database\n      legacy:\n        aliases:\n          - mysql\n\nnetworks:\n  new:\n  legacy:\n```\n\n#### ipv4_address, ipv6_address\n\nSpecify a static IP address for containers for this service when joining the network.\n\nThe corresponding network configuration in the [top-level networks section](#network-configuration-reference) must have an `ipam` block with subnet and gateway configurations covering each static address.\n\n> If IPv6 addressing is desired, the [`enable_ipv6`](#enable_ipv6) option must be set.\n\nAn example:\n\n``` \nversion: \"2.4\"\n\nservices:\n  app:\n    image: busybox\n    command: ifconfig\n    networks:\n      app_net:\n        ipv4_address: 172.16.238.10\n        ipv6_address: 2001:3984:3989::10\n\nnetworks:\n  app_net:\n    driver: bridge\n    enable_ipv6: true\n    ipam:\n      driver: default\n      config:\n        - subnet: 172.16.238.0/24\n          gateway: 172.16.238.1\n        - subnet: 2001:3984:3989::/64\n          gateway: 2001:3984:3989::1\n```\n\n#### link_local_ips\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nSpecify a list of link-local IPs. Link-local IPs are special IPs which belong to a well known subnet and are purely managed by the operator, usually dependent on the architecture where they are deployed. Therefore they are not managed by docker (IPAM driver).\n\nExample usage:\n\n``` \nversion: \"2.4\"\nservices:\n  app:\n    image: busybox\n    command: top\n    networks:\n      app_net:\n        link_local_ips:\n          - 57.123.22.11\n          - 57.123.22.13\nnetworks:\n  app_net:\n    driver: bridge\n```\n\n#### priority\n\nSpecify a priority to indicate in which order Compose should connect the service’s containers to its networks. If unspecified, the default value is `0`.\n\nIn the following example, the `app` service connects to `app_net_1` first as it has the highest priority. It then connects to `app_net_3`, then `app_net_2`, which uses the default priority value of `0`.\n\n``` \nversion: \"2.4\"\nservices:\n  app:\n    image: busybox\n    command: top\n    networks:\n      app_net_1:\n        priority: 1000\n      app_net_2:\n\n      app_net_3:\n        priority: 100\nnetworks:\n  app_net_1:\n  app_net_2:\n  app_net_3:\n```\n\n> **Note**\n>\n> If multiple networks have the same priority, the connection order is undefined.\n\n### pid\n\n``` \npid: \"host\"\n```\n\n``` \npid: \"container:custom_container_1\"\n```\n\n``` \npid: \"service:foobar\"\n```\n\nIf set to one of the following forms: `container:<container_name>`, `service:<service_name>`, the service shares the PID address space of the designated container or service.\n\nIf set to “host”, the service’s PID mode is the host PID mode. This turns on sharing between container and the host operating system the PID address space. Containers launched with this flag can access and manipulate other containers in the bare-metal machine’s namespace and vice versa.\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n>\n> The `service:` and `container:` forms require [version 2.1](../compose-versioning/index#version-21) or above\n\n### pids_limit\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nTunes a container’s PIDs limit. Set to `-1` for unlimited PIDs.\n\n``` \npids_limit: 10\n```\n\n### platform\n\n> Added in [version 2.4](../compose-versioning/index#version-24) file format.\n\nTarget platform containers for this service will run on, using the `os[/arch[/variant]]` syntax, e.g.\n\n``` \nplatform: osx\n```\n\n``` \nplatform: windows/amd64\n```\n\n``` \nplatform: linux/arm64/v8\n```\n\nThis parameter determines which version of the image will be pulled and/or on which platform the service’s build will be performed.\n\n### ports\n\nExpose ports. Either specify both ports (`HOST:CONTAINER`), or just the container port (an ephemeral host port is chosen).\n\n> **Note**\n>\n> When mapping ports in the `HOST:CONTAINER` format, you may experience erroneous results when using a container port lower than 60, because YAML parses numbers in the format `xx:yy` as a base-60 value. For this reason, we recommend always explicitly specifying your port mappings as strings.\n\n``` \nports:\n  - \"3000\"\n  - \"3000-3005\"\n  - \"8000:8000\"\n  - \"9090-9091:8080-8081\"\n  - \"49100:22\"\n  - \"127.0.0.1:8001:8001\"\n  - \"127.0.0.1:5000-5010:5000-5010\"\n  - \"6060:6060/udp\"\n  - \"12400-12500:1240\"\n```\n\n### runtime\n\n> Added in [version 2.3](../compose-versioning/index#version-23) file format.\n\nSpecify which runtime to use for the service’s containers. Default runtime and available runtimes are listed in the output of `docker info`.\n\n``` \nweb:\n  image: busybox:latest\n  command: true\n  runtime: runc\n```\n\n### scale\n\n> Added in [version 2.2](../compose-versioning/index#version-22) file format.\n\nSpecify the default number of containers to deploy for this service. Whenever you run `docker-compose up`, Compose creates or removes containers to match the specified number. This value can be overridden using the [`--scale`](../../reference/up/index) flag.\n\n``` \nweb:\n  image: busybox:latest\n  command: echo 'scaled'\n  scale: 3\n```\n\n### security_opt\n\nOverride the default labeling scheme for each container.\n\n``` \nsecurity_opt:\n  - label:user:USER\n  - label:role:ROLE\n```\n\n### stop_grace_period\n\nSpecify how long to wait when attempting to stop a container if it doesn’t handle SIGTERM (or whatever stop signal has been specified with [`stop_signal`](#stop_signal)), before sending SIGKILL. Specified as a [duration](#specifying-durations).\n\n``` \nstop_grace_period: 1s\n```\n\n``` \nstop_grace_period: 1m30s\n```\n\nBy default, `stop` waits 10 seconds for the container to exit before sending SIGKILL.\n\n### stop_signal\n\nSets an alternative signal to stop the container. By default `stop` uses SIGTERM. Setting an alternative signal using `stop_signal` causes `stop` to send that signal instead.\n\n``` \nstop_signal: SIGUSR1\n```\n\n### storage_opt\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nSet storage driver options for this service.\n\n``` \nstorage_opt:\n  size: '1G'\n```\n\n### sysctls\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nKernel parameters to set in the container. You can use either an array or a dictionary.\n\n``` \nsysctls:\n  net.core.somaxconn: 1024\n  net.ipv4.tcp_syncookies: 0\n```\n\n``` \nsysctls:\n  - net.core.somaxconn=1024\n  - net.ipv4.tcp_syncookies=0\n```\n\n### tmpfs\n\nMount a temporary file system inside the container. Can be a single value or a list.\n\n``` \ntmpfs: /run\n```\n\n``` \ntmpfs:\n  - /run\n  - /tmp\n```\n\n### ulimits\n\nOverride the default ulimits for a container. You can either specify a single limit as an integer or soft/hard limits as a mapping.\n\n``` \nulimits:\n  nproc: 65535\n  nofile:\n    soft: 20000\n    hard: 40000\n```\n\n### userns_mode\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\n``` \nuserns_mode: \"host\"\n```\n\nDisables the user namespace for this service, if Docker daemon is configured with user namespaces. See [dockerd](../../../engine/security/userns-remap/index#disable-namespace-remapping-for-a-container) for more information.\n\n### volumes\n\nMount host paths or named volumes. Named volumes need to be specified with the [top-level `volumes` key](#volume-configuration-reference).\n\n#### Short syntax\n\nThe short syntax uses the generic `[SOURCE:]TARGET[:MODE]` format, where `SOURCE` can be either a host path or volume name. `TARGET` is the container path where the volume is mounted. Standard modes are `ro` for read-only and `rw` for read-write (default).\n\nYou can mount a relative path on the host, which expands relative to the directory of the Compose configuration file being used. Relative paths should always begin with `.` or `..`.\n\n``` \nvolumes:\n  # Just specify a path and let the Engine create a volume\n  - /var/lib/mysql\n\n  # Specify an absolute path mapping\n  - /opt/data:/var/lib/mysql\n\n  # Path on the host, relative to the Compose file\n  - ./cache:/tmp/cache\n\n  # User-relative path\n  - ~/configs:/etc/configs/:ro\n\n  # Named volume\n  - datavolume:/var/lib/mysql\n```\n\n#### Long syntax\n\n> Added in [version 2.3](../compose-versioning/index#version-23) file format.\n\nThe long form syntax allows the configuration of additional fields that can’t be expressed in the short form.\n\n- `type`: the mount type `volume`, `bind`, `tmpfs` or `npipe`\n- `source`: the source of the mount, a path on the host for a bind mount, or the name of a volume defined in the [top-level `volumes` key](#volume-configuration-reference). Not applicable for a tmpfs mount.\n- `target`: the path in the container where the volume is mounted\n- `read_only`: flag to set the volume as read-only\n- `bind`: configure additional bind options\n  - `propagation`: the propagation mode used for the bind\n- `volume`: configure additional volume options\n  - `nocopy`: flag to disable copying of data from a container when a volume is created\n- `tmpfs`: configure additional tmpfs options\n  - `size`: the size for the tmpfs mount in bytes\n\n``` \nversion: \"2.4\"\nservices:\n  web:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - type: volume\n        source: mydata\n        target: /data\n        volume:\n          nocopy: true\n      - type: bind\n        source: ./static\n        target: /opt/app/static\n\nnetworks:\n  webnet:\n\nvolumes:\n  mydata:\n```\n\n> **Note**\n>\n> When creating bind mounts, using the long syntax requires the referenced folder to be created beforehand. Using the short syntax creates the folder on the fly if it doesn’t exist. See the [bind mounts documentation](https://docs.docker.com/storage/bind-mounts/#differences-between--v-and---mount-behavior) for more information.\n\n### volume_driver\n\nSpecify a default volume driver to be used for all declared volumes on this service.\n\n``` \nvolume_driver: mydriver\n```\n\n> **Note**\n>\n> In [version 2 files](../compose-versioning/index#version-2), this option only applies to anonymous volumes (those specified in the image, or specified under `volumes` without an explicit named volume or host path). To configure the driver for a named volume, use the `driver` key under the entry in the [top-level `volumes` option](#volume-configuration-reference).\n\nSee [Docker Volumes](https://docs.docker.com/storage/volumes/) and [Volume Plugins](../../../engine/extend/plugins_volume/index) for more information.\n\n### volumes_from\n\nMount all of the volumes from another service or container, optionally specifying read-only access (`ro`) or read-write (`rw`). If no access level is specified, then read-write is used.\n\n``` \nvolumes_from:\n  - service_name\n  - service_name:ro\n  - container:container_name\n  - container:container_name:rw\n```\n\n> Changed in [version 2](../compose-versioning/index#version-2) file format.\n\n### restart\n\n`no` is the default restart policy, and it doesn’t restart a container under any circumstance. When `always` is specified, the container always restarts. The `on-failure` policy restarts a container if the exit code indicates an on-failure error.\n\n``` \nrestart: \"no\"\n```\n\n``` \nrestart: \"always\"\n```\n\n``` \nrestart: \"on-failure\"\n```\n\n``` \nrestart: \"unless-stopped\"\n```\n\n### cpu_count, cpu_percent, cpu_shares, cpu_period, cpu_quota, cpus, cpuset, domainname, hostname, ipc, mac_address, mem_limit, memswap_limit, mem_swappiness, mem_reservation, oom_kill_disable, oom_score_adj, privileged, read_only, shm_size, stdin_open, tty, user, working_dir\n\nEach of these is a single value, analogous to its [docker run](../../../engine/reference/run/index#runtime-constraints-on-resources) counterpart.\n\n> Added in [version 2.2](../compose-versioning/index#version-22) file format.\n>\n> The `cpu_count`, `cpu_percent`, and `cpus` options were added in [version 2.2](../compose-versioning/index#version-22).\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n>\n> The `oom_kill_disable` and `cpu_period` options were added in [version 2.1](../compose-versioning/index#version-21).\n\n``` \ncpu_count: 2\ncpu_percent: 50\ncpus: 0.5\ncpu_shares: 73\ncpu_quota: 50000\ncpu_period: 20ms\ncpuset: 0,1\n\nuser: postgresql\nworking_dir: /code\n\ndomainname: foo.com\nhostname: foo\nipc: host\nmac_address: 02:42:ac:11:65:43\n\nmem_limit: 1000000000\nmemswap_limit: 2000000000\nmem_reservation: 512m\nprivileged: true\n\noom_score_adj: 500\noom_kill_disable: true\n\nread_only: true\nshm_size: 64M\nstdin_open: true\ntty: true\n```\n\n## Specifying durations\n\nSome configuration options, such as the `interval` and `timeout` sub-options for [`healthcheck`](#healthcheck), accept a duration as a string in a format that looks like this:\n\n``` \n2.5s\n10s\n1m30s\n2h32m\n5h34m56s\n```\n\nThe supported units are `us`, `ms`, `s`, `m` and `h`.\n\n## Specifying byte values\n\nSome configuration options, such as the `device_read_bps` sub-option for [`blkio_config`](#blkio_config), accept a byte value as a string in a format that looks like this:\n\n``` \n2b\n1024kb\n2048k\n300m\n1gb\n```\n\nThe supported units are `b`, `k`, `m` and `g`, and their alternative notation `kb`, `mb` and `gb`. Decimal values are not supported at this time.\n\n## Volume configuration reference\n\nWhile it is possible to declare [volumes](#volumes) on the fly as part of the service declaration, this section allows you to create named volumes that can be reused across multiple services (without relying on `volumes_from`), and are easily retrieved and inspected using the docker command line or API. See the [docker volume](../../../engine/reference/commandline/volume_create/index) subcommand documentation for more information.\n\nSee [use volumes](https://docs.docker.com/storage/volumes/) and [volume plugins](../../../engine/extend/plugins_volume/index) for general information on volumes.\n\nHere’s an example of a two-service setup where a database’s data directory is shared with another service as a volume so that it can be periodically backed up:\n\n``` \nversion: \"2.4\"\n\nservices:\n  db:\n    image: db\n    volumes:\n      - data-volume:/var/lib/db\n  backup:\n    image: backup-service\n    volumes:\n      - data-volume:/var/lib/backup/data\n\nvolumes:\n  data-volume:\n```\n\nAn entry under the top-level `volumes` key can be empty, in which case it uses the default driver configured by the Engine (in most cases, this is the `local` driver). Optionally, you can configure it with the following keys:\n\n### driver\n\nSpecify which volume driver should be used for this volume. Defaults to whatever driver the Docker Engine has been configured to use, which in most cases is `local`. If the driver is not available, the Engine returns an error when `docker-compose up` tries to create the volume.\n\n``` \ndriver: foobar\n```\n\n### driver_opts\n\nSpecify a list of options as key-value pairs to pass to the driver for this volume. Those options are driver-dependent - consult the driver’s documentation for more information. Optional.\n\n``` \nvolumes:\n  example:\n    driver_opts:\n      type: \"nfs\"\n      o: \"addr=10.40.0.199,nolock,soft,rw\"\n      device: \":/docker/example\"\n```\n\n### external\n\nIf set to `true`, specifies that this volume has been created outside of Compose. `docker-compose up` does not attempt to create it, and raises an error if it doesn’t exist.\n\nFor version 2.0 of the format, `external` cannot be used in conjunction with other volume configuration keys (`driver`, `driver_opts`, `labels`). This limitation no longer exists for [version 2.1](../compose-versioning/index#version-21) and above.\n\nIn the example below, instead of attempting to create a volume called `[projectname]_data`, Compose looks for an existing volume simply called `data` and mount it into the `db` service’s containers.\n\n``` \nversion: \"2.4\"\n\nservices:\n  db:\n    image: postgres\n    volumes:\n      - data:/var/lib/postgresql/data\n\nvolumes:\n  data:\n    external: true\n```\n\nYou can also specify the name of the volume separately from the name used to refer to it within the Compose file:\n\n``` \nvolumes:\n  data:\n    external:\n      name: actual-name-of-volume\n```\n\n> Deprecated in [version 2.1](../compose-versioning/index#version-21) file format.\n>\n> external.name was deprecated in version 2.1 file format use `name` instead.\n\n### labels\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nAdd metadata to containers using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Database volume\"\n  com.example.department: \"IT/Ops\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Database volume\"\n  - \"com.example.department=IT/Ops\"\n  - \"com.example.label-with-empty-value\"\n```\n\n### name\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nSet a custom name for this volume. The name field can be used to reference volumes that contain special characters. The name is used as is and will **not** be scoped with the stack name.\n\n``` \nversion: \"2.4\"\nvolumes:\n  data:\n    name: my-app-data\n```\n\nIt can also be used in conjunction with the `external` property:\n\n``` \nversion: \"2.4\"\nvolumes:\n  data:\n    external: true\n    name: my-app-data\n```\n\n## Network configuration reference\n\nThe top-level `networks` key lets you specify networks to be created. For a full explanation of Compose’s use of Docker networking features, see the [Networking guide](../../networking/index).\n\n### driver\n\nSpecify which driver should be used for this network.\n\nThe default driver depends on how the Docker Engine you’re using is configured, but in most instances it is `bridge` on a single host and `overlay` on a Swarm.\n\nThe Docker Engine returns an error if the driver is not available.\n\n``` \ndriver: overlay\n```\n\n> Changed in [version 2.1](../compose-versioning/index#version-21) file format.\n>\n> Starting with Compose file format 2.1, overlay networks are always created as `attachable`, and this is not configurable. This means that standalone containers can connect to overlay networks.\n\n### driver_opts\n\nSpecify a list of options as key-value pairs to pass to the driver for this network. Those options are driver-dependent - consult the driver’s documentation for more information. Optional.\n\n``` \ndriver_opts:\n  foo: \"bar\"\n  baz: 1\n```\n\n### enable_ipv6\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nEnable IPv6 networking on this network.\n\n### ipam\n\nSpecify custom IPAM config. This is an object with several properties, each of which is optional:\n\n- `driver`: Custom IPAM driver, instead of the default.\n- `config`: A list with zero or more config blocks, each containing any of the following keys:\n  - `subnet`: Subnet in CIDR format that represents a network segment\n  - `ip_range`: Range of IPs from which to allocate container IPs\n  - `gateway`: IPv4 or IPv6 gateway for the master subnet\n  - `aux_addresses`: Auxiliary IPv4 or IPv6 addresses used by Network driver, as a mapping from hostname to IP\n- `options`: Driver-specific options as a key-value mapping.\n\nA full example:\n\n``` \nipam:\n  driver: default\n  config:\n    - subnet: 172.28.0.0/16\n      ip_range: 172.28.5.0/24\n      gateway: 172.28.5.254\n      aux_addresses:\n        host1: 172.28.1.5\n        host2: 172.28.1.6\n        host3: 172.28.1.7\n  options:\n    foo: bar\n    baz: \"0\"\n```\n\n### internal\n\nBy default, Docker also connects a bridge network to it to provide external connectivity. If you want to create an externally isolated overlay network, you can set this option to `true`.\n\n### labels\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nAdd metadata to containers using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Financial transaction network\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Financial transaction network\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n```\n\n### external\n\nIf set to `true`, specifies that this network has been created outside of Compose. `docker-compose up` does not attempt to create it, and raises an error if it doesn’t exist.\n\nFor version 2.0 of the format, `external` cannot be used in conjunction with other network configuration keys (`driver`, `driver_opts`, `ipam`, `internal`). This limitation no longer exists for [version 2.1](../compose-versioning/index#version-21) and above.\n\nIn the example below, `proxy` is the gateway to the outside world. Instead of attempting to create a network called `[projectname]_outside`, Compose looks for an existing network simply called `outside` and connect the `proxy` service’s containers to it.\n\n``` \nversion: \"2.4\"\n\nservices:\n  proxy:\n    build: ./proxy\n    networks:\n      - outside\n      - default\n  app:\n    build: ./app\n    networks:\n      - default\n\nnetworks:\n  outside:\n    external: true\n```\n\nYou can also specify the name of the network separately from the name used to refer to it within the Compose file:\n\n``` \nversion: \"2.4\"\nnetworks:\n  outside:\n    external:\n      name: actual-name-of-network\n```\n\nNot supported for version 2 `docker-compose` files. Use [network_mode](#network_mode) instead.\n\n### name\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nSet a custom name for this network. The name field can be used to reference networks which contain special characters. The name is used as is and will **not** be scoped with the stack name.\n\n``` \nversion: \"2.4\"\nnetworks:\n  network1:\n    name: my-app-net\n```\n\nIt can also be used in conjunction with the `external` property:\n\n``` \nversion: \"2.4\"\nnetworks:\n  network1:\n    external: true\n    name: my-app-net\n```\n\n## Variable substitution\n\nYour configuration options can contain environment variables. Compose uses the variable values from the shell environment in which `docker-compose` is run. For example, suppose the shell contains `POSTGRES_VERSION=9.3` and you supply this configuration:\n\n``` \ndb:\n  image: \"postgres:${POSTGRES_VERSION}\"\n```\n\nWhen you run `docker-compose up` with this configuration, Compose looks for the `POSTGRES_VERSION` environment variable in the shell and substitutes its value in. For this example, Compose resolves the `image` to `postgres:9.3` before running the configuration.\n\nIf an environment variable is not set, Compose substitutes with an empty string. In the example above, if `POSTGRES_VERSION` is not set, the value for the `image` option is `postgres:`.\n\nYou can set default values for environment variables using a [`.env` file](../../env-file/index), which Compose automatically looks for in project directory (parent folder of your Compose file). Values set in the shell environment override those set in the `.env` file.\n\n> Note when using docker stack deploy\n>\n> The `.env file` feature only works when you use the `docker-compose up` command and does not work with `docker stack deploy`.\n\nBoth `$VARIABLE` and `${VARIABLE}` syntax are supported. Additionally when using the [2.1 file format](../compose-versioning/index#version-21), it is possible to provide inline default values using typical shell syntax:\n\n- `${VARIABLE:-default}` evaluates to `default` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE-default}` evaluates to `default` only if `VARIABLE` is unset in the environment.\n\nSimilarly, the following syntax allows you to specify mandatory variables:\n\n- `${VARIABLE:?err}` exits with an error message containing `err` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE?err}` exits with an error message containing `err` if `VARIABLE` is unset in the environment.\n\nOther extended shell-style features, such as `${VARIABLE/foo/bar}`, are not supported.\n\nYou can use a `$$` (double-dollar sign) when your configuration needs a literal dollar sign. This also prevents Compose from interpolating a value, so a `$$` allows you to refer to environment variables that you don’t want processed by Compose.\n\n``` \nweb:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n```\n\nIf you forget and use a single dollar sign (`$`), Compose interprets the value as an environment variable and warns you:\n\n``` \nThe VAR_NOT_INTERPOLATED_BY_COMPOSE is not set. Substituting an empty string.\n```\n\n## Extension fields\n\n> Added in [version 2.1](../compose-versioning/index#version-21) file format.\n\nIt is possible to re-use configuration fragments using extension fields. Those special fields can be of any format as long as they are located at the root of your Compose file and their name start with the `x-` character sequence.\n\n> **Note**\n>\n> Starting with the 3.7 format (for the 3.x series) and 2.4 format (for the 2.x series), extension fields are also allowed at the root of service, volume, network, config and secret definitions.\n\n``` \nversion: \"3.9\"\nx-custom:\n  items:\n    - a\n    - b\n  options:\n    max-size: '12m'\n  name: \"custom\"\n```\n\nThe contents of those fields are ignored by Compose, but they can be inserted in your resource definitions using [YAML anchors](https://yaml.org/spec/1.2/spec.html#id2765878). For example, if you want several of your services to use the same logging configuration:\n\n``` \nlogging:\n  options:\n    max-size: '12m'\n    max-file: '5'\n  driver: json-file\n```\n\nYou may write your Compose file as follows:\n\n``` \nversion: \"3.9\"\nx-logging:\n  &default-logging\n  options:\n    max-size: '12m'\n    max-file: '5'\n  driver: json-file\n\nservices:\n  web:\n    image: myapp/web:latest\n    logging: *default-logging\n  db:\n    image: mysql:latest\n    logging: *default-logging\n```\n\nIt is also possible to partially override values in extension fields using the [YAML merge type](https://yaml.org/type/merge.html). For example:\n\n``` \nversion: \"3.9\"\nx-volumes:\n  &default-volume\n  driver: foobar-storage\n\nservices:\n  web:\n    image: myapp/web:latest\n    volumes: [\"vol1\", \"vol2\", \"vol3\"]\nvolumes:\n  vol1: *default-volume\n  vol2:\n    << : *default-volume\n    name: volume02\n  vol3:\n    << : *default-volume\n    driver: default\n    name: volume-local\n```\n\n## Compose documentation\n\n- [User guide](../../index)\n- [Installing Compose](../../install/index)\n- [Compose file versions and upgrading](../compose-versioning/index)\n- [Sample apps with Compose](../../samples-for-compose/index)\n- [Command line reference](../../reference/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose version 2](https://docs.docker.com/search/?q=compose%20version%202), [docker](https://docs.docker.com/search/?q=docker)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/compose-file/compose-file-v2/](https://docs.docker.com/compose/compose-file/compose-file-v2/)"
- name: Compose file version 3 reference
  id: compose/compose-file/compose-file-v3/index
  summary: These topics describe version 3 of the Compose file format
  description: "# Compose file version 3 reference\n\n## Reference and guidelines\n\nThese topics describe version 3 of the Compose file format. This is the newest version.\n\n## Compose and Docker compatibility matrix\n\nThere are several versions of the Compose file format – 1, 2, 2.x, and 3.x. The table below is a quick look. For full details on what each version includes and how to upgrade, see **[About versions and upgrading](../compose-versioning/index)**.\n\nThis table shows which Compose file versions support specific Docker releases.\n\n| **Compose file format** | **Docker Engine release** |\n|-------------------------|---------------------------|\n| Compose specification   | 19.03.0+                  |\n| 3.8                     | 19.03.0+                  |\n| 3.7                     | 18.06.0+                  |\n| 3.6                     | 18.02.0+                  |\n| 3.5                     | 17.12.0+                  |\n| 3.4                     | 17.09.0+                  |\n| 3.3                     | 17.06.0+                  |\n| 3.2                     | 17.04.0+                  |\n| 3.1                     | 1.13.1+                   |\n| 3.0                     | 1.13.0+                   |\n| 2.4                     | 17.12.0+                  |\n| 2.3                     | 17.06.0+                  |\n| 2.2                     | 1.13.0+                   |\n| 2.1                     | 1.12.0+                   |\n| 2.0                     | 1.10.0+                   |\n\nIn addition to Compose file format versions shown in the table, the Compose itself is on a release schedule, as shown in [Compose releases](https://github.com/docker/compose/releases/), but file format versions do not necessarily increment with each release. For example, Compose file format 3.0 was first introduced in [Compose release 1.10.0](https://github.com/docker/compose/releases/tag/1.10.0), and versioned gradually in subsequent releases.\n\nThe latest Compose file format is defined by the [Compose Specification](https://github.com/compose-spec/compose-spec/blob/master/spec/) and is implemented by Docker Compose **1.27.0+**.\n\n## Compose file structure and examples\n\nHere is a sample Compose file from the voting app sample used in the [Docker for Beginners lab](https://github.com/docker/labs/tree/master/beginner/) topic on [Deploying an app to a Swarm](https://github.com/docker/labs/blob/master/beginner/chapters/votingapp/):\n\nExample Compose file version 3\n\n``` \nversion: \"3.9\"\nservices:\n\n  redis:\n    image: redis:alpine\n    ports:\n      - \"6379\"\n    networks:\n      - frontend\n    deploy:\n      replicas: 2\n      update_config:\n        parallelism: 2\n        delay: 10s\n      restart_policy:\n        condition: on-failure\n\n  db:\n    image: postgres:9.4\n    volumes:\n      - db-data:/var/lib/postgresql/data\n    networks:\n      - backend\n    deploy:\n      placement:\n        max_replicas_per_node: 1\n        constraints:\n          - \"node.role==manager\"\n\n  vote:\n    image: dockersamples/examplevotingapp_vote:before\n    ports:\n      - \"5000:80\"\n    networks:\n      - frontend\n    depends_on:\n      - redis\n    deploy:\n      replicas: 2\n      update_config:\n        parallelism: 2\n      restart_policy:\n        condition: on-failure\n\n  result:\n    image: dockersamples/examplevotingapp_result:before\n    ports:\n      - \"5001:80\"\n    networks:\n      - backend\n    depends_on:\n      - db\n    deploy:\n      replicas: 1\n      update_config:\n        parallelism: 2\n        delay: 10s\n      restart_policy:\n        condition: on-failure\n\n  worker:\n    image: dockersamples/examplevotingapp_worker\n    networks:\n      - frontend\n      - backend\n    deploy:\n      mode: replicated\n      replicas: 1\n      labels: [APP=VOTING]\n      restart_policy:\n        condition: on-failure\n        delay: 10s\n        max_attempts: 3\n        window: 120s\n      placement:\n        constraints:\n          - \"node.role==manager\"\n\n  visualizer:\n    image: dockersamples/visualizer:stable\n    ports:\n      - \"8080:8080\"\n    stop_grace_period: 1m30s\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock\"\n    deploy:\n      placement:\n        constraints:\n          - \"node.role==manager\"\n\nnetworks:\n  frontend:\n  backend:\n\nvolumes:\n  db-data:\n```\n\nThe topics on this reference page are organized alphabetically by top-level key to reflect the structure of the Compose file itself. Top-level keys that define a section in the configuration file such as `build`, `deploy`, `depends_on`, `networks`, and so on, are listed with the options that support them as sub-topics. This maps to the `<key>: <option>: <value>` indent structure of the Compose file.\n\n## Service configuration reference\n\nThe Compose file is a [YAML](https://yaml.org) file defining [services](#service-configuration-reference), [networks](#network-configuration-reference) and [volumes](#volume-configuration-reference). The default path for a Compose file is `./docker-compose.yml`.\n\n> **Tip**: You can use either a `.yml` or `.yaml` extension for this file. They both work.\n\nA service definition contains configuration that is applied to each container started for that service, much like passing command-line parameters to `docker run`. Likewise, network and volume definitions are analogous to `docker network create` and `docker volume create`.\n\nAs with `docker run`, options specified in the Dockerfile, such as `CMD`, `EXPOSE`, `VOLUME`, `ENV`, are respected by default - you don’t need to specify them again in `docker-compose.yml`.\n\nYou can use environment variables in configuration values with a Bash-like `${VARIABLE}` syntax - see [variable substitution](#variable-substitution) for full details.\n\nThis section contains a list of all configuration options supported by a service definition in version 3.\n\n### build\n\nConfiguration options that are applied at build time.\n\n`build` can be specified either as a string containing a path to the build context:\n\n``` \nversion: \"3.9\"\nservices:\n  webapp:\n    build: ./dir\n```\n\nOr, as an object with the path specified under [context](#context) and optionally [Dockerfile](#dockerfile) and [args](#args):\n\n``` \nversion: \"3.9\"\nservices:\n  webapp:\n    build:\n      context: ./dir\n      dockerfile: Dockerfile-alternate\n      args:\n        buildno: 1\n```\n\nIf you specify `image` as well as `build`, then Compose names the built image with the `webapp` and optional `tag` specified in `image`:\n\n``` \nbuild: ./dir\nimage: webapp:tag\n```\n\nThis results in an image named `webapp` and tagged `tag`, built from `./dir`.\n\n> Note when using docker stack deploy\n>\n> The `build` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index) The `docker stack` command does not build images before deploying.\n\n#### context\n\nEither a path to a directory containing a Dockerfile, or a url to a git repository.\n\nWhen the value supplied is a relative path, it is interpreted as relative to the location of the Compose file. This directory is also the build context that is sent to the Docker daemon.\n\nCompose builds and tags it with a generated name, and uses that image thereafter.\n\n``` \nbuild:\n  context: ./dir\n```\n\n#### dockerfile\n\nAlternate Dockerfile.\n\nCompose uses an alternate file to build with. A build path must also be specified.\n\n``` \nbuild:\n  context: .\n  dockerfile: Dockerfile-alternate\n```\n\n#### args\n\nAdd build arguments, which are environment variables accessible only during the build process.\n\nFirst, specify the arguments in your Dockerfile:\n\n``` \n# syntax=docker/dockerfile:1\n\nARG buildno\nARG gitcommithash\n\nRUN echo \"Build number: $buildno\"\nRUN echo \"Based on commit: $gitcommithash\"\n```\n\nThen specify the arguments under the `build` key. You can pass a mapping or a list:\n\n``` \nbuild:\n  context: .\n  args:\n    buildno: 1\n    gitcommithash: cdc3b19\n```\n\n``` \nbuild:\n  context: .\n  args:\n    - buildno=1\n    - gitcommithash=cdc3b19\n```\n\n> Scope of build-args\n>\n> In your Dockerfile, if you specify `ARG` before the `FROM` instruction, `ARG` is not available in the build instructions under `FROM`. If you need an argument to be available in both places, also specify it under the `FROM` instruction. Refer to the [understand how ARGS and FROM interact](../../../engine/reference/builder/index#understand-how-arg-and-from-interact) section in the documentation for usage details.\n\nYou can omit the value when specifying a build argument, in which case its value at build time is the value in the environment where Compose is running.\n\n``` \nargs:\n  - buildno\n  - gitcommithash\n```\n\n> Tip when using boolean values\n>\n> YAML boolean values (`\"true\"`, `\"false\"`, `\"yes\"`, `\"no\"`, `\"on\"`, `\"off\"`) must be enclosed in quotes, so that the parser interprets them as strings.\n\n#### cache_from\n\n> Added in [version 3.2](../compose-versioning/index#version-32) file format\n\nA list of images that the engine uses for cache resolution.\n\n``` \nbuild:\n  context: .\n  cache_from:\n    - alpine:latest\n    - corp/web_app:3.14\n```\n\n#### labels\n\n> Added in [version 3.3](../compose-versioning/index#version-33) file format\n\nAdd metadata to the resulting image using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nbuild:\n  context: .\n  labels:\n    com.example.description: \"Accounting webapp\"\n    com.example.department: \"Finance\"\n    com.example.label-with-empty-value: \"\"\n```\n\n``` \nbuild:\n  context: .\n  labels:\n    - \"com.example.description=Accounting webapp\"\n    - \"com.example.department=Finance\"\n    - \"com.example.label-with-empty-value\"\n```\n\n#### network\n\n> Added in [version 3.4](../compose-versioning/index#version-34) file format\n\nSet the network containers connect to for the `RUN` instructions during build.\n\n``` \nbuild:\n  context: .\n  network: host\n```\n\n``` \nbuild:\n  context: .\n  network: custom_network_1\n```\n\nUse `none` to disable networking during build:\n\n``` \nbuild:\n  context: .\n  network: none\n```\n\n#### shm_size\n\n> Added in [version 3.5](../compose-versioning/index#version-35) file format\n\nSet the size of the `/dev/shm` partition for this build’s containers. Specify as an integer value representing the number of bytes or as a string expressing a [byte value](#specifying-byte-values).\n\n``` \nbuild:\n  context: .\n  shm_size: '2gb'\n```\n\n``` \nbuild:\n  context: .\n  shm_size: 10000000\n```\n\n#### target\n\n> Added in [version 3.4](../compose-versioning/index#version-34) file format\n\nBuild the specified stage as defined inside the `Dockerfile`. See the [multi-stage build docs](https://docs.docker.com/develop/develop-images/multistage-build/) for details.\n\n``` \nbuild:\n  context: .\n  target: prod\n```\n\n### cap_add, cap_drop\n\nAdd or drop container capabilities. See `man 7 capabilities` for a full list.\n\n``` \ncap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n```\n\n> Note when using docker stack deploy\n>\n> The `cap_add` and `cap_drop` options are ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index)\n\n### cgroup_parent\n\nSpecify an optional parent cgroup for the container.\n\n``` \ncgroup_parent: m-executor-abcd\n```\n\n> Note when using docker stack deploy\n>\n> The `cgroup_parent` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index)\n\n### command\n\nOverride the default command.\n\n``` \ncommand: bundle exec thin -p 3000\n```\n\nThe command can also be a list, in a manner similar to [dockerfile](../../../engine/reference/builder/index#cmd):\n\n``` \ncommand: [\"bundle\", \"exec\", \"thin\", \"-p\", \"3000\"]\n```\n\n### configs\n\nGrant access to configs on a per-service basis using the per-service `configs` configuration. Two different syntax variants are supported.\n\n> **Note**: The config must already exist or be [defined in the top-level `configs` configuration](#configs-configuration-reference) of this stack file, or stack deployment fails.\n\nFor more information on configs, see [configs](../../../engine/swarm/configs/index).\n\n#### Short syntax\n\nThe short syntax variant only specifies the config name. This grants the container access to the config and mounts it at `/<config_name>` within the container. The source name and destination mountpoint are both set to the config name.\n\nThe following example uses the short syntax to grant the `redis` service access to the `my_config` and `my_other_config` configs. The value of `my_config` is set to the contents of the file `./my_config.txt`, and `my_other_config` is defined as an external resource, which means that it has already been defined in Docker, either by running the `docker config create` command or by another stack deployment. If the external config does not exist, the stack deployment fails with a `config not found` error.\n\n> Added in [version 3.3](../compose-versioning/index#version-33) file format.\n>\n> `config` definitions are only supported in version 3.3 and higher of the compose file format.\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:latest\n    deploy:\n      replicas: 1\n    configs:\n      - my_config\n      - my_other_config\nconfigs:\n  my_config:\n    file: ./my_config.txt\n  my_other_config:\n    external: true\n```\n\n#### Long syntax\n\nThe long syntax provides more granularity in how the config is created within the service’s task containers.\n\n- `source`: The identifier of the config as it is defined in this configuration.\n- `target`: The path and name of the file to be mounted in the service’s task containers. Defaults to `/<source>` if not specified.\n- `uid` and `gid`: The numeric UID or GID that owns the mounted config file within in the service’s task containers. Both default to `0` on Linux if not specified. Not supported on Windows.\n- `mode`: The permissions for the file that is mounted within the service’s task containers, in octal notation. For instance, `0444` represents world-readable. The default is `0444`. Configs cannot be writable because they are mounted in a temporary filesystem, so if you set the writable bit, it is ignored. The executable bit can be set. If you aren’t familiar with UNIX file permission modes, you may find this [permissions calculator](http://permissions-calculator.org/) useful.\n\nThe following example sets the name of `my_config` to `redis_config` within the container, sets the mode to `0440` (group-readable) and sets the user and group to `103`. The `redis` service does not have access to the `my_other_config` config.\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:latest\n    deploy:\n      replicas: 1\n    configs:\n      - source: my_config\n        target: /redis_config\n        uid: '103'\n        gid: '103'\n        mode: 0440\nconfigs:\n  my_config:\n    file: ./my_config.txt\n  my_other_config:\n    external: true\n```\n\nYou can grant a service access to multiple configs and you can mix long and short syntax. Defining a config does not imply granting a service access to it.\n\n### container_name\n\nSpecify a custom container name, rather than a generated default name.\n\n``` \ncontainer_name: my-web-container\n```\n\nBecause Docker container names must be unique, you cannot scale a service beyond 1 container if you have specified a custom name. Attempting to do so results in an error.\n\n> Note when using docker stack deploy\n>\n> The `container_name` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index)\n\n### credential_spec\n\n> Added in [version 3.3](../compose-versioning/index#version-33) file format.\n>\n> The `credential_spec` option was added in v3.3. Using group Managed Service Account (gMSA) configurations with compose files is supported in file format version 3.8 or up.\n\nConfigure the credential spec for managed service account. This option is only used for services using Windows containers. The `credential_spec` must be in the format `file://<filename>` or `registry://<value-name>`.\n\nWhen using `file:`, the referenced file must be present in the `CredentialSpecs` subdirectory in the Docker data directory, which defaults to `C:\\ProgramData\\Docker\\` on Windows. The following example loads the credential spec from a file named `C:\\ProgramData\\Docker\\CredentialSpecs\\my-credential-spec.json`.\n\n``` \ncredential_spec:\n  file: my-credential-spec.json\n```\n\nWhen using `registry:`, the credential spec is read from the Windows registry on the daemon’s host. A registry value with the given name must be located in:\n\n``` \nHKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Virtualization\\Containers\\CredentialSpecs\n```\n\nThe following example load the credential spec from a value named `my-credential-spec` in the registry:\n\n``` \ncredential_spec:\n  registry: my-credential-spec\n```\n\n#### Example gMSA configuration\n\nWhen configuring a gMSA credential spec for a service, you only need to specify a credential spec with `config`, as shown in the following example:\n\n``` \nversion: \"3.9\"\nservices:\n  myservice:\n    image: myimage:latest\n    credential_spec:\n      config: my_credential_spec\n\nconfigs:\n  my_credentials_spec:\n    file: ./my-credential-spec.json|\n```\n\n### depends_on\n\nExpress dependency between services. Service dependencies cause the following behaviors:\n\n- `docker-compose up` starts services in dependency order. In the following example, `db` and `redis` are started before `web`.\n- `docker-compose up SERVICE` automatically includes `SERVICE`’s dependencies. In the example below, `docker-compose up web` also creates and starts `db` and `redis`.\n- `docker-compose stop` stops services in dependency order. In the following example, `web` is stopped before `db` and `redis`.\n\nSimple example:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    build: .\n    depends_on:\n      - db\n      - redis\n  redis:\n    image: redis\n  db:\n    image: postgres\n```\n\n> There are several things to be aware of when using `depends_on`:\n>\n> - `depends_on` does not wait for `db` and `redis` to be “ready” before starting `web` - only until they have been started. If you need to wait for a service to be ready, see [Controlling startup order](../../startup-order/index) for more on this problem and strategies for solving it.\n> - The `depends_on` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index) with a version 3 Compose file.\n\n### deploy\n\n> Added in [version 3](../compose-versioning/index#version-3) file format.\n\nSpecify configuration related to the deployment and running of services. The following  \nsub-options only takes effect when deploying to a [swarm](../../../engine/swarm/index) with [docker stack deploy](../../../engine/reference/commandline/stack_deploy/index), and is ignored by `docker-compose up` and `docker-compose run`, except for `resources`.\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:alpine\n    deploy:\n      replicas: 6\n      placement:\n        max_replicas_per_node: 1\n      update_config:\n        parallelism: 2\n        delay: 10s\n      restart_policy:\n        condition: on-failure\n```\n\nSeveral sub-options are available:\n\n#### endpoint_mode\n\n> Added in [version 3.2](../compose-versioning/index#version-32) file format.\n\nSpecify a service discovery method for external clients connecting to a swarm.\n\n- `endpoint_mode: vip` - Docker assigns the service a virtual IP (VIP) that acts as the front end for clients to reach the service on a network. Docker routes requests between the client and available worker nodes for the service, without client knowledge of how many nodes are participating in the service or their IP addresses or ports. (This is the default.)\n\n- `endpoint_mode: dnsrr` - DNS round-robin (DNSRR) service discovery does not use a single virtual IP. Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these. DNS round-robin is useful in cases where you want to use your own load balancer, or for Hybrid Windows and Linux applications.\n\n``` \nversion: \"3.9\"\n\nservices:\n  wordpress:\n    image: wordpress\n    ports:\n      - \"8080:80\"\n    networks:\n      - overlay\n    deploy:\n      mode: replicated\n      replicas: 2\n      endpoint_mode: vip\n\n  mysql:\n    image: mysql\n    volumes:\n       - db-data:/var/lib/mysql/data\n    networks:\n       - overlay\n    deploy:\n      mode: replicated\n      replicas: 2\n      endpoint_mode: dnsrr\n\nvolumes:\n  db-data:\n\nnetworks:\n  overlay:\n```\n\nThe options for `endpoint_mode` also work as flags on the swarm mode CLI command [docker service create](../../../engine/reference/commandline/service_create/index). For a quick list of all swarm related `docker` commands, see [Swarm mode CLI commands](../../../engine/swarm/index#swarm-mode-key-concepts-and-tutorial).\n\nTo learn more about service discovery and networking in swarm mode, see [Configure service discovery](https://docs.docker.com/network/overlay#configure-service-discovery) in the swarm mode topics.\n\n#### labels\n\nSpecify labels for the service. These labels are *only* set on the service, and *not* on any containers for the service.\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    image: web\n    deploy:\n      labels:\n        com.example.description: \"This label will appear on the web service\"\n```\n\nTo set labels on containers instead, use the `labels` key outside of `deploy`:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    image: web\n    labels:\n      com.example.description: \"This label will appear on all containers for the web service\"\n```\n\n#### mode\n\nEither `global` (exactly one container per swarm node) or `replicated` (a specified number of containers). The default is `replicated`. (To learn more, see [Replicated and global services](../../../engine/swarm/how-swarm-mode-works/services/index#replicated-and-global-services) in the [swarm](../../../engine/swarm/index) topics.)\n\n``` \nversion: \"3.9\"\nservices:\n  worker:\n    image: dockersamples/examplevotingapp_worker\n    deploy:\n      mode: global\n```\n\n#### placement\n\nSpecify placement of constraints and preferences. See the docker service create documentation for a full description of the syntax and available types of [constraints](../../../engine/reference/commandline/service_create/index#specify-service-constraints---constraint), [preferences](../../../engine/reference/commandline/service_create/index#specify-service-placement-preferences---placement-pref), and [specifying the maximum replicas per node](../../../engine/reference/commandline/service_create/index#specify-maximum-replicas-per-node---replicas-max-per-node)\n\n``` \nversion: \"3.9\"\nservices:\n  db:\n    image: postgres\n    deploy:\n      placement:\n        constraints:\n          - \"node.role==manager\"\n          - \"engine.labels.operatingsystem==ubuntu 18.04\"\n        preferences:\n          - spread: node.labels.zone\n```\n\n#### max_replicas_per_node\n\n> Added in [version 3.8](../compose-versioning/index#version-38) file format.\n\nIf the service is `replicated` (which is the default), [limit the number of replicas](../../../engine/reference/commandline/service_create/index#specify-maximum-replicas-per-node---replicas-max-per-node) that can run on a node at any time.\n\nWhen there are more tasks requested than running nodes, an error `no suitable node (max replicas per node limit exceed)` is raised.\n\n``` \nversion: \"3.9\"\nservices:\n  worker:\n    image: dockersamples/examplevotingapp_worker\n    networks:\n      - frontend\n      - backend\n    deploy:\n      mode: replicated\n      replicas: 6\n      placement:\n        max_replicas_per_node: 1\n```\n\n#### replicas\n\nIf the service is `replicated` (which is the default), specify the number of containers that should be running at any given time.\n\n``` \nversion: \"3.9\"\nservices:\n  worker:\n    image: dockersamples/examplevotingapp_worker\n    networks:\n      - frontend\n      - backend\n    deploy:\n      mode: replicated\n      replicas: 6\n```\n\n#### resources\n\nConfigures resource constraints.\n\n> Changed in compose-file version 3\n>\n> The `resources` section replaces the [older resource constraint options](../compose-file-v2/index#cpu-and-other-resources) in Compose files prior to version 3 (`cpu_shares`, `cpu_quota`, `cpuset`, `mem_limit`, `memswap_limit`, `mem_swappiness`). Refer to [Upgrading version 2.x to 3.x](../compose-versioning/index#upgrading) to learn about differences between version 2 and 3 of the compose-file format.\n\nEach of these is a single value, analogous to its [docker service create](../../../engine/reference/commandline/service_create/index) counterpart.\n\nIn this general example, the `redis` service is constrained to use no more than 50M of memory and `0.50` (50% of a single core) of available processing time (CPU), and has `20M` of memory and `0.25` CPU time reserved (as always available to it).\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:alpine\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 50M\n        reservations:\n          cpus: '0.25'\n          memory: 20M\n```\n\nThe topics below describe available options to set resource constraints on services or containers in a swarm.\n\n> Looking for options to set resources on non swarm mode containers?\n>\n> The options described here are specific to the `deploy` key and swarm mode. If you want to set resource constraints on non swarm deployments, use [Compose file format version 2 CPU, memory, and other resource options](../compose-file-v2/index#cpu-and-other-resources). If you have further questions, refer to the discussion on the GitHub issue [docker/compose/4513](https://github.com/docker/compose/issues/4513).\n\n##### Out Of Memory Exceptions (OOME)\n\nIf your services or containers attempt to use more memory than the system has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see [Understand the risks of running out of memory](https://docs.docker.com/config/containers/resource_constraints/#understand-the-risks-of-running-out-of-memory).\n\n#### restart_policy\n\nConfigures if and how to restart containers when they exit. Replaces [`restart`](../compose-file-v2/index#orig-resources).\n\n- `condition`: One of `none`, `on-failure` or `any` (default: `any`).\n- `delay`: How long to wait between restart attempts, specified as a [duration](#specifying-durations) (default: 5s).\n- `max_attempts`: How many times to attempt to restart a container before giving up (default: never give up). If the restart does not succeed within the configured `window`, this attempt doesn’t count toward the configured `max_attempts` value. For example, if `max_attempts` is set to ‘2’, and the restart fails on the first attempt, more than two restarts may be attempted.\n- `window`: How long to wait before deciding if a restart has succeeded, specified as a [duration](#specifying-durations) (default: decide immediately).\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:alpine\n    deploy:\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\n```\n\n#### rollback_config\n\n> Added in [version 3.7](../compose-versioning/index#version-37) file format.\n\nConfigures how the service should be rollbacked in case of a failing update.\n\n- `parallelism`: The number of containers to rollback at a time. If set to 0, all containers rollback simultaneously.\n- `delay`: The time to wait between each container group’s rollback (default 0s).\n- `failure_action`: What to do if a rollback fails. One of `continue` or `pause` (default `pause`)\n- `monitor`: Duration after each task update to monitor for failure `(ns|us|ms|s|m|h)` (default 5s) **Note**: Setting to 0 will use the default 5s.\n- `max_failure_ratio`: Failure rate to tolerate during a rollback (default 0).\n- `order`: Order of operations during rollbacks. One of `stop-first` (old task is stopped before starting new one), or `start-first` (new task is started first, and the running tasks briefly overlap) (default `stop-first`).\n\n#### update_config\n\nConfigures how the service should be updated. Useful for configuring rolling updates.\n\n- `parallelism`: The number of containers to update at a time.\n- `delay`: The time to wait between updating a group of containers.\n- `failure_action`: What to do if an update fails. One of `continue`, `rollback`, or `pause` (default: `pause`).\n- `monitor`: Duration after each task update to monitor for failure `(ns|us|ms|s|m|h)` (default 5s) **Note**: Setting to 0 will use the default 5s.\n- `max_failure_ratio`: Failure rate to tolerate during an update.\n- `order`: Order of operations during updates. One of `stop-first` (old task is stopped before starting new one), or `start-first` (new task is started first, and the running tasks briefly overlap) (default `stop-first`) **Note**: Only supported for v3.4 and higher.\n\n> Added in [version 3.4](../compose-versioning/index#version-34) file format.\n>\n> The `order` option is only supported by v3.4 and higher of the compose file format.\n\n``` \nversion: \"3.9\"\nservices:\n  vote:\n    image: dockersamples/examplevotingapp_vote:before\n    depends_on:\n      - redis\n    deploy:\n      replicas: 2\n      update_config:\n        parallelism: 2\n        delay: 10s\n        order: stop-first\n```\n\n#### Not supported for `docker stack deploy`\n\nThe following sub-options (supported for `docker-compose up` and `docker-compose run`) are *not supported* for `docker stack deploy` or the `deploy` key.\n\n- [build](#build)\n- [cgroup_parent](#cgroup_parent)\n- [container_name](#container_name)\n- [devices](#devices)\n- [tmpfs](#tmpfs)\n- [external_links](#external_links)\n- [links](#links)\n- [network_mode](#network_mode)\n- [restart](#restart)\n- [security_opt](#security_opt)\n- [userns_mode](#userns_mode)\n\n> Tip\n>\n> See the section on [how to configure volumes for services, swarms, and docker-stack.yml files](#volumes-for-services-swarms-and-stack-files). Volumes *are* supported but to work with swarms and services, they must be configured as named volumes or associated with services that are constrained to nodes with access to the requisite volumes.\n\n### devices\n\nList of device mappings. Uses the same format as the `--device` docker client create option.\n\n``` \ndevices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n```\n\n> Note when using docker stack deploy\n>\n> The `devices` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index)\n\n### dns\n\nCustom DNS servers. Can be a single value or a list.\n\n``` \ndns: 8.8.8.8\n```\n\n``` \ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n```\n\n### dns_search\n\nCustom DNS search domains. Can be a single value or a list.\n\n``` \ndns_search: example.com\n```\n\n``` \ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n```\n\n### entrypoint\n\nOverride the default entrypoint.\n\n``` \nentrypoint: /code/entrypoint.sh\n```\n\nThe entrypoint can also be a list, in a manner similar to [dockerfile](../../../engine/reference/builder/index#entrypoint):\n\n``` \nentrypoint: [\"php\", \"-d\", \"memory_limit=-1\", \"vendor/bin/phpunit\"]\n```\n\n> **Note**\n>\n> Setting `entrypoint` both overrides any default entrypoint set on the service’s image with the `ENTRYPOINT` Dockerfile instruction, *and* clears out any default command on the image - meaning that if there’s a `CMD` instruction in the Dockerfile, it is ignored.\n\n### env_file\n\nAdd environment variables from a file. Can be a single value or a list.\n\nIf you have specified a Compose file with `docker-compose -f FILE`, paths in `env_file` are relative to the directory that file is in.\n\nEnvironment variables declared in the [environment](#environment) section *override* these values – this holds true even if those values are empty or undefined.\n\n``` \nenv_file: .env\n```\n\n``` \nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/runtime_opts.env\n```\n\nCompose expects each line in an env file to be in `VAR=VAL` format. Lines beginning with `#` are treated as comments and are ignored. Blank lines are also ignored.\n\n``` \n# Set Rails/Rack environment\nRACK_ENV=development\n```\n\nCompose also recognizes inline comments, like in:\n\n``` \nMY_VAR = value # this is a comment\n```\n\nTo avoid interpreting “#” as an inline comment, use the quotation marks:\n\n``` \nMY_VAR = \"All the # inside are taken as part of the value\"\n```\n\n> **Note**\n>\n> If your service specifies a [build](#build) option, variables defined in environment files are *not* automatically visible during the build. Use the [args](#args) sub-option of `build` to define build-time environment variables.\n\nThe value of `VAL` is used as is and not modified at all. For example if the value is surrounded by quotes (as is often the case of shell variables), the quotes are included in the value passed to Compose.\n\nKeep in mind that *the order of files in the list is significant in determining the value assigned to a variable that shows up more than once*. The files in the list are processed from the top down. For the same variable specified in file `a.env` and assigned a different value in file `b.env`, if `b.env` is listed below (after), then the value from `b.env` stands. For example, given the following declaration in `docker-compose.yml`:\n\n``` \nservices:\n  some-service:\n    env_file:\n      - a.env\n      - b.env\n```\n\nAnd the following files:\n\n``` \n# a.env\nVAR=1\n```\n\nand\n\n``` \n# b.env\nVAR=hello\n```\n\n`$VAR` is `hello`.\n\n### environment\n\nAdd environment variables. You can use either an array or a dictionary. Any boolean values (true, false, yes, no) need to be enclosed in quotes to ensure they are not converted to True or False by the YML parser.\n\nEnvironment variables with only a key are resolved to their values on the machine Compose is running on, which can be helpful for secret or host-specific values.\n\n``` \nenvironment:\n  RACK_ENV: development\n  SHOW: 'true'\n  SESSION_SECRET:\n```\n\n``` \nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET\n```\n\n> **Note**\n>\n> If your service specifies a [build](#build) option, variables defined in `environment` are *not* automatically visible during the build. Use the [args](#args) sub-option of `build` to define build-time environment variables.\n\n### expose\n\nExpose ports without publishing them to the host machine - they’ll only be accessible to linked services. Only the internal port can be specified.\n\n``` \nexpose:\n  - \"3000\"\n  - \"8000\"\n```\n\n### external_links\n\nLink to containers started outside this `docker-compose.yml` or even outside of Compose, especially for containers that provide shared or common services. `external_links` follow semantics similar to the legacy option `links` when specifying both the container name and the link alias (`CONTAINER:ALIAS`).\n\n``` \nexternal_links:\n  - redis_1\n  - project_db_1:mysql\n  - project_db_1:postgresql\n```\n\n> **Note**\n>\n> The externally-created containers must be connected to at least one of the same networks as the service that is linking to them. [Links](../compose-file-v2/index#links) are a legacy option. We recommend using [networks](#networks) instead.\n\n> Note when using docker stack deploy\n>\n> The `external_links` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index)\n\n### extra_hosts\n\nAdd hostname mappings. Use the same values as the docker client `--add-host` parameter.\n\n``` \nextra_hosts:\n  - \"somehost:162.242.195.82\"\n  - \"otherhost:50.31.209.229\"\n```\n\nAn entry with the ip address and hostname is created in `/etc/hosts` inside containers for this service, e.g:\n\n``` \n162.242.195.82  somehost\n50.31.209.229   otherhost\n```\n\n### healthcheck\n\nConfigure a check that’s run to determine whether or not containers for this service are “healthy”. See the docs for the [HEALTHCHECK Dockerfile instruction](../../../engine/reference/builder/index#healthcheck) for details on how healthchecks work.\n\n``` \nhealthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n  interval: 1m30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n```\n\n`interval`, `timeout` and `start_period` are specified as [durations](#specifying-durations).\n\n> Added in [version 3.4](../compose-versioning/index#version-34) file format.\n>\n> The `start_period` option was added in file format 3.4.\n\n`test` must be either a string or a list. If it’s a list, the first item must be either `NONE`, `CMD` or `CMD-SHELL`. If it’s a string, it’s equivalent to specifying `CMD-SHELL` followed by that string.\n\n``` \n# Hit the local web app\ntest: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n```\n\nAs above, but wrapped in `/bin/sh`. Both forms below are equivalent.\n\n``` \ntest: [\"CMD-SHELL\", \"curl -f http://localhost || exit 1\"]\n```\n\n``` \ntest: curl -f https://localhost || exit 1\n```\n\nTo disable any default healthcheck set by the image, you can use `disable: true`. This is equivalent to specifying `test: [\"NONE\"]`.\n\n``` \nhealthcheck:\n  disable: true\n```\n\n### image\n\nSpecify the image to start the container from. Can either be a repository/tag or a partial image ID.\n\n``` \nimage: redis\n```\n\n``` \nimage: ubuntu:18.04\n```\n\n``` \nimage: tutum/influxdb\n```\n\n``` \nimage: example-registry.com:4000/postgresql\n```\n\n``` \nimage: a4bc65fd\n```\n\nIf the image does not exist, Compose attempts to pull it, unless you have also specified [build](#build), in which case it builds it using the specified options and tags it with the specified tag.\n\n### init\n\n> Added in [version 3.7](../compose-versioning/index#version-37) file format.\n\nRun an init inside the container that forwards signals and reaps processes. Set this option to `true` to enable this feature for the service.\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    image: alpine:latest\n    init: true\n```\n\n> The default init binary that is used is [Tini](https://github.com/krallin/tini), and is installed in `/usr/libexec/docker-init` on the daemon host. You can configure the daemon to use a custom init binary through the [`init-path` configuration option](../../../engine/reference/commandline/dockerd/index#daemon-configuration-file).\n\n### isolation\n\nSpecify a container’s isolation technology. On Linux, the only supported value is `default`. On Windows, acceptable values are `default`, `process` and `hyperv`. Refer to the [Docker Engine docs](../../../engine/reference/commandline/run/index#specify-isolation-technology-for-container---isolation) for details.\n\n### labels\n\nAdd metadata to containers using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n```\n\n### links\n\n> **Warning**\n>\n> The `--link` flag is a legacy feature of Docker. It may eventually be removed. Unless you absolutely need to continue using it, we recommend that you use [user-defined networks](../../networking/index) to facilitate communication between two containers instead of using `--link`.\n>\n> One feature that user-defined networks do not support that you can do with `--link` is sharing environmental variables between containers. However, you can use other mechanisms such as volumes to share environment variables between containers in a more controlled way.\n\nLink to containers in another service. Either specify both the service name and a link alias (`\"SERVICE:ALIAS\"`), or just the service name.\n\n``` \nweb:\n  links:\n    - \"db\"\n    - \"db:database\"\n    - \"redis\"\n```\n\nContainers for the linked service are reachable at a hostname identical to the alias, or the service name if no alias was specified.\n\nLinks are not required to enable services to communicate - by default, any service can reach any other service at that service’s name. (See also, the [Links topic in Networking in Compose](../../networking/index#links).)\n\nLinks also express dependency between services in the same way as [depends_on](#depends_on), so they determine the order of service startup.\n\n> **Note**\n>\n> If you define both links and [networks](#networks), services with links between them must share at least one network in common to communicate.\n\n> Note when using docker stack deploy\n>\n> The `links` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index)\n\n### logging\n\nLogging configuration for the service.\n\n``` \nlogging:\n  driver: syslog\n  options:\n    syslog-address: \"tcp://192.168.0.42:123\"\n```\n\nThe `driver` name specifies a logging driver for the service’s containers, as with the `--log-driver` option for docker run ([documented here](https://docs.docker.com/config/containers/logging/configure/)).\n\nThe default value is json-file.\n\n``` \ndriver: \"json-file\"\n```\n\n``` \ndriver: \"syslog\"\n```\n\n``` \ndriver: \"none\"\n```\n\n> **Note**\n>\n> Only the `json-file` and `journald` drivers make the logs available directly from `docker-compose up` and `docker-compose logs`. Using any other driver does not print any logs.\n\nSpecify logging options for the logging driver with the `options` key, as with the `--log-opt` option for `docker run`.\n\nLogging options are key-value pairs. An example of `syslog` options:\n\n``` \ndriver: \"syslog\"\noptions:\n  syslog-address: \"tcp://192.168.0.42:123\"\n```\n\nThe default driver [json-file](https://docs.docker.com/config/containers/logging/json-file/), has options to limit the amount of logs stored. To do this, use a key-value pair for maximum storage size and maximum number of files:\n\n``` \noptions:\n  max-size: \"200k\"\n  max-file: \"10\"\n```\n\nThe example shown above would store log files until they reach a `max-size` of 200kB, and then rotate them. The amount of individual log files stored is specified by the `max-file` value. As logs grow beyond the max limits, older log files are removed to allow storage of new logs.\n\nHere is an example `docker-compose.yml` file that limits logging storage:\n\n``` \nversion: \"3.9\"\nservices:\n  some-service:\n    image: some-service\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"200k\"\n        max-file: \"10\"\n```\n\n> Logging options available depend on which logging driver you use\n>\n> The above example for controlling log files and sizes uses options specific to the [json-file driver](https://docs.docker.com/config/containers/logging/json-file/). These particular options are not available on other logging drivers. For a full list of supported logging drivers and their options, refer to the [logging drivers](https://docs.docker.com/config/containers/logging/configure/) documentation.\n\n### network_mode\n\nNetwork mode. Use the same values as the docker client `--network` parameter, plus the special form `service:[service name]`.\n\n``` \nnetwork_mode: \"bridge\"\n```\n\n``` \nnetwork_mode: \"host\"\n```\n\n``` \nnetwork_mode: \"none\"\n```\n\n``` \nnetwork_mode: \"service:[service name]\"\n```\n\n``` \nnetwork_mode: \"container:[container name/id]\"\n```\n\n> **Note**\n>\n> - This option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index).\n> - `network_mode: \"host\"` cannot be mixed with [links](#links).\n\n### networks\n\nNetworks to join, referencing entries under the [top-level `networks` key](#network-configuration-reference).\n\n``` \nservices:\n  some-service:\n    networks:\n     - some-network\n     - other-network\n```\n\n#### aliases\n\nAliases (alternative hostnames) for this service on the network. Other containers on the same network can use either the service name or this alias to connect to one of the service’s containers.\n\nSince `aliases` is network-scoped, the same service can have different aliases on different networks.\n\n> **Note**\n>\n> A network-wide alias can be shared by multiple containers, and even by multiple services. If it is, then exactly which container the name resolves to is not guaranteed.\n\nThe general format is shown here.\n\n``` \nservices:\n  some-service:\n    networks:\n      some-network:\n        aliases:\n          - alias1\n          - alias3\n      other-network:\n        aliases:\n          - alias2\n```\n\nIn the example below, three services are provided (`web`, `worker`, and `db`), along with two networks (`new` and `legacy`). The `db` service is reachable at the hostname `db` or `database` on the `new` network, and at `db` or `mysql` on the `legacy` network.\n\n``` \nversion: \"3.9\"\n\nservices:\n  web:\n    image: \"nginx:alpine\"\n    networks:\n      - new\n\n  worker:\n    image: \"my-worker-image:latest\"\n    networks:\n      - legacy\n\n  db:\n    image: mysql\n    networks:\n      new:\n        aliases:\n          - database\n      legacy:\n        aliases:\n          - mysql\n\nnetworks:\n  new:\n  legacy:\n```\n\n#### ipv4_address, ipv6_address\n\nSpecify a static IP address for containers for this service when joining the network.\n\nThe corresponding network configuration in the [top-level networks section](#network-configuration-reference) must have an `ipam` block with subnet configurations covering each static address.\n\nIf you’d like to use IPv6, you must first ensure that the Docker daemon is configured to support IPv6. See [Enable IPv6](https://docs.docker.com/config/daemon/ipv6/) for detailed instructions. You can then access IPv6 addressing in a version 3.x Compose file by editing the `/etc/docker/daemon.json` to contain: `{\"ipv6\": true, \"fixed-cidr-v6\": \"2001:db8:1::/64\"}`\n\nThen, reload the docker daemon and edit docker-compose.yml to contain the following under the service:\n\n``` \n    sysctls:\n      - net.ipv6.conf.all.disable_ipv6=0\n```\n\n> The [`enable_ipv6`](../compose-file-v2/index#enable_ipv6) option is only available in a [version 2.x Compose file](../compose-file-v2/index#ipv4_address-ipv6_address). *IPv6 options do not currently work in swarm mode*.\n\nAn example:\n\n``` \nversion: \"3.9\"\n\nservices:\n  app:\n    image: nginx:alpine\n    networks:\n      app_net:\n        ipv4_address: 172.16.238.10\n        ipv6_address: 2001:3984:3989::10\n\nnetworks:\n  app_net:\n    ipam:\n      driver: default\n      config:\n        - subnet: \"172.16.238.0/24\"\n        - subnet: \"2001:3984:3989::/64\"\n```\n\n### pid\n\n``` \npid: \"host\"\n```\n\nSets the PID mode to the host PID mode. This turns on sharing between container and the host operating system the PID address space. Containers launched with this flag can access and manipulate other containers in the bare-metal machine’s namespace and vice versa.\n\n### ports\n\nExpose ports.\n\n> **Note**\n>\n> Port mapping is incompatible with `network_mode: host`\n\n> **Note**\n>\n> `docker-compose run` ignores `ports` unless you include `--service-ports`.\n\n#### Short syntax\n\nThere are three options:\n\n- Specify both ports (`HOST:CONTAINER`)\n- Specify just the container port (an ephemeral host port is chosen for the host port).\n- Specify the host IP address to bind to AND both ports (the default is 0.0.0.0, meaning all interfaces): (`IPADDR:HOSTPORT:CONTAINERPORT`). If HOSTPORT is empty (for example `127.0.0.1::80`), an ephemeral port is chosen to bind to on the host.\n\n> **Note**\n>\n> When mapping ports in the `HOST:CONTAINER` format, you may experience erroneous results when using a container port lower than 60, because YAML parses numbers in the format `xx:yy` as a base-60 value. For this reason, we recommend always explicitly specifying your port mappings as strings.\n\n``` \nports:\n  - \"3000\"\n  - \"3000-3005\"\n  - \"8000:8000\"\n  - \"9090-9091:8080-8081\"\n  - \"49100:22\"\n  - \"127.0.0.1:8001:8001\"\n  - \"127.0.0.1:5000-5010:5000-5010\"\n  - \"127.0.0.1::5000\"\n  - \"6060:6060/udp\"\n  - \"12400-12500:1240\"\n```\n\n#### Long syntax\n\nThe long form syntax allows the configuration of additional fields that can’t be expressed in the short form.\n\n- `target`: the port inside the container\n- `published`: the publicly exposed port\n- `protocol`: the port protocol (`tcp` or `udp`)\n- `mode`: `host` for publishing a host port on each node, or `ingress` for a swarm mode port to be load balanced.\n\n``` \nports:\n  - target: 80\n    published: 8080\n    protocol: tcp\n    mode: host\n```\n\n> Added in [version 3.2](../compose-versioning/index#version-32) file format.\n>\n> The long syntax is new in the v3.2 file format.\n\n### profiles\n\n``` \nprofiles: [\"frontend\", \"debug\"]\nprofiles:\n  - frontend\n  - debug\n```\n\n`profiles` defines a list of named profiles for the service to be enabled under. When not set, the service is *always* enabled. For the services that make up your core application you should omit `profiles` so they will always be started.\n\nValid profile names follow the regex format `[a-zA-Z0-9][a-zA-Z0-9_.-]+`.\n\nSee also [*Using profiles with Compose*](../../profiles/index) to learn more about profiles.\n\n### restart\n\n`no` is the default [restart policy](https://docs.docker.com/config/containers/start-containers-automatically/#use-a-restart-policy), and it does not restart a container under any circumstance. When `always` is specified, the container always restarts. The `on-failure` policy restarts a container if the exit code indicates an on-failure error. `unless-stopped` always restarts a container, except when the container is stopped (manually or otherwise).\n\n``` \nrestart: \"no\"\nrestart: always\nrestart: on-failure\nrestart: unless-stopped\n```\n\n> Note when using docker stack deploy\n>\n> The `restart` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index).\n\n### secrets\n\nGrant access to secrets on a per-service basis using the per-service `secrets` configuration. Two different syntax variants are supported.\n\n> Note when using docker stack deploy\n>\n> The secret must already exist or be [defined in the top-level `secrets` configuration](#secrets-configuration-reference) of the compose file, or stack deployment fails.\n\nFor more information on secrets, see [secrets](../../../engine/swarm/secrets/index).\n\n#### Short syntax\n\nThe short syntax variant only specifies the secret name. This grants the container access to the secret and mounts it at `/run/secrets/<secret_name>` within the container. The source name and destination mountpoint are both set to the secret name.\n\nThe following example uses the short syntax to grant the `redis` service access to the `my_secret` and `my_other_secret` secrets. The value of `my_secret` is set to the contents of the file `./my_secret.txt`, and `my_other_secret` is defined as an external resource, which means that it has already been defined in Docker, either by running the `docker secret create` command or by another stack deployment. If the external secret does not exist, the stack deployment fails with a `secret not found` error.\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:latest\n    deploy:\n      replicas: 1\n    secrets:\n      - my_secret\n      - my_other_secret\nsecrets:\n  my_secret:\n    file: ./my_secret.txt\n  my_other_secret:\n    external: true\n```\n\n#### Long syntax\n\nThe long syntax provides more granularity in how the secret is created within the service’s task containers.\n\n- `source`: The identifier of the secret as it is defined in this configuration.\n- `target`: The name of the file to be mounted in `/run/secrets/` in the service’s task containers. Defaults to `source` if not specified.\n- `uid` and `gid`: The numeric UID or GID that owns the file within `/run/secrets/` in the service’s task containers. Both default to `0` if not specified.\n- `mode`: The permissions for the file to be mounted in `/run/secrets/` in the service’s task containers, in octal notation. For instance, `0444` represents world-readable. The default in Docker 1.13.1 is `0000`, but it is `0444` in newer versions. Secrets cannot be writable because they are mounted in a temporary filesystem, so if you set the writable bit, it is ignored. The executable bit can be set. If you aren’t familiar with UNIX file permission modes, you may find this [permissions calculator](http://permissions-calculator.org/) useful.\n\nThe following example sets name of the `my_secret` to `redis_secret` within the container, sets the mode to `0440` (group-readable) and sets the user and group to `103`. The `redis` service does not have access to the `my_other_secret` secret.\n\n``` \nversion: \"3.9\"\nservices:\n  redis:\n    image: redis:latest\n    deploy:\n      replicas: 1\n    secrets:\n      - source: my_secret\n        target: redis_secret\n        uid: '103'\n        gid: '103'\n        mode: 0440\nsecrets:\n  my_secret:\n    file: ./my_secret.txt\n  my_other_secret:\n    external: true\n```\n\nYou can grant a service access to multiple secrets and you can mix long and short syntax. Defining a secret does not imply granting a service access to it.\n\n### security_opt\n\nOverride the default labeling scheme for each container.\n\n``` \nsecurity_opt:\n  - label:user:USER\n  - label:role:ROLE\n```\n\n> Note when using docker stack deploy\n>\n> The `security_opt` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index).\n\n### stop_grace_period\n\nSpecify how long to wait when attempting to stop a container if it doesn’t handle SIGTERM (or whatever stop signal has been specified with [`stop_signal`](#stop_signal)), before sending SIGKILL. Specified as a [duration](#specifying-durations).\n\n``` \nstop_grace_period: 1s\n```\n\n``` \nstop_grace_period: 1m30s\n```\n\nBy default, `stop` waits 10 seconds for the container to exit before sending SIGKILL.\n\n### stop_signal\n\nSets an alternative signal to stop the container. By default `stop` uses SIGTERM. Setting an alternative signal using `stop_signal` causes `stop` to send that signal instead.\n\n``` \nstop_signal: SIGUSR1\n```\n\n### sysctls\n\nKernel parameters to set in the container. You can use either an array or a dictionary.\n\n``` \nsysctls:\n  net.core.somaxconn: 1024\n  net.ipv4.tcp_syncookies: 0\n```\n\n``` \nsysctls:\n  - net.core.somaxconn=1024\n  - net.ipv4.tcp_syncookies=0\n```\n\nYou can only use sysctls that are namespaced in the kernel. Docker does not support changing sysctls inside a container that also modify the host system. For an overview of supported sysctls, refer to [configure namespaced kernel parameters (sysctls) at runtime](../../../engine/reference/commandline/run/index#configure-namespaced-kernel-parameters-sysctls-at-runtime).\n\n> Note when using docker stack deploy\n>\n> This option requires Docker Engine 19.03 or up when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index).\n\n### tmpfs\n\n> Added in [version 3.6](../compose-versioning/index#version-36) file format.\n\nMount a temporary file system inside the container. Can be a single value or a list.\n\n``` \ntmpfs: /run\n```\n\n``` \ntmpfs:\n  - /run\n  - /tmp\n```\n\n> Note when using docker stack deploy\n>\n> This option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index) with a (version 3-3.5) Compose file.\n\nMount a temporary file system inside the container. Size parameter specifies the size of the tmpfs mount in bytes. Unlimited by default.\n\n``` \n- type: tmpfs\n  target: /app\n  tmpfs:\n    size: 1000\n```\n\n### ulimits\n\nOverride the default ulimits for a container. You can either specify a single limit as an integer or soft/hard limits as a mapping.\n\n``` \nulimits:\n  nproc: 65535\n  nofile:\n    soft: 20000\n    hard: 40000\n```\n\n### userns_mode\n\n``` \nuserns_mode: \"host\"\n```\n\nDisables the user namespace for this service, if Docker daemon is configured with user namespaces. See [dockerd](../../../engine/security/userns-remap/index#disable-namespace-remapping-for-a-container) for more information.\n\n> Note when using docker stack deploy\n>\n> The `userns_mode` option is ignored when [deploying a stack in swarm mode](../../../engine/reference/commandline/stack_deploy/index).\n\n### volumes\n\nMount host paths or named volumes, specified as sub-options to a service.\n\nYou can mount a host path as part of a definition for a single service, and there is no need to define it in the top level `volumes` key.\n\nBut, if you want to reuse a volume across multiple services, then define a named volume in the [top-level `volumes` key](#volume-configuration-reference). Use named volumes with [services, swarms, and stack files](#volumes-for-services-swarms-and-stack-files).\n\n> Changed in [version 3](../compose-versioning/index#version-3) file format.\n>\n> The top-level [volumes](#volume-configuration-reference) key defines a named volume and references it from each service’s `volumes` list. This replaces `volumes_from` in earlier versions of the Compose file format.\n\nThis example shows a named volume (`mydata`) being used by the `web` service, and a bind mount defined for a single service (first path under `db` service `volumes`). The `db` service also uses a named volume called `dbdata` (second path under `db` service `volumes`), but defines it using the old string format for mounting a named volume. Named volumes must be listed under the top-level `volumes` key, as shown.\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    image: nginx:alpine\n    volumes:\n      - type: volume\n        source: mydata\n        target: /data\n        volume:\n          nocopy: true\n      - type: bind\n        source: ./static\n        target: /opt/app/static\n\n  db:\n    image: postgres:latest\n    volumes:\n      - \"/var/run/postgres/postgres.sock:/var/run/postgres/postgres.sock\"\n      - \"dbdata:/var/lib/postgresql/data\"\n\nvolumes:\n  mydata:\n  dbdata:\n```\n\n> **Note**\n>\n> For general information on volumes, refer to the [use volumes](https://docs.docker.com/storage/volumes/) and [volume plugins](../../../engine/extend/plugins_volume/index) sections in the documentation.\n\n#### Short syntax\n\nThe short syntax uses the generic `[SOURCE:]TARGET[:MODE]` format, where `SOURCE` can be either a host path or volume name. `TARGET` is the container path where the volume is mounted. Standard modes are `ro` for read-only and `rw` for read-write (default).\n\nYou can mount a relative path on the host, which expands relative to the directory of the Compose configuration file being used. Relative paths should always begin with `.` or `..`.\n\n``` \nvolumes:\n  # Just specify a path and let the Engine create a volume\n  - /var/lib/mysql\n\n  # Specify an absolute path mapping\n  - /opt/data:/var/lib/mysql\n\n  # Path on the host, relative to the Compose file\n  - ./cache:/tmp/cache\n\n  # User-relative path\n  - ~/configs:/etc/configs/:ro\n\n  # Named volume\n  - datavolume:/var/lib/mysql\n```\n\n#### Long syntax\n\n> Added in [version 3.2](../compose-versioning/index#version-32) file format.\n\nThe long form syntax allows the configuration of additional fields that can’t be expressed in the short form.\n\n- `type`: the mount type `volume`, `bind`, `tmpfs` or `npipe`\n- `source`: the source of the mount, a path on the host for a bind mount, or the name of a volume defined in the [top-level `volumes` key](#volume-configuration-reference). Not applicable for a tmpfs mount.\n- `target`: the path in the container where the volume is mounted\n- `read_only`: flag to set the volume as read-only\n- `bind`: configure additional bind options\n  - `propagation`: the propagation mode used for the bind\n- `volume`: configure additional volume options\n  - `nocopy`: flag to disable copying of data from a container when a volume is created\n- `tmpfs`: configure additional tmpfs options\n  - `size`: the size for the tmpfs mount in bytes\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - type: volume\n        source: mydata\n        target: /data\n        volume:\n          nocopy: true\n      - type: bind\n        source: ./static\n        target: /opt/app/static\n\nnetworks:\n  webnet:\n\nvolumes:\n  mydata:\n```\n\n> **Note**\n>\n> When creating bind mounts, using the long syntax requires the referenced folder to be created beforehand. Using the short syntax creates the folder on the fly if it doesn’t exist. See the [bind mounts documentation](https://docs.docker.com/storage/bind-mounts/#differences-between--v-and---mount-behavior) for more information.\n\n#### Volumes for services, swarms, and stack files\n\n> Note when using docker stack deploy\n>\n> When working with services, swarms, and `docker-stack.yml` files, keep in mind that the tasks (containers) backing a service can be deployed on any node in a swarm, and this may be a different node each time the service is updated.\n\nIn the absence of having named volumes with specified sources, Docker creates an anonymous volume for each task backing a service. Anonymous volumes do not persist after the associated containers are removed.\n\nIf you want your data to persist, use a named volume and a volume driver that is multi-host aware, so that the data is accessible from any node. Or, set constraints on the service so that its tasks are deployed on a node that has the volume present.\n\nAs an example, the `docker-stack.yml` file for the [votingapp sample in Docker Labs](https://github.com/docker/labs/blob/master/beginner/chapters/votingapp/) defines a service called `db` that runs a `postgres` database. It is configured as a named volume to persist the data on the swarm, *and* is constrained to run only on `manager` nodes. Here is the relevant snip-it from that file:\n\n``` \nversion: \"3.9\"\nservices:\n  db:\n    image: postgres:9.4\n    volumes:\n      - db-data:/var/lib/postgresql/data\n    networks:\n      - backend\n    deploy:\n      placement:\n        constraints: [node.role == manager]\n```\n\n### domainname, hostname, ipc, mac_address, privileged, read_only, shm_size, stdin_open, tty, user, working_dir\n\nEach of these is a single value, analogous to its [docker run](../../../engine/reference/run/index) counterpart. Note that `mac_address` is a legacy option.\n\n``` \nuser: postgresql\nworking_dir: /code\n\ndomainname: foo.com\nhostname: foo\nipc: host\nmac_address: 02:42:ac:11:65:43\n\nprivileged: true\n\n\nread_only: true\nshm_size: 64M\nstdin_open: true\ntty: true\n```\n\n## Specifying durations\n\nSome configuration options, such as the `interval` and `timeout` sub-options for [`check`](#healthcheck), accept a duration as a string in a format that looks like this:\n\n``` \n2.5s\n10s\n1m30s\n2h32m\n5h34m56s\n```\n\nThe supported units are `us`, `ms`, `s`, `m` and `h`.\n\n## Specifying byte values\n\nSome configuration options, such as the `shm_size` sub-option for [`build`](#build), accept a byte value as a string in a format that looks like this:\n\n``` \n2b\n1024kb\n2048k\n300m\n1gb\n```\n\nThe supported units are `b`, `k`, `m` and `g`, and their alternative notation `kb`, `mb` and `gb`. Decimal values are not supported at this time.\n\n## Volume configuration reference\n\nWhile it is possible to declare [volumes](#volumes) on the fly as part of the service declaration, this section allows you to create named volumes that can be reused across multiple services (without relying on `volumes_from`), and are easily retrieved and inspected using the docker command line or API. See the [docker volume](../../../engine/reference/commandline/volume_create/index) subcommand documentation for more information.\n\nSee [use volumes](https://docs.docker.com/storage/volumes/) and [volume plugins](../../../engine/extend/plugins_volume/index) for general information on volumes.\n\nHere’s an example of a two-service setup where a database’s data directory is shared with another service as a volume so that it can be periodically backed up:\n\n``` \nversion: \"3.9\"\n\nservices:\n  db:\n    image: db\n    volumes:\n      - data-volume:/var/lib/db\n  backup:\n    image: backup-service\n    volumes:\n      - data-volume:/var/lib/backup/data\n\nvolumes:\n  data-volume:\n```\n\nAn entry under the top-level `volumes` key can be empty, in which case it uses the default driver configured by the Engine (in most cases, this is the `local` driver). Optionally, you can configure it with the following keys:\n\n### driver\n\nSpecify which volume driver should be used for this volume. Defaults to whatever driver the Docker Engine has been configured to use, which in most cases is `local`. If the driver is not available, the Engine returns an error when `docker-compose up` tries to create the volume.\n\n``` \ndriver: foobar\n```\n\n### driver_opts\n\nSpecify a list of options as key-value pairs to pass to the driver for this volume. Those options are driver-dependent - consult the driver’s documentation for more information. Optional.\n\n``` \nvolumes:\n  example:\n    driver_opts:\n      type: \"nfs\"\n      o: \"addr=10.40.0.199,nolock,soft,rw\"\n      device: \":/docker/example\"\n```\n\n### external\n\nIf set to `true`, specifies that this volume has been created outside of Compose. `docker-compose up` does not attempt to create it, and raises an error if it doesn’t exist.\n\nFor version 3.3 and below of the format, `external` cannot be used in conjunction with other volume configuration keys (`driver`, `driver_opts`, `labels`). This limitation no longer exists for [version 3.4](../compose-versioning/index#version-34) and above.\n\nIn the example below, instead of attempting to create a volume called `[projectname]_data`, Compose looks for an existing volume simply called `data` and mount it into the `db` service’s containers.\n\n``` \nversion: \"3.9\"\n\nservices:\n  db:\n    image: postgres\n    volumes:\n      - data:/var/lib/postgresql/data\n\nvolumes:\n  data:\n    external: true\n```\n\n> Deprecated in [version 3.4](../compose-versioning/index#version-34) file format.\n>\n> external.name was deprecated in version 3.4 file format use `name` instead.\n\nYou can also specify the name of the volume separately from the name used to refer to it within the Compose file:\n\n``` \nvolumes:\n  data:\n    external:\n      name: actual-name-of-volume\n```\n\n> Note when using docker stack deploy\n>\n> External volumes that do not exist *are created* if you use [docker stack deploy](#deploy) to launch the app in [swarm mode](../../../engine/swarm/index) (instead of [docker compose up](../../reference/up/index)). In swarm mode, a volume is automatically created when it is defined by a service. As service tasks are scheduled on new nodes, [swarmkit](https://github.com/docker/swarmkit/blob/master/README/) creates the volume on the local node. To learn more, see [moby/moby#29976](https://github.com/moby/moby/issues/29976).\n\n### labels\n\nAdd metadata to containers using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Database volume\"\n  com.example.department: \"IT/Ops\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Database volume\"\n  - \"com.example.department=IT/Ops\"\n  - \"com.example.label-with-empty-value\"\n```\n\n### name\n\n> Added in [version 3.4](../compose-versioning/index#version-34) file format.\n\nSet a custom name for this volume. The name field can be used to reference volumes that contain special characters. The name is used as is and will **not** be scoped with the stack name.\n\n``` \nversion: \"3.9\"\nvolumes:\n  data:\n    name: my-app-data\n```\n\nIt can also be used in conjunction with the `external` property:\n\n``` \nversion: \"3.9\"\nvolumes:\n  data:\n    external: true\n    name: my-app-data\n```\n\n## Network configuration reference\n\nThe top-level `networks` key lets you specify networks to be created.\n\n- For a full explanation of Compose’s use of Docker networking features and all network driver options, see the [Networking guide](../../networking/index).\n- For [Docker Labs](https://github.com/docker/labs/blob/master/README/) tutorials on networking, start with [Designing Scalable, Portable Docker Container Networks](https://github.com/docker/labs/blob/master/networking/README/)\n\n### driver\n\nSpecify which driver should be used for this network.\n\nThe default driver depends on how the Docker Engine you’re using is configured, but in most instances it is `bridge` on a single host and `overlay` on a Swarm.\n\nThe Docker Engine returns an error if the driver is not available.\n\n``` \ndriver: overlay\n```\n\n#### bridge\n\nDocker defaults to using a `bridge` network on a single host. For examples of how to work with bridge networks, see the Docker Labs tutorial on [Bridge networking](https://github.com/docker/labs/blob/master/networking/A2-bridge-networking/).\n\n#### overlay\n\nThe `overlay` driver creates a named network across multiple nodes in a [swarm](../../../engine/swarm/index).\n\n- For a working example of how to build and use an `overlay` network with a service in swarm mode, see the Docker Labs tutorial on [Overlay networking and service discovery](https://github.com/docker/labs/blob/master/networking/A3-overlay-networking/).\n\n- For an in-depth look at how it works under the hood, see the networking concepts lab on the [Overlay Driver Network Architecture](https://github.com/docker/labs/blob/master/networking/concepts/06-overlay-networks/).\n\n#### host or none\n\nUse the host’s networking stack, or no networking. Equivalent to `docker run --net=host` or `docker run --net=none`. Only used if you use `docker stack` commands. If you use the `docker-compose` command, use [network_mode](#network_mode) instead.\n\nIf you want to use a particular network on a common build, use \\[network\\] as mentioned in the second yaml file example.\n\nThe syntax for using built-in networks such as `host` and `none` is a little different. Define an external network with the name `host` or `none` (that Docker has already created automatically) and an alias that Compose can use (`hostnet` or `nonet` in the following examples), then grant the service access to that network using the alias.\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    networks:\n      hostnet: {}\n\nnetworks:\n  hostnet:\n    external: true\n    name: host\n```\n\n``` \nservices:\n  web:\n    ...\n    build:\n      ...\n      network: host\n      context: .\n      ...\n```\n\n``` \nservices:\n  web:\n    ...\n    networks:\n      nonet: {}\n\nnetworks:\n  nonet:\n    external: true\n    name: none\n```\n\n### driver_opts\n\nSpecify a list of options as key-value pairs to pass to the driver for this network. Those options are driver-dependent - consult the driver’s documentation for more information. Optional.\n\n``` \ndriver_opts:\n  foo: \"bar\"\n  baz: 1\n```\n\n### attachable\n\n> Added in [version 3.2](../compose-versioning/index#version-32) file format.\n\nOnly used when the `driver` is set to `overlay`. If set to `true`, then standalone containers can attach to this network, in addition to services. If a standalone container attaches to an overlay network, it can communicate with services and standalone containers that are also attached to the overlay network from other Docker daemons.\n\n``` \nnetworks:\n  mynet1:\n    driver: overlay\n    attachable: true\n```\n\n### enable_ipv6\n\nEnable IPv6 networking on this network.\n\n> Not supported in Compose File version 3\n>\n> `enable_ipv6` requires you to use a version 2 Compose file, as this directive is not yet supported in Swarm mode.\n\n### ipam\n\nSpecify custom IPAM config. This is an object with several properties, each of which is optional:\n\n- `driver`: Custom IPAM driver, instead of the default.\n- `config`: A list with zero or more config blocks, each containing any of the following keys:\n  - `subnet`: Subnet in CIDR format that represents a network segment\n\nA full example:\n\n``` \nipam:\n  driver: default\n  config:\n    - subnet: 172.28.0.0/16\n```\n\n> **Note**\n>\n> Additional IPAM configurations, such as `gateway`, are only honored for version 2 at the moment.\n\n### internal\n\nBy default, Docker also connects a bridge network to it to provide external connectivity. If you want to create an externally isolated overlay network, you can set this option to `true`.\n\n### labels\n\nAdd metadata to containers using [Docker labels](https://docs.docker.com/config/labels-custom-metadata/). You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Financial transaction network\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Financial transaction network\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n```\n\n### external\n\nIf set to `true`, specifies that this network has been created outside of Compose. `docker-compose up` does not attempt to create it, and raises an error if it doesn’t exist.\n\nFor version 3.3 and below of the format, `external` cannot be used in conjunction with other network configuration keys (`driver`, `driver_opts`, `ipam`, `internal`). This limitation no longer exists for [version 3.4](../compose-versioning/index#version-34) and above.\n\nIn the example below, `proxy` is the gateway to the outside world. Instead of attempting to create a network called `[projectname]_outside`, Compose looks for an existing network simply called `outside` and connect the `proxy` service’s containers to it.\n\n``` \nversion: \"3.9\"\n\nservices:\n  proxy:\n    build: ./proxy\n    networks:\n      - outside\n      - default\n  app:\n    build: ./app\n    networks:\n      - default\n\nnetworks:\n  outside:\n    external: true\n```\n\n> Deprecated in [version 3.5](../compose-versioning/index#version-35) file format.\n>\n> external.name was deprecated in version 3.5 file format use `name` instead.\n\nYou can also specify the name of the network separately from the name used to refer to it within the Compose file:\n\n``` \nversion: \"3.9\"\nnetworks:\n  outside:\n    external:\n      name: actual-name-of-network\n```\n\n### name\n\n> Added in [version 3.5](../compose-versioning/index#version-35) file format.\n\nSet a custom name for this network. The name field can be used to reference networks which contain special characters. The name is used as is and will **not** be scoped with the stack name.\n\n``` \nversion: \"3.9\"\nnetworks:\n  network1:\n    name: my-app-net\n```\n\nIt can also be used in conjunction with the `external` property:\n\n``` \nversion: \"3.9\"\nnetworks:\n  network1:\n    external: true\n    name: my-app-net\n```\n\n## configs configuration reference\n\nThe top-level `configs` declaration defines or references [configs](../../../engine/swarm/configs/index) that can be granted to the services in this stack. The source of the config is either `file` or `external`.\n\n- `file`: The config is created with the contents of the file at the specified path.\n- `external`: If set to true, specifies that this config has already been created. Docker does not attempt to create it, and if it does not exist, a `config not found` error occurs.\n- `name`: The name of the config object in Docker. This field can be used to reference configs that contain special characters. The name is used as is and will **not** be scoped with the stack name. Introduced in version 3.5 file format.\n- `driver` and `driver_opts`: The name of a custom secret driver, and driver-specific options passed as key/value pairs. Introduced in version 3.8 file format, and only supported when using `docker stack`.\n- `template_driver`: The name of the templating driver to use, which controls whether and how to evaluate the secret payload as a template. If no driver is set, no templating is used. The only driver currently supported is `golang`, which uses a `golang`. Introduced in version 3.8 file format, and only supported when using `docker stack`. Refer to [use a templated config](../../../engine/swarm/configs/index#example-use-a-templated-config) for a examples of templated configs.\n\nIn this example, `my_first_config` is created (as `<stack_name>_my_first_config)`when the stack is deployed, and `my_second_config` already exists in Docker.\n\n``` \nconfigs:\n  my_first_config:\n    file: ./config_data\n  my_second_config:\n    external: true\n```\n\nAnother variant for external configs is when the name of the config in Docker is different from the name that exists within the service. The following example modifies the previous one to use the external config called `redis_config`.\n\n``` \nconfigs:\n  my_first_config:\n    file: ./config_data\n  my_second_config:\n    external:\n      name: redis_config\n```\n\nYou still need to [grant access to the config](#configs) to each service in the stack.\n\n## secrets configuration reference\n\nThe top-level `secrets` declaration defines or references [secrets](../../../engine/swarm/secrets/index) that can be granted to the services in this stack. The source of the secret is either `file` or `external`.\n\n- `file`: The secret is created with the contents of the file at the specified path.\n- `external`: If set to true, specifies that this secret has already been created. Docker does not attempt to create it, and if it does not exist, a `secret not found` error occurs.\n- `name`: The name of the secret object in Docker. This field can be used to reference secrets that contain special characters. The name is used as is and will **not** be scoped with the stack name. Introduced in version 3.5 file format.\n- `template_driver`: The name of the templating driver to use, which controls whether and how to evaluate the secret payload as a template. If no driver is set, no templating is used. The only driver currently supported is `golang`, which uses a `golang`. Introduced in version 3.8 file format, and only supported when using `docker stack`.\n\nIn this example, `my_first_secret` is created as `<stack_name>_my_first_secret`when the stack is deployed, and `my_second_secret` already exists in Docker.\n\n``` \nsecrets:\n  my_first_secret:\n    file: ./secret_data\n  my_second_secret:\n    external: true\n```\n\nAnother variant for external secrets is when the name of the secret in Docker is different from the name that exists within the service. The following example modifies the previous one to use the external secret called `redis_secret`.\n\n### Compose File v3.5 and above\n\n``` \nsecrets:\n  my_first_secret:\n    file: ./secret_data\n  my_second_secret:\n    external: true\n    name: redis_secret\n```\n\n### Compose File v3.4 and under\n\n``` \n  my_second_secret:\n    external:\n      name: redis_secret\n```\n\nYou still need to [grant access to the secrets](#secrets) to each service in the stack.\n\n## Variable substitution\n\nYour configuration options can contain environment variables. Compose uses the variable values from the shell environment in which `docker-compose` is run. For example, suppose the shell contains `POSTGRES_VERSION=9.3` and you supply this configuration:\n\n``` \ndb:\n  image: \"postgres:${POSTGRES_VERSION}\"\n```\n\nWhen you run `docker-compose up` with this configuration, Compose looks for the `POSTGRES_VERSION` environment variable in the shell and substitutes its value in. For this example, Compose resolves the `image` to `postgres:9.3` before running the configuration.\n\nIf an environment variable is not set, Compose substitutes with an empty string. In the example above, if `POSTGRES_VERSION` is not set, the value for the `image` option is `postgres:`.\n\nYou can set default values for environment variables using a [`.env` file](../../env-file/index), which Compose automatically looks for in project directory (parent folder of your Compose file). Values set in the shell environment override those set in the `.env` file.\n\n> Note when using docker stack deploy\n>\n> The `.env file` feature only works when you use the `docker-compose up` command and does not work with `docker stack deploy`.\n\nBoth `$VARIABLE` and `${VARIABLE}` syntax are supported. Additionally when using the [2.1 file format](../compose-versioning/index#version-21), it is possible to provide inline default values using typical shell syntax:\n\n- `${VARIABLE:-default}` evaluates to `default` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE-default}` evaluates to `default` only if `VARIABLE` is unset in the environment.\n\nSimilarly, the following syntax allows you to specify mandatory variables:\n\n- `${VARIABLE:?err}` exits with an error message containing `err` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE?err}` exits with an error message containing `err` if `VARIABLE` is unset in the environment.\n\nOther extended shell-style features, such as `${VARIABLE/foo/bar}`, are not supported.\n\nYou can use a `$$` (double-dollar sign) when your configuration needs a literal dollar sign. This also prevents Compose from interpolating a value, so a `$$` allows you to refer to environment variables that you don’t want processed by Compose.\n\n``` \nweb:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n```\n\nIf you forget and use a single dollar sign (`$`), Compose interprets the value as an environment variable and warns you:\n\n``` \nThe VAR_NOT_INTERPOLATED_BY_COMPOSE is not set. Substituting an empty string.\n```\n\n## Extension fields\n\n> Added in [version 3.4](../compose-versioning/index#version-34) file format.\n\nIt is possible to re-use configuration fragments using extension fields. Those special fields can be of any format as long as they are located at the root of your Compose file and their name start with the `x-` character sequence.\n\n> **Note**\n>\n> Starting with the 3.7 format (for the 3.x series) and 2.4 format (for the 2.x series), extension fields are also allowed at the root of service, volume, network, config and secret definitions.\n\n``` \nversion: \"3.9\"\nx-custom:\n  items:\n    - a\n    - b\n  options:\n    max-size: '12m'\n  name: \"custom\"\n```\n\nThe contents of those fields are ignored by Compose, but they can be inserted in your resource definitions using [YAML anchors](https://yaml.org/spec/1.2/spec.html#id2765878). For example, if you want several of your services to use the same logging configuration:\n\n``` \nlogging:\n  options:\n    max-size: '12m'\n    max-file: '5'\n  driver: json-file\n```\n\nYou may write your Compose file as follows:\n\n``` \nversion: \"3.9\"\nx-logging:\n  &default-logging\n  options:\n    max-size: '12m'\n    max-file: '5'\n  driver: json-file\n\nservices:\n  web:\n    image: myapp/web:latest\n    logging: *default-logging\n  db:\n    image: mysql:latest\n    logging: *default-logging\n```\n\nIt is also possible to partially override values in extension fields using the [YAML merge type](https://yaml.org/type/merge.html). For example:\n\n``` \nversion: \"3.9\"\nx-volumes:\n  &default-volume\n  driver: foobar-storage\n\nservices:\n  web:\n    image: myapp/web:latest\n    volumes: [\"vol1\", \"vol2\", \"vol3\"]\nvolumes:\n  vol1: *default-volume\n  vol2:\n    << : *default-volume\n    name: volume02\n  vol3:\n    << : *default-volume\n    driver: default\n    name: volume-local\n```\n\n## Compose documentation\n\n- [User guide](../../index)\n- [Installing Compose](../../install/index)\n- [Compose file versions and upgrading](../compose-versioning/index)\n- [Sample apps with Compose](../../samples-for-compose/index)\n- [Command line reference](../../reference/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose version 3](https://docs.docker.com/search/?q=compose%20version%203), [docker](https://docs.docker.com/search/?q=docker)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/compose-file/compose-file-v3/](https://docs.docker.com/compose/compose-file/compose-file-v3/)"
- name: Compose file versions and upgrading
  id: compose/compose-file/compose-versioning/index
  summary: The Compose file is a YAML file defining services, networks, and volumes for a Docker application
  description: "# Compose file versions and upgrading\n\nThe Compose file is a [YAML](https://yaml.org) file defining services, networks, and volumes for a Docker application.\n\nThe Compose file formats are now described in these references, specific to each version.\n\n| **Reference file**                                                | **What changed in this version**           |\n|:------------------------------------------------------------------|:-------------------------------------------|\n| [Compose Specification](../index) (most current, and recommended) | [Versioning](index#versioning)             |\n| [Version 3](../compose-file-v3/index)                             | [Version 3 updates](#version-3)            |\n| [Version 2](../compose-file-v2/index)                             | [Version 2 updates](#version-2)            |\n| Version 1 (Deprecated)                                            | [Version 1 updates](#version-1-deprecated) |\n\nThe topics below explain the differences among the versions, Docker Engine compatibility, and [how to upgrade](#upgrading).\n\n## Compatibility matrix\n\nThere are several versions of the Compose file format – 1, 2, 2.x, and 3.x\n\nThis table shows which Compose file versions support specific Docker releases.\n\n| **Compose file format** | **Docker Engine release** |\n|-------------------------|---------------------------|\n| Compose specification   | 19.03.0+                  |\n| 3.8                     | 19.03.0+                  |\n| 3.7                     | 18.06.0+                  |\n| 3.6                     | 18.02.0+                  |\n| 3.5                     | 17.12.0+                  |\n| 3.4                     | 17.09.0+                  |\n| 3.3                     | 17.06.0+                  |\n| 3.2                     | 17.04.0+                  |\n| 3.1                     | 1.13.1+                   |\n| 3.0                     | 1.13.0+                   |\n| 2.4                     | 17.12.0+                  |\n| 2.3                     | 17.06.0+                  |\n| 2.2                     | 1.13.0+                   |\n| 2.1                     | 1.12.0+                   |\n| 2.0                     | 1.10.0+                   |\n\nIn addition to Compose file format versions shown in the table, the Compose itself is on a release schedule, as shown in [Compose releases](https://github.com/docker/compose/releases/), but file format versions do not necessarily increment with each release. For example, Compose file format 3.0 was first introduced in [Compose release 1.10.0](https://github.com/docker/compose/releases/tag/1.10.0), and versioned gradually in subsequent releases.\n\nThe latest Compose file format is defined by the [Compose Specification](https://github.com/compose-spec/compose-spec/blob/master/spec/) and is implemented by Docker Compose **1.27.0+**.\n\n> Looking for more detail on Docker and Compose compatibility?\n>\n> We recommend keeping up-to-date with newer releases as much as possible. However, if you are using an older version of Docker and want to determine which Compose release is compatible, refer to the [Compose release notes](https://github.com/docker/compose/releases/). Each set of release notes gives details on which versions of Docker Engine are supported, along with compatible Compose file format versions. (See also, the discussion in [issue \\#3404](https://github.com/docker/docker.github.io/issues/3404).)\n\nFor details on versions and how to upgrade, see [Versioning](index#versioning) and [Upgrading](index#upgrading).\n\n## Versioning\n\nThere are three legacy versions of the Compose file format:\n\n- Version 1. This is specified by omitting a `version` key at the root of the YAML.\n\n- Version 2.x. This is specified with a `version: '2'` or `version: '2.1'`, etc., entry at the root of the YAML.\n\n- Version 3.x, designed to be cross-compatible between Compose and the Docker Engine’s [swarm mode](../../../engine/swarm/index). This is specified with a `version: '3'` or `version: '3.1'`, etc., entry at the root of the YAML.\n\nThe latest and recommended version of the Compose file format is defined by the [Compose Specification](https://github.com/compose-spec/compose-spec/blob/master/spec/). This format merges the 2.x and 3.x versions and is implemented by **Compose 1.27.0+**.\n\n> ### v2 and v3 Declaration\n>\n> **Note**: When specifying the Compose file version to use, make sure to specify both the *major* and *minor* numbers. If no minor version is given, `0` is used by default and not the latest minor version.\n\nThe [Compatibility Matrix](#compatibility-matrix) shows Compose file versions mapped to Docker Engine releases.\n\nTo move your project to a later version, see the [Upgrading](#upgrading) section.\n\n> **Note**: If you’re using [multiple Compose files](../../extends/index#multiple-compose-files) or [extending services](../../extends/index#extending-services), each file must be of the same version - you cannot, for example, mix version 1 and 2 in a single project.\n\nSeveral things differ depending on which version you use:\n\n- The structure and permitted configuration keys\n- The minimum Docker Engine version you must be running\n- Compose’s behaviour with regards to networking\n\nThese differences are explained below.\n\n### Version 1 (Deprecated)\n\nCompose files that do not declare a version are considered “version 1”. In those files, all the [services](../compose-file-v3/index#service-configuration-reference) are declared at the root of the document.\n\nVersion 1 is supported by **Compose up to 1.6.x**. It will be deprecated in a future Compose release.\n\nVersion 1 files cannot declare named [volumes](../compose-file-v3/index#volume-configuration-reference), [networks](../compose-file-v3/index#network-configuration-reference) or [build arguments](../compose-file-v3/index#args).\n\nCompose does not take advantage of [networking](../../networking/index) when you use version 1: every container is placed on the default `bridge` network and is reachable from every other container at its IP address. You need to use `links` to enable discovery between containers.\n\nExample:\n\n``` \nweb:\n  build: .\n  ports:\n   - \"8000:5000\"\n  volumes:\n   - .:/code\n  links:\n   - redis\nredis:\n  image: redis\n```\n\n### Version 2\n\nCompose files using the version 2 syntax must indicate the version number at the root of the document. All [services](../compose-file-v2/index#service-configuration-reference) must be declared under the `services` key.\n\nVersion 2 files are supported by **Compose 1.6.0+** and require a Docker Engine of version **1.10.0+**.\n\nNamed [volumes](../compose-file-v2/index#volume-configuration-reference) can be declared under the `volumes` key, and [networks](../compose-file-v2/index#network-configuration-reference) can be declared under the `networks` key.\n\nBy default, every container joins an application-wide default network, and is discoverable at a hostname that’s the same as the service name. This means [links](../compose-file-v2/index#links) are largely unnecessary. For more details, see [Networking in Compose](../../networking/index).\n\n> **Note**\n>\n> When specifying the Compose file version to use, make sure to specify both the *major* and *minor* numbers. If no minor version is given, `0` is used by default and not the latest minor version. As a result, features added in later versions will not be supported. For example:\n>\n> ``` \n> version: \"2\"\n> ```\n>\n> is equivalent to:\n>\n> ``` \n> version: \"2.0\"\n> ```\n\nSimple example:\n\n``` \nversion: \"2.4\"\nservices:\n  web:\n    build: .\n    ports:\n     - \"8000:5000\"\n    volumes:\n     - .:/code\n  redis:\n    image: redis\n```\n\nA more extended example, defining volumes and networks:\n\n``` \nversion: \"2.4\"\nservices:\n  web:\n    build: .\n    ports:\n     - \"8000:5000\"\n    volumes:\n     - .:/code\n    networks:\n      - front-tier\n      - back-tier\n  redis:\n    image: redis\n    volumes:\n      - redis-data:/var/lib/redis\n    networks:\n      - back-tier\nvolumes:\n  redis-data:\n    driver: local\nnetworks:\n  front-tier:\n    driver: bridge\n  back-tier:\n    driver: bridge\n```\n\nSeveral other options were added to support networking, such as:\n\n- [`aliases`](../compose-file-v2/index#aliases)\n\n- The [`depends_on`](../compose-file-v2/index#depends_on) option can be used in place of links to indicate dependencies between services and startup order.\n\n  ``` \n  version: \"2.4\"\n  services:\n    web:\n      build: .\n      depends_on:\n        - db\n        - redis\n    redis:\n      image: redis\n    db:\n      image: postgres\n  ```\n\n- [`ipv4_address`, `ipv6_address`](../compose-file-v2/index#ipv4_address-ipv6_address)\n\n[Variable substitution](../compose-file-v2/index#variable-substitution) also was added in Version 2.\n\n### Version 2.1\n\nAn upgrade of [version 2](#version-2) that introduces new parameters only available with Docker Engine version **1.12.0+**. Version 2.1 files are supported by **Compose 1.9.0+**.\n\nIntroduces the following additional parameters:\n\n- [`link_local_ips`](../compose-file-v2/index#link_local_ips)\n- [`isolation`](../compose-file-v2/index#isolation-1) in build configurations and service definitions\n- `labels` for [volumes](../compose-file-v2/index#volume-configuration-reference), [networks](../compose-file-v2/index#network-configuration-reference), and [build](../compose-file-v3/index#build)\n- `name` for [volumes](../compose-file-v2/index#volume-configuration-reference)\n- [`userns_mode`](../compose-file-v2/index#userns_mode)\n- [`healthcheck`](../compose-file-v2/index#healthcheck)\n- [`sysctls`](../compose-file-v2/index#sysctls)\n- [`pids_limit`](../compose-file-v2/index#pids_limit)\n- [`oom_kill_disable`](../compose-file-v2/index#cpu-and-other-resources)\n- [`cpu_period`](../compose-file-v2/index#cpu-and-other-resources)\n\n### Version 2.2\n\nAn upgrade of [version 2.1](#version-21) that introduces new parameters only available with Docker Engine version **1.13.0+**. Version 2.2 files are supported by **Compose 1.13.0+**. This version also allows you to specify default scale numbers inside the service’s configuration.\n\nIntroduces the following additional parameters:\n\n- [`init`](../compose-file-v2/index#init)\n- [`scale`](../compose-file-v2/index#scale)\n- [`cpu_rt_runtime` and `cpu_rt_period`](../compose-file-v2/index#cpu_rt_runtime-cpu_rt_period)\n- [`network`](../compose-file-v2/index#network) for [build configurations](../compose-file-v2/index#build)\n\n### Version 2.3\n\nAn upgrade of [version 2.2](#version-22) that introduces new parameters only available with Docker Engine version **17.06.0+**. Version 2.3 files are supported by **Compose 1.16.0+**.\n\nIntroduces the following additional parameters:\n\n- [`target`](../compose-file-v2/index#target), [`extra_hosts`](../compose-file-v2/index#extra_hosts-1) and [`shm_size`](../compose-file-v2/index#shm_size) for [build configurations](../compose-file-v2/index#build)\n- `start_period` for [`healthchecks`](../compose-file-v2/index#healthcheck)\n- [“Long syntax” for volumes](../compose-file-v2/index#long-syntax)\n- [`runtime`](../compose-file-v2/index#runtime) for service definitions\n- [`device_cgroup_rules`](../compose-file-v2/index#device_cgroup_rules)\n\n### Version 2.4\n\nAn upgrade of [version 2.3](#version-23) that introduces new parameters only available with Docker Engine version **17.12.0+**. Version 2.4 files are supported by **Compose 1.21.0+**.\n\nIntroduces the following additional parameters:\n\n- [`platform`](../compose-file-v2/index#platform) for service definitions\n- Support for extension fields at the root of service, network, and volume definitions\n\n### Version 3\n\nDesigned to be cross-compatible between Compose and the Docker Engine’s [swarm mode](../../../engine/swarm/index), version 3 removes several options and adds several more.\n\n- Removed: `volume_driver`, `volumes_from`, `cpu_shares`, `cpu_quota`, `cpuset`, `mem_limit`, `memswap_limit`, `extends`, `group_add`. See the [upgrading](#upgrading) guide for how to migrate away from these. (For more information on `extends`, see [Extending services](../../extends/index#extending-services).)\n\n- Added: [deploy](../compose-file-v3/index#deploy)\n\n> **Note**: When specifying the Compose file version to use, make sure to specify both the *major* and *minor* numbers. If no minor version is given, `0` is used by default and not the latest minor version. As a result, features added in later versions will not be supported. For example:\n>\n> ``` \n> version: \"3\"\n> ```\n>\n> is equivalent to:\n>\n> ``` \n> version: \"3.0\"\n> ```\n\n### Version 3.1\n\nAn upgrade of [version 3](#version-3) that introduces new parameters only available with Docker Engine version **1.13.1+**, and higher.\n\nIntroduces the following additional parameters:\n\n- [`secrets`](../compose-file-v3/index#secrets)\n\n### Version 3.2\n\nAn upgrade of [version 3](#version-3) that introduces new parameters only available with Docker Engine version **17.04.0+**, and higher.\n\nIntroduces the following additional parameters:\n\n- [`cache_from`](../compose-file-v3/index#cache_from) in [build configurations](../compose-file-v3/index#build)\n- Long syntax for [ports](../compose-file-v3/index#ports) and [volume mounts](../compose-file-v3/index#volumes)\n- [`attachable`](../compose-file-v3/index#attachable) network driver option\n- [deploy `endpoint_mode`](../compose-file-v3/index#endpoint_mode)\n- [deploy placement `preference`](../compose-file-v3/index#placement)\n\n### Version 3.3\n\nAn upgrade of [version 3](#version-3) that introduces new parameters only available with Docker Engine version **17.06.0+**, and higher.\n\nIntroduces the following additional parameters:\n\n- [build `labels`](../compose-file-v3/index#build)\n- [`credential_spec`](../compose-file-v3/index#credential_spec)\n- [`configs`](../compose-file-v3/index#configs)\n\n### Version 3.4\n\nAn upgrade of [version 3](#version-3) that introduces new parameters. It is only available with Docker Engine version **17.09.0** and higher.\n\nIntroduces the following additional parameters:\n\n- [`target`](../compose-file-v3/index#target) and [`network`](../compose-file-v3/index#network) in [build configurations](../compose-file-v3/index#build)\n- `start_period` for [`healthchecks`](../compose-file-v3/index#healthcheck)\n- `order` for [update configurations](../compose-file-v3/index#update_config)\n- `name` for [volumes](../compose-file-v3/index#volume-configuration-reference)\n\n### Version 3.5\n\nAn upgrade of [version 3](#version-3) that introduces new parameters. It is only available with Docker Engine version **17.12.0** and higher.\n\nIntroduces the following additional parameters:\n\n- [`isolation`](../compose-file-v3/index#isolation) in service definitions\n- `name` for networks, secrets and configs\n- `shm_size` in [build configurations](../compose-file-v3/index#build)\n\n### Version 3.6\n\nAn upgrade of [version 3](#version-3) that introduces new parameters. It is only available with Docker Engine version **18.02.0** and higher.\n\nIntroduces the following additional parameters:\n\n- [`tmpfs` size](../compose-file-v3/index#long-syntax-3) for `tmpfs`-type mounts\n\n### Version 3.7\n\nAn upgrade of [version 3](#version-3) that introduces new parameters. It is only available with Docker Engine version **18.06.0** and higher.\n\nIntroduces the following additional parameters:\n\n- [`init`](../compose-file-v3/index#init) in service definitions\n- [`rollback_config`](../compose-file-v3/index#rollback_config) in deploy configurations\n- Support for extension fields at the root of service, network, volume, secret and config definitions\n\n### Version 3.8\n\nAn upgrade of [version 3](#version-3) that introduces new parameters. It is only available with Docker Engine version **19.03.0** and higher.\n\nIntroduces the following additional parameters:\n\n- [`max_replicas_per_node`](../compose-file-v3/index#max_replicas_per_node) in placement configurations\n- `template_driver` option for [config](../compose-file-v3/index#configs-configuration-reference) and [secret](../compose-file-v3/index#secrets-configuration-reference) configurations. This option is only supported when deploying swarm services using `docker stack deploy`.\n- `driver` and `driver_opts` option for [secret](../compose-file-v3/index#secrets-configuration-reference) configurations. This option is only supported when deploying swarm services using `docker stack deploy`.\n\n## Upgrading\n\n### Version 2.x to 3.x\n\nBetween versions 2.x and 3.x, the structure of the Compose file is the same, but several options have been removed:\n\n- `volume_driver`: Instead of setting the volume driver on the service, define a volume using the [top-level `volumes` option](../compose-file-v3/index#volume-configuration-reference) and specify the driver there.\n\n  ``` \n  version: \"3.9\"\n  services:\n    db:\n      image: postgres\n      volumes:\n        - data:/var/lib/postgresql/data\n  volumes:\n    data:\n      driver: mydriver\n  ```\n\n- `volumes_from`: To share a volume between services, define it using the [top-level `volumes` option](../compose-file-v3/index#volume-configuration-reference) and reference it from each service that shares it using the [service-level `volumes` option](../compose-file-v3/index#driver).\n\n- `cpu_shares`, `cpu_quota`, `cpuset`, `mem_limit`, `memswap_limit`: These have been replaced by the [resources](../compose-file-v3/index#resources) key under `deploy`. `deploy` configuration only takes effect when using `docker stack deploy`, and is ignored by `docker-compose`.\n\n- `extends`: This option has been removed for `version: \"3.x\"` Compose files. (For more information, see [Extending services](../../extends/index#extending-services).)\n\n- `group_add`: This option has been removed for `version: \"3.x\"` Compose files.\n\n- `pids_limit`: This option has not been introduced in `version: \"3.x\"` Compose files.\n\n- `link_local_ips` in `networks`: This option has not been introduced in `version: \"3.x\"` Compose files.\n\n### Version 1 to 2.x\n\nIn the majority of cases, moving from version 1 to 2 is a very simple process:\n\n1.  Indent the whole file by one level and put a `services:` key at the top.\n2.  Add a `version: '2'` line at the top of the file.\n\nIt’s more complicated if you’re using particular configuration features:\n\n- `dockerfile`: This now lives under the `build` key:\n\n  ``` \n  build:\n    context: .\n    dockerfile: Dockerfile-alternate\n  ```\n\n- `log_driver`, `log_opt`: These now live under the `logging` key:\n\n  ``` \n  logging:\n    driver: syslog\n    options:\n      syslog-address: \"tcp://192.168.0.42:123\"\n  ```\n\n- `links` with environment variables: environment variables created by links, such as `CONTAINERNAME_PORT`, \\` have been deprecated for some time. In the new Docker network system, they have been removed. You should either connect directly to the appropriate hostname or set the relevant environment variable yourself, using the link hostname:\n\n  ``` \n  web:\n    links:\n      - db\n    environment:\n      - DB_PORT=tcp://db:5432\n  ```\n\n- `external_links`: Compose uses Docker networks when running version 2 projects, so links behave slightly differently. In particular, two containers must be connected to at least one network in common in order to communicate, even if explicitly linked together.\n\n  Either connect the external container to your app’s [default network](../../networking/index), or connect both the external container and your service’s containers to an [external network](../../networking/index#use-a-pre-existing-network).\n\n- `net`: This is now replaced by [network_mode](../compose-file-v3/index#network_mode):\n\n  ``` \n  net: host    ->  network_mode: host\n  net: bridge  ->  network_mode: bridge\n  net: none    ->  network_mode: none\n  ```\n\n  If you’re using `net: \"container:[service name]\"`, you must now use `network_mode: \"service:[service name]\"` instead.\n\n  ``` \n  net: \"container:web\"  ->  network_mode: \"service:web\"\n  ```\n\n  If you’re using `net: \"container:[container name/id]\"`, the value does not need to change.\n\n  ``` \n  net: \"container:cont-name\"  ->  network_mode: \"container:cont-name\"\n  net: \"container:abc12345\"   ->  network_mode: \"container:abc12345\"\n  ```\n\n- `volumes` with named volumes: these must now be explicitly declared in a top-level `volumes` section of your Compose file. If a service mounts a named volume called `data`, you must declare a `data` volume in your top-level `volumes` section. The whole file might look like this:\n\n  ``` \n  version: \"2.4\"\n  services:\n    db:\n      image: postgres\n      volumes:\n        - data:/var/lib/postgresql/data\n  volumes:\n    data: {}\n  ```\n\n  By default, Compose creates a volume whose name is prefixed with your project name. If you want it to just be called `data`, declare it as external:\n\n  ``` \n  volumes:\n    data:\n      external: true\n  ```\n\n## Compatibility mode\n\n`docker-compose` 1.20.0 introduces a new `--compatibility` flag designed to help developers transition to version 3 more easily. When enabled, `docker-compose` reads the `deploy` section of each service’s definition and attempts to translate it into the equivalent version 2 parameter. Currently, the following deploy keys are translated:\n\n- [resources](../compose-file-v3/index#resources) limits and memory reservations\n- [replicas](../compose-file-v3/index#replicas)\n- [restart_policy](../compose-file-v3/index#restart_policy) `condition` and `max_attempts`\n\nAll other keys are ignored and produce a warning if present. You can review the configuration that will be used to deploy by using the `--compatibility` flag with the `config` command.\n\n> Do not use this in production!\n>\n> We recommend against using `--compatibility` mode in production. Because the resulting configuration is only an approximate using non-Swarm mode properties, it may produce unexpected results.\n\n## Compose file format references\n\n- [Compose Specification](../index)\n- [Compose file version 3](../compose-file-v3/index)\n- [Compose file version 2](../compose-file-v2/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [versions](https://docs.docker.com/search/?q=versions), [upgrading](https://docs.docker.com/search/?q=upgrading), [docker](https://docs.docker.com/search/?q=docker)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/compose-file/compose-versioning/](https://docs.docker.com/compose/compose-file/compose-versioning/)"
- name: Compose specification
  id: compose/compose-file/index
  summary: The Compose file is a YAML file defining services, networks, and volumes for a Docker application
  description: "# Compose specification\n\nThe Compose file is a [YAML](https://yaml.org) file defining services, networks, and volumes for a Docker application. The latest and recommended version of the Compose file format is defined by the [Compose Specification](https://github.com/compose-spec/compose-spec/blob/master/spec/). The Compose spec merges the legacy 2.x and 3.x versions, aggregating properties across these formats and is implemented by **Compose 1.27.0+**.\n\n## Status of this document\n\nThis document specifies the Compose file format used to define multi-containers applications. Distribution of this document is unlimited.\n\nThe key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in [RFC 2119](https://tools.ietf.org/html/rfc2119).\n\n### Requirements and optional attributes\n\nThe Compose specification includes properties designed to target a local [OCI](https://opencontainers.org/) container runtime, exposing Linux kernel specific configuration options, but also some Windows container specific properties, as well as cloud platform features related to resource placement on a cluster, replicated application distribution and scalability.\n\nWe acknowledge that no Compose implementation is expected to support **all** attributes, and that support for some properties is Platform dependent and can only be confirmed at runtime. The definition of a versioned schema to control the supported properties in a Compose file, established by the [docker-compose](https://github.com/docker/compose) tool where the Compose file format was designed, doesn’t offer any guarantee to the end-user attributes will be actually implemented.\n\nThe specification defines the expected configuration syntax and behavior, but - until noted - supporting any of those is OPTIONAL.\n\nA Compose implementation to parse a Compose file using unsupported attributes SHOULD warn user. We recommend implementors to support those running modes:\n\n- default: warn user about unsupported attributes, but ignore them\n- strict: warn user about unsupported attributes and reject the compose file\n- loose: ignore unsupported attributes AND unknown attributes (that were not defined by the spec by the time implementation was created)\n\n## The Compose application model\n\nThe Compose specification allows one to define a platform-agnostic container based application. Such an application is designed as a set of containers which have to both run together with adequate shared resources and communication channels.\n\nComputing components of an application are defined as [Services](#services-top-level-element). A Service is an abstract concept implemented on platforms by running the same container image (and configuration) one or more times.\n\nServices communicate with each other through [Networks](#networks-top-level-element). In this specification, a Network is a platform capability abstraction to establish an IP route between containers within services connected together. Low-level, platform-specific networking options are grouped into the Network definition and MAY be partially implemented on some platforms.\n\nServices store and share persistent data into [Volumes](#volumes-top-level-element). The specification describes such a persistent data as a high-level filesystem mount with global options. Actual platform-specific implementation details are grouped into the Volumes definition and MAY be partially implemented on some platforms.\n\nSome services require configuration data that is dependent on the runtime or platform. For this, the specification defines a dedicated concept: [Configs](#configs-top-level-element). From a Service container point of view, Configs are comparable to Volumes, in that they are files mounted into the container. But the actual definition involves distinct platform resources and services, which are abstracted by this type.\n\nA [Secret](#secrets-top-level-element) is a specific flavor of configuration data for sensitive data that SHOULD NOT be exposed without security considerations. Secrets are made available to services as files mounted into their containers, but the platform-specific resources to provide sensitive data are specific enough to deserve a distinct concept and definition within the Compose specification.\n\nDistinction within Volumes, Configs and Secret allows implementations to offer a comparable abstraction at service level, but cover the specific configuration of adequate platform resources for well identified data usages.\n\nA **Project** is an individual deployment of an application specification on a platform. A project’s name is used to group resources together and isolate them from other applications or other installation of the same Compose specified application with distinct parameters. A Compose implementation creating resources on a platform MUST prefix resource names by project and set the label `com.docker.compose.project`.\n\nProject name can be set explicitly by top-level `name` attribute. Compose implementation MUST offer a way for user to set a custom project name and override this name, so that the same `compose.yaml` file can be deployed twice on the same infrastructure, without changes, by just passing a distinct name.\n\n### Illustrative example\n\nThe following example illustrates Compose specification concepts with a concrete example application. The example is non-normative.\n\nConsider an application split into a frontend web application and a backend service.\n\nThe frontend is configured at runtime with an HTTP configuration file managed by infrastructure, providing an external domain name, and an HTTPS server certificate injected by the platform’s secured secret store.\n\nThe backend stores data in a persistent volume.\n\nBoth services communicate with each other on an isolated back-tier network, while frontend is also connected to a front-tier network and exposes port 443 for external usage.\n\n``` \n(External user) --> 443 [frontend network]\n                            |\n                  +--------------------+\n                  |  frontend service  |...ro...<HTTP configuration>\n                  |      \"webapp\"      |...ro...<server certificate> #secured\n                  +--------------------+\n                            |\n                        [backend network]\n                            |\n                  +--------------------+\n                  |  backend service   |  r+w   ___________________\n                  |     \"database\"     |=======( persistent volume )\n                  +--------------------+        \\_________________/\n```\n\nThe example application is composed of the following parts:\n\n- 2 services, backed by Docker images: `webapp` and `database`\n- 1 secret (HTTPS certificate), injected into the frontend\n- 1 configuration (HTTP), injected into the frontend\n- 1 persistent volume, attached to the backend\n- 2 networks\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    ports:\n      - \"443:8043\"\n    networks:\n      - front-tier\n      - back-tier\n    configs:\n      - httpd-config\n    secrets:\n      - server-certificate\n\n  backend:\n    image: awesome/database\n    volumes:\n      - db-data:/etc/data\n    networks:\n      - back-tier\n\nvolumes:\n  db-data:\n    driver: flocker\n    driver_opts:\n      size: \"10GiB\"\n\nconfigs:\n  httpd-config:\n    external: true\n\nsecrets:\n  server-certificate:\n    external: true\n\nnetworks:\n  # The presence of these objects is sufficient to define them\n  front-tier: {}\n  back-tier: {}\n```\n\nThis example illustrates the distinction between volumes, configs and secrets. While all of them are all exposed to service containers as mounted files or directories, only a volume can be configured for read+write access. Secrets and configs are read-only. The volume configuration allows you to select a volume driver and pass driver options to tweak volume management according to the actual infrastructure. Configs and Secrets rely on platform services, and are declared `external` as they are not managed as part of the application lifecycle: the Compose implementation will use a platform-specific lookup mechanism to retrieve runtime values.\n\n## Compose file\n\nThe Compose file is a [YAML](http://yaml.org/) file defining [version](#version-top-level-element) (DEPRECATED), [services](#services-top-level-element) (REQUIRED), [networks](#networks-top-level-element), [volumes](#volumes-top-level-element), [configs](#configs-top-level-element) and [secrets](#secrets-top-level-element). The default path for a Compose file is `compose.yaml` (preferred) or `compose.yml` in working directory. Compose implementations SHOULD also support `docker-compose.yaml` and `docker-compose.yml` for backward compatibility. If both files exist, Compose implementations MUST prefer canonical `compose.yaml` one.\n\nMultiple Compose files can be combined together to define the application model. The combination of YAML files MUST be implemented by appending/overriding YAML elements based on Compose file order set by the user. Simple attributes and maps get overridden by the highest order Compose file, lists get merged by appending. Relative paths MUST be resolved based on the **first** Compose file’s parent folder, whenever complimentary files being merged are hosted in other folders.\n\nAs some Compose file elements can both be expressed as single strings or complex objects, merges MUST apply to the expanded form.\n\n### Profiles\n\nProfiles allow to adjust the Compose application model for various usages and environments. A Compose implementation SHOULD allow the user to define a set of active profiles. The exact mechanism is implementation specific and MAY include command line flags, environment variables, etc.\n\nThe Services top-level element supports a `profiles` attribute to define a list of named profiles. Services without a `profiles` attribute set MUST always be enabled. A service MUST be ignored by the Compose implementation when none of the listed `profiles` match the active ones, unless the service is explicitly targeted by a command. In that case its `profiles` MUST be added to the set of active profiles. All other top-level elements are not affected by `profiles` and are always active.\n\nReferences to other services (by `links`, `extends` or shared resource syntax `service:xxx`) MUST not automatically enable a component that would otherwise have been ignored by active profiles. Instead the Compose implementation MUST return an error.\n\n#### Illustrative example\n\n``` \nservices:\n  foo:\n    image: foo\n  bar:\n    image: bar\n    profiles:\n      - test\n  baz:\n    image: baz\n    depends_on:\n      - bar\n    profiles:\n      - test\n  zot:\n    image: zot\n    depends_on:\n      - bar\n    profiles:\n      - debug\n```\n\n- Compose application model parsed with no profile enabled only contains the `foo` service.\n- If profile `test` is enabled, model contains the services `bar` and `baz` which are enabled by the `test` profile and service `foo` which is always enabled.\n- If profile `debug` is enabled, model contains both `foo` and `zot` services, but not `bar` and `baz` and as such the model is invalid regarding the `depends_on` constraint of `zot`.\n- If profiles `debug` and `test` are enabled, model contains all services: `foo`, `bar`, `baz` and `zot`.\n- If Compose implementation is executed with `bar` as explicit service to run, it and the `test` profile will be active even if `test` profile is not enabled *by the user*.\n- If Compose implementation is executed with `baz` as explicit service to run, the service `baz` and the profile `test` will be active and `bar` will be pulled in by the `depends_on` constraint.\n- If Compose implementation is executed with `zot` as explicit service to run, again the model will be invalid regarding the `depends_on` constraint of `zot` since `zot` and `bar` have no common `profiles` listed.\n- If Compose implementation is executed with `zot` as explicit service to run and profile `test` enabled, profile `debug` is automatically enabled and service `bar` is pulled in as a dependency starting both services `zot` and `bar`.\n\n## Version top-level element\n\nTop-level `version` property is defined by the specification for backward compatibility but is only informative.\n\nA Compose implementation SHOULD NOT use this version to select an exact schema to validate the Compose file, but prefer the most recent schema at the time it has been designed.\n\nCompose implementations SHOULD validate whether they can fully parse the Compose file. If some fields are unknown, typically because the Compose file was written with fields defined by a newer version of the specification, Compose implementations SHOULD warn the user. Compose implementations MAY offer options to ignore unknown fields (as defined by [“loose”](#requirements-and-optional-attributes) mode).\n\n## Name top-level element\n\nTop-level `name` property is defined by the specification as project name to be used if user doesn’t set one explicitly. Compose implementations MUST offer a way for user to override this name, and SHOULD define a mechanism to compute a default project name, to be used if the top-level `name` element is not set.\n\nWhenever project name is defined by top-level `name` or by some custom mechanism, it MUST be exposed for [interpolation](#interpolation) and environment variable resolution as `COMPOSE_PROJECT_NAME`\n\n``` \nservices:\n  foo:\n    image: busybox\n    environment:\n      - COMPOSE_PROJECT_NAME\n    command: echo \"I'm running ${COMPOSE_PROJECT_NAME}\"\n```\n\n## Services top-level element\n\nA Service is an abstract definition of a computing resource within an application which can be scaled/replaced independently from other components. Services are backed by a set of containers, run by the platform according to replication requirements and placement constraints. Being backed by containers, Services are defined by a Docker image and set of runtime arguments. All containers within a service are identically created with these arguments.\n\nA Compose file MUST declare a `services` root element as a map whose keys are string representations of service names, and whose values are service definitions. A service definition contains the configuration that is applied to each container started for that service.\n\nEach service MAY also include a Build section, which defines how to create the Docker image for the service. Compose implementations MAY support building docker images using this service definition. If not implemented the Build section SHOULD be ignored and the Compose file MUST still be considered valid.\n\nBuild support is an OPTIONAL aspect of the Compose specification, and is described in detail in the [Build support](build/index) documentation.\n\nEach Service defines runtime constraints and requirements to run its containers. The `deploy` section groups these constraints and allows the platform to adjust the deployment strategy to best match containers’ needs with available resources.\n\nDeploy support is an OPTIONAL aspect of the Compose specification, and is described in detail in the [Deployment support](deploy/index) documentation. not implemented the Deploy section SHOULD be ignored and the Compose file MUST still be considered valid.\n\n### build\n\n`build` specifies the build configuration for creating container image from source, as defined in the [Build support](build/index) documentation.\n\n### blkio_config\n\n`blkio_config` defines a set of configuration options to set block IO limits for this service.\n\n``` \nservices:\n  foo:\n    image: busybox\n    blkio_config:\n       weight: 300\n       weight_device:\n         - path: /dev/sda\n           weight: 400\n       device_read_bps:\n         - path: /dev/sdb\n           rate: '12mb'\n       device_read_iops:\n         - path: /dev/sdb\n           rate: 120\n       device_write_bps:\n         - path: /dev/sdb\n           rate: '1024k'\n       device_write_iops:\n         - path: /dev/sdb\n           rate: 30\n```\n\n#### device_read_bps, device_write_bps\n\nSet a limit in bytes per second for read / write operations on a given device. Each item in the list MUST have two keys:\n\n- `path`: defining the symbolic path to the affected device.\n- `rate`: either as an integer value representing the number of bytes or as a string expressing a byte value.\n\n#### device_read_iops, device_write_iops\n\nSet a limit in operations per second for read / write operations on a given device. Each item in the list MUST have two keys:\n\n- `path`: defining the symbolic path to the affected device.\n- `rate`: as an integer value representing the permitted number of operations per second.\n\n#### weight\n\nModify the proportion of bandwidth allocated to this service relative to other services. Takes an integer value between 10 and 1000, with 500 being the default.\n\n#### weight_device\n\nFine-tune bandwidth allocation by device. Each item in the list must have two keys:\n\n- `path`: defining the symbolic path to the affected device.\n- `weight`: an integer value between 10 and 1000.\n\n### cpu_count\n\n`cpu_count` defines the number of usable CPUs for service container.\n\n### cpu_percent\n\n`cpu_percent` defines the usable percentage of the available CPUs.\n\n### cpu_shares\n\n`cpu_shares` defines (as integer value) service container relative CPU weight versus other containers.\n\n### cpu_period\n\n`cpu_period` allow Compose implementations to configure CPU CFS (Completely Fair Scheduler) period when platform is based on Linux kernel.\n\n### cpu_quota\n\n`cpu_quota` allow Compose implementations to configure CPU CFS (Completely Fair Scheduler) quota when platform is based on Linux kernel.\n\n### cpu_rt_runtime\n\n`cpu_rt_runtime` configures CPU allocation parameters for platform with support for realtime scheduler. Can be either an integer value using microseconds as unit or a [duration](#specifying-durations).\n\n``` \n cpu_rt_runtime: '400ms'\n cpu_rt_runtime: 95000`\n```\n\n### cpu_rt_period\n\n`cpu_rt_period` configures CPU allocation parameters for platform with support for realtime scheduler. Can be either an integer value using microseconds as unit or a [duration](#specifying-durations).\n\n``` \n cpu_rt_period: '1400us'\n cpu_rt_period: 11000`\n```\n\n### cpus\n\n*DEPRECATED: use [deploy.reservations.cpus](deploy/index#cpus)*\n\n`cpus` define the number of (potentially virtual) CPUs to allocate to service containers. This is a fractional number. `0.000` means no limit.\n\n### cpuset\n\n`cpuset` defines the explicit CPUs in which to allow execution. Can be a range `0-3` or a list `0,1`\n\n### cap_add\n\n`cap_add` specifies additional container [capabilities](http://man7.org/linux/man-pages/man7/capabilities.7.html) as strings.\n\n``` \ncap_add:\n  - ALL\n```\n\n### cap_drop\n\n`cap_drop` specifies container [capabilities](http://man7.org/linux/man-pages/man7/capabilities.7.html) to drop as strings.\n\n``` \ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n```\n\n### cgroup_parent\n\n`cgroup_parent` specifies an OPTIONAL parent [cgroup](http://man7.org/linux/man-pages/man7/cgroups.7.html) for the container.\n\n``` \ncgroup_parent: m-executor-abcd\n```\n\n### command\n\n`command` overrides the the default command declared by the container image (i.e. by Dockerfile’s `CMD`).\n\n``` \ncommand: bundle exec thin -p 3000\n```\n\nThe command can also be a list, in a manner similar to [Dockerfile](../../engine/reference/builder/index#cmd):\n\n``` \ncommand: [ \"bundle\", \"exec\", \"thin\", \"-p\", \"3000\" ]\n```\n\n### configs\n\n`configs` grant access to configs on a per-service basis using the per-service `configs` configuration. Two different syntax variants are supported.\n\nCompose implementations MUST report an error if config doesn’t exist on platform or isn’t defined in the [`configs`](#configs-top-level-element) section of this Compose file.\n\nThere are two syntaxes defined for configs. To remain compliant to this specification, an implementation MUST support both syntaxes. Implementations MUST allow use of both short and long syntaxes within the same document.\n\n#### Short syntax\n\nThe short syntax variant only specifies the config name. This grants the container access to the config and mounts it at `/<config_name>` within the container. The source name and destination mount point are both set to the config name.\n\nThe following example uses the short syntax to grant the `redis` service access to the `my_config` and `my_other_config` configs. The value of `my_config` is set to the contents of the file `./my_config.txt`, and `my_other_config` is defined as an external resource, which means that it has already been defined in the platform. If the external config does not exist, the deployment MUST fail.\n\n``` \nservices:\n  redis:\n    image: redis:latest\n    configs:\n      - my_config\nconfigs:\n  my_config:\n    file: ./my_config.txt\n  my_other_config:\n    external: true\n```\n\n#### Long syntax\n\nThe long syntax provides more granularity in how the config is created within the service’s task containers.\n\n- `source`: The name of the config as it exists in the platform.\n- `target`: The path and name of the file to be mounted in the service’s task containers. Defaults to `/<source>` if not specified.\n- `uid` and `gid`: The numeric UID or GID that owns the mounted config file within the service’s task containers. Default value when not specified is USER running container.\n- `mode`: The [permissions](http://permissions-calculator.org/) for the file that is mounted within the service’s task containers, in octal notation. Default value is world-readable (`0444`). Writable bit MUST be ignored. The executable bit can be set.\n\nThe following example sets the name of `my_config` to `redis_config` within the container, sets the mode to `0440` (group-readable) and sets the user and group to `103`. The `redis` service does not have access to the `my_other_config` config.\n\n``` \nservices:\n  redis:\n    image: redis:latest\n    configs:\n      - source: my_config\n        target: /redis_config\n        uid: \"103\"\n        gid: \"103\"\n        mode: 0440\nconfigs:\n  my_config:\n    external: true\n  my_other_config:\n    external: true\n```\n\nYou can grant a service access to multiple configs, and you can mix long and short syntax.\n\n### container_name\n\n`container_name` is a string that specifies a custom container name, rather than a generated default name.\n\n``` \ncontainer_name: my-web-container\n```\n\nCompose implementation MUST NOT scale a service beyond one container if the Compose file specifies a `container_name`. Attempting to do so MUST result in an error.\n\nIf present, `container_name` SHOULD follow the regex format of `[a-zA-Z0-9][a-zA-Z0-9_.-]+`\n\n### credential_spec\n\n`credential_spec` configures the credential spec for a managed service account.\n\nCompose implementations that support services using Windows containers MUST support `file:` and `registry:` protocols for credential_spec. Compose implementations MAY also support additional protocols for custom use-cases.\n\nThe `credential_spec` must be in the format `file://<filename>` or `registry://<value-name>`.\n\n``` \ncredential_spec:\n  file: my-credential-spec.json\n```\n\nWhen using `registry:`, the credential spec is read from the Windows registry on the daemon’s host. A registry value with the given name must be located in:\n\n``` \nHKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Virtualization\\Containers\\CredentialSpecs\n```\n\nThe following example loads the credential spec from a value named `my-credential-spec` in the registry:\n\n``` \ncredential_spec:\n  registry: my-credential-spec\n```\n\n#### Example gMSA configuration\n\nWhen configuring a gMSA credential spec for a service, you only need to specify a credential spec with `config`, as shown in the following example:\n\n``` \nservices:\n  myservice:\n    image: myimage:latest\n    credential_spec:\n      config: my_credential_spec\n\nconfigs:\n  my_credentials_spec:\n    file: ./my-credential-spec.json|\n```\n\n### depends_on\n\n`depends_on` expresses startup and shutdown dependencies between services.\n\n#### Short syntax\n\nThe short syntax variant only specifies service names of the dependencies. Service dependencies cause the following behaviors:\n\n- Compose implementations MUST create services in dependency order. In the following example, `db` and `redis` are created before `web`.\n\n- Compose implementations MUST remove services in dependency order. In the following example, `web` is removed before `db` and `redis`.\n\nSimple example:\n\n``` \nservices:\n  web:\n    build: .\n    depends_on:\n      - db\n      - redis\n  redis:\n    image: redis\n  db:\n    image: postgres\n```\n\nCompose implementations MUST guarantee dependency services have been started before starting a dependent service. Compose implementations MAY wait for dependency services to be “ready” before starting a dependent service.\n\n#### Long syntax\n\nThe long form syntax enables the configuration of additional fields that can’t be expressed in the short form.\n\n- `condition`: condition under which dependency is considered satisfied\n  - `service_started`: is an equivalent of the short syntax described above\n  - `service_healthy`: specifies that a dependency is expected to be “healthy” (as indicated by [healthcheck](#healthcheck)) before starting a dependent service.\n  - `service_completed_successfully`: specifies that a dependency is expected to run to successful completion before starting a dependent service.\n\nService dependencies cause the following behaviors:\n\n- Compose implementations MUST create services in dependency order. In the following example, `db` and `redis` are created before `web`.\n\n- Compose implementations MUST wait for healthchecks to pass on dependencies marked with `service_healthy`. In the following example, `db` is expected to be “healthy” before `web` is created.\n\n- Compose implementations MUST remove services in dependency order. In the following example, `web` is removed before `db` and `redis`.\n\nSimple example:\n\n``` \nservices:\n  web:\n    build: .\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_started\n  redis:\n    image: redis\n  db:\n    image: postgres\n```\n\nCompose implementations MUST guarantee dependency services have been started before starting a dependent service. Compose implementations MUST guarantee dependency services marked with `service_healthy` are “healthy” before starting a dependent service.\n\n### deploy\n\n`deploy` specifies the configuration for the deployment and lifecycle of services, as defined [here](deploy/index).\n\n### device_cgroup_rules\n\n`device_cgroup_rules` defines a list of device cgroup rules for this container. The format is the same format the Linux kernel specifies in the [Control Groups Device Whitelist Controller](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/devices.html).\n\n``` \ndevice_cgroup_rules:\n  - 'c 1:3 mr'\n  - 'a 7:* rmw'\n```\n\n### devices\n\n`devices` defines a list of device mappings for created containers in the form of `HOST_PATH:CONTAINER_PATH[:CGROUP_PERMISSIONS]`.\n\n``` \ndevices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n  - \"/dev/sda:/dev/xvda:rwm\"\n```\n\n### dns\n\n`dns` defines custom DNS servers to set on the container network interface configuration. Can be a single value or a list.\n\n``` \ndns: 8.8.8.8\n```\n\n``` \ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n```\n\n### dns_opt\n\n`dns_opt` list custom DNS options to be passed to the container’s DNS resolver (`/etc/resolv.conf` file on Linux).\n\n``` \ndns_opt:\n  - use-vc\n  - no-tld-query\n```\n\n### dns_search\n\n`dns` defines custom DNS search domains to set on container network interface configuration. Can be a single value or a list.\n\n``` \ndns_search: example.com\n```\n\n``` \ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n```\n\n### domainname\n\n`domainname` declares a custom domain name to use for the service container. MUST be a valid RFC 1123 hostname.\n\n### entrypoint\n\n`entrypoint` overrides the default entrypoint for the Docker image (i.e. `ENTRYPOINT` set by Dockerfile). Compose implementations MUST clear out any default command on the Docker image - both `ENTRYPOINT` and `CMD` instruction in the Dockerfile - when `entrypoint` is configured by a Compose file. If [`command`](#command) is also set, it is used as parameter to `entrypoint` as a replacement for Docker image’s `CMD`\n\n``` \nentrypoint: /code/entrypoint.sh\n```\n\nThe entrypoint can also be a list, in a manner similar to [Dockerfile](../../engine/reference/builder/index#cmd):\n\n``` \nentrypoint:\n  - php\n  - -d\n  - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so\n  - -d\n  - memory_limit=-1\n  - vendor/bin/phpunit\n```\n\n### env_file\n\n`env_file` adds environment variables to the container based on file content.\n\n``` \nenv_file: .env\n```\n\n`env_file` can also be a list. The files in the list MUST be processed from the top down. For the same variable specified in two env files, the value from the last file in the list MUST stand.\n\n``` \nenv_file:\n  - ./a.env\n  - ./b.env\n```\n\nRelative path MUST be resolved from the Compose file’s parent folder. As absolute paths prevent the Compose file from being portable, Compose implementations SHOULD warn users when such a path is used to set `env_file`.\n\nEnvironment variables declared in the [environment](#environment) section MUST override these values – this holds true even if those values are empty or undefined.\n\n#### Env_file format\n\nEach line in an env file MUST be in `VAR[=[VAL]]` format. Lines beginning with `#` MUST be ignored. Blank lines MUST also be ignored.\n\nThe value of `VAL` is used as a raw string and not modified at all. If the value is surrounded by quotes (as is often the case for shell variables), the quotes MUST be **included** in the value passed to containers created by the Compose implementation.\n\n`VAL` MAY be omitted, in such cases the variable value is empty string. `=VAL` MAY be omitted, in such cases the variable is **unset**.\n\n``` \n# Set Rails/Rack environment\nRACK_ENV=development\nVAR=\"quoted\"\n```\n\n### environment\n\n`environment` defines environment variables set in the container. `environment` can use either an array or a map. Any boolean values; true, false, yes, no, SHOULD be enclosed in quotes to ensure they are not converted to True or False by the YAML parser.\n\nEnvironment variables MAY be declared by a single key (no value to equals sign). In such a case Compose implementations SHOULD rely on some user interaction to resolve the value. If they do not, the variable is unset and will be removed from the service container environment.\n\nMap syntax:\n\n``` \nenvironment:\n  RACK_ENV: development\n  SHOW: \"true\"\n  USER_INPUT:\n```\n\nArray syntax:\n\n``` \nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - USER_INPUT\n```\n\nWhen both `env_file` and `environment` are set for a service, values set by `environment` have precedence.\n\n### expose\n\n`expose` defines the ports that Compose implementations MUST expose from container. These ports MUST be accessible to linked services and SHOULD NOT be published to the host machine. Only the internal container ports can be specified.\n\n``` \nexpose:\n  - \"3000\"\n  - \"8000\"\n```\n\n### extends\n\nExtend another service, in the current file or another, optionally overriding configuration. You can use `extends` on any service together with other configuration keys. The `extends` value MUST be a mapping defined with a required `service` and an optional `file` key.\n\n``` \nextends:\n  file: common.yml\n  service: webapp\n```\n\nIf supported Compose implementations MUST process `extends` in the following way:\n\n- `service` defines the name of the service being referenced as a base, for example `web` or `database`.\n- `file` is the location of a Compose configuration file defining that service.\n\n#### Restrictions\n\nThe following restrictions apply to the service being referenced:\n\n- Services that have dependencies on other services cannot be used as a base. Therefore, any key that introduces a dependency on another service is incompatible with `extends`. The non-exhaustive list of such keys is: `links`, `volumes_from`, `container` mode (in `ipc`, `pid`, `network_mode` and `net`), `service` mode (in `ipc`, `pid` and `network_mode`), `depends_on`.\n- Services cannot have circular references with `extends`\n\nCompose implementations MUST return an error in all of these cases.\n\n#### Finding referenced service\n\n`file` value can be:\n\n- Not present. This indicates that another service within the same Compose file is being referenced.\n- File path, which can be either:\n  - Relative path. This path is considered as relative to the location of the main Compose file.\n  - Absolute path.\n\nService denoted by `service` MUST be present in the identified referenced Compose file. Compose implementations MUST return an error if:\n\n- Service denoted by `service` was not found\n- Compose file denoted by `file` was not found\n\n#### Merging service definitions\n\nTwo service definitions (*main* one in the current Compose file and *referenced* one specified by `extends`) MUST be merged in the following way:\n\n- Mappings: keys in mappings of *main* service definition override keys in mappings of *referenced* service definition. Keys that aren’t overridden are included as is.\n- Sequences: items are combined together into an new sequence. Order of elements is preserved with the *referenced* items coming first and *main* items after.\n- Scalars: keys in *main* service definition take precedence over keys in the *referenced* one.\n\n##### Mappings\n\nThe following keys should be treated as mappings: `build.args`, `build.labels`, `build.extra_hosts`, `deploy.labels`, `deploy.update_config`, `deploy.rollback_config`, `deploy.restart_policy`, `deploy.resources.limits`, `environment`, `healthcheck`, `labels`, `logging.options`, `sysctls`, `storage_opt`, `extra_hosts`, `ulimits`.\n\nOne exception that applies to `healthcheck` is that *main* mapping cannot specify `disable: true` unless *referenced* mapping also specifies `disable: true`. Compose implementations MUST return an error in this case.\n\nFor example, the input below:\n\n``` \nservices:\n  common:\n    image: busybox\n    environment:\n      TZ: utc\n      PORT: 80\n  cli:\n    extends:\n      service: common\n    environment:\n      PORT: 8080\n```\n\nProduces the following configuration for the `cli` service. The same output is produced if array syntax is used.\n\n``` \nenvironment:\n  PORT: 8080\n  TZ: utc\nimage: busybox\n```\n\nItems under `blkio_config.device_read_bps`, `blkio_config.device_read_iops`, `blkio_config.device_write_bps`, `blkio_config.device_write_iops`, `devices` and `volumes` are also treated as mappings where key is the target path inside the container.\n\nFor example, the input below:\n\n``` \nservices:\n  common:\n    image: busybox\n    volumes:\n      - common-volume:/var/lib/backup/data:rw\n  cli:\n    extends:\n      service: common\n    volumes:\n      - cli-volume:/var/lib/backup/data:ro\n```\n\nProduces the following configuration for the `cli` service. Note that mounted path now points to the new volume name and `ro` flag was applied.\n\n``` \nimage: busybox\nvolumes:\n- cli-volume:/var/lib/backup/data:ro\n```\n\nIf *referenced* service definition contains `extends` mapping, the items under it are simply copied into the new *merged* definition. Merging process is then kicked off again until no `extends` keys are remaining.\n\nFor example, the input below:\n\n``` \nservices:\n  base:\n    image: busybox\n    user: root\n  common:\n    image: busybox\n    extends:\n      service: base\n  cli:\n    extends:\n      service: common\n```\n\nProduces the following configuration for the `cli` service. Here, `cli` services gets `user` key from `common` service, which in turn gets this key from `base` service.\n\n``` \nimage: busybox\nuser: root\n```\n\n##### Sequences\n\nThe following keys should be treated as sequences: `cap_add`, `cap_drop`, `configs`, `deploy.placement.constraints`, `deploy.placement.preferences`, `deploy.reservations.generic_resources`, `device_cgroup_rules`, `expose`, `external_links`, `ports`, `secrets`, `security_opt`. Any duplicates resulting from the merge are removed so that the sequence only contains unique elements.\n\nFor example, the input below:\n\n``` \nservices:\n  common:\n    image: busybox\n    security_opt:\n      - label:role:ROLE\n  cli:\n    extends:\n      service: common\n    security_opt:\n      - label:user:USER\n```\n\nProduces the following configuration for the `cli` service.\n\n``` \nimage: busybox\nsecurity_opt:\n- label:role:ROLE\n- label:user:USER\n```\n\nIn case list syntax is used, the following keys should also be treated as sequences: `dns`, `dns_search`, `env_file`, `tmpfs`. Unlike sequence fields mentioned above, duplicates resulting from the merge are not removed.\n\n##### Scalars\n\nAny other allowed keys in the service definition should be treated as scalars.\n\n### external_links\n\n`external_links` link service containers to services managed outside this Compose application. `external_links` define the name of an existing service to retrieve using the platform lookup mechanism. An alias of the form `SERVICE:ALIAS` can be specified.\n\n``` \nexternal_links:\n  - redis\n  - database:mysql\n  - database:postgresql\n```\n\n### extra_hosts\n\n`extra_hosts` adds hostname mappings to the container network interface configuration (`/etc/hosts` for Linux). Values MUST set hostname and IP address for additional hosts in the form of `HOSTNAME:IP`.\n\n``` \nextra_hosts:\n  - \"somehost:162.242.195.82\"\n  - \"otherhost:50.31.209.229\"\n```\n\nCompose implementations MUST create matching entry with the IP address and hostname in the container’s network configuration, which means for Linux `/etc/hosts` will get extra lines:\n\n``` \n162.242.195.82  somehost\n50.31.209.229   otherhost\n```\n\n### group_add\n\n`group_add` specifies additional groups (by name or number) which the user inside the container MUST be a member of.\n\nAn example of where this is useful is when multiple containers (running as different users) need to all read or write the same file on a shared volume. That file can be owned by a group shared by all the containers, and specified in `group_add`.\n\n``` \nservices:\n  myservice:\n    image: alpine\n    group_add:\n      - mail\n```\n\nRunning `id` inside the created container MUST show that the user belongs to the `mail` group, which would not have been the case if `group_add` were not declared.\n\n### healthcheck\n\n`healthcheck` declares a check that’s run to determine whether or not containers for this service are “healthy”. This overrides [HEALTHCHECK Dockerfile instruction](../../engine/reference/builder/index#healthcheck) set by the service’s Docker image.\n\n``` \nhealthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n  interval: 1m30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n```\n\n`interval`, `timeout` and `start_period` are [specified as durations](#specifying-durations).\n\n`test` defines the command the Compose implementation will run to check container health. It can be either a string or a list. If it’s a list, the first item must be either `NONE`, `CMD` or `CMD-SHELL`. If it’s a string, it’s equivalent to specifying `CMD-SHELL` followed by that string.\n\n``` \n# Hit the local web app\ntest: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n```\n\nUsing `CMD-SHELL` will run the command configured as a string using the container’s default shell (`/bin/sh` for Linux). Both forms below are equivalent:\n\n``` \ntest: [\"CMD-SHELL\", \"curl -f http://localhost || exit 1\"]\n```\n\n``` \ntest: curl -f https://localhost || exit 1\n```\n\n`NONE` disable the healthcheck, and is mostly useful to disable Healthcheck set by image. Alternatively the healthcheck set by the image can be disabled by setting `disable: true`:\n\n``` \nhealthcheck:\n  disable: true\n```\n\n### hostname\n\n`hostname` declares a custom host name to use for the service container. MUST be a valid RFC 1123 hostname.\n\n### image\n\n`image` specifies the image to start the container from. Image MUST follow the Open Container Specification [addressable image format](https://github.com/opencontainers/org/blob/master/docs/docs/introduction/digests/), as `[<registry>/][<project>/]<image>[:<tag>|@<digest>]`.\n\n``` \n    image: redis\n    image: redis:5\n    image: redis@sha256:0ed5d5928d4737458944eb604cc8509e245c3e19d02ad83935398bc4b991aac7\n    image: library/redis\n    image: docker.io/library/redis\n    image: my_private.registry:5000/redis\n```\n\nIf the image does not exist on the platform, Compose implementations MUST attempt to pull it based on the `pull_policy`. Compose implementations with build support MAY offer alternative options for the end user to control precedence of pull over building the image from source, however pulling the image MUST be the default behavior.\n\n`image` MAY be omitted from a Compose file as long as a `build` section is declared. Compose implementations without build support MUST fail when `image` is missing from the Compose file.\n\n### init\n\n`init` run an init process (PID 1) inside the container that forwards signals and reaps processes. Set this option to `true` to enable this feature for the service.\n\n``` \nservices:\n  web:\n    image: alpine:latest\n    init: true\n```\n\nThe init binary that is used is platform specific.\n\n### ipc\n\n`ipc` configures the IPC isolation mode set by service container. Available values are platform specific, but Compose specification defines specific values which MUST be implemented as described if supported:\n\n- `shareable` which gives the container own private IPC namespace, with a possibility to share it with other containers.\n- `service:{name}` which makes the container join another (`shareable`) container’s IPC namespace.\n\n``` \n    ipc: \"shareable\"\n    ipc: \"service:[service name]\"\n```\n\n### isolation\n\n`isolation` specifies a container’s isolation technology. Supported values are platform-specific.\n\n### labels\n\n`labels` add metadata to containers. You can use either an array or a map.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n```\n\nCompose implementations MUST create containers with canonical labels:\n\n- `com.docker.compose.project` set on all resources created by Compose implementation to the user project name\n- `com.docker.compose.service` set on service containers with service name as defined in the Compose file\n\nThe `com.docker.compose` label prefix is reserved. Specifying labels with this prefix in the Compose file MUST result in a runtime error.\n\n### links\n\n`links` defines a network link to containers in another service. Either specify both the service name and a link alias (`SERVICE:ALIAS`), or just the service name.\n\n``` \nweb:\n  links:\n    - db\n    - db:database\n    - redis\n```\n\nContainers for the linked service MUST be reachable at a hostname identical to the alias, or the service name if no alias was specified.\n\nLinks are not required to enable services to communicate - when no specific network configuration is set, any service MUST be able to reach any other service at that service’s name on the `default` network. If services do declare networks they are attached to, `links` SHOULD NOT override the network configuration and services not attached to a shared network SHOULD NOT be able to communicate. Compose implementations MAY NOT warn the user about this configuration mismatch.\n\nLinks also express implicit dependency between services in the same way as [depends_on](#depends_on), so they determine the order of service startup.\n\n### logging\n\n`logging` defines the logging configuration for the service.\n\n``` \nlogging:\n  driver: syslog\n  options:\n    syslog-address: \"tcp://192.168.0.42:123\"\n```\n\nThe `driver` name specifies a logging driver for the service’s containers. The default and available values are platform specific. Driver specific options can be set with `options` as key-value pairs.\n\n### network_mode\n\n`network_mode` set service containers network mode. Available values are platform specific, but Compose specification define specific values which MUST be implemented as described if supported:\n\n- `none` which disable all container networking\n- `host` which gives the container raw access to host’s network interface\n- `service:{name}` which gives the containers access to the specified service only\n\n``` \n    network_mode: \"host\"\n    network_mode: \"none\"\n    network_mode: \"service:[service name]\"\n```\n\n### networks\n\n`networks` defines the networks that service containers are attached to, referencing entries under the [top-level `networks` key](#networks-top-level-element).\n\n``` \nservices:\n  some-service:\n    networks:\n      - some-network\n      - other-network\n```\n\n#### aliases\n\n`aliases` declares alternative hostnames for this service on the network. Other containers on the same network can use either the service name or this alias to connect to one of the service’s containers.\n\nSince `aliases` are network-scoped, the same service can have different aliases on different networks.\n\n> **Note**: A network-wide alias can be shared by multiple containers, and even by multiple services. If it is, then exactly which container the name resolves to is not guaranteed.\n\nThe general format is shown here:\n\n``` \nservices:\n  some-service:\n    networks:\n      some-network:\n        aliases:\n          - alias1\n          - alias3\n      other-network:\n        aliases:\n          - alias2\n```\n\nIn the example below, service `frontend` will be able to reach the `backend` service at the hostname `backend` or `database` on the `back-tier` network, and service `monitoring` will be able to reach same `backend` service at `db` or `mysql` on the `admin` network.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    networks:\n      - front-tier\n      - back-tier\n\n  monitoring:\n    image: awesome/monitoring\n    networks:\n      - admin\n\n  backend:\n    image: awesome/backend\n    networks:\n      back-tier:\n        aliases:\n          - database\n      admin:\n        aliases:\n          - mysql\n\nnetworks:\n  front-tier:\n  back-tier:\n  admin:\n```\n\n#### ipv4_address, ipv6_address\n\nSpecify a static IP address for containers for this service when joining the network.\n\nThe corresponding network configuration in the [top-level networks section](#networks) MUST have an `ipam` block with subnet configurations covering each static address.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    networks:\n      front-tier:\n        ipv4_address: 172.16.238.10\n        ipv6_address: 2001:3984:3989::10\n\nnetworks:\n  front-tier:\n    ipam:\n      driver: default\n      config:\n        - subnet: \"172.16.238.0/24\"\n        - subnet: \"2001:3984:3989::/64\"\n```\n\n#### link_local_ips\n\n`link_local_ips` specifies a list of link-local IPs. Link-local IPs are special IPs which belong to a well known subnet and are purely managed by the operator, usually dependent on the architecture where they are deployed. Implementation is Platform specific.\n\nExample:\n\n``` \nservices:\n  app:\n    image: busybox\n    command: top\n    networks:\n      app_net:\n        link_local_ips:\n          - 57.123.22.11\n          - 57.123.22.13\nnetworks:\n  app_net:\n    driver: bridge\n```\n\n#### priority\n\n`priority` indicates in which order Compose implementation SHOULD connect the service’s containers to its networks. If unspecified, the default value is 0.\n\nIn the following example, the app service connects to app_net_1 first as it has the highest priority. It then connects to app_net_3, then app_net_2, which uses the default priority value of 0.\n\n``` \nservices:\n  app:\n    image: busybox\n    command: top\n    networks:\n      app_net_1:\n        priority: 1000\n      app_net_2:\n\n      app_net_3:\n        priority: 100\nnetworks:\n  app_net_1:\n  app_net_2:\n  app_net_3:\n```\n\n### mac_address\n\n`mac_address` sets a MAC address for service container.\n\n### mem_limit\n\n*DEPRECATED: use [deploy.limits.memory](deploy/index#memory)*\n\n### mem_reservation\n\n*DEPRECATED: use [deploy.reservations.memory](deploy/index#memory)*\n\n### mem_swappiness\n\n`mem_swappiness` defines as a percentage (a value between 0 and 100) for the host kernel to swap out anonymous memory pages used by a container.\n\n- a value of 0 turns off anonymous page swapping.\n- a value of 100 sets all anonymous pages as swappable.\n\nDefault value is platform specific.\n\n### memswap_limit\n\n`memswap_limit` defines the amount of memory container is allowed to swap to disk. This is a modifier attribute that only has meaning if `memory` is also set. Using swap allows the container to write excess memory requirements to disk when the container has exhausted all the memory that is available to it. There is a performance penalty for applications that swap memory to disk often.\n\n- If `memswap_limit` is set to a positive integer, then both `memory` and `memswap_limit` MUST be set. `memswap_limit` represents the total amount of memory and swap that can be used, and `memory` controls the amount used by non-swap memory. So if `memory`=”300m” and `memswap_limit`=”1g”, the container can use 300m of memory and 700m (1g - 300m) swap.\n- If `memswap_limit` is set to 0, the setting MUST be ignored, and the value is treated as unset.\n- If `memswap_limit` is set to the same value as `memory`, and `memory` is set to a positive integer, the container does not have access to swap. See Prevent a container from using swap.\n- If `memswap_limit` is unset, and `memory` is set, the container can use as much swap as the `memory` setting, if the host container has swap memory configured. For instance, if `memory`=”300m” and `memswap_limit` is not set, the container can use 600m in total of memory and swap.\n- If `memswap_limit` is explicitly set to -1, the container is allowed to use unlimited swap, up to the amount available on the host system.\n\n### oom_kill_disable\n\nIf `oom_kill_disable` is set Compose implementation MUST configure the platform so it won’t kill the container in case of memory starvation.\n\n### oom_score_adj\n\n`oom_score_adj` tunes the preference for containers to be killed by platform in case of memory starvation. Value MUST be within \\[-1000,1000\\] range.\n\n### pid\n\n`pid` sets the PID mode for container created by the Compose implementation. Supported values are platform specific.\n\n### pids_limit\n\n*DEPRECATED: use [deploy.reservations.pids](deploy/index#pids)*\n\n`pids_limit` tunes a container’s PIDs limit. Set to -1 for unlimited PIDs.\n\n``` \npids_limit: 10\n```\n\n### platform\n\n`platform` defines the target platform containers for this service will run on, using the `os[/arch[/variant]]` syntax. Compose implementation MUST use this attribute when declared to determine which version of the image will be pulled and/or on which platform the service’s build will be performed.\n\n``` \nplatform: osx\nplatform: windows/amd64\nplatform: linux/arm64/v8\n```\n\n### ports\n\nExposes container ports. Port mapping MUST NOT be used with `network_mode: host` and doing so MUST result in a runtime error.\n\n#### Short syntax\n\nThe short syntax is a colon-separated string to set host IP, host port and container port in the form:\n\n`[HOST:]CONTAINER[/PROTOCOL]` where:\n\n- `HOST` is `[IP:](port | range)`\n- `CONTAINER` is `port | range`\n- `PROTOCOL` to restrict port to specified protocol. `tcp` and `udp` values are defined by the specification, Compose implementations MAY offer support for platform-specific protocol names.\n\nHost IP, if not set, MUST bind to all network interfaces. Port can be either a single value or a range. Host and container MUST use equivalent ranges.\n\nEither specify both ports (`HOST:CONTAINER`), or just the container port. In the latter case, the Compose implementation SHOULD automatically allocate any unassigned host port.\n\n`HOST:CONTAINER` SHOULD always be specified as a (quoted) string, to avoid conflicts with [yaml base-60 float](https://yaml.org/type/float.html).\n\nSamples:\n\n``` \nports:\n  - \"3000\"\n  - \"3000-3005\"\n  - \"8000:8000\"\n  - \"9090-9091:8080-8081\"\n  - \"49100:22\"\n  - \"127.0.0.1:8001:8001\"\n  - \"127.0.0.1:5000-5010:5000-5010\"\n  - \"6060:6060/udp\"\n```\n\n> **Note**: Host IP mapping MAY not be supported on the platform, in such case Compose implementations SHOULD reject the Compose file and MUST inform the user they will ignore the specified host IP.\n\n#### Long syntax\n\nThe long form syntax allows the configuration of additional fields that can’t be expressed in the short form.\n\n- `target`: the container port\n- `published`: the publicly exposed port. Can be set as a range using syntax `start-end`, then actual port SHOULD be assigned within this range based on available ports.\n- `host_ip`: the Host IP mapping, unspecified means all network interfaces (`0.0.0.0`)\n- `protocol`: the port protocol (`tcp` or `udp`), unspecified means any protocol\n- `mode`: `host` for publishing a host port on each node, or `ingress` for a port to be load balanced.\n\n``` \nports:\n  - target: 80\n    host_ip: 127.0.0.1\n    published: 8080\n    protocol: tcp\n    mode: host\n\n  - target: 80\n    host_ip: 127.0.0.1\n    published: 8000-9000\n    protocol: tcp\n    mode: host\n```\n\n### privileged\n\n`privileged` configures the service container to run with elevated privileges. Support and actual impacts are platform-specific.\n\n### profiles\n\n`profiles` defines a list of named profiles for the service to be enabled under. When not set, service is always enabled.\n\nIf present, `profiles` SHOULD follow the regex format of `[a-zA-Z0-9][a-zA-Z0-9_.-]+`.\n\n### pull_policy\n\n`pull_policy` defines the decisions Compose implementations will make when it starts to pull images. Possible values are:\n\n- `always`: Compose implementations SHOULD always pull the image from the registry.\n- `never`: Compose implementations SHOULD NOT pull the image from a registry and SHOULD rely on the platform cached image. If there is no cached image, a failure MUST be reported.\n- `missing`: Compose implementations SHOULD pull the image only if it’s not available in the platform cache. This SHOULD be the default option for Compose implementations without build support. `if_not_present` SHOULD be considered an alias for this value for backward compatibility\n- `build`: Compose implementations SHOULD build the image. Compose implementations SHOULD rebuild the image if already present.\n\nIf `pull_policy` and `build` both presents, Compose implementations SHOULD build the image by default. Compose implementations MAY override this behavior in the toolchain.\n\n### read_only\n\n`read_only` configures service container to be created with a read-only filesystem.\n\n### restart\n\n`restart` defines the policy that the platform will apply on container termination.\n\n- `no`: The default restart policy. Does not restart a container under any circumstances.\n- `always`: The policy always restarts the container until its removal.\n- `on-failure`: The policy restarts a container if the exit code indicates an error.\n- `unless-stopped`: The policy restarts a container irrespective of the exit code but will stop restarting when the service is stopped or removed.\n\n``` \n    restart: \"no\"\n    restart: always\n    restart: on-failure\n    restart: unless-stopped\n```\n\n### runtime\n\n`runtime` specifies which runtime to use for the service’s containers.\n\nThe value of `runtime` is specific to implementation. For example, `runtime` can be the name of [an implementation of OCI Runtime Spec](https://github.com/opencontainers/runtime-spec/blob/master/implementations/), such as “runc”.\n\n``` \nweb:\n  image: busybox:latest\n  command: true\n  runtime: runc\n```\n\n### scale\n\n*DEPRECATED: use [deploy/replicas](deploy/index#replicas)*\n\n`scale` specifies the default number of containers to deploy for this service.\n\n### secrets\n\n`secrets` grants access to sensitive data defined by [secrets](#secrets) on a per-service basis. Two different syntax variants are supported: the short syntax and the long syntax.\n\nCompose implementations MUST report an error if the secret doesn’t exist on the platform or isn’t defined in the [`secrets`](#secrets-top-level-element) section of this Compose file.\n\n#### Short syntax\n\nThe short syntax variant only specifies the secret name. This grants the container access to the secret and mounts it as read-only to `/run/secrets/<secret_name>` within the container. The source name and destination mountpoint are both set to the secret name.\n\nThe following example uses the short syntax to grant the `frontend` service access to the `server-certificate` secret. The value of `server-certificate` is set to the contents of the file `./server.cert`.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    secrets:\n      - server-certificate\nsecrets:\n  server-certificate:\n    file: ./server.cert\n```\n\n#### Long syntax\n\nThe long syntax provides more granularity in how the secret is created within the service’s containers.\n\n- `source`: The name of the secret as it exists on the platform.\n- `target`: The name of the file to be mounted in `/run/secrets/` in the service’s task containers. Defaults to `source` if not specified.\n- `uid` and `gid`: The numeric UID or GID that owns the file within `/run/secrets/` in the service’s task containers. Default value is USER running container.\n- `mode`: The [permissions](http://permissions-calculator.org/) for the file to be mounted in `/run/secrets/` in the service’s task containers, in octal notation. Default value is world-readable permissions (mode `0444`). The writable bit MUST be ignored if set. The executable bit MAY be set.\n\nThe following example sets the name of the `server-certificate` secret file to `server.crt` within the container, sets the mode to `0440` (group-readable) and sets the user and group to `103`. The value of `server-certificate` secret is provided by the platform through a lookup and the secret lifecycle not directly managed by the Compose implementation.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    secrets:\n      - source: server-certificate\n        target: server.cert\n        uid: \"103\"\n        gid: \"103\"\n        mode: 0440\nsecrets:\n  server-certificate:\n    external: true\n```\n\nServices MAY be granted access to multiple secrets. Long and short syntax for secrets MAY be used in the same Compose file. Defining a secret in the top-level `secrets` MUST NOT imply granting any service access to it. Such grant must be explicit within service specification as [secrets](#secrets) service element.\n\n### security_opt\n\n`security_opt` overrides the default labeling scheme for each container.\n\n``` \nsecurity_opt:\n  - label:user:USER\n  - label:role:ROLE\n```\n\n### shm_size\n\n`shm_size` configures the size of the shared memory (`/dev/shm` partition on Linux) allowed by the service container. Specified as a [byte value](#specifying-byte-values).\n\n### stdin_open\n\n`stdin_open` configures service containers to run with an allocated stdin.\n\n### stop_grace_period\n\n`stop_grace_period` specifies how long the Compose implementation MUST wait when attempting to stop a container if it doesn’t handle SIGTERM (or whichever stop signal has been specified with [`stop_signal`](#stop_signal)), before sending SIGKILL. Specified as a [duration](#specifying-durations).\n\n``` \n    stop_grace_period: 1s\n    stop_grace_period: 1m30s\n```\n\nDefault value is 10 seconds for the container to exit before sending SIGKILL.\n\n### stop_signal\n\n`stop_signal` defines the signal that the Compose implementation MUST use to stop the service containers. If unset containers are stopped by the Compose Implementation by sending `SIGTERM`.\n\n``` \nstop_signal: SIGUSR1\n```\n\n### storage_opt\n\n`storage_opt` defines storage driver options for a service.\n\n``` \nstorage_opt:\n  size: '1G'\n```\n\n### sysctls\n\n`sysctls` defines kernel parameters to set in the container. `sysctls` can use either an array or a map.\n\n``` \nsysctls:\n  net.core.somaxconn: 1024\n  net.ipv4.tcp_syncookies: 0\n```\n\n``` \nsysctls:\n  - net.core.somaxconn=1024\n  - net.ipv4.tcp_syncookies=0\n```\n\nYou can only use sysctls that are namespaced in the kernel. Docker does not support changing sysctls inside a container that also modify the host system. For an overview of supported sysctls, refer to [configure namespaced kernel parameters (sysctls) at runtime](../../engine/reference/commandline/run/index#configure-namespaced-kernel-parameters-sysctls-at-runtime).\n\n### tmpfs\n\n`tmpfs` mounts a temporary file system inside the container. Can be a single value or a list.\n\n``` \ntmpfs: /run\n```\n\n``` \ntmpfs:\n  - /run\n  - /tmp\n```\n\n### tty\n\n`tty` configure service container to run with a TTY.\n\n### ulimits\n\n`ulimits` overrides the default ulimits for a container. Either specifies as a single limit as an integer or soft/hard limits as a mapping.\n\n``` \nulimits:\n  nproc: 65535\n  nofile:\n    soft: 20000\n    hard: 40000\n```\n\n### user\n\n`user` overrides the user used to run the container process. Default is that set by image (i.e. Dockerfile `USER`), if not set, `root`.\n\n### userns_mode\n\n`userns_mode` sets the user namespace for the service. Supported values are platform specific and MAY depend on platform configuration\n\n``` \nuserns_mode: \"host\"\n```\n\n### volumes\n\n`volumes` defines mount host paths or named volumes that MUST be accessible by service containers.\n\nIf the mount is a host path and only used by a single service, it MAY be declared as part of the service definition instead of the top-level `volumes` key.\n\nTo reuse a volume across multiple services, a named volume MUST be declared in the [top-level `volumes` key](#volumes-top-level-element).\n\nThis example shows a named volume (`db-data`) being used by the `backend` service, and a bind mount defined for a single service\n\n``` \nservices:\n  backend:\n    image: awesome/backend\n    volumes:\n      - type: volume\n        source: db-data\n        target: /data\n        volume:\n          nocopy: true\n      - type: bind\n        source: /var/run/postgres/postgres.sock\n        target: /var/run/postgres/postgres.sock\n\nvolumes:\n  db-data:\n```\n\n#### Short syntax\n\nThe short syntax uses a single string with colon-separated values to specify a volume mount (`VOLUME:CONTAINER_PATH`), or an access mode (`VOLUME:CONTAINER_PATH:ACCESS_MODE`).\n\n- `VOLUME`: MAY be either a host path on the platform hosting containers (bind mount) or a volume name\n- `CONTAINER_PATH`: the path in the container where the volume is mounted\n- `ACCESS_MODE`: is a comma-separated `,` list of options and MAY be set to:\n  - `rw`: read and write access (default)\n  - `ro`: read-only access\n  - `z`: SELinux option indicates that the bind mount host content is shared among multiple containers\n  - `Z`: SELinux option indicates that the bind mount host content is private and unshared for other containers\n\n> **Note**: The SELinux re-labeling bind mount option is ignored on platforms without SELinux.\n\n> **Note**: Relative host paths MUST only be supported by Compose implementations that deploy to a local container runtime. This is because the relative path is resolved from the Compose file’s parent directory which is only applicable in the local case. Compose Implementations deploying to a non-local platform MUST reject Compose files which use relative host paths with an error. To avoid ambiguities with named volumes, relative paths SHOULD always begin with `.` or `..`.\n\n#### Long syntax\n\nThe long form syntax allows the configuration of additional fields that can’t be expressed in the short form.\n\n- `type`: the mount type `volume`, `bind`, `tmpfs` or `npipe`\n- `source`: the source of the mount, a path on the host for a bind mount, or the name of a volume defined in the [top-level `volumes` key](#volumes-top-level-element). Not applicable for a tmpfs mount.\n- `target`: the path in the container where the volume is mounted\n- `read_only`: flag to set the volume as read-only\n- `bind`: configure additional bind options\n  - `propagation`: the propagation mode used for the bind\n  - `create_host_path`: create a directory at the source path on host if there is nothing present. Do nothing if there is something present at the path. This is automatically implied by short syntax for backward compatibility with docker-compose legacy.\n  - `selinux`: the SELinux re-labeling option `z` (shared) or `Z` (private)\n- `volume`: configure additional volume options\n  - `nocopy`: flag to disable copying of data from a container when a volume is created\n- `tmpfs`: configure additional tmpfs options\n  - `size`: the size for the tmpfs mount in bytes (either numeric or as bytes unit)\n- `consistency`: the consistency requirements of the mount. Available values are platform specific\n\n### volumes_from\n\n`volumes_from` mounts all of the volumes from another service or container, optionally specifying read-only access (ro) or read-write (rw). If no access level is specified, then read-write MUST be used.\n\nString value defines another service in the Compose application model to mount volumes from. The `container:` prefix, if supported, allows to mount volumes from a container that is not managed by the Compose implementation.\n\n``` \nvolumes_from:\n  - service_name\n  - service_name:ro\n  - container:container_name\n  - container:container_name:rw\n```\n\n### working_dir\n\n`working_dir` overrides the container’s working directory from that specified by image (i.e. Dockerfile `WORKDIR`).\n\n## Networks top-level element\n\nNetworks are the layer that allow services to communicate with each other. The networking model exposed to a service is limited to a simple IP connection with target services and external resources, while the Network definition allows fine-tuning the actual implementation provided by the platform.\n\nNetworks can be created by specifying the network name under a top-level `networks` section. Services can connect to networks by specifying the network name under the service [`networks`](#networks) subsection\n\nIn the following example, at runtime, networks `front-tier` and `back-tier` will be created and the `frontend` service connected to the `front-tier` network and the `back-tier` network.\n\n``` \nservices:\n  frontend:\n    image: awesome/webapp\n    networks:\n      - front-tier\n      - back-tier\n\nnetworks:\n  front-tier:\n  back-tier:\n```\n\n### driver\n\n`driver` specifies which driver should be used for this network. Compose implementations MUST return an error if the driver is not available on the platform.\n\n``` \ndriver: overlay\n```\n\nDefault and available values are platform specific. Compose specification MUST support the following specific drivers: `none` and `host`\n\n- `host` use the host’s networking stack\n- `none` disable networking\n\n#### host or none\n\nThe syntax for using built-in networks such as `host` and `none` is different, as such networks implicitly exists outside the scope of the Compose implementation. To use them one MUST define an external network with the name `host` or `none` and an alias that the Compose implementation can use (`hostnet` or `nonet` in the following examples), then grant the service access to that network using its alias.\n\n``` \nservices:\n  web:\n    networks:\n      hostnet: {}\n\nnetworks:\n  hostnet:\n    external: true\n    name: host\n```\n\n``` \nservices:\n  web:\n    ...\n    networks:\n      nonet: {}\n\nnetworks:\n  nonet:\n    external: true\n    name: none\n```\n\n### driver_opts\n\n`driver_opts` specifies a list of options as key-value pairs to pass to the driver for this network. These options are driver-dependent - consult the driver’s documentation for more information. Optional.\n\n``` \ndriver_opts:\n  foo: \"bar\"\n  baz: 1\n```\n\n### attachable\n\nIf `attachable` is set to `true`, then standalone containers SHOULD be able attach to this network, in addition to services. If a standalone container attaches to the network, it can communicate with services and other standalone containers that are also attached to the network.\n\n``` \nnetworks:\n  mynet1:\n    driver: overlay\n    attachable: true\n```\n\n### enable_ipv6\n\n`enable_ipv6` enable IPv6 networking on this network.\n\n### ipam\n\n`ipam` specifies custom a IPAM configuration. This is an object with several properties, each of which is optional:\n\n- `driver`: Custom IPAM driver, instead of the default.\n- `config`: A list with zero or more configuration elements, each containing:\n  - `subnet`: Subnet in CIDR format that represents a network segment\n  - `ip_range`: Range of IPs from which to allocate container IPs\n  - `gateway`: IPv4 or IPv6 gateway for the master subnet\n  - `aux_addresses`: Auxiliary IPv4 or IPv6 addresses used by Network driver, as a mapping from hostname to IP\n- `options`: Driver-specific options as a key-value mapping.\n\nA full example:\n\n``` \nipam:\n  driver: default\n  config:\n    - subnet: 172.28.0.0/16\n      ip_range: 172.28.5.0/24\n      gateway: 172.28.5.254\n      aux_addresses:\n        host1: 172.28.1.5\n        host2: 172.28.1.6\n        host3: 172.28.1.7\n  options:\n    foo: bar\n    baz: \"0\"\n```\n\n### internal\n\nBy default, Compose implementations MUST provides external connectivity to networks. `internal` when set to `true` allow to create an externally isolated network.\n\n### labels\n\nAdd metadata to containers using Labels. Can use either an array or a dictionary.\n\nUsers SHOULD use reverse-DNS notation to prevent labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Financial transaction network\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Financial transaction network\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n```\n\nCompose implementations MUST set `com.docker.compose.project` and `com.docker.compose.network` labels.\n\n### external\n\nIf set to `true`, `external` specifies that this network’s lifecycle is maintained outside of that of the application. Compose Implementations SHOULD NOT attempt to create these networks, and raises an error if one doesn’t exist.\n\nIn the example below, `proxy` is the gateway to the outside world. Instead of attempting to create a network, Compose implementations SHOULD interrogate the platform for an existing network simply called `outside` and connect the `proxy` service’s containers to it.\n\n``` \nservices:\n  proxy:\n    image: awesome/proxy\n    networks:\n      - outside\n      - default\n  app:\n    image: awesome/app\n    networks:\n      - default\n\nnetworks:\n  outside:\n    external: true\n```\n\n### name\n\n`name` sets a custom name for this network. The name field can be used to reference networks which contain special characters. The name is used as is and will **not** be scoped with the project name.\n\n``` \nnetworks:\n  network1:\n    name: my-app-net\n```\n\nIt can also be used in conjunction with the `external` property to define the platform network that the Compose implementation should retrieve, typically by using a parameter so the Compose file doesn’t need to hard-code runtime specific values:\n\n``` \nnetworks:\n  network1:\n    external: true\n    name: \"${NETWORK_ID}\"\n```\n\n## Volumes top-level element\n\nVolumes are persistent data stores implemented by the platform. The Compose specification offers a neutral abstraction for services to mount volumes, and configuration parameters to allocate them on infrastructure.\n\nThe `volumes` section allows the configuration of named volumes that can be reused across multiple services. Here’s an example of a two-service setup where a database’s data directory is shared with another service as a volume named `db-data` so that it can be periodically backed up:\n\n``` \nservices:\n  backend:\n    image: awesome/database\n    volumes:\n      - db-data:/etc/data\n\n  backup:\n    image: backup-service\n    volumes:\n      - db-data:/var/lib/backup/data\n\nvolumes:\n  db-data:\n```\n\nAn entry under the top-level `volumes` key can be empty, in which case it uses the platform’s default configuration for creating a volume. Optionally, you can configure it with the following keys:\n\n### driver\n\nSpecify which volume driver should be used for this volume. Default and available values are platform specific. If the driver is not available, the Compose implementation MUST return an error and stop application deployment.\n\n``` \ndriver: foobar\n```\n\n### driver_opts\n\n`driver_opts` specifies a list of options as key-value pairs to pass to the driver for this volume. Those options are driver-dependent.\n\n``` \nvolumes:\n  example:\n    driver_opts:\n      type: \"nfs\"\n      o: \"addr=10.40.0.199,nolock,soft,rw\"\n      device: \":/docker/example\"\n```\n\n### external\n\nIf set to `true`, `external` specifies that this volume already exist on the platform and its lifecycle is managed outside of that of the application. Compose implementations MUST NOT attempt to create these volumes, and MUST return an error if they do not exist.\n\nIn the example below, instead of attempting to create a volume called `{project_name}_db-data`, Compose looks for an existing volume simply called `db-data` and mounts it into the `backend` service’s containers.\n\n``` \nservices:\n  backend:\n    image: awesome/database\n    volumes:\n      - db-data:/etc/data\n\nvolumes:\n  db-data:\n    external: true\n```\n\n### labels\n\n`labels` are used to add metadata to volumes. You can use either an array or a dictionary.\n\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\n``` \nlabels:\n  com.example.description: \"Database volume\"\n  com.example.department: \"IT/Ops\"\n  com.example.label-with-empty-value: \"\"\n```\n\n``` \nlabels:\n  - \"com.example.description=Database volume\"\n  - \"com.example.department=IT/Ops\"\n  - \"com.example.label-with-empty-value\"\n```\n\nCompose implementation MUST set `com.docker.compose.project` and `com.docker.compose.volume` labels.\n\n### name\n\n`name` set a custom name for this volume. The name field can be used to reference volumes that contain special characters. The name is used as is and will **not** be scoped with the stack name.\n\n``` \nvolumes:\n  data:\n    name: \"my-app-data\"\n```\n\nIt can also be used in conjunction with the `external` property. Doing so the name of the volume used to lookup for actual volume on platform is set separately from the name used to refer to it within the Compose file:\n\n``` \nvolumes:\n  db-data:\n    external:\n      name: actual-name-of-volume\n```\n\nThis make it possible to make this lookup name a parameter of a Compose file, so that the model ID for volume is hard-coded but the actual volume ID on platform is set at runtime during deployment:\n\n``` \nvolumes:\n  db-data:\n    external:\n      name: ${DATABASE_VOLUME}\n```\n\n## Configs top-level element\n\nConfigs allow services to adapt their behaviour without the need to rebuild a Docker image. Configs are comparable to Volumes from a service point of view as they are mounted into service’s containers filesystem. The actual implementation detail to get configuration provided by the platform can be set from the Configuration definition.\n\nWhen granted access to a config, the config content is mounted as a file in the container. The location of the mount point within the container defaults to `/<config-name>` in Linux containers and `C:\\<config-name>` in Windows containers.\n\nBy default, the config MUST be owned by the user running the container command but can be overridden by service configuration. By default, the config MUST have world-readable permissions (mode 0444), unless service is configured to override this.\n\nServices can only access configs when explicitly granted by a [`configs`](#configs) subsection.\n\nThe top-level `configs` declaration defines or references configuration data that can be granted to the services in this application. The source of the config is either `file` or `external`.\n\n- `file`: The config is created with the contents of the file at the specified path.\n- `external`: If set to true, specifies that this config has already been created. Compose implementation does not attempt to create it, and if it does not exist, an error occurs.\n- `name`: The name of config object on Platform to lookup. This field can be used to reference configs that contain special characters. The name is used as is and will **not** be scoped with the project name.\n\nIn this example, `http_config` is created (as `<project_name>_http_config`) when the application is deployed, and `my_second_config` MUST already exist on Platform and value will be obtained by lookup.\n\nIn this example, `server-http_config` is created as `<project_name>_http_config` when the application is deployed, by registering content of the `httpd.conf` as configuration data.\n\n``` \nconfigs:\n  http_config:\n    file: ./httpd.conf\n```\n\nAlternatively, `http_config` can be declared as external, doing so Compose implementation will lookup `http_config` to expose configuration data to relevant services.\n\n``` \nconfigs:\n  http_config:\n    external: true\n```\n\nExternal configs lookup can also use a distinct key by specifying a `name`. The following example modifies the previous one to lookup for config using a parameter `HTTP_CONFIG_KEY`. Doing so the actual lookup key will be set at deployment time by [interpolation](#interpolation) of variables, but exposed to containers as hard-coded ID `http_config`.\n\n``` \nconfigs:\n  http_config:\n    external: true\n    name: \"${HTTP_CONFIG_KEY}\"\n```\n\nCompose file need to explicitly grant access to the configs to relevant services in the application.\n\n## Secrets top-level element\n\nSecrets are a flavour of Configs focussing on sensitive data, with specific constraint for this usage. As the platform implementation may significantly differ from Configs, dedicated Secrets section allows to configure the related resources.\n\nThe top-level `secrets` declaration defines or references sensitive data that can be granted to the services in this application. The source of the secret is either `file` or `external`.\n\n- `file`: The secret is created with the contents of the file at the specified path.\n- `external`: If set to true, specifies that this secret has already been created. Compose implementation does not attempt to create it, and if it does not exist, an error occurs.\n- `name`: The name of the secret object in Docker. This field can be used to reference secrets that contain special characters. The name is used as is and will **not** be scoped with the project name.\n\nIn this example, `server-certificate` is created as `<project_name>_server-certificate` when the application is deployed, by registering content of the `server.cert` as a platform secret.\n\n``` \nsecrets:\n  server-certificate:\n    file: ./server.cert\n```\n\nAlternatively, `server-certificate` can be declared as external, doing so Compose implementation will lookup `server-certificate` to expose secret to relevant services.\n\n``` \nsecrets:\n  server-certificate:\n    external: true\n```\n\nExternal secrets lookup can also use a distinct key by specifying a `name`. The following example modifies the previous one to look up for secret using a parameter `CERTIFICATE_KEY`. Doing so the actual lookup key will be set at deployment time by [interpolation](#interpolation) of variables, but exposed to containers as hard-coded ID `server-certificate`.\n\n``` \nsecrets:\n  server-certificate:\n    external: true\n    name: \"${CERTIFICATE_KEY}\"\n```\n\nCompose file need to explicitly grant access to the secrets to relevant services in the application.\n\n## Fragments\n\nIt is possible to re-use configuration fragments using [YAML anchors](http://www.yaml.org/spec/1.2/spec.html#id2765878).\n\n``` \nvolumes:\n  db-data: &default-volume\n    driver: default\n  metrics: *default-volume\n```\n\nIn previous sample, an *anchor* is created as `default-volume` based on `db-data` volume specification. It is later reused by *alias* `*default-volume` to define `metrics` volume. Same logic can apply to any element in a Compose file. Anchor resolution MUST take place before [variables interpolation](#interpolation), so variables can’t be used to set anchors or aliases.\n\nIt is also possible to partially override values set by anchor reference using the [YAML merge type](http://yaml.org/type/merge.html). In following example, `metrics` volume specification uses alias to avoid repetition but override `name` attribute:\n\n``` \nservices:\n  backend:\n    image: awesome/database\n    volumes:\n      - db-data\n      - metrics\nvolumes:\n  db-data: &default-volume\n    driver: default\n    name: \"data\"\n  metrics:\n    <<: *default-volume\n    name: \"metrics\"\n```\n\n## Extension\n\nSpecial extension fields can be of any format as long as their name starts with the `x-` character sequence. They can be used within any structure in a Compose file. This is the sole exception for Compose implementations to silently ignore unrecognized field.\n\n``` \nx-custom:\n  foo:\n    - bar\n    - zot\n\nservices:\n  webapp:\n    image: awesome/webapp\n    x-foo: bar\n```\n\nThe contents of such fields are unspecified by Compose specification, and can be used to enable custom features. Compose implementation to encounter an unknown extension field MUST NOT fail, but COULD warn about unknown field.\n\nFor platform extensions, it is highly recommended to prefix extension by platform/vendor name, the same way browsers add support for [custom CSS features](https://www.w3.org/TR/2011/REC-CSS2-20110607/syndata.html#vendor-keywords).\n\n``` \nservice:\n  backend:\n    deploy:\n      placement:\n        x-aws-role: \"arn:aws:iam::XXXXXXXXXXXX:role/foo\"\n        x-aws-region: \"eu-west-3\"\n        x-azure-region: \"france-central\"\n```\n\n### Informative Historical Notes\n\nThis section is informative. At the time of writing, the following prefixes are known to exist:\n\n| prefix     | vendor/organization |\n|------------|---------------------|\n| docker     | Docker              |\n| kubernetes | Kubernetes          |\n\n### Using extensions as fragments\n\nWith the support for extension fields, Compose file can be written as follows to improve readability of reused fragments:\n\n``` \nx-logging: &default-logging\n  options:\n    max-size: \"12m\"\n    max-file: \"5\"\n  driver: json-file\n\nservices:\n  frontend:\n    image: awesome/webapp\n    logging: *default-logging\n  backend:\n    image: awesome/database\n    logging: *default-logging\n```\n\n### specifying byte values\n\nValue express a byte value as a string in `{amount}{byte unit}` format: The supported units are `b` (bytes), `k` or `kb` (kilo bytes), `m` or `mb` (mega bytes) and `g` or `gb` (giga bytes).\n\n``` \n    2b\n    1024kb\n    2048k\n    300m\n    1gb\n```\n\n### specifying durations\n\nValue express a duration as a string in the in the form of `{value}{unit}`. The supported units are `us` (microseconds), `ms` (milliseconds), `s` (seconds), `m` (minutes) and `h` (hours). Value can can combine multiple values and using without separator.\n\n``` \n  10ms\n  40s\n  1m30s\n  1h5m30s20ms\n```\n\n## Interpolation\n\nValues in a Compose file can be set by variables, and interpolated at runtime. Compose files use a Bash-like syntax `${VARIABLE}`\n\nBoth `$VARIABLE` and `${VARIABLE}` syntax are supported. Default values can be defined inline using typical shell syntax: latest\n\n- `${VARIABLE:-default}` evaluates to `default` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE-default}` evaluates to `default` only if `VARIABLE` is unset in the environment.\n\nSimilarly, the following syntax allows you to specify mandatory variables:\n\n- `${VARIABLE:?err}` exits with an error message containing `err` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE?err}` exits with an error message containing `err` if `VARIABLE` is unset in the environment.\n\nInterpolation can also be nested:\n\n- `${VARIABLE:-${FOO}}`\n- `${VARIABLE?$FOO}`\n- `${VARIABLE:-${FOO:-default}}`\n\nOther extended shell-style features, such as `${VARIABLE/foo/bar}`, are not supported by the Compose specification.\n\nYou can use a `$$` (double-dollar sign) when your configuration needs a literal dollar sign. This also prevents Compose from interpolating a value, so a `$$` allows you to refer to environment variables that you don’t want processed by Compose.\n\n``` \nweb:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n```\n\nIf the Compose implementation can’t resolve a substituted variable and no default value is defined, it MUST warn the user and substitute the variable with an empty string.\n\nAs any values in a Compose file can be interpolated with variable substitution, including compact string notation for complex elements, interpolation MUST be applied *before* merge on a per-file-basis.\n\n## Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Compose file versions and upgrading](compose-versioning/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n- [Enabling GPU access with Compose](../gpu-support/index)\n- [Command line reference](../reference/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/)"
- name: Content trust in Docker
  id: engine/security/trust/index
  summary: When transferring data among networked systems, trust is a central concern
  description: "# Content trust in Docker\n\nWhen transferring data among networked systems, *trust* is a central concern. In particular, when communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and the publisher of all the data a system operates on. You use the Docker Engine to push and pull images (data) to a public or private registry. Content trust gives you the ability to verify both the integrity and the publisher of all the data received from a registry over any channel.\n\n## About Docker Content Trust (DCT)\n\nDocker Content Trust (DCT) provides the ability to use digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side or runtime verification of the integrity and publisher of specific image tags.\n\nThrough DCT, image publishers can sign their images and image consumers can ensure that the images they pull are signed. Publishers could be individuals or organizations manually signing their content or automated software supply chains signing content as part of their release process.\n\n### Image tags and DCT\n\nAn individual image record has the following identifier:\n\n``` \n[REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]\n```\n\nA particular image `REPOSITORY` can have multiple tags. For example, `latest` and `3.1.2` are both tags on the `mongo` image. An image publisher can build an image and tag combination many times changing the image with each build.\n\nDCT is associated with the `TAG` portion of an image. Each image repository has a set of keys that image publishers use to sign an image tag. Image publishers have discretion on which tags they sign.\n\nAn image repository can contain an image with one tag that is signed and another tag that is not. For example, consider [the Mongo image repository](https://hub.docker.com/r/library/mongo/tags/). The `latest` tag could be unsigned while the `3.1.6` tag could be signed. It is the responsibility of the image publisher to decide if an image tag is signed or not. In this representation, some image tags are signed, others are not:\n\nPublishers can choose to sign a specific tag or not. As a result, the content of an unsigned tag and that of a signed tag with the same name may not match. For example, a publisher can push a tagged image `someimage:latest` and sign it. Later, the same publisher can push an unsigned `someimage:latest` image. This second push replaces the last unsigned tag `latest` but does not affect the signed `latest` version. The ability to choose which tags they can sign, allows publishers to iterate over the unsigned version of an image before officially signing it.\n\nImage consumers can enable DCT to ensure that images they use were signed. If a consumer enables DCT, they can only pull, run, or build with trusted images. Enabling DCT is a bit like applying a “filter” to your registry. Consumers “see” only signed image tags and the less desirable, unsigned image tags are “invisible” to them.\n\nTo the consumer who has not enabled DCT, nothing about how they work with Docker images changes. Every image is visible regardless of whether it is signed or not.\n\n### Docker Content Trust Keys\n\nTrust for an image tag is managed through the use of signing keys. A key set is created when an operation using DCT is first invoked. A key set consists of the following classes of keys:\n\n- an offline key that is the root of DCT for an image tag\n- repository or tagging keys that sign tags\n- server-managed keys such as the timestamp key, which provides freshness security guarantees for your repository\n\nThe following image depicts the various signing keys and their relationships:\n\n> **WARNING**\n>\n> Loss of the root key is **very difficult** to recover from. Correcting this loss requires intervention from [Docker Support](https://support.docker.com) to reset the repository state. This loss also requires **manual intervention** from every consumer that used a signed tag from this repository prior to the loss.\n\nYou should back up the root key somewhere safe. Given that it is only required to create new repositories, it is a good idea to store it offline in hardware. For details on securing, and backing up your keys, make sure you read how to [manage keys for DCT](trust_key_mng/index).\n\n## Signing Images with Docker Content Trust\n\nWithin the Docker CLI we can sign and push a container image with the `$ docker trust` command syntax. This is built on top of the Notary feature set. For more information, see the [Notary GitHub repository](https://github.com/theupdateframework/notary).\n\nA prerequisite for signing an image is a Docker Registry with a Notary server attached (Such as the Docker Hub ). Instructions for standing up a self-hosted environment can be found [here](deploying_notary/index).\n\nTo sign a Docker Image you will need a delegation key pair. These keys can be generated locally using `$ docker trust key generate` or generated by a certificate authority.\n\nFirst we will add the delegation private key to the local Docker trust repository. (By default this is stored in `~/.docker/trust/`). If you are generating delegation keys with `$ docker trust key generate`, the private key is automatically added to the local trust store. If you are importing a separate key, you will need to use the `$ docker trust key load` command.\n\n``` \n$ docker trust key generate jeff\nGenerating key for jeff...\nEnter passphrase for new jeff key with ID 9deed25:\nRepeat passphrase for new jeff key with ID 9deed25:\nSuccessfully generated and loaded private key. Corresponding public key available: /home/ubuntu/Documents/mytrustdir/jeff.pub\n```\n\nOr if you have an existing key:\n\n``` \n$ docker trust key load key.pem --name jeff\nLoading key from \"key.pem\"...\nEnter passphrase for new jeff key with ID 8ae710e:\nRepeat passphrase for new jeff key with ID 8ae710e:\nSuccessfully imported key from key.pem\n```\n\nNext we will need to add the delegation public key to the Notary server; this is specific to a particular image repository in Notary known as a Global Unique Name (GUN). If this is the first time you are adding a delegation to that repository, this command will also initiate the repository, using a local Notary canonical root key. To understand more about initiating a repository, and the role of delegations, head to [delegations for content trust](trust_delegation/index).\n\n``` \n$ docker trust signer add --key cert.pem jeff registry.example.com/admin/demo\nAdding signer \"jeff\" to registry.example.com/admin/demo...\nEnter passphrase for new repository key with ID 10b5e94:\n```\n\nFinally, we will use the delegation private key to sign a particular tag and push it up to the registry.\n\n``` \n$ docker trust sign registry.example.com/admin/demo:1\nSigning and pushing trust data for local image registry.example.com/admin/demo:1, may overwrite remote trust data\nThe push refers to repository [registry.example.com/admin/demo]\n7bff100f35cb: Pushed\n1: digest: sha256:3d2e482b82608d153a374df3357c0291589a61cc194ec4a9ca2381073a17f58e size: 528\nSigning and pushing trust metadata\nEnter passphrase for signer key with ID 8ae710e:\nSuccessfully signed registry.example.com/admin/demo:1\n```\n\nAlternatively, once the keys have been imported an image can be pushed with the `$ docker push` command, by exporting the DCT environmental variable.\n\n``` \n$ export DOCKER_CONTENT_TRUST=1\n\n$ docker push registry.example.com/admin/demo:1\nThe push refers to repository [registry.example.com/admin/demo:1]\n7bff100f35cb: Pushed\n1: digest: sha256:3d2e482b82608d153a374df3357c0291589a61cc194ec4a9ca2381073a17f58e size: 528\nSigning and pushing trust metadata\nEnter passphrase for signer key with ID 8ae710e:\nSuccessfully signed registry.example.com/admin/demo:1\n```\n\nRemote trust data for a tag or a repository can be viewed by the `$ docker trust inspect` command:\n\n``` \n$ docker trust inspect --pretty registry.example.com/admin/demo:1\n\nSignatures for registry.example.com/admin/demo:1\n\nSIGNED TAG          DIGEST                                                             SIGNERS\n1                   3d2e482b82608d153a374df3357c0291589a61cc194ec4a9ca2381073a17f58e   jeff\n\nList of signers and their keys for registry.example.com/admin/demo:1\n\nSIGNER              KEYS\njeff                8ae710e3ba82\n\nAdministrative keys for registry.example.com/admin/demo:1\n\n  Repository Key:   10b5e94c916a0977471cc08fa56c1a5679819b2005ba6a257aa78ce76d3a1e27\n  Root Key: 84ca6e4416416d78c4597e754f38517bea95ab427e5f95871f90d460573071fc\n```\n\nRemote Trust data for a tag can be removed by the `$ docker trust revoke` command:\n\n``` \n$ docker trust revoke registry.example.com/admin/demo:1\nEnter passphrase for signer key with ID 8ae710e:\nSuccessfully deleted signature for registry.example.com/admin/demo:1\n```\n\n## Client Enforcement with Docker Content Trust\n\nContent trust is disabled by default in the Docker Client. To enable it, set the `DOCKER_CONTENT_TRUST` environment variable to `1`. This prevents users from working with tagged images unless they contain a signature.\n\nWhen DCT is enabled in the Docker client, `docker` CLI commands that operate on tagged images must either have content signatures or explicit content hashes. The commands that operate with DCT are:\n\n- `push`\n- `build`\n- `create`\n- `pull`\n- `run`\n\nFor example, with DCT enabled a `docker pull someimage:latest` only succeeds if `someimage:latest` is signed. However, an operation with an explicit content hash always succeeds as long as the hash exists:\n\n``` \n$ docker pull registry.example.com/user/image:1\nError: remote trust data does not exist for registry.example.com/user/image: registry.example.com does not have trust data for registry.example.com/user/image\n\n$ docker pull registry.example.com/user/image@sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a\nsha256:ee7491c9c31db1ffb7673d91e9fac5d6354a89d0e97408567e09df069a1687c1: Pulling from user/image\nff3a5c916c92: Pull complete\na59a168caba3: Pull complete\nDigest: sha256:ee7491c9c31db1ffb7673d91e9fac5d6354a89d0e97408567e09df069a1687c1\nStatus: Downloaded newer image for registry.example.com/user/image@sha256:ee7491c9c31db1ffb7673d91e9fac5d6354a89d0e97408567e09df069a1687c1\n```\n\n## Related information\n\n- [Delegations for content trust](trust_delegation/index)\n- [Automation with content trust](trust_automation/index)\n- [Manage keys for content trust](trust_key_mng/index)\n- [Play in a content trust sandbox](trust_sandbox/index)\n\n[content](https://docs.docker.com/search/?q=content), [trust](https://docs.docker.com/search/?q=trust), [security](https://docs.docker.com/search/?q=security), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/trust/](https://docs.docker.com/engine/security/trust/)"
- name: Control startup and shutdown order in Compose
  id: compose/startup-order/index
  summary: You can control the order of service startup and shutdown with the depends_on option
  description: "# Control startup and shutdown order in Compose\n\nYou can control the order of service startup and shutdown with the [depends_on](../compose-file/compose-file-v3/index#depends_on) option. Compose always starts and stops containers in dependency order, where dependencies are determined by `depends_on`, `links`, `volumes_from`, and `network_mode: \"service:...\"`.\n\nHowever, for startup Compose does not wait until a container is “ready” (whatever that means for your particular application) - only until it’s running. There’s a good reason for this.\n\nThe problem of waiting for a database (for example) to be ready is really just a subset of a much larger problem of distributed systems. In production, your database could become unavailable or move hosts at any time. Your application needs to be resilient to these types of failures.\n\nTo handle this, design your application to attempt to re-establish a connection to the database after a failure. If the application retries the connection, it can eventually connect to the database.\n\nThe best solution is to perform this check in your application code, both at startup and whenever a connection is lost for any reason. However, if you don’t need this level of resilience, you can work around the problem with a wrapper script:\n\n- Use a tool such as [wait-for-it](https://github.com/vishnubob/wait-for-it), [dockerize](https://github.com/powerman/dockerize), sh-compatible [wait-for](https://github.com/Eficode/wait-for), or [RelayAndContainers](https://github.com/jasonsychau/RelayAndContainers) template. These are small wrapper scripts which you can include in your application’s image to poll a given host and port until it’s accepting TCP connections.\n\n  For example, to use `wait-for-it.sh` or `wait-for` to wrap your service’s command:\n\n  ``` \n  version: \"2\"\n  services:\n    web:\n      build: .\n      ports:\n        - \"80:8000\"\n      depends_on:\n        - \"db\"\n      command: [\"./wait-for-it.sh\", \"db:5432\", \"--\", \"python\", \"app.py\"]\n    db:\n      image: postgres\n  ```\n\n  > **Tip**\n  >\n  > There are limitations to this first solution. For example, it doesn’t verify when a specific service is really ready. If you add more arguments to the command, use the `bash shift` command with a loop, as shown in the next example.\n\n- Alternatively, write your own wrapper script to perform a more application-specific health check. For example, you might want to wait until Postgres is ready to accept commands:\n\n  ``` \n  #!/bin/sh\n  # wait-for-postgres.sh\n\n  set -e\n    \n  host=\"$1\"\n  shift\n    \n  until PGPASSWORD=$POSTGRES_PASSWORD psql -h \"$host\" -U \"postgres\" -c '\\q'; do\n    >&2 echo \"Postgres is unavailable - sleeping\"\n    sleep 1\n  done\n    \n  >&2 echo \"Postgres is up - executing command\"\n  exec \"$@\"\n  ```\n\n  You can use this as a wrapper script as in the previous example, by setting:\n\n  ``` \n  command: [\"./wait-for-postgres.sh\", \"db\", \"python\", \"app.py\"]\n  ```\n\n## Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [startup](https://docs.docker.com/search/?q=startup), [shutdown](https://docs.docker.com/search/?q=shutdown), [order](https://docs.docker.com/search/?q=order)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/startup-order/](https://docs.docker.com/compose/startup-order/)"
- name: Create a swarm
  id: engine/swarm/swarm-tutorial/create-swarm/index
  summary: After you complete the tutorial setup steps, you’re ready to create a swarm
  description: "# Create a swarm\n\nAfter you complete the [tutorial setup](../index) steps, you’re ready to create a swarm. Make sure the Docker Engine daemon is started on the host machines.\n\n1.  Open a terminal and ssh into the machine where you want to run your manager node. This tutorial uses a machine named `manager1`. If you use Docker Machine, you can connect to it via SSH using the following command:\n\n    ``` \n    $ docker-machine ssh manager1\n    ```\n\n2.  Run the following command to create a new swarm:\n\n    ``` \n    $ docker swarm init --advertise-addr <MANAGER-IP>\n    ```\n\n    > **Note**: If you are using Docker Desktop for Mac or Docker Desktop for Windows to test single-node swarm, simply run `docker swarm init` with no arguments. There is no need to specify `--advertise-addr` in this case. To learn more, see the topic on how to [Use Docker Desktop for Mac or Docker Desktop for Windows](../index#use-docker-desktop-for-mac-or-docker-desktop-for-windows) with Swarm.\n\n    In the tutorial, the following command creates a swarm on the `manager1` machine:\n\n    ``` \n    $ docker swarm init --advertise-addr 192.168.99.100\n    Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.\n\n    To add a worker to this swarm, run the following command:\n\n        docker swarm join \\\n        --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n        192.168.99.100:2377\n\n    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n    ```\n\n    The `--advertise-addr` flag configures the manager node to publish its address as `192.168.99.100`. The other nodes in the swarm must be able to access the manager at the IP address.\n\n    The output includes the commands to join new nodes to the swarm. Nodes will join as managers or workers depending on the value for the `--token` flag.\n\n3.  Run `docker info` to view the current state of the swarm:\n\n    ``` \n    $ docker info\n\n    Containers: 2\n    Running: 0\n    Paused: 0\n    Stopped: 2\n      ...snip...\n    Swarm: active\n      NodeID: dxn1zf6l61qsb1josjja83ngz\n      Is Manager: true\n      Managers: 1\n      Nodes: 1\n      ...snip...\n    ```\n\n4.  Run the `docker node ls` command to view information about nodes:\n\n    ``` \n    $ docker node ls\n\n    ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n    dxn1zf6l61qsb1josjja83ngz *  manager1  Ready   Active        Leader\n    ```\n\n    The `*` next to the node ID indicates that you’re currently connected on this node.\n\n    Docker Engine swarm mode automatically names the node for the machine host name. The tutorial covers other columns in later steps.\n\n## What’s next?\n\nIn the next section of the tutorial, we [add two more nodes](../add-nodes/index) to the cluster.\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/)"
- name: Declare default environment variables in file
  id: compose/env-file/index
  summary: Compose supports declaring default environment variables in an environment file named .env placed in the project directory
  description: "# Declare default environment variables in file\n\nCompose supports declaring default environment variables in an environment file named `.env` placed in the project directory. Docker Compose versions earlier than `1.28`, load the `.env` file from the current working directory, where the command is executed, or from the project directory if this is explicitly set with the `--project-directory` option. This inconsistency has been addressed starting with `+v1.28` by limiting the default `.env` file path to the project directory. You can use the `--env-file` commandline option to override the default `.env` and specify the path to a custom environment file.\n\nThe project directory is specified by the order of precedence:\n\n- `--project-directory` flag\n- Folder of the first `--file` flag\n- Current directory\n\n## Syntax rules\n\nThe following syntax rules apply to the `.env` file:\n\n- Compose expects each line in an `env` file to be in `VAR=VAL` format.\n- Lines beginning with `#` are processed as comments and ignored.\n- Blank lines are ignored.\n- There is no special handling of quotation marks. This means that **they are part of the VAL**.\n\n## Compose file and CLI variables\n\nThe environment variables you define here are used for [variable substitution](../compose-file/compose-file-v3/index#variable-substitution) in your Compose file, and can also be used to define the following [CLI variables](../reference/envvars/index):\n\n- `COMPOSE_API_VERSION`\n- `COMPOSE_CONVERT_WINDOWS_PATHS`\n- `COMPOSE_FILE`\n- `COMPOSE_HTTP_TIMEOUT`\n- `COMPOSE_PROFILES`\n- `COMPOSE_PROJECT_NAME`\n- `COMPOSE_TLS_VERSION`\n- `DOCKER_CERT_PATH`\n- `DOCKER_HOST`\n- `DOCKER_TLS_VERIFY`\n\n> **Notes**\n>\n> - Values present in the environment at runtime always override those defined inside the `.env` file. Similarly, values passed via command-line arguments take precedence as well.\n> - Environment variables defined in the `.env` file are not automatically visible inside containers. To set container-applicable environment variables, follow the guidelines in the topic [Environment variables in Compose](../environment-variables/index), which describes how to pass shell environment variables through to containers, define environment variables in Compose files, and more.\n\n## More Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [environment](https://docs.docker.com/search/?q=environment), [env file](https://docs.docker.com/search/?q=env%20file)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/env-file/](https://docs.docker.com/compose/env-file/)"
- name: Delegations for content trust
  id: engine/security/trust/trust_delegation/index
  summary: Delegations in Docker Content Trust (DCT) allow you to control who can and cannot sign an image tag
  description: "# Delegations for content trust\n\nDelegations in Docker Content Trust (DCT) allow you to control who can and cannot sign an image tag. A delegation will have a pair of private and public delegation keys. A delegation could contain multiple pairs of keys and contributors in order to a) allow multiple users to be part of a delegation, and b) to support key rotation.\n\nThe most important delegation within Docker Content Trust is `targets/releases`. This is seen as the canonical source of a trusted image tag, and without a contributor’s key being under this delegation, they will be unable to sign a tag.\n\nFortunately when using the `$ docker trust` commands, we will automatically initialize a repository, manage the repository keys, and add a collaborator’s key to the `targets/releases` delegation via `docker trust signer add`.\n\n## Configuring the Docker Client\n\nBy default, the `$ docker trust` commands expect the notary server URL to be the same as the registry URL specified in the image tag (following a similar logic to `$ docker push`). When using Docker Hub or DTR, the notary server URL is the same as the registry URL. However, for self-hosted environments or 3rd party registries, you will need to specify an alternative URL for the notary server. This is done with:\n\n``` \n$ export DOCKER_CONTENT_TRUST_SERVER=https://<URL>:<PORT>\n```\n\nIf you do not export this variable in self-hosted environments, you may see errors such as:\n\n``` \n$ docker trust signer add --key cert.pem jeff registry.example.com/admin/demo\nAdding signer \"jeff\" to registry.example.com/admin/demo...\n<...>\nError: trust data missing for remote repository registry.example.com/admin/demo or remote repository not found: timestamp key trust data unavailable.  Has a notary repository been initialized?\n\n$ docker trust inspect registry.example.com/admin/demo --pretty\nWARN[0000] Error while downloading remote metadata, using cached timestamp - this might not be the latest version available remotely\n<...>\n```\n\nIf you have enabled authentication for your notary server, or are using DTR, you will need to log in before you can push data to the notary server.\n\n``` \n$ docker login registry.example.com/user/repo\nUsername: admin\nPassword:\n\nLogin Succeeded\n\n$ docker trust signer add --key cert.pem jeff registry.example.com/user/repo\nAdding signer \"jeff\" to registry.example.com/user/repo...\nInitializing signed repository for registry.example.com/user/repo...\nSuccessfully initialized \"registry.example.com/user/repo\"\nSuccessfully added signer: jeff to registry.example.com/user/repo\n```\n\nIf you do not log in, you will see:\n\n``` \n$ docker trust signer add --key cert.pem jeff registry.example.com/user/repo\nAdding signer \"jeff\" to registry.example.com/user/repo...\nInitializing signed repository for registry.example.com/user/repo...\nyou are not authorized to perform this operation: server returned 401.\n\nFailed to add signer to: registry.example.com/user/repo\n```\n\n## Configuring the Notary Client\n\nSome of the more advanced features of DCT require the Notary CLI. To install and configure the Notary CLI:\n\n1.  Download the [client](https://github.com/theupdateframework/notary/releases) and ensure that it is available on your path.\n\n2.  Create a configuration file at `~/.notary/config.json` with the following content:\n\n``` \n{\n  \"trust_dir\" : \"~/.docker/trust\",\n  \"remote_server\": {\n    \"url\": \"https://registry.example.com\",\n    \"root_ca\": \"../.docker/ca.pem\"\n  }\n}\n```\n\nThe newly created configuration file contains information about the location of your local Docker trust data and the notary server URL.\n\nFor more detailed information about how to use notary outside of the Docker Content Trust use cases, refer to the Notary CLI documentation [here](https://github.com/theupdateframework/notary/blob/master/docs/command_reference/)\n\n## Creating Delegation Keys\n\nA prerequisite to adding your first contributor is a pair of delegation keys. These keys can either be generated locally using `$ docker trust`, generated by a certificate authority.\n\n### Using Docker Trust to Generate Keys\n\nDocker trust has a built-in generator for a delegation key pair, `$ docker trust generate <name>`. Running this command will automatically load the delegation private key in to the local Docker trust store.\n\n``` \n$ docker trust key generate jeff\n\nGenerating key for jeff...\nEnter passphrase for new jeff key with ID 9deed25: \nRepeat passphrase for new jeff key with ID 9deed25: \nSuccessfully generated and loaded private key. Corresponding public key available: /home/ubuntu/Documents/mytrustdir/jeff.pub\n```\n\n### Manually Generating Keys\n\nIf you need to manually generate a private key (either RSA or ECDSA) and a x509 certificate containing the public key, you can use local tools like openssl or cfssl along with a local or company-wide Certificate Authority.\n\nHere is an example of how to generate a 2048-bit RSA portion key (all RSA keys must be at least 2048 bits):\n\n``` \n$ openssl genrsa -out delegation.key 2048\n\nGenerating RSA private key, 2048 bit long modulus\n....................................................+++\n............+++\ne is 65537 (0x10001)\n```\n\nThey should keep `delegation.key` private because it is used to sign tags.\n\nThen they need to generate an x509 certificate containing the public key, which is what you need from them. Here is the command to generate a CSR (certificate signing request):\n\n``` \n$ openssl req -new -sha256 -key delegation.key -out delegation.csr\n```\n\nThen they can send it to whichever CA you trust to sign certificates, or they can self-sign the certificate (in this example, creating a certificate that is valid for 1 year):\n\n``` \n$ openssl x509 -req -sha256 -days 365 -in delegation.csr -signkey delegation.key -out delegation.crt\n```\n\nThen they need to give you `delegation.crt`, whether it is self-signed or signed by a CA.\n\nFinally you will need to add the private key into your local Docker trust store.\n\n``` \n$ docker trust key load delegation.key --name jeff\n\nLoading key from \"delegation.key\"...\nEnter passphrase for new jeff key with ID 8ae710e: \nRepeat passphrase for new jeff key with ID 8ae710e: \nSuccessfully imported key from delegation.key\n```\n\n### Viewing local Delegation keys\n\nTo list the keys that have been imported in to the local Docker trust store we can use the Notary CLI.\n\n``` \n$ notary key list\n\nROLE       GUN                          KEY ID                                                              LOCATION\n----       ---                          ------                                                              --------\nroot                                    f6c6a4b00fefd8751f86194c7d87a3bede444540eb3378c4a11ce10852ab1f96    /home/ubuntu/.docker/trust/private\njeff                                    9deed251daa1aa6f9d5f9b752847647cf8d705da0763aa5467650d0987ed5306    /home/ubuntu/.docker/trust/private\n```\n\n## Managing Delegations in a Notary Server\n\nWhen the first Delegation is added to the Notary Server using `$ docker trust`, we automatically initiate trust data for the repository. This includes creating the notary target and snapshots keys, and rotating the snapshot key to be managed by the notary server. More information on these keys can be found [here](../trust_key_mng/index)\n\nWhen initiating a repository, you will need the key and the passphrase of a local Notary Canonical Root Key. If you have not initiated a repository before, and therefore don’t have a Notary root key, `$ docker trust` will create one for you.\n\n> Be sure to protect and back up your [Notary Canonical Root Key](../trust_key_mng/index)\n\n### Initiating the Repository\n\nTo upload the first key to a delegation, at the same time initiating a repository, you can use the `$ docker trust signer add` command. This will add the contributor’s public key to the `targets/releases` delegation, and create a second `targets/<name>` delegation.\n\nFor DCT the name of the second delegation, in the below example `jeff`, is there to help you keep track of the owner of the keys. In more advanced use cases of Notary additional delegations are used for hierarchy.\n\n``` \n$ docker trust signer add --key cert.pem jeff registry.example.com/admin/demo\n\nAdding signer \"jeff\" to registry.example.com/admin/demo...\nInitializing signed repository for registry.example.com/admin/demo...\nEnter passphrase for root key with ID f6c6a4b: \nEnter passphrase for new repository key with ID b0014f8: \nRepeat passphrase for new repository key with ID b0014f8: \nSuccessfully initialized \"registry.example.com/admin/demo\"\nSuccessfully added signer: jeff to registry.example.com/admin/demo\n```\n\nYou can see which keys have been pushed to the Notary server for each repository with the `$ docker trust inspect` command.\n\n``` \n$ docker trust inspect --pretty registry.example.com/admin/demo\n\nNo signatures for registry.example.com/admin/demo\n\n\nList of signers and their keys for registry.example.com/admin/demo\n\nSIGNER              KEYS\njeff                1091060d7bfd\n\nAdministrative keys for registry.example.com/admin/demo\n\n  Repository Key:   b0014f8e4863df2d028095b74efcb05d872c3591de0af06652944e310d96598d\n  Root Key: 64d147e59e44870311dd2d80b9f7840039115ef3dfa5008127d769a5f657a5d7\n```\n\nYou could also use the Notary CLI to list delegations and keys. Here you can clearly see the keys were attached to `targets/releases` and `targets/jeff`.\n\n``` \n$ notary delegation list registry.example.com/admin/demo\n\nROLE                PATHS             KEY IDS                                                             THRESHOLD\n----                -----             -------                                                             ---------\ntargets/jeff        \"\" <all paths>    1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1    1\n                                          \ntargets/releases    \"\" <all paths>    1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1    1 \n```\n\n### Adding Additional Signers\n\nDocker Trust allows you to configure multiple delegations per repository, allowing you to manage the lifecycle of delegations. When adding additional delegations with `$ docker trust` the collaborators key is once again added to the `targets/release` role.\n\n> Note you will need the passphrase for the repository key; this would have been configured when you first initiated the repository.\n\n``` \n$ docker trust signer add --key ben.pub ben registry.example.com/admin/demo\n\nAdding signer \"ben\" to registry.example.com/admin/demo...\nEnter passphrase for repository key with ID b0014f8: \nSuccessfully added signer: ben to registry.example.com/admin/demo\n```\n\nCheck to prove that there are now 2 delegations (Signer).\n\n``` \n$ docker trust inspect --pretty registry.example.com/admin/demo\n\nNo signatures for registry.example.com/admin/demo\n\nList of signers and their keys for registry.example.com/admin/demo\n\nSIGNER              KEYS\nben                 afa404703b25\njeff                1091060d7bfd\n\nAdministrative keys for registry.example.com/admin/demo\n\n  Repository Key:   b0014f8e4863df2d028095b74efcb05d872c3591de0af06652944e310d96598d\n  Root Key: 64d147e59e44870311dd2d80b9f7840039115ef3dfa5008127d769a5f657a5d7\n```\n\n### Adding Keys to an Existing Delegation\n\nTo support things like key rotation and expiring / retiring keys you can publish multiple contributor keys per delegation. The only prerequisite here is to make sure you use the same the delegation name, in this case `jeff`. Docker trust will automatically handle adding this new key to `targets/releases`.\n\n> Note you will need the passphrase for the repository key; this would have been configured when you first initiated the repository.\n\n``` \n$ docker trust signer add --key cert2.pem jeff registry.example.com/admin/demo\n\nAdding signer \"jeff\" to registry.example.com/admin/demo...\nEnter passphrase for repository key with ID b0014f8: \nSuccessfully added signer: jeff to registry.example.com/admin/demo\n```\n\nCheck to prove that the delegation (Signer) now contains multiple Key IDs.\n\n``` \n$ docker trust inspect --pretty registry.example.com/admin/demo\n\nNo signatures for registry.example.com/admin/demo\n\n\nList of signers and their keys for registry.example.com/admin/demo\n\nSIGNER              KEYS\njeff                1091060d7bfd, 5570b88df073\n\nAdministrative keys for registry.example.com/admin/demo\n\n  Repository Key:   b0014f8e4863df2d028095b74efcb05d872c3591de0af06652944e310d96598d\n  Root Key: 64d147e59e44870311dd2d80b9f7840039115ef3dfa5008127d769a5f657a5d7\n```\n\n### Removing a Delegation\n\nIf you need to remove a delegation, including the contributor keys that are attached to the `targets/releases` role, you can use the `$ docker trust signer remove` command.\n\n> Note tags that were signed by the removed delegation will need to be resigned by an active delegation\n\n``` \n$ docker trust signer remove registry.example.com/admin/demo\nRemoving signer \"ben\" from registry.example.com/admin/demo...\nEnter passphrase for repository key with ID b0014f8: \nSuccessfully removed ben from registry.example.com/admin/demo\n```\n\n#### Troubleshooting\n\n1\\) If you see an error that there are no usable keys in `targets/releases`, you will need to add additional delegations using `docker trust signer add` before resigning images.\n\n``` \nWARN[0000] role targets/releases has fewer keys than its threshold of 1; it will not be usable until keys are added to it\n```\n\n2\\) If you have added additional delegations already and are seeing an error message that there are no valid signatures in `targest/releases`, you will need to resign the `targets/releases` delegation file with the Notary CLI.\n\n``` \nWARN[0000] Error getting targets/releases: valid signatures did not meet threshold for targets/releases \n```\n\nResigning the delegation file is done with the `$ notary witness` command\n\n``` \n$ notary witness registry.example.com/admin/demo targets/releases --publish\n```\n\nMore information on the `$ notary witness` command can be found [here](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage/#recovering-a-delegation)\n\n### Removing a Contributor’s Key from a Delegation\n\nAs part of rotating keys for a delegation, you may want to remove an individual key but retain the delegation. This can be done with the Notary CLI.\n\nRemember you will have to remove the key from both the `targets/releases` role and the role specific to that signer `targets/<name>`.\n\n1\\) We will need to grab the Key ID from the Notary Server\n\n``` \n$ notary delegation list registry.example.com/admin/demo\n\nROLE                PATHS             KEY IDS                                                             THRESHOLD\n----                -----             -------                                                             ---------\ntargets/jeff        \"\" <all paths>    8fb597cbaf196f0781628b2f52bff6b3912e4e8075720378fda60d17232bbcf9    1\n                                      1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1    \ntargets/releases    \"\" <all paths>    8fb597cbaf196f0781628b2f52bff6b3912e4e8075720378fda60d17232bbcf9    1\n                                      1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1    \n```\n\n2\\) Remove from the `targets/releases` delegation\n\n``` \n$ notary delegation remove registry.example.com/admin/demo targets/releases 1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1 --publish\n\nAuto-publishing changes to registry.example.com/admin/demo\nEnter username: admin\nEnter password: \nEnter passphrase for targets key with ID b0014f8: \nSuccessfully published changes for repository registry.example.com/admin/demo\n```\n\n3\\) Remove from the `targets/<name>` delegation\n\n``` \n$ notary delegation remove registry.example.com/admin/demo targets/jeff 1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1 --publish\n\nRemoval of delegation role targets/jeff with keys [5570b88df0736c468493247a07e235e35cf3641270c944d0e9e8899922fc6f99], to repository \"registry.example.com/admin/demo\" staged for next publish.\n\nAuto-publishing changes to registry.example.com/admin/demo\nEnter username: admin    \nEnter password: \nEnter passphrase for targets key with ID b0014f8: \nSuccessfully published changes for repository registry.example.com/admin/demo\n```\n\n4\\) Check the remaining delegation list\n\n``` \n$ notary delegation list registry.example.com/admin/demo\n\nROLE                PATHS             KEY IDS                                                             THRESHOLD\n----                -----             -------                                                             ---------\ntargets/jeff        \"\" <all paths>    8fb597cbaf196f0781628b2f52bff6b3912e4e8075720378fda60d17232bbcf9    1    \ntargets/releases    \"\" <all paths>    8fb597cbaf196f0781628b2f52bff6b3912e4e8075720378fda60d17232bbcf9    1    \n```\n\n### Removing a local Delegation Private Key\n\nAs part of rotating delegation keys, you may need to remove a local delegation key from the local Docker trust store. This is done with the Notary CLI, using the `$ notary key remove` command.\n\n1\\) We will need to get the Key ID from the local Docker Trust store\n\n``` \n$ notary key list\n\nROLE       GUN                          KEY ID                                                              LOCATION\n----       ---                          ------                                                              --------\nroot                                    f6c6a4b00fefd8751f86194c7d87a3bede444540eb3378c4a11ce10852ab1f96    /home/ubuntu/.docker/trust/private\nadmin                                   8fb597cbaf196f0781628b2f52bff6b3912e4e8075720378fda60d17232bbcf9    /home/ubuntu/.docker/trust/private\njeff                                    1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1    /home/ubuntu/.docker/trust/private\ntargets    ...example.com/admin/demo    c819f2eda8fba2810ec6a7f95f051c90276c87fddfc3039058856fad061c009d    /home/ubuntu/.docker/trust/private\n```\n\n2\\) Remove the key from the local Docker Trust store\n\n``` \n$ notary key remove 1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1\n\nAre you sure you want to remove 1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1 (role jeff) from /home/ubuntu/.docker/trust/private?  (yes/no)  y\n\nDeleted 1091060d7bfd938dfa5be703fa057974f9322a4faef6f580334f3d6df44c02d1 (role jeff) from /home/ubuntu/.docker/trust/private.\n```\n\n## Removing all trust data from a Repository\n\nYou can remove all trust data from a repository, including repository, target, snapshot and all delegations keys using the Notary CLI.\n\nThis is often required by a container registry before a particular repository can be deleted.\n\n``` \n$ notary delete registry.example.com/admin/demo --remote\n\nDeleting trust data for repository registry.example.com/admin/demo\nEnter username: admin\nEnter password: \nSuccessfully deleted local and remote trust data for repository registry.example.com/admin/demo\n\n$ docker trust inspect --pretty registry.example.com/admin/demo\n\nNo signatures or cannot access registry.example.com/admin/demo\n```\n\n## Related information\n\n- [Content trust in Docker](../index)\n- [Manage keys for content trust](../trust_key_mng/index)\n- [Automation with content trust](../trust_automation/index)\n- [Play in a content trust sandbox](../trust_sandbox/index)\n\n[trust](https://docs.docker.com/search/?q=trust), [security](https://docs.docker.com/search/?q=security), [delegations](https://docs.docker.com/search/?q=delegations), [keys](https://docs.docker.com/search/?q=keys), [repository](https://docs.docker.com/search/?q=repository)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/trust/trust_delegation/](https://docs.docker.com/engine/security/trust/trust_delegation/)"
- name: Delete the service running on the swarm
  id: engine/swarm/swarm-tutorial/delete-service/index
  summary: The remaining steps in the tutorial don’t use the helloworld service, so now you can delete the service from the swarm
  description: "# Delete the service running on the swarm\n\nThe remaining steps in the tutorial don’t use the `helloworld` service, so now you can delete the service from the swarm.\n\n1.  If you haven’t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n\n2.  Run `docker service rm helloworld` to remove the `helloworld` service.\n\n    ``` \n    $ docker service rm helloworld\n\n    helloworld\n    ```\n\n3.  Run `docker service inspect <SERVICE-ID>` to verify that the swarm manager removed the service. The CLI returns a message that the service is not found:\n\n    ``` \n    $ docker service inspect helloworld\n    []\n    Error: no such service: helloworld\n    ```\n\n4.  Even though the service no longer exists, the task containers take a few seconds to clean up. You can use `docker ps` on the nodes to verify when the tasks have been removed.\n\n    ``` \n    $ docker ps\n\n    CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS     NAMES\n    db1651f50347        alpine:latest       \"ping docker.com\"        44 minutes ago      Up 46 seconds                 helloworld.5.9lkmos2beppihw95vdwxy1j3w\n    43bf6e532a92        alpine:latest       \"ping docker.com\"        44 minutes ago      Up 46 seconds                 helloworld.3.a71i8rp6fua79ad43ycocl4t2\n    5a0fb65d8fa7        alpine:latest       \"ping docker.com\"        44 minutes ago      Up 45 seconds                 helloworld.2.2jpgensh7d935qdc857pxulfr\n    afb0ba67076f        alpine:latest       \"ping docker.com\"        44 minutes ago      Up 46 seconds                 helloworld.4.1c47o7tluz7drve4vkm2m5olx\n    688172d3bfaa        alpine:latest       \"ping docker.com\"        45 minutes ago      Up About a minute             helloworld.1.74nbhb3fhud8jfrhigd7s29we\n\n    $ docker ps\n    CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS     NAMES\n    ```\n\n## What’s next?\n\nIn the next step of the tutorial, you set up a new service and apply a [rolling update](../rolling-update/index).\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm](https://docs.docker.com/search/?q=swarm), [service](https://docs.docker.com/search/?q=service)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/delete-service/](https://docs.docker.com/engine/swarm/swarm-tutorial/delete-service/)"
- name: Deploy a service to the swarm
  id: engine/swarm/swarm-tutorial/deploy-service/index
  summary: After you create a swarm, you can deploy a service to the swarm
  description: "# Deploy a service to the swarm\n\nAfter you [create a swarm](../create-swarm/index), you can deploy a service to the swarm. For this tutorial, you also [added worker nodes](../add-nodes/index), but that is not a requirement to deploy a service.\n\n1.  Open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n\n2.  Run the following command:\n\n    ``` \n    $ docker service create --replicas 1 --name helloworld alpine ping docker.com\n\n    9uk4639qpg7npwf3fn2aasksr\n    ```\n\n    - The `docker service create` command creates the service.\n    - The `--name` flag names the service `helloworld`.\n    - The `--replicas` flag specifies the desired state of 1 running instance.\n    - The arguments `alpine ping docker.com` define the service as an Alpine Linux container that executes the command `ping docker.com`.\n\n3.  Run `docker service ls` to see the list of running services:\n\n    ``` \n    $ docker service ls\n\n    ID            NAME        SCALE  IMAGE   COMMAND\n    9uk4639qpg7n  helloworld  1/1    alpine  ping docker.com\n    ```\n\n## What’s next?\n\nNow you’ve deployed a service to the swarm, you’re ready to [inspect the service](../inspect-service/index).\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/](https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/)"
- name: Deploy a stack to a swarm
  id: engine/swarm/stack-deploy/index
  summary: When running Docker Engine in swarm mode, you can use docker stack deploy to deploy a complete application stack to the swarm
  description: "# Deploy a stack to a swarm\n\nWhen running Docker Engine in swarm mode, you can use `docker stack deploy` to deploy a complete application stack to the swarm. The `deploy` command accepts a stack description in the form of a [Compose file](../../../compose/compose-file/compose-file-v3/index).\n\nThe `docker stack deploy` command supports any Compose file of version “3.0” or above. If you have an older version, see the [upgrade guide](../../../compose/compose-file/compose-versioning/index#upgrading).\n\nTo run through this tutorial, you need:\n\n1.  A Docker Engine running in [swarm mode](../swarm-mode/index). If you’re not familiar with swarm mode, you might want to read [Swarm mode key concepts](../key-concepts/index) and [How services work](../how-swarm-mode-works/services/index).\n\n    > **Note**\n    >\n    > If you’re trying things out on a local development environment, you can put your engine into swarm mode with `docker swarm init`.\n    >\n    > If you’ve already got a multi-node swarm running, keep in mind that all `docker stack` and `docker service` commands must be run from a manager node.\n\n2.  A current version of [Docker Compose](../../../compose/install/index).\n\n## Set up a Docker registry\n\nBecause a swarm consists of multiple Docker Engines, a registry is required to distribute images to all of them. You can use the [Docker Hub](https://hub.docker.com) or maintain your own. Here’s how to create a throwaway registry, which you can discard afterward.\n\n1.  Start the registry as a service on your swarm:\n\n    ``` \n    $ docker service create --name registry --publish published=5000,target=5000 registry:2\n    ```\n\n2.  Check its status with `docker service ls`:\n\n    ``` \n    $ docker service ls\n\n    ID            NAME      REPLICAS  IMAGE                                                                               COMMAND\n    l7791tpuwkco  registry  1/1       registry:2@sha256:1152291c7f93a4ea2ddc95e46d142c31e743b6dd70e194af9e6ebe530f782c17\n    ```\n\n    Once it reads `1/1` under `REPLICAS`, it’s running. If it reads `0/1`, it’s probably still pulling the image.\n\n3.  Check that it’s working with `curl`:\n\n    ``` \n    $ curl http://localhost:5000/v2/\n\n    {}\n    ```\n\n## Create the example application\n\nThe app used in this guide is based on the hit counter app in the [Get started with Docker Compose](../../../compose/gettingstarted/index) guide. It consists of a Python app which maintains a counter in a Redis instance and increments the counter whenever you visit it.\n\n1.  Create a directory for the project:\n\n    ``` \n    $ mkdir stackdemo\n    $ cd stackdemo\n    ```\n\n2.  Create a file called `app.py` in the project directory and paste this in:\n\n    ``` \n    from flask import Flask\n    from redis import Redis\n\n    app = Flask(__name__)\n    redis = Redis(host='redis', port=6379)\n\n    @app.route('/')\n    def hello():\n        count = redis.incr('hits')\n        return 'Hello World! I have been seen {} times.\\n'.format(count)\n\n    if __name__ == \"__main__\":\n        app.run(host=\"0.0.0.0\", port=8000, debug=True)\n    ```\n\n3.  Create a file called `requirements.txt` and paste these two lines in:\n\n        flask\n        redis\n\n4.  Create a file called `Dockerfile` and paste this in:\n\n    ``` \n    # syntax=docker/dockerfile:1\n    FROM python:3.4-alpine\n    ADD . /code\n    WORKDIR /code\n    RUN pip install -r requirements.txt\n    CMD [\"python\", \"app.py\"]\n    ```\n\n5.  Create a file called `docker-compose.yml` and paste this in:\n\n        version: \"3.9\"\n\n        services:\n          web:\n            image: 127.0.0.1:5000/stackdemo\n            build: .\n            ports:\n              - \"8000:8000\"\n          redis:\n            image: redis:alpine\n\n    The image for the web app is built using the Dockerfile defined above. It’s also tagged with `127.0.0.1:5000` - the address of the registry created earlier. This is important when distributing the app to the swarm.\n\n## Test the app with Compose\n\n1.  Start the app with `docker-compose up`. This builds the web app image, pulls the Redis image if you don’t already have it, and creates two containers.\n\n    You see a warning about the Engine being in swarm mode. This is because Compose doesn’t take advantage of swarm mode, and deploys everything to a single node. You can safely ignore this.\n\n        $ docker-compose up -d\n\n        WARNING: The Docker Engine you're using is running in swarm mode.\n\n        Compose does not use swarm mode to deploy services to multiple nodes in\n        a swarm. All containers are scheduled on the current node.\n\n        To deploy your application across the swarm, use `docker stack deploy`.\n\n        Creating network \"stackdemo_default\" with the default driver\n        Building web\n        ...(build output)...\n        Creating stackdemo_redis_1\n        Creating stackdemo_web_1\n\n2.  Check that the app is running with `docker-compose ps`:\n\n    ``` \n    $ docker-compose ps\n\n          Name                     Command               State           Ports\n    -----------------------------------------------------------------------------------\n    stackdemo_redis_1   docker-entrypoint.sh redis ...   Up      6379/tcp\n    stackdemo_web_1     python app.py                    Up      0.0.0.0:8000->8000/tcp\n    ```\n\n    You can test the app with `curl`:\n\n    ``` \n    $ curl http://localhost:8000\n    Hello World! I have been seen 1 times.\n\n    $ curl http://localhost:8000\n    Hello World! I have been seen 2 times.\n\n    $ curl http://localhost:8000\n    Hello World! I have been seen 3 times.\n    ```\n\n3.  Bring the app down:\n\n    ``` \n    $ docker-compose down --volumes\n\n    Stopping stackdemo_web_1 ... done\n    Stopping stackdemo_redis_1 ... done\n    Removing stackdemo_web_1 ... done\n    Removing stackdemo_redis_1 ... done\n    Removing network stackdemo_default\n    ```\n\n## Push the generated image to the registry\n\nTo distribute the web app’s image across the swarm, it needs to be pushed to the registry you set up earlier. With Compose, this is very simple:\n\n``` \n$ docker-compose push\n\nPushing web (127.0.0.1:5000/stackdemo:latest)...\nThe push refers to a repository [127.0.0.1:5000/stackdemo]\n5b5a49501a76: Pushed\nbe44185ce609: Pushed\nbd7330a79bcf: Pushed\nc9fc143a069a: Pushed\n011b303988d2: Pushed\nlatest: digest: sha256:a81840ebf5ac24b42c1c676cbda3b2cb144580ee347c07e1bc80e35e5ca76507 size: 1372\n```\n\nThe stack is now ready to be deployed.\n\n## Deploy the stack to the swarm\n\n1.  Create the stack with `docker stack deploy`:\n\n    ``` \n    $ docker stack deploy --compose-file docker-compose.yml stackdemo\n\n    Ignoring unsupported options: build\n\n    Creating network stackdemo_default\n    Creating service stackdemo_web\n    Creating service stackdemo_redis\n    ```\n\n    The last argument is a name for the stack. Each network, volume and service name is prefixed with the stack name.\n\n2.  Check that it’s running with `docker stack services stackdemo`:\n\n    ``` \n    $ docker stack services stackdemo\n\n    ID            NAME             MODE        REPLICAS  IMAGE\n    orvjk2263y1p  stackdemo_redis  replicated  1/1       redis:3.2-alpine@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86d\n    s1nf0xy8t1un  stackdemo_web    replicated  1/1       127.0.0.1:5000/stackdemo@sha256:adb070e0805d04ba2f92c724298370b7a4eb19860222120d43e0f6351ddbc26f\n    ```\n\n    Once it’s running, you should see `1/1` under `REPLICAS` for both services. This might take some time if you have a multi-node swarm, as images need to be pulled.\n\n    As before, you can test the app with `curl`:\n\n    ``` \n    $ curl http://localhost:8000\n    Hello World! I have been seen 1 times.\n\n    $ curl http://localhost:8000\n    Hello World! I have been seen 2 times.\n\n    $ curl http://localhost:8000\n    Hello World! I have been seen 3 times.\n    ```\n\n    Thanks to Docker’s built-in routing mesh, you can access any node in the swarm on port 8000 and get routed to the app:\n\n    ``` \n    $ curl http://address-of-other-node:8000\n    Hello World! I have been seen 4 times.\n    ```\n\n3.  Bring the stack down with `docker stack rm`:\n\n    ``` \n    $ docker stack rm stackdemo\n\n    Removing service stackdemo_web\n    Removing service stackdemo_redis\n    Removing network stackdemo_default\n    ```\n\n4.  Bring the registry down with `docker service rm`:\n\n    ``` \n    $ docker service rm registry\n    ```\n\n5.  If you’re just testing things out on a local machine and want to bring your Docker Engine out of swarm mode, use `docker swarm leave`:\n\n    ``` \n    $ docker swarm leave --force\n\n    Node left the swarm.\n    ```\n\n[guide](https://docs.docker.com/search/?q=guide), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [composefile](https://docs.docker.com/search/?q=composefile), [stack](https://docs.docker.com/search/?q=stack), [compose](https://docs.docker.com/search/?q=compose), [deploy](https://docs.docker.com/search/?q=deploy)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/stack-deploy/](https://docs.docker.com/engine/swarm/stack-deploy/)"
- name: Deploy Notary Server with Compose
  id: engine/security/trust/deploying_notary/index
  summary: The easiest way to deploy Notary Server is by using Docker Compose
  description: "# Deploy Notary Server with Compose\n\nThe easiest way to deploy Notary Server is by using Docker Compose. To follow the procedure on this page, you must have already [installed Docker Compose](../../../../compose/install/index).\n\n1.  Clone the Notary repository.\n\n    ``` \n    git clone https://github.com/theupdateframework/notary.git\n    ```\n\n2.  Build and start Notary Server with the sample certificates.\n\n    ``` \n    docker-compose up -d\n    ```\n\nFor more detailed documentation about how to deploy Notary Server, see the [instructions to run a Notary service](https://github.com/theupdateframework/notary/blob/master/docs/running_a_service/) as well as [the Notary repository](https://github.com/theupdateframework/notary) for more information.\n\n1.  Make sure that your Docker or Notary client trusts Notary Server’s certificate before you try to interact with the Notary server.\n\nSee the instructions for [Docker](../../../reference/commandline/cli/index#notary) or for [Notary](https://github.com/docker/notary#using-notary) depending on which one you are using.\n\n## If you want to use Notary in production\n\nCheck back here for instructions after Notary Server has an official stable release. To get a head start on deploying Notary in production, see [the Notary repository](https://github.com/theupdateframework/notary).\n\n[trust](https://docs.docker.com/search/?q=trust), [security](https://docs.docker.com/search/?q=security), [notary](https://docs.docker.com/search/?q=notary), [deployment](https://docs.docker.com/search/?q=deployment)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/trust/deploying_notary/](https://docs.docker.com/engine/security/trust/deploying_notary/)"
- name: Deploy services to a swarm
  id: engine/swarm/services/index
  summary: Swarm services use a declarative model, which means that you define the desired state of the service, and rely upon Docker to maintain this state
  description: "# Deploy services to a swarm\n\nSwarm services use a *declarative* model, which means that you define the desired state of the service, and rely upon Docker to maintain this state. The state includes information such as (but not limited to):\n\n- the image name and tag the service containers should run\n- how many containers participate in the service\n- whether any ports are exposed to clients outside the swarm\n- whether the service should start automatically when Docker starts\n- the specific behavior that happens when the service is restarted (such as whether a rolling restart is used)\n- characteristics of the nodes where the service can run (such as resource constraints and placement preferences)\n\nFor an overview of swarm mode, see [Swarm mode key concepts](../key-concepts/index). For an overview of how services work, see [How services work](../how-swarm-mode-works/services/index).\n\n## Create a service\n\nTo create a single-replica service with no extra configuration, you only need to supply the image name. This command starts an Nginx service with a randomly-generated name and no published ports. This is a naive example, since you can’t interact with the Nginx service.\n\n``` \n$ docker service create nginx\n```\n\nThe service is scheduled on an available node. To confirm that the service was created and started successfully, use the `docker service ls` command:\n\n``` \n$ docker service ls\n\nID                  NAME                MODE                REPLICAS            IMAGE                                                                                             PORTS\na3iixnklxuem        quizzical_lamarr    replicated          1/1                 docker.io/library/nginx@sha256:41ad9967ea448d7c2b203c699b429abe1ed5af331cd92533900c6d77490e0268\n```\n\nCreated services do not always run right away. A service can be in a pending state if its image is unavailable, if no node meets the requirements you configure for the service, or other reasons. See [Pending services](../how-swarm-mode-works/services/index#pending-services) for more information.\n\nTo provide a name for your service, use the `--name` flag:\n\n``` \n$ docker service create --name my_web nginx\n```\n\nJust like with standalone containers, you can specify a command that the service’s containers should run, by adding it after the image name. This example starts a service called `helloworld` which uses an `alpine` image and runs the command `ping docker.com`:\n\n``` \n$ docker service create --name helloworld alpine ping docker.com\n```\n\nYou can also specify an image tag for the service to use. This example modifies the previous one to use the `alpine:3.6` tag:\n\n``` \n$ docker service create --name helloworld alpine:3.6 ping docker.com\n```\n\nFor more details about image tag resolution, see [Specify the image version the service should use](#specify-the-image-version-a-service-should-use).\n\n### gMSA for Swarm\n\nSwarm now allows using a Docker Config as a gMSA credential spec - a requirement for Active Directory-authenticated applications. This reduces the burden of distributing credential specs to the nodes they’re used on.\n\nThe following example assumes a gMSA and its credential spec (called credspec.json) already exists, and that the nodes being deployed to are correctly configured for the gMSA.\n\nTo use a Config as a credential spec, first create the Docker Config containing the credential spec:\n\n``` \n$ docker config create credspec credspec.json\n```\n\nNow, you should have a Docker Config named credspec, and you can create a service using this credential spec. To do so, use the --credential-spec flag with the config name, like this:\n\n``` \n$ docker service create --credential-spec=\"config://credspec\" <your image>\n```\n\nYour service will use the gMSA credential spec when it starts, but unlike a typical Docker Config (used by passing the --config flag), the credential spec will not be mounted into the container.\n\n### Create a service using an image on a private registry\n\nIf your image is available on a private registry which requires login, use the `--with-registry-auth` flag with `docker service create`, after logging in. If your image is stored on `registry.example.com`, which is a private registry, use a command like the following:\n\n``` \n$ docker login registry.example.com\n\n$ docker service  create \\\n  --with-registry-auth \\\n  --name my_service \\\n  registry.example.com/acme/my_image:latest\n```\n\nThis passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes are able to log into the registry and pull the image.\n\n### Provide credential specs for managed service accounts\n\nIn Enterprise Edition 3.0, security is improved through the centralized distribution and management of Group Managed Service Account(gMSA) credentials using Docker Config functionality. Swarm now allows using a Docker Config as a gMSA credential spec, which reduces the burden of distributing credential specs to the nodes on which they are used.\n\n**Note**: This option is only applicable to services using Windows containers.\n\nCredential spec files are applied at runtime, eliminating the need for host-based credential spec files or registry entries - no gMSA credentials are written to disk on worker nodes. You can make credential specs available to Docker Engine running swarm kit worker nodes before a container starts. When deploying a service using a gMSA-based config, the credential spec is passed directly to the runtime of containers in that service.\n\nThe `--credential-spec` must be one of the following formats:\n\n- `file://<filename>`: The referenced file must be present in the `CredentialSpecs` subdirectory in the docker data directory, which defaults to `C:\\ProgramData\\Docker\\` on Windows. For example, specifying `file://spec.json` loads `C:\\ProgramData\\Docker\\CredentialSpecs\\spec.json`.\n- `registry://<value-name>`: The credential spec is read from the Windows registry on the daemon’s host.\n- `config://<config-name>`: The config name is automatically converted to the config ID in the CLI. The credential spec contained in the specified `config` is used.\n\nThe following simple example retrieves the gMSA name and JSON contents from your Active Directory (AD) instance:\n\n``` \n$ name=\"mygmsa\"\n$ contents=\"{...}\"\n$ echo $contents > contents.json\n```\n\nMake sure that the nodes to which you are deploying are correctly configured for the gMSA.\n\nTo use a Config as a credential spec, create a Docker Config in a credential spec file named `credpspec.json`. You can specify any name for the name of the `config`.\n\n``` \n$ docker config create --label com.docker.gmsa.name=mygmsa credspec credspec.json\n```\n\nNow you can create a service using this credential spec. Specify the `--credential-spec` flag with the config name:\n\n``` \n$ docker service create --credential-spec=\"config://credspec\" <your image>\n```\n\nYour service uses the gMSA credential spec when it starts, but unlike a typical Docker Config (used by passing the --config flag), the credential spec is not mounted into the container.\n\n## Update a service\n\nYou can change almost everything about an existing service using the `docker service update` command. When you update a service, Docker stops its containers and restarts them with the new configuration.\n\nSince Nginx is a web service, it works much better if you publish port 80 to clients outside the swarm. You can specify this when you create the service, using the `-p` or `--publish` flag. When updating an existing service, the flag is `--publish-add`. There is also a `--publish-rm` flag to remove a port that was previously published.\n\nAssuming that the `my_web` service from the previous section still exists, use the following command to update it to publish port 80.\n\n``` \n$ docker service update --publish-add 80 my_web\n```\n\nTo verify that it worked, use `docker service ls`:\n\n``` \n$ docker service ls\n\nID                  NAME                MODE                REPLICAS            IMAGE                                                                                             PORTS\n4nhxl7oxw5vz        my_web              replicated          1/1                 docker.io/library/nginx@sha256:41ad9967ea448d7c2b203c699b429abe1ed5af331cd92533900c6d77490e0268   *:0->80/tcp\n```\n\nFor more information on how publishing ports works, see [publish ports](#publish-ports).\n\nYou can update almost every configuration detail about an existing service, including the image name and tag it runs. See [Update a service’s image after creation](#update-a-services-image-after-creation).\n\n## Remove a service\n\nTo remove a service, use the `docker service remove` command. You can remove a service by its ID or name, as shown in the output of the `docker service ls` command. The following command removes the `my_web` service.\n\n``` \n$ docker service remove my_web\n```\n\n## Service configuration details\n\nThe following sections provide details about service configuration. This topic does not cover every flag or scenario. In almost every instance where you can define a configuration at service creation, you can also update an existing service’s configuration in a similar way.\n\nSee the command-line references for [`docker service create`](../../reference/commandline/service_create/index) and [`docker service update`](../../reference/commandline/service_update/index), or run one of those commands with the `--help` flag.\n\n### Configure the runtime environment\n\nYou can configure the following options for the runtime environment in the container:\n\n- environment variables using the `--env` flag\n- the working directory inside the container using the `--workdir` flag\n- the username or UID using the `--user` flag\n\nThe following service’s containers have an environment variable `$MYVAR` set to `myvalue`, run from the `/tmp/` directory, and run as the `my_user` user.\n\n``` \n$ docker service create --name helloworld \\\n  --env MYVAR=myvalue \\\n  --workdir /tmp \\\n  --user my_user \\\n  alpine ping docker.com\n```\n\n### Update the command an existing service runs\n\nTo update the command an existing service runs, you can use the `--args` flag. The following example updates an existing service called `helloworld` so that it runs the command `ping docker.com` instead of whatever command it was running before:\n\n``` \n$ docker service update --args \"ping docker.com\" helloworld\n```\n\n### Specify the image version a service should use\n\nWhen you create a service without specifying any details about the version of the image to use, the service uses the version tagged with the `latest` tag. You can force the service to use a specific version of the image in a few different ways, depending on your desired outcome.\n\nAn image version can be expressed in several different ways:\n\n- If you specify a tag, the manager (or the Docker client, if you use [content trust](#image_resolution_with_trust)) resolves that tag to a digest. When the request to create a container task is received on a worker node, the worker node only sees the digest, not the tag.\n\n  ``` \n  $ docker service create --name=\"myservice\" ubuntu:16.04\n  ```\n\n  Some tags represent discrete releases, such as `ubuntu:16.04`. Tags like this almost always resolve to a stable digest over time. It is recommended that you use this kind of tag when possible.\n\n  Other types of tags, such as `latest` or `nightly`, may resolve to a new digest often, depending on how often an image’s author updates the tag. It is not recommended to run services using a tag which is updated frequently, to prevent different service replica tasks from using different image versions.\n\n- If you don’t specify a version at all, by convention the image’s `latest` tag is resolved to a digest. Workers use the image at this digest when creating the service task.\n\n  Thus, the following two commands are equivalent:\n\n  ``` \n  $ docker service create --name=\"myservice\" ubuntu\n\n  $ docker service create --name=\"myservice\" ubuntu:latest\n  ```\n\n- If you specify a digest directly, that exact version of the image is always used when creating service tasks.\n\n  ``` \n  $ docker service create \\\n      --name=\"myservice\" \\\n      ubuntu:16.04@sha256:35bc48a1ca97c3971611dc4662d08d131869daa692acb281c7e9e052924e38b1\n  ```\n\nWhen you create a service, the image’s tag is resolved to the specific digest the tag points to **at the time of service creation**. Worker nodes for that service use that specific digest forever unless the service is explicitly updated. This feature is particularly important if you do use often-changing tags such as `latest`, because it ensures that all service tasks use the same version of the image.\n\n> **Note**: If [content trust](../../security/trust/index) is enabled, the client actually resolves the image’s tag to a digest before contacting the swarm manager, to verify that the image is signed. Thus, if you use content trust, the swarm manager receives the request pre-resolved. In this case, if the client cannot resolve the image to a digest, the request fails.\n\nIf the manager can’t resolve the tag to a digest, each worker node is responsible for resolving the tag to a digest, and different nodes may use different versions of the image. If this happens, a warning like the following is logged, substituting the placeholders for real information.\n\n``` \nunable to pin image <IMAGE-NAME> to digest: <REASON>\n```\n\nTo see an image’s current digest, issue the command `docker inspect <IMAGE>:<TAG>` and look for the `RepoDigests` line. The following is the current digest for `ubuntu:latest` at the time this content was written. The output is truncated for clarity.\n\n``` \n$ docker inspect ubuntu:latest\n```\n\n``` \n\"RepoDigests\": [\n    \"ubuntu@sha256:35bc48a1ca97c3971611dc4662d08d131869daa692acb281c7e9e052924e38b1\"\n],\n```\n\nAfter you create a service, its image is never updated unless you explicitly run `docker service update` with the `--image` flag as described below. Other update operations such as scaling the service, adding or removing networks or volumes, renaming the service, or any other type of update operation do not update the service’s image.\n\n### Update a service’s image after creation\n\nEach tag represents a digest, similar to a Git hash. Some tags, such as `latest`, are updated often to point to a new digest. Others, such as `ubuntu:16.04`, represent a released software version and are not expected to update to point to a new digest often if at all. When you create a service, it is constrained to create tasks using a specific digest of an image until you update the service using `service update` with the `--image` flag.\n\nWhen you run `service update` with the `--image` flag, the swarm manager queries Docker Hub or your private Docker registry for the digest the tag currently points to and updates the service tasks to use that digest.\n\n> **Note**: If you use [content trust](#image_resolution_with_trust), the Docker client resolves image and the swarm manager receives the image and digest, rather than a tag.\n\nUsually, the manager can resolve the tag to a new digest and the service updates, redeploying each task to use the new image. If the manager can’t resolve the tag or some other problem occurs, the next two sections outline what to expect.\n\n#### If the manager resolves the tag\n\nIf the swarm manager can resolve the image tag to a digest, it instructs the worker nodes to redeploy the tasks and use the image at that digest.\n\n- If a worker has cached the image at that digest, it uses it.\n\n- If not, it attempts to pull the image from Docker Hub or the private registry.\n\n  - If it succeeds, the task is deployed using the new image.\n\n  - If the worker fails to pull the image, the service fails to deploy on that worker node. Docker tries again to deploy the task, possibly on a different worker node.\n\n#### If the manager cannot resolve the tag\n\nIf the swarm manager cannot resolve the image to a digest, all is not lost:\n\n- The manager instructs the worker nodes to redeploy the tasks using the image at that tag.\n\n- If the worker has a locally cached image that resolves to that tag, it uses that image.\n\n- If the worker does not have a locally cached image that resolves to the tag, the worker tries to connect to Docker Hub or the private registry to pull the image at that tag.\n\n  - If this succeeds, the worker uses that image.\n\n  - If this fails, the task fails to deploy and the manager tries again to deploy the task, possibly on a different worker node.\n\n### Publish ports\n\nWhen you create a swarm service, you can publish that service’s ports to hosts outside the swarm in two ways:\n\n- [You can rely on the routing mesh](#publish-a-services-ports-using-the-routing-mesh). When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.\n\n- [You can publish a service task’s port directly on the swarm node](#publish-a-services-ports-directly-on-the-swarm-node) where that service is running. This bypasses the routing mesh and provides the maximum flexibility, including the ability for you to develop your own routing framework. However, you are responsible for keeping track of where each task is running and routing requests to the tasks, and load-balancing across the nodes.\n\nKeep reading for more information and use cases for each of these methods.\n\n#### Publish a service’s ports using the routing mesh\n\nTo publish a service’s ports externally to the swarm, use the `--publish <PUBLISHED-PORT>:<SERVICE-PORT>` flag. The swarm makes the service accessible at the published port **on every swarm node**. If an external host connects to that port on any swarm node, the routing mesh routes it to a task. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond. For more details about swarm service networking, see [Manage swarm service networks](https://docs.docker.com/network/overlay).\n\n##### Example: Run a three-task Nginx service on 10-node swarm\n\nImagine that you have a 10-node swarm, and you deploy an Nginx service running three tasks on a 10-node swarm:\n\n``` \n$ docker service create --name my_web \\\n                        --replicas 3 \\\n                        --publish published=8080,target=80 \\\n                        nginx\n```\n\nThree tasks run on up to three nodes. You don’t need to know which nodes are running the tasks; connecting to port 8080 on **any** of the 10 nodes connects you to one of the three `nginx` tasks. You can test this using `curl`. The following example assumes that `localhost` is one of the swarm nodes. If this is not the case, or `localhost` does not resolve to an IP address on your host, substitute the host’s IP address or resolvable host name.\n\nThe HTML output is truncated:\n\n``` \n$ curl localhost:8080\n\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n...truncated...\n</html>\n```\n\nSubsequent connections may be routed to the same swarm node or a different one.\n\n#### Publish a service’s ports directly on the swarm node\n\nUsing the routing mesh may not be the right choice for your application if you need to make routing decisions based on application state or you need total control of the process for routing requests to your service’s tasks. To publish a service’s port directly on the node where it is running, use the `mode=host` option to the `--publish` flag.\n\n> **Note**: If you publish a service’s ports directly on the swarm node using `mode=host` and also set `published=<PORT>` this creates an implicit limitation that you can only run one task for that service on a given swarm node. You can work around this by specifying `published` without a port definition, which causes Docker to assign a random port for each task.\n>\n> In addition, if you use `mode=host` and you do not use the `--mode=global` flag on `docker service create`, it is difficult to know which nodes are running the service to route work to them.\n\n##### Example: Run an `nginx` web server service on every swarm node\n\n[nginx](https://hub.docker.com/_/nginx/) is an open source reverse proxy, load balancer, HTTP cache, and a web server. If you run nginx as a service using the routing mesh, connecting to the nginx port on any swarm node shows you the web page for (effectively) **a random swarm node** running the service.\n\nThe following example runs nginx as a service on each node in your swarm and exposes nginx port locally on each swarm node.\n\n``` \n$ docker service create \\\n  --mode global \\\n  --publish mode=host,target=80,published=8080 \\\n  --name=nginx \\\n  nginx:latest\n```\n\nYou can reach the nginx server on port 8080 of every swarm node. If you add a node to the swarm, a nginx task is started on it. You cannot start another service or container on any swarm node which binds to port 8080.\n\n> **Note**: This is a naive example. Creating an application-layer routing framework for a multi-tiered service is complex and out of scope for this topic.\n\n### Connect the service to an overlay network\n\nYou can use overlay networks to connect one or more services within the swarm.\n\nFirst, create overlay network on a manager node using the `docker network create` command with the `--driver overlay` flag.\n\n``` \n$ docker network create --driver overlay my-network\n```\n\nAfter you create an overlay network in swarm mode, all manager nodes have access to the network.\n\nYou can create a new service and pass the `--network` flag to attach the service to the overlay network:\n\n``` \n$ docker service create \\\n  --replicas 3 \\\n  --network my-network \\\n  --name my-web \\\n  nginx\n```\n\nThe swarm extends `my-network` to each node running the service.\n\nYou can also connect an existing service to an overlay network using the `--network-add` flag.\n\n``` \n$ docker service update --network-add my-network my-web\n```\n\nTo disconnect a running service from a network, use the `--network-rm` flag.\n\n``` \n$ docker service update --network-rm my-network my-web\n```\n\nFor more information on overlay networking and service discovery, refer to [Attach services to an overlay network](https://docs.docker.com/network/overlay) and [Docker swarm mode overlay network security model](https://docs.docker.com/network/overlay/).\n\n### Grant a service access to secrets\n\nTo create a service with access to Docker-managed secrets, use the `--secret` flag. For more information, see [Manage sensitive strings (secrets) for Docker services](../secrets/index)\n\n### Customize a service’s isolation mode\n\nDocker allows you to specify a swarm service’s isolation mode. **This setting applies to Windows hosts only and is ignored for Linux hosts.** The isolation mode can be one of the following:\n\n- `default`: Use the default isolation mode configured for the Docker host, as configured by the `-exec-opt` flag or `exec-opts` array in `daemon.json`. If the daemon does not specify an isolation technology, `process` is the default for Windows Server, and `hyperv` is the default (and only) choice for Windows 10.\n\n- `process`: Run the service tasks as a separate process on the host.\n\n  > **Note**: `process` isolation mode is only supported on Windows Server. Windows 10 only supports `hyperv` isolation mode.\n\n- `hyperv`: Run the service tasks as isolated `hyperv` tasks. This increases overhead but provides more isolation.\n\nYou can specify the isolation mode when creating or updating a new service using the `--isolation` flag.\n\n### Control service placement\n\nSwarm services provide a few different ways for you to control scale and placement of services on different nodes.\n\n- You can specify whether the service needs to run a specific number of replicas or should run globally on every worker node. See [Replicated or global services](#replicated-or-global-services).\n\n- You can configure the service’s [CPU or memory requirements](#reserve-memory-or-cpus-for-a-service), and the service only runs on nodes which can meet those requirements.\n\n- [Placement constraints](#placement-constraints) let you configure the service to run only on nodes with specific (arbitrary) metadata set, and cause the deployment to fail if appropriate nodes do not exist. For instance, you can specify that your service should only run on nodes where an arbitrary label `pci_compliant` is set to `true`.\n\n- [Placement preferences](#placement-preferences) let you apply an arbitrary label with a range of values to each node, and spread your service’s tasks across those nodes using an algorithm. Currently, the only supported algorithm is `spread`, which tries to place them evenly. For instance, if you label each node with a label `rack` which has a value from 1-10, then specify a placement preference keyed on `rack`, then service tasks are placed as evenly as possible across all nodes with the label `rack`, after taking other placement constraints, placement preferences, and other node-specific limitations into account.\n\n  Unlike constraints, placement preferences are best-effort, and a service does not fail to deploy if no nodes can satisfy the preference. If you specify a placement preference for a service, nodes that match that preference are ranked higher when the swarm managers decide which nodes should run the service tasks. Other factors, such as high availability of the service, also factor into which nodes are scheduled to run service tasks. For example, if you have N nodes with the rack label (and then some others), and your service is configured to run N+1 replicas, the +1 is scheduled on a node that doesn’t already have the service on it if there is one, regardless of whether that node has the `rack` label or not.\n\n#### Replicated or global services\n\nSwarm mode has two types of services: replicated and global. For replicated services, you specify the number of replica tasks for the swarm manager to schedule onto available nodes. For global services, the scheduler places one task on each available node that meets the service’s [placement constraints](#placement-constraints) and [resource requirements](#reserve-memory-or-cpus-for-a-service).\n\nYou control the type of service using the `--mode` flag. If you don’t specify a mode, the service defaults to `replicated`. For replicated services, you specify the number of replica tasks you want to start using the `--replicas` flag. For example, to start a replicated nginx service with 3 replica tasks:\n\n``` \n$ docker service create \\\n  --name my_web \\\n  --replicas 3 \\\n  nginx\n```\n\nTo start a global service on each available node, pass `--mode global` to `docker service create`. Every time a new node becomes available, the scheduler places a task for the global service on the new node. For example to start a service that runs alpine on every node in the swarm:\n\n``` \n$ docker service create \\\n  --name myservice \\\n  --mode global \\\n  alpine top\n```\n\nService constraints let you set criteria for a node to meet before the scheduler deploys a service to the node. You can apply constraints to the service based upon node attributes and metadata or engine metadata. For more information on constraints, refer to the `docker service create` [CLI reference](../../reference/commandline/service_create/index).\n\n#### Reserve memory or CPUs for a service\n\nTo reserve a given amount of memory or number of CPUs for a service, use the `--reserve-memory` or `--reserve-cpu` flags. If no available nodes can satisfy the requirement (for instance, if you request 4 CPUs and no node in the swarm has 4 CPUs), the service remains in a pending state until an appropriate node is available to run its tasks.\n\n##### Out Of Memory Exceptions (OOME)\n\nIf your service attempts to use more memory than the swarm node has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see [Understand the risks of running out of memory](https://docs.docker.com/config/containers/resource_constraints/#understand-the-risks-of-running-out-of-memory).\n\nSwarm services allow you to use resource constraints, placement preferences, and labels to ensure that your service is deployed to the appropriate swarm nodes.\n\n#### Placement constraints\n\nUse placement constraints to control the nodes a service can be assigned to. In the following example, the service only runs on nodes with the [label](../manage-nodes/index#add-or-remove-label-metadata) `region` set to `east`. If no appropriately-labelled nodes are available, tasks will wait in `Pending` until they become available. The `--constraint` flag uses an equality operator (`==` or `!=`). For replicated services, it is possible that all services run on the same node, or each node only runs one replica, or that some nodes don’t run any replicas. For global services, the service runs on every node that meets the placement constraint and any [resource requirements](#reserve-memory-or-cpus-for-a-service).\n\n``` \n$ docker service create \\\n  --name my-nginx \\\n  --replicas 5 \\\n  --constraint node.labels.region==east \\\n  nginx\n```\n\nYou can also use the `constraint` service-level key in a `docker-compose.yml` file.\n\nIf you specify multiple placement constraints, the service only deploys onto nodes where they are all met. The following example limits the service to run on all nodes where `region` is set to `east` and `type` is not set to `devel`:\n\n``` \n$ docker service create \\\n  --name my-nginx \\\n  --mode global \\\n  --constraint node.labels.region==east \\\n  --constraint node.labels.type!=devel \\\n  nginx\n```\n\nYou can also use placement constraints in conjunction with placement preferences and CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\n\nFor more information on constraints, refer to the `docker service create` [CLI reference](../../reference/commandline/service_create/index).\n\n#### Placement preferences\n\nWhile [placement constraints](#placement-constraints) limit the nodes a service can run on, *placement preferences* try to place tasks on appropriate nodes in an algorithmic way (currently, only spread evenly). For instance, if you assign each node a `rack` label, you can set a placement preference to spread the service evenly across nodes with the `rack` label, by value. This way, if you lose a rack, the service is still running on nodes on other racks.\n\nPlacement preferences are not strictly enforced. If no node has the label you specify in your preference, the service is deployed as though the preference were not set.\n\n> Placement preferences are ignored for global services.\n\nThe following example sets a preference to spread the deployment across nodes based on the value of the `datacenter` label. If some nodes have `datacenter=us-east` and others have `datacenter=us-west`, the service is deployed as evenly as possible across the two sets of nodes.\n\n``` \n$ docker service create \\\n  --replicas 9 \\\n  --name redis_2 \\\n  --placement-pref 'spread=node.labels.datacenter' \\\n  redis:3.0.6\n```\n\n> Missing or null labels\n>\n> Nodes which are missing the label used to spread still receive task assignments. As a group, these nodes receive tasks in equal proportion to any of the other groups identified by a specific label value. In a sense, a missing label is the same as having the label with a null value attached to it. If the service should **only** run on nodes with the label being used for the spread preference, the preference should be combined with a constraint.\n\nYou can specify multiple placement preferences, and they are processed in the order they are encountered. The following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):\n\n``` \n$ docker service create \\\n  --replicas 9 \\\n  --name redis_2 \\\n  --placement-pref 'spread=node.labels.datacenter' \\\n  --placement-pref 'spread=node.labels.rack' \\\n  redis:3.0.6\n```\n\nYou can also use placement preferences in conjunction with placement constraints or CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\n\nThis diagram illustrates how placement preferences work:\n\nWhen updating a service with `docker service update`, `--placement-pref-add` appends a new placement preference after all existing placement preferences. `--placement-pref-rm` removes an existing placement preference that matches the argument.\n\n### Configure a service’s update behavior\n\nWhen you create a service, you can specify a rolling update behavior for how the swarm should apply changes to the service when you run `docker service update`. You can also specify these flags as part of the update, as arguments to `docker service update`.\n\nThe `--update-delay` flag configures the time delay between updates to a service task or sets of tasks. You can describe the time `T` as a combination of the number of seconds `Ts`, minutes `Tm`, or hours `Th`. So `10m30s` indicates a 10 minute 30 second delay.\n\nBy default the scheduler updates 1 task at a time. You can pass the `--update-parallelism` flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\n\nWhen an update to an individual task returns a state of `RUNNING`, the scheduler continues the update by continuing to another task until all tasks are updated. If, at any time during an update a task returns `FAILED`, the scheduler pauses the update. You can control the behavior using the `--update-failure-action` flag for `docker service create` or `docker service update`.\n\nIn the example service below, the scheduler applies updates to a maximum of 2 replicas at a time. When an updated task returns either `RUNNING` or `FAILED`, the scheduler waits 10 seconds before stopping the next task to update:\n\n``` \n$ docker service create \\\n  --replicas 10 \\\n  --name my_web \\\n  --update-delay 10s \\\n  --update-parallelism 2 \\\n  --update-failure-action continue \\\n  alpine\n```\n\nThe `--update-max-failure-ratio` flag controls what fraction of tasks can fail during an update before the update as a whole is considered to have failed. For example, with `--update-max-failure-ratio 0.1 --update-failure-action pause`, after 10% of the tasks being updated fail, the update is paused.\n\nAn individual task update is considered to have failed if the task doesn’t start up, or if it stops running within the monitoring period specified with the `--update-monitor` flag. The default value for `--update-monitor` is 30 seconds, which means that a task failing in the first 30 seconds after its started counts towards the service update failure threshold, and a failure after that is not counted.\n\n### Roll back to the previous version of a service\n\nIn case the updated version of a service doesn’t function as expected, it’s possible to manually roll back to the previous version of the service using `docker service update`’s `--rollback` flag. This reverts the service to the configuration that was in place before the most recent `docker service update` command.\n\nOther options can be combined with `--rollback`; for example, `--update-delay 0s` to execute the rollback without a delay between tasks:\n\n``` \n$ docker service update \\\n  --rollback \\\n  --update-delay 0s\n  my_web\n```\n\nYou can configure a service to roll back automatically if a service update fails to deploy. See [Automatically roll back if an update fails](#automatically-roll-back-if-an-update-fails).\n\nManual rollback is handled at the server side, which allows manually-initiated rollbacks to respect the new rollback parameters. Note that `--rollback` cannot be used in conjunction with other flags to `docker service update`.\n\n### Automatically roll back if an update fails\n\nYou can configure a service in such a way that if an update to the service causes redeployment to fail, the service can automatically roll back to the previous configuration. This helps protect service availability. You can set one or more of the following flags at service creation or update. If you do not set a value, the default is used.\n\n| Flag                           | Default | Description                                                                                                                                                                                                                                                                                                             |\n|:-------------------------------|:--------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--rollback-delay`             | `0s`    | Amount of time to wait after rolling back a task before rolling back the next one. A value of `0` means to roll back the second task immediately after the first rolled-back task deploys.                                                                                                                              |\n| `--rollback-failure-action`    | `pause` | When a task fails to roll back, whether to `pause` or `continue` trying to roll back other tasks.                                                                                                                                                                                                                       |\n| `--rollback-max-failure-ratio` | `0`     | The failure rate to tolerate during a rollback, specified as a floating-point number between 0 and 1. For instance, given 5 tasks, a failure ratio of `.2` would tolerate one task failing to roll back. A value of `0` means no failure are tolerated, while a value of `1` means any number of failure are tolerated. |\n| `--rollback-monitor`           | `5s`    | Duration after each task rollback to monitor for failure. If a task stops before this time period has elapsed, the rollback is considered to have failed.                                                                                                                                                               |\n| `--rollback-parallelism`       | `1`     | The maximum number of tasks to roll back in parallel. By default, one task is rolled back at a time. A value of `0` causes all tasks to be rolled back in parallel.                                                                                                                                                     |\n\nThe following example configures a `redis` service to roll back automatically if a `docker service update` fails to deploy. Two tasks can be rolled back in parallel. Tasks are monitored for 20 seconds after rollback to be sure they do not exit, and a maximum failure ratio of 20% is tolerated. Default values are used for `--rollback-delay` and `--rollback-failure-action`.\n\n``` \n$ docker service create --name=my_redis \\\n                        --replicas=5 \\\n                        --rollback-parallelism=2 \\\n                        --rollback-monitor=20s \\\n                        --rollback-max-failure-ratio=.2 \\\n                        redis:latest\n```\n\n### Give a service access to volumes or bind mounts\n\nFor best performance and portability, you should avoid writing important data directly into a container’s writable layer, instead using data volumes or bind mounts. This principle also applies to services.\n\nYou can create two types of mounts for services in a swarm, `volume` mounts or `bind` mounts. Regardless of which type of mount you use, configure it using the `--mount` flag when you create a service, or the `--mount-add` or `--mount-rm` flag when updating an existing service. The default is a data volume if you don’t specify a type.\n\n#### Data volumes\n\nData volumes are storage that exist independently of a container. The lifecycle of data volumes under swarm services is similar to that under containers. Volumes outlive tasks and services, so their removal must be managed separately. Volumes can be created before deploying a service, or if they don’t exist on a particular host when a task is scheduled there, they are created automatically according to the volume specification on the service.\n\nTo use existing data volumes with a service use the `--mount` flag:\n\n``` \n$ docker service create \\\n  --mount src=<VOLUME-NAME>,dst=<CONTAINER-PATH> \\\n  --name myservice \\\n  <IMAGE>\n```\n\nIf a volume with the same `<VOLUME-NAME>` does not exist when a task is scheduled to a particular host, then one is created. The default volume driver is `local`. To use a different volume driver with this create-on-demand pattern, specify the driver and its options with the `--mount` flag:\n\n``` \n$ docker service create \\\n  --mount type=volume,src=<VOLUME-NAME>,dst=<CONTAINER-PATH>,volume-driver=<DRIVER>,volume-opt=<KEY0>=<VALUE0>,volume-opt=<KEY1>=<VALUE1>\n  --name myservice \\\n  <IMAGE>\n```\n\nFor more information on how to create data volumes and the use of volume drivers, see [Use volumes](https://docs.docker.com/storage/volumes/).\n\n#### Bind mounts\n\nBind mounts are file system paths from the host where the scheduler deploys the container for the task. Docker mounts the path into the container. The file system path must exist before the swarm initializes the container for the task.\n\nThe following examples show bind mount syntax:\n\n- To mount a read-write bind:\n\n  ``` \n  $ docker service create \\\n    --mount type=bind,src=<HOST-PATH>,dst=<CONTAINER-PATH> \\\n    --name myservice \\\n    <IMAGE>\n  ```\n\n- To mount a read-only bind:\n\n  ``` \n  $ docker service create \\\n    --mount type=bind,src=<HOST-PATH>,dst=<CONTAINER-PATH>,readonly \\\n    --name myservice \\\n    <IMAGE>\n  ```\n\n> **Important**: Bind mounts can be useful but they can also cause problems. In most cases, it is recommended that you architect your application such that mounting paths from the host is unnecessary. The main risks include the following:\n>\n> - If you bind mount a host path into your service’s containers, the path must exist on every swarm node. The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify.\n>\n> - The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.\n>\n> - Host bind mounts are non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.\n\n### Create services using templates\n\nYou can use templates for some flags of `service create`, using the syntax provided by the Go’s [text/template](https://golang.org/pkg/text/template/) package.\n\nThe following flags are supported:\n\n- `--hostname`\n- `--mount`\n- `--env`\n\nValid placeholders for the Go template are:\n\n| Placeholder       | Description    |\n|:------------------|:---------------|\n| `.Service.ID`     | Service ID     |\n| `.Service.Name`   | Service name   |\n| `.Service.Labels` | Service labels |\n| `.Node.ID`        | Node ID        |\n| `.Node.Hostname`  | Node hostname  |\n| `.Task.Name`      | Task name      |\n| `.Task.Slot`      | Task slot      |\n\n#### Template example\n\nThis example sets the template of the created containers based on the service’s name and the ID of the node where the container is running:\n\n``` \n$ docker service create --name hosttempl \\\n                        --hostname=\"{{.Node.ID}}-{{.Service.Name}}\"\\\n                         busybox top\n```\n\nTo see the result of using the template, use the `docker service ps` and `docker inspect` commands.\n\n``` \n$ docker service ps va8ew30grofhjoychbr6iot8c\n\nID            NAME         IMAGE                                                                                   NODE          DESIRED STATE  CURRENT STATE               ERROR  PORTS\nwo41w8hg8qan  hosttempl.1  busybox:latest@sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912  2e7a8a9c4da2  Running        Running about a minute ago\n```\n\n``` \n$ docker inspect --format=\"{{.Config.Hostname}}\" hosttempl.1.wo41w8hg8qanxwjwsg4kxpprj\n```\n\n## Learn More\n\n- [Swarm administration guide](../admin_guide/index)\n- [Docker Engine command line reference](../../reference/commandline/docker/index)\n- [Swarm mode tutorial](../swarm-tutorial/index)\n\n[guide](https://docs.docker.com/search/?q=guide), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [swarm](https://docs.docker.com/search/?q=swarm), [service](https://docs.docker.com/search/?q=service)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/services/](https://docs.docker.com/engine/swarm/services/)"
- name: Deploy to Kubernetes
  id: get-started/kube-deploy/index
  summary: Download and install Docker Desktop as described in Orientation and setup
  description: "# Deploy to Kubernetes\n\n## Prerequisites\n\n- Download and install Docker Desktop as described in [Orientation and setup](../index).\n\n- Work through containerizing an application in [Part 2](../02_our_app/index).\n\n- Make sure that Kubernetes is enabled on your Docker Desktop:\n\n  - **Mac**: Click the Docker icon in your menu bar, navigate to **Preferences** and make sure there’s a green light beside ‘Kubernetes’.\n  - **Windows**: Click the Docker icon in the system tray and navigate to **Settings** and make sure there’s a green light beside ‘Kubernetes’.\n\n  If Kubernetes isn’t running, follow the instructions in [Orchestration](../orchestration/index) of this tutorial to finish setting it up.\n\n## Introduction\n\nNow that we’ve demonstrated that the individual components of our application run as stand-alone containers, it’s time to arrange for them to be managed by an orchestrator like Kubernetes. Kubernetes provides many tools for scaling, networking, securing and maintaining your containerized applications, above and beyond the abilities of containers themselves.\n\nIn order to validate that our containerized application works well on Kubernetes, we’ll use Docker Desktop’s built in Kubernetes environment right on our development machine to deploy our application, before handing it off to run on a full Kubernetes cluster in production. The Kubernetes environment created by Docker Desktop is *fully featured*, meaning it has all the Kubernetes features your app will enjoy on a real cluster, accessible from the convenience of your development machine.\n\n## Describing apps using Kubernetes YAML\n\nAll containers in Kubernetes are scheduled as *pods*, which are groups of co-located containers that share some resources. Furthermore, in a realistic application we almost never create individual pods; instead, most of our workloads are scheduled as *deployments*, which are scalable groups of pods maintained automatically by Kubernetes. Lastly, all Kubernetes objects can and should be described in manifests called *Kubernetes YAML* files. These YAML files describe all the components and configurations of your Kubernetes app, and can be used to easily create and destroy your app in any Kubernetes environment.\n\n1.  You already wrote a very basic Kubernetes YAML file in the Orchestration overview part of this tutorial. Now, let’s write a slightly more sophisticated YAML file to run and manage our bulletin board. Place the following in a file called `bb.yaml`:\n\n    ``` \n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: bb-demo\n      namespace: default\n    spec:\n      replicas: 1\n      selector:\n        matchLabels:\n          bb: web\n      template:\n        metadata:\n          labels:\n            bb: web\n        spec:\n          containers:\n          - name: bb-site\n            image: getting-started\n    ---\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: bb-entrypoint\n      namespace: default\n    spec:\n      type: NodePort\n      selector:\n        bb: web\n      ports:\n      - port: 3000\n        targetPort: 3000\n        nodePort: 30001\n    ```\n\n    In this Kubernetes YAML file, we have two objects, separated by the `---`:\n\n    - A `Deployment`, describing a scalable group of identical pods. In this case, you’ll get just one `replica`, or copy of your pod, and that pod (which is described under the `template:` key) has just one container in it, based off of your `bulletinboard:1.0` image from the previous step in this tutorial.\n    - A `NodePort` service, which will route traffic from port 30001 on your host to port 3000 inside the pods it routes to, allowing you to reach your bulletin board from the network.\n\n    Also, notice that while Kubernetes YAML can appear long and complicated at first, it almost always follows the same pattern:\n\n    - The `apiVersion`, which indicates the Kubernetes API that parses this object\n    - The `kind` indicating what sort of object this is\n    - Some `metadata` applying things like names to your objects\n    - The `spec` specifying all the parameters and configurations of your object.\n\n## Deploy and check your application\n\n1.  In a terminal, navigate to where you created `bb.yaml` and deploy your application to Kubernetes:\n\n    ``` \n    $ kubectl apply -f bb.yaml\n    ```\n\n    you should see output that looks like the following, indicating your Kubernetes objects were created successfully:\n\n    ``` \n    deployment.apps/bb-demo created\n    service/bb-entrypoint created\n    ```\n\n2.  Make sure everything worked by listing your deployments:\n\n    ``` \n    $ kubectl get deployments\n    ```\n\n    if all is well, your deployment should be listed as follows:\n\n    ``` \n    NAME      READY   UP-TO-DATE   AVAILABLE   AGE\n    bb-demo   1/1     1            1           40s\n    ```\n\n    This indicates all one of the pods you asked for in your YAML are up and running. Do the same check for your services:\n\n    ``` \n    $ kubectl get services\n\n    NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\n    bb-entrypoint   NodePort    10.106.145.116   <none>        3000:30001/TCP   53s\n    kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP          138d\n    ```\n\n    In addition to the default `kubernetes` service, we see our `bb-entrypoint` service, accepting traffic on port 30001/TCP.\n\n3.  Open a browser and visit your bulletin board at `localhost:30001`; you should see your bulletin board, the same as when we ran it as a stand-alone container in [Part 2](../02_our_app/index) of the Quickstart tutorial.\n\n4.  Once satisfied, tear down your application:\n\n    ``` \n    $ kubectl delete -f bb.yaml\n    ```\n\n## Conclusion\n\nAt this point, we have successfully used Docker Desktop to deploy our application to a fully-featured Kubernetes environment on our development machine. We haven’t done much with Kubernetes yet, but the door is now open; you can begin adding other components to your app and taking advantage of all the features and power of Kubernetes, right on your own machine.\n\nIn addition to deploying to Kubernetes, we have also described our application as a Kubernetes YAML file. This simple text file contains everything we need to create our application in a running state. We can check it into version control and share it with our colleagues, allowing us to distribute our applications to other clusters (like the testing and production clusters that probably come after our development environments) easily.\n\n## Kubernetes references\n\nFurther documentation for all new Kubernetes objects used in this article are available here:\n\n- [Kubernetes Pods](https://kubernetes.io/docs/concepts/workloads/pods/pod/)\n- [Kubernetes Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)\n- [Kubernetes Services](https://kubernetes.io/docs/concepts/services-networking/service/)\n\n[kubernetes](https://docs.docker.com/search/?q=kubernetes), [pods](https://docs.docker.com/search/?q=pods), [deployments](https://docs.docker.com/search/?q=deployments), [kubernetes services](https://docs.docker.com/search/?q=kubernetes%20services)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/kube-deploy/](https://docs.docker.com/get-started/kube-deploy/)"
- name: Deploy to Swarm
  id: get-started/swarm-deploy/index
  summary: Download and install Docker Desktop as described in Orientation and setup
  description: "# Deploy to Swarm\n\n## Prerequisites\n\n- Download and install Docker Desktop as described in [Orientation and setup](../index).\n\n- Work through containerizing an application in [Part 2](../02_our_app/index).\n\n- Make sure that Swarm is enabled on your Docker Desktop by typing `docker system info`, and looking for a message `Swarm: active` (you might have to scroll up a little).\n\n  If Swarm isn’t running, simply type `docker swarm init` in a shell prompt to set it up.\n\n## Introduction\n\nNow that we’ve demonstrated that the individual components of our application run as stand-alone containers and shown how to deploy it using Kubernetes, let’s look at how to arrange for them to be managed by Docker Swarm. Swarm provides many tools for scaling, networking, securing and maintaining your containerized applications, above and beyond the abilities of containers themselves.\n\nIn order to validate that our containerized application works well on Swarm, we’ll use Docker Desktop’s built in Swarm environment right on our development machine to deploy our application, before handing it off to run on a full Swarm cluster in production. The Swarm environment created by Docker Desktop is *fully featured*, meaning it has all the Swarm features your app will enjoy on a real cluster, accessible from the convenience of your development machine.\n\n## Describe apps using stack files\n\nSwarm never creates individual containers like we did in the previous step of this tutorial. Instead, all Swarm workloads are scheduled as *services*, which are scalable groups of containers with added networking features maintained automatically by Swarm. Furthermore, all Swarm objects can and should be described in manifests called *stack files*. These YAML files describe all the components and configurations of your Swarm app, and can be used to easily create and destroy your app in any Swarm environment.\n\nLet’s write a simple stack file to run and manage our bulletin board. Place the following in a file called `bb-stack.yaml`:\n\n``` \nversion: '3.7'\n\nservices:\n  bb-app:\n    image: bulletinboard:1.0\n    ports:\n      - \"8000:8080\"\n```\n\nIn this Swarm YAML file, we have just one object: a `service`, describing a scalable group of identical containers. In this case, you’ll get just one container (the default), and that container will be based on your `bulletinboard:1.0` image created in [Part 2](../02_our_app/index) of the Quickstart tutorial. In addition, We’ve asked Swarm to forward all traffic arriving at port 8000 on our development machine to port 8080 inside our bulletin board container.\n\n> **Kubernetes Services and Swarm Services are very different!** Despite the similar name, the two orchestrators mean very different things by the term ‘service’. In Swarm, a service provides both scheduling *and* networking facilities, creating containers and providing tools for routing traffic to them. In Kubernetes, scheduling and networking are handled separately: *deployments* (or other controllers) handle the scheduling of containers as pods, while *services* are responsible only for adding networking features to those pods.\n\n## Deploy and check your application\n\n1.  Deploy your application to Swarm:\n\n    ``` \n    $ docker stack deploy -c bb-stack.yaml demo\n    ```\n\n    If all goes well, Swarm will report creating all your stack objects with no complaints:\n\n    ``` \n    Creating network demo_default\n    Creating service demo_bb-app\n    ```\n\n    Notice that in addition to your service, Swarm also creates a Docker network by default to isolate the containers deployed as part of your stack.\n\n2.  Make sure everything worked by listing your service:\n\n    ``` \n    $ docker service ls\n    ```\n\n    If all has gone well, your service will report with 1/1 of its replicas created:\n\n    ``` \n    ID                  NAME                MODE                REPLICAS            IMAGE               PORTS\n    il7elwunymbs        demo_bb-app         replicated          1/1                 bulletinboard:1.0   *:8000->8080/tcp\n    ```\n\n    This indicates 1/1 containers you asked for as part of your services are up and running. Also, we see that port 8000 on your development machine is getting forwarded to port 8080 in your bulletin board container.\n\n3.  Open a browser and visit your bulletin board at `localhost:8000`; you should see your bulletin board, the same as when we ran it as a stand-alone container in Part 2 of the Quickstart tutorial.\n\n4.  Once satisfied, tear down your application:\n\n    ``` \n    $ docker stack rm demo\n    ```\n\n## Conclusion\n\nAt this point, we have successfully used Docker Desktop to deploy our application to a fully-featured Swarm environment on our development machine. We haven’t done much with Swarm yet, but the door is now open: you can begin adding other components to your app and taking advantage of all the features and power of Swarm, right on your own machine.\n\nIn addition to deploying to Swarm, we have also described our application as a stack file. This simple text file contains everything we need to create our application in a running state; we can check it into version control and share it with our colleagues, allowing us to distribute our applications to other clusters (like the testing and production clusters that probably come after our development environments) easily.\n\n## Swarm and CLI references\n\nFurther documentation for all new Swarm objects and CLI commands used in this article are available here:\n\n- [Swarm Mode](../../engine/swarm/index)\n- [Swarm Mode Services](../../engine/swarm/how-swarm-mode-works/services/index)\n- [Swarm Stacks](../../engine/swarm/stack-deploy/index)\n- [`docker stack *`](../../engine/reference/commandline/stack/index)\n- [`docker service *`](../../engine/reference/commandline/service/index)\n\n[swarm](https://docs.docker.com/search/?q=swarm), [swarm services](https://docs.docker.com/search/?q=swarm%20services), [stacks](https://docs.docker.com/search/?q=stacks)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/swarm-deploy/](https://docs.docker.com/get-started/swarm-deploy/)"
- name: Deprecated Engine Features
  id: engine/deprecated/index
  summary: This page provides an overview of features that are deprecated in Engine
  description: "# Deprecated Engine Features\n\nThis page provides an overview of features that are deprecated in Engine. Changes in packaging, and supported (Linux) distributions are not included. To learn about end of support for Linux distributions, refer to the [release notes](../release-notes/index).\n\n## Feature Deprecation Policy\n\nAs changes are made to Docker there may be times when existing features need to be removed or replaced with newer features. Before an existing feature is removed it is labeled as “deprecated” within the documentation and remains in Docker for at least one stable release unless specified explicitly otherwise. After that time it may be removed.\n\nUsers are expected to take note of the list of deprecated features each release and plan their migration away from those features, and (if applicable) towards the replacement features as soon as possible.\n\n## Deprecated Engine Features\n\nThe table below provides an overview of the current status of deprecated features:\n\n- **Deprecated**: the feature is marked “deprecated” and should no longer be used. The feature may be removed, disabled, or change behavior in a future release. The *“Deprecated”* column contains the release in which the feature was marked deprecated, whereas the *“Remove”* column contains a tentative release in which the feature is to be removed. If no release is included in the *“Remove”* column, the release is yet to be decided on.\n- **Removed**: the feature was removed, disabled, or hidden. Refer to the linked section for details. Some features are “soft” deprecated, which means that they remain functional for backward compatibility, and to allow users to migrate to alternatives. In such cases, a warning may be printed, and users should not rely on this feature.\n\n| Status     | Feature                                                                                                                            | Deprecated | Remove |\n|------------|------------------------------------------------------------------------------------------------------------------------------------|------------|--------|\n| Deprecated | [Support for encrypted TLS private keys](#support-for-encrypted-tls-private-keys)                                                  | v20.10     | \\-     |\n| Deprecated | [Kubernetes stack and context support](#kubernetes-stack-and-context-support)                                                      | v20.10     | \\-     |\n| Deprecated | [Pulling images from non-compliant image registries](#pulling-images-from-non-compliant-image-registries)                          | v20.10     | \\-     |\n| Deprecated | [Linux containers on Windows (LCOW)](#linux-containers-on-windows-lcow-experimental)                                               | v20.10     | \\-     |\n| Deprecated | [BLKIO weight options with cgroups v1](#blkio-weight-options-with-cgroups-v1)                                                      | v20.10     | \\-     |\n| Deprecated | [Kernel memory limit](#kernel-memory-limit)                                                                                        | v20.10     | \\-     |\n| Deprecated | [Classic Swarm and overlay networks using external key/value stores](#classic-swarm-and-overlay-networks-using-cluster-store)      | v20.10     | \\-     |\n| Deprecated | [Support for the legacy `~/.dockercfg` configuration file for authentication](#support-for-legacy-dockercfg-configuration-files)   | v20.10     | \\-     |\n| Deprecated | [CLI plugins support](#cli-plugins-support)                                                                                        | v20.10     | \\-     |\n| Deprecated | [Dockerfile legacy `ENV name value` syntax](#dockerfile-legacy-env-name-value-syntax)                                              | v20.10     | \\-     |\n| Removed    | [`docker build --stream` flag (experimental)](#docker-build---stream-flag-experimental)                                            | v20.10     | v20.10 |\n| Deprecated | [`fluentd-async-connect` log opt](#fluentd-async-connect-log-opt)                                                                  | v20.10     | \\-     |\n| Deprecated | [Configuration options for experimental CLI features](#configuration-options-for-experimental-cli-features)                        | v19.03     | v20.10 |\n| Deprecated | [Pushing and pulling with image manifest v2 schema 1](#pushing-and-pulling-with-image-manifest-v2-schema-1)                        | v19.03     | v20.10 |\n| Removed    | [`docker engine` subcommands](#docker-engine-subcommands)                                                                          | v19.03     | v20.10 |\n| Removed    | [Top-level `docker deploy` subcommand (experimental)](#top-level-docker-deploy-subcommand-experimental)                            | v19.03     | v20.10 |\n| Removed    | [`docker stack deploy` using “dab” files (experimental)](#docker-stack-deploy-using-dab-files-experimental)                        | v19.03     | v20.10 |\n| Deprecated | [AuFS storage driver](#aufs-storage-driver)                                                                                        | v19.03     | \\-     |\n| Deprecated | [Legacy “overlay” storage driver](#legacy-overlay-storage-driver)                                                                  | v18.09     | \\-     |\n| Deprecated | [Device mapper storage driver](#device-mapper-storage-driver)                                                                      | v18.09     | \\-     |\n| Removed    | [Use of reserved namespaces in engine labels](#use-of-reserved-namespaces-in-engine-labels)                                        | v18.06     | v20.10 |\n| Removed    | [`--disable-legacy-registry` override daemon option](#--disable-legacy-registry-override-daemon-option)                            | v17.12     | v19.03 |\n| Removed    | [Interacting with V1 registries](#interacting-with-v1-registries)                                                                  | v17.06     | v17.12 |\n| Removed    | [Asynchronous `service create` and `service update` as default](#asynchronous-service-create-and-service-update-as-default)        | v17.05     | v17.10 |\n| Removed    | [`-g` and `--graph` flags on `dockerd`](#-g-and---graph-flags-on-dockerd)                                                          | v17.05     | \\-     |\n| Deprecated | [Top-level network properties in NetworkSettings](#top-level-network-properties-in-networksettings)                                | v1.13      | v17.12 |\n| Removed    | [`filter` param for `/images/json` endpoint](#filter-param-for-imagesjson-endpoint)                                                | v1.13      | v20.10 |\n| Removed    | [`repository:shortid` image references](#repositoryshortid-image-references)                                                       | v1.13      | v17.12 |\n| Removed    | [`docker daemon` subcommand](#docker-daemon-subcommand)                                                                            | v1.13      | v17.12 |\n| Removed    | [Duplicate keys with conflicting values in engine labels](#duplicate-keys-with-conflicting-values-in-engine-labels)                | v1.13      | v17.12 |\n| Deprecated | [`MAINTAINER` in Dockerfile](#maintainer-in-dockerfile)                                                                            | v1.13      | \\-     |\n| Deprecated | [API calls without a version](#api-calls-without-a-version)                                                                        | v1.13      | v17.12 |\n| Removed    | [Backing filesystem without `d_type` support for overlay/overlay2](#backing-filesystem-without-d_type-support-for-overlayoverlay2) | v1.13      | v17.12 |\n| Removed    | [`--automated` and `--stars` flags on `docker search`](#--automated-and---stars-flags-on-docker-search)                            | v1.12      | v20.10 |\n| Deprecated | [`-h` shorthand for `--help`](#-h-shorthand-for---help)                                                                            | v1.12      | v17.09 |\n| Removed    | [`-e` and `--email` flags on `docker login`](#-e-and---email-flags-on-docker-login)                                                | v1.11      | v17.06 |\n| Deprecated | [Separator (`:`) of `--security-opt` flag on `docker run`](#separator--of---security-opt-flag-on-docker-run)                       | v1.11      | v17.06 |\n| Deprecated | [Ambiguous event fields in API](#ambiguous-event-fields-in-api)                                                                    | v1.10      | \\-     |\n| Removed    | [`-f` flag on `docker tag`](#-f-flag-on-docker-tag)                                                                                | v1.10      | v1.12  |\n| Removed    | [HostConfig at API container start](#hostconfig-at-api-container-start)                                                            | v1.10      | v1.12  |\n| Removed    | [`--before` and `--since` flags on `docker ps`](#--before-and---since-flags-on-docker-ps)                                          | v1.10      | v1.12  |\n| Removed    | [Driver-specific log tags](#driver-specific-log-tags)                                                                              | v1.9       | v1.12  |\n| Removed    | [Docker Content Trust `ENV` passphrase variables name change](#docker-content-trust-env-passphrase-variables-name-change)          | v1.9       | v1.12  |\n| Removed    | [`/containers/(id or name)/copy` endpoint](#containersid-or-namecopy-endpoint)                                                     | v1.8       | v1.12  |\n| Removed    | [LXC built-in exec driver](#lxc-built-in-exec-driver)                                                                              | v1.8       | v1.10  |\n| Removed    | [Old Command Line Options](#old-command-line-options)                                                                              | v1.8       | v1.10  |\n| Removed    | [`--api-enable-cors` flag on `dockerd`](#--api-enable-cors-flag-on-dockerd)                                                        | v1.6       | v17.09 |\n| Removed    | [`--run` flag on `docker commit`](#--run-flag-on-docker-commit)                                                                    | v0.10      | v1.13  |\n| Removed    | [Three arguments form in `docker import`](#three-arguments-form-in-docker-import)                                                  | v0.6.7     | v1.12  |\n\n### Support for encrypted TLS private keys\n\n**Deprecated in Release: v20.10**\n\nUse of encrypted TLS private keys has been deprecated, and will be removed in a future release. Golang has deprecated support for legacy PEM encryption (as specified in [RFC 1423](https://datatracker.ietf.org/doc/html/rfc1423)), as it is insecure by design (see <https://go-review.googlesource.com/c/go/+/264159>).\n\n### Kubernetes stack and context support\n\n**Deprecated in Release: v20.10**\n\nFollowing the deprecation of [Compose on Kubernetes](https://github.com/docker/compose-on-kubernetes), support for Kubernetes in the `stack` and `context` commands in the docker CLI is now marked as deprecated as well.\n\n### Pulling images from non-compliant image registries\n\n**Deprecated in Release: v20.10**\n\nDocker Engine v20.10 and up includes optimizations to verify if images in the local image cache need updating before pulling, preventing the Docker Engine from making unnecessary API requests. These optimizations require the container image registry to conform to the [Open Container Initiative Distribution Specification](https://github.com/opencontainers/distribution-spec).\n\nWhile most registries conform to the specification, we encountered some registries to be non-compliant, resulting in `docker pull` to fail.\n\nAs a temporary solution, Docker Engine v20.10 includes a fallback mechanism to allow `docker pull` to be functional when using a non-compliant registry. A warning message is printed in this situation:\n\n``` \nWARNING Failed to pull manifest by the resolved digest. This registry does not\n        appear to conform to the distribution registry specification; falling back to\n        pull by tag. This fallback is DEPRECATED, and will be removed in a future\n        release.\n```\n\nThe fallback is added to allow users to either migrate their images to a compliant registry, or for these registries to become compliant.\n\nNote that this fallback only addresses failures on `docker pull`. Other commands, such as `docker stack deploy`, or pulling images with `containerd` will continue to fail.\n\nGiven that other functionality is still broken with these registries, we consider this fallback a *temporary* solution, and will remove the fallback in an upcoming major release.\n\n### Linux containers on Windows (LCOW) (experimental)\n\n**Deprecated in Release: v20.10**\n\nThe experimental feature to run Linux containers on Windows (LCOW) was introduced as a technical preview in Docker 17.09. While many enhancements were made after its introduction, the feature never reached completeness, and development has now stopped in favor of running docker natively on Linux in WSL2.\n\nDevelopers who want to run Linux workloads on a Windows host are encouraged to use [Docker Desktop with WSL2](https://docs.docker.com/docker-for-windows/wsl/) instead.\n\n### BLKIO weight options with cgroups v1\n\n**Deprecated in Release: v20.10**\n\nSpecifying blkio weight (`docker run --blkio-weight` and `docker run --blkio-weight-device`) is now marked as deprecated when using cgroups v1 because the corresponding features were [removed in Linux kernel v5.0 and up](https://github.com/torvalds/linux/commit/f382fb0bcef4c37dc049e9f6963e3baf204d815c). When using cgroups v2, the `--blkio-weight` options are implemented using [\\`io.weight](https://github.com/torvalds/linux/blob/v5.0/Documentation/admin-guide/cgroup-v2.rst#io).\n\n### Kernel memory limit\n\n**Deprecated in Release: v20.10**\n\nSpecifying kernel memory limit (`docker run --kernel-memory`) is now marked as deprecated, as [Linux kernel deprecated `kmem.limit_in_bytes` in v5.4](https://github.com/torvalds/linux/commit/0158115f702b0ba208ab0b5adf44cae99b3ebcc7).\n\n### Classic Swarm and overlay networks using cluster store\n\n**Deprecated in Release: v20.10**\n\nStandalone (“classic”) Swarm has been deprecated, and with that the use of overlay networks using an external key/value store. The corresponding`--cluster-advertise`, `--cluster-store`, and `--cluster-store-opt` daemon options have been marked deprecated, and will be disabled or removed in a future release.\n\n### Support for legacy `~/.dockercfg` configuration files\n\n**Deprecated in Release: v20.10**\n\nThe docker CLI up until v1.7.0 used the `~/.dockercfg` file to store credentials after authenticating to a registry (`docker login`). Docker v1.7.0 replaced this file with a new CLI configuration file, located in `~/.docker/config.json`. When implementing the new configuration file, the old file (and file-format) was kept as a fall-back, to assist existing users with migrating to the new file.\n\nGiven that the old file format encourages insecure storage of credentials (credentials are stored unencrypted), and that no version of the CLI since Docker v1.7.0 has created this file, the file is marked deprecated, and support for this file will be removed in a future release.\n\n### Configuration options for experimental CLI features\n\nThe `DOCKER_CLI_EXPERIMENTAL` environment variable and the corresponding `experimental` field in the CLI configuration file are deprecated. Experimental features will be enabled by default, and these configuration options will no longer be functional.\n\n### CLI plugins support\n\n**Deprecated in Release: v20.10**\n\nCLI Plugin API is now marked as deprecated.\n\n### Dockerfile legacy `ENV name value` syntax\n\n**Deprecated in Release: v20.10**\n\nThe Dockerfile `ENV` instruction allows values to be set using either `ENV name=value` or `ENV name value`. The latter (`ENV name value`) form can be ambiguous, for example, the following defines a single env-variable (`ONE`) with value `\"TWO= THREE=world\"`, but may have intended to be setting three env-vars:\n\n``` \nENV ONE TWO= THREE=world\n```\n\nThis format also does not allow setting multiple environment-variables in a single `ENV` line in the Dockerfile.\n\nUse of the `ENV name value` syntax is discouraged, and may be removed in a future release. Users are encouraged to update their Dockerfiles to use the `ENV name=value` syntax, for example:\n\n``` \nENV ONE=\"\" TWO=\"\" THREE=\"world\"\n```\n\n### `docker build --stream` flag (experimental)\n\n**Deprecated in Release: v20.10** **Removed in Release: v20.10**\n\nDocker v17.07 introduced an experimental `--stream` flag on `docker build` which allowed the build-context to be incrementally sent to the daemon, instead of unconditionally sending the whole build-context.\n\nThis functionality has been reimplemented as part of BuildKit, which uses streaming by default and the `--stream` option will be ignored when using the classic builder, printing a deprecation warning instead.\n\nUsers that want to use this feature are encouraged to enable BuildKit by setting the `DOCKER_BUILDKIT=1` environment variable or through the daemon or CLI configuration files.\n\n### `fluentd-async-connect` log opt\n\n**Deprecated in Release: v20.10**\n\nThe `--log-opt fluentd-async-connect` option for the fluentd logging driver is [deprecated in favor of `--log-opt fluentd-async`](https://github.com/moby/moby/pull/39086). A deprecation message is logged in the daemon logs if the old option is used:\n\n``` \nfluent#New: AsyncConnect is now deprecated, please use Async instead\n```\n\nUsers are encouraged to use the `fluentd-async` option going forward, as support for the old option will be removed in a future release.\n\n### Pushing and pulling with image manifest v2 schema 1\n\n**Deprecated in Release: v19.03**\n\n**Target For Removal In Release: v20.10**\n\nThe image manifest [v2 schema 1](https://github.com/docker/distribution/blob/fda42e5ef908bdba722d435ff1f330d40dfcd56c/docs/spec/manifest-v2-1/) format is deprecated in favor of the [v2 schema 2](https://github.com/docker/distribution/blob/fda42e5ef908bdba722d435ff1f330d40dfcd56c/docs/spec/manifest-v2-2/) format.\n\nIf the registry you are using still supports v2 schema 1, urge their administrators to move to v2 schema 2.\n\n### `docker engine` subcommands\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nThe `docker engine activate`, `docker engine check`, and `docker engine update` provided an alternative installation method to upgrade Docker Community engines to Docker Enterprise, using an image-based distribution of the Docker Engine.\n\nThis feature was only available on Linux, and only when executed on a local node. Given the limitations of this feature, and the feature not getting widely adopted, the `docker engine` subcommands will be removed, in favor of installation through standard package managers.\n\n### Top-level `docker deploy` subcommand (experimental)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nThe top-level `docker deploy` command (using the “Docker Application Bundle” (.dab) file format was introduced as an experimental feature in Docker 1.13 / 17.03, but superseded by support for Docker Compose files using the `docker stack deploy` subcommand.\n\n### `docker stack deploy` using “dab” files (experimental)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nWith no development being done on this feature, and no active use of the file format, support for the DAB file format and the top-level docker deploy command (hidden by default in 19.03), will be removed, in favour of `docker stack deploy` using compose files.\n\n### AuFS storage driver\n\n**Deprecated in Release: v19.03**\n\nThe `aufs` storage driver is deprecated in favor of `overlay2`, and will be removed in a future release. Users of the `aufs` storage driver are recommended to migrate to a different storage driver, such as `overlay2`, which is now the default storage driver.\n\nThe `aufs` storage driver facilitates running Docker on distros that have no support for OverlayFS, such as Ubuntu 14.04 LTS, which originally shipped with a 3.14 kernel.\n\nNow that Ubuntu 14.04 is no longer a supported distro for Docker, and `overlay2` is available to all supported distros (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to continue maintenance of the `aufs` storage driver.\n\n### Legacy “overlay” storage driver\n\n**Deprecated in Release: v18.09**\n\nThe `overlay` storage driver is deprecated in favor of the `overlay2` storage driver, which has all the benefits of `overlay`, without its limitations (excessive inode consumption). The legacy `overlay` storage driver will be removed in a future release. Users of the `overlay` storage driver should migrate to the `overlay2` storage driver.\n\nThe legacy `overlay` storage driver allowed using overlayFS-backed filesystems on pre 4.x kernels. Now that all supported distributions are able to run `overlay2` (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to keep maintaining the `overlay` storage driver.\n\n### Device mapper storage driver\n\n**Deprecated in Release: v18.09**\n\nThe `devicemapper` storage driver is deprecated in favor of `overlay2`, and will be removed in a future release. Users of the `devicemapper` storage driver are recommended to migrate to a different storage driver, such as `overlay2`, which is now the default storage driver.\n\nThe `devicemapper` storage driver facilitates running Docker on older (3.x) kernels that have no support for other storage drivers (such as overlay2, or AUFS).\n\nNow that support for `overlay2` is added to all supported distros (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to continue maintenance of the `devicemapper` storage driver.\n\n### Use of reserved namespaces in engine labels\n\n**Deprecated in Release: v18.06**\n\n**Removed In Release: v20.10**\n\nThe namespaces `com.docker.*`, `io.docker.*`, and `org.dockerproject.*` in engine labels were always documented to be reserved, but there was never any enforcement.\n\nUsage of these namespaces will now cause a warning in the engine logs to discourage their use, and will error instead in v20.10 and above.\n\n### `--disable-legacy-registry` override daemon option\n\n**Disabled In Release: v17.12**\n\n**Removed In Release: v19.03**\n\nThe `--disable-legacy-registry` flag was disabled in Docker 17.12 and will print an error when used. For this error to be printed, the flag itself is still present, but hidden. The flag has been removed in Docker 19.03.\n\n### Interacting with V1 registries\n\n**Disabled By Default In Release: v17.06**\n\n**Removed In Release: v17.12**\n\nVersion 1.8.3 added a flag (`--disable-legacy-registry=false`) which prevents the docker daemon from `pull`, `push`, and `login` operations against v1 registries. Though enabled by default, this signals the intent to deprecate the v1 protocol.\n\nSupport for the v1 protocol to the public registry was removed in 1.13. Any mirror configurations using v1 should be updated to use a [v2 registry mirror](https://docs.docker.com/registry/recipes/mirror/).\n\nStarting with Docker 17.12, support for V1 registries has been removed, and the `--disable-legacy-registry` flag can no longer be used, and `dockerd` will fail to start when set.\n\n### Asynchronous `service create` and `service update` as default\n\n**Deprecated In Release: v17.05**\n\n**Disabled by default in release: [v17.10](https://github.com/docker/docker-ce/releases/tag/v17.10.0-ce)**\n\nDocker 17.05 added an optional `--detach=false` option to make the `docker service create` and `docker service update` work synchronously. This option will be enabled by default in Docker 17.10, at which point the `--detach` flag can be used to use the previous (asynchronous) behavior.\n\nThe default for this option will also be changed accordingly for `docker service rollback` and `docker service scale` in Docker 17.10.\n\n### `-g` and `--graph` flags on `dockerd`\n\n**Deprecated In Release: v17.05**\n\nThe `-g` or `--graph` flag for the `dockerd` or `docker daemon` command was used to indicate the directory in which to store persistent data and resource configuration and has been replaced with the more descriptive `--data-root` flag.\n\nThese flags were added before Docker 1.0, so will not be *removed*, only *hidden*, to discourage their use.\n\n### Top-level network properties in NetworkSettings\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Target For Removal In Release: v17.12**\n\nWhen inspecting a container, `NetworkSettings` contains top-level information about the default (“bridge”) network;\n\n`EndpointID`, `Gateway`, `GlobalIPv6Address`, `GlobalIPv6PrefixLen`, `IPAddress`, `IPPrefixLen`, `IPv6Gateway`, and `MacAddress`.\n\nThese properties are deprecated in favor of per-network properties in `NetworkSettings.Networks`. These properties were already “deprecated” in docker 1.9, but kept around for backward compatibility.\n\nRefer to [\\#17538](https://github.com/docker/docker/pull/17538) for further information.\n\n### `filter` param for `/images/json` endpoint\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v20.10**\n\nThe `filter` param to filter the list of image by reference (name or name:tag) is now implemented as a regular filter, named `reference`.\n\n### `repository:shortid` image references\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe `repository:shortid` syntax for referencing images is very little used, collides with tag references, and can be confused with digest references.\n\nSupport for the `repository:shortid` notation to reference images was removed in Docker 17.12.\n\n### `docker daemon` subcommand\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe daemon is moved to a separate binary (`dockerd`), and should be used instead.\n\n### Duplicate keys with conflicting values in engine labels\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nWhen setting duplicate keys with conflicting values, an error will be produced, and the daemon will fail to start.\n\n### `MAINTAINER` in Dockerfile\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n`MAINTAINER` was an early very limited form of `LABEL` which should be used instead.\n\n### API calls without a version\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Target For Removal In Release: v17.12**\n\nAPI versions should be supplied to all API calls to ensure compatibility with future Engine versions. Instead of just requesting, for example, the URL `/containers/json`, you must now request `/v1.25/containers/json`.\n\n### Backing filesystem without `d_type` support for overlay/overlay2\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe overlay and overlay2 storage driver does not work as expected if the backing filesystem does not support `d_type`. For example, XFS does not support `d_type` if it is formatted with the `ftype=0` option.\n\nStarting with Docker 17.12, new installations will not support running overlay2 on a backing filesystem without `d_type` support. For existing installations that upgrade to 17.12, a warning will be printed.\n\nPlease also refer to [\\#27358](https://github.com/docker/docker/issues/27358) for further information.\n\n### `--automated` and `--stars` flags on `docker search`\n\n**Deprecated in Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\n**Removed In Release: v20.10**\n\nThe `docker search --automated` and `docker search --stars` options are deprecated. Use `docker search --filter=is-automated=<true|false>` and `docker search --filter=stars=...` instead.\n\n### `-h` shorthand for `--help`\n\n**Deprecated In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\n**Target For Removal In Release: v17.09**\n\nThe shorthand (`-h`) is less common than `--help` on Linux and cannot be used on all subcommands (due to it conflicting with, e.g. `-h` / `--hostname` on `docker create`). For this reason, the `-h` shorthand was not printed in the “usage” output of subcommands, nor documented, and is now marked “deprecated”.\n\n### `-e` and `--email` flags on `docker login`\n\n**Deprecated In Release: [v1.11.0](https://github.com/docker/docker/releases/tag/v1.11.0)**\n\n**Removed In Release: [v17.06](https://github.com/docker/docker-ce/releases/tag/v17.06.0-ce)**\n\nThe docker login command is removing the ability to automatically register for an account with the target registry if the given username doesn’t exist. Due to this change, the email flag is no longer required, and will be deprecated.\n\n### Separator (`:`) of `--security-opt` flag on `docker run`\n\n**Deprecated In Release: [v1.11.0](https://github.com/docker/docker/releases/tag/v1.11.0)**\n\n**Target For Removal In Release: v17.06**\n\nThe flag `--security-opt` doesn’t use the colon separator (`:`) anymore to divide keys and values, it uses the equal symbol (`=`) for consistency with other similar flags, like `--storage-opt`.\n\n### Ambiguous event fields in API\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe fields `ID`, `Status` and `From` in the events API have been deprecated in favor of a more rich structure. See the events API documentation for the new format.\n\n### `-f` flag on `docker tag`\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nTo make tagging consistent across the various `docker` commands, the `-f` flag on the `docker tag` command is deprecated. It is not longer necessary to specify `-f` to move a tag from one image to another. Nor will `docker` generate an error if the `-f` flag is missing and the specified tag is already in use.\n\n### HostConfig at API container start\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nPassing an `HostConfig` to `POST /containers/{name}/start` is deprecated in favor of defining it at container creation (`POST /containers/create`).\n\n### `--before` and `--since` flags on `docker ps`\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe `docker ps --before` and `docker ps --since` options are deprecated. Use `docker ps --filter=before=...` and `docker ps --filter=since=...` instead.\n\n### Driver-specific log tags\n\n**Deprecated In Release: [v1.9.0](https://github.com/docker/docker/releases/tag/v1.9.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nLog tags are now generated in a standard way across different logging drivers. Because of which, the driver specific log tag options `syslog-tag`, `gelf-tag` and `fluentd-tag` have been deprecated in favor of the generic `tag` option.\n\n``` \n$ docker --log-driver=syslog --log-opt tag=\"{{.ImageName}}/{{.Name}}/{{.ID}}\"\n```\n\n### Docker Content Trust ENV passphrase variables name change\n\n**Deprecated In Release: [v1.9.0](https://github.com/docker/docker/releases/tag/v1.9.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nSince 1.9, Docker Content Trust Offline key has been renamed to Root key and the Tagging key has been renamed to Repository key. Due to this renaming, we’re also changing the corresponding environment variables\n\n- DOCKER_CONTENT_TRUST_OFFLINE_PASSPHRASE is now named DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE\n- DOCKER_CONTENT_TRUST_TAGGING_PASSPHRASE is now named DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE\n\n### `/containers/(id or name)/copy` endpoint\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe endpoint `/containers/(id or name)/copy` is deprecated in favor of `/containers/(id or name)/archive`.\n\n### LXC built-in exec driver\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe built-in LXC execution driver, the lxc-conf flag, and API fields have been removed.\n\n### Old Command Line Options\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe flags `-d` and `--daemon` are deprecated in favor of the `daemon` subcommand:\n\n``` \ndocker daemon -H ...\n```\n\nThe following single-dash (`-opt`) variant of certain command line options are deprecated and replaced with double-dash options (`--opt`):\n\n``` \ndocker attach -nostdin\ndocker attach -sig-proxy\ndocker build -no-cache\ndocker build -rm\ndocker commit -author\ndocker commit -run\ndocker events -since\ndocker history -notrunc\ndocker images -notrunc\ndocker inspect -format\ndocker ps -beforeId\ndocker ps -notrunc\ndocker ps -sinceId\ndocker rm -link\ndocker run -cidfile\ndocker run -dns\ndocker run -entrypoint\ndocker run -expose\ndocker run -link\ndocker run -lxc-conf\ndocker run -n\ndocker run -privileged\ndocker run -volumes-from\ndocker search -notrunc\ndocker search -stars\ndocker search -t\ndocker search -trusted\ndocker tag -force\n```\n\nThe following double-dash options are deprecated and have no replacement:\n\n``` \ndocker run --cpuset\ndocker run --networking\ndocker ps --since-id\ndocker ps --before-id\ndocker search --trusted\n```\n\n**Deprecated In Release: [v1.5.0](https://github.com/docker/docker/releases/tag/v1.5.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe single-dash (`-help`) was removed, in favor of the double-dash `--help`\n\n``` \ndocker -help\ndocker [COMMAND] -help\n```\n\n### `--api-enable-cors` flag on dockerd\n\n**Deprecated In Release: [v1.6.0](https://github.com/docker/docker/releases/tag/v1.6.0)**\n\n**Removed In Release: [v17.09](https://github.com/docker/docker-ce/releases/tag/v17.09.0-ce)**\n\nThe flag `--api-enable-cors` is deprecated since v1.6.0. Use the flag `--api-cors-header` instead.\n\n### `--run` flag on docker commit\n\n**Deprecated In Release: [v0.10.0](https://github.com/docker/docker/releases/tag/v0.10.0)**\n\n**Removed In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\nThe flag `--run` of the docker commit (and its short version `-run`) were deprecated in favor of the `--changes` flag that allows to pass `Dockerfile` commands.\n\n### Three arguments form in `docker import`\n\n**Deprecated In Release: [v0.6.7](https://github.com/docker/docker/releases/tag/v0.6.7)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe `docker import` command format `file|URL|- [REPOSITORY [TAG]]` is deprecated since November 2013. It’s no more supported.\n\n[docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation), [about](https://docs.docker.com/search/?q=about), [technology](https://docs.docker.com/search/?q=technology), [deprecate](https://docs.docker.com/search/?q=deprecate)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/deprecated/](https://docs.docker.com/engine/deprecated/)"
- name: Develop with Docker Engine API
  id: engine/api/index
  summary: Docker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python
  description: "# Develop with Docker Engine API\n\nDocker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python. The SDKs allow you to build and scale Docker apps and solutions quickly and easily. If Go or Python don’t work for you, you can use the Docker Engine API directly.\n\nFor information about Docker Engine SDKs, see [Develop with Docker Engine SDKs](sdk/index).\n\nThe Docker Engine API is a RESTful API accessed by an HTTP client such as `wget` or `curl`, or the HTTP library which is part of most modern programming languages.\n\n## View the API reference\n\nYou can [view the reference for the latest version of the API](https://docs.docker.com/develop/sdk) or [choose a specific version](https://docs.docker.com/engine/api/version-history/).\n\n## Versioned API and SDK\n\nThe version of the Docker Engine API you should use depends upon the version of your Docker daemon and Docker client.\n\nA given version of the Docker Engine SDK supports a specific version of the Docker Engine API, as well as all earlier versions. If breaking changes occur, they are documented prominently.\n\n> Daemon and client API mismatches\n>\n> The Docker daemon and client do not necessarily need to be the same version at all times. However, keep the following in mind.\n>\n> - If the daemon is newer than the client, the client does not know about new features or deprecated API endpoints in the daemon.\n>\n> - If the client is newer than the daemon, the client can request API endpoints that the daemon does not know about.\n\nA new version of the API is released when new features are added. The Docker API is backward-compatible, so you do not need to update code that uses the API unless you need to take advantage of new features.\n\nTo see the highest version of the API your Docker daemon and client support, use `docker version`:\n\n``` \n$ docker version\n\nClient: Docker Engine - Community\n Version:           20.10.0\n API version:       1.41\n Go version:        go1.13.15\n Git commit:        7287ab3\n Built:             Tue Dec  8 19:00:39 2020\n OS/Arch:           linux/amd64\n Context:           default\n Experimental:      true\nServer: Docker Engine - Community\n Engine:\n  Version:          20.10.0\n  API version:      1.41 (minimum version 1.12)\n  Go version:       go1.13.15\n  Git commit:       eeddea2\n  Built:            Tue Dec  8 18:58:12 2020\n  OS/Arch:          linux/amd64\n  ...\n```\n\nYou can specify the API version to use, in one of the following ways:\n\n- When using the SDK, use the latest version you can, but at least the version that incorporates the API version with the features you need.\n\n- When using `curl` directly, specify the version as the first part of the URL. For instance, if the endpoint is `/containers/`, you can use `/v1.41/containers/`.\n\n- To force the Docker CLI or the Docker Engine SDKs to use an old version version of the API than the version reported by `docker version`, set the environment variable `DOCKER_API_VERSION` to the correct version. This works on Linux, Windows, or macOS clients.\n\n  ``` \n  $ DOCKER_API_VERSION='1.41'\n  ```\n\n  While the environment variable is set, that version of the API is used, even if the Docker daemon supports a newer version. This environment variable disables API version negotiation, and as such should only be used if you must use a specific version of the API, or for debugging purposes.\n\n- The Docker Go SDK allows you to enable API version negotiation, automatically selects an API version that is supported by both the client, and the Docker Engine that is used.\n\n- For the SDKs, you can also specify the API version programmatically, as a parameter to the `client` object. See the [Go constructor](https://github.com/moby/moby/blob/v19.03.6/client/client.go#L119) or the [Python SDK documentation for `client`](https://docker-py.readthedocs.io/en/stable/client.html).\n\n### API version matrix\n\n| Docker version | Maximum API version                               | Change log                                                                      |\n|:---------------|:--------------------------------------------------|:--------------------------------------------------------------------------------|\n| 20.10          | [1.41](https://docs.docker.com/engine/api/v1.41/) | [changes](https://docs.docker.com/engine/api/version-history/#v141-api-changes) |\n| 19.03          | [1.40](https://docs.docker.com/engine/api/v1.40/) | [changes](https://docs.docker.com/engine/api/version-history/#v140-api-changes) |\n| 18.09          | [1.39](https://docs.docker.com/engine/api/v1.39/) | [changes](https://docs.docker.com/engine/api/version-history/#v139-api-changes) |\n| 18.06          | [1.38](https://docs.docker.com/engine/api/v1.38/) | [changes](https://docs.docker.com/engine/api/version-history/#v138-api-changes) |\n| 18.05          | [1.37](https://docs.docker.com/engine/api/v1.37/) | [changes](https://docs.docker.com/engine/api/version-history/#v137-api-changes) |\n| 18.04          | [1.37](https://docs.docker.com/engine/api/v1.37/) | [changes](https://docs.docker.com/engine/api/version-history/#v137-api-changes) |\n| 18.03          | [1.37](https://docs.docker.com/engine/api/v1.37/) | [changes](https://docs.docker.com/engine/api/version-history/#v137-api-changes) |\n| 18.02          | [1.36](https://docs.docker.com/engine/api/v1.36/) | [changes](https://docs.docker.com/engine/api/version-history/#v136-api-changes) |\n| 17.12          | [1.35](https://docs.docker.com/engine/api/v1.35/) | [changes](https://docs.docker.com/engine/api/version-history/#v135-api-changes) |\n| 17.11          | [1.34](https://docs.docker.com/engine/api/v1.34/) | [changes](https://docs.docker.com/engine/api/version-history/#v134-api-changes) |\n| 17.10          | [1.33](https://docs.docker.com/engine/api/v1.33/) | [changes](https://docs.docker.com/engine/api/version-history/#v133-api-changes) |\n| 17.09          | [1.32](https://docs.docker.com/engine/api/v1.32/) | [changes](https://docs.docker.com/engine/api/version-history/#v132-api-changes) |\n| 17.07          | [1.31](https://docs.docker.com/engine/api/v1.31/) | [changes](https://docs.docker.com/engine/api/version-history/#v131-api-changes) |\n| 17.06          | [1.30](https://docs.docker.com/engine/api/v1.30/) | [changes](https://docs.docker.com/engine/api/version-history/#v130-api-changes) |\n| 17.05          | [1.29](https://docs.docker.com/engine/api/v1.29/) | [changes](https://docs.docker.com/engine/api/version-history/#v129-api-changes) |\n| 17.04          | [1.28](https://docs.docker.com/engine/api/v1.28/) | [changes](https://docs.docker.com/engine/api/version-history/#v128-api-changes) |\n| 17.03.1        | [1.27](https://docs.docker.com/engine/api/v1.27/) | [changes](https://docs.docker.com/engine/api/version-history/#v127-api-changes) |\n| 17.03          | [1.26](https://docs.docker.com/engine/api/v1.27/) | [changes](https://docs.docker.com/engine/api/version-history/#v126-api-changes) |\n| 1.13.1         | [1.26](https://docs.docker.com/engine/api/v1.26/) | [changes](https://docs.docker.com/engine/api/version-history/#v126-api-changes) |\n| 1.13           | [1.25](https://docs.docker.com/engine/api/v1.26/) | [changes](https://docs.docker.com/engine/api/version-history/#v125-api-changes) |\n| 1.12           | [1.24](https://docs.docker.com/engine/api/v1.24/) | [changes](https://docs.docker.com/engine/api/version-history/#v124-api-changes) |\n| 1.11           | [1.23](https://docs.docker.com/engine/api/v1.23/) | [changes](https://docs.docker.com/engine/api/version-history/#v123-api-changes) |\n| 1.10           | [1.22](https://docs.docker.com/engine/api/v1.22/) | [changes](https://docs.docker.com/engine/api/version-history/#v122-api-changes) |\n| 1.9            | [1.21](https://docs.docker.com/engine/api/v1.21/) | [changes](https://docs.docker.com/engine/api/version-history/#v121-api-changes) |\n| 1.8            | [1.20](https://docs.docker.com/engine/api/v1.20/) | [changes](https://docs.docker.com/engine/api/version-history/#v120-api-changes) |\n| 1.7            | [1.19](https://docs.docker.com/engine/api/v1.19/) | [changes](https://docs.docker.com/engine/api/version-history/#v119-api-changes) |\n| 1.6            | [1.18](https://docs.docker.com/engine/api/v1.18/) | [changes](https://docs.docker.com/engine/api/version-history/#v118-api-changes) |\n\n### Archived API versions\n\nDocumentation for older versions of the API has been archived, but can be found in the [docker code repository on GitHub](https://github.com/moby/moby/tree/v1.9.1/docs/reference/api)\n\n[developing](https://docs.docker.com/search/?q=developing), [api](https://docs.docker.com/search/?q=api)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/api/](https://docs.docker.com/engine/api/)"
- name: Develop with Docker Engine SDKs
  id: engine/api/sdk/index
  summary: Docker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python
  description: "# Develop with Docker Engine SDKs\n\nDocker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python. The SDKs allow you to build and scale Docker apps and solutions quickly and easily. If Go or Python don’t work for you, you can use the Docker Engine API directly.\n\nThe Docker Engine API is a RESTful API accessed by an HTTP client such as `wget` or `curl`, or the HTTP library which is part of most modern programming languages.\n\n## Install the SDKs\n\nUse the following commands to install the Go or Python SDK. Both SDKs can be installed and coexist together.\n\n### Go SDK\n\n``` \n$ go get github.com/docker/docker/client\n```\n\nThe client requires a recent version of Go. Run `go version` and ensure that you are running a currently supported version of Go\n\n[Read the full Docker Engine Go SDK reference](https://godoc.org/github.com/docker/docker/client).\n\n### Python SDK\n\n- **Recommended**: Run `pip install docker`.\n\n- **If you can’t use `pip`**:\n\n  1.  [Download the package directly](https://pypi.python.org/pypi/docker/).\n  2.  Extract it and change to the extracted directory,\n  3.  Run `python setup.py install`.\n\n[Read the full Docker Engine Python SDK reference](https://docker-py.readthedocs.io/).\n\n## View the API reference\n\nYou can [view the reference for the latest version of the API](https://docs.docker.com/develop/sdk) or [choose a specific version](https://docs.docker.com/engine/api/version-history/).\n\n## Versioned API and SDK\n\nThe version of the Docker Engine API you should use depends upon the version of your Docker daemon and Docker client. Refer to the [versioned API and SDK](../index#versioned-api-and-sdk) section in the API documentation for details.\n\n## SDK and API quickstart\n\nUse the following guidelines to choose the SDK or API version to use in your code:\n\n- If you’re starting a new project, use the [latest version](https://docs.docker.com/develop/sdk), but use API version negotiation or specify the version you are using. This helps prevent surprises.\n- If you need a new feature, update your code to use at least the minimum version that supports the feature, and prefer the latest version you can use.\n- Otherwise, continue to use the version that your code is already using.\n\nAs an example, the `docker run` command can be easily implemented using the Docker API directly, or using the Python or Go SDK.\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"io\"\n    \"os\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/api/types/container\"\n    \"github.com/docker/docker/client\"\n    \"github.com/docker/docker/pkg/stdcopy\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    reader, err := cli.ImagePull(ctx, \"docker.io/library/alpine\", types.ImagePullOptions{})\n    if err != nil {\n        panic(err)\n    }\n    io.Copy(os.Stdout, reader)\n\n    resp, err := cli.ContainerCreate(ctx, &container.Config{\n        Image: \"alpine\",\n        Cmd:   []string{\"echo\", \"hello world\"},\n    }, nil, nil, nil, \"\")\n    if err != nil {\n        panic(err)\n    }\n\n    if err := cli.ContainerStart(ctx, resp.ID, types.ContainerStartOptions{}); err != nil {\n        panic(err)\n    }\n\n    statusCh, errCh := cli.ContainerWait(ctx, resp.ID, container.WaitConditionNotRunning)\n    select {\n    case err := <-errCh:\n        if err != nil {\n            panic(err)\n        }\n    case <-statusCh:\n    }\n\n    out, err := cli.ContainerLogs(ctx, resp.ID, types.ContainerLogsOptions{ShowStdout: true})\n    if err != nil {\n        panic(err)\n    }\n\n    stdcopy.StdCopy(os.Stdout, os.Stderr, out)\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\nprint client.containers.run(\"alpine\", [\"echo\", \"hello\", \"world\"])\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock -H \"Content-Type: application/json\" \\\n  -d '{\"Image\": \"alpine\", \"Cmd\": [\"echo\", \"hello world\"]}' \\\n  -X POST http://localhost/v1.41/containers/create\n{\"Id\":\"1c6594faf5\",\"Warnings\":null}\n\n$ curl --unix-socket /var/run/docker.sock -X POST http://localhost/v1.41/containers/1c6594faf5/start\n\n$ curl --unix-socket /var/run/docker.sock -X POST http://localhost/v1.41/containers/1c6594faf5/wait\n{\"StatusCode\":0}\n\n$ curl --unix-socket /var/run/docker.sock \"http://localhost/v1.41/containers/1c6594faf5/logs?stdout=1\"\nhello world\n```\n\nWhen using cURL to connect over a unix socket, the hostname is not important. The examples above use `localhost`, but any hostname would work.\n\n> **Using cURL 7.47.0 or below?**\n>\n> The examples above assume you are using cURL 7.50.0 or above. Older versions of cURL used a [non-standard URL notation](https://github.com/moby/moby/issues/17960) when using a socket connection.\n>\n> If you are using an older version of cURL, use `http:/<API version>/` instead, for example, `http:/v1.41/containers/1c6594faf5/start`\n\nFor more examples, take a look at the [SDK examples](examples/index).\n\n## Unofficial libraries\n\nThere are a number of community supported libraries available for other languages. They have not been tested by Docker, so if you run into any issues, file them with the library maintainers.\n\n| Language              | Library                                                                     |\n|:----------------------|:----------------------------------------------------------------------------|\n| C                     | [libdocker](https://github.com/danielsuo/libdocker)                         |\n| C#                    | [Docker.DotNet](https://github.com/ahmetalpbalkan/Docker.DotNet)            |\n| C++                   | [lasote/docker_client](https://github.com/lasote/docker_client)             |\n| Clojure               | [clj-docker-client](https://github.com/into-docker/clj-docker-client)       |\n| Clojure               | [contajners](https://github.com/lispyclouds/contajners)                     |\n| Dart                  | [bwu_docker](https://github.com/bwu-dart/bwu_docker)                        |\n| Erlang                | [erldocker](https://github.com/proger/erldocker)                            |\n| Gradle                | [gradle-docker-plugin](https://github.com/gesellix/gradle-docker-plugin)    |\n| Groovy                | [docker-client](https://github.com/gesellix/docker-client)                  |\n| Haskell               | [docker-hs](https://github.com/denibertovic/docker-hs)                      |\n| HTML (Web Components) | [docker-elements](https://github.com/kapalhq/docker-elements)               |\n| Java                  | [docker-client](https://github.com/spotify/docker-client)                   |\n| Java                  | [docker-java](https://github.com/docker-java/docker-java)                   |\n| Java                  | [docker-java-api](https://github.com/amihaiemil/docker-java-api)            |\n| Java                  | [jocker](https://github.com/ndeloof/jocker)                                 |\n| NodeJS                | [dockerode](https://github.com/apocas/dockerode)                            |\n| NodeJS                | [harbor-master](https://github.com/arhea/harbor-master)                     |\n| Perl                  | [Eixo::Docker](https://github.com/alambike/eixo-docker)                     |\n| PHP                   | [Docker-PHP](https://github.com/docker-php/docker-php)                      |\n| Ruby                  | [docker-api](https://github.com/swipely/docker-api)                         |\n| Rust                  | [docker-rust](https://github.com/abh1nav/docker-rust)                       |\n| Rust                  | [shiplift](https://github.com/softprops/shiplift)                           |\n| Scala                 | [tugboat](https://github.com/softprops/tugboat)                             |\n| Scala                 | [reactive-docker](https://github.com/almoehi/reactive-docker)               |\n| Swift                 | [docker-client-swift](https://github.com/valeriomazzeo/docker-client-swift) |\n\n[developing](https://docs.docker.com/search/?q=developing), [sdk](https://docs.docker.com/search/?q=sdk)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/api/sdk/](https://docs.docker.com/engine/api/sdk/)"
- name: docker
  id: engine/reference/commandline/docker/index
  summary: The base command for the Docker CLI
  description: "# docker\n\n  \n\nThe base command for the Docker CLI.\n\n## Child commands\n\n| Command                                  | Description                                                                   |\n|------------------------------------------|-------------------------------------------------------------------------------|\n| [docker attach](../attach/index)         | Attach local standard input, output, and error streams to a running container |\n| [docker build](../build/index)           | Build an image from a Dockerfile                                              |\n| [docker builder](../builder/index)       | Manage builds                                                                 |\n| [docker checkpoint](../checkpoint/index) | Manage checkpoints                                                            |\n| [docker commit](../commit/index)         | Create a new image from a container’s changes                                 |\n| [docker config](../config/index)         | Manage Docker configs                                                         |\n| [docker container](../container/index)   | Manage containers                                                             |\n| [docker context](../context/index)       | Manage contexts                                                               |\n| [docker cp](../cp/index)                 | Copy files/folders between a container and the local filesystem               |\n| [docker create](../create/index)         | Create a new container                                                        |\n| [docker diff](../diff/index)             | Inspect changes to files or directories on a container’s filesystem           |\n| [docker events](../events/index)         | Get real time events from the server                                          |\n| [docker exec](../exec/index)             | Run a command in a running container                                          |\n| [docker export](../export/index)         | Export a container’s filesystem as a tar archive                              |\n| [docker history](../history/index)       | Show the history of an image                                                  |\n| [docker image](../image/index)           | Manage images                                                                 |\n| [docker images](../images/index)         | List images                                                                   |\n| [docker import](../import/index)         | Import the contents from a tarball to create a filesystem image               |\n| [docker info](../info/index)             | Display system-wide information                                               |\n| [docker inspect](../inspect/index)       | Return low-level information on Docker objects                                |\n| [docker kill](../kill/index)             | Kill one or more running containers                                           |\n| [docker load](../load/index)             | Load an image from a tar archive or STDIN                                     |\n| [docker login](../login/index)           | Log in to a Docker registry                                                   |\n| [docker logout](../logout/index)         | Log out from a Docker registry                                                |\n| [docker logs](../logs/index)             | Fetch the logs of a container                                                 |\n| [docker manifest](../manifest/index)     | Manage Docker image manifests and manifest lists                              |\n| [docker network](../network/index)       | Manage networks                                                               |\n| [docker node](../node/index)             | Manage Swarm nodes                                                            |\n| [docker pause](../pause/index)           | Pause all processes within one or more containers                             |\n| [docker plugin](../plugin/index)         | Manage plugins                                                                |\n| [docker port](../port/index)             | List port mappings or a specific mapping for the container                    |\n| [docker ps](../ps/index)                 | List containers                                                               |\n| [docker pull](../pull/index)             | Pull an image or a repository from a registry                                 |\n| [docker push](../push/index)             | Push an image or a repository to a registry                                   |\n| [docker rename](../rename/index)         | Rename a container                                                            |\n| [docker restart](../restart/index)       | Restart one or more containers                                                |\n| [docker rm](../rm/index)                 | Remove one or more containers                                                 |\n| [docker rmi](../rmi/index)               | Remove one or more images                                                     |\n| [docker run](../run/index)               | Run a command in a new container                                              |\n| [docker save](../save/index)             | Save one or more images to a tar archive (streamed to STDOUT by default)      |\n| [docker search](../search/index)         | Search the Docker Hub for images                                              |\n| [docker secret](../secret/index)         | Manage Docker secrets                                                         |\n| [docker service](../service/index)       | Manage services                                                               |\n| [docker stack](../stack/index)           | Manage Docker stacks                                                          |\n| [docker start](../start/index)           | Start one or more stopped containers                                          |\n| [docker stats](../stats/index)           | Display a live stream of container(s) resource usage statistics               |\n| [docker stop](../stop/index)             | Stop one or more running containers                                           |\n| [docker swarm](../swarm/index)           | Manage Swarm                                                                  |\n| [docker system](../system/index)         | Manage Docker                                                                 |\n| [docker tag](../tag/index)               | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                         |\n| [docker top](../top/index)               | Display the running processes of a container                                  |\n| [docker trust](../trust/index)           | Manage trust on Docker images                                                 |\n| [docker unpause](../unpause/index)       | Unpause all processes within one or more containers                           |\n| [docker update](../update/index)         | Update configuration of one or more containers                                |\n| [docker version](../version/index)       | Show the Docker version information                                           |\n| [docker volume](../volume/index)         | Manage volumes                                                                |\n| [docker wait](../wait/index)             | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/docker/](https://docs.docker.com/engine/reference/commandline/docker/)"
- name: docker attach
  id: engine/reference/commandline/attach/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker attach\n\n  \n\nAttach local standard input, output, and error streams to a running container\n\n## Usage\n\n``` \n$ docker attach [OPTIONS] CONTAINER\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUse `docker attach` to attach your terminal’s standard input, output, and error (or any combination of the three) to a running container using the container’s ID or name. This allows you to view its ongoing output or to control it interactively, as though the commands were running directly in your terminal.\n\n> **Note:** The `attach` command will display the output of the `ENTRYPOINT/CMD` process. This can appear as if the attach command is hung when in fact the process may simply not be interacting with the terminal at that time.\n\nYou can attach to the same contained process multiple times simultaneously, from different sessions on the Docker host.\n\nTo stop a container, use `CTRL-c`. This key sequence sends `SIGKILL` to the container. If `--sig-proxy` is true (the default),`CTRL-c` sends a `SIGINT` to the container. If the container was run with `-i` and `-t`, you can detach from a container and leave it running using the `CTRL-p CTRL-q` key sequence.\n\n> **Note:** A process running as PID 1 inside a container is treated specially by Linux: it ignores any signal with the default action. So, the process will not terminate on `SIGINT` or `SIGTERM` unless it is coded to do so.\n\nIt is forbidden to redirect the standard input of a `docker attach` command while attaching to a tty-enabled container (i.e.: launched with `-t`).\n\nWhile a client is connected to container’s stdio using `docker attach`, Docker uses a ~1MB memory buffer to maximize the throughput of the application. If this buffer is filled, the speed of the API connection will start to have an effect on the process output writing speed. This is similar to other applications like SSH. Because of this, it is not recommended to run performance critical applications that generate a lot of output in the foreground over a slow client connection. Instead, users should use the `docker logs` command to get access to the logs.\n\n### Override the detach sequence\n\nIf you want, you can configure an override the Docker key sequence for detach. This is useful if the Docker default sequence conflicts with key sequence you use for other applications. There are two ways to define your own detach key sequence, as a per-container override or as a configuration property on your entire configuration.\n\nTo override the sequence for an individual container, use the `--detach-keys=\"<sequence>\"` flag with the `docker attach` command. The format of the `<sequence>` is either a letter \\[a-Z\\], or the `ctrl-` combined with any of the following:\n\n- `a-z` (a single lowercase alpha character )\n- `@` (at sign)\n- `[` (left bracket)\n- `\\\\` (two backward slashes)\n- `_` (underscore)\n- `^` (caret)\n\nThese `a`, `ctrl-a`, `X`, or `ctrl-\\\\` values are all examples of valid key sequences. To configure a different configuration default key sequence for all containers, see [**Configuration file** section](../cli/index#configuration-files).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                                         |\n|-----------------|---------|-----------------------------------------------------|\n| `--detach-keys` |         | Override the key sequence for detaching a container |\n| `--no-stdin`    |         | Do not attach STDIN                                 |\n| `--sig-proxy`   | `true`  | Proxy all received signals to the process           |\n\n## Examples\n\n### Attach to and detach from a running container\n\n``` \n$ docker run -d --name topdemo ubuntu /usr/bin/top -b\n\n$ docker attach topdemo\n\ntop - 02:05:52 up  3:05,  0 users,  load average: 0.01, 0.02, 0.05\nTasks:   1 total,   1 running,   0 sleeping,   0 stopped,   0 zombie\nCpu(s):  0.1%us,  0.2%sy,  0.0%ni, 99.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\nMem:    373572k total,   355560k used,    18012k free,    27872k buffers\nSwap:   786428k total,        0k used,   786428k free,   221740k cached\n\nPID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n 1 root      20   0 17200 1116  912 R    0  0.3   0:00.03 top\n\n top - 02:05:55 up  3:05,  0 users,  load average: 0.01, 0.02, 0.05\n Tasks:   1 total,   1 running,   0 sleeping,   0 stopped,   0 zombie\n Cpu(s):  0.0%us,  0.2%sy,  0.0%ni, 99.8%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\n Mem:    373572k total,   355244k used,    18328k free,    27872k buffers\n Swap:   786428k total,        0k used,   786428k free,   221776k cached\n\n   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n       1 root      20   0 17208 1144  932 R    0  0.3   0:00.03 top\n\n\n top - 02:05:58 up  3:06,  0 users,  load average: 0.01, 0.02, 0.05\n Tasks:   1 total,   1 running,   0 sleeping,   0 stopped,   0 zombie\n Cpu(s):  0.2%us,  0.3%sy,  0.0%ni, 99.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\n Mem:    373572k total,   355780k used,    17792k free,    27880k buffers\n Swap:   786428k total,        0k used,   786428k free,   221776k cached\n\n PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n      1 root      20   0 17208 1144  932 R    0  0.3   0:00.03 top\n^C$\n\n$ echo $?\n0\n$ docker ps -a | grep topdemo\n\n7998ac8581f9        ubuntu:14.04        \"/usr/bin/top -b\"   38 seconds ago      Exited (0) 21 seconds ago                          topdemo\n```\n\n### Get the exit code of the container’s command\n\nAnd in this second example, you can see the exit code returned by the `bash` process is returned by the `docker attach` command to its caller too:\n\n``` \n$ docker run --name test -d -it debian\n275c44472aebd77c926d4527885bb09f2f6db21d878c75f0a1c212c03d3bcfab\n\n$ docker attach test\nroot@f38c87f2a42d:/# exit 13\n\nexit\n\n$ echo $?\n13\n\n$ docker ps -a | grep test\n\n275c44472aeb        debian:7            \"/bin/bash\"         26 seconds ago      Exited (13) 17 seconds ago                         test\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/attach/](https://docs.docker.com/engine/reference/commandline/attach/)"
- name: docker build
  id: engine/reference/commandline/build/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker build\n\n  \n\nBuild an image from a Dockerfile\n\n## Usage\n\n``` \n$ docker build [OPTIONS] PATH | URL | -\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker build` command builds Docker images from a Dockerfile and a “context”. A build’s context is the set of files located in the specified `PATH` or `URL`. The build process can refer to any of the files in the context. For example, your build can use a [*COPY*](../../builder/index#copy) instruction to reference a file in the context.\n\nThe `URL` parameter can refer to three kinds of resources: Git repositories, pre-packaged tarball contexts and plain text files.\n\n### Git repositories\n\nWhen the `URL` parameter points to the location of a Git repository, the repository acts as the build context. The system recursively fetches the repository and its submodules. The commit history is not preserved. A repository is first pulled into a temporary directory on your local host. After that succeeds, the directory is sent to the Docker daemon as the context. Local copy gives you the ability to access private repositories using local user credentials, VPN’s, and so forth.\n\n> **Note**\n>\n> If the `URL` parameter contains a fragment the system will recursively clone the repository and its submodules using a `git clone --recursive` command.\n\nGit URLs accept context configuration in their fragment section, separated by a colon (`:`). The first part represents the reference that Git will check out, and can be either a branch, a tag, or a remote reference. The second part represents a subdirectory inside the repository that will be used as a build context.\n\nFor example, run this command to use a directory called `docker` in the branch `container`:\n\n``` \n$ docker build https://github.com/docker/rootfs.git#container:docker\n```\n\nThe following table represents all the valid suffixes with their build contexts:\n\n| Build Syntax Suffix            | Commit Used           | Build Context Used |\n|--------------------------------|-----------------------|--------------------|\n| `myrepo.git`                   | `refs/heads/master`   | `/`                |\n| `myrepo.git#mytag`             | `refs/tags/mytag`     | `/`                |\n| `myrepo.git#mybranch`          | `refs/heads/mybranch` | `/`                |\n| `myrepo.git#pull/42/head`      | `refs/pull/42/head`   | `/`                |\n| `myrepo.git#:myfolder`         | `refs/heads/master`   | `/myfolder`        |\n| `myrepo.git#master:myfolder`   | `refs/heads/master`   | `/myfolder`        |\n| `myrepo.git#mytag:myfolder`    | `refs/tags/mytag`     | `/myfolder`        |\n| `myrepo.git#mybranch:myfolder` | `refs/heads/mybranch` | `/myfolder`        |\n\n> **Note**\n>\n> You cannot specify the build-context directory (`myfolder` in the examples above) when using BuildKit as builder (`DOCKER_BUILDKIT=1`). Support for this feature is tracked in [buildkit#1684](https://github.com/moby/buildkit/issues/1684).\n\n### Tarball contexts\n\nIf you pass an URL to a remote tarball, the URL itself is sent to the daemon:\n\n``` \n$ docker build http://server/context.tar.gz\n```\n\nThe download operation will be performed on the host the Docker daemon is running on, which is not necessarily the same host from which the build command is being issued. The Docker daemon will fetch `context.tar.gz` and use it as the build context. Tarball contexts must be tar archives conforming to the standard `tar` UNIX format and can be compressed with any one of the ‘xz’, ‘bzip2’, ‘gzip’ or ‘identity’ (no compression) formats.\n\n### Text files\n\nInstead of specifying a context, you can pass a single `Dockerfile` in the `URL` or pipe the file in via `STDIN`. To pipe a `Dockerfile` from `STDIN`:\n\n``` \n$ docker build - < Dockerfile\n```\n\nWith Powershell on Windows, you can run:\n\n``` \nGet-Content Dockerfile | docker build -\n```\n\nIf you use `STDIN` or specify a `URL` pointing to a plain text file, the system places the contents into a file called `Dockerfile`, and any `-f`, `--file` option is ignored. In this scenario, there is no context.\n\nBy default the `docker build` command will look for a `Dockerfile` at the root of the build context. The `-f`, `--file`, option lets you specify the path to an alternative file to use instead. This is useful in cases where the same set of files are used for multiple builds. The path must be to a file within the build context. If a relative path is specified then it is interpreted as relative to the root of the context.\n\nIn most cases, it’s best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the build’s performance, you can exclude files and directories by adding a `.dockerignore` file to that directory as well. For information on creating one, see the [.dockerignore file](../../builder/index#dockerignore-file).\n\nIf the Docker client loses connection to the daemon, the build is canceled. This happens if you interrupt the Docker client with `CTRL-c` or if the Docker client is killed for any reason. If the build initiated a pull which is still running at the time the build is cancelled, the pull is cancelled as well.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default | Description                                                                                                                              |\n|---------------------------|---------|------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |         | Add a custom host-to-IP mapping (host:ip)                                                                                                |\n| `--build-arg`             |         | Set build-time variables                                                                                                                 |\n| `--cache-from`            |         | Images to consider as cache sources                                                                                                      |\n| `--cgroup-parent`         |         | Optional parent cgroup for the container                                                                                                 |\n| `--compress`              |         | Compress the build context using gzip                                                                                                    |\n| `--cpu-period`            |         | Limit the CPU CFS (Completely Fair Scheduler) period                                                                                     |\n| `--cpu-quota`             |         | Limit the CPU CFS (Completely Fair Scheduler) quota                                                                                      |\n| `--cpu-shares` , `-c`     |         | CPU shares (relative weight)                                                                                                             |\n| `--cpuset-cpus`           |         | CPUs in which to allow execution (0-3, 0,1)                                                                                              |\n| `--cpuset-mems`           |         | MEMs in which to allow execution (0-3, 0,1)                                                                                              |\n| `--disable-content-trust` | `true`  | Skip image verification                                                                                                                  |\n| `--file` , `-f`           |         | Name of the Dockerfile (Default is 'PATH/Dockerfile')                                                                                    |\n| `--force-rm`              |         | Always remove intermediate containers                                                                                                    |\n| `--iidfile`               |         | Write the image ID to the file                                                                                                           |\n| `--isolation`             |         | Container isolation technology                                                                                                           |\n| `--label`                 |         | Set metadata for an image                                                                                                                |\n| `--memory` , `-m`         |         | Memory limit                                                                                                                             |\n| `--memory-swap`           |         | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                      |\n| `--network`               |         | Set the networking mode for the RUN instructions during build                                                                            |\n| `--no-cache`              |         | Do not use cache when building the image                                                                                                 |\n| `--output` , `-o`         |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Output destination (format: type=local,dest=path)                                 |\n| `--platform`              |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Set platform if server is multi-platform capable                                  |\n| `--progress`              | `auto`  | Set type of progress output (auto, plain, tty). Use plain to show container output                                                       |\n| `--pull`                  |         | Always attempt to pull a newer version of the image                                                                                      |\n| `--quiet` , `-q`          |         | Suppress the build output and print image ID on success                                                                                  |\n| `--rm`                    | `true`  | Remove intermediate containers after a successful build                                                                                  |\n| `--secret`                |         | Secret file to expose to the build (only if BuildKit enabled): id=mysecret,src=/local/secret                                             |\n| `--security-opt`          |         | Security options                                                                                                                         |\n| `--shm-size`              |         | Size of /dev/shm                                                                                                                         |\n| `--squash`                |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Squash newly built layers into a single new layer                    |\n| `--ssh`                   |         | SSH agent socket or keys to expose to the build (only if BuildKit enabled) (format: default\\|\\<id\\>\\[=\\<socket\\>\\|\\<key\\>\\[,\\<key\\>\\]\\]) |\n| `--stream`                |         | Stream attaches to server to negotiate build context                                                                                     |\n| `--tag` , `-t`            |         | Name and optionally a tag in the 'name:tag' format                                                                                       |\n| `--target`                |         | Set the target build stage to build.                                                                                                     |\n| `--ulimit`                |         | Ulimit options                                                                                                                           |\n\n## Examples\n\n### Build with PATH\n\n``` \n$ docker build .\n\nUploading context 10240 bytes\nStep 1/3 : FROM busybox\nPulling repository busybox\n ---> e9aa60c60128MB/2.284 MB (100%) endpoint: https://cdn-registry-1.docker.io/v1/\nStep 2/3 : RUN ls -lh /\n ---> Running in 9c9e81692ae9\ntotal 24\ndrwxr-xr-x    2 root     root        4.0K Mar 12  2013 bin\ndrwxr-xr-x    5 root     root        4.0K Oct 19 00:19 dev\ndrwxr-xr-x    2 root     root        4.0K Oct 19 00:19 etc\ndrwxr-xr-x    2 root     root        4.0K Nov 15 23:34 lib\nlrwxrwxrwx    1 root     root           3 Mar 12  2013 lib64 -> lib\ndr-xr-xr-x  116 root     root           0 Nov 15 23:34 proc\nlrwxrwxrwx    1 root     root           3 Mar 12  2013 sbin -> bin\ndr-xr-xr-x   13 root     root           0 Nov 15 23:34 sys\ndrwxr-xr-x    2 root     root        4.0K Mar 12  2013 tmp\ndrwxr-xr-x    2 root     root        4.0K Nov 15 23:34 usr\n ---> b35f4035db3f\nStep 3/3 : CMD echo Hello world\n ---> Running in 02071fceb21b\n ---> f52f38b7823e\nSuccessfully built f52f38b7823e\nRemoving intermediate container 9c9e81692ae9\nRemoving intermediate container 02071fceb21b\n```\n\nThis example specifies that the `PATH` is `.`, and so all the files in the local directory get `tar`d and sent to the Docker daemon. The `PATH` specifies where to find the files for the “context” of the build on the Docker daemon. Remember that the daemon could be running on a remote machine and that no parsing of the Dockerfile happens at the client side (where you’re running `docker build`). That means that *all* the files at `PATH` get sent, not just the ones listed to [*ADD*](../../builder/index#add) in the Dockerfile.\n\nThe transfer of context from the local machine to the Docker daemon is what the `docker` client means when you see the “Sending build context” message.\n\nIf you wish to keep the intermediate containers after the build is complete, you must use `--rm=false`. This does not affect the build cache.\n\n### Build with URL\n\n``` \n$ docker build github.com/creack/docker-firefox\n```\n\nThis will clone the GitHub repository and use the cloned repository as context. The Dockerfile at the root of the repository is used as Dockerfile. You can specify an arbitrary Git repository by using the `git://` or `git@` scheme.\n\n``` \n$ docker build -f ctx/Dockerfile http://server/ctx.tar.gz\n\nDownloading context: http://server/ctx.tar.gz [===================>]    240 B/240 B\nStep 1/3 : FROM busybox\n ---> 8c2e06607696\nStep 2/3 : ADD ctx/container.cfg /\n ---> e7829950cee3\nRemoving intermediate container b35224abf821\nStep 3/3 : CMD /bin/ls\n ---> Running in fbc63d321d73\n ---> 3286931702ad\nRemoving intermediate container fbc63d321d73\nSuccessfully built 377c409b35e4\n```\n\nThis sends the URL `http://server/ctx.tar.gz` to the Docker daemon, which downloads and extracts the referenced tarball. The `-f ctx/Dockerfile` parameter specifies a path inside `ctx.tar.gz` to the `Dockerfile` that is used to build the image. Any `ADD` commands in that `Dockerfile` that refers to local paths must be relative to the root of the contents inside `ctx.tar.gz`. In the example above, the tarball contains a directory `ctx/`, so the `ADD ctx/container.cfg /` operation works as expected.\n\n### Build with -\n\n``` \n$ docker build - < Dockerfile\n```\n\nThis will read a Dockerfile from `STDIN` without context. Due to the lack of a context, no contents of any local directory will be sent to the Docker daemon. Since there is no context, a Dockerfile `ADD` only works if it refers to a remote URL.\n\n``` \n$ docker build - < context.tar.gz\n```\n\nThis will build an image for a compressed context read from `STDIN`. Supported formats are: bzip2, gzip and xz.\n\n### Use a .dockerignore file\n\n``` \n$ docker build .\n\nUploading context 18.829 MB\nUploading context\nStep 1/2 : FROM busybox\n ---> 769b9341d937\nStep 2/2 : CMD echo Hello world\n ---> Using cache\n ---> 99cc1ad10469\nSuccessfully built 99cc1ad10469\n$ echo \".git\" > .dockerignore\n$ docker build .\nUploading context  6.76 MB\nUploading context\nStep 1/2 : FROM busybox\n ---> 769b9341d937\nStep 2/2 : CMD echo Hello world\n ---> Using cache\n ---> 99cc1ad10469\nSuccessfully built 99cc1ad10469\n```\n\nThis example shows the use of the `.dockerignore` file to exclude the `.git` directory from the context. Its effect can be seen in the changed size of the uploaded context. The builder reference contains detailed information on [creating a .dockerignore file](../../builder/index#dockerignore-file).\n\nWhen using the [BuildKit backend](../../builder/index#buildkit), `docker build` searches for a `.dockerignore` file relative to the Dockerfile name. For example, running `docker build -f myapp.Dockerfile .` will first look for an ignore file named `myapp.Dockerfile.dockerignore`. If such a file is not found, the `.dockerignore` file is used if present. Using a Dockerfile based `.dockerignore` is useful if a project contains multiple Dockerfiles that expect to ignore different sets of files.\n\n### Tag an image (-t)\n\n``` \n$ docker build -t vieux/apache:2.0 .\n```\n\nThis will build like the previous example, but it will then tag the resulting image. The repository name will be `vieux/apache` and the tag will be `2.0`. [Read more about valid tags](../tag/index).\n\nYou can apply multiple tags to an image. For example, you can apply the `latest` tag to a newly built image and add another tag that references a specific version. For example, to tag an image both as `whenry/fedora-jboss:latest` and `whenry/fedora-jboss:v2.1`, use the following:\n\n``` \n$ docker build -t whenry/fedora-jboss:latest -t whenry/fedora-jboss:v2.1 .\n```\n\n### Specify a Dockerfile (-f)\n\n``` \n$ docker build -f Dockerfile.debug .\n```\n\nThis will use a file called `Dockerfile.debug` for the build instructions instead of `Dockerfile`.\n\n``` \n$ curl example.com/remote/Dockerfile | docker build -f - .\n```\n\nThe above command will use the current directory as the build context and read a Dockerfile from stdin.\n\n``` \n$ docker build -f dockerfiles/Dockerfile.debug -t myapp_debug .\n$ docker build -f dockerfiles/Dockerfile.prod  -t myapp_prod .\n```\n\nThe above commands will build the current build context (as specified by the `.`) twice, once using a debug version of a `Dockerfile` and once using a production version.\n\n``` \n$ cd /home/me/myapp/some/dir/really/deep\n$ docker build -f /home/me/myapp/dockerfiles/debug /home/me/myapp\n$ docker build -f ../../../../dockerfiles/debug /home/me/myapp\n```\n\nThese two `docker build` commands do the exact same thing. They both use the contents of the `debug` file instead of looking for a `Dockerfile` and will use `/home/me/myapp` as the root of the build context. Note that `debug` is in the directory structure of the build context, regardless of how you refer to it on the command line.\n\n> **Note**\n>\n> `docker build` returns a `no such file or directory` error if the file or directory does not exist in the uploaded context. This may happen if there is no context, or if you specify a file that is elsewhere on the Host system. The context is limited to the current directory (and its children) for security reasons, and to ensure repeatable builds on remote Docker hosts. This is also the reason why `ADD ../file` does not work.\n\n### Use a custom parent cgroup (--cgroup-parent)\n\nWhen `docker build` is run with the `--cgroup-parent` option the containers used in the build will be run with the [corresponding `docker run` flag](../../run/index#specify-custom-cgroups).\n\n### Set ulimits in container (--ulimit)\n\nUsing the `--ulimit` option with `docker build` will cause each build step’s container to be started using those [`--ulimit` flag values](../run/index#set-ulimits-in-container---ulimit).\n\n### Set build-time variables (--build-arg)\n\nYou can use `ENV` instructions in a Dockerfile to define variable values. These values persist in the built image. However, often persistence is not what you want. Users want to specify variables differently depending on which host they build an image on.\n\nA good example is `http_proxy` or source versions for pulling intermediate files. The `ARG` instruction lets Dockerfile authors define values that users can set at build-time using the `--build-arg` flag:\n\n``` \n$ docker build --build-arg HTTP_PROXY=http://10.20.30.2:1234 --build-arg FTP_PROXY=http://40.50.60.5:4567 .\n```\n\nThis flag allows you to pass the build-time variables that are accessed like regular environment variables in the `RUN` instruction of the Dockerfile. Also, these values don’t persist in the intermediate or final images like `ENV` values do. You must add `--build-arg` for each build argument.\n\nUsing this flag will not alter the output you see when the `ARG` lines from the Dockerfile are echoed during the build process.\n\nFor detailed information on using `ARG` and `ENV` instructions, see the [Dockerfile reference](../../builder/index).\n\nYou may also use the `--build-arg` flag without a value, in which case the value from the local environment will be propagated into the Docker container being built:\n\n``` \n$ export HTTP_PROXY=http://10.20.30.2:1234\n$ docker build --build-arg HTTP_PROXY .\n```\n\nThis is similar to how `docker run -e` works. Refer to the [`docker run` documentation](../run/index#set-environment-variables--e---env---env-file) for more information.\n\n### Optional security options (--security-opt)\n\nThis flag is only supported on a daemon running on Windows, and only supports the `credentialspec` option. The `credentialspec` must be in the format `file://spec.txt` or `registry://keyname`.\n\n### Specify isolation technology for container (--isolation)\n\nThis option is useful in situations where you are running Docker containers on Windows. The `--isolation=<value>` option sets a container’s isolation technology. On Linux, the only supported is the `default` option which uses Linux namespaces. On Microsoft Windows, you can specify these values:\n\n| Value     | Description                                                                                                                                                                    |\n|-----------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `default` | Use the value specified by the Docker daemon’s `--exec-opt` . If the `daemon` does not specify an isolation technology, Microsoft Windows uses `process` as its default value. |\n| `process` | Namespace isolation only.                                                                                                                                                      |\n| `hyperv`  | Hyper-V hypervisor partition-based isolation.                                                                                                                                  |\n\nSpecifying the `--isolation` flag without a value is the same as setting `--isolation=\"default\"`.\n\n### Add entries to container hosts file (--add-host)\n\nYou can add other hosts into a container’s `/etc/hosts` file by using one or more `--add-host` flags. This example adds a static address for a host named `docker`:\n\n``` \n$ docker build --add-host=docker:10.180.0.1 .\n```\n\n### Specifying target build stage (--target)\n\nWhen building a Dockerfile with multiple build stages, `--target` can be used to specify an intermediate build stage by name as a final stage for the resulting image. Commands after the target stage will be skipped.\n\n``` \nFROM debian AS build-env\n# ...\n\nFROM alpine AS production-env\n# ...\n```\n\n``` \n$ docker build -t mybuildimage --target build-env .\n```\n\n### Custom build outputs\n\nBy default, a local container image is created from the build result. The `--output` (or `-o`) flag allows you to override this behavior, and a specify a custom exporter. For example, custom exporters allow you to export the build artifacts as files on the local filesystem instead of a Docker image, which can be useful for generating local binaries, code generation etc.\n\nThe value for `--output` is a CSV-formatted string defining the exporter type and options. Currently, `local` and `tar` exporters are supported. The `local` exporter writes the resulting build files to a directory on the client side. The `tar` exporter is similar but writes the files as a single tarball (`.tar`).\n\nIf no type is specified, the value defaults to the output directory of the local exporter. Use a hyphen (`-`) to write the output tarball to standard output (`STDOUT`).\n\nThe following example builds an image using the current directory (`.`) as build context, and exports the files to a directory named `out` in the current directory. If the directory does not exist, Docker creates the directory automatically:\n\n``` \n$ docker build -o out .\n```\n\nThe example above uses the short-hand syntax, omitting the `type` options, and thus uses the default (`local`) exporter. The example below shows the equivalent using the long-hand CSV syntax, specifying both `type` and `dest` (destination path):\n\n``` \n$ docker build --output type=local,dest=out .\n```\n\nUse the `tar` type to export the files as a `.tar` archive:\n\n``` \n$ docker build --output type=tar,dest=out.tar .\n```\n\nThe example below shows the equivalent when using the short-hand syntax. In this case, `-` is specified as destination, which automatically selects the `tar` type, and writes the output tarball to standard output, which is then redirected to the `out.tar` file:\n\n``` \n$ docker build -o - . > out.tar\n```\n\nThe `--output` option exports all files from the target stage. A common pattern for exporting only specific files is to do multi-stage builds and to copy the desired files to a new scratch stage with [`COPY --from`](../../builder/index#copy).\n\nThe example `Dockerfile` below uses a separate stage to collect the build-artifacts for exporting:\n\n``` \nFROM golang AS build-stage\nRUN go get -u github.com/LK4D4/vndr\n\nFROM scratch AS export-stage\nCOPY --from=build-stage /go/bin/vndr /\n```\n\nWhen building the Dockerfile with the `-o` option, only the files from the final stage are exported to the `out` directory, in this case, the `vndr` binary:\n\n``` \n$ docker build -o out .\n\n[+] Building 2.3s (7/7) FINISHED\n => [internal] load build definition from Dockerfile                                                                          0.1s\n => => transferring dockerfile: 176B                                                                                          0.0s\n => [internal] load .dockerignore                                                                                             0.0s\n => => transferring context: 2B                                                                                               0.0s\n => [internal] load metadata for docker.io/library/golang:latest                                                              1.6s\n => [build-stage 1/2] FROM docker.io/library/golang@sha256:2df96417dca0561bf1027742dcc5b446a18957cd28eba6aa79269f23f1846d3f   0.0s\n => => resolve docker.io/library/golang@sha256:2df96417dca0561bf1027742dcc5b446a18957cd28eba6aa79269f23f1846d3f               0.0s\n => CACHED [build-stage 2/2] RUN go get -u github.com/LK4D4/vndr                                                              0.0s\n => [export-stage 1/1] COPY --from=build-stage /go/bin/vndr /                                                                 0.2s\n => exporting to client                                                                                                       0.4s\n => => copying files 10.30MB                                                                                                  0.3s\n\n$ ls ./out\nvndr\n```\n\n> **Note**\n>\n> This feature requires the BuildKit backend. You can either [enable BuildKit](../../builder/index#buildkit) or use the [buildx](https://github.com/docker/buildx) plugin which provides more output type options.\n\n### Specifying external cache sources\n\nIn addition to local build cache, the builder can reuse the cache generated from previous builds with the `--cache-from` flag pointing to an image in the registry.\n\nTo use an image as a cache source, cache metadata needs to be written into the image on creation. This can be done by setting `--build-arg BUILDKIT_INLINE_CACHE=1` when building the image. After that, the built image can be used as a cache source for subsequent builds.\n\nUpon importing the cache, the builder will only pull the JSON metadata from the registry and determine possible cache hits based on that information. If there is a cache hit, the matched layers are pulled into the local environment.\n\nIn addition to images, the cache can also be pulled from special cache manifests generated by [`buildx`](https://github.com/docker/buildx) or the BuildKit CLI (`buildctl`). These manifests (when built with the `type=registry` and `mode=max` options) allow pulling layer data for intermediate stages in multi-stage builds.\n\nThe following example builds an image with inline-cache metadata and pushes it to a registry, then uses the image as a cache source on another machine:\n\n``` \n$ docker build -t myname/myapp --build-arg BUILDKIT_INLINE_CACHE=1 .\n$ docker push myname/myapp\n```\n\nAfter pushing the image, the image is used as cache source on another machine. BuildKit automatically pulls the image from the registry if needed.\n\nOn another machine:\n\n``` \n$ docker build --cache-from myname/myapp .\n```\n\n> **Note**\n>\n> This feature requires the BuildKit backend. You can either [enable BuildKit](../../builder/index#buildkit) or use the [buildx](https://github.com/docker/buildx) plugin. The previous builder has limited support for reusing cache from pre-pulled images.\n\n### Squash an image’s layers (--squash) (experimental)\n\n#### Overview\n\nOnce the image is built, squash the new layers into a new image with a single new layer. Squashing does not destroy any existing image, rather it creates a new image with the content of the squashed layers. This effectively makes it look like all `Dockerfile` commands were created with a single layer. The build cache is preserved with this method.\n\nThe `--squash` option is an experimental feature, and should not be considered stable.\n\nSquashing layers can be beneficial if your Dockerfile produces multiple layers modifying the same files, for example, files that are created in one step, and removed in another step. For other use-cases, squashing images may actually have a negative impact on performance; when pulling an image consisting of multiple layers, layers can be pulled in parallel, and allows sharing layers between images (saving space).\n\nFor most use cases, multi-stage builds are a better alternative, as they give more fine-grained control over your build, and can take advantage of future optimizations in the builder. Refer to the [use multi-stage builds](https://docs.docker.com/develop/develop-images/multistage-build/) section in the userguide for more information.\n\n#### Known limitations\n\nThe `--squash` option has a number of known limitations:\n\n- When squashing layers, the resulting image cannot take advantage of layer sharing with other images, and may use significantly more space. Sharing the base image is still supported.\n- When using this option you may see significantly more space used due to storing two copies of the image, one for the build cache with all the cache layers intact, and one for the squashed version.\n- While squashing layers may produce smaller images, it may have a negative impact on performance, as a single layer takes longer to extract, and downloading a single layer cannot be parallelized.\n- When attempting to squash an image that does not make changes to the filesystem (for example, the Dockerfile only contains `ENV` instructions), the squash step will fail (see [issue \\#33823](https://github.com/moby/moby/issues/33823)).\n\n#### Prerequisites\n\nThe example on this page is using experimental mode in Docker 19.03.\n\nExperimental mode can be enabled by using the `--experimental` flag when starting the Docker daemon or setting `experimental: true` in the `daemon.json` configuration file.\n\nBy default, experimental mode is disabled. To see the current configuration of the docker daemon, use the `docker version` command and check the `Experimental` line in the `Engine` section:\n\n``` \nClient: Docker Engine - Community\n Version:           19.03.8\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        afacb8b\n Built:             Wed Mar 11 01:21:11 2020\n OS/Arch:           darwin/amd64\n Experimental:      false\n\nServer: Docker Engine - Community\n Engine:\n  Version:          19.03.8\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       afacb8b\n  Built:            Wed Mar 11 01:29:16 2020\n  OS/Arch:          linux/amd64\n  Experimental:     true\n [...]\n```\n\nTo enable experimental mode, users need to restart the docker daemon with the experimental flag enabled.\n\n#### Enable Docker experimental\n\nTo enable experimental features, you need to start the Docker daemon with `--experimental` flag. You can also enable the daemon flag via `/etc/docker/daemon.json`, for example:\n\n``` \n{\n    \"experimental\": true\n}\n```\n\nThen make sure the experimental flag is enabled:\n\n``` \n$ docker version -f '{{.Server.Experimental}}'\ntrue\n```\n\n#### Build an image with `--squash` argument\n\nThe following is an example of docker build with `--squash` argument\n\n``` \nFROM busybox\nRUN echo hello > /hello\nRUN echo world >> /hello\nRUN touch remove_me /remove_me\nENV HELLO=world\nRUN rm /remove_me\n```\n\nAn image named `test` is built with `--squash` argument.\n\n``` \n$ docker build --squash -t test .\n\n<...>\n```\n\nIf everything is right, the history looks like this:\n\n``` \n$ docker history test\n\nIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n4e10cb5b4cac        3 seconds ago                                                       12 B                merge sha256:88a7b0112a41826885df0e7072698006ee8f621c6ab99fca7fe9151d7b599702 to sha256:47bcc53f74dc94b1920f0b34f6036096526296767650f223433fe65c35f149eb\n<missing>           5 minutes ago       /bin/sh -c rm /remove_me                        0 B\n<missing>           5 minutes ago       /bin/sh -c #(nop) ENV HELLO=world               0 B\n<missing>           5 minutes ago       /bin/sh -c touch remove_me /remove_me           0 B\n<missing>           5 minutes ago       /bin/sh -c echo world >> /hello                 0 B\n<missing>           6 minutes ago       /bin/sh -c echo hello > /hello                  0 B\n<missing>           7 weeks ago         /bin/sh -c #(nop) CMD [\"sh\"]                    0 B\n<missing>           7 weeks ago         /bin/sh -c #(nop) ADD file:47ca6e777c36a4cfff   1.113 MB\n```\n\nWe could find that a layer’s name is `<missing>`, and there is a new layer with COMMENT `merge`.\n\nTest the image, check for `/remove_me` being gone, make sure `hello\\nworld` is in `/hello`, make sure the `HELLO` environment variable’s value is `world`.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/build/](https://docs.docker.com/engine/reference/commandline/build/)"
- name: docker builder
  id: engine/reference/commandline/builder/index
  summary: © 2019 Docker, Inc
  description: "# docker builder\n\n  \n\nManage builds\n\n## Usage\n\n``` \n$ docker builder COMMAND\n```\n\n## Child commands\n\n| Command                                        | Description                      |\n|------------------------------------------------|----------------------------------|\n| [docker builder build](../builder_build/index) | Build an image from a Dockerfile |\n| [docker builder prune](../builder_prune/index) | Remove build cache               |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/builder/](https://docs.docker.com/engine/reference/commandline/builder/)"
- name: docker builder build
  id: engine/reference/commandline/builder_build/index
  summary: © 2019 Docker, Inc
  description: "# docker builder build\n\n  \n\nBuild an image from a Dockerfile\n\n## Usage\n\n``` \n$ docker builder build [OPTIONS] PATH | URL | -\n```\n\n## Options\n\n| Name, shorthand           | Default | Description                                                                                                                              |\n|---------------------------|---------|------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |         | Add a custom host-to-IP mapping (host:ip)                                                                                                |\n| `--build-arg`             |         | Set build-time variables                                                                                                                 |\n| `--cache-from`            |         | Images to consider as cache sources                                                                                                      |\n| `--cgroup-parent`         |         | Optional parent cgroup for the container                                                                                                 |\n| `--compress`              |         | Compress the build context using gzip                                                                                                    |\n| `--cpu-period`            |         | Limit the CPU CFS (Completely Fair Scheduler) period                                                                                     |\n| `--cpu-quota`             |         | Limit the CPU CFS (Completely Fair Scheduler) quota                                                                                      |\n| `--cpu-shares` , `-c`     |         | CPU shares (relative weight)                                                                                                             |\n| `--cpuset-cpus`           |         | CPUs in which to allow execution (0-3, 0,1)                                                                                              |\n| `--cpuset-mems`           |         | MEMs in which to allow execution (0-3, 0,1)                                                                                              |\n| `--disable-content-trust` | `true`  | Skip image verification                                                                                                                  |\n| `--file` , `-f`           |         | Name of the Dockerfile (Default is 'PATH/Dockerfile')                                                                                    |\n| `--force-rm`              |         | Always remove intermediate containers                                                                                                    |\n| `--iidfile`               |         | Write the image ID to the file                                                                                                           |\n| `--isolation`             |         | Container isolation technology                                                                                                           |\n| `--label`                 |         | Set metadata for an image                                                                                                                |\n| `--memory` , `-m`         |         | Memory limit                                                                                                                             |\n| `--memory-swap`           |         | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                      |\n| `--network`               |         | Set the networking mode for the RUN instructions during build                                                                            |\n| `--no-cache`              |         | Do not use cache when building the image                                                                                                 |\n| `--output` , `-o`         |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Output destination (format: type=local,dest=path)                                 |\n| `--platform`              |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Set platform if server is multi-platform capable                                  |\n| `--progress`              | `auto`  | Set type of progress output (auto, plain, tty). Use plain to show container output                                                       |\n| `--pull`                  |         | Always attempt to pull a newer version of the image                                                                                      |\n| `--quiet` , `-q`          |         | Suppress the build output and print image ID on success                                                                                  |\n| `--rm`                    | `true`  | Remove intermediate containers after a successful build                                                                                  |\n| `--secret`                |         | Secret file to expose to the build (only if BuildKit enabled): id=mysecret,src=/local/secret                                             |\n| `--security-opt`          |         | Security options                                                                                                                         |\n| `--shm-size`              |         | Size of /dev/shm                                                                                                                         |\n| `--squash`                |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Squash newly built layers into a single new layer                    |\n| `--ssh`                   |         | SSH agent socket or keys to expose to the build (only if BuildKit enabled) (format: default\\|\\<id\\>\\[=\\<socket\\>\\|\\<key\\>\\[,\\<key\\>\\]\\]) |\n| `--stream`                |         | Stream attaches to server to negotiate build context                                                                                     |\n| `--tag` , `-t`            |         | Name and optionally a tag in the 'name:tag' format                                                                                       |\n| `--target`                |         | Set the target build stage to build.                                                                                                     |\n| `--ulimit`                |         | Ulimit options                                                                                                                           |\n\n## Parent command\n\n| Command                            | Description   |\n|:-----------------------------------|:--------------|\n| [docker builder](../builder/index) | Manage builds |\n\n## Related commands\n\n| Command                                        | Description                      |\n|------------------------------------------------|----------------------------------|\n| [docker builder build](index)                  | Build an image from a Dockerfile |\n| [docker builder prune](../builder_prune/index) | Remove build cache               |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/builder_build/](https://docs.docker.com/engine/reference/commandline/builder_build/)"
- name: docker builder prune
  id: engine/reference/commandline/builder_prune/index
  summary: © 2019 Docker, Inc
  description: "# docker builder prune\n\n  \n\nRemove build cache\n\n## Usage\n\n``` \n$ docker builder prune\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                                           |\n|------------------|---------|-------------------------------------------------------|\n| `--all` , `-a`   |         | Remove all unused build cache, not just dangling ones |\n| `--filter`       |         | Provide filter values (e.g. 'until=24h')              |\n| `--force` , `-f` |         | Do not prompt for confirmation                        |\n| `--keep-storage` |         | Amount of disk space to keep for cache                |\n\n## Parent command\n\n| Command                            | Description   |\n|:-----------------------------------|:--------------|\n| [docker builder](../builder/index) | Manage builds |\n\n## Related commands\n\n| Command                                        | Description                      |\n|------------------------------------------------|----------------------------------|\n| [docker builder build](../builder_build/index) | Build an image from a Dockerfile |\n| [docker builder prune](index)                  | Remove build cache               |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/builder_prune/](https://docs.docker.com/engine/reference/commandline/builder_prune/)"
- name: docker checkpoint
  id: engine/reference/commandline/checkpoint/index
  summary: This command is experimental
  description: "# docker checkpoint\n\n  \n\nManage checkpoints\n\n> This command is experimental.\n>\n> This command is experimental on the Docker daemon. It should not be used in production environments. To enable experimental features on the Docker daemon, edit the [daemon.json](../dockerd/index#daemon-configuration-file) and set `experimental` to `true`.\n>\n> Experimental features provide early access to future product functionality. These features are intended for testing and feedback only as they may change between releases without warning or can be removed entirely from a future release. Experimental features must not be used in production environments. Docker does not offer support for experimental features.\n\nFor a list of current experimental features in the Docker CLI, see [Docker CLI Experimental features](https://github.com/docker/cli/blob/master/experimental/README/).\n\n## Usage\n\n``` \n$ docker checkpoint COMMAND\n```\n\n## Description\n\nCheckpoint and Restore is an experimental feature that allows you to freeze a running container by checkpointing it, which turns its state into a collection of files on disk. Later, the container can be restored from the point it was frozen.\n\nThis is accomplished using a tool called [CRIU](https://criu.org), which is an external dependency of this feature. A good overview of the history of checkpoint and restore in Docker is available in this [Kubernetes blog post](https://kubernetes.io/blog/2015/07/how-did-quake-demo-from-dockercon-work/).\n\n### Installing CRIU\n\nIf you use a Debian system, you can add the CRIU PPA and install with `apt-get` [from the criu launchpad](https://launchpad.net/~criu/+archive/ubuntu/ppa).\n\nAlternatively, you can [build CRIU from source](https://criu.org/Installation).\n\nYou need at least version 2.0 of CRIU to run checkpoint and restore in Docker.\n\n### Use cases for checkpoint and restore\n\nThis feature is currently focused on single-host use cases for checkpoint and restore. Here are a few:\n\n- Restarting the host machine without stopping/starting containers\n- Speeding up the start time of slow start applications\n- “Rewinding” processes to an earlier point in time\n- “Forensic debugging” of running processes\n\nAnother primary use case of checkpoint and restore outside of Docker is the live migration of a server from one machine to another. This is possible with the current implementation, but not currently a priority (and so the workflow is not optimized for the task).\n\n### Using checkpoint and restore\n\nA new top level command `docker checkpoint` is introduced, with three subcommands:\n\n- `docker checkpoint create` (creates a new checkpoint)\n- `docker checkpoint ls` (lists existing checkpoints)\n- `docker checkpoint rm` (deletes an existing checkpoint)\n\nAdditionally, a `--checkpoint` flag is added to the `docker container start` command.\n\nThe options for `docker checkpoint create`:\n\n``` \nUsage:  docker checkpoint create [OPTIONS] CONTAINER CHECKPOINT\n\nCreate a checkpoint from a running container\n\n  --leave-running=false    Leave the container running after checkpoint\n  --checkpoint-dir         Use a custom checkpoint storage directory\n```\n\nAnd to restore a container:\n\n``` \nUsage:  docker start --checkpoint CHECKPOINT_ID [OTHER OPTIONS] CONTAINER\n```\n\nExample of using checkpoint and restore on a container:\n\n``` \n$ docker run --security-opt=seccomp:unconfined --name cr -d busybox /bin/sh -c 'i=0; while true; do echo $i; i=$(expr $i + 1); sleep 1; done'\nabc0123\n\n$ docker checkpoint create cr checkpoint1\n\n# <later>\n$ docker start --checkpoint checkpoint1 cr\nabc0123\n```\n\nThis process just logs an incrementing counter to stdout. If you run `docker logs` in between running/checkpoint/restoring you should see that the counter increases while the process is running, stops while it’s checkpointed, and resumes from the point it left off once you restore.\n\n### Known limitations\n\nseccomp is only supported by CRIU in very up to date kernels.\n\nExternal terminal (i.e. `docker run -t ..`) is not supported at the moment. If you try to create a checkpoint for a container with an external terminal, it would fail:\n\n``` \n$ docker checkpoint create cr checkpoint1\nError response from daemon: Cannot checkpoint container c1: rpc error: code = 2 desc = exit status 1: \"criu failed: type NOTIFY errno 0\\nlog file: /var/lib/docker/containers/eb62ebdbf237ce1a8736d2ae3c7d88601fc0a50235b0ba767b559a1f3c5a600b/checkpoints/checkpoint1/criu.work/dump.log\\n\"\n\n$ cat /var/lib/docker/containers/eb62ebdbf237ce1a8736d2ae3c7d88601fc0a50235b0ba767b559a1f3c5a600b/checkpoints/checkpoint1/criu.work/dump.log\nError (mount.c:740): mnt: 126:./dev/console doesn't have a proper root mount\n```\n\n## Child commands\n\n| Command                                                | Description                                  |\n|--------------------------------------------------------|----------------------------------------------|\n| [docker checkpoint create](../checkpoint_create/index) | Create a checkpoint from a running container |\n| [docker checkpoint ls](../checkpoint_ls/index)         | List checkpoints for a container             |\n| [docker checkpoint rm](../checkpoint_rm/index)         | Remove a checkpoint                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/checkpoint/](https://docs.docker.com/engine/reference/commandline/checkpoint/)"
- name: docker checkpoint create
  id: engine/reference/commandline/checkpoint_create/index
  summary: This command is experimental
  description: "# docker checkpoint create\n\n  \n\nCreate a checkpoint from a running container\n\n> This command is experimental.\n>\n> This command is experimental on the Docker daemon. It should not be used in production environments. To enable experimental features on the Docker daemon, edit the [daemon.json](../dockerd/index#daemon-configuration-file) and set `experimental` to `true`.\n>\n> Experimental features provide early access to future product functionality. These features are intended for testing and feedback only as they may change between releases without warning or can be removed entirely from a future release. Experimental features must not be used in production environments. Docker does not offer support for experimental features.\n\nFor a list of current experimental features in the Docker CLI, see [Docker CLI Experimental features](https://github.com/docker/cli/blob/master/experimental/README/).\n\n## Usage\n\n``` \n$ docker checkpoint create [OPTIONS] CONTAINER CHECKPOINT\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                                  |\n|--------------------|---------|----------------------------------------------|\n| `--checkpoint-dir` |         | Use a custom checkpoint storage directory    |\n| `--leave-running`  |         | Leave the container running after checkpoint |\n\n## Parent command\n\n| Command                                  | Description        |\n|:-----------------------------------------|:-------------------|\n| [docker checkpoint](../checkpoint/index) | Manage checkpoints |\n\n## Related commands\n\n| Command                                        | Description                                  |\n|------------------------------------------------|----------------------------------------------|\n| [docker checkpoint create](index)              | Create a checkpoint from a running container |\n| [docker checkpoint ls](../checkpoint_ls/index) | List checkpoints for a container             |\n| [docker checkpoint rm](../checkpoint_rm/index) | Remove a checkpoint                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/checkpoint_create/](https://docs.docker.com/engine/reference/commandline/checkpoint_create/)"
- name: docker checkpoint ls
  id: engine/reference/commandline/checkpoint_ls/index
  summary: This command is experimental
  description: "# docker checkpoint ls\n\n  \n\nList checkpoints for a container\n\n> This command is experimental.\n>\n> This command is experimental on the Docker daemon. It should not be used in production environments. To enable experimental features on the Docker daemon, edit the [daemon.json](../dockerd/index#daemon-configuration-file) and set `experimental` to `true`.\n>\n> Experimental features provide early access to future product functionality. These features are intended for testing and feedback only as they may change between releases without warning or can be removed entirely from a future release. Experimental features must not be used in production environments. Docker does not offer support for experimental features.\n\nFor a list of current experimental features in the Docker CLI, see [Docker CLI Experimental features](https://github.com/docker/cli/blob/master/experimental/README/).\n\n## Usage\n\n``` \n$ docker checkpoint ls [OPTIONS] CONTAINER\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                               |\n|--------------------|---------|-------------------------------------------|\n| `--checkpoint-dir` |         | Use a custom checkpoint storage directory |\n\n## Parent command\n\n| Command                                  | Description        |\n|:-----------------------------------------|:-------------------|\n| [docker checkpoint](../checkpoint/index) | Manage checkpoints |\n\n## Related commands\n\n| Command                                                | Description                                  |\n|--------------------------------------------------------|----------------------------------------------|\n| [docker checkpoint create](../checkpoint_create/index) | Create a checkpoint from a running container |\n| [docker checkpoint ls](index)                          | List checkpoints for a container             |\n| [docker checkpoint rm](../checkpoint_rm/index)         | Remove a checkpoint                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/checkpoint_ls/](https://docs.docker.com/engine/reference/commandline/checkpoint_ls/)"
- name: docker checkpoint rm
  id: engine/reference/commandline/checkpoint_rm/index
  summary: This command is experimental
  description: "# docker checkpoint rm\n\n  \n\nRemove a checkpoint\n\n> This command is experimental.\n>\n> This command is experimental on the Docker daemon. It should not be used in production environments. To enable experimental features on the Docker daemon, edit the [daemon.json](../dockerd/index#daemon-configuration-file) and set `experimental` to `true`.\n>\n> Experimental features provide early access to future product functionality. These features are intended for testing and feedback only as they may change between releases without warning or can be removed entirely from a future release. Experimental features must not be used in production environments. Docker does not offer support for experimental features.\n\nFor a list of current experimental features in the Docker CLI, see [Docker CLI Experimental features](https://github.com/docker/cli/blob/master/experimental/README/).\n\n## Usage\n\n``` \n$ docker checkpoint rm [OPTIONS] CONTAINER CHECKPOINT\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                               |\n|--------------------|---------|-------------------------------------------|\n| `--checkpoint-dir` |         | Use a custom checkpoint storage directory |\n\n## Parent command\n\n| Command                                  | Description        |\n|:-----------------------------------------|:-------------------|\n| [docker checkpoint](../checkpoint/index) | Manage checkpoints |\n\n## Related commands\n\n| Command                                                | Description                                  |\n|--------------------------------------------------------|----------------------------------------------|\n| [docker checkpoint create](../checkpoint_create/index) | Create a checkpoint from a running container |\n| [docker checkpoint ls](../checkpoint_ls/index)         | List checkpoints for a container             |\n| [docker checkpoint rm](index)                          | Remove a checkpoint                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/checkpoint_rm/](https://docs.docker.com/engine/reference/commandline/checkpoint_rm/)"
- name: docker commit
  id: engine/reference/commandline/commit/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker commit\n\n  \n\nCreate a new image from a container’s changes\n\n## Usage\n\n``` \n$ docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nIt can be useful to commit a container’s file changes or settings into a new image. This allows you to debug a container by running an interactive shell, or to export a working dataset to another server. Generally, it is better to use Dockerfiles to manage your images in a documented and maintainable way. [Read more about valid image names and tags](../tag/index).\n\nThe commit operation will not include any data contained in volumes mounted inside the container.\n\nBy default, the container being committed and its processes will be paused while the image is committed. This reduces the likelihood of encountering data corruption during the process of creating the commit. If this behavior is undesired, set the `--pause` option to false.\n\nThe `--change` option will apply `Dockerfile` instructions to the image that is created. Supported `Dockerfile` instructions: `CMD`\\|`ENTRYPOINT`\\|`ENV`\\|`EXPOSE`\\|`LABEL`\\|`ONBUILD`\\|`USER`\\|`VOLUME`\\|`WORKDIR`\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand    | Default | Description                                                  |\n|--------------------|---------|--------------------------------------------------------------|\n| `--author` , `-a`  |         | Author (e.g., \"John Hannibal Smith \\<hannibal@a-team.com\\>\") |\n| `--change` , `-c`  |         | Apply Dockerfile instruction to the created image            |\n| `--message` , `-m` |         | Commit message                                               |\n| `--pause` , `-p`   | `true`  | Pause container during commit                                |\n\n## Examples\n\n### Commit a container\n\n``` \n$ docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS              NAMES\nc3f279d17e0a        ubuntu:12.04        /bin/bash           7 days ago          Up 25 hours                            desperate_dubinsky\n197387f1b436        ubuntu:12.04        /bin/bash           7 days ago          Up 25 hours                            focused_hamilton\n\n$ docker commit c3f279d17e0a  svendowideit/testimage:version3\n\nf5283438590d\n\n$ docker images\n\nREPOSITORY                        TAG                 ID                  CREATED             SIZE\nsvendowideit/testimage            version3            f5283438590d        16 seconds ago      335.7 MB\n```\n\n### Commit a container with new configurations\n\n``` \n$ docker ps\n\nCONTAINER ID       IMAGE               COMMAND             CREATED             STATUS              PORTS              NAMES\nc3f279d17e0a        ubuntu:12.04        /bin/bash           7 days ago          Up 25 hours                            desperate_dubinsky\n197387f1b436        ubuntu:12.04        /bin/bash           7 days ago          Up 25 hours                            focused_hamilton\n\n$ docker inspect -f \"{{ .Config.Env }}\" c3f279d17e0a\n\n[HOME=/ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin]\n\n$ docker commit --change \"ENV DEBUG=true\" c3f279d17e0a  svendowideit/testimage:version3\n\nf5283438590d\n\n$ docker inspect -f \"{{ .Config.Env }}\" f5283438590d\n\n[HOME=/ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin DEBUG=true]\n```\n\n### Commit a container with new `CMD` and `EXPOSE` instructions\n\n``` \n$ docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS              NAMES\nc3f279d17e0a        ubuntu:12.04        /bin/bash           7 days ago          Up 25 hours                            desperate_dubinsky\n197387f1b436        ubuntu:12.04        /bin/bash           7 days ago          Up 25 hours                            focused_hamilton\n\n$ docker commit --change='CMD [\"apachectl\", \"-DFOREGROUND\"]' -c \"EXPOSE 80\" c3f279d17e0a  svendowideit/testimage:version4\n\nf5283438590d\n\n$ docker run -d svendowideit/testimage:version4\n\n89373736e2e7f00bc149bd783073ac43d0507da250e999f3f1036e0db60817c0\n\n$ docker ps\n\nCONTAINER ID        IMAGE               COMMAND                 CREATED             STATUS              PORTS              NAMES\n89373736e2e7        testimage:version4  \"apachectl -DFOREGROU\"  3 seconds ago       Up 2 seconds        80/tcp             distracted_fermat\nc3f279d17e0a        ubuntu:12.04        /bin/bash               7 days ago          Up 25 hours                            desperate_dubinsky\n197387f1b436        ubuntu:12.04        /bin/bash               7 days ago          Up 25 hours                            focused_hamilton\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/commit/](https://docs.docker.com/engine/reference/commandline/commit/)"
- name: docker config
  id: engine/reference/commandline/config/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker config\n\n  \n\nManage Docker configs\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker config COMMAND\n```\n\n## Description\n\nManage configs.\n\n## Child commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker config create](../config_create/index)   | Create a config from a file or STDIN                |\n| [docker config inspect](../config_inspect/index) | Display detailed information on one or more configs |\n| [docker config ls](../config_ls/index)           | List configs                                        |\n| [docker config rm](../config_rm/index)           | Remove one or more configs                          |\n\n## More info\n\n[Store configuration data using Docker Configs](../../../swarm/configs/index)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/config/](https://docs.docker.com/engine/reference/commandline/config/)"
- name: docker config create
  id: engine/reference/commandline/config_create/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker config create\n\n  \n\nCreate a config from a file or STDIN\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker config create [OPTIONS] CONFIG file|-\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a config using standard input or from a file for the config content.\n\nFor detailed information about using configs, refer to [store configuration data using Docker Configs](../../../swarm/configs/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand     | Default | Description     |\n|---------------------|---------|-----------------|\n| `--label` , `-l`    |         | Config labels   |\n| `--template-driver` |         | Template driver |\n\n## Examples\n\n### Create a config\n\n``` \n$ printf <config> | docker config create my_config -\n\nonakdyv307se2tl7nl20anokv\n\n$ docker config ls\n\nID                          NAME                CREATED             UPDATED\nonakdyv307se2tl7nl20anokv   my_config           6 seconds ago       6 seconds ago\n```\n\n### Create a config with a file\n\n``` \n$ docker config create my_config ./config.json\n\ndg426haahpi5ezmkkj5kyl3sn\n\n$ docker config ls\n\nID                          NAME                CREATED             UPDATED\ndg426haahpi5ezmkkj5kyl3sn   my_config           7 seconds ago       7 seconds ago\n```\n\n### Create a config with labels\n\n``` \n$ docker config create \\\n    --label env=dev \\\n    --label rev=20170324 \\\n    my_config ./config.json\n\neo7jnzguqgtpdah3cm5srfb97\n```\n\n``` \n$ docker config inspect my_config\n\n[\n    {\n        \"ID\": \"eo7jnzguqgtpdah3cm5srfb97\",\n        \"Version\": {\n            \"Index\": 17\n        },\n        \"CreatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n        \"UpdatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n        \"Spec\": {\n            \"Name\": \"my_config\",\n            \"Labels\": {\n                \"env\": \"dev\",\n                \"rev\": \"20170324\"\n            },\n            \"Data\": \"aGVsbG8K\"\n        }\n    }\n]\n```\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker config](../config/index) | Manage Docker configs |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker config create](index)                    | Create a config from a file or STDIN                |\n| [docker config inspect](../config_inspect/index) | Display detailed information on one or more configs |\n| [docker config ls](../config_ls/index)           | List configs                                        |\n| [docker config rm](../config_rm/index)           | Remove one or more configs                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/config_create/](https://docs.docker.com/engine/reference/commandline/config_create/)"
- name: docker config inspect
  id: engine/reference/commandline/config_inspect/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker config inspect\n\n  \n\nDisplay detailed information on one or more configs\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker config inspect [OPTIONS] CONFIG [CONFIG...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nInspects the specified config.\n\nBy default, this renders all results in a JSON array. If a format is specified, the given template will be executed for each result.\n\nGo’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nFor detailed information about using configs, refer to [store configuration data using Docker Configs](../../../swarm/configs/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                      |\n|-------------------|---------|--------------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template    |\n| `--pretty`        |         | Print the information in a human friendly format |\n\n## Examples\n\n### Inspect a config by name or ID\n\nYou can inspect a config, either by its *name*, or *ID*\n\nFor example, given the following config:\n\n``` \n$ docker config ls\n\nID                          NAME                CREATED             UPDATED\neo7jnzguqgtpdah3cm5srfb97   my_config           3 minutes ago       3 minutes ago\n```\n\n``` \n$ docker config inspect config.json\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"ID\": \"eo7jnzguqgtpdah3cm5srfb97\",\n    \"Version\": {\n      \"Index\": 17\n    },\n    \"CreatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n    \"UpdatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n    \"Spec\": {\n      \"Name\": \"my_config\",\n      \"Labels\": {\n        \"env\": \"dev\",\n        \"rev\": \"20170324\"\n      },\n      \"Data\": \"aGVsbG8K\"\n    }\n  }\n]\n```\n\n### Formatting\n\nYou can use the --format option to obtain specific information about a config. The following example command outputs the creation time of the config.\n\n``` \n$ docker config inspect --format='{{.CreatedAt}}' eo7jnzguqgtpdah3cm5srfb97\n\n2017-03-24 08:15:09.735271783 +0000 UTC\n```\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker config](../config/index) | Manage Docker configs |\n\n## Related commands\n\n| Command                                        | Description                                         |\n|------------------------------------------------|-----------------------------------------------------|\n| [docker config create](../config_create/index) | Create a config from a file or STDIN                |\n| [docker config inspect](index)                 | Display detailed information on one or more configs |\n| [docker config ls](../config_ls/index)         | List configs                                        |\n| [docker config rm](../config_rm/index)         | Remove one or more configs                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/config_inspect/](https://docs.docker.com/engine/reference/commandline/config_inspect/)"
- name: docker config ls
  id: engine/reference/commandline/config_ls/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker config ls\n\n  \n\nList configs\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker config ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRun this command on a manager node to list the configs in the swarm.\n\nFor detailed information about using configs, refer to [store configuration data using Docker Configs](../../../swarm/configs/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print configs using a Go template   |\n| `--quiet` , `-q`  |         | Only display IDs                           |\n\n## Examples\n\n``` \n$ docker config ls\n\nID                          NAME                        CREATED             UPDATED\n6697bflskwj1998km1gnnjr38   q5s5570vtvnimefos1fyeo2u2   6 weeks ago         6 weeks ago\n9u9hk4br2ej0wgngkga6rp4hq   my_config                   5 weeks ago         5 weeks ago\nmem02h8n73mybpgqjf0kfi1n0   test_config                 3 seconds ago       3 seconds ago\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- [id](#id) (config’s ID)\n- [label](#label) (`label=<key>` or `label=<key>=<value>`)\n- [name](#name) (config’s name)\n\n#### id\n\nThe `id` filter matches all or prefix of a config’s id.\n\n``` \n$ docker config ls -f \"id=6697bflskwj1998km1gnnjr38\"\n\nID                          NAME                        CREATED             UPDATED\n6697bflskwj1998km1gnnjr38   q5s5570vtvnimefos1fyeo2u2   6 weeks ago         6 weeks ago\n```\n\n#### label\n\nThe `label` filter matches configs based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches all configs with a `project` label regardless of its value:\n\n``` \n$ docker config ls --filter label=project\n\nID                          NAME                        CREATED             UPDATED\nmem02h8n73mybpgqjf0kfi1n0   test_config                 About an hour ago   About an hour ago\n```\n\nThe following filter matches only services with the `project` label with the `project-a` value.\n\n``` \n$ docker service ls --filter label=project=test\n\nID                          NAME                        CREATED             UPDATED\nmem02h8n73mybpgqjf0kfi1n0   test_config                 About an hour ago   About an hour ago\n```\n\n#### name\n\nThe `name` filter matches on all or prefix of a config’s name.\n\nThe following filter matches config with a name containing a prefix of `test`.\n\n``` \n$ docker config ls --filter name=test_config\n\nID                          NAME                        CREATED             UPDATED\nmem02h8n73mybpgqjf0kfi1n0   test_config                 About an hour ago   About an hour ago\n```\n\n### Format the output\n\nThe formatting option (`--format`) pretty prints configs output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder  | Description                                                                    |\n|--------------|--------------------------------------------------------------------------------|\n| `.ID`        | Config ID                                                                      |\n| `.Name`      | Config name                                                                    |\n| `.CreatedAt` | Time when the config was created                                               |\n| `.UpdatedAt` | Time when the config was updated                                               |\n| `.Labels`    | All labels assigned to the config                                              |\n| `.Label`     | Value of a specific label for this config. For example `{{.Label \"my-label\"}}` |\n\nWhen using the `--format` option, the `config ls` command will either output the data exactly as the template declares or, when using the `table` directive, will include column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `Name` entries separated by a colon (`:`) for all images:\n\n``` \n$ docker config ls --format \"{{.ID}}: {{.Name}}\"\n\n77af4d6b9913: config-1\nb6fa739cedf5: config-2\n78a85c484f71: config-3\n```\n\nTo list all configs with their name and created date in a table format you can use:\n\n``` \n$ docker config ls --format \"table {{.ID}}\\t{{.Name}}\\t{{.CreatedAt}}\"\n\nID                  NAME                      CREATED\n77af4d6b9913        config-1                  5 minutes ago\nb6fa739cedf5        config-2                  3 hours ago\n78a85c484f71        config-3                  10 days ago\n```\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker config](../config/index) | Manage Docker configs |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker config create](../config_create/index)   | Create a config from a file or STDIN                |\n| [docker config inspect](../config_inspect/index) | Display detailed information on one or more configs |\n| [docker config ls](index)                        | List configs                                        |\n| [docker config rm](../config_rm/index)           | Remove one or more configs                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/config_ls/](https://docs.docker.com/engine/reference/commandline/config_ls/)"
- name: docker config rm
  id: engine/reference/commandline/config_rm/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker config rm\n\n  \n\nRemove one or more configs\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker config rm CONFIG [CONFIG...]\n```\n\n## Description\n\nRemoves the specified configs from the swarm.\n\nFor detailed information about using configs, refer to [store configuration data using Docker Configs](../../../swarm/configs/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\nThis example removes a config:\n\n``` \n$ docker config rm my_config\nsapth4csdo5b6wz2p5uimh5xg\n```\n\n> **Warning**\n>\n> Unlike `docker rm`, this command does not ask for confirmation before removing a config.\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker config](../config/index) | Manage Docker configs |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker config create](../config_create/index)   | Create a config from a file or STDIN                |\n| [docker config inspect](../config_inspect/index) | Display detailed information on one or more configs |\n| [docker config ls](../config_ls/index)           | List configs                                        |\n| [docker config rm](index)                        | Remove one or more configs                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/config_rm/](https://docs.docker.com/engine/reference/commandline/config_rm/)"
- name: docker container
  id: engine/reference/commandline/container/index
  summary: Manage containers
  description: "# docker container\n\n  \n\nManage containers\n\n## Usage\n\n``` \n$ docker container COMMAND\n```\n\n## Description\n\nManage containers.\n\n## Child commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container/](https://docs.docker.com/engine/reference/commandline/container/)"
- name: docker container attach
  id: engine/reference/commandline/container_attach/index
  summary: © 2019 Docker, Inc
  description: "# docker container attach\n\n  \n\nAttach local standard input, output, and error streams to a running container\n\n## Usage\n\n``` \n$ docker container attach [OPTIONS] CONTAINER\n```\n\n## Options\n\n| Name, shorthand | Default | Description                                         |\n|-----------------|---------|-----------------------------------------------------|\n| `--detach-keys` |         | Override the key sequence for detaching a container |\n| `--no-stdin`    |         | Do not attach STDIN                                 |\n| `--sig-proxy`   | `true`  | Proxy all received signals to the process           |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](index)                       | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_attach/](https://docs.docker.com/engine/reference/commandline/container_attach/)"
- name: docker container commit
  id: engine/reference/commandline/container_commit/index
  summary: © 2019 Docker, Inc
  description: "# docker container commit\n\n  \n\nCreate a new image from a container’s changes\n\n## Usage\n\n``` \n$ docker container commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                                                  |\n|--------------------|---------|--------------------------------------------------------------|\n| `--author` , `-a`  |         | Author (e.g., \"John Hannibal Smith \\<hannibal@a-team.com\\>\") |\n| `--change` , `-c`  |         | Apply Dockerfile instruction to the created image            |\n| `--message` , `-m` |         | Commit message                                               |\n| `--pause` , `-p`   | `true`  | Pause container during commit                                |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](index)                       | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_commit/](https://docs.docker.com/engine/reference/commandline/container_commit/)"
- name: docker container cp
  id: engine/reference/commandline/container_cp/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker container cp\n\n  \n\nCopy files/folders between a container and the local filesystem\n\n## Usage\n\n``` \n$ docker container cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-\ndocker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCopy files/folders between a container and the local filesystem\n\nUse ‘-‘ as the source to read a tar archive from stdin and extract it to a directory destination in a container. Use ‘-‘ as the destination to stream a tar archive of a container source to stdout.\n\n## Options\n\n| Name, shorthand        | Default | Description                                 |\n|------------------------|---------|---------------------------------------------|\n| `--archive` , `-a`     |         | Archive mode (copy all uid/gid information) |\n| `--follow-link` , `-L` |         | Always follow symbol link in SRC_PATH       |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](index)                           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_cp/](https://docs.docker.com/engine/reference/commandline/container_cp/)"
- name: docker container create
  id: engine/reference/commandline/container_create/index
  summary: © 2019 Docker, Inc
  description: "# docker container create\n\n  \n\nCreate a new container\n\n## Usage\n\n``` \n$ docker container create [OPTIONS] IMAGE [COMMAND] [ARG...]\n```\n\n## Options\n\n| Name, shorthand           | Default   | Description                                                                                                                                                                                                                                                                                                                            |\n|---------------------------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |           | Add a custom host-to-IP mapping (host:ip)                                                                                                                                                                                                                                                                                              |\n| `--attach` , `-a`         |           | Attach to STDIN, STDOUT or STDERR                                                                                                                                                                                                                                                                                                      |\n| `--blkio-weight`          |           | Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)                                                                                                                                                                                                                                                           |\n| `--blkio-weight-device`   |           | Block IO weight (relative device weight)                                                                                                                                                                                                                                                                                               |\n| `--cap-add`               |           | Add Linux capabilities                                                                                                                                                                                                                                                                                                                 |\n| `--cap-drop`              |           | Drop Linux capabilities                                                                                                                                                                                                                                                                                                                |\n| `--cgroup-parent`         |           | Optional parent cgroup for the container                                                                                                                                                                                                                                                                                               |\n| `--cgroupns`              |           | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Cgroup namespace to use (host\\|private) 'host': Run the container in the Docker host's cgroup namespace 'private': Run the container in its own private cgroup namespace '': Use the cgroup namespace as configured by the default-cgroupns-mode option on the daemon (default) |\n| `--cidfile`               |           | Write the container ID to the file                                                                                                                                                                                                                                                                                                     |\n| `--cpu-count`             |           | CPU count (Windows only)                                                                                                                                                                                                                                                                                                               |\n| `--cpu-percent`           |           | CPU percent (Windows only)                                                                                                                                                                                                                                                                                                             |\n| `--cpu-period`            |           | Limit CPU CFS (Completely Fair Scheduler) period                                                                                                                                                                                                                                                                                       |\n| `--cpu-quota`             |           | Limit CPU CFS (Completely Fair Scheduler) quota                                                                                                                                                                                                                                                                                        |\n| `--cpu-rt-period`         |           | Limit CPU real-time period in microseconds                                                                                                                                                                                                                                                                                             |\n| `--cpu-rt-runtime`        |           | Limit CPU real-time runtime in microseconds                                                                                                                                                                                                                                                                                            |\n| `--cpu-shares` , `-c`     |           | CPU shares (relative weight)                                                                                                                                                                                                                                                                                                           |\n| `--cpus`                  |           | Number of CPUs                                                                                                                                                                                                                                                                                                                         |\n| `--cpuset-cpus`           |           | CPUs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--cpuset-mems`           |           | MEMs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--device`                |           | Add a host device to the container                                                                                                                                                                                                                                                                                                     |\n| `--device-cgroup-rule`    |           | Add a rule to the cgroup allowed devices list                                                                                                                                                                                                                                                                                          |\n| `--device-read-bps`       |           | Limit read rate (bytes per second) from a device                                                                                                                                                                                                                                                                                       |\n| `--device-read-iops`      |           | Limit read rate (IO per second) from a device                                                                                                                                                                                                                                                                                          |\n| `--device-write-bps`      |           | Limit write rate (bytes per second) to a device                                                                                                                                                                                                                                                                                        |\n| `--device-write-iops`     |           | Limit write rate (IO per second) to a device                                                                                                                                                                                                                                                                                           |\n| `--disable-content-trust` | `true`    | Skip image verification                                                                                                                                                                                                                                                                                                                |\n| `--dns`                   |           | Set custom DNS servers                                                                                                                                                                                                                                                                                                                 |\n| `--dns-opt`               |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-option`            |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-search`            |           | Set custom DNS search domains                                                                                                                                                                                                                                                                                                          |\n| `--domainname`            |           | Container NIS domain name                                                                                                                                                                                                                                                                                                              |\n| `--entrypoint`            |           | Overwrite the default ENTRYPOINT of the image                                                                                                                                                                                                                                                                                          |\n| `--env` , `-e`            |           | Set environment variables                                                                                                                                                                                                                                                                                                              |\n| `--env-file`              |           | Read in a file of environment variables                                                                                                                                                                                                                                                                                                |\n| `--expose`                |           | Expose a port or a range of ports                                                                                                                                                                                                                                                                                                      |\n| `--gpus`                  |           | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) GPU devices to add to the container ('all' to pass all GPUs)                                                                                                                                                                                                                    |\n| `--group-add`             |           | Add additional groups to join                                                                                                                                                                                                                                                                                                          |\n| `--health-cmd`            |           | Command to run to check health                                                                                                                                                                                                                                                                                                         |\n| `--health-interval`       |           | Time between running the check (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                              |\n| `--health-retries`        |           | Consecutive failures needed to report unhealthy                                                                                                                                                                                                                                                                                        |\n| `--health-start-period`   |           | Start period for the container to initialize before starting health-retries countdown (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                       |\n| `--health-timeout`        |           | Maximum time to allow one check to run (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                      |\n| `--help`                  |           | Print usage                                                                                                                                                                                                                                                                                                                            |\n| `--hostname` , `-h`       |           | Container host name                                                                                                                                                                                                                                                                                                                    |\n| `--init`                  |           | Run an init inside the container that forwards signals and reaps processes                                                                                                                                                                                                                                                             |\n| `--interactive` , `-i`    |           | Keep STDIN open even if not attached                                                                                                                                                                                                                                                                                                   |\n| `--io-maxbandwidth`       |           | Maximum IO bandwidth limit for the system drive (Windows only)                                                                                                                                                                                                                                                                         |\n| `--io-maxiops`            |           | Maximum IOps limit for the system drive (Windows only)                                                                                                                                                                                                                                                                                 |\n| `--ip`                    |           | IPv4 address (e.g., 172.30.100.104)                                                                                                                                                                                                                                                                                                    |\n| `--ip6`                   |           | IPv6 address (e.g., 2001:db8::33)                                                                                                                                                                                                                                                                                                      |\n| `--ipc`                   |           | IPC mode to use                                                                                                                                                                                                                                                                                                                        |\n| `--isolation`             |           | Container isolation technology                                                                                                                                                                                                                                                                                                         |\n| `--kernel-memory`         |           | Kernel memory limit                                                                                                                                                                                                                                                                                                                    |\n| `--label` , `-l`          |           | Set meta data on a container                                                                                                                                                                                                                                                                                                           |\n| `--label-file`            |           | Read in a line delimited file of labels                                                                                                                                                                                                                                                                                                |\n| `--link`                  |           | Add link to another container                                                                                                                                                                                                                                                                                                          |\n| `--link-local-ip`         |           | Container IPv4/IPv6 link-local addresses                                                                                                                                                                                                                                                                                               |\n| `--log-driver`            |           | Logging driver for the container                                                                                                                                                                                                                                                                                                       |\n| `--log-opt`               |           | Log driver options                                                                                                                                                                                                                                                                                                                     |\n| `--mac-address`           |           | Container MAC address (e.g., 92:d0:c6:0a:29:33)                                                                                                                                                                                                                                                                                        |\n| `--memory` , `-m`         |           | Memory limit                                                                                                                                                                                                                                                                                                                           |\n| `--memory-reservation`    |           | Memory soft limit                                                                                                                                                                                                                                                                                                                      |\n| `--memory-swap`           |           | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                                                                                                                                                                                                                    |\n| `--memory-swappiness`     | `-1`      | Tune container memory swappiness (0 to 100)                                                                                                                                                                                                                                                                                            |\n| `--mount`                 |           | Attach a filesystem mount to the container                                                                                                                                                                                                                                                                                             |\n| `--name`                  |           | Assign a name to the container                                                                                                                                                                                                                                                                                                         |\n| `--net`                   |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--net-alias`             |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--network`               |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--network-alias`         |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--no-healthcheck`        |           | Disable any container-specified HEALTHCHECK                                                                                                                                                                                                                                                                                            |\n| `--oom-kill-disable`      |           | Disable OOM Killer                                                                                                                                                                                                                                                                                                                     |\n| `--oom-score-adj`         |           | Tune host's OOM preferences (-1000 to 1000)                                                                                                                                                                                                                                                                                            |\n| `--pid`                   |           | PID namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--pids-limit`            |           | Tune container pids limit (set -1 for unlimited)                                                                                                                                                                                                                                                                                       |\n| `--platform`              |           | Set platform if server is multi-platform capable                                                                                                                                                                                                                                                                                       |\n| `--privileged`            |           | Give extended privileges to this container                                                                                                                                                                                                                                                                                             |\n| `--publish` , `-p`        |           | Publish a container's port(s) to the host                                                                                                                                                                                                                                                                                              |\n| `--publish-all` , `-P`    |           | Publish all exposed ports to random ports                                                                                                                                                                                                                                                                                              |\n| `--pull`                  | `missing` | Pull image before creating (\"always\"\\|\"missing\"\\|\"never\")                                                                                                                                                                                                                                                                              |\n| `--read-only`             |           | Mount the container's root filesystem as read only                                                                                                                                                                                                                                                                                     |\n| `--restart`               | `no`      | Restart policy to apply when a container exits                                                                                                                                                                                                                                                                                         |\n| `--rm`                    |           | Automatically remove the container when it exits                                                                                                                                                                                                                                                                                       |\n| `--runtime`               |           | Runtime to use for this container                                                                                                                                                                                                                                                                                                      |\n| `--security-opt`          |           | Security Options                                                                                                                                                                                                                                                                                                                       |\n| `--shm-size`              |           | Size of /dev/shm                                                                                                                                                                                                                                                                                                                       |\n| `--stop-signal`           | `SIGTERM` | Signal to stop a container                                                                                                                                                                                                                                                                                                             |\n| `--stop-timeout`          |           | Timeout (in seconds) to stop a container                                                                                                                                                                                                                                                                                               |\n| `--storage-opt`           |           | Storage driver options for the container                                                                                                                                                                                                                                                                                               |\n| `--sysctl`                |           | Sysctl options                                                                                                                                                                                                                                                                                                                         |\n| `--tmpfs`                 |           | Mount a tmpfs directory                                                                                                                                                                                                                                                                                                                |\n| `--tty` , `-t`            |           | Allocate a pseudo-TTY                                                                                                                                                                                                                                                                                                                  |\n| `--ulimit`                |           | Ulimit options                                                                                                                                                                                                                                                                                                                         |\n| `--user` , `-u`           |           | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\])                                                                                                                                                                                                                                                                             |\n| `--userns`                |           | User namespace to use                                                                                                                                                                                                                                                                                                                  |\n| `--uts`                   |           | UTS namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--volume` , `-v`         |           | Bind mount a volume                                                                                                                                                                                                                                                                                                                    |\n| `--volume-driver`         |           | Optional volume driver for the container                                                                                                                                                                                                                                                                                               |\n| `--volumes-from`          |           | Mount volumes from the specified container(s)                                                                                                                                                                                                                                                                                          |\n| `--workdir` , `-w`        |           | Working directory inside the container                                                                                                                                                                                                                                                                                                 |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](index)                       | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_create/](https://docs.docker.com/engine/reference/commandline/container_create/)"
- name: docker container diff
  id: engine/reference/commandline/container_diff/index
  summary: © 2019 Docker, Inc
  description: "# docker container diff\n\n  \n\nInspect changes to files or directories on a container’s filesystem\n\n## Usage\n\n``` \n$ docker container diff CONTAINER\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](index)                         | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_diff/](https://docs.docker.com/engine/reference/commandline/container_diff/)"
- name: docker container exec
  id: engine/reference/commandline/container_exec/index
  summary: © 2019 Docker, Inc
  description: "# docker container exec\n\n  \n\nRun a command in a running container\n\n## Usage\n\n``` \n$ docker container exec [OPTIONS] CONTAINER COMMAND [ARG...]\n```\n\n## Options\n\n| Name, shorthand        | Default | Description                                                |\n|------------------------|---------|------------------------------------------------------------|\n| `--detach` , `-d`      |         | Detached mode: run command in the background               |\n| `--detach-keys`        |         | Override the key sequence for detaching a container        |\n| `--env` , `-e`         |         | Set environment variables                                  |\n| `--env-file`           |         | Read in a file of environment variables                    |\n| `--interactive` , `-i` |         | Keep STDIN open even if not attached                       |\n| `--privileged`         |         | Give extended privileges to the command                    |\n| `--tty` , `-t`         |         | Allocate a pseudo-TTY                                      |\n| `--user` , `-u`        |         | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\]) |\n| `--workdir` , `-w`     |         | Working directory inside the container                     |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](index)                         | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_exec/](https://docs.docker.com/engine/reference/commandline/container_exec/)"
- name: docker container export
  id: engine/reference/commandline/container_export/index
  summary: © 2019 Docker, Inc
  description: "# docker container export\n\n  \n\nExport a container’s filesystem as a tar archive\n\n## Usage\n\n``` \n$ docker container export [OPTIONS] CONTAINER\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                        |\n|-------------------|---------|------------------------------------|\n| `--output` , `-o` |         | Write to a file, instead of STDOUT |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](index)                       | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_export/](https://docs.docker.com/engine/reference/commandline/container_export/)"
- name: docker container inspect
  id: engine/reference/commandline/container_inspect/index
  summary: © 2019 Docker, Inc
  description: "# docker container inspect\n\n  \n\nDisplay detailed information on one or more containers\n\n## Usage\n\n``` \n$ docker container inspect [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n| `--size` , `-s`   |         | Display total file sizes                      |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](index)                      | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_inspect/](https://docs.docker.com/engine/reference/commandline/container_inspect/)"
- name: docker container kill
  id: engine/reference/commandline/container_kill/index
  summary: © 2019 Docker, Inc
  description: "# docker container kill\n\n  \n\nKill one or more running containers\n\n## Usage\n\n``` \n$ docker container kill [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                     |\n|-------------------|---------|---------------------------------|\n| `--signal` , `-s` | `KILL`  | Signal to send to the container |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](index)                         | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_kill/](https://docs.docker.com/engine/reference/commandline/container_kill/)"
- name: docker container logs
  id: engine/reference/commandline/container_logs/index
  summary: © 2019 Docker, Inc
  description: "# docker container logs\n\n  \n\nFetch the logs of a container\n\n## Usage\n\n``` \n$ docker container logs [OPTIONS] CONTAINER\n```\n\n## Options\n\n| Name, shorthand       | Default | Description                                                                                    |\n|-----------------------|---------|------------------------------------------------------------------------------------------------|\n| `--details`           |         | Show extra details provided to logs                                                            |\n| `--follow` , `-f`     |         | Follow log output                                                                              |\n| `--since`             |         | Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)    |\n| `--tail` , `-n`       | `all`   | Number of lines to show from the end of the logs                                               |\n| `--timestamps` , `-t` |         | Show timestamps                                                                                |\n| `--until`             |         | Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](index)                         | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_logs/](https://docs.docker.com/engine/reference/commandline/container_logs/)"
- name: docker container ls
  id: engine/reference/commandline/container_ls/index
  summary: © 2019 Docker, Inc
  description: "# docker container ls\n\n  \n\nList containers\n\n## Usage\n\n``` \n$ docker container ls [OPTIONS]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                                             |\n|-------------------|---------|---------------------------------------------------------|\n| `--all` , `-a`    |         | Show all containers (default shows just running)        |\n| `--filter` , `-f` |         | Filter output based on conditions provided              |\n| `--format`        |         | Pretty-print containers using a Go template             |\n| `--last` , `-n`   | `-1`    | Show n last created containers (includes all states)    |\n| `--latest` , `-l` |         | Show the latest created container (includes all states) |\n| `--no-trunc`      |         | Don't truncate output                                   |\n| `--quiet` , `-q`  |         | Only display container IDs                              |\n| `--size` , `-s`   |         | Display total file sizes                                |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](index)                           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_ls/](https://docs.docker.com/engine/reference/commandline/container_ls/)"
- name: docker container pause
  id: engine/reference/commandline/container_pause/index
  summary: © 2019 Docker, Inc
  description: "# docker container pause\n\n  \n\nPause all processes within one or more containers\n\n## Usage\n\n``` \n$ docker container pause CONTAINER [CONTAINER...]\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](index)                        | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_pause/](https://docs.docker.com/engine/reference/commandline/container_pause/)"
- name: docker container port
  id: engine/reference/commandline/container_port/index
  summary: © 2019 Docker, Inc
  description: "# docker container port\n\n  \n\nList port mappings or a specific mapping for the container\n\n## Usage\n\n``` \n$ docker container port CONTAINER [PRIVATE_PORT[/PROTO]]\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](index)                         | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_port/](https://docs.docker.com/engine/reference/commandline/container_port/)"
- name: docker container prune
  id: engine/reference/commandline/container_prune/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker container prune\n\n  \n\nRemove all stopped containers\n\n## Usage\n\n``` \n$ docker container prune [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemoves all stopped containers.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                        |\n|------------------|---------|----------------------------------------------------|\n| `--filter`       |         | Provide filter values (e.g. 'until=\\<timestamp\\>') |\n| `--force` , `-f` |         | Do not prompt for confirmation                     |\n\n## Examples\n\n### Prune containers\n\n``` \n$ docker container prune\nWARNING! This will remove all stopped containers.\nAre you sure you want to continue? [y/N] y\nDeleted Containers:\n4a7f7eebae0f63178aff7eb0aa39cd3f0627a203ab2df258c1a00b456cf20063\nf98f9c2aa1eaf727e4ec9c0283bc7d4aa4762fbdba7f26191f26c97f64090360\n\nTotal reclaimed space: 212 B\n```\n\n### Filtering\n\nThe filtering flag (`--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- until (`<timestamp>`) - only remove containers created before given timestamp\n- label (`label=<key>`, `label=<key>=<value>`, `label!=<key>`, or `label!=<key>=<value>`) - only remove containers with (or without, in case `label!=...` is used) the specified labels.\n\nThe `until` filter can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the daemon machine’s time. Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the daemon will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long.\n\nThe `label` filter accepts two formats. One is the `label=...` (`label=<key>` or `label=<key>=<value>`), which removes containers with the specified labels. The other format is the `label!=...` (`label!=<key>` or `label!=<key>=<value>`), which removes containers without the specified labels.\n\nThe following removes containers created more than 5 minutes ago:\n\n``` \n$ docker ps -a --format 'table {{.ID}}\\t{{.Image}}\\t{{.Command}}\\t{{.CreatedAt}}\\t{{.Status}}'\n\nCONTAINER ID        IMAGE               COMMAND             CREATED AT                      STATUS\n61b9efa71024        busybox             \"sh\"                2017-01-04 13:23:33 -0800 PST   Exited (0) 41 seconds ago\n53a9bc23a516        busybox             \"sh\"                2017-01-04 13:11:59 -0800 PST   Exited (0) 12 minutes ago\n\n$ docker container prune --force --filter \"until=5m\"\n\nDeleted Containers:\n53a9bc23a5168b6caa2bfbefddf1b30f93c7ad57f3dec271fd32707497cb9369\n\nTotal reclaimed space: 25 B\n\n$ docker ps -a --format 'table {{.ID}}\\t{{.Image}}\\t{{.Command}}\\t{{.CreatedAt}}\\t{{.Status}}'\n\nCONTAINER ID        IMAGE               COMMAND             CREATED AT                      STATUS\n61b9efa71024        busybox             \"sh\"                2017-01-04 13:23:33 -0800 PST   Exited (0) 44 seconds ago\n```\n\nThe following removes containers created before `2017-01-04T13:10:00`:\n\n``` \n$ docker ps -a --format 'table {{.ID}}\\t{{.Image}}\\t{{.Command}}\\t{{.CreatedAt}}\\t{{.Status}}'\n\nCONTAINER ID        IMAGE               COMMAND             CREATED AT                      STATUS\n53a9bc23a516        busybox             \"sh\"                2017-01-04 13:11:59 -0800 PST   Exited (0) 7 minutes ago\n4a75091a6d61        busybox             \"sh\"                2017-01-04 13:09:53 -0800 PST   Exited (0) 9 minutes ago\n\n$ docker container prune --force --filter \"until=2017-01-04T13:10:00\"\n\nDeleted Containers:\n4a75091a6d618526fcd8b33ccd6e5928ca2a64415466f768a6180004b0c72c6c\n\nTotal reclaimed space: 27 B\n\n$ docker ps -a --format 'table {{.ID}}\\t{{.Image}}\\t{{.Command}}\\t{{.CreatedAt}}\\t{{.Status}}'\n\nCONTAINER ID        IMAGE               COMMAND             CREATED AT                      STATUS\n53a9bc23a516        busybox             \"sh\"                2017-01-04 13:11:59 -0800 PST   Exited (0) 9 minutes ago\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](index)                        | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_prune/](https://docs.docker.com/engine/reference/commandline/container_prune/)"
- name: docker container rename
  id: engine/reference/commandline/container_rename/index
  summary: © 2019 Docker, Inc
  description: "# docker container rename\n\n  \n\nRename a container\n\n## Usage\n\n``` \n$ docker container rename CONTAINER NEW_NAME\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](index)                       | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_rename/](https://docs.docker.com/engine/reference/commandline/container_rename/)"
- name: docker container restart
  id: engine/reference/commandline/container_restart/index
  summary: © 2019 Docker, Inc
  description: "# docker container restart\n\n  \n\nRestart one or more containers\n\n## Usage\n\n``` \n$ docker container restart [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand | Default | Description                                           |\n|-----------------|---------|-------------------------------------------------------|\n| `--time` , `-t` | `10`    | Seconds to wait for stop before killing the container |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](index)                      | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_restart/](https://docs.docker.com/engine/reference/commandline/container_restart/)"
- name: docker container rm
  id: engine/reference/commandline/container_rm/index
  summary: © 2019 Docker, Inc
  description: "# docker container rm\n\n  \n\nRemove one or more containers\n\n## Usage\n\n``` \n$ docker container rm [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                                             |\n|--------------------|---------|---------------------------------------------------------|\n| `--force` , `-f`   |         | Force the removal of a running container (uses SIGKILL) |\n| `--link` , `-l`    |         | Remove the specified link                               |\n| `--volumes` , `-v` |         | Remove anonymous volumes associated with the container  |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](index)                           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_rm/](https://docs.docker.com/engine/reference/commandline/container_rm/)"
- name: docker container run
  id: engine/reference/commandline/container_run/index
  summary: © 2019 Docker, Inc
  description: "# docker container run\n\n  \n\nRun a command in a new container\n\n## Usage\n\n``` \n$ docker container run [OPTIONS] IMAGE [COMMAND] [ARG...]\n```\n\n## Options\n\n| Name, shorthand           | Default   | Description                                                                                                                                                                                                                                                                                                                            |\n|---------------------------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |           | Add a custom host-to-IP mapping (host:ip)                                                                                                                                                                                                                                                                                              |\n| `--attach` , `-a`         |           | Attach to STDIN, STDOUT or STDERR                                                                                                                                                                                                                                                                                                      |\n| `--blkio-weight`          |           | Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)                                                                                                                                                                                                                                                           |\n| `--blkio-weight-device`   |           | Block IO weight (relative device weight)                                                                                                                                                                                                                                                                                               |\n| `--cap-add`               |           | Add Linux capabilities                                                                                                                                                                                                                                                                                                                 |\n| `--cap-drop`              |           | Drop Linux capabilities                                                                                                                                                                                                                                                                                                                |\n| `--cgroup-parent`         |           | Optional parent cgroup for the container                                                                                                                                                                                                                                                                                               |\n| `--cgroupns`              |           | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Cgroup namespace to use (host\\|private) 'host': Run the container in the Docker host's cgroup namespace 'private': Run the container in its own private cgroup namespace '': Use the cgroup namespace as configured by the default-cgroupns-mode option on the daemon (default) |\n| `--cidfile`               |           | Write the container ID to the file                                                                                                                                                                                                                                                                                                     |\n| `--cpu-count`             |           | CPU count (Windows only)                                                                                                                                                                                                                                                                                                               |\n| `--cpu-percent`           |           | CPU percent (Windows only)                                                                                                                                                                                                                                                                                                             |\n| `--cpu-period`            |           | Limit CPU CFS (Completely Fair Scheduler) period                                                                                                                                                                                                                                                                                       |\n| `--cpu-quota`             |           | Limit CPU CFS (Completely Fair Scheduler) quota                                                                                                                                                                                                                                                                                        |\n| `--cpu-rt-period`         |           | Limit CPU real-time period in microseconds                                                                                                                                                                                                                                                                                             |\n| `--cpu-rt-runtime`        |           | Limit CPU real-time runtime in microseconds                                                                                                                                                                                                                                                                                            |\n| `--cpu-shares` , `-c`     |           | CPU shares (relative weight)                                                                                                                                                                                                                                                                                                           |\n| `--cpus`                  |           | Number of CPUs                                                                                                                                                                                                                                                                                                                         |\n| `--cpuset-cpus`           |           | CPUs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--cpuset-mems`           |           | MEMs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--detach` , `-d`         |           | Run container in background and print container ID                                                                                                                                                                                                                                                                                     |\n| `--detach-keys`           |           | Override the key sequence for detaching a container                                                                                                                                                                                                                                                                                    |\n| `--device`                |           | Add a host device to the container                                                                                                                                                                                                                                                                                                     |\n| `--device-cgroup-rule`    |           | Add a rule to the cgroup allowed devices list                                                                                                                                                                                                                                                                                          |\n| `--device-read-bps`       |           | Limit read rate (bytes per second) from a device                                                                                                                                                                                                                                                                                       |\n| `--device-read-iops`      |           | Limit read rate (IO per second) from a device                                                                                                                                                                                                                                                                                          |\n| `--device-write-bps`      |           | Limit write rate (bytes per second) to a device                                                                                                                                                                                                                                                                                        |\n| `--device-write-iops`     |           | Limit write rate (IO per second) to a device                                                                                                                                                                                                                                                                                           |\n| `--disable-content-trust` | `true`    | Skip image verification                                                                                                                                                                                                                                                                                                                |\n| `--dns`                   |           | Set custom DNS servers                                                                                                                                                                                                                                                                                                                 |\n| `--dns-opt`               |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-option`            |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-search`            |           | Set custom DNS search domains                                                                                                                                                                                                                                                                                                          |\n| `--domainname`            |           | Container NIS domain name                                                                                                                                                                                                                                                                                                              |\n| `--entrypoint`            |           | Overwrite the default ENTRYPOINT of the image                                                                                                                                                                                                                                                                                          |\n| `--env` , `-e`            |           | Set environment variables                                                                                                                                                                                                                                                                                                              |\n| `--env-file`              |           | Read in a file of environment variables                                                                                                                                                                                                                                                                                                |\n| `--expose`                |           | Expose a port or a range of ports                                                                                                                                                                                                                                                                                                      |\n| `--gpus`                  |           | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) GPU devices to add to the container ('all' to pass all GPUs)                                                                                                                                                                                                                    |\n| `--group-add`             |           | Add additional groups to join                                                                                                                                                                                                                                                                                                          |\n| `--health-cmd`            |           | Command to run to check health                                                                                                                                                                                                                                                                                                         |\n| `--health-interval`       |           | Time between running the check (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                              |\n| `--health-retries`        |           | Consecutive failures needed to report unhealthy                                                                                                                                                                                                                                                                                        |\n| `--health-start-period`   |           | Start period for the container to initialize before starting health-retries countdown (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                       |\n| `--health-timeout`        |           | Maximum time to allow one check to run (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                      |\n| `--help`                  |           | Print usage                                                                                                                                                                                                                                                                                                                            |\n| `--hostname` , `-h`       |           | Container host name                                                                                                                                                                                                                                                                                                                    |\n| `--init`                  |           | Run an init inside the container that forwards signals and reaps processes                                                                                                                                                                                                                                                             |\n| `--interactive` , `-i`    |           | Keep STDIN open even if not attached                                                                                                                                                                                                                                                                                                   |\n| `--io-maxbandwidth`       |           | Maximum IO bandwidth limit for the system drive (Windows only)                                                                                                                                                                                                                                                                         |\n| `--io-maxiops`            |           | Maximum IOps limit for the system drive (Windows only)                                                                                                                                                                                                                                                                                 |\n| `--ip`                    |           | IPv4 address (e.g., 172.30.100.104)                                                                                                                                                                                                                                                                                                    |\n| `--ip6`                   |           | IPv6 address (e.g., 2001:db8::33)                                                                                                                                                                                                                                                                                                      |\n| `--ipc`                   |           | IPC mode to use                                                                                                                                                                                                                                                                                                                        |\n| `--isolation`             |           | Container isolation technology                                                                                                                                                                                                                                                                                                         |\n| `--kernel-memory`         |           | Kernel memory limit                                                                                                                                                                                                                                                                                                                    |\n| `--label` , `-l`          |           | Set meta data on a container                                                                                                                                                                                                                                                                                                           |\n| `--label-file`            |           | Read in a line delimited file of labels                                                                                                                                                                                                                                                                                                |\n| `--link`                  |           | Add link to another container                                                                                                                                                                                                                                                                                                          |\n| `--link-local-ip`         |           | Container IPv4/IPv6 link-local addresses                                                                                                                                                                                                                                                                                               |\n| `--log-driver`            |           | Logging driver for the container                                                                                                                                                                                                                                                                                                       |\n| `--log-opt`               |           | Log driver options                                                                                                                                                                                                                                                                                                                     |\n| `--mac-address`           |           | Container MAC address (e.g., 92:d0:c6:0a:29:33)                                                                                                                                                                                                                                                                                        |\n| `--memory` , `-m`         |           | Memory limit                                                                                                                                                                                                                                                                                                                           |\n| `--memory-reservation`    |           | Memory soft limit                                                                                                                                                                                                                                                                                                                      |\n| `--memory-swap`           |           | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                                                                                                                                                                                                                    |\n| `--memory-swappiness`     | `-1`      | Tune container memory swappiness (0 to 100)                                                                                                                                                                                                                                                                                            |\n| `--mount`                 |           | Attach a filesystem mount to the container                                                                                                                                                                                                                                                                                             |\n| `--name`                  |           | Assign a name to the container                                                                                                                                                                                                                                                                                                         |\n| `--net`                   |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--net-alias`             |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--network`               |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--network-alias`         |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--no-healthcheck`        |           | Disable any container-specified HEALTHCHECK                                                                                                                                                                                                                                                                                            |\n| `--oom-kill-disable`      |           | Disable OOM Killer                                                                                                                                                                                                                                                                                                                     |\n| `--oom-score-adj`         |           | Tune host's OOM preferences (-1000 to 1000)                                                                                                                                                                                                                                                                                            |\n| `--pid`                   |           | PID namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--pids-limit`            |           | Tune container pids limit (set -1 for unlimited)                                                                                                                                                                                                                                                                                       |\n| `--platform`              |           | Set platform if server is multi-platform capable                                                                                                                                                                                                                                                                                       |\n| `--privileged`            |           | Give extended privileges to this container                                                                                                                                                                                                                                                                                             |\n| `--publish` , `-p`        |           | Publish a container's port(s) to the host                                                                                                                                                                                                                                                                                              |\n| `--publish-all` , `-P`    |           | Publish all exposed ports to random ports                                                                                                                                                                                                                                                                                              |\n| `--pull`                  | `missing` | Pull image before running (\"always\"\\|\"missing\"\\|\"never\")                                                                                                                                                                                                                                                                               |\n| `--read-only`             |           | Mount the container's root filesystem as read only                                                                                                                                                                                                                                                                                     |\n| `--restart`               | `no`      | Restart policy to apply when a container exits                                                                                                                                                                                                                                                                                         |\n| `--rm`                    |           | Automatically remove the container when it exits                                                                                                                                                                                                                                                                                       |\n| `--runtime`               |           | Runtime to use for this container                                                                                                                                                                                                                                                                                                      |\n| `--security-opt`          |           | Security Options                                                                                                                                                                                                                                                                                                                       |\n| `--shm-size`              |           | Size of /dev/shm                                                                                                                                                                                                                                                                                                                       |\n| `--sig-proxy`             | `true`    | Proxy received signals to the process                                                                                                                                                                                                                                                                                                  |\n| `--stop-signal`           | `SIGTERM` | Signal to stop a container                                                                                                                                                                                                                                                                                                             |\n| `--stop-timeout`          |           | Timeout (in seconds) to stop a container                                                                                                                                                                                                                                                                                               |\n| `--storage-opt`           |           | Storage driver options for the container                                                                                                                                                                                                                                                                                               |\n| `--sysctl`                |           | Sysctl options                                                                                                                                                                                                                                                                                                                         |\n| `--tmpfs`                 |           | Mount a tmpfs directory                                                                                                                                                                                                                                                                                                                |\n| `--tty` , `-t`            |           | Allocate a pseudo-TTY                                                                                                                                                                                                                                                                                                                  |\n| `--ulimit`                |           | Ulimit options                                                                                                                                                                                                                                                                                                                         |\n| `--user` , `-u`           |           | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\])                                                                                                                                                                                                                                                                             |\n| `--userns`                |           | User namespace to use                                                                                                                                                                                                                                                                                                                  |\n| `--uts`                   |           | UTS namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--volume` , `-v`         |           | Bind mount a volume                                                                                                                                                                                                                                                                                                                    |\n| `--volume-driver`         |           | Optional volume driver for the container                                                                                                                                                                                                                                                                                               |\n| `--volumes-from`          |           | Mount volumes from the specified container(s)                                                                                                                                                                                                                                                                                          |\n| `--workdir` , `-w`        |           | Working directory inside the container                                                                                                                                                                                                                                                                                                 |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](index)                          | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_run/](https://docs.docker.com/engine/reference/commandline/container_run/)"
- name: docker container start
  id: engine/reference/commandline/container_start/index
  summary: © 2019 Docker, Inc
  description: "# docker container start\n\n  \n\nStart one or more stopped containers\n\n## Usage\n\n``` \n$ docker container start [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand        | Default | Description                                                                                                   |\n|------------------------|---------|---------------------------------------------------------------------------------------------------------------|\n| `--attach` , `-a`      |         | Attach STDOUT/STDERR and forward signals                                                                      |\n| `--checkpoint`         |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Restore from this checkpoint              |\n| `--checkpoint-dir`     |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Use a custom checkpoint storage directory |\n| `--detach-keys`        |         | Override the key sequence for detaching a container                                                           |\n| `--interactive` , `-i` |         | Attach container's STDIN                                                                                      |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](index)                        | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_start/](https://docs.docker.com/engine/reference/commandline/container_start/)"
- name: docker container stats
  id: engine/reference/commandline/container_stats/index
  summary: © 2019 Docker, Inc
  description: "# docker container stats\n\n  \n\nDisplay a live stream of container(s) resource usage statistics\n\n## Usage\n\n``` \n$ docker container stats [OPTIONS] [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand | Default | Description                                            |\n|-----------------|---------|--------------------------------------------------------|\n| `--all` , `-a`  |         | Show all containers (default shows just running)       |\n| `--format`      |         | Pretty-print images using a Go template                |\n| `--no-stream`   |         | Disable streaming stats and only pull the first result |\n| `--no-trunc`    |         | Do not truncate output                                 |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](index)                        | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_stats/](https://docs.docker.com/engine/reference/commandline/container_stats/)"
- name: docker container stop
  id: engine/reference/commandline/container_stop/index
  summary: © 2019 Docker, Inc
  description: "# docker container stop\n\n  \n\nStop one or more running containers\n\n## Usage\n\n``` \n$ docker container stop [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand | Default | Description                                |\n|-----------------|---------|--------------------------------------------|\n| `--time` , `-t` | `10`    | Seconds to wait for stop before killing it |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](index)                         | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_stop/](https://docs.docker.com/engine/reference/commandline/container_stop/)"
- name: docker container top
  id: engine/reference/commandline/container_top/index
  summary: © 2019 Docker, Inc
  description: "# docker container top\n\n  \n\nDisplay the running processes of a container\n\n## Usage\n\n``` \n$ docker container top CONTAINER [ps OPTIONS]\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](index)                          | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_top/](https://docs.docker.com/engine/reference/commandline/container_top/)"
- name: docker container unpause
  id: engine/reference/commandline/container_unpause/index
  summary: © 2019 Docker, Inc
  description: "# docker container unpause\n\n  \n\nUnpause all processes within one or more containers\n\n## Usage\n\n``` \n$ docker container unpause CONTAINER [CONTAINER...]\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](index)                      | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_unpause/](https://docs.docker.com/engine/reference/commandline/container_unpause/)"
- name: docker container update
  id: engine/reference/commandline/container_update/index
  summary: © 2019 Docker, Inc
  description: "# docker container update\n\n  \n\nUpdate configuration of one or more containers\n\n## Usage\n\n``` \n$ docker container update [OPTIONS] CONTAINER [CONTAINER...]\n```\n\n## Options\n\n| Name, shorthand        | Default | Description                                                                                             |\n|------------------------|---------|---------------------------------------------------------------------------------------------------------|\n| `--blkio-weight`       |         | Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)                            |\n| `--cpu-period`         |         | Limit CPU CFS (Completely Fair Scheduler) period                                                        |\n| `--cpu-quota`          |         | Limit CPU CFS (Completely Fair Scheduler) quota                                                         |\n| `--cpu-rt-period`      |         | Limit the CPU real-time period in microseconds                                                          |\n| `--cpu-rt-runtime`     |         | Limit the CPU real-time runtime in microseconds                                                         |\n| `--cpu-shares` , `-c`  |         | CPU shares (relative weight)                                                                            |\n| `--cpus`               |         | Number of CPUs                                                                                          |\n| `--cpuset-cpus`        |         | CPUs in which to allow execution (0-3, 0,1)                                                             |\n| `--cpuset-mems`        |         | MEMs in which to allow execution (0-3, 0,1)                                                             |\n| `--kernel-memory`      |         | Kernel memory limit                                                                                     |\n| `--memory` , `-m`      |         | Memory limit                                                                                            |\n| `--memory-reservation` |         | Memory soft limit                                                                                       |\n| `--memory-swap`        |         | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                     |\n| `--pids-limit`         |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Tune container pids limit (set -1 for unlimited) |\n| `--restart`            |         | Restart policy to apply when a container exits                                                          |\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](index)                       | Update configuration of one or more containers                                |\n| [docker container wait](../container_wait/index)       | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_update/](https://docs.docker.com/engine/reference/commandline/container_update/)"
- name: docker container wait
  id: engine/reference/commandline/container_wait/index
  summary: © 2019 Docker, Inc
  description: "# docker container wait\n\n  \n\nBlock until one or more containers stop, then print their exit codes\n\n## Usage\n\n``` \n$ docker container wait CONTAINER [CONTAINER...]\n```\n\n## Parent command\n\n| Command                                | Description       |\n|:---------------------------------------|:------------------|\n| [docker container](../container/index) | Manage containers |\n\n## Related commands\n\n| Command                                                | Description                                                                   |\n|--------------------------------------------------------|-------------------------------------------------------------------------------|\n| [docker container attach](../container_attach/index)   | Attach local standard input, output, and error streams to a running container |\n| [docker container commit](../container_commit/index)   | Create a new image from a container’s changes                                 |\n| [docker container cp](../container_cp/index)           | Copy files/folders between a container and the local filesystem               |\n| [docker container create](../container_create/index)   | Create a new container                                                        |\n| [docker container diff](../container_diff/index)       | Inspect changes to files or directories on a container’s filesystem           |\n| [docker container exec](../container_exec/index)       | Run a command in a running container                                          |\n| [docker container export](../container_export/index)   | Export a container’s filesystem as a tar archive                              |\n| [docker container inspect](../container_inspect/index) | Display detailed information on one or more containers                        |\n| [docker container kill](../container_kill/index)       | Kill one or more running containers                                           |\n| [docker container logs](../container_logs/index)       | Fetch the logs of a container                                                 |\n| [docker container ls](../container_ls/index)           | List containers                                                               |\n| [docker container pause](../container_pause/index)     | Pause all processes within one or more containers                             |\n| [docker container port](../container_port/index)       | List port mappings or a specific mapping for the container                    |\n| [docker container prune](../container_prune/index)     | Remove all stopped containers                                                 |\n| [docker container rename](../container_rename/index)   | Rename a container                                                            |\n| [docker container restart](../container_restart/index) | Restart one or more containers                                                |\n| [docker container rm](../container_rm/index)           | Remove one or more containers                                                 |\n| [docker container run](../container_run/index)         | Run a command in a new container                                              |\n| [docker container start](../container_start/index)     | Start one or more stopped containers                                          |\n| [docker container stats](../container_stats/index)     | Display a live stream of container(s) resource usage statistics               |\n| [docker container stop](../container_stop/index)       | Stop one or more running containers                                           |\n| [docker container top](../container_top/index)         | Display the running processes of a container                                  |\n| [docker container unpause](../container_unpause/index) | Unpause all processes within one or more containers                           |\n| [docker container update](../container_update/index)   | Update configuration of one or more containers                                |\n| [docker container wait](index)                         | Block until one or more containers stop, then print their exit codes          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/container_wait/](https://docs.docker.com/engine/reference/commandline/container_wait/)"
- name: docker context
  id: engine/reference/commandline/context/index
  summary: Manage contexts
  description: "# docker context\n\n  \n\nManage contexts\n\n## Usage\n\n``` \n$ docker context COMMAND\n```\n\n## Description\n\nManage contexts.\n\n## Child commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context/](https://docs.docker.com/engine/reference/commandline/context/)"
- name: Docker Context
  id: engine/context/working-with-contexts/index
  summary: This guide shows how contexts make it easy for a single Docker CLI to manage multiple Swarm clusters, multiple Kubernetes clusters, and multiple individual Docker nodes
  description: "# Docker Context\n\n## Introduction\n\nThis guide shows how *contexts* make it easy for a **single Docker CLI** to manage multiple Swarm clusters, multiple Kubernetes clusters, and multiple individual Docker nodes.\n\nA single Docker CLI can have multiple contexts. Each context contains all of the endpoint and security information required to manage a different cluster or node. The `docker context` command makes it easy to configure these contexts and switch between them.\n\nAs an example, a single Docker client on your company laptop might be configured with two contexts; **dev-k8s** and **prod-swarm**. **dev-k8s** contains the endpoint data and security credentials to configure and manage a Kubernetes cluster in a development environment. **prod-swarm** contains everything required to manage a Swarm cluster in a production environment. Once these contexts are configured, you can use the top-level `docker context use <context-name>` to easily switch between them.\n\nFor information on using Docker Context to deploy your apps to the cloud, see [Deploying Docker containers on Azure](https://docs.docker.com/cloud/aci-integration/) and [Deploying Docker containers on ECS](https://docs.docker.com/cloud/ecs-integration/).\n\n## Prerequisites\n\nTo follow the examples in this guide, you’ll need:\n\n- A Docker client that supports the top-level `context` command\n\nRun `docker context` to verify that your Docker client supports contexts.\n\nYou will also need one of the following:\n\n- Docker Swarm cluster\n- Single-engine Docker node\n- Kubernetes cluster\n\n## The anatomy of a context\n\nA context is a combination of several properties. These include:\n\n- Name\n- Endpoint configuration\n- TLS info\n- Orchestrator\n\nThe easiest way to see what a context looks like is to view the **default** context.\n\n``` \n$ docker context ls\nNAME          DESCRIPTION     DOCKER ENDPOINT                KUBERNETES ENDPOINT      ORCHESTRATOR\ndefault *     Current...      unix:///var/run/docker.sock                             swarm\n```\n\nThis shows a single context called “default”. It’s configured to talk to a Swarm cluster through the local `/var/run/docker.sock` Unix socket. It has no Kubernetes endpoint configured.\n\nThe asterisk in the `NAME` column indicates that this is the active context. This means all `docker` commands will be executed against the “default” context unless overridden with environment variables such as `DOCKER_HOST` and `DOCKER_CONTEXT`, or on the command-line with the `--context` and `--host` flags.\n\nDig a bit deeper with `docker context inspect`. In this example, we’re inspecting the context called `default`.\n\n``` \n$ docker context inspect default\n[\n    {\n        \"Name\": \"default\",\n        \"Metadata\": {\n            \"StackOrchestrator\": \"swarm\"\n        },\n        \"Endpoints\": {\n            \"docker\": {\n                \"Host\": \"unix:///var/run/docker.sock\",\n                \"SkipTLSVerify\": false\n            }\n        },\n        \"TLSMaterial\": {},\n        \"Storage\": {\n            \"MetadataPath\": \"\\u003cIN MEMORY\\u003e\",\n            \"TLSPath\": \"\\u003cIN MEMORY\\u003e\"\n        }\n    }\n]\n```\n\nThis context is using “swarm” as the orchestrator (`metadata.stackOrchestrator`). It is configured to talk to an endpoint exposed on a local Unix socket at `/var/run/docker.sock` (`Endpoints.docker.Host`), and requires TLS verification (`Endpoints.docker.SkipTLSVerify`).\n\n### Create a new context\n\nYou can create new contexts with the `docker context create` command.\n\nThe following example creates a new context called “docker-test” and specifies the following:\n\n- Default orchestrator = Swarm\n- Issue commands to the local Unix socket `/var/run/docker.sock`\n\n``` \n$ docker context create docker-test \\\n  --default-stack-orchestrator=swarm \\\n  --docker host=unix:///var/run/docker.sock\n\nSuccessfully created context \"docker-test\"\n```\n\nThe new context is stored in a `meta.json` file below `~/.docker/contexts/`. Each new context you create gets its own `meta.json` stored in a dedicated sub-directory of `~/.docker/contexts/`.\n\n> **Note:** The default context behaves differently than manually created contexts. It does not have a `meta.json` configuration file, and it dynamically updates based on the current configuration. For example, if you switch your current Kubernetes config using `kubectl config use-context`, the default Docker context will dynamically update itself to the new Kubernetes endpoint.\n\nYou can view the new context with `docker context ls` and `docker context inspect <context-name>`.\n\nThe following can be used to create a config with Kubernetes as the default orchestrator using the existing kubeconfig stored in `/home/ubuntu/.kube/config`. For this to work, you will need a valid kubeconfig file in `/home/ubuntu/.kube/config`. If your kubeconfig has more than one context, the current context (`kubectl config current-context`) will be used.\n\n``` \n$ docker context create k8s-test \\\n  --default-stack-orchestrator=kubernetes \\\n  --kubernetes config-file=/home/ubuntu/.kube/config \\\n  --docker host=unix:///var/run/docker.sock\n\nSuccessfully created context \"k8s-test\"\n```\n\nYou can view all contexts on the system with `docker context ls`.\n\n``` \n$ docker context ls\nNAME           DESCRIPTION   DOCKER ENDPOINT               KUBERNETES ENDPOINT               ORCHESTRATOR\ndefault *      Current       unix:///var/run/docker.sock   https://35.226.99.100 (default)   swarm\nk8s-test                     unix:///var/run/docker.sock   https://35.226.99.100 (default)   kubernetes\ndocker-test                  unix:///var/run/docker.sock                                     swarm\n```\n\nThe current context is indicated with an asterisk (“\\*”).\n\n## Use a different context\n\nYou can use `docker context use` to quickly switch between contexts.\n\nThe following command will switch the `docker` CLI to use the “k8s-test” context.\n\n``` \n$ docker context use k8s-test\n\nk8s-test\nCurrent context is now \"k8s-test\"\n```\n\nVerify the operation by listing all contexts and ensuring the asterisk (“\\*”) is against the “k8s-test” context.\n\n``` \n$ docker context ls\nNAME            DESCRIPTION                               DOCKER ENDPOINT               KUBERNETES ENDPOINT               ORCHESTRATOR\ndefault         Current DOCKER_HOST based configuration   unix:///var/run/docker.sock   https://35.226.99.100 (default)   swarm\ndocker-test                                               unix:///var/run/docker.sock                                     swarm\nk8s-test *                                                unix:///var/run/docker.sock   https://35.226.99.100 (default)   kubernetes\n```\n\n`docker` commands will now target endpoints defined in the “k8s-test” context.\n\nYou can also set the current context using the `DOCKER_CONTEXT` environment variable. This overrides the context set with `docker context use`.\n\nUse the appropriate command below to set the context to `docker-test` using an environment variable.\n\nWindows PowerShell:\n\n``` \n> $Env:DOCKER_CONTEXT=docker-test\n```\n\nLinux:\n\n``` \n$ export DOCKER_CONTEXT=docker-test\n```\n\nRun a `docker context ls` to verify that the “docker-test” context is now the active context.\n\nYou can also use the global `--context` flag to override the context specified by the `DOCKER_CONTEXT` environment variable. For example, the following will send the command to a context called “production”.\n\n``` \n$ docker --context production container ls\n```\n\n## Exporting and importing Docker contexts\n\nThe `docker context` command makes it easy to export and import contexts on different machines with the Docker client installed.\n\nYou can use the `docker context export` command to export an existing context to a file. This file can later be imported on another machine that has the `docker` client installed.\n\nBy default, contexts will be exported as a *native Docker contexts*. You can export and import these using the `docker context` command. If the context you are exporting includes a Kubernetes endpoint, the Kubernetes part of the context will be included in the `export` and `import` operations.\n\nThere is also an option to export just the Kubernetes part of a context. This will produce a native kubeconfig file that can be manually merged with an existing `~/.kube/config` file on another host that has `kubectl` installed. You cannot export just the Kubernetes portion of a context and then import it with `docker context import`. The only way to import the exported Kubernetes config is to manually merge it into an existing kubeconfig file.\n\nLet’s look at exporting and importing a native Docker context.\n\n### Exporting and importing a native Docker context\n\nThe following example exports an existing context called “docker-test”. It will be written to a file called `docker-test.dockercontext`.\n\n``` \n$ docker context export docker-test\nWritten file \"docker-test.dockercontext\"\n```\n\nCheck the contents of the export file.\n\n``` \n$ cat docker-test.dockercontext\nmeta.json0000644000000000000000000000022300000000000011023 0ustar0000000000000000{\"Name\":\"docker-test\",\"Metadata\":{\"StackOrchestrator\":\"swarm\"},\"Endpoints\":{\"docker\":{\"Host\":\"unix:///var/run/docker.sock\",\"SkipTLSVerify\":false}}}tls0000700000000000000000000000000000000000000007716 5ustar0000000000000000\n```\n\nThis file can be imported on another host using `docker context import`. The target host must have the Docker client installed.\n\n``` \n$ docker context import docker-test docker-test.dockercontext\ndocker-test\nSuccessfully imported context \"docker-test\"\n```\n\nYou can verify that the context was imported with `docker context ls`.\n\nThe format of the import command is `docker context import <context-name> <context-file>`.\n\nNow, let’s look at exporting just the Kubernetes parts of a context.\n\n### Exporting a Kubernetes context\n\nYou can export a Kubernetes context only if the context you are exporting has a Kubernetes endpoint configured. You cannot import a Kubernetes context using `docker context import`.\n\nThese steps will use the `--kubeconfig` flag to export **only** the Kubernetes elements of the existing `k8s-test` context to a file called “k8s-test.kubeconfig”. The `cat` command will then show that it’s exported as a valid kubeconfig file.\n\n``` \n$ docker context export k8s-test --kubeconfig\nWritten file \"k8s-test.kubeconfig\"\n```\n\nVerify that the exported file contains a valid kubectl config.\n\n``` \n$ cat k8s-test.kubeconfig\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data:\n    <Snip>\n    server: https://35.226.99.100\n  name: cluster\ncontexts:\n- context:\n    cluster: cluster\n    namespace: default\n    user: authInfo\n  name: context\ncurrent-context: context\nkind: Config\npreferences: {}\nusers:\n- name: authInfo\n  user:\n    auth-provider:\n      config:\n        cmd-args: config config-helper --format=json\n        cmd-path: /snap/google-cloud-sdk/77/bin/gcloud\n        expiry-key: '{.credential.token_expiry}'\n        token-key: '{.credential.access_token}'\n      name: gcp\n```\n\nYou can merge this with an existing `~/.kube/config` file on another machine.\n\n## Updating a context\n\nYou can use `docker context update` to update fields in an existing context.\n\nThe following example updates the “Description” field in the existing `k8s-test` context.\n\n``` \n$ docker context update k8s-test --description \"Test Kubernetes cluster\"\nk8s-test\nSuccessfully updated context \"k8s-test\"\n```\n\n[engine](https://docs.docker.com/search/?q=engine), [context](https://docs.docker.com/search/?q=context), [cli](https://docs.docker.com/search/?q=cli), [kubernetes](https://docs.docker.com/search/?q=kubernetes)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/context/working-with-contexts/](https://docs.docker.com/engine/context/working-with-contexts/)"
- name: docker context create
  id: engine/reference/commandline/context_create/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker context create\n\n  \n\nCreate a context\n\n## Usage\n\n``` \n$ docker context create [OPTIONS] CONTEXT\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a new `context`. This allows you to quickly switch the cli configuration to connect to different clusters or single nodes.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand                | Default | Description                                                                                                                         |\n|--------------------------------|---------|-------------------------------------------------------------------------------------------------------------------------------------|\n| `--default-stack-orchestrator` |         | [deprecated](../../../deprecated/index) Default orchestrator for stack operations to use with this context (swarm\\|kubernetes\\|all) |\n| `--description`                |         | Description of the context                                                                                                          |\n| `--docker`                     |         | set the docker endpoint                                                                                                             |\n| `--from`                       |         | create context from a named context                                                                                                 |\n| `--kubernetes`                 |         | [deprecated](../../../deprecated/index)Kubernetes set the kubernetes endpoint                                                       |\n\n## Examples\n\n### Create a context with a docker and kubernetes endpoint\n\nTo create a context from scratch provide the docker and, if required, kubernetes options. The example below creates the context `my-context` with a docker endpoint of `/var/run/docker.sock` and a kubernetes configuration sourced from the file `/home/me/my-kube-config`:\n\n``` \n$ docker context create \\\n    --docker host=unix:///var/run/docker.sock \\\n    --kubernetes config-file=/home/me/my-kube-config \\\n    my-context\n```\n\n### Create a context based on an existing context\n\nUse the `--from=<context-name>` option to create a new context from an existing context. The example below creates a new context named `my-context` from the existing context `existing-context`:\n\n``` \n$ docker context create --from existing-context my-context\n```\n\nIf the `--from` option is not set, the `context` is created from the current context:\n\n``` \n$ docker context create my-context\n```\n\nThis can be used to create a context out of an existing `DOCKER_HOST` based script:\n\n``` \n$ source my-setup-script.sh\n$ docker context create my-context\n```\n\nTo source only the `docker` endpoint configuration from an existing context use the `--docker from=<context-name>` option. The example below creates a new context named `my-context` using the docker endpoint configuration from the existing context `existing-context` and a kubernetes configuration sourced from the file `/home/me/my-kube-config`:\n\n``` \n$ docker context create \\\n    --docker from=existing-context \\\n    --kubernetes config-file=/home/me/my-kube-config \\\n    my-context\n```\n\nTo source only the `kubernetes` configuration from an existing context use the `--kubernetes from=<context-name>` option. The example below creates a new context named `my-context` using the kuberentes configuration from the existing context `existing-context` and a docker endpoint of `/var/run/docker.sock`:\n\n``` \n$ docker context create \\\n    --docker host=unix:///var/run/docker.sock \\\n    --kubernetes from=existing-context \\\n    my-context\n```\n\nDocker and Kubernetes endpoints configurations, as well as default stack orchestrator and description can be modified with `docker context update`.\n\nRefer to the [`docker context update` reference](../context_update/index) for details.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](index)                     | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_create/](https://docs.docker.com/engine/reference/commandline/context_create/)"
- name: docker context export
  id: engine/reference/commandline/context_export/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker context export\n\n  \n\nExport a context to a tar or kubeconfig file\n\n## Usage\n\n``` \n$ docker context export [OPTIONS] CONTEXT [FILE|-]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nExports a context in a file that can then be used with `docker context import` (or with `kubectl` if `--kubeconfig` is set). Default output filename is `<CONTEXT>.dockercontext`, or `<CONTEXT>.kubeconfig` if `--kubeconfig` is set. To export to `STDOUT`, you can run `docker context export my-context -`.\n\n## Options\n\n| Name, shorthand | Default | Description                                                                   |\n|-----------------|---------|-------------------------------------------------------------------------------|\n| `--kubeconfig`  |         | [deprecated](../../../deprecated/index)Kubernetes Export as a kubeconfig file |\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](index)                     | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_export/](https://docs.docker.com/engine/reference/commandline/context_export/)"
- name: docker context import
  id: engine/reference/commandline/context_import/index
  summary: Imports a context previously exported with docker context export
  description: "# docker context import\n\n  \n\nImport a context from a tar or zip file\n\n## Usage\n\n``` \n$ docker context import CONTEXT FILE|-\n```\n\n## Description\n\nImports a context previously exported with `docker context export`. To import from stdin, use a hyphen (`-`) as filename.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](index)                     | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_import/](https://docs.docker.com/engine/reference/commandline/context_import/)"
- name: docker context inspect
  id: engine/reference/commandline/context_inspect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker context inspect\n\n  \n\nDisplay detailed information on one or more contexts\n\n## Usage\n\n``` \n$ docker context inspect [OPTIONS] [CONTEXT] [CONTEXT...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nInspects one or more contexts.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n\n## Examples\n\n### Inspect a context by name\n\n``` \n$ docker context inspect \"local+aks\"\n\n[\n  {\n    \"Name\": \"local+aks\",\n    \"Metadata\": {\n      \"Description\": \"Local Docker Engine + Azure AKS endpoint\",\n      \"StackOrchestrator\": \"kubernetes\"\n    },\n    \"Endpoints\": {\n      \"docker\": {\n        \"Host\": \"npipe:////./pipe/docker_engine\",\n        \"SkipTLSVerify\": false\n      },\n      \"kubernetes\": {\n        \"Host\": \"https://simon-aks-***.hcp.uksouth.azmk8s.io:443\",\n        \"SkipTLSVerify\": false,\n        \"DefaultNamespace\": \"default\"\n      }\n    },\n    \"TLSMaterial\": {\n      \"kubernetes\": [\n        \"ca.pem\",\n        \"cert.pem\",\n        \"key.pem\"\n      ]\n    },\n    \"Storage\": {\n      \"MetadataPath\": \"C:\\\\Users\\\\simon\\\\.docker\\\\contexts\\\\meta\\\\cb6d08c0a1bfa5fe6f012e61a442788c00bed93f509141daff05f620fc54ddee\",\n      \"TLSPath\": \"C:\\\\Users\\\\simon\\\\.docker\\\\contexts\\\\tls\\\\cb6d08c0a1bfa5fe6f012e61a442788c00bed93f509141daff05f620fc54ddee\"\n    }\n  }\n]\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                          | Description                                          |\n|--------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index) | Create a context                                     |\n| [docker context export](../context_export/index) | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index) | Import a context from a tar or zip file              |\n| [docker context inspect](index)                  | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)         | List contexts                                        |\n| [docker context rm](../context_rm/index)         | Remove one or more contexts                          |\n| [docker context update](../context_update/index) | Update a context                                     |\n| [docker context use](../context_use/index)       | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_inspect/](https://docs.docker.com/engine/reference/commandline/context_inspect/)"
- name: docker context ls
  id: engine/reference/commandline/context_ls/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker context ls\n\n  \n\nList contexts\n\n## Usage\n\n``` \n$ docker context ls [OPTIONS]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                               |\n|------------------|---------|-------------------------------------------|\n| `--format`       |         | Pretty-print contexts using a Go template |\n| `--quiet` , `-q` |         | Only show context names                   |\n\n## Examples\n\nUse `docker context ls` to print all contexts. The currently active context is indicated with an `*`:\n\n``` \n$ docker context ls\n\nNAME                DESCRIPTION                               DOCKER ENDPOINT                      KUBERNETES ENDPOINT   ORCHESTRATOR\ndefault *           Current DOCKER_HOST based configuration   unix:///var/run/docker.sock                                swarm\nproduction                                                    tcp:///prod.corp.example.com:2376\nstaging                                                       tcp:///stage.corp.example.com:2376\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](index)                         | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_ls/](https://docs.docker.com/engine/reference/commandline/context_ls/)"
- name: docker context rm
  id: engine/reference/commandline/context_rm/index
  summary: © 2019 Docker, Inc
  description: "# docker context rm\n\n  \n\nRemove one or more contexts\n\n## Usage\n\n``` \n$ docker context rm CONTEXT [CONTEXT...]\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                           |\n|------------------|---------|---------------------------------------|\n| `--force` , `-f` |         | Force the removal of a context in use |\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](index)                         | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_rm/](https://docs.docker.com/engine/reference/commandline/context_rm/)"
- name: docker context update
  id: engine/reference/commandline/context_update/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker context update\n\n  \n\nUpdate a context\n\n## Usage\n\n``` \n$ docker context update [OPTIONS] CONTEXT\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUpdates an existing `context`. See [context create](../context_create/index).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand                | Default | Description                                                                                                                         |\n|--------------------------------|---------|-------------------------------------------------------------------------------------------------------------------------------------|\n| `--default-stack-orchestrator` |         | [deprecated](../../../deprecated/index) Default orchestrator for stack operations to use with this context (swarm\\|kubernetes\\|all) |\n| `--description`                |         | Description of the context                                                                                                          |\n| `--docker`                     |         | set the docker endpoint                                                                                                             |\n| `--kubernetes`                 |         | [deprecated](../../../deprecated/index)Kubernetes set the kubernetes endpoint                                                       |\n\n## Examples\n\n### Update an existing context\n\n``` \n$ docker context update \\\n    --description \"some description\" \\\n    --docker \"host=tcp://myserver:2376,ca=~/ca-file,cert=~/cert-file,key=~/key-file\" \\\n    my-context\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](index)                     | Update a context                                     |\n| [docker context use](../context_use/index)         | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_update/](https://docs.docker.com/engine/reference/commandline/context_update/)"
- name: docker context use
  id: engine/reference/commandline/context_use/index
  summary: Set the default context to use, when DOCKER_HOST, DOCKER_CONTEXT environment variables and --host, --context global options are not set
  description: "# docker context use\n\n  \n\nSet the current docker context\n\n## Usage\n\n``` \n$ docker context use CONTEXT\n```\n\n## Description\n\nSet the default context to use, when `DOCKER_HOST`, `DOCKER_CONTEXT` environment variables and `--host`, `--context` global options are not set. To disable usage of contexts, you can use the special `default` context.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker context](../context/index) | Manage contexts |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker context create](../context_create/index)   | Create a context                                     |\n| [docker context export](../context_export/index)   | Export a context to a tar or kubeconfig file         |\n| [docker context import](../context_import/index)   | Import a context from a tar or zip file              |\n| [docker context inspect](../context_inspect/index) | Display detailed information on one or more contexts |\n| [docker context ls](../context_ls/index)           | List contexts                                        |\n| [docker context rm](../context_rm/index)           | Remove one or more contexts                          |\n| [docker context update](../context_update/index)   | Update a context                                     |\n| [docker context use](index)                        | Set the current docker context                       |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/context_use/](https://docs.docker.com/engine/reference/commandline/context_use/)"
- name: docker cp
  id: engine/reference/commandline/cp/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker cp\n\n  \n\nCopy files/folders between a container and the local filesystem\n\n## Usage\n\n``` \n$ docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-\ndocker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker cp` utility copies the contents of `SRC_PATH` to the `DEST_PATH`. You can copy from the container’s file system to the local machine or the reverse, from the local filesystem to the container. If `-` is specified for either the `SRC_PATH` or `DEST_PATH`, you can also stream a tar archive from `STDIN` or to `STDOUT`. The `CONTAINER` can be a running or stopped container. The `SRC_PATH` or `DEST_PATH` can be a file or directory.\n\nThe `docker cp` command assumes container paths are relative to the container’s `/` (root) directory. This means supplying the initial forward slash is optional; The command sees `compassionate_darwin:/tmp/foo/myfile.txt` and `compassionate_darwin:tmp/foo/myfile.txt` as identical. Local machine paths can be an absolute or relative value. The command interprets a local machine’s relative paths as relative to the current working directory where `docker cp` is run.\n\nThe `cp` command behaves like the Unix `cp -a` command in that directories are copied recursively with permissions preserved if possible. Ownership is set to the user and primary group at the destination. For example, files copied to a container are created with `UID:GID` of the root user. Files copied to the local machine are created with the `UID:GID` of the user which invoked the `docker cp` command. However, if you specify the `-a` option, `docker cp` sets the ownership to the user and primary group at the source. If you specify the `-L` option, `docker cp` follows any symbolic link in the `SRC_PATH`. `docker cp` does *not* create parent directories for `DEST_PATH` if they do not exist.\n\nAssuming a path separator of `/`, a first argument of `SRC_PATH` and second argument of `DEST_PATH`, the behavior is as follows:\n\n- `SRC_PATH` specifies a file\n  - `DEST_PATH` does not exist\n    - the file is saved to a file created at `DEST_PATH`\n  - `DEST_PATH` does not exist and ends with `/`\n    - Error condition: the destination directory must exist.\n  - `DEST_PATH` exists and is a file\n    - the destination is overwritten with the source file’s contents\n  - `DEST_PATH` exists and is a directory\n    - the file is copied into this directory using the basename from `SRC_PATH`\n- `SRC_PATH` specifies a directory\n  - `DEST_PATH` does not exist\n    - `DEST_PATH` is created as a directory and the *contents* of the source directory are copied into this directory\n  - `DEST_PATH` exists and is a file\n    - Error condition: cannot copy a directory to a file\n  - `DEST_PATH` exists and is a directory\n    - `SRC_PATH` does not end with `/.` (that is: *slash* followed by *dot*)\n      - the source directory is copied into this directory\n    - `SRC_PATH` does end with `/.` (that is: *slash* followed by *dot*)\n      - the *content* of the source directory is copied into this directory\n\nThe command requires `SRC_PATH` and `DEST_PATH` to exist according to the above rules. If `SRC_PATH` is local and is a symbolic link, the symbolic link, not the target, is copied by default. To copy the link target and not the link, specify the `-L` option.\n\nA colon (`:`) is used as a delimiter between `CONTAINER` and its path. You can also use `:` when specifying paths to a `SRC_PATH` or `DEST_PATH` on a local machine, for example `file:name.txt`. If you use a `:` in a local machine path, you must be explicit with a relative or absolute path, for example:\n\n``` \n`/path/to/file:name.txt` or `./file:name.txt`\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand        | Default | Description                                 |\n|------------------------|---------|---------------------------------------------|\n| `--archive` , `-a`     |         | Archive mode (copy all uid/gid information) |\n| `--follow-link` , `-L` |         | Always follow symbol link in SRC_PATH       |\n\n## Examples\n\nCopy a local file into container\n\n``` \n$ docker cp ./some_file CONTAINER:/work\n```\n\nCopy files from container to local path\n\n``` \n$ docker cp CONTAINER:/var/logs/ /tmp/app_logs\n```\n\nCopy a file from container to stdout. Please note `cp` command produces a tar stream\n\n``` \n$ docker cp CONTAINER:/var/logs/app.log - | tar x -O | grep \"ERROR\"\n```\n\n### Corner cases\n\nIt is not possible to copy certain system files such as resources under `/proc`, `/sys`, `/dev`, [tmpfs](../run/index#mount-tmpfs---tmpfs), and mounts created by the user in the container. However, you can still copy such files by manually running `tar` in `docker exec`. Both of the following examples do the same thing in different ways (consider `SRC_PATH` and `DEST_PATH` are directories):\n\n``` \n$ docker exec CONTAINER tar Ccf $(dirname SRC_PATH) - $(basename SRC_PATH) | tar Cxf DEST_PATH -\n```\n\n``` \n$ tar Ccf $(dirname SRC_PATH) - $(basename SRC_PATH) | docker exec -i CONTAINER tar Cxf DEST_PATH -\n```\n\nUsing `-` as the `SRC_PATH` streams the contents of `STDIN` as a tar archive. The command extracts the content of the tar to the `DEST_PATH` in container’s filesystem. In this case, `DEST_PATH` must specify a directory. Using `-` as the `DEST_PATH` streams the contents of the resource as a tar archive to `STDOUT`.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/cp/](https://docs.docker.com/engine/reference/commandline/cp/)"
- name: docker create
  id: engine/reference/commandline/create/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker create\n\n  \n\nCreate a new container\n\n## Usage\n\n``` \n$ docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker container create` (or shorthand: `docker create`) command creates a new container from the specified image, without starting it.\n\nWhen creating a container, the docker daemon creates a writeable container layer over the specified image and prepares it for running the specified command. The container ID is then printed to `STDOUT`. This is similar to `docker run -d` except the container is never started. You can then use the `docker container start` (or shorthand: `docker start`) command to start the container at any point.\n\nThis is useful when you want to set up a container configuration ahead of time so that it is ready to start when you need it. The initial status of the new container is `created`.\n\nThe `docker create` command shares most of its options with the `docker run` command (which performs a `docker create` before starting it). Refer to the [`docker run` command](../run/index) section and the [Docker run reference](../../run/index) for details on the available flags and options.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default   | Description                                                                                                                                                                                                                                                                                                                            |\n|---------------------------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |           | Add a custom host-to-IP mapping (host:ip)                                                                                                                                                                                                                                                                                              |\n| `--attach` , `-a`         |           | Attach to STDIN, STDOUT or STDERR                                                                                                                                                                                                                                                                                                      |\n| `--blkio-weight`          |           | Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)                                                                                                                                                                                                                                                           |\n| `--blkio-weight-device`   |           | Block IO weight (relative device weight)                                                                                                                                                                                                                                                                                               |\n| `--cap-add`               |           | Add Linux capabilities                                                                                                                                                                                                                                                                                                                 |\n| `--cap-drop`              |           | Drop Linux capabilities                                                                                                                                                                                                                                                                                                                |\n| `--cgroup-parent`         |           | Optional parent cgroup for the container                                                                                                                                                                                                                                                                                               |\n| `--cgroupns`              |           | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Cgroup namespace to use (host\\|private) 'host': Run the container in the Docker host's cgroup namespace 'private': Run the container in its own private cgroup namespace '': Use the cgroup namespace as configured by the default-cgroupns-mode option on the daemon (default) |\n| `--cidfile`               |           | Write the container ID to the file                                                                                                                                                                                                                                                                                                     |\n| `--cpu-count`             |           | CPU count (Windows only)                                                                                                                                                                                                                                                                                                               |\n| `--cpu-percent`           |           | CPU percent (Windows only)                                                                                                                                                                                                                                                                                                             |\n| `--cpu-period`            |           | Limit CPU CFS (Completely Fair Scheduler) period                                                                                                                                                                                                                                                                                       |\n| `--cpu-quota`             |           | Limit CPU CFS (Completely Fair Scheduler) quota                                                                                                                                                                                                                                                                                        |\n| `--cpu-rt-period`         |           | Limit CPU real-time period in microseconds                                                                                                                                                                                                                                                                                             |\n| `--cpu-rt-runtime`        |           | Limit CPU real-time runtime in microseconds                                                                                                                                                                                                                                                                                            |\n| `--cpu-shares` , `-c`     |           | CPU shares (relative weight)                                                                                                                                                                                                                                                                                                           |\n| `--cpus`                  |           | Number of CPUs                                                                                                                                                                                                                                                                                                                         |\n| `--cpuset-cpus`           |           | CPUs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--cpuset-mems`           |           | MEMs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--device`                |           | Add a host device to the container                                                                                                                                                                                                                                                                                                     |\n| `--device-cgroup-rule`    |           | Add a rule to the cgroup allowed devices list                                                                                                                                                                                                                                                                                          |\n| `--device-read-bps`       |           | Limit read rate (bytes per second) from a device                                                                                                                                                                                                                                                                                       |\n| `--device-read-iops`      |           | Limit read rate (IO per second) from a device                                                                                                                                                                                                                                                                                          |\n| `--device-write-bps`      |           | Limit write rate (bytes per second) to a device                                                                                                                                                                                                                                                                                        |\n| `--device-write-iops`     |           | Limit write rate (IO per second) to a device                                                                                                                                                                                                                                                                                           |\n| `--disable-content-trust` | `true`    | Skip image verification                                                                                                                                                                                                                                                                                                                |\n| `--dns`                   |           | Set custom DNS servers                                                                                                                                                                                                                                                                                                                 |\n| `--dns-opt`               |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-option`            |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-search`            |           | Set custom DNS search domains                                                                                                                                                                                                                                                                                                          |\n| `--domainname`            |           | Container NIS domain name                                                                                                                                                                                                                                                                                                              |\n| `--entrypoint`            |           | Overwrite the default ENTRYPOINT of the image                                                                                                                                                                                                                                                                                          |\n| `--env` , `-e`            |           | Set environment variables                                                                                                                                                                                                                                                                                                              |\n| `--env-file`              |           | Read in a file of environment variables                                                                                                                                                                                                                                                                                                |\n| `--expose`                |           | Expose a port or a range of ports                                                                                                                                                                                                                                                                                                      |\n| `--gpus`                  |           | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) GPU devices to add to the container ('all' to pass all GPUs)                                                                                                                                                                                                                    |\n| `--group-add`             |           | Add additional groups to join                                                                                                                                                                                                                                                                                                          |\n| `--health-cmd`            |           | Command to run to check health                                                                                                                                                                                                                                                                                                         |\n| `--health-interval`       |           | Time between running the check (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                              |\n| `--health-retries`        |           | Consecutive failures needed to report unhealthy                                                                                                                                                                                                                                                                                        |\n| `--health-start-period`   |           | Start period for the container to initialize before starting health-retries countdown (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                       |\n| `--health-timeout`        |           | Maximum time to allow one check to run (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                      |\n| `--help`                  |           | Print usage                                                                                                                                                                                                                                                                                                                            |\n| `--hostname` , `-h`       |           | Container host name                                                                                                                                                                                                                                                                                                                    |\n| `--init`                  |           | Run an init inside the container that forwards signals and reaps processes                                                                                                                                                                                                                                                             |\n| `--interactive` , `-i`    |           | Keep STDIN open even if not attached                                                                                                                                                                                                                                                                                                   |\n| `--io-maxbandwidth`       |           | Maximum IO bandwidth limit for the system drive (Windows only)                                                                                                                                                                                                                                                                         |\n| `--io-maxiops`            |           | Maximum IOps limit for the system drive (Windows only)                                                                                                                                                                                                                                                                                 |\n| `--ip`                    |           | IPv4 address (e.g., 172.30.100.104)                                                                                                                                                                                                                                                                                                    |\n| `--ip6`                   |           | IPv6 address (e.g., 2001:db8::33)                                                                                                                                                                                                                                                                                                      |\n| `--ipc`                   |           | IPC mode to use                                                                                                                                                                                                                                                                                                                        |\n| `--isolation`             |           | Container isolation technology                                                                                                                                                                                                                                                                                                         |\n| `--kernel-memory`         |           | Kernel memory limit                                                                                                                                                                                                                                                                                                                    |\n| `--label` , `-l`          |           | Set meta data on a container                                                                                                                                                                                                                                                                                                           |\n| `--label-file`            |           | Read in a line delimited file of labels                                                                                                                                                                                                                                                                                                |\n| `--link`                  |           | Add link to another container                                                                                                                                                                                                                                                                                                          |\n| `--link-local-ip`         |           | Container IPv4/IPv6 link-local addresses                                                                                                                                                                                                                                                                                               |\n| `--log-driver`            |           | Logging driver for the container                                                                                                                                                                                                                                                                                                       |\n| `--log-opt`               |           | Log driver options                                                                                                                                                                                                                                                                                                                     |\n| `--mac-address`           |           | Container MAC address (e.g., 92:d0:c6:0a:29:33)                                                                                                                                                                                                                                                                                        |\n| `--memory` , `-m`         |           | Memory limit                                                                                                                                                                                                                                                                                                                           |\n| `--memory-reservation`    |           | Memory soft limit                                                                                                                                                                                                                                                                                                                      |\n| `--memory-swap`           |           | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                                                                                                                                                                                                                    |\n| `--memory-swappiness`     | `-1`      | Tune container memory swappiness (0 to 100)                                                                                                                                                                                                                                                                                            |\n| `--mount`                 |           | Attach a filesystem mount to the container                                                                                                                                                                                                                                                                                             |\n| `--name`                  |           | Assign a name to the container                                                                                                                                                                                                                                                                                                         |\n| `--net`                   |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--net-alias`             |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--network`               |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--network-alias`         |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--no-healthcheck`        |           | Disable any container-specified HEALTHCHECK                                                                                                                                                                                                                                                                                            |\n| `--oom-kill-disable`      |           | Disable OOM Killer                                                                                                                                                                                                                                                                                                                     |\n| `--oom-score-adj`         |           | Tune host's OOM preferences (-1000 to 1000)                                                                                                                                                                                                                                                                                            |\n| `--pid`                   |           | PID namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--pids-limit`            |           | Tune container pids limit (set -1 for unlimited)                                                                                                                                                                                                                                                                                       |\n| `--platform`              |           | Set platform if server is multi-platform capable                                                                                                                                                                                                                                                                                       |\n| `--privileged`            |           | Give extended privileges to this container                                                                                                                                                                                                                                                                                             |\n| `--publish` , `-p`        |           | Publish a container's port(s) to the host                                                                                                                                                                                                                                                                                              |\n| `--publish-all` , `-P`    |           | Publish all exposed ports to random ports                                                                                                                                                                                                                                                                                              |\n| `--pull`                  | `missing` | Pull image before creating (\"always\"\\|\"missing\"\\|\"never\")                                                                                                                                                                                                                                                                              |\n| `--read-only`             |           | Mount the container's root filesystem as read only                                                                                                                                                                                                                                                                                     |\n| `--restart`               | `no`      | Restart policy to apply when a container exits                                                                                                                                                                                                                                                                                         |\n| `--rm`                    |           | Automatically remove the container when it exits                                                                                                                                                                                                                                                                                       |\n| `--runtime`               |           | Runtime to use for this container                                                                                                                                                                                                                                                                                                      |\n| `--security-opt`          |           | Security Options                                                                                                                                                                                                                                                                                                                       |\n| `--shm-size`              |           | Size of /dev/shm                                                                                                                                                                                                                                                                                                                       |\n| `--stop-signal`           | `SIGTERM` | Signal to stop a container                                                                                                                                                                                                                                                                                                             |\n| `--stop-timeout`          |           | Timeout (in seconds) to stop a container                                                                                                                                                                                                                                                                                               |\n| `--storage-opt`           |           | Storage driver options for the container                                                                                                                                                                                                                                                                                               |\n| `--sysctl`                |           | Sysctl options                                                                                                                                                                                                                                                                                                                         |\n| `--tmpfs`                 |           | Mount a tmpfs directory                                                                                                                                                                                                                                                                                                                |\n| `--tty` , `-t`            |           | Allocate a pseudo-TTY                                                                                                                                                                                                                                                                                                                  |\n| `--ulimit`                |           | Ulimit options                                                                                                                                                                                                                                                                                                                         |\n| `--user` , `-u`           |           | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\])                                                                                                                                                                                                                                                                             |\n| `--userns`                |           | User namespace to use                                                                                                                                                                                                                                                                                                                  |\n| `--uts`                   |           | UTS namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--volume` , `-v`         |           | Bind mount a volume                                                                                                                                                                                                                                                                                                                    |\n| `--volume-driver`         |           | Optional volume driver for the container                                                                                                                                                                                                                                                                                               |\n| `--volumes-from`          |           | Mount volumes from the specified container(s)                                                                                                                                                                                                                                                                                          |\n| `--workdir` , `-w`        |           | Working directory inside the container                                                                                                                                                                                                                                                                                                 |\n\n## Examples\n\n### Create and start a container\n\nThe following example creates an interactive container with a pseudo-TTY attached, then starts the container and attaches to it:\n\n``` \n$ docker container create -i -t --name mycontainer alpine\n6d8af538ec541dd581ebc2a24153a28329acb5268abe5ef868c1f1a261221752\n\n$ docker container start --attach -i mycontainer\n/ # echo hello world\nhello world\n```\n\nThe above is the equivalent of a `docker run`:\n\n``` \n$ docker run -it --name mycontainer2 alpine\n/ # echo hello world\nhello world\n```\n\n### Initialize volumes\n\nContainer volumes are initialized during the `docker create` phase (i.e., `docker run` too). For example, this allows you to `create` the `data` volume container, and then use it from another container:\n\n``` \n$ docker create -v /data --name data ubuntu\n\n240633dfbb98128fa77473d3d9018f6123b99c454b3251427ae190a7d951ad57\n\n$ docker run --rm --volumes-from data ubuntu ls -la /data\n\ntotal 8\ndrwxr-xr-x  2 root root 4096 Dec  5 04:10 .\ndrwxr-xr-x 48 root root 4096 Dec  5 04:11 ..\n```\n\nSimilarly, `create` a host directory bind mounted volume container, which can then be used from the subsequent container:\n\n``` \n$ docker create -v /home/docker:/docker --name docker ubuntu\n\n9aa88c08f319cd1e4515c3c46b0de7cc9aa75e878357b1e96f91e2c773029f03\n\n$ docker run --rm --volumes-from docker ubuntu ls -la /docker\n\ntotal 20\ndrwxr-sr-x  5 1000 staff  180 Dec  5 04:00 .\ndrwxr-xr-x 48 root root  4096 Dec  5 04:13 ..\n-rw-rw-r--  1 1000 staff 3833 Dec  5 04:01 .ash_history\n-rw-r--r--  1 1000 staff  446 Nov 28 11:51 .ashrc\n-rw-r--r--  1 1000 staff   25 Dec  5 04:00 .gitconfig\ndrwxr-sr-x  3 1000 staff   60 Dec  1 03:28 .local\n-rw-r--r--  1 1000 staff  920 Nov 28 11:51 .profile\ndrwx--S---  2 1000 staff  460 Dec  5 00:51 .ssh\ndrwxr-xr-x 32 1000 staff 1140 Dec  5 04:01 docker\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/create/](https://docs.docker.com/engine/reference/commandline/create/)"
- name: docker diff
  id: engine/reference/commandline/diff/index
  summary: List the changed files and directories in a container᾿s filesystem since the container was created
  description: "# docker diff\n\n  \n\nInspect changes to files or directories on a container’s filesystem\n\n## Usage\n\n``` \n$ docker diff CONTAINER\n```\n\n## Description\n\nList the changed files and directories in a container᾿s filesystem since the container was created. Three different types of change are tracked:\n\n| Symbol | Description                     |\n|--------|---------------------------------|\n| `A`    | A file or directory was added   |\n| `D`    | A file or directory was deleted |\n| `C`    | A file or directory was changed |\n\nYou can use the full or shortened container ID or the container name set using `docker run --name` option.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\nInspect the changes to an `nginx` container:\n\n``` \n$ docker diff 1fdfd1f54c1b\n\nC /dev\nC /dev/console\nC /dev/core\nC /dev/stdout\nC /dev/fd\nC /dev/ptmx\nC /dev/stderr\nC /dev/stdin\nC /run\nA /run/nginx.pid\nC /var/lib/nginx/tmp\nA /var/lib/nginx/tmp/client_body\nA /var/lib/nginx/tmp/fastcgi\nA /var/lib/nginx/tmp/proxy\nA /var/lib/nginx/tmp/scgi\nA /var/lib/nginx/tmp/uwsgi\nC /var/log/nginx\nA /var/log/nginx/access.log\nA /var/log/nginx/error.log\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/diff/](https://docs.docker.com/engine/reference/commandline/diff/)"
- name: Docker Engine managed plugin system
  id: engine/extend/index
  summary: Docker Engine’s plugin system allows you to install, start, stop, and remove plugins using Docker Engine
  description: "# Docker Engine managed plugin system\n\n- [Installing and using a plugin](index#installing-and-using-a-plugin)\n- [Developing a plugin](index#developing-a-plugin)\n- [Debugging plugins](index#debugging-plugins)\n\nDocker Engine’s plugin system allows you to install, start, stop, and remove plugins using Docker Engine.\n\nFor information about legacy (non-managed) plugins, refer to [Understand legacy Docker Engine plugins](legacy_plugins/index).\n\n> **Note**\n>\n> Docker Engine managed plugins are currently not supported on Windows daemons.\n\n## Installing and using a plugin\n\nPlugins are distributed as Docker images and can be hosted on Docker Hub or on a private registry.\n\nTo install a plugin, use the `docker plugin install` command, which pulls the plugin from Docker Hub or your private registry, prompts you to grant permissions or capabilities if necessary, and enables the plugin.\n\nTo check the status of installed plugins, use the `docker plugin ls` command. Plugins that start successfully are listed as enabled in the output.\n\nAfter a plugin is installed, you can use it as an option for another Docker operation, such as creating a volume.\n\nIn the following example, you install the `sshfs` plugin, verify that it is enabled, and use it to create a volume.\n\n> **Note**\n>\n> This example is intended for instructional purposes only. Once the volume is created, your SSH password to the remote host will be exposed as plaintext when inspecting the volume. You should delete the volume as soon as you are done with the example.\n\n1.  Install the `sshfs` plugin.\n\n    ``` \n    $ docker plugin install vieux/sshfs\n\n    Plugin \"vieux/sshfs\" is requesting the following privileges:\n    - network: [host]\n    - capabilities: [CAP_SYS_ADMIN]\n    Do you grant the above permissions? [y/N] y\n\n    vieux/sshfs\n    ```\n\n    The plugin requests 2 privileges:\n\n    - It needs access to the `host` network.\n    - It needs the `CAP_SYS_ADMIN` capability, which allows the plugin to run the `mount` command.\n\n2.  Check that the plugin is enabled in the output of `docker plugin ls`.\n\n    ``` \n    $ docker plugin ls\n\n    ID                    NAME                  TAG                 DESCRIPTION                   ENABLED\n    69553ca1d789          vieux/sshfs           latest              the `sshfs` plugin            true\n    ```\n\n3.  Create a volume using the plugin. This example mounts the `/remote` directory on host `1.2.3.4` into a volume named `sshvolume`.\n\n    This volume can now be mounted into containers.\n\n    ``` \n    $ docker volume create \\\n      -d vieux/sshfs \\\n      --name sshvolume \\\n      -o sshcmd=user@1.2.3.4:/remote \\\n      -o password=$(cat file_containing_password_for_remote_host)\n\n    sshvolume\n    ```\n\n4.  Verify that the volume was created successfully.\n\n    ``` \n    $ docker volume ls\n\n    DRIVER              NAME\n    vieux/sshfs         sshvolume\n    ```\n\n5.  Start a container that uses the volume `sshvolume`.\n\n    ``` \n    $ docker run --rm -v sshvolume:/data busybox ls /data\n\n    <content of /remote on machine 1.2.3.4>\n    ```\n\n6.  Remove the volume `sshvolume`\n\n    ``` \n    $ docker volume rm sshvolume\n\n    sshvolume\n    ```\n\nTo disable a plugin, use the `docker plugin disable` command. To completely remove it, use the `docker plugin remove` command. For other available commands and options, see the [command line reference](../reference/commandline/cli/index).\n\n## Developing a plugin\n\n#### The rootfs directory\n\nThe `rootfs` directory represents the root filesystem of the plugin. In this example, it was created from a Dockerfile:\n\n> **Note:** The `/run/docker/plugins` directory is mandatory inside of the plugin’s filesystem for docker to communicate with the plugin.\n\n``` \n$ git clone https://github.com/vieux/docker-volume-sshfs\n$ cd docker-volume-sshfs\n$ docker build -t rootfsimage .\n$ id=$(docker create rootfsimage true) # id was cd851ce43a403 when the image was created\n$ sudo mkdir -p myplugin/rootfs\n$ sudo docker export \"$id\" | sudo tar -x -C myplugin/rootfs\n$ docker rm -vf \"$id\"\n$ docker rmi rootfsimage\n```\n\n#### The config.json file\n\nThe `config.json` file describes the plugin. See the [plugins config reference](config/index).\n\nConsider the following `config.json` file.\n\n``` \n{\n    \"description\": \"sshFS plugin for Docker\",\n    \"documentation\": \"https://docs.docker.com/engine/extend/plugins/\",\n    \"entrypoint\": [\"/docker-volume-sshfs\"],\n    \"network\": {\n           \"type\": \"host\"\n           },\n    \"interface\" : {\n           \"types\": [\"docker.volumedriver/1.0\"],\n           \"socket\": \"sshfs.sock\"\n    },\n    \"linux\": {\n        \"capabilities\": [\"CAP_SYS_ADMIN\"]\n    }\n}\n```\n\nThis plugin is a volume driver. It requires a `host` network and the `CAP_SYS_ADMIN` capability. It depends upon the `/docker-volume-sshfs` entrypoint and uses the `/run/docker/plugins/sshfs.sock` socket to communicate with Docker Engine. This plugin has no runtime parameters.\n\n#### Creating the plugin\n\nA new plugin can be created by running `docker plugin create <plugin-name> ./path/to/plugin/data` where the plugin data contains a plugin configuration file `config.json` and a root filesystem in subdirectory `rootfs`.\n\nAfter that the plugin `<plugin-name>` will show up in `docker plugin ls`. Plugins can be pushed to remote registries with `docker plugin push <plugin-name>`.\n\n## Debugging plugins\n\nStdout of a plugin is redirected to dockerd logs. Such entries have a `plugin=<ID>` suffix. Here are a few examples of commands for pluginID `f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62` and their corresponding log entries in the docker daemon logs.\n\n``` \n$ docker plugin install tiborvass/sample-volume-plugin\n\nINFO[0036] Starting...       Found 0 volumes on startup  plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\n```\n\n``` \n$ docker volume create -d tiborvass/sample-volume-plugin samplevol\n\nINFO[0193] Create Called...  Ensuring directory /data/samplevol exists on host...  plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\nINFO[0193] open /var/lib/docker/plugin-data/local-persist.json: no such file or directory  plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\nINFO[0193]                   Created volume samplevol with mountpoint /data/samplevol  plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\nINFO[0193] Path Called...    Returned path /data/samplevol  plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\n```\n\n``` \n$ docker run -v samplevol:/tmp busybox sh\n\nINFO[0421] Get Called...     Found samplevol                plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\nINFO[0421] Mount Called...   Mounted samplevol              plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\nINFO[0421] Path Called...    Returned path /data/samplevol  plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\nINFO[0421] Unmount Called... Unmounted samplevol            plugin=f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62\n```\n\n#### Using docker-runc to obtain logfiles and shell into the plugin.\n\n`docker-runc`, the default docker container runtime can be used for debugging plugins. This is specifically useful to collect plugin logs if they are redirected to a file.\n\n``` \n$ sudo docker-runc --root /var/run/docker/plugins/runtime-root/moby-plugins list\n\nID                                                                 PID         STATUS      BUNDLE                                                                                                                                       CREATED                          OWNER\n93f1e7dbfe11c938782c2993628c895cf28e2274072c4a346a6002446c949b25   15806       running     /run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby-plugins/93f1e7dbfe11c938782c2993628c895cf28e2274072c4a346a6002446c949b25   2018-02-08T21:40:08.621358213Z   root\n9b4606d84e06b56df84fadf054a21374b247941c94ce405b0a261499d689d9c9   14992       running     /run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby-plugins/9b4606d84e06b56df84fadf054a21374b247941c94ce405b0a261499d689d9c9   2018-02-08T21:35:12.321325872Z   root\nc5bb4b90941efcaccca999439ed06d6a6affdde7081bb34dc84126b57b3e793d   14984       running     /run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby-plugins/c5bb4b90941efcaccca999439ed06d6a6affdde7081bb34dc84126b57b3e793d   2018-02-08T21:35:12.321288966Z   root\n```\n\n``` \n$ sudo docker-runc --root /var/run/docker/plugins/runtime-root/moby-plugins exec 93f1e7dbfe11c938782c2993628c895cf28e2274072c4a346a6002446c949b25 cat /var/log/plugin.log\n```\n\nIf the plugin has a built-in shell, then exec into the plugin can be done as follows:\n\n``` \n$ sudo docker-runc --root /var/run/docker/plugins/runtime-root/moby-plugins exec -t 93f1e7dbfe11c938782c2993628c895cf28e2274072c4a346a6002446c949b25 sh\n```\n\n#### Using curl to debug plugin socket issues.\n\nTo verify if the plugin API socket that the docker daemon communicates with is responsive, use curl. In this example, we will make API calls from the docker host to volume and network plugins using curl 7.47.0 to ensure that the plugin is listening on the said socket. For a well functioning plugin, these basic requests should work. Note that plugin sockets are available on the host under `/var/run/docker/plugins/<pluginID>`\n\n``` \n$ curl -H \"Content-Type: application/json\" -XPOST -d '{}' --unix-socket /var/run/docker/plugins/e8a37ba56fc879c991f7d7921901723c64df6b42b87e6a0b055771ecf8477a6d/plugin.sock http:/VolumeDriver.List\n\n{\"Mountpoint\":\"\",\"Err\":\"\",\"Volumes\":[{\"Name\":\"myvol1\",\"Mountpoint\":\"/data/myvol1\"},{\"Name\":\"myvol2\",\"Mountpoint\":\"/data/myvol2\"}],\"Volume\":null}\n```\n\n``` \n$ curl -H \"Content-Type: application/json\" -XPOST -d '{}' --unix-socket /var/run/docker/plugins/45e00a7ce6185d6e365904c8bcf62eb724b1fe307e0d4e7ecc9f6c1eb7bcdb70/plugin.sock http:/NetworkDriver.GetCapabilities\n\n{\"Scope\":\"local\"}\n```\n\nWhen using curl 7.5 and above, the URL should be of the form `http://hostname/APICall`, where `hostname` is the valid hostname where the plugin is installed and `APICall` is the call to the plugin API.\n\nFor example, `http://localhost/VolumeDriver.List`\n\n[API](https://docs.docker.com/search/?q=API), [Usage](https://docs.docker.com/search/?q=Usage), [plugins](https://docs.docker.com/search/?q=plugins), [documentation](https://docs.docker.com/search/?q=documentation), [developer](https://docs.docker.com/search/?q=developer)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/](https://docs.docker.com/engine/extend/)"
- name: Docker Engine release notes
  id: engine/release-notes/index
  summary: This document describes the latest changes, additions, known issues, and fixes for Docker Engine
  description: "# Docker Engine release notes\n\nThis document describes the latest changes, additions, known issues, and fixes for Docker Engine.\n\n# Version 20.10\n\n## 20.10.16\n\n2022-05-12\n\nThis release of Docker Engine fixes a regression in the Docker CLI builds for macOS, fixes an issue with `docker stats` when using containerd 1.5 and up, and updates the Go runtime to include a fix for [CVE-2022-29526](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### Client\n\n- Fixed a regression in binaries for macOS introduced in [20.10.15](#201015), which resulted in a panic [docker/cli#43426](https://github.com/docker/cli/pull/3592).\n- Update golang.org/x/sys dependency which contains a fix for [CVE-2022-29526](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### Daemon\n\n- Fixed an issue where `docker stats` was showing empty stats when running with containerd 1.5.0 or up [moby/moby#43567](https://github.com/moby/moby/pull/43567).\n- Updated the `golang.org/x/sys` build-time dependency which contains a fix for [CVE-2022-29526](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### Packaging\n\n- Updated Go runtime to [1.17.10](https://go.dev/doc/devel/release#go1.17.minor), which contains a fix for [CVE-2022-29526](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n- Used “weak” dependencies for the `docker scan` CLI plugin, to prevent a “conflicting requests” error when users performed an off-line installation from downloaded RPM packages [docker/docker-ce-packaging#659](https://github.com/docker/docker-ce-packaging/pull/659).\n\n## 20.10.15\n\n2022-05-05\n\nThis release of Docker Engine comes with updated versions of the `compose`, `buildx`, `containerd`, and `runc` components, as well as some minor bug fixes.\n\n> **Known issues**\n>\n> We’ve identified an issue with the [macOS CLI binaries](https://download.docker.com/mac/static/stable/) in the 20.10.15 release. This issue has been resolved in the [20.10.16](#201016) release.\n\n### Daemon\n\n- Use a RWMutex for stateCounter to prevent potential locking congestion [moby/moby#43426](https://github.com/moby/moby/pull/43426).\n- Prevent an issue where the daemon was unable to find an available IP-range in some conditions [moby/moby#43360](https://github.com/moby/moby/pull/43360)\n\n### Packaging\n\n- Update Docker Compose to [v2.5.0](https://github.com/docker/compose/releases/tag/v2.5.0).\n- Update Docker Buildx to [v0.8.2](https://github.com/docker/buildx/releases/tag/v0.8.2).\n- Update Go runtime to [1.17.9](https://go.dev/doc/devel/release#go1.17.minor).\n- Update containerd (`containerd.io` package) to [v1.6.4](https://github.com/containerd/containerd/releases/tag/v1.6.4).\n- Update runc version to [v1.1.1](https://github.com/opencontainers/runc/releases/tag/v1.1.1).\n- Add packages for CentOS 9 stream and Fedora 36.\n\n## 20.10.14\n\n2022-03-23\n\nThis release of Docker Engine updates the default inheritable capabilities for containers to address [CVE-2022-24769](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-24769), a new version of the `containerd.io` runtime is also included to address the same issue.\n\n### Daemon\n\n- Update the default inheritable capabilities.\n\n### Builder\n\n- Update the default inheritable capabilities for containers used during build.\n\n### Packaging\n\n- Update containerd (`containerd.io` package) to [v1.5.11](https://github.com/containerd/containerd/releases/tag/v1.5.11).\n- Update `docker buildx` to [v0.8.1](https://github.com/docker/buildx/releases/tag/v0.8.1).\n\n## 20.10.13\n\n2022-03-10\n\nThis release of Docker Engine contains some bug-fixes and packaging changes, updates to the `docker scan` and `docker buildx` commands, an updated version of the Go runtime, and new versions of the `containerd.io` runtime. Together with this release, we now also provide `.deb` and `.rpm` packages of Docker Compose V2, which can be installed using the (optional) `docker-compose-plugin` package.\n\n### Builder\n\n- Updated the bundled version of buildx to [v0.8.0](https://github.com/docker/buildx/releases/tag/v0.8.0).\n\n### Daemon\n\n- Fix a race condition when updating the container’s state [moby/moby#43166](https://github.com/moby/moby/pull/43166).\n- Update the etcd dependency to prevent the daemon from incorrectly holding file locks [moby/moby#43259](https://github.com/moby/moby/pull/43259)\n- Fix detection of user-namespaces when configuring the default `net.ipv4.ping_group_range` sysctl [moby/moby#43084](https://github.com/moby/moby/pull/43084).\n\n### Distribution\n\n- Retry downloading image-manifests if a connection failure happens during image pull [moby/moby#43333](https://github.com/moby/moby/pull/43333).\n\n### Documentation\n\n- Various fixes in command-line reference and API documentation.\n\n### Logging\n\n- Prevent an OOM when using the “local” logging driver with containers that produce a large amount of log messages [moby/moby#43165](https://github.com/moby/moby/pull/43165).\n- Updates the fluentd log driver to prevent a potential daemon crash, and prevent containers from hanging when using the `fluentd-async-connect=true` and the remote server is unreachable [moby/moby#43147](https://github.com/moby/moby/pull/43147).\n\n### Packaging\n\n- Provide `.deb` and `.rpm` packages for Docker Compose V2. [Docker Compose v2.3.3](https://github.com/docker/compose/releases/tag/v2.3.3) can now be installed on Linux using the `docker-compose-plugin` packages, which provides the `docker compose` subcommand on the Docker CLI. The Docker Compose plugin can also be installed and run standalone to be used as a drop-in replacement for `docker-compose` (Docker Compose V1) [docker/docker-ce-packaging#638](https://github.com/docker/docker-ce-packaging/pull/638). The `compose-cli-plugin` package can also be used on older version of the Docker CLI with support for CLI plugins (Docker CLI 18.09 and up).\n- Provide packages for the upcoming Ubuntu 22.04 “Jammy Jellyfish” LTS release [docker/docker-ce-packaging#645](https://github.com/docker/docker-ce-packaging/pull/645), [docker/containerd-packaging#271](https://github.com/docker/containerd-packaging/pull/271).\n- Update `docker buildx` to [v0.8.0](https://github.com/docker/buildx/releases/tag/v0.8.0).\n- Update `docker scan` (`docker-scan-plugin`) to [v0.17.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.17.0).\n- Update containerd (`containerd.io` package) to [v1.5.10](https://github.com/containerd/containerd/releases/tag/v1.5.10).\n- Update the bundled runc version to [v1.0.3](https://github.com/opencontainers/runc/releases/tag/v1.0.3).\n- Update Golang runtime to Go 1.16.15.\n\n## 20.10.12\n\n2021-12-13\n\nThis release of Docker Engine contains changes in packaging only, and provides updates to the `docker scan` and `docker buildx` commands. Versions of `docker scan` before v0.11.0 are not able to detect the [Log4j 2 CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228). We are shipping an updated version of `docker scan` in this release to help you scan your images for this vulnerability.\n\n> **Note**\n>\n> The `docker scan` command on Linux is currently only supported on x86 platforms. We do not yet provide a package for other hardware architectures on Linux.\n\nThe `docker scan` feature is provided as a separate package and, depending on your upgrade or installation method, ‘docker scan’ may not be updated automatically to the latest version. Use the instructions below to update `docker scan` to the latest version. You can also use these instructions to install, or upgrade the `docker scan` package without upgrading the Docker Engine:\n\nOn `.deb` based distros, such as Ubuntu and Debian:\n\n``` \n$ apt-get update && apt-get install docker-scan-plugin\n```\n\nOn rpm-based distros, such as CentOS or Fedora:\n\n``` \n$ yum install docker-scan-plugin\n```\n\nAfter upgrading, verify you have the latest version of `docker scan` installed:\n\n``` \n$ docker scan --accept-license --version\nVersion:    v0.12.0\nGit commit: 1074dd0\nProvider:   Snyk (1.790.0 (standalone))\n```\n\n[Read our blog post on CVE-2021-44228](https://www.docker.com/blog/apache-log4j-2-cve-2021-44228/) to learn how to use the `docker scan` command to check if images are vulnerable.\n\n### Packaging\n\n- Update `docker scan` to [v0.12.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.12.0).\n- Update `docker buildx` to [v0.7.1](https://github.com/docker/buildx/releases/tag/v0.7.1).\n- Update Golang runtime to Go 1.16.12.\n\n## 20.10.11\n\n2021-11-17\n\n> **IMPORTANT**\n>\n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n>\n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### Distribution\n\n- Handle ambiguous OCI manifest parsing to mitigate [CVE-2021-41190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41190) / [GHSA-mc8v-mgrf-8f4m](https://github.com/opencontainers/distribution-spec/security/advisories/GHSA-mc8v-mgrf-8f4m). See [GHSA-xmmx-7jpf-fx42](https://github.com/moby/moby/security/advisories/GHSA-xmmx-7jpf-fx42) for details.\n\n### Windows\n\n- Fix panic.log file having read-only attribute set [moby/moby#42987](https://github.com/moby/moby/pull/42987).\n\n### Packaging\n\n- Update containerd to [v1.4.12](https://github.com/containerd/containerd/releases/tag/v1.4.12) to mitigate [CVE-2021-41190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41190).\n- Update Golang runtime to Go 1.16.10.\n\n## 20.10.10\n\n2021-10-25\n\n> **IMPORTANT**\n>\n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n>\n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### Builder\n\n- Fix platform-matching logic to fix `docker build` using not finding images in the local image cache on Arm machines when using BuildKit [moby/moby#42954](https://github.com/moby/moby/pull/42954)\n\n### Runtime\n\n- Add support for `clone3` syscall in the default seccomp policy to support running containers based on recent versions of Fedora and Ubuntu. [moby/moby/#42836](https://github.com/moby/moby/pull/42836).\n- Windows: update hcsshim library to fix a bug in sparse file handling in container layers, which was exposed by recent changes in Windows [moby/moby#42944](https://github.com/moby/moby/pull/42944).\n- Fix some situations where `docker stop` could hang forever [moby/moby#42956](https://github.com/moby/moby/pull/42956).\n\n### Swarm\n\n- Fix an issue where updating a service did not roll back on failure [moby/moby#42875](https://github.com/moby/moby/pull/42875).\n\n### Packaging\n\n- Add packages for Ubuntu 21.10 “Impish Indri” and Fedora 35.\n- Update `docker scan` to v0.9.0\n- Update Golang runtime to Go 1.16.9.\n\n## 20.10.9\n\n2021-10-04\n\nThis release is a security release with security fixes in the CLI, runtime, as well as updated versions of the containerd.io package.\n\n> **IMPORTANT**\n>\n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n>\n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### Client\n\n- [CVE-2021-41092](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41092) Ensure default auth config has address field set, to prevent credentials being sent to the default registry.\n\n### Runtime\n\n- [CVE-2021-41089](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41089) Create parent directories inside a chroot during `docker cp` to prevent a specially crafted container from changing permissions of existing files in the host’s filesystem.\n- [CVE-2021-41091](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41091) Lock down file permissions to prevent unprivileged users from discovering and executing programs in `/var/lib/docker`.\n\n### Packaging\n\n> **Known issue**\n>\n> The `ctr` binary shipping with the static packages of this release is not statically linked, and will not run in Docker images using alpine as a base image. Users can install the `libc6-compat` package, or download a previous version of the `ctr` binary as a workaround. Refer to the containerd ticket related to this issue for more details: [containerd/containerd#5824](https://github.com/containerd/containerd/issues/5824).\n\n- Update Golang runtime to Go 1.16.8, which contains fixes for [CVE-2021-36221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-36221) and [CVE-2021-39293](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-39293)\n- Update static binaries and containerd.io rpm and deb packages to containerd v1.4.11 and runc v1.0.2 to address [CVE-2021-41103](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41103).\n- Update the bundled buildx version to v0.6.3 for rpm and deb packages.\n\n## 20.10.8\n\n2021-08-03\n\n> **IMPORTANT**\n>\n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n>\n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### Deprecation\n\n- Deprecate support for encrypted TLS private keys. Legacy PEM encryption as specified in RFC 1423 is insecure by design. Because it does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext. Support for encrypted TLS private keys is now marked as deprecated, and will be removed in an upcoming release. [docker/cli#3219](https://github.com/docker/cli/pull/3219)\n- Deprecate Kubernetes stack support. Following the deprecation of [Compose on Kubernetes](https://github.com/docker/compose-on-kubernetes), support for Kubernetes in the `stack` and `context` commands in the Docker CLI is now marked as deprecated, and will be removed in an upcoming release [docker/cli#3174](https://github.com/docker/cli/pull/3174).\n\n### Client\n\n- Fix `Invalid standard handle identifier` errors on Windows [docker/cli#3132](https://github.com/docker/cli/pull/3132).\n\n### Rootless\n\n- Avoid `can't open lock file /run/xtables.lock: Permission denied` error on SELinux hosts [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n- Disable overlay2 when running with SELinux to prevent permission denied errors [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n- Fix `x509: certificate signed by unknown authority` error on openSUSE Tumbleweed [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n\n### Runtime\n\n- Print a warning when using the `--platform` option to pull a single-arch image that does not match the specified architecture [moby/moby#42633](https://github.com/moby/moby/pull/42633).\n- Fix incorrect `Your kernel does not support swap memory limit` warning when running with cgroups v2 [moby/moby#42479](https://github.com/moby/moby/pull/42479).\n- Windows: Fix a situation where containers were not stopped if `HcsShutdownComputeSystem` returned an `ERROR_PROC_NOT_FOUND` error [moby/moby#42613](https://github.com/moby/moby/pull/42613)\n\n### Swarm\n\n- Fix a possibility where overlapping IP addresses could exist as a result of the node failing to clean up its old loadbalancer IPs [moby/moby#42538](https://github.com/moby/moby/pull/42538)\n- Fix a deadlock in log broker (“dispatcher is stopped”) [moby/moby#42537](https://github.com/moby/moby/pull/42537)\n\n### Packaging\n\n> **Known issue**\n>\n> The `ctr` binary shipping with the static packages of this release is not statically linked, and will not run in Docker images using alpine as a base image. Users can install the `libc6-compat` package, or download a previous version of the `ctr` binary as a workaround. Refer to the containerd ticket related to this issue for more details: [containerd/containerd#5824](https://github.com/containerd/containerd/issues/5824).\n\n- Remove packaging for Ubuntu 16.04 “Xenial” and Fedora 32, as they reached EOL [docker/docker-ce-packaging#560](https://github.com/docker/docker-ce-packaging/pull/560)\n- Update Golang runtime to Go 1.16.6\n- Update the bundled buildx version to v0.6.1 for rpm and deb packages [docker/docker-ce-packaging#562](https://github.com/docker/docker-ce-packaging/pull/562)\n- Update static binaries and containerd.io rpm and deb packages to containerd v1.4.9 and runc v1.0.1: [docker/containerd-packaging#241](https://github.com/docker/containerd-packaging/pull/241), [docker/containerd-packaging#245](https://github.com/docker/containerd-packaging/pull/245), [docker/containerd-packaging#247](https://github.com/docker/containerd-packaging/pull/247).\n\n## 20.10.7\n\n2021-06-02\n\n### Client\n\n- Suppress warnings for deprecated cgroups [docker/cli#3099](https://github.com/docker/cli/pull/3099).\n- Prevent sending `SIGURG` signals to container on Linux and macOS. The Go runtime (starting with Go 1.14) uses `SIGURG` signals internally as an interrupt to support preemptable syscalls. In situations where the Docker CLI was attached to a container, these interrupts were forwarded to the container. This fix changes the Docker CLI to ignore `SIGURG` signals [docker/cli#3107](https://github.com/docker/cli/pull/3107), [moby/moby#42421](https://github.com/moby/moby/pull/42421).\n\n### Builder\n\n- Update BuildKit to version v0.8.3-3-g244e8cde [moby/moby#42448](https://github.com/moby/moby/pull/42448):\n  - Transform relative mountpoints for exec mounts in the executor to work around a breaking change in runc v1.0.0-rc94 and up. [moby/buildkit#2137](https://github.com/moby/buildkit/pull/2137).\n  - Add retry on image push 5xx errors. [moby/buildkit#2043](https://github.com/moby/buildkit/pull/2043).\n  - Fix build-cache not being invalidated when renaming a file that is copied using a `COPY` command with a wildcard. Note that this change invalidates existing build caches for copy commands that use a wildcard. [moby/buildkit#2018](https://github.com/moby/buildkit/pull/2018).\n  - Fix build-cache not being invalidated when using mounts [moby/buildkit#2076](https://github.com/moby/buildkit/pull/2076).\n- Fix build failures when `FROM` image is not cached when using legacy schema 1 images [moby/moby#42382](https://github.com/moby/moby/pull/42382).\n\n### Logging\n\n- Update the hcsshim SDK to make daemon logs on Windows less verbose [moby/moby#42292](https://github.com/moby/moby/pull/42292).\n\n### Rootless\n\n- Fix capabilities not being honored when an image was built on a daemon with user-namespaces enabled [moby/moby#42352](https://github.com/moby/moby/pull/42352).\n\n### Networking\n\n- Update libnetwork to fix publishing ports on environments with kernel boot parameter `ipv6.disable=1`, and to fix a deadlock causing internal DNS lookups to fail [moby/moby#42413](https://github.com/moby/moby/pull/42413).\n\n### Contrib\n\n- Update rootlesskit to v0.14.2 to fix a timeout when starting the userland proxy with the `slirp4netns` port driver [moby/moby#42294](https://github.com/moby/moby/pull/42294).\n- Fix “Device or resource busy” errors when running docker-in-docker on a rootless daemon [moby/moby#42342](https://github.com/moby/moby/pull/42342).\n\n### Packaging\n\n- Update containerd to v1.4.6, runc v1.0.0-rc95 to address [CVE-2021-30465](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-30465) [moby/moby#42398](https://github.com/moby/moby/pull/42398), [moby/moby#42395](https://github.com/moby/moby/pull/42395), [ocker/containerd-packaging#234](https://github.com/docker/containerd-packaging/pull/234)\n- Update containerd to v1.4.5, runc v1.0.0-rc94 [moby/moby#42372](https://github.com/moby/moby/pull/42372), [moby/moby#42388](https://github.com/moby/moby/pull/42388), [docker/containerd-packaging#232](https://github.com/docker/containerd-packaging/pull/232).\n- Update Docker Scan plugin packages (`docker-scan-plugin`) to v0.8 [docker/docker-ce-packaging#545](https://github.com/docker/docker-ce-packaging/pull/545).\n\n## 20.10.6\n\n2021-04-12\n\n### Client\n\n- Apple Silicon (darwin/arm64) support for Docker CLI [docker/cli#3042](https://github.com/docker/cli/pull/3042)\n- config: print deprecation warning when falling back to pre-v1.7.0 config file `~/.dockercfg`. Support for this file will be removed in a future release [docker/cli#3000](https://github.com/docker/cli/pull/3000)\n\n### Builder\n\n- Fix classic builder silently ignoring unsupported Dockerfile options and prompt to enable BuildKit instead [moby/moby#42197](https://github.com/moby/moby/pull/42197)\n\n### Logging\n\n- json-file: fix sporadic unexpected EOF errors [moby/moby#42174](https://github.com/moby/moby/pull/42174)\n\n### Networking\n\n- Fix a regression in docker 20.10, causing IPv6 addresses no longer to be bound by default when mapping ports [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n- Fix implicit IPv6 port-mappings not included in API response. Before docker 20.10, published ports were accessible through both IPv4 and IPv6 by default, but the API only included information about the IPv4 (0.0.0.0) mapping [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n- Fix a regression in docker 20.10, causing the docker-proxy to not be terminated in all cases [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n- Fix iptables forwarding rules not being cleaned up upon container removal [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n\n### Packaging\n\n- Update containerd to [v1.4.4](https://github.com/containerd/containerd/releases/tag/v1.4.4) for static binaries. The containerd.io package on apt/yum repos already had this update out of band. Includes a fix for [CVE-2021-21334](https://github.com/containerd/containerd/security/advisories/GHSA-6g2q-w5j3-fwh4). [moby/moby#42124](https://github.com/moby/moby/pull/42124)\n- Packages for Debian/Raspbian 11 Bullseye, Ubuntu 21.04 Hirsute Hippo and Fedora 34 [docker/docker-ce-packaging#521](https://github.com/docker/docker-ce-packaging/pull/521) [docker/docker-ce-packaging#522](https://github.com/docker/docker-ce-packaging/pull/522) [docker/docker-ce-packaging#533](https://github.com/docker/docker-ce-packaging/pull/533)\n- Provide the [Docker Scan CLI](https://github.com/docker/scan-cli-plugin) plugin on Linux amd64 via a `docker-scan-plugin` package as a recommended dependency for the `docker-ce-cli` package [docker/docker-ce-packaging#537](https://github.com/docker/docker-ce-packaging/pull/537)\n- Include VPNKit binary for arm64 [moby/moby#42141](https://github.com/moby/moby/pull/42141)\n\n### Plugins\n\n- Fix docker plugin create making plugins that were incompatible with older versions of Docker [moby/moby#42256](https://github.com/moby/moby/pull/42256)\n\n### Rootless\n\n- Update RootlessKit to [v0.14.1](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.14.1) (see also [v0.14.0](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.14.0) [v0.13.2](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.13.2)) [moby/moby#42186](https://github.com/moby/moby/pull/42186) [moby/moby#42232](https://github.com/moby/moby/pull/42232)\n- dockerd-rootless-setuptool.sh: create CLI context “rootless” [moby/moby#42109](https://github.com/moby/moby/pull/42109)\n- dockerd-rootless.sh: prohibit running as root [moby/moby#42072](https://github.com/moby/moby/pull/42072)\n- Fix “operation not permitted” when bind mounting existing mounts [moby/moby#42233](https://github.com/moby/moby/pull/42233)\n- overlay2: fix “createDirWithOverlayOpaque(...) ... input/output error” [moby/moby#42235](https://github.com/moby/moby/pull/42235)\n- overlay2: support “userxattr” option (kernel 5.11) [moby/moby#42168](https://github.com/moby/moby/pull/42168)\n- btrfs: allow unprivileged user to delete subvolumes (kernel \\>= 4.18) [moby/moby#42253](https://github.com/moby/moby/pull/42253)\n- cgroup2: Move cgroup v2 out of experimental [moby/moby#42263](https://github.com/moby/moby/pull/42263)\n\n## 20.10.5\n\n2021-03-02\n\n### Client\n\n- Revert [docker/cli#2960](https://github.com/docker/cli/pull/2960) to fix hanging in `docker start --attach` and remove spurious `Unsupported signal: <nil>. Discarding` messages. [docker/cli#2987](https://github.com/docker/cli/pull/2987).\n\n## 20.10.4\n\n2021-02-26\n\n### Builder\n\n- Fix incorrect cache match for inline cache import with empty layers [moby/moby#42061](https://github.com/moby/moby/pull/42061)\n- Update BuildKit to v0.8.2 [moby/moby#42061](https://github.com/moby/moby/pull/42061)\n  - resolver: avoid error caching on token fetch\n  - fileop: fix checksum to contain indexes of inputs preventing certain cache misses\n  - Fix reference count issues on typed errors with mount references (fixing `invalid mutable ref` errors)\n  - git: set token only for main remote access allowing cloning submodules with different credentials\n- Ensure blobs get deleted in /var/lib/docker/buildkit/content/blobs/sha256 after pull. To clean up old state run `builder prune` [moby/moby#42065](https://github.com/moby/moby/pull/42065)\n- Fix parallel pull synchronization regression [moby/moby#42049](https://github.com/moby/moby/pull/42049)\n- Ensure libnetwork state files do not leak [moby/moby#41972](https://github.com/moby/moby/pull/41972)\n\n### Client\n\n- Fix a panic on `docker login` if no config file is present [docker/cli#2959](https://github.com/docker/cli/pull/2959)\n- Fix `WARNING: Error loading config file: .dockercfg: $HOME is not defined` [docker/cli#2958](https://github.com/docker/cli/pull/2958)\n\n### Runtime\n\n- docker info: silence unhandleable warnings [moby/moby#41958](https://github.com/moby/moby/pull/41958)\n- Avoid creating parent directories for XGlobalHeader [moby/moby#42017](https://github.com/moby/moby/pull/42017)\n- Use 0755 permissions when creating missing directories [moby/moby#42017](https://github.com/moby/moby/pull/42017)\n- Fallback to manifest list when no platform matches in image config [moby/moby#42045](https://github.com/moby/moby/pull/42045) [moby/moby#41873](https://github.com/moby/moby/pull/41873)\n- Fix a daemon panic on setups with a custom default runtime configured [moby/moby#41974](https://github.com/moby/moby/pull/41974)\n- Fix a panic when daemon configuration is empty [moby/moby#41976](https://github.com/moby/moby/pull/41976)\n- Fix daemon panic when starting container with invalid device cgroup rule [moby/moby#42001](https://github.com/moby/moby/pull/42001)\n- Fix userns-remap option when username & UID match [moby/moby#42013](https://github.com/moby/moby/pull/42013)\n- static: update runc binary to v1.0.0-rc93 [moby/moby#42014](https://github.com/moby/moby/pull/42014)\n\n### Logger\n\n- Honor `labels-regex` config even if `labels` is not set [moby/moby#42046](https://github.com/moby/moby/pull/42046)\n- Handle long log messages correctly preventing awslogs in non-blocking mode to split events bigger than 16kB [mobymoby#41975](https://github.com/moby/moby/pull/41975)\n\n### Rootless\n\n- Prevent the service hanging when stopping by setting systemd KillMode to mixed [moby/moby#41956](https://github.com/moby/moby/pull/41956)\n- dockerd-rootless.sh: add typo guard [moby/moby#42070](https://github.com/moby/moby/pull/42070)\n- Update rootlesskit to v0.13.1 to fix handling of IPv6 addresses [moby/moby#42025](https://github.com/moby/moby/pull/42025)\n- allow mknodding FIFO inside userns [moby/moby#41957](https://github.com/moby/moby/pull/41957)\n\n### Security\n\n- profiles: seccomp: update to Linux 5.11 syscall list [moby/moby#41971](https://github.com/moby/moby/pull/41971)\n\n### Swarm\n\n- Fix issue with heartbeat not persisting upon restart [moby/moby#42060](https://github.com/moby/moby/pull/42060)\n- Fix potential stalled tasks [moby/moby#42060](https://github.com/moby/moby/pull/42060)\n- Fix `--update-order` and `--rollback-order` flags when only `--update-order` or `--rollback-order` is provided [docker/cli#2963](https://github.com/docker/cli/pull/2963)\n- Fix `docker service rollback` returning a non-zero exit code in some situations [docker/cli#2964](https://github.com/docker/cli/pull/2964)\n- Fix inconsistent progress-bar direction on `docker service rollback` [docker/cli#2964](https://github.com/docker/cli/pull/2964)\n\n## 20.10.3\n\n2021-02-01\n\n### Security\n\n- [CVE-2021-21285](https://github.com/moby/moby/security/advisories/GHSA-6fj5-m822-rqx8) Prevent an invalid image from crashing docker daemon\n- [CVE-2021-21284](https://github.com/moby/moby/security/advisories/GHSA-7452-xqpj-6rpc) Lock down file permissions to prevent remapped root from accessing docker state\n- Ensure AppArmor and SELinux profiles are applied when building with BuildKit\n\n### Client\n\n- Check contexts before importing them to reduce risk of extracted files escaping context store\n- Windows: prevent executing certain binaries from current directory [docker/cli#2950](https://github.com/docker/cli/pull/2950)\n\n## 20.10.2\n\n2021-01-04\n\n### Runtime\n\n- Fix a daemon start up hang when restoring containers with restart policies but that keep failing to start [moby/moby#41729](https://github.com/moby/moby/pull/41729)\n- overlay2: fix an off-by-one error preventing to build or run containers when data-root is 24-bytes long [moby/moby#41830](https://github.com/moby/moby/pull/41830)\n- systemd: send `sd_notify STOPPING=1` when shutting down [moby/moby#41832](https://github.com/moby/moby/pull/41832)\n\n### Networking\n\n- Fix IPv6 port forwarding [moby/moby#41805](https://github.com/moby/moby/pull/41805) [moby/libnetwork#2604](https://github.com/moby/libnetwork/pull/2604)\n\n### Swarm\n\n- Fix filtering for `replicated-job` and `global-job` service modes [moby/moby#41806](https://github.com/moby/moby/pull/41806)\n\n### Packaging\n\n- buildx updated to [v0.5.1](https://github.com/docker/buildx/releases/tag/v0.5.1) [docker/docker-ce-packaging#516](https://github.com/docker/docker-ce-packaging/pull/516)\n\n## 20.10.1\n\n2020-12-14\n\n### Builder\n\n- buildkit: updated to [v0.8.1](https://github.com/moby/buildkit/releases/tag/v0.8.1) with various bugfixes [moby/moby#41793](https://github.com/moby/moby/pull/41793)\n\n### Packaging\n\n- Revert a change in the systemd unit that could prevent docker from starting due to a startup order conflict [docker/docker-ce-packaging#514](https://github.com/docker/docker-ce-packaging/pull/514)\n- buildx updated to [v0.5.0](https://github.com/docker/buildx/releases/tag/v0.5.0) [docker/docker-ce-packaging#515](https://github.com/docker/docker-ce-packaging/pull/515)\n\n## 20.10.0\n\n2020-12-08\n\n### Deprecation / Removal\n\nFor an overview of all deprecated features, refer to the [Deprecated Engine Features](../deprecated/index) page.\n\n- Warnings and deprecation notice when `docker pull`-ing from non-compliant registries not supporting pull-by-digest [docker/cli#2872](https://github.com/docker/cli/pull/2872)\n- Sterner warnings and deprecation notice for unauthenticated tcp access [moby/moby#41285](https://github.com/moby/moby/pull/41285)\n- Deprecate KernelMemory (`docker run --kernel-memory`) [moby/moby#41254](https://github.com/moby/moby/pull/41254) [docker/cli#2652](https://github.com/docker/cli/pull/2652)\n- Deprecate `aufs` storage driver [docker/cli#1484](https://github.com/docker/cli/pull/1484)\n- Deprecate host-discovery and overlay networks with external k/v stores [moby/moby#40614](https://github.com/moby/moby/pull/40614) [moby/moby#40510](https://github.com/moby/moby/pull/40510)\n- Deprecate Dockerfile legacy ‘ENV name value’ syntax, use `ENV name=value` instead [docker/cli#2743](https://github.com/docker/cli/pull/2743)\n- Remove deprecated “filter” parameter for API v1.41 and up [moby/moby#40491](https://github.com/moby/moby/pull/40491)\n- Disable distribution manifest v2 schema 1 on push [moby/moby#41295](https://github.com/moby/moby/pull/41295)\n- Remove hack MalformedHostHeaderOverride breaking old docker clients (\\<= 1.12) in which case, set `DOCKER_API_VERSION` [moby/moby#39076](https://github.com/moby/moby/pull/39076)\n- Remove “docker engine” subcommands [docker/cli#2207](https://github.com/docker/cli/pull/2207)\n- Remove experimental “deploy” from “dab” files [docker/cli#2216](https://github.com/docker/cli/pull/2216)\n- Remove deprecated `docker search --automated` and `--stars` flags [docker/cli#2338](https://github.com/docker/cli/pull/2338)\n- No longer allow reserved namespaces in engine labels [docker/cli#2326](https://github.com/docker/cli/pull/2326)\n\n### API\n\n- Update API version to v1.41\n- Do not require “experimental” for metrics API [moby/moby#40427](https://github.com/moby/moby/pull/40427)\n- `GET /events` now returns `prune` events after pruning resources have completed [moby/moby#41259](https://github.com/moby/moby/pull/41259)\n  - Prune events are returned for `container`, `network`, `volume`, `image`, and `builder`, and have a `reclaimed` attribute, indicating the amount of space reclaimed (in bytes)\n- Add `one-shot` stats option to not prime the stats [moby/moby#40478](https://github.com/moby/moby/pull/40478)\n- Adding OS version info to the system info’s API (`/info`) [moby/moby#38349](https://github.com/moby/moby/pull/38349)\n- Add DefaultAddressPools to docker info [moby/moby#40714](https://github.com/moby/moby/pull/40714)\n- Add API support for PidsLimit on services [moby/moby#39882](https://github.com/moby/moby/pull/39882)\n\n### Builder\n\n- buildkit,dockerfile: Support for `RUN --mount` options without needing to specify experimental dockerfile `#syntax` directive. [moby/buildkit#1717](https://github.com/moby/buildkit/pull/1717)\n- dockerfile: `ARG` command now supports defining multiple build args on the same line similarly to `ENV` [moby/buildkit#1692](https://github.com/moby/buildkit/pull/1692)\n- dockerfile: `--chown` flag in `ADD` now allows parameter expansion [moby/buildkit#1473](https://github.com/moby/buildkit/pull/1473)\n- buildkit: Fetching authorization tokens has been moved to client-side (if the client supports it). Passwords do not leak into the build daemon anymore and users can see from build output when credentials or tokens are accessed. [moby/buildkit#1660](https://github.com/moby/buildkit/pull/1660)\n- buildkit: Connection errors while communicating with the registry for push and pull now trigger a retry [moby/buildkit#1791](https://github.com/moby/buildkit/pull/1791)\n- buildkit: Git source now supports token authentication via build secrets [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1533](https://github.com/moby/buildkit/pull/1533)\n- buildkit: Building from git source now supports forwarding SSH socket for authentication [moby/buildkit#1782](https://github.com/moby/buildkit/pull/1782)\n- buildkit: Avoid builds that generate excessive logs to cause a crash or slow down the build. Clipping is performed if needed. [moby/buildkit#1754](https://github.com/moby/buildkit/pull/1754)\n- buildkit: Change default Seccomp profile to the one provided by Docker [moby/buildkit#1807](https://github.com/moby/buildkit/pull/1807)\n- buildkit: Support for exposing SSH agent socket on Windows has been improved [moby/buildkit#1695](https://github.com/moby/buildkit/pull/1695)\n- buildkit: Disable truncating by default when using --progress=plain [moby/buildkit#1435](https://github.com/moby/buildkit/pull/1435)\n- buildkit: Allow better handling client sessions dropping while it is being shared by multiple builds [moby/buildkit#1551](https://github.com/moby/buildkit/pull/1551)\n- buildkit: secrets: allow providing secrets with env [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1534](https://github.com/moby/buildkit/pull/1534)\n  - Support `--secret id=foo,env=MY_ENV` as an alternative for storing a secret value to a file.\n  - `--secret id=GIT_AUTH_TOKEN` will load env if it exists and the file does not.\n- buildkit: Support for mirrors fallbacks, insecure TLS and custom TLS config [moby/moby#40814](https://github.com/moby/moby/pull/40814)\n- buildkit: remotecache: Only visit each item once when walking results [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1577](https://github.com/moby/buildkit/pull/1577)\n  - Improves performance and CPU use on bigger graphs\n- buildkit: Check remote when local image platform doesn’t match [moby/moby#40629](https://github.com/moby/moby/pull/40629)\n- buildkit: image export: Use correct media type when creating new layer blobs [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1541](https://github.com/moby/buildkit/pull/1541)\n- buildkit: progressui: fix logs time formatting [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1549](https://github.com/moby/buildkit/pull/1549)\n- buildkit: mitigate containerd issue on parallel push [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1548](https://github.com/moby/buildkit/pull/1548)\n- buildkit: inline cache: fix handling of duplicate blobs [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1568](https://github.com/moby/buildkit/pull/1568)\n  - Fixes https://github.com/moby/buildkit/issues/1388 cache-from working unreliably\n  - Fixes https://github.com/moby/moby/issues/41219 Image built from cached layers is missing data\n- Allow ssh:// for remote context URLs [moby/moby#40179](https://github.com/moby/moby/pull/40179)\n- builder: remove legacy build’s session handling (was experimental) [moby/moby#39983](https://github.com/moby/moby/pull/39983)\n\n### Client\n\n- Add swarm jobs support to CLI [docker/cli#2262](https://github.com/docker/cli/pull/2262)\n- Add `-a/--all-tags` to docker push [docker/cli#2220](https://github.com/docker/cli/pull/2220)\n- Add support for Kubernetes username/password auth [docker/cli#2308](https://github.com/docker/cli/pull/2308)\n- Add `--pull=missing|always|never` to `run` and `create` commands [docker/cli#1498](https://github.com/docker/cli/pull/1498)\n- Add `--env-file` flag to `docker exec` for parsing environment variables from a file [docker/cli#2602](https://github.com/docker/cli/pull/2602)\n- Add shorthand `-n` for `--tail` option [docker/cli#2646](https://github.com/docker/cli/pull/2646)\n- Add log-driver and options to service inspect “pretty” format [docker/cli#1950](https://github.com/docker/cli/pull/1950)\n- docker run: specify cgroup namespace mode with `--cgroupns` [docker/cli#2024](https://github.com/docker/cli/pull/2024)\n- `docker manifest rm` command to remove manifest list draft from local storage [docker/cli#2449](https://github.com/docker/cli/pull/2449)\n- Add “context” to “docker version” and “docker info” [docker/cli#2500](https://github.com/docker/cli/pull/2500)\n- Propagate platform flag to container create API [docker/cli#2551](https://github.com/docker/cli/pull/2551)\n- The `docker ps --format` flag now has a `.State` placeholder to print the container’s state without additional details about uptime and health check [docker/cli#2000](https://github.com/docker/cli/pull/2000)\n- Add support for docker-compose schema v3.9 [docker/cli#2073](https://github.com/docker/cli/pull/2073)\n- Add support for docker push `--quiet` [docker/cli#2197](https://github.com/docker/cli/pull/2197)\n- Hide flags that are not supported by BuildKit, if BuildKit is enabled [docker/cli#2123](https://github.com/docker/cli/pull/2123)\n- Update flag description for `docker rm -v` to clarify the option only removes anonymous (unnamed) volumes [docker/cli#2289](https://github.com/docker/cli/pull/2289)\n- Improve tasks printing for docker services [docker/cli#2341](https://github.com/docker/cli/pull/2341)\n- docker info: list CLI plugins alphabetically [docker/cli#2236](https://github.com/docker/cli/pull/2236)\n- Fix order of processing of `--label-add/--label-rm`, `--container-label-add/--container-label-rm`, and `--env-add/--env-rm` flags on `docker service update` to allow replacing existing values [docker/cli#2668](https://github.com/docker/cli/pull/2668)\n- Fix `docker rm --force` returning a non-zero exit code if one or more containers did not exist [docker/cli#2678](https://github.com/docker/cli/pull/2678)\n- Improve memory stats display by using `total_inactive_file` instead of `cache` [docker/cli#2415](https://github.com/docker/cli/pull/2415)\n- Mitigate against YAML files that has excessive aliasing [docker/cli#2117](https://github.com/docker/cli/pull/2117)\n- Allow using advanced syntax when setting a config or secret with only the source field [docker/cli#2243](https://github.com/docker/cli/pull/2243)\n- Fix reading config files containing `username` and `password` auth even if `auth` is empty [docker/cli#2122](https://github.com/docker/cli/pull/2122)\n- docker cp: prevent NPE when failing to stat destination [docker/cli#2221](https://github.com/docker/cli/pull/2221)\n- config: preserve ownership and permissions on configfile [docker/cli#2228](https://github.com/docker/cli/pull/2228)\n\n### Logging\n\n- Support reading `docker logs` with all logging drivers (best effort) [moby/moby#40543](https://github.com/moby/moby/pull/40543)\n- Add `splunk-index-acknowledgment` log option to work with Splunk HECs with index acknowledgment enabled [moby/moby#39987](https://github.com/moby/moby/pull/39987)\n- Add partial metadata to journald logs [moby/moby#41407](https://github.com/moby/moby/pull/41407)\n- Reduce allocations for logfile reader [moby/moby#40796](https://github.com/moby/moby/pull/40796)\n- Fluentd: add fluentd-async, fluentd-request-ack, and deprecate fluentd-async-connect [moby/moby#39086](https://github.com/moby/moby/pull/39086)\n\n### Runtime\n\n- Support cgroup2 [moby/moby#40174](https://github.com/moby/moby/pull/40174) [moby/moby#40657](https://github.com/moby/moby/pull/40657) [moby/moby#40662](https://github.com/moby/moby/pull/40662)\n- cgroup2: use “systemd” cgroup driver by default when available [moby/moby#40846](https://github.com/moby/moby/pull/40846)\n- new storage driver: fuse-overlayfs [moby/moby#40483](https://github.com/moby/moby/pull/40483)\n- Update containerd binary to v1.4.3 [moby/moby#41732](https://github.com/moby/moby/pull/41732)\n- `docker push` now defaults to `latest` tag instead of all tags [moby/moby#40302](https://github.com/moby/moby/pull/40302)\n- Added ability to change the number of reconnect attempts during connection loss while pulling an image by adding max-download-attempts to the config file [moby/moby#39949](https://github.com/moby/moby/pull/39949)\n- Add support for containerd v2 shim by using the now default `io.containerd.runc.v2` runtime [moby/moby#41182](https://github.com/moby/moby/pull/41182)\n- cgroup v1: change the default runtime to io.containerd.runc.v2. Requires containerd v1.3.0 or later. v1.3.5 or later is recommended [moby/moby#41210](https://github.com/moby/moby/pull/41210)\n- Start containers in their own cgroup namespaces [moby/moby#38377](https://github.com/moby/moby/pull/38377)\n- Enable DNS Lookups for CIFS Volumes [moby/moby#39250](https://github.com/moby/moby/pull/39250)\n- Use MemAvailable instead of MemFree to estimate actual available memory [moby/moby#39481](https://github.com/moby/moby/pull/39481)\n- The `--device` flag in `docker run` will now be honored when the container is started in privileged mode [moby/moby#40291](https://github.com/moby/moby/pull/40291)\n- Enforce reserved internal labels [moby/moby#40394](https://github.com/moby/moby/pull/40394)\n- Raise minimum memory limit to 6M, to account for higher memory use by runtimes during container startup [moby/moby#41168](https://github.com/moby/moby/pull/41168)\n- Add support for `CAP_PERFMON`, `CAP_BPF`, and `CAP_CHECKPOINT_RESTORE` on supported kernels [moby/moby#41460](https://github.com/moby/moby/pull/41460)\n- vendor runc v1.0.0-rc92 [moby/moby#41344](https://github.com/moby/moby/pull/41344) [moby/moby#41317](https://github.com/moby/moby/pull/41317)\n- info: add warnings about missing blkio cgroup support [moby/moby#41083](https://github.com/moby/moby/pull/41083)\n- Accept platform spec on container create [moby/moby#40725](https://github.com/moby/moby/pull/40725)\n- Fix handling of looking up user- and group-names with spaces [moby/moby#41377](https://github.com/moby/moby/pull/41377)\n\n### Networking\n\n- Support host.docker.internal in dockerd on Linux [moby/moby#40007](https://github.com/moby/moby/pull/40007)\n- Include IPv6 address of linked containers in /etc/hosts [moby/moby#39837](https://github.com/moby/moby/pull/39837)\n- `--ip6tables` enables IPv6 iptables rules (only if experimental) [moby/moby#41622](https://github.com/moby/moby/pull/41622)\n- Add alias for hostname if hostname != container name [moby/moby#39204](https://github.com/moby/moby/pull/39204)\n- Better selection of DNS server (with systemd) [moby/moby#41022](https://github.com/moby/moby/pull/41022)\n- Add docker interfaces to firewalld docker zone [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2548](https://github.com/moby/libnetwork/pull/2548)\n  - Fixes DNS issue on CentOS8 [docker/for-linux#957](https://github.com/docker/for-linux/issues/957)\n  - Fixes Port Forwarding on RHEL 8 with Firewalld running with FirewallBackend=nftables [moby/libnetwork#2496](https://github.com/moby/libnetwork/issues/2496)\n- Fix an issue reporting ‘failed to get network during CreateEndpoint’ [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2554](https://github.com/moby/libnetwork/pull/2554)\n- Log error instead of disabling IPv6 router advertisement failed [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2563](https://github.com/moby/libnetwork/pull/2563)\n- No longer ignore `--default-address-pool` option in certain cases [moby/moby#40711](https://github.com/moby/moby/pull/40711)\n- Produce an error with invalid address pool [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2538](https://github.com/moby/libnetwork/pull/2538)\n- Fix `DOCKER-USER` chain not created when IPTableEnable=false [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2471](https://github.com/moby/libnetwork/pull/2471)\n- Fix panic on startup in systemd environments [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2544](https://github.com/moby/libnetwork/pull/2544)\n- Fix issue preventing containers to communicate over macvlan internal network [moby/moby#40596](https://github.com/moby/moby/pull/40596) [moby/libnetwork#2407](https://github.com/moby/libnetwork/pull/2407)\n- Fix InhibitIPv4 nil panic [moby/moby#40596](https://github.com/moby/moby/pull/40596)\n- Fix VFP leak in Windows overlay network deletion [moby/moby#40596](https://github.com/moby/moby/pull/40596) [moby/libnetwork#2524](https://github.com/moby/libnetwork/pull/2524)\n\n### Packaging\n\n- docker.service: Add multi-user.target to After= in unit file [moby/moby#41297](https://github.com/moby/moby/pull/41297)\n- docker.service: Allow socket activation [moby/moby#37470](https://github.com/moby/moby/pull/37470)\n- seccomp: Remove dependency in dockerd on libseccomp [moby/moby#41395](https://github.com/moby/moby/pull/41395)\n\n### Rootless\n\n- rootless: graduate from experimental [moby/moby#40759](https://github.com/moby/moby/pull/40759)\n- Add dockerd-rootless-setuptool.sh [moby/moby#40950](https://github.com/moby/moby/pull/40950)\n- Support `--exec-opt native.cgroupdriver=systemd` [moby/moby#40486](https://github.com/moby/moby/pull/40486)\n\n### Security\n\n- Fix CVE-2019-14271 loading of nsswitch based config inside chroot under Glibc [moby/moby#39612](https://github.com/moby/moby/pull/39612)\n- seccomp: Whitelist `clock_adjtime`. `CAP_SYS_TIME` is still required for time adjustment [moby/moby#40929](https://github.com/moby/moby/pull/40929)\n- seccomp: Add openat2 and faccessat2 to default seccomp profile [moby/moby#41353](https://github.com/moby/moby/pull/41353)\n- seccomp: allow ‘rseq’ syscall in default seccomp profile [moby/moby#41158](https://github.com/moby/moby/pull/41158)\n- seccomp: allow syscall membarrier [moby/moby#40731](https://github.com/moby/moby/pull/40731)\n- seccomp: whitelist io-uring related system calls [moby/moby#39415](https://github.com/moby/moby/pull/39415)\n- Add default sysctls to allow ping sockets and privileged ports with no capabilities [moby/moby#41030](https://github.com/moby/moby/pull/41030)\n- Fix seccomp profile for clone syscall [moby/moby#39308](https://github.com/moby/moby/pull/39308)\n\n### Swarm\n\n- Add support for swarm jobs [moby/moby#40307](https://github.com/moby/moby/pull/40307)\n- Add capabilities support to stack/service commands [docker/cli#2687](https://github.com/docker/cli/pull/2687) [docker/cli#2709](https://github.com/docker/cli/pull/2709) [moby/moby#39173](https://github.com/moby/moby/pull/39173) [moby/moby#41249](https://github.com/moby/moby/pull/41249)\n- Add support for sending down service Running and Desired task counts [moby/moby#39231](https://github.com/moby/moby/pull/39231)\n- service: support `--mount type=bind,bind-nonrecursive` [moby/moby#38788](https://github.com/moby/moby/pull/38788)\n- Support ulimits on Swarm services. [moby/moby#41284](https://github.com/moby/moby/pull/41284) [docker/cli#2712](https://github.com/docker/cli/pull/2712)\n- Fixed an issue where service logs could leak goroutines on the worker [moby/moby#40426](https://github.com/moby/moby/pull/40426)\n\n[docker](https://docs.docker.com/search/?q=docker), [docker engine](https://docs.docker.com/search/?q=docker%20engine), [ce](https://docs.docker.com/search/?q=ce), [whats new](https://docs.docker.com/search/?q=whats%20new), [release notes](https://docs.docker.com/search/?q=release%20notes)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/release-notes/](https://docs.docker.com/engine/release-notes/)"
- name: docker events
  id: engine/reference/commandline/events/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker events\n\n  \n\nGet real time events from the server\n\n## Usage\n\n``` \n$ docker events [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUse `docker events` to get real-time events from the server. These events differ per Docker object type. Different event types have different scopes. Local scoped events are only seen on the node they take place on, and swarm scoped events are seen on all managers.\n\nOnly the last 1000 log events are returned. You can use filters to further limit the number of events returned.\n\n### Object types\n\n#### Containers\n\nDocker containers report the following events:\n\n- `attach`\n- `commit`\n- `copy`\n- `create`\n- `destroy`\n- `detach`\n- `die`\n- `exec_create`\n- `exec_detach`\n- `exec_die`\n- `exec_start`\n- `export`\n- `health_status`\n- `kill`\n- `oom`\n- `pause`\n- `rename`\n- `resize`\n- `restart`\n- `start`\n- `stop`\n- `top`\n- `unpause`\n- `update`\n\n#### Images\n\nDocker images report the following events:\n\n- `delete`\n- `import`\n- `load`\n- `pull`\n- `push`\n- `save`\n- `tag`\n- `untag`\n\n#### Plugins\n\nDocker plugins report the following events:\n\n- `enable`\n- `disable`\n- `install`\n- `remove`\n\n#### Volumes\n\nDocker volumes report the following events:\n\n- `create`\n- `destroy`\n- `mount`\n- `unmount`\n\n#### Networks\n\nDocker networks report the following events:\n\n- `create`\n- `connect`\n- `destroy`\n- `disconnect`\n- `remove`\n\n#### Daemons\n\nDocker daemons report the following events:\n\n- `reload`\n\n#### Services\n\nDocker services report the following events:\n\n- `create`\n- `remove`\n- `update`\n\n#### Nodes\n\nDocker nodes report the following events:\n\n- `create`\n- `remove`\n- `update`\n\n#### Secrets\n\nDocker secrets report the following events:\n\n- `create`\n- `remove`\n- `update`\n\n#### Configs\n\nDocker configs report the following events:\n\n- `create`\n- `remove`\n- `update`\n\n### Limiting, filtering, and formatting the output\n\n#### Limit events by time\n\nThe `--since` and `--until` parameters can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the client machine’s time. If you do not provide the `--since` option, the command returns only new and/or live events. Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the client will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long.\n\nOnly the last 1000 log events are returned. You can use filters to further limit the number of events returned.\n\n#### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If you would like to use multiple filters, pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nUsing the same filter multiple times will be handled as a *OR*; for example `--filter container=588a23dac085 --filter container=a8f7720b8c22` will display events for container 588a23dac085 *OR* container a8f7720b8c22\n\nUsing multiple filters will be handled as a *AND*; for example `--filter container=588a23dac085 --filter event=start` will display events for container container 588a23dac085 *AND* the event type is *start*\n\nThe currently supported filters are:\n\n- config (`config=<name or id>`)\n- container (`container=<name or id>`)\n- daemon (`daemon=<name or id>`)\n- event (`event=<event action>`)\n- image (`image=<repository or tag>`)\n- label (`label=<key>` or `label=<key>=<value>`)\n- network (`network=<name or id>`)\n- node (`node=<id>`)\n- plugin (`plugin=<name or id>`)\n- scope (`scope=<local or swarm>`)\n- secret (`secret=<name or id>`)\n- service (`service=<name or id>`)\n- type (`type=<container or image or volume or network or daemon or plugin or service or node or secret or config>`)\n- volume (`volume=<name>`)\n\n#### Format\n\nIf a format (`--format`) is specified, the given template will be executed instead of the default format. Go’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nIf a format is set to `{{json .}}`, the events are streamed as valid JSON Lines. For information about JSON Lines, please refer to https://jsonlines.org/.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided    |\n| `--format`        |         | Format the output using the given Go template |\n| `--since`         |         | Show all events created since timestamp       |\n| `--until`         |         | Stream events until this timestamp            |\n\n## Examples\n\n### Basic example\n\nYou’ll need two shells for this example.\n\n**Shell 1: Listening for events:**\n\n``` \n$ docker events\n```\n\n**Shell 2: Start and Stop containers:**\n\n``` \n$ docker create --name test alpine:latest top\n$ docker start test\n$ docker stop test\n```\n\n**Shell 1: (Again .. now showing events):**\n\n``` \n2017-01-05T00:35:58.859401177+08:00 container create 0fdb48addc82871eb34eb23a847cfd033dedd1a0a37bef2e6d9eb3870fc7ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1f5ceda09d4300f3a846f0acfaa9a8bb0d89e775eb744c5acecd60e0529e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n```\n\nTo exit the `docker events` command, use `CTRL+C`.\n\n### Filter events by time\n\nYou can filter the output by an absolute timestamp or relative time on the host machine, using the following different time syntaxes:\n\n``` \n$ docker events --since 1483283804\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker events --since '2017-01-05'\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker events --since '2013-09-03T15:49:29'\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker events --since '10m'\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker events --since '2017-01-05T00:35:30' --until '2017-01-05T00:36:05'\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n```\n\n### Filter events by criteria\n\nThe following commands show several different ways to filter the `docker event` output.\n\n``` \n$ docker events --filter 'event=stop'\n\n2017-01-05T00:40:22.880175420+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:41:17.888104182+08:00 container stop 2a8f...4e78 (image=alpine, name=kickass_brattain)\n\n$ docker events --filter 'image=alpine'\n\n2017-01-05T00:41:55.784240236+08:00 container create d9cd...4d70 (image=alpine, name=happy_meitner)\n2017-01-05T00:41:55.913156783+08:00 container start d9cd...4d70 (image=alpine, name=happy_meitner)\n2017-01-05T00:42:01.106875249+08:00 container kill d9cd...4d70 (image=alpine, name=happy_meitner, signal=15)\n2017-01-05T00:42:11.111934041+08:00 container kill d9cd...4d70 (image=alpine, name=happy_meitner, signal=9)\n2017-01-05T00:42:11.119578204+08:00 container die d9cd...4d70 (exitCode=137, image=alpine, name=happy_meitner)\n2017-01-05T00:42:11.173276611+08:00 container stop d9cd...4d70 (image=alpine, name=happy_meitner)\n\n$ docker events --filter 'container=test'\n\n2017-01-05T00:43:00.139719934+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:43:09.259951086+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:43:09.270102715+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:43:09.312556440+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker events --filter 'container=test' --filter 'container=d9cdb1525ea8'\n\n2017-01-05T00:44:11.517071981+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:44:17.685870901+08:00 container start d9cd...4d70 (image=alpine, name=happy_meitner)\n2017-01-05T00:44:29.757658470+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=9)\n2017-01-05T00:44:29.767718510+08:00 container die 0fdb...ff37 (exitCode=137, image=alpine:latest, name=test)\n2017-01-05T00:44:29.815798344+08:00 container destroy 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker events --filter 'container=test' --filter 'event=stop'\n\n2017-01-05T00:46:13.664099505+08:00 container stop a9d1...e130 (image=alpine, name=test)\n\n$ docker events --filter 'type=volume'\n\n2015-12-23T21:05:28.136212689Z volume create test-event-volume-local (driver=local)\n2015-12-23T21:05:28.383462717Z volume mount test-event-volume-local (read/write=true, container=562f...5025, destination=/foo, driver=local, propagation=rprivate)\n2015-12-23T21:05:28.650314265Z volume unmount test-event-volume-local (container=562f...5025, driver=local)\n2015-12-23T21:05:28.716218405Z volume destroy test-event-volume-local (driver=local)\n\n$ docker events --filter 'type=network'\n\n2015-12-23T21:38:24.705709133Z network create 8b11...2c5b (name=test-event-network-local, type=bridge)\n2015-12-23T21:38:25.119625123Z network connect 8b11...2c5b (name=test-event-network-local, container=b4be...c54e, type=bridge)\n\n$ docker events --filter 'container=container_1' --filter 'container=container_2'\n\n2014-09-03T15:49:29.999999999Z07:00 container die 4386fb97867d (image=ubuntu-1:14.04)\n2014-05-10T17:42:14.999999999Z07:00 container stop 4386fb97867d (image=ubuntu-1:14.04)\n2014-05-10T17:42:14.999999999Z07:00 container die 7805c1d35632 (imager=redis:2.8)\n2014-09-03T15:49:29.999999999Z07:00 container stop 7805c1d35632 (image=redis:2.8)\n\n$ docker events --filter 'type=volume'\n\n2015-12-23T21:05:28.136212689Z volume create test-event-volume-local (driver=local)\n2015-12-23T21:05:28.383462717Z volume mount test-event-volume-local (read/write=true, container=562fe10671e9273da25eed36cdce26159085ac7ee6707105fd534866340a5025, destination=/foo, driver=local, propagation=rprivate)\n2015-12-23T21:05:28.650314265Z volume unmount test-event-volume-local (container=562fe10671e9273da25eed36cdce26159085ac7ee6707105fd534866340a5025, driver=local)\n2015-12-23T21:05:28.716218405Z volume destroy test-event-volume-local (driver=local)\n\n$ docker events --filter 'type=network'\n\n2015-12-23T21:38:24.705709133Z network create 8b111217944ba0ba844a65b13efcd57dc494932ee2527577758f939315ba2c5b (name=test-event-network-local, type=bridge)\n2015-12-23T21:38:25.119625123Z network connect 8b111217944ba0ba844a65b13efcd57dc494932ee2527577758f939315ba2c5b (name=test-event-network-local, container=b4be644031a3d90b400f88ab3d4bdf4dc23adb250e696b6328b85441abe2c54e, type=bridge)\n\n$ docker events --filter 'type=plugin'\n\n2016-07-25T17:30:14.825557616Z plugin pull ec7b87f2ce84330fe076e666f17dfc049d2d7ae0b8190763de94e1f2d105993f (name=tiborvass/sample-volume-plugin:latest)\n2016-07-25T17:30:14.888127370Z plugin enable ec7b87f2ce84330fe076e666f17dfc049d2d7ae0b8190763de94e1f2d105993f (name=tiborvass/sample-volume-plugin:latest)\n\n$ docker events -f type=service\n\n2017-07-12T06:34:07.999446625Z service create wj64st89fzgchxnhiqpn8p4oj (name=reverent_albattani)\n2017-07-12T06:34:21.405496207Z service remove wj64st89fzgchxnhiqpn8p4oj (name=reverent_albattani)\n\n$ docker events -f type=node\n\n2017-07-12T06:21:51.951586759Z node update 3xyz5ttp1a253q74z1thwywk9 (name=ip-172-31-23-42, state.new=ready, state.old=unknown)\n\n$ docker events -f type=secret\n\n2017-07-12T06:32:13.915704367Z secret create s8o6tmlnndrgzbmdilyy5ymju (name=new_secret)\n2017-07-12T06:32:37.052647783Z secret remove s8o6tmlnndrgzbmdilyy5ymju (name=new_secret)\n\n$  docker events -f type=config\n2017-07-12T06:44:13.349037127Z config create u96zlvzdfsyb9sg4mhyxfh3rl (name=abc)\n2017-07-12T06:44:36.327694184Z config remove u96zlvzdfsyb9sg4mhyxfh3rl (name=abc)\n\n$ docker events --filter 'scope=swarm'\n\n2017-07-10T07:46:50.250024503Z service create m8qcxu8081woyof7w3jaax6gk (name=affectionate_wilson)\n2017-07-10T07:47:31.093797134Z secret create 6g5pufzsv438p9tbvl9j94od4 (name=new_secret)\n```\n\n### Format the output\n\n``` \n$ docker events --filter 'type=container' --format 'Type={{.Type}}  Status={{.Status}}  ID={{.ID}}'\n\nType=container  Status=create  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=attach  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=start  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=resize  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=die  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=destroy  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\n```\n\n#### Format as JSON\n\n``` \n$ docker events --format '{{json .}}'\n\n{\"status\":\"create\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f4..\n{\"status\":\"attach\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f4..\n{\"Type\":\"network\",\"Action\":\"connect\",\"Actor\":{\"ID\":\"1b50a5bf755f6021dfa78e..\n{\"status\":\"start\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f42..\n{\"status\":\"resize\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f4..\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/events/](https://docs.docker.com/engine/reference/commandline/events/)"
- name: docker exec
  id: engine/reference/commandline/exec/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker exec\n\n  \n\nRun a command in a running container\n\n## Usage\n\n``` \n$ docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker exec` command runs a new command in a running container.\n\nThe command started using `docker exec` only runs while the container’s primary process (`PID 1`) is running, and it is not restarted if the container is restarted.\n\nCOMMAND will run in the default directory of the container. If the underlying image has a custom directory specified with the WORKDIR directive in its Dockerfile, this will be used instead.\n\nCOMMAND should be an executable, a chained or a quoted command will not work. Example: `docker exec -ti my_container \"echo a && echo b\"` will not work, but `docker exec -ti my_container sh -c \"echo a && echo b\"` will.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand        | Default | Description                                                |\n|------------------------|---------|------------------------------------------------------------|\n| `--detach` , `-d`      |         | Detached mode: run command in the background               |\n| `--detach-keys`        |         | Override the key sequence for detaching a container        |\n| `--env` , `-e`         |         | Set environment variables                                  |\n| `--env-file`           |         | Read in a file of environment variables                    |\n| `--interactive` , `-i` |         | Keep STDIN open even if not attached                       |\n| `--privileged`         |         | Give extended privileges to the command                    |\n| `--tty` , `-t`         |         | Allocate a pseudo-TTY                                      |\n| `--user` , `-u`        |         | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\]) |\n| `--workdir` , `-w`     |         | Working directory inside the container                     |\n\n## Examples\n\n### Run `docker exec` on a running container\n\nFirst, start a container.\n\n``` \n$ docker run --name ubuntu_bash --rm -i -t ubuntu bash\n```\n\nThis will create a container named `ubuntu_bash` and start a Bash session.\n\nNext, execute a command on the container.\n\n``` \n$ docker exec -d ubuntu_bash touch /tmp/execWorks\n```\n\nThis will create a new file `/tmp/execWorks` inside the running container `ubuntu_bash`, in the background.\n\nNext, execute an interactive `bash` shell on the container.\n\n``` \n$ docker exec -it ubuntu_bash bash\n```\n\nThis will create a new Bash session in the container `ubuntu_bash`.\n\nNext, set an environment variable in the current bash session.\n\n``` \n$ docker exec -it -e VAR=1 ubuntu_bash bash\n```\n\nThis will create a new Bash session in the container `ubuntu_bash` with environment variable `$VAR` set to “1”. Note that this environment variable will only be valid on the current Bash session.\n\nBy default `docker exec` command runs in the same working directory set when container was created.\n\n``` \n$ docker exec -it ubuntu_bash pwd\n/\n```\n\nYou can select working directory for the command to execute into\n\n``` \n$ docker exec -it -w /root ubuntu_bash pwd\n/root\n```\n\n### Try to run `docker exec` on a paused container\n\nIf the container is paused, then the `docker exec` command will fail with an error:\n\n``` \n$ docker pause test\n\ntest\n\n$ docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                   PORTS               NAMES\n1ae3b36715d2        ubuntu:latest       \"bash\"              17 seconds ago      Up 16 seconds (Paused)                       test\n\n$ docker exec test ls\n\nFATA[0000] Error response from daemon: Container test is paused, unpause the container before exec\n\n$ echo $?\n1\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/exec/](https://docs.docker.com/engine/reference/commandline/exec/)"
- name: docker export
  id: engine/reference/commandline/export/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker export\n\n  \n\nExport a container’s filesystem as a tar archive\n\n## Usage\n\n``` \n$ docker export [OPTIONS] CONTAINER\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker export` command does not export the contents of volumes associated with the container. If a volume is mounted on top of an existing directory in the container, `docker export` will export the contents of the *underlying* directory, not the contents of the volume.\n\nRefer to [Backup, restore, or migrate data volumes](https://docs.docker.com/storage/volumes/#backup-restore-or-migrate-data-volumes) in the user guide for examples on exporting data in a volume.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                        |\n|-------------------|---------|------------------------------------|\n| `--output` , `-o` |         | Write to a file, instead of STDOUT |\n\n## Examples\n\nEach of these commands has the same result.\n\n``` \n$ docker export red_panda > latest.tar\n```\n\n``` \n$ docker export --output=\"latest.tar\" red_panda\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/export/](https://docs.docker.com/engine/reference/commandline/export/)"
- name: docker history
  id: engine/reference/commandline/history/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker history\n\n  \n\nShow the history of an image\n\n## Usage\n\n``` \n$ docker history [OPTIONS] IMAGE\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                    |\n|------------------|---------|------------------------------------------------|\n| `--format`       |         | Pretty-print images using a Go template        |\n| `--human` , `-H` | `true`  | Print sizes and dates in human readable format |\n| `--no-trunc`     |         | Don't truncate output                          |\n| `--quiet` , `-q` |         | Only show image IDs                            |\n\n## Examples\n\nTo see how the `docker:latest` image was built:\n\n``` \n$ docker history docker\n\nIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n3e23a5875458        8 days ago          /bin/sh -c #(nop) ENV LC_ALL=C.UTF-8            0 B\n8578938dd170        8 days ago          /bin/sh -c dpkg-reconfigure locales &&    loc   1.245 MB\nbe51b77efb42        8 days ago          /bin/sh -c apt-get update && apt-get install    338.3 MB\n4b137612be55        6 weeks ago         /bin/sh -c #(nop) ADD jessie.tar.xz in /        121 MB\n750d58736b4b        6 weeks ago         /bin/sh -c #(nop) MAINTAINER Tianon Gravi <ad   0 B\n511136ea3c5a        9 months ago                                                        0 B                 Imported from -\n```\n\nTo see how the `docker:apache` image was added to a container’s base image:\n\n``` \n$ docker history docker:scm\nIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n2ac9d1098bf1        3 months ago        /bin/bash                                       241.4 MB            Added Apache to Fedora base image\n88b42ffd1f7c        5 months ago        /bin/sh -c #(nop) ADD file:1fd8d7f9f6557cafc7   373.7 MB\nc69cab00d6ef        5 months ago        /bin/sh -c #(nop) MAINTAINER Lokesh Mandvekar   0 B\n511136ea3c5a        19 months ago                                                       0 B                 Imported from -\n```\n\n### Format the output\n\nThe formatting option (`--format`) will pretty-prints history output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder     | Description                                                                                               |\n|-----------------|-----------------------------------------------------------------------------------------------------------|\n| `.ID`           | Image ID                                                                                                  |\n| `.CreatedSince` | Elapsed time since the image was created if `--human=true`, otherwise timestamp of when image was created |\n| `.CreatedAt`    | Timestamp of when image was created                                                                       |\n| `.CreatedBy`    | Command that was used to create the image                                                                 |\n| `.Size`         | Image disk size                                                                                           |\n| `.Comment`      | Comment for image                                                                                         |\n\nWhen using the `--format` option, the `history` command will either output the data exactly as the template declares or, when using the `table` directive, will include column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `CreatedSince` entries separated by a colon (`:`) for the `busybox` image:\n\n``` \n$ docker history --format \"{{.ID}}: {{.CreatedSince}}\" busybox\n\nf6e427c148a7: 4 weeks ago\n<missing>: 4 weeks ago\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/history/](https://docs.docker.com/engine/reference/commandline/history/)"
- name: docker image
  id: engine/reference/commandline/image/index
  summary: Manage images
  description: "# docker image\n\n  \n\nManage images\n\n## Usage\n\n``` \n$ docker image COMMAND\n```\n\n## Description\n\nManage images.\n\n## Child commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image/](https://docs.docker.com/engine/reference/commandline/image/)"
- name: docker image build
  id: engine/reference/commandline/image_build/index
  summary: © 2019 Docker, Inc
  description: "# docker image build\n\n  \n\nBuild an image from a Dockerfile\n\n## Usage\n\n``` \n$ docker image build [OPTIONS] PATH | URL | -\n```\n\n## Options\n\n| Name, shorthand           | Default | Description                                                                                                                              |\n|---------------------------|---------|------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |         | Add a custom host-to-IP mapping (host:ip)                                                                                                |\n| `--build-arg`             |         | Set build-time variables                                                                                                                 |\n| `--cache-from`            |         | Images to consider as cache sources                                                                                                      |\n| `--cgroup-parent`         |         | Optional parent cgroup for the container                                                                                                 |\n| `--compress`              |         | Compress the build context using gzip                                                                                                    |\n| `--cpu-period`            |         | Limit the CPU CFS (Completely Fair Scheduler) period                                                                                     |\n| `--cpu-quota`             |         | Limit the CPU CFS (Completely Fair Scheduler) quota                                                                                      |\n| `--cpu-shares` , `-c`     |         | CPU shares (relative weight)                                                                                                             |\n| `--cpuset-cpus`           |         | CPUs in which to allow execution (0-3, 0,1)                                                                                              |\n| `--cpuset-mems`           |         | MEMs in which to allow execution (0-3, 0,1)                                                                                              |\n| `--disable-content-trust` | `true`  | Skip image verification                                                                                                                  |\n| `--file` , `-f`           |         | Name of the Dockerfile (Default is 'PATH/Dockerfile')                                                                                    |\n| `--force-rm`              |         | Always remove intermediate containers                                                                                                    |\n| `--iidfile`               |         | Write the image ID to the file                                                                                                           |\n| `--isolation`             |         | Container isolation technology                                                                                                           |\n| `--label`                 |         | Set metadata for an image                                                                                                                |\n| `--memory` , `-m`         |         | Memory limit                                                                                                                             |\n| `--memory-swap`           |         | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                      |\n| `--network`               |         | Set the networking mode for the RUN instructions during build                                                                            |\n| `--no-cache`              |         | Do not use cache when building the image                                                                                                 |\n| `--output` , `-o`         |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Output destination (format: type=local,dest=path)                                 |\n| `--platform`              |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Set platform if server is multi-platform capable                                  |\n| `--progress`              | `auto`  | Set type of progress output (auto, plain, tty). Use plain to show container output                                                       |\n| `--pull`                  |         | Always attempt to pull a newer version of the image                                                                                      |\n| `--quiet` , `-q`          |         | Suppress the build output and print image ID on success                                                                                  |\n| `--rm`                    | `true`  | Remove intermediate containers after a successful build                                                                                  |\n| `--secret`                |         | Secret file to expose to the build (only if BuildKit enabled): id=mysecret,src=/local/secret                                             |\n| `--security-opt`          |         | Security options                                                                                                                         |\n| `--shm-size`              |         | Size of /dev/shm                                                                                                                         |\n| `--squash`                |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Squash newly built layers into a single new layer                    |\n| `--ssh`                   |         | SSH agent socket or keys to expose to the build (only if BuildKit enabled) (format: default\\|\\<id\\>\\[=\\<socket\\>\\|\\<key\\>\\[,\\<key\\>\\]\\]) |\n| `--stream`                |         | Stream attaches to server to negotiate build context                                                                                     |\n| `--tag` , `-t`            |         | Name and optionally a tag in the 'name:tag' format                                                                                       |\n| `--target`                |         | Set the target build stage to build.                                                                                                     |\n| `--ulimit`                |         | Ulimit options                                                                                                                           |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](index)                    | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_build/](https://docs.docker.com/engine/reference/commandline/image_build/)"
- name: docker image history
  id: engine/reference/commandline/image_history/index
  summary: © 2019 Docker, Inc
  description: "# docker image history\n\n  \n\nShow the history of an image\n\n## Usage\n\n``` \n$ docker image history [OPTIONS] IMAGE\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                                    |\n|------------------|---------|------------------------------------------------|\n| `--format`       |         | Pretty-print images using a Go template        |\n| `--human` , `-H` | `true`  | Print sizes and dates in human readable format |\n| `--no-trunc`     |         | Don't truncate output                          |\n| `--quiet` , `-q` |         | Only show image IDs                            |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](index)                  | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_history/](https://docs.docker.com/engine/reference/commandline/image_history/)"
- name: docker image import
  id: engine/reference/commandline/image_import/index
  summary: © 2019 Docker, Inc
  description: "# docker image import\n\n  \n\nImport the contents from a tarball to create a filesystem image\n\n## Usage\n\n``` \n$ docker image import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                                       |\n|--------------------|---------|---------------------------------------------------|\n| `--change` , `-c`  |         | Apply Dockerfile instruction to the created image |\n| `--message` , `-m` |         | Set commit message for imported image             |\n| `--platform`       |         | Set platform if server is multi-platform capable  |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](index)                   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_import/](https://docs.docker.com/engine/reference/commandline/image_import/)"
- name: docker image inspect
  id: engine/reference/commandline/image_inspect/index
  summary: © 2019 Docker, Inc
  description: "# docker image inspect\n\n  \n\nDisplay detailed information on one or more images\n\n## Usage\n\n``` \n$ docker image inspect [OPTIONS] IMAGE [IMAGE...]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](index)                  | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_inspect/](https://docs.docker.com/engine/reference/commandline/image_inspect/)"
- name: docker image load
  id: engine/reference/commandline/image_load/index
  summary: © 2019 Docker, Inc
  description: "# docker image load\n\n  \n\nLoad an image from a tar archive or STDIN\n\n## Usage\n\n``` \n$ docker image load [OPTIONS]\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                                  |\n|------------------|---------|----------------------------------------------|\n| `--input` , `-i` |         | Read from tar archive file, instead of STDIN |\n| `--quiet` , `-q` |         | Suppress the load output                     |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](index)                     | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_load/](https://docs.docker.com/engine/reference/commandline/image_load/)"
- name: docker image ls
  id: engine/reference/commandline/image_ls/index
  summary: © 2019 Docker, Inc
  description: "# docker image ls\n\n  \n\nList images\n\n## Usage\n\n``` \n$ docker image ls [OPTIONS] [REPOSITORY[:TAG]]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                                         |\n|-------------------|---------|-----------------------------------------------------|\n| `--all` , `-a`    |         | Show all images (default hides intermediate images) |\n| `--digests`       |         | Show digests                                        |\n| `--filter` , `-f` |         | Filter output based on conditions provided          |\n| `--format`        |         | Pretty-print images using a Go template             |\n| `--no-trunc`      |         | Don't truncate output                               |\n| `--quiet` , `-q`  |         | Only show image IDs                                 |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](index)                       | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_ls/](https://docs.docker.com/engine/reference/commandline/image_ls/)"
- name: docker image prune
  id: engine/reference/commandline/image_prune/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker image prune\n\n  \n\nRemove unused images\n\n## Usage\n\n``` \n$ docker image prune [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemove all dangling images. If `-a` is specified, will also remove all images not referenced by any container.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                        |\n|------------------|---------|----------------------------------------------------|\n| `--all` , `-a`   |         | Remove all unused images, not just dangling ones   |\n| `--filter`       |         | Provide filter values (e.g. 'until=\\<timestamp\\>') |\n| `--force` , `-f` |         | Do not prompt for confirmation                     |\n\n## Examples\n\nExample output:\n\n``` \n$ docker image prune -a\n\nWARNING! This will remove all images without at least one container associated to them.\nAre you sure you want to continue? [y/N] y\nDeleted Images:\nuntagged: alpine:latest\nuntagged: alpine@sha256:3dcdb92d7432d56604d4545cbd324b14e647b313626d99b889d0626de158f73a\ndeleted: sha256:4e38e38c8ce0b8d9041a9c4fefe786631d1416225e13b0bfe8cfa2321aec4bba\ndeleted: sha256:4fe15f8d0ae69e169824f25f1d4da3015a48feeeeebb265cd2e328e15c6a869f\nuntagged: alpine:3.3\nuntagged: alpine@sha256:4fa633f4feff6a8f02acfc7424efd5cb3e76686ed3218abf4ca0fa4a2a358423\nuntagged: my-jq:latest\ndeleted: sha256:ae67841be6d008a374eff7c2a974cde3934ffe9536a7dc7ce589585eddd83aff\ndeleted: sha256:34f6f1261650bc341eb122313372adc4512b4fceddc2a7ecbb84f0958ce5ad65\ndeleted: sha256:cf4194e8d8db1cb2d117df33f2c75c0369c3a26d96725efb978cc69e046b87e7\nuntagged: my-curl:latest\ndeleted: sha256:b2789dd875bf427de7f9f6ae001940073b3201409b14aba7e5db71f408b8569e\ndeleted: sha256:96daac0cb203226438989926fc34dd024f365a9a8616b93e168d303cfe4cb5e9\ndeleted: sha256:5cbd97a14241c9cd83250d6b6fc0649833c4a3e84099b968dd4ba403e609945e\ndeleted: sha256:a0971c4015c1e898c60bf95781c6730a05b5d8a2ae6827f53837e6c9d38efdec\ndeleted: sha256:d8359ca3b681cc5396a4e790088441673ed3ce90ebc04de388bfcd31a0716b06\ndeleted: sha256:83fc9ba8fb70e1da31dfcc3c88d093831dbd4be38b34af998df37e8ac538260c\ndeleted: sha256:ae7041a4cc625a9c8e6955452f7afe602b401f662671cea3613f08f3d9343b35\ndeleted: sha256:35e0f43a37755b832f0bbea91a2360b025ee351d7309dae0d9737bc96b6d0809\ndeleted: sha256:0af941dd29f00e4510195dd00b19671bc591e29d1495630e7e0f7c44c1e6a8c0\ndeleted: sha256:9fc896fc2013da84f84e45b3096053eb084417b42e6b35ea0cce5a3529705eac\ndeleted: sha256:47cf20d8c26c46fff71be614d9f54997edacfe8d46d51769706e5aba94b16f2b\ndeleted: sha256:2c675ee9ed53425e31a13e3390bf3f539bf8637000e4bcfbb85ee03ef4d910a1\n\nTotal reclaimed space: 16.43 MB\n```\n\n### Filtering\n\nThe filtering flag (`--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- until (`<timestamp>`) - only remove images created before given timestamp\n- label (`label=<key>`, `label=<key>=<value>`, `label!=<key>`, or `label!=<key>=<value>`) - only remove images with (or without, in case `label!=...` is used) the specified labels.\n\nThe `until` filter can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the daemon machine’s time. Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the daemon will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long.\n\nThe `label` filter accepts two formats. One is the `label=...` (`label=<key>` or `label=<key>=<value>`), which removes images with the specified labels. The other format is the `label!=...` (`label!=<key>` or `label!=<key>=<value>`), which removes images without the specified labels.\n\n> **Predicting what will be removed**\n>\n> If you are using positive filtering (testing for the existence of a label or that a label has a specific value), you can use `docker image ls` with the same filtering syntax to see which images match your filter.\n>\n> However, if you are using negative filtering (testing for the absence of a label or that a label does *not* have a specific value), this type of filter does not work with `docker image ls` so you cannot easily predict which images will be removed. In addition, the confirmation prompt for `docker image prune` always warns that *all* dangling images will be removed, even if you are using `--filter`.\n\nThe following removes images created before `2017-01-04T00:00:00`:\n\n``` \n$ docker images --format 'table {{.Repository}}\\t{{.Tag}}\\t{{.ID}}\\t{{.CreatedAt}}\\t{{.Size}}'\nREPOSITORY          TAG                 IMAGE ID            CREATED AT                      SIZE\nfoo                 latest              2f287ac753da        2017-01-04 13:42:23 -0800 PST   3.98 MB\nalpine              latest              88e169ea8f46        2016-12-27 10:17:25 -0800 PST   3.98 MB\nbusybox             latest              e02e811dd08f        2016-10-07 14:03:58 -0700 PDT   1.09 MB\n\n$ docker image prune -a --force --filter \"until=2017-01-04T00:00:00\"\n\nDeleted Images:\nuntagged: alpine:latest\nuntagged: alpine@sha256:dfbd4a3a8ebca874ebd2474f044a0b33600d4523d03b0df76e5c5986cb02d7e8\nuntagged: busybox:latest\nuntagged: busybox@sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912\ndeleted: sha256:e02e811dd08fd49e7f6032625495118e63f597eb150403d02e3238af1df240ba\ndeleted: sha256:e88b3f82283bc59d5e0df427c824e9f95557e661fcb0ea15fb0fb6f97760f9d9\n\nTotal reclaimed space: 1.093 MB\n\n$ docker images --format 'table {{.Repository}}\\t{{.Tag}}\\t{{.ID}}\\t{{.CreatedAt}}\\t{{.Size}}'\n\nREPOSITORY          TAG                 IMAGE ID            CREATED AT                      SIZE\nfoo                 latest              2f287ac753da        2017-01-04 13:42:23 -0800 PST   3.98 MB\n```\n\nThe following removes images created more than 10 days (`240h`) ago:\n\n``` \n$ docker images\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nfoo                 latest              2f287ac753da        14 seconds ago      3.98 MB\nalpine              latest              88e169ea8f46        8 days ago          3.98 MB\ndebian              jessie              7b0a06c805e8        2 months ago        123 MB\nbusybox             latest              e02e811dd08f        2 months ago        1.09 MB\ngolang              1.7.0               138c2e655421        4 months ago        670 MB\n\n$ docker image prune -a --force --filter \"until=240h\"\n\nDeleted Images:\nuntagged: golang:1.7.0\nuntagged: golang@sha256:6765038c2b8f407fd6e3ecea043b44580c229ccfa2a13f6d85866cf2b4a9628e\ndeleted: sha256:138c2e6554219de65614d88c15521bfb2da674cbb0bf840de161f89ff4264b96\ndeleted: sha256:ec353c2e1a673f456c4b78906d0d77f9d9456cfb5229b78c6a960bfb7496b76a\ndeleted: sha256:fe22765feaf3907526b4921c73ea6643ff9e334497c9b7e177972cf22f68ee93\ndeleted: sha256:ff845959c80148421a5c3ae11cc0e6c115f950c89bc949646be55ed18d6a2912\ndeleted: sha256:a4320831346648c03db64149eafc83092e2b34ab50ca6e8c13112388f25899a7\ndeleted: sha256:4c76020202ee1d9709e703b7c6de367b325139e74eebd6b55b30a63c196abaf3\ndeleted: sha256:d7afd92fb07236c8a2045715a86b7d5f0066cef025018cd3ca9a45498c51d1d6\ndeleted: sha256:9e63c5bce4585dd7038d830a1f1f4e44cb1a1515b00e620ac718e934b484c938\nuntagged: debian:jessie\nuntagged: debian@sha256:c1af755d300d0c65bb1194d24bce561d70c98a54fb5ce5b1693beb4f7988272f\ndeleted: sha256:7b0a06c805e8f23807fb8856621c60851727e85c7bcb751012c813f122734c8d\ndeleted: sha256:f96222d75c5563900bc4dd852179b720a0885de8f7a0619ba0ac76e92542bbc8\n\nTotal reclaimed space: 792.6 MB\n\n$ docker images\n\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nfoo                 latest              2f287ac753da        About a minute ago   3.98 MB\nalpine              latest              88e169ea8f46        8 days ago           3.98 MB\nbusybox             latest              e02e811dd08f        2 months ago         1.09 MB\n```\n\nThe following example removes images with the label `deprecated`:\n\n``` \n$ docker image prune --filter=\"label=deprecated\"\n```\n\nThe following example removes images with the label `maintainer` set to `john`:\n\n``` \n$ docker image prune --filter=\"label=maintainer=john\"\n```\n\nThis example removes images which have no `maintainer` label:\n\n``` \n$ docker image prune --filter=\"label!=maintainer\"\n```\n\nThis example removes images which have a maintainer label not set to `john`:\n\n``` \n$ docker image prune --filter=\"label!=maintainer=john\"\n```\n\n> **Note**\n>\n> You are prompted for confirmation before the `prune` removes anything, but you are not shown a list of what will potentially be removed. In addition, `docker image ls` does not support negative filtering, so it difficult to predict what images will actually be removed.\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](index)                    | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_prune/](https://docs.docker.com/engine/reference/commandline/image_prune/)"
- name: docker image pull
  id: engine/reference/commandline/image_pull/index
  summary: © 2019 Docker, Inc
  description: "# docker image pull\n\n  \n\nPull an image or a repository from a registry\n\n## Usage\n\n``` \n$ docker image pull [OPTIONS] NAME[:TAG|@DIGEST]\n```\n\n## Options\n\n| Name, shorthand           | Default | Description                                      |\n|---------------------------|---------|--------------------------------------------------|\n| `--all-tags` , `-a`       |         | Download all tagged images in the repository     |\n| `--disable-content-trust` | `true`  | Skip image verification                          |\n| `--platform`              |         | Set platform if server is multi-platform capable |\n| `--quiet` , `-q`          |         | Suppress verbose output                          |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](index)                     | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_pull/](https://docs.docker.com/engine/reference/commandline/image_pull/)"
- name: docker image push
  id: engine/reference/commandline/image_push/index
  summary: © 2019 Docker, Inc
  description: "# docker image push\n\n  \n\nPush an image or a repository to a registry\n\n## Usage\n\n``` \n$ docker image push [OPTIONS] NAME[:TAG]\n```\n\n## Options\n\n| Name, shorthand           | Default | Description                              |\n|---------------------------|---------|------------------------------------------|\n| `--all-tags` , `-a`       |         | Push all tagged images in the repository |\n| `--disable-content-trust` | `true`  | Skip image signing                       |\n| `--quiet` , `-q`          |         | Suppress verbose output                  |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](index)                     | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_push/](https://docs.docker.com/engine/reference/commandline/image_push/)"
- name: docker image rm
  id: engine/reference/commandline/image_rm/index
  summary: © 2019 Docker, Inc
  description: "# docker image rm\n\n  \n\nRemove one or more images\n\n## Usage\n\n``` \n$ docker image rm [OPTIONS] IMAGE [IMAGE...]\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                    |\n|------------------|---------|--------------------------------|\n| `--force` , `-f` |         | Force removal of the image     |\n| `--no-prune`     |         | Do not delete untagged parents |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](index)                       | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_rm/](https://docs.docker.com/engine/reference/commandline/image_rm/)"
- name: docker image save
  id: engine/reference/commandline/image_save/index
  summary: © 2019 Docker, Inc
  description: "# docker image save\n\n  \n\nSave one or more images to a tar archive (streamed to STDOUT by default)\n\n## Usage\n\n``` \n$ docker image save [OPTIONS] IMAGE [IMAGE...]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                        |\n|-------------------|---------|------------------------------------|\n| `--output` , `-o` |         | Write to a file, instead of STDOUT |\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](index)                     | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](../image_tag/index)         | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_save/](https://docs.docker.com/engine/reference/commandline/image_save/)"
- name: docker image tag
  id: engine/reference/commandline/image_tag/index
  summary: © 2019 Docker, Inc
  description: "# docker image tag\n\n  \n\nCreate a tag TARGET_IMAGE that refers to SOURCE_IMAGE\n\n## Usage\n\n``` \n$ docker image tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]\n```\n\n## Parent command\n\n| Command                        | Description   |\n|:-------------------------------|:--------------|\n| [docker image](../image/index) | Manage images |\n\n## Related commands\n\n| Command                                        | Description                                                              |\n|------------------------------------------------|--------------------------------------------------------------------------|\n| [docker image build](../image_build/index)     | Build an image from a Dockerfile                                         |\n| [docker image history](../image_history/index) | Show the history of an image                                             |\n| [docker image import](../image_import/index)   | Import the contents from a tarball to create a filesystem image          |\n| [docker image inspect](../image_inspect/index) | Display detailed information on one or more images                       |\n| [docker image load](../image_load/index)       | Load an image from a tar archive or STDIN                                |\n| [docker image ls](../image_ls/index)           | List images                                                              |\n| [docker image prune](../image_prune/index)     | Remove unused images                                                     |\n| [docker image pull](../image_pull/index)       | Pull an image or a repository from a registry                            |\n| [docker image push](../image_push/index)       | Push an image or a repository to a registry                              |\n| [docker image rm](../image_rm/index)           | Remove one or more images                                                |\n| [docker image save](../image_save/index)       | Save one or more images to a tar archive (streamed to STDOUT by default) |\n| [docker image tag](index)                      | Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE                    |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/image_tag/](https://docs.docker.com/engine/reference/commandline/image_tag/)"
- name: docker images
  id: engine/reference/commandline/images/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker images\n\n  \n\nList images\n\n## Usage\n\n``` \n$ docker images [OPTIONS] [REPOSITORY[:TAG]]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe default `docker images` will show all top level images, their repository and tags, and their size.\n\nDocker images have intermediate layers that increase reusability, decrease disk usage, and speed up `docker build` by allowing each step to be cached. These intermediate layers are not shown by default.\n\nThe `SIZE` is the cumulative space taken up by the image and all its parent images. This is also the disk space used by the contents of the Tar file created when you `docker save` an image.\n\nAn image will be listed more than once if it has multiple repository names or tags. This single image (identifiable by its matching `IMAGE ID`) uses up the `SIZE` listed only once.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                         |\n|-------------------|---------|-----------------------------------------------------|\n| `--all` , `-a`    |         | Show all images (default hides intermediate images) |\n| `--digests`       |         | Show digests                                        |\n| `--filter` , `-f` |         | Filter output based on conditions provided          |\n| `--format`        |         | Pretty-print images using a Go template             |\n| `--no-trunc`      |         | Don't truncate output                               |\n| `--quiet` , `-q`  |         | Only show image IDs                                 |\n\n## Examples\n\n### List the most recently created images\n\n``` \n$ docker images\n\nREPOSITORY                TAG                 IMAGE ID            CREATED             SIZE\n<none>                    <none>              77af4d6b9913        19 hours ago        1.089 GB\ncommitt                   latest              b6fa739cedf5        19 hours ago        1.089 GB\n<none>                    <none>              78a85c484f71        19 hours ago        1.089 GB\ndocker                    latest              30557a29d5ab        20 hours ago        1.089 GB\n<none>                    <none>              5ed6274db6ce        24 hours ago        1.089 GB\npostgres                  9                   746b819f315e        4 days ago          213.4 MB\npostgres                  9.3                 746b819f315e        4 days ago          213.4 MB\npostgres                  9.3.5               746b819f315e        4 days ago          213.4 MB\npostgres                  latest              746b819f315e        4 days ago          213.4 MB\n```\n\n### List images by name and tag\n\nThe `docker images` command takes an optional `[REPOSITORY[:TAG]]` argument that restricts the list to images that match the argument. If you specify `REPOSITORY`but no `TAG`, the `docker images` command lists all images in the given repository.\n\nFor example, to list all images in the “java” repository, run this command :\n\n``` \n$ docker images java\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\njava                8                   308e519aac60        6 days ago          824.5 MB\njava                7                   493d82594c15        3 months ago        656.3 MB\njava                latest              2711b1d6f3aa        5 months ago        603.9 MB\n```\n\nThe `[REPOSITORY[:TAG]]` value must be an “exact match”. This means that, for example, `docker images jav` does not match the image `java`.\n\nIf both `REPOSITORY` and `TAG` are provided, only images matching that repository and tag are listed. To find all local images in the “java” repository with tag “8” you can use:\n\n``` \n$ docker images java:8\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\njava                8                   308e519aac60        6 days ago          824.5 MB\n```\n\nIf nothing matches `REPOSITORY[:TAG]`, the list is empty.\n\n``` \n$ docker images java:0\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n```\n\n### List the full length image IDs\n\n``` \n$ docker images --no-trunc\n\nREPOSITORY                    TAG                 IMAGE ID                                                                  CREATED             SIZE\n<none>                        <none>              sha256:77af4d6b9913e693e8d0b4b294fa62ade6054e6b2f1ffb617ac955dd63fb0182   19 hours ago        1.089 GB\ncommittest                    latest              sha256:b6fa739cedf5ea12a620a439402b6004d057da800f91c7524b5086a5e4749c9f   19 hours ago        1.089 GB\n<none>                        <none>              sha256:78a85c484f71509adeaace20e72e941f6bdd2b25b4c75da8693efd9f61a37921   19 hours ago        1.089 GB\ndocker                        latest              sha256:30557a29d5abc51e5f1d5b472e79b7e296f595abcf19fe6b9199dbbc809c6ff4   20 hours ago        1.089 GB\n<none>                        <none>              sha256:0124422dd9f9cf7ef15c0617cda3931ee68346455441d66ab8bdc5b05e9fdce5   20 hours ago        1.089 GB\n<none>                        <none>              sha256:18ad6fad340262ac2a636efd98a6d1f0ea775ae3d45240d3418466495a19a81b   22 hours ago        1.082 GB\n<none>                        <none>              sha256:f9f1e26352f0a3ba6a0ff68167559f64f3e21ff7ada60366e2d44a04befd1d3a   23 hours ago        1.089 GB\ntryout                        latest              sha256:2629d1fa0b81b222fca63371ca16cbf6a0772d07759ff80e8d1369b926940074   23 hours ago        131.5 MB\n<none>                        <none>              sha256:5ed6274db6ceb2397844896966ea239290555e74ef307030ebb01ff91b1914df   24 hours ago        1.089 GB\n```\n\n### List image digests\n\nImages that use the v2 or later format have a content-addressable identifier called a `digest`. As long as the input used to generate the image is unchanged, the digest value is predictable. To list image digest values, use the `--digests` flag:\n\n``` \n$ docker images --digests\nREPOSITORY                         TAG                 DIGEST                                                                    IMAGE ID            CREATED             SIZE\nlocalhost:5000/test/busybox        <none>              sha256:cbbf2f9a99b47fc460d422812b6a5adff7dfee951d8fa2e4a98caa0382cfbdbf   4986bf8c1536        9 weeks ago         2.43 MB\n```\n\nWhen pushing or pulling to a 2.0 registry, the `push` or `pull` command output includes the image digest. You can `pull` using a digest value. You can also reference by digest in `create`, `run`, and `rmi` commands, as well as the `FROM` image reference in a Dockerfile.\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- dangling (boolean - true or false)\n- label (`label=<key>` or `label=<key>=<value>`)\n- before (`<image-name>[:<tag>]`, `<image id>` or `<image@digest>`) - filter images created before given id or references\n- since (`<image-name>[:<tag>]`, `<image id>` or `<image@digest>`) - filter images created since given id or references\n- reference (pattern of an image reference) - filter images whose reference matches the specified pattern\n\n#### Show untagged images (dangling)\n\n``` \n$ docker images --filter \"dangling=true\"\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n<none>              <none>              8abc22fbb042        4 weeks ago         0 B\n<none>              <none>              48e5f45168b9        4 weeks ago         2.489 MB\n<none>              <none>              bf747efa0e2f        4 weeks ago         0 B\n<none>              <none>              980fe10e5736        12 weeks ago        101.4 MB\n<none>              <none>              dea752e4e117        12 weeks ago        101.4 MB\n<none>              <none>              511136ea3c5a        8 months ago        0 B\n```\n\nThis will display untagged images that are the leaves of the images tree (not intermediary layers). These images occur when a new build of an image takes the `repo:tag` away from the image ID, leaving it as `<none>:<none>` or untagged. A warning will be issued if trying to remove an image when a container is presently using it. By having this flag it allows for batch cleanup.\n\nYou can use this in conjunction with `docker rmi ...`:\n\n``` \n$ docker rmi $(docker images -f \"dangling=true\" -q)\n\n8abc22fbb042\n48e5f45168b9\nbf747efa0e2f\n980fe10e5736\ndea752e4e117\n511136ea3c5a\n```\n\nDocker warns you if any containers exist that are using these untagged images.\n\n#### Show images with a given label\n\nThe `label` filter matches images based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches images with the `com.example.version` label regardless of its value.\n\n``` \n$ docker images --filter \"label=com.example.version\"\n\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nmatch-me-1          latest              eeae25ada2aa        About a minute ago   188.3 MB\nmatch-me-2          latest              dea752e4e117        About a minute ago   188.3 MB\n```\n\nThe following filter matches images with the `com.example.version` label with the `1.0` value.\n\n``` \n$ docker images --filter \"label=com.example.version=1.0\"\n\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nmatch-me            latest              511136ea3c5a        About a minute ago   188.3 MB\n```\n\nIn this example, with the `0.1` value, it returns an empty set because no matches were found.\n\n``` \n$ docker images --filter \"label=com.example.version=0.1\"\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\n```\n\n#### Filter images by time\n\nThe `before` filter shows only images created before the image with given id or reference. For example, having these images:\n\n``` \n$ docker images\n\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nimage1              latest              eeae25ada2aa        4 minutes ago        188.3 MB\nimage2              latest              dea752e4e117        9 minutes ago        188.3 MB\nimage3              latest              511136ea3c5a        25 minutes ago       188.3 MB\n```\n\nFiltering with `before` would give:\n\n``` \n$ docker images --filter \"before=image1\"\n\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nimage2              latest              dea752e4e117        9 minutes ago        188.3 MB\nimage3              latest              511136ea3c5a        25 minutes ago       188.3 MB\n```\n\nFiltering with `since` would give:\n\n``` \n$ docker images --filter \"since=image3\"\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nimage1              latest              eeae25ada2aa        4 minutes ago        188.3 MB\nimage2              latest              dea752e4e117        9 minutes ago        188.3 MB\n```\n\n#### Filter images by reference\n\nThe `reference` filter shows only images whose reference matches the specified pattern.\n\n``` \n$ docker images\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nbusybox             latest              e02e811dd08f        5 weeks ago         1.09 MB\nbusybox             uclibc              e02e811dd08f        5 weeks ago         1.09 MB\nbusybox             musl                733eb3059dce        5 weeks ago         1.21 MB\nbusybox             glibc               21c16b6787c6        5 weeks ago         4.19 MB\n```\n\nFiltering with `reference` would give:\n\n``` \n$ docker images --filter=reference='busy*:*libc'\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nbusybox             uclibc              e02e811dd08f        5 weeks ago         1.09 MB\nbusybox             glibc               21c16b6787c6        5 weeks ago         4.19 MB\n```\n\nFiltering with multiple `reference` would give, either match A or B:\n\n``` \n$ docker images --filter=reference='busy*:uclibc' --filter=reference='busy*:glibc'\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nbusybox             uclibc              e02e811dd08f        5 weeks ago         1.09 MB\nbusybox             glibc               21c16b6787c6        5 weeks ago         4.19 MB\n```\n\n### Format the output\n\nThe formatting option (`--format`) will pretty print container output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder     | Description                              |\n|-----------------|------------------------------------------|\n| `.ID`           | Image ID                                 |\n| `.Repository`   | Image repository                         |\n| `.Tag`          | Image tag                                |\n| `.Digest`       | Image digest                             |\n| `.CreatedSince` | Elapsed time since the image was created |\n| `.CreatedAt`    | Time when the image was created          |\n| `.Size`         | Image disk size                          |\n\nWhen using the `--format` option, the `image` command will either output the data exactly as the template declares or, when using the `table` directive, will include column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `Repository` entries separated by a colon (`:`) for all images:\n\n``` \n$ docker images --format \"{{.ID}}: {{.Repository}}\"\n\n77af4d6b9913: <none>\nb6fa739cedf5: committ\n78a85c484f71: <none>\n30557a29d5ab: docker\n5ed6274db6ce: <none>\n746b819f315e: postgres\n746b819f315e: postgres\n746b819f315e: postgres\n746b819f315e: postgres\n```\n\nTo list all images with their repository and tag in a table format you can use:\n\n``` \n$ docker images --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\"\n\nIMAGE ID            REPOSITORY                TAG\n77af4d6b9913        <none>                    <none>\nb6fa739cedf5        committ                   latest\n78a85c484f71        <none>                    <none>\n30557a29d5ab        docker                    latest\n5ed6274db6ce        <none>                    <none>\n746b819f315e        postgres                  9\n746b819f315e        postgres                  9.3\n746b819f315e        postgres                  9.3.5\n746b819f315e        postgres                  latest\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/images/](https://docs.docker.com/engine/reference/commandline/images/)"
- name: docker import
  id: engine/reference/commandline/import/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker import\n\n  \n\nImport the contents from a tarball to create a filesystem image\n\n## Usage\n\n``` \n$ docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nYou can specify a `URL` or `-` (dash) to take data directly from `STDIN`. The `URL` can point to an archive (.tar, .tar.gz, .tgz, .bzip, .tar.xz, or .txz) containing a filesystem or to an individual file on the Docker host. If you specify an archive, Docker untars it in the container relative to the `/` (root). If you specify an individual file, you must specify the full path within the host. To import from a remote location, specify a `URI` that begins with the `http://` or `https://` protocol.\n\nThe `--change` option applies `Dockerfile` instructions to the image that is created. Supported `Dockerfile` instructions: `CMD`\\|`ENTRYPOINT`\\|`ENV`\\|`EXPOSE`\\|`ONBUILD`\\|`USER`\\|`VOLUME`\\|`WORKDIR`\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand    | Default | Description                                       |\n|--------------------|---------|---------------------------------------------------|\n| `--change` , `-c`  |         | Apply Dockerfile instruction to the created image |\n| `--message` , `-m` |         | Set commit message for imported image             |\n| `--platform`       |         | Set platform if server is multi-platform capable  |\n\n## Examples\n\n### Import from a remote location\n\nThis creates a new untagged image.\n\n``` \n$ docker import https://example.com/exampleimage.tgz\n```\n\n### Import from a local file\n\nImport to docker via pipe and `STDIN`.\n\n``` \n$ cat exampleimage.tgz | docker import - exampleimagelocal:new\n```\n\nImport with a commit message.\n\n``` \n$ cat exampleimage.tgz | docker import --message \"New image imported from tarball\" - exampleimagelocal:new\n```\n\nImport to docker from a local archive.\n\n``` \n$ docker import /path/to/exampleimage.tgz\n```\n\n### Import from a local directory\n\n``` \n$ sudo tar -c . | docker import - exampleimagedir\n```\n\n### Import from a local directory with new configurations\n\n``` \n$ sudo tar -c . | docker import --change \"ENV DEBUG=true\" - exampleimagedir\n```\n\nNote the `sudo` in this example – you must preserve the ownership of the files (especially root ownership) during the archiving with tar. If you are not root (or the sudo command) when you tar, then the ownerships might not get preserved.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/import/](https://docs.docker.com/engine/reference/commandline/import/)"
- name: docker info
  id: engine/reference/commandline/info/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker info\n\n  \n\nDisplay system-wide information\n\n## Usage\n\n``` \n$ docker info [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThis command displays system wide information regarding the Docker installation. Information displayed includes the kernel version, number of containers and images. The number of images shown is the number of unique images. The same image tagged under different names is counted only once.\n\nIf a format is specified, the given template will be executed instead of the default format. Go’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nDepending on the storage driver in use, additional information can be shown, such as pool name, data file, metadata file, data space used, total data space, metadata space used, and total metadata space.\n\nThe data file is where the images are stored and the metadata file is where the meta data regarding those images are stored. When run for the first time Docker allocates a certain amount of data space and meta data space from the space available on the volume where `/var/lib/docker` is mounted.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n\n## Examples\n\n### Show output\n\nThe example below shows the output for a daemon running on Red Hat Enterprise Linux, using the `devicemapper` storage driver. As can be seen in the output, additional information about the `devicemapper` storage driver is shown:\n\n``` \n$ docker info\n\nClient:\n Context:    default\n Debug Mode: false\n\nServer:\n Containers: 14\n  Running: 3\n  Paused: 1\n  Stopped: 10\n Images: 52\n Server Version: 1.10.3\n Storage Driver: devicemapper\n  Pool Name: docker-202:2-25583803-pool\n  Pool Blocksize: 65.54 kB\n  Base Device Size: 10.74 GB\n  Backing Filesystem: xfs\n  Data file: /dev/loop0\n  Metadata file: /dev/loop1\n  Data Space Used: 1.68 GB\n  Data Space Total: 107.4 GB\n  Data Space Available: 7.548 GB\n  Metadata Space Used: 2.322 MB\n  Metadata Space Total: 2.147 GB\n  Metadata Space Available: 2.145 GB\n  Udev Sync Supported: true\n  Deferred Removal Enabled: false\n  Deferred Deletion Enabled: false\n  Deferred Deleted Device Count: 0\n  Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n  Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n  Library Version: 1.02.107-RHEL7 (2015-12-01)\n Execution Driver: native-0.2\n Logging Driver: json-file\n Plugins:\n  Volume: local\n  Network: null host bridge\n Kernel Version: 3.10.0-327.el7.x86_64\n Operating System: Red Hat Enterprise Linux Server 7.2 (Maipo)\n OSType: linux\n Architecture: x86_64\n CPUs: 1\n Total Memory: 991.7 MiB\n Name: ip-172-30-0-91.ec2.internal\n ID: I54V:OLXT:HVMM:TPKO:JPHQ:CQCD:JNLC:O3BZ:4ZVJ:43XJ:PFHZ:6N2S\n Docker Root Dir: /var/lib/docker\n Debug Mode: false\n Username: gordontheturtle\n Registry: https://index.docker.io/v1/\n Insecure registries:\n  myinsecurehost:5000\n  127.0.0.0/8\n```\n\n### Show debugging output\n\nHere is a sample output for a daemon running on Ubuntu, using the overlay2 storage driver and a node that is part of a 2-node swarm:\n\n``` \n$ docker --debug info\n\nClient:\n Context:    default\n Debug Mode: true\n\nServer:\n Containers: 14\n  Running: 3\n  Paused: 1\n  Stopped: 10\n Images: 52\n Server Version: 1.13.0\n Storage Driver: overlay2\n  Backing Filesystem: extfs\n  Supports d_type: true\n  Native Overlay Diff: false\n Logging Driver: json-file\n Cgroup Driver: cgroupfs\n Plugins:\n  Volume: local\n  Network: bridge host macvlan null overlay\n Swarm: active\n  NodeID: rdjq45w1op418waxlairloqbm\n  Is Manager: true\n  ClusterID: te8kdyw33n36fqiz74bfjeixd\n  Managers: 1\n  Nodes: 2\n  Orchestration:\n   Task History Retention Limit: 5\n  Raft:\n   Snapshot Interval: 10000\n   Number of Old Snapshots to Retain: 0\n   Heartbeat Tick: 1\n   Election Tick: 3\n  Dispatcher:\n   Heartbeat Period: 5 seconds\n  CA Configuration:\n   Expiry Duration: 3 months\n  Root Rotation In Progress: false\n  Node Address: 172.16.66.128 172.16.66.129\n  Manager Addresses:\n   172.16.66.128:2477\n Runtimes: runc\n Default Runtime: runc\n Init Binary: docker-init\n containerd version: 8517738ba4b82aff5662c97ca4627e7e4d03b531\n runc version: ac031b5bf1cc92239461125f4c1ffb760522bbf2\n init version: N/A (expected: v0.13.0)\n Security Options:\n  apparmor\n  seccomp\n   Profile: default\n Kernel Version: 4.4.0-31-generic\n Operating System: Ubuntu 16.04.1 LTS\n OSType: linux\n Architecture: x86_64\n CPUs: 2\n Total Memory: 1.937 GiB\n Name: ubuntu\n ID: H52R:7ZR6:EIIA:76JG:ORIY:BVKF:GSFU:HNPG:B5MK:APSC:SZ3Q:N326\n Docker Root Dir: /var/lib/docker\n Debug Mode: true\n  File Descriptors: 30\n  Goroutines: 123\n  System Time: 2016-11-12T17:24:37.955404361-08:00\n  EventsListeners: 0\n Http Proxy: http://test:test@proxy.example.com:8080\n Https Proxy: https://test:test@proxy.example.com:8080\n No Proxy: localhost,127.0.0.1,docker-registry.somecorporation.com\n Registry: https://index.docker.io/v1/\n WARNING: No swap limit support\n Labels:\n  storage=ssd\n  staging=true\n Experimental: false\n Insecure Registries:\n  127.0.0.0/8\n Registry Mirrors:\n   http://192.168.1.2/\n   http://registry-mirror.example.com:5000/\n Live Restore Enabled: false\n```\n\nThe global `-D` option causes all `docker` commands to output debug information.\n\n### Format the output\n\nYou can also specify the output format:\n\n``` \n$ docker info --format '{{json .}}'\n\n{\"ID\":\"I54V:OLXT:HVMM:TPKO:JPHQ:CQCD:JNLC:O3BZ:4ZVJ:43XJ:PFHZ:6N2S\",\"Containers\":14, ...}\n```\n\n### Run `docker info` on Windows\n\nHere is a sample output for a daemon running on Windows Server 2016:\n\n``` \nE:\\docker>docker info\nClient:\n Context:    default\n Debug Mode: false\n\nServer:\n Containers: 1\n  Running: 0\n  Paused: 0\n  Stopped: 1\n Images: 17\n Server Version: 1.13.0\n Storage Driver: windowsfilter\n  Windows:\n Logging Driver: json-file\n Plugins:\n  Volume: local\n  Network: nat null overlay\n Swarm: inactive\n Default Isolation: process\n Kernel Version: 10.0 14393 (14393.206.amd64fre.rs1_release.160912-1937)\n Operating System: Windows Server 2016 Datacenter\n OSType: windows\n Architecture: x86_64\n CPUs: 8\n Total Memory: 3.999 GiB\n Name: WIN-V0V70C0LU5P\n ID: NYMS:B5VK:UMSL:FVDZ:EWB5:FKVK:LPFL:FJMQ:H6FT:BZJ6:L2TD:XH62\n Docker Root Dir: C:\\control\n Debug Mode: false\n Registry: https://index.docker.io/v1/\n Insecure Registries:\n  127.0.0.0/8\n Registry Mirrors:\n   http://192.168.1.2/\n   http://registry-mirror.example.com:5000/\n Live Restore Enabled: false\n```\n\n## Warnings about kernel support\n\nIf your operating system does not enable certain capabilities, you may see warnings such as one of the following, when you run `docker info`:\n\n``` \nWARNING: Your kernel does not support swap limit capabilities. Limitation discarded.\n```\n\n``` \nWARNING: No swap limit support\n```\n\nYou can ignore these warnings unless you actually need the ability to [limit these resources](https://docs.docker.com/config/containers/resource_constraints/), in which case you should consult your operating system’s documentation for enabling them. [Learn more](../../../install/linux-postinstall/index#your-kernel-does-not-support-cgroup-swap-limit-capabilities).\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/info/](https://docs.docker.com/engine/reference/commandline/info/)"
- name: docker inspect
  id: engine/reference/commandline/inspect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker inspect\n\n  \n\nReturn low-level information on Docker objects\n\n## Usage\n\n``` \n$ docker inspect [OPTIONS] NAME|ID [NAME|ID...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nDocker inspect provides detailed information on constructs controlled by Docker.\n\nBy default, `docker inspect` will render results in a JSON array.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                       |\n|-------------------|---------|---------------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template     |\n| `--size` , `-s`   |         | Display total file sizes if the type is container |\n| `--type`          |         | Return JSON for specified type                    |\n\n## Examples\n\n### Get an instance’s IP address\n\nFor the most part, you can pick out any field from the JSON in a fairly straightforward manner.\n\n``` \n$ docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $INSTANCE_ID\n```\n\n### Get an instance’s MAC address\n\n``` \n$ docker inspect --format='{{range .NetworkSettings.Networks}}{{.MacAddress}}{{end}}' $INSTANCE_ID\n```\n\n### Get an instance’s log path\n\n``` \n$ docker inspect --format='{{.LogPath}}' $INSTANCE_ID\n```\n\n### Get an instance’s image name\n\n``` \n$ docker inspect --format='{{.Config.Image}}' $INSTANCE_ID\n```\n\n### List all port bindings\n\nYou can loop over arrays and maps in the results to produce simple text output:\n\n``` \n$ docker inspect --format='{{range $p, $conf := .NetworkSettings.Ports}} {{$p}} -> {{(index $conf 0).HostPort}} {{end}}' $INSTANCE_ID\n```\n\n### Find a specific port mapping\n\nThe `.Field` syntax doesn’t work when the field name begins with a number, but the template language’s `index` function does. The `.NetworkSettings.Ports` section contains a map of the internal port mappings to a list of external address/port objects. To grab just the numeric public port, you use `index` to find the specific port map, and then `index` 0 contains the first object inside of that. Then we ask for the `HostPort` field to get the public address.\n\n``` \n$ docker inspect --format='{{(index (index .NetworkSettings.Ports \"8787/tcp\") 0).HostPort}}' $INSTANCE_ID\n```\n\n### Get a subsection in JSON format\n\nIf you request a field which is itself a structure containing other fields, by default you get a Go-style dump of the inner values. Docker adds a template function, `json`, which can be applied to get results in JSON format.\n\n``` \n$ docker inspect --format='{{json .Config}}' $INSTANCE_ID\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/inspect/](https://docs.docker.com/engine/reference/commandline/inspect/)"
- name: docker kill
  id: engine/reference/commandline/kill/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker kill\n\n  \n\nKill one or more running containers\n\n## Usage\n\n``` \n$ docker kill [OPTIONS] CONTAINER [CONTAINER...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker kill` subcommand kills one or more containers. The main process inside the container is sent `SIGKILL` signal (default), or the signal that is specified with the `--signal` option. You can reference a container by its ID, ID-prefix, or name.\n\nThe `--signal` (or `-s` shorthand) flag sets the system call signal that is sent to the container. This signal can be a signal name in the format `SIG<NAME>`, for instance `SIGINT`, or an unsigned number that matches a position in the kernel’s syscall table, for instance `2`.\n\nWhile the default (`SIGKILL`) signal will terminate the container, the signal set through `--signal` may be non-terminal, depending on the container’s main process. For example, the `SIGHUP` signal in most cases will be non-terminal, and the container will continue running after receiving the signal.\n\n> **Note**\n>\n> `ENTRYPOINT` and `CMD` in the *shell* form run as a child process of `/bin/sh -c`, which does not pass signals. This means that the executable is not the container’s PID 1 and does not receive Unix signals.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                     |\n|-------------------|---------|---------------------------------|\n| `--signal` , `-s` | `KILL`  | Signal to send to the container |\n\n## Examples\n\n### Send a KILL signal to a container\n\nThe following example sends the default `SIGKILL` signal to the container named `my_container`:\n\n``` \n$ docker kill my_container\n```\n\n### Send a custom signal to a container\n\nThe following example sends a `SIGHUP` signal to the container named `my_container`:\n\n``` \n$ docker kill --signal=SIGHUP  my_container\n```\n\nYou can specify a custom signal either by *name*, or *number*. The `SIG` prefix is optional, so the following examples are equivalent:\n\n``` \n$ docker kill --signal=SIGHUP my_container\n$ docker kill --signal=HUP my_container\n$ docker kill --signal=1 my_container\n```\n\nRefer to the [`signal(7)`](https://man7.org/linux/man-pages/man7/signal.7.html) man-page for a list of standard Linux signals.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/kill/](https://docs.docker.com/engine/reference/commandline/kill/)"
- name: docker load
  id: engine/reference/commandline/load/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker load\n\n  \n\nLoad an image from a tar archive or STDIN\n\n## Usage\n\n``` \n$ docker load [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLoad an image or repository from a tar archive (even if compressed with gzip, bzip2, or xz) from a file or STDIN. It restores both images and tags.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                  |\n|------------------|---------|----------------------------------------------|\n| `--input` , `-i` |         | Read from tar archive file, instead of STDIN |\n| `--quiet` , `-q` |         | Suppress the load output                     |\n\n## Examples\n\n``` \n$ docker image ls\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n\n$ docker load < busybox.tar.gz\n\nLoaded image: busybox:latest\n$ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nbusybox             latest              769b9341d937        7 weeks ago         2.489 MB\n\n$ docker load --input fedora.tar\n\nLoaded image: fedora:rawhide\n\nLoaded image: fedora:20\n\n$ docker images\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nbusybox             latest              769b9341d937        7 weeks ago         2.489 MB\nfedora              rawhide             0d20aec6529d        7 weeks ago         387 MB\nfedora              20                  58394af37342        7 weeks ago         385.5 MB\nfedora              heisenbug           58394af37342        7 weeks ago         385.5 MB\nfedora              latest              58394af37342        7 weeks ago         385.5 MB\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/load/](https://docs.docker.com/engine/reference/commandline/load/)"
- name: docker login
  id: engine/reference/commandline/login/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker login\n\n  \n\nLog in to a Docker registry\n\n## Usage\n\n``` \n$ docker login [OPTIONS] [SERVER]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLogin to a registry.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand     | Default | Description                  |\n|---------------------|---------|------------------------------|\n| `--password` , `-p` |         | Password                     |\n| `--password-stdin`  |         | Take the password from stdin |\n| `--username` , `-u` |         | Username                     |\n\n## Examples\n\n### Login to a self-hosted registry\n\nIf you want to login to a self-hosted registry you can specify this by adding the server name.\n\n``` \n$ docker login localhost:8080\n```\n\n### Provide a password using STDIN\n\nTo run the `docker login` command non-interactively, you can set the `--password-stdin` flag to provide a password through `STDIN`. Using `STDIN` prevents the password from ending up in the shell’s history, or log-files.\n\nThe following example reads a password from a file, and passes it to the `docker login` command using `STDIN`:\n\n``` \n$ cat ~/my_password.txt | docker login --username foo --password-stdin\n```\n\n### Privileged user requirement\n\n`docker login` requires user to use `sudo` or be `root`, except when:\n\n1.  connecting to a remote daemon, such as a `docker-machine` provisioned `docker engine`.\n2.  user is added to the `docker` group. This will impact the security of your system; the `docker` group is `root` equivalent. See [Docker Daemon Attack Surface](../../../security/index#docker-daemon-attack-surface) for details.\n\nYou can log into any public or private repository for which you have credentials. When you log in, the command stores credentials in `$HOME/.docker/config.json` on Linux or `%USERPROFILE%/.docker/config.json` on Windows, via the procedure described below.\n\n### Credentials store\n\nThe Docker Engine can keep user credentials in an external credentials store, such as the native keychain of the operating system. Using an external store is more secure than storing credentials in the Docker configuration file.\n\nTo use a credentials store, you need an external helper program to interact with a specific keychain or external store. Docker requires the helper program to be in the client’s host `$PATH`.\n\nThis is the list of currently available credentials helpers and where you can download them from:\n\n- D-Bus Secret Service: https://github.com/docker/docker-credential-helpers/releases\n- Apple macOS keychain: https://github.com/docker/docker-credential-helpers/releases\n- Microsoft Windows Credential Manager: https://github.com/docker/docker-credential-helpers/releases\n- [pass](https://www.passwordstore.org/): https://github.com/docker/docker-credential-helpers/releases\n\n#### Configure the credentials store\n\nYou need to specify the credentials store in `$HOME/.docker/config.json` to tell the docker engine to use it. The value of the config property should be the suffix of the program to use (i.e. everything after `docker-credential-`). For example, to use `docker-credential-osxkeychain`:\n\n``` \n{\n  \"credsStore\": \"osxkeychain\"\n}\n```\n\nIf you are currently logged in, run `docker logout` to remove the credentials from the file and run `docker login` again.\n\n#### Default behavior\n\nBy default, Docker looks for the native binary on each of the platforms, i.e. “osxkeychain” on macOS, “wincred” on windows, and “pass” on Linux. A special case is that on Linux, Docker will fall back to the “secretservice” binary if it cannot find the “pass” binary. If none of these binaries are present, it stores the credentials (i.e. password) in base64 encoding in the config files described above.\n\n#### Credential helper protocol\n\nCredential helpers can be any program or script that follows a very simple protocol. This protocol is heavily inspired by Git, but it differs in the information shared.\n\nThe helpers always use the first argument in the command to identify the action. There are only three possible values for that argument: `store`, `get`, and `erase`.\n\nThe `store` command takes a JSON payload from the standard input. That payload carries the server address, to identify the credential, the user name, and either a password or an identity token.\n\n``` \n{\n  \"ServerURL\": \"https://index.docker.io/v1\",\n  \"Username\": \"david\",\n  \"Secret\": \"passw0rd1\"\n}\n```\n\nIf the secret being stored is an identity token, the Username should be set to `<token>`.\n\nThe `store` command can write error messages to `STDOUT` that the docker engine will show if there was an issue.\n\nThe `get` command takes a string payload from the standard input. That payload carries the server address that the docker engine needs credentials for. This is an example of that payload: `https://index.docker.io/v1`.\n\nThe `get` command writes a JSON payload to `STDOUT`. Docker reads the user name and password from this payload:\n\n``` \n{\n  \"Username\": \"david\",\n  \"Secret\": \"passw0rd1\"\n}\n```\n\nThe `erase` command takes a string payload from `STDIN`. That payload carries the server address that the docker engine wants to remove credentials for. This is an example of that payload: `https://index.docker.io/v1`.\n\nThe `erase` command can write error messages to `STDOUT` that the docker engine will show if there was an issue.\n\n### Credential helpers\n\nCredential helpers are similar to the credential store above, but act as the designated programs to handle credentials for *specific registries*. The default credential store (`credsStore` or the config file itself) will not be used for operations concerning credentials of the specified registries.\n\n#### Configure credential helpers\n\nIf you are currently logged in, run `docker logout` to remove the credentials from the default store.\n\nCredential helpers are specified in a similar way to `credsStore`, but allow for multiple helpers to be configured at a time. Keys specify the registry domain, and values specify the suffix of the program to use (i.e. everything after `docker-credential-`). For example:\n\n``` \n{\n  \"credHelpers\": {\n    \"registry.example.com\": \"registryhelper\",\n    \"awesomereg.example.org\": \"hip-star\",\n    \"unicorn.example.io\": \"vcbait\"\n  }\n}\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/login/](https://docs.docker.com/engine/reference/commandline/login/)"
- name: docker logout
  id: engine/reference/commandline/logout/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker logout\n\n  \n\nLog out from a Docker registry\n\n## Usage\n\n``` \n$ docker logout [SERVER]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker logout localhost:8080\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/logout/](https://docs.docker.com/engine/reference/commandline/logout/)"
- name: docker logs
  id: engine/reference/commandline/logs/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker logs\n\n  \n\nFetch the logs of a container\n\n## Usage\n\n``` \n$ docker logs [OPTIONS] CONTAINER\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker logs` command batch-retrieves logs present at the time of execution.\n\n> **Note**\n>\n> This command is only functional for containers that are started with the `json-file` or `journald` logging driver.\n\nFor more information about selecting and configuring logging drivers, refer to [Configure logging drivers](https://docs.docker.com/config/containers/logging/configure/).\n\nThe `docker logs --follow` command will continue streaming the new output from the container’s `STDOUT` and `STDERR`.\n\nPassing a negative number or a non-integer to `--tail` is invalid and the value is set to `all` in that case.\n\nThe `docker logs --timestamps` command will add an [RFC3339Nano timestamp](https://golang.org/pkg/time/#pkg-constants) , for example `2014-09-16T06:17:46.000000000Z`, to each log entry. To ensure that the timestamps are aligned the nano-second part of the timestamp will be padded with zero when necessary.\n\nThe `docker logs --details` command will add on extra attributes, such as environment variables and labels, provided to `--log-opt` when creating the container.\n\nThe `--since` option shows only the container logs generated after a given date. You can specify the date as an RFC 3339 date, a UNIX timestamp, or a Go duration string (e.g. `1m30s`, `3h`). Besides RFC3339 date format you may also use RFC3339Nano, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the client will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long. You can combine the `--since` option with either or both of the `--follow` or `--tail` options.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand       | Default | Description                                                                                    |\n|-----------------------|---------|------------------------------------------------------------------------------------------------|\n| `--details`           |         | Show extra details provided to logs                                                            |\n| `--follow` , `-f`     |         | Follow log output                                                                              |\n| `--since`             |         | Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)    |\n| `--tail` , `-n`       | `all`   | Number of lines to show from the end of the logs                                               |\n| `--timestamps` , `-t` |         | Show timestamps                                                                                |\n| `--until`             |         | Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) |\n\n## Examples\n\n### Retrieve logs until a specific point in time\n\nIn order to retrieve logs before a specific point in time, run:\n\n``` \n$ docker run --name test -d busybox sh -c \"while true; do $(echo date); sleep 1; done\"\n$ date\nTue 14 Nov 2017 16:40:00 CET\n$ docker logs -f --until=2s test\nTue 14 Nov 2017 16:40:00 CET\nTue 14 Nov 2017 16:40:01 CET\nTue 14 Nov 2017 16:40:02 CET\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/logs/](https://docs.docker.com/engine/reference/commandline/logs/)"
- name: docker manifest
  id: engine/reference/commandline/manifest/index
  summary: This command is experimental
  description: "# docker manifest\n\n  \n\nManage Docker image manifests and manifest lists\n\n> This command is experimental.\n>\n> [Experimental features](../cli/index#experimental-features) are intended for testing and feedback as their functionality or UX may change between releases without warning or can be removed entirely in a future release.\n\n## Usage\n\n``` \n$ docker manifest COMMAND COMMAND\n```\n\n## Description\n\nThe `docker manifest` command by itself performs no action. In order to operate on a manifest or manifest list, one of the subcommands must be used.\n\nA single manifest is information about an image, such as layers, size, and digest. The docker manifest command also gives users additional information such as the os and architecture an image was built for.\n\nA manifest list is a list of image layers that is created by specifying one or more (ideally more than one) image names. It can then be used in the same way as an image name in `docker pull` and `docker run` commands, for example.\n\nIdeally a manifest list is created from images that are identical in function for different os/arch combinations. For this reason, manifest lists are often referred to as “multi-arch images”. However, a user could create a manifest list that points to two images -- one for windows on amd64, and one for darwin on amd64.\n\n### manifest inspect\n\n``` \n$ docker manifest inspect --help\n\nUsage:  docker manifest inspect [OPTIONS] [MANIFEST_LIST] MANIFEST\n\nDisplay an image manifest, or manifest list\n\nOptions:\n      --help       Print usage\n      --insecure   Allow communication with an insecure registry\n  -v, --verbose    Output additional info including layers and platform\n```\n\n### manifest create\n\n``` \nUsage:  docker manifest create MANIFEST_LIST MANIFEST [MANIFEST...]\n\nCreate a local manifest list for annotating and pushing to a registry\n\nOptions:\n  -a, --amend      Amend an existing manifest list\n      --insecure   Allow communication with an insecure registry\n      --help       Print usage\n```\n\n### manifest annotate\n\n``` \nUsage:  docker manifest annotate [OPTIONS] MANIFEST_LIST MANIFEST\n\nAdd additional information to a local image manifest\n\nOptions:\n      --arch string               Set architecture\n      --help                      Print usage\n      --os string                 Set operating system\n      --os-version string         Set operating system version\n      --os-features stringSlice   Set operating system feature\n      --variant string            Set architecture variant\n```\n\n### manifest push\n\n``` \nUsage:  docker manifest push [OPTIONS] MANIFEST_LIST\n\nPush a manifest list to a repository\n\nOptions:\n      --help       Print usage\n      --insecure   Allow push to an insecure registry\n  -p, --purge      Remove the local manifest list after push\n```\n\n### Working with insecure registries\n\nThe manifest command interacts solely with a Docker registry. Because of this, it has no way to query the engine for the list of allowed insecure registries. To allow the CLI to interact with an insecure registry, some `docker manifest` commands have an `--insecure` flag. For each transaction, such as a `create`, which queries a registry, the `--insecure` flag must be specified. This flag tells the CLI that this registry call may ignore security concerns like missing or self-signed certificates. Likewise, on a `manifest push` to an insecure registry, the `--insecure` flag must be specified. If this is not used with an insecure registry, the manifest command fails to find a registry that meets the default requirements.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n### Inspect an image’s manifest object\n\n``` \n$ docker manifest inspect hello-world\n{\n        \"schemaVersion\": 2,\n        \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n        \"config\": {\n                \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n                \"size\": 1520,\n                \"digest\": \"sha256:1815c82652c03bfd8644afda26fb184f2ed891d921b20a0703b46768f9755c57\"\n        },\n        \"layers\": [\n                {\n                        \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n                        \"size\": 972,\n                        \"digest\": \"sha256:b04784fba78d739b526e27edc02a5a8cd07b1052e9283f5fc155828f4b614c28\"\n                }\n        ]\n}\n```\n\n### Inspect an image’s manifest and get the os/arch info\n\nThe `docker manifest inspect` command takes an optional `--verbose` flag that gives you the image’s name (Ref), and architecture and os (Platform).\n\nJust as with other docker commands that take image names, you can refer to an image with or without a tag, or by digest (e.g. `hello-world@sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f`).\n\nHere is an example of inspecting an image’s manifest with the `--verbose` flag:\n\n``` \n$ docker manifest inspect --verbose hello-world\n{\n        \"Ref\": \"docker.io/library/hello-world:latest\",\n        \"Digest\": \"sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f\",\n        \"SchemaV2Manifest\": {\n                \"schemaVersion\": 2,\n                \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n                \"config\": {\n                        \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n                        \"size\": 1520,\n                        \"digest\": \"sha256:1815c82652c03bfd8644afda26fb184f2ed891d921b20a0703b46768f9755c57\"\n                },\n                \"layers\": [\n                        {\n                                \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n                                \"size\": 972,\n                                \"digest\": \"sha256:b04784fba78d739b526e27edc02a5a8cd07b1052e9283f5fc155828f4b614c28\"\n                        }\n                ]\n        },\n        \"Platform\": {\n                \"architecture\": \"amd64\",\n                \"os\": \"linux\"\n        }\n}\n```\n\n### Create and push a manifest list\n\nTo create a manifest list, you first `create` the manifest list locally by specifying the constituent images you would like to have included in your manifest list. Keep in mind that this is pushed to a registry, so if you want to push to a registry other than the docker registry, you need to create your manifest list with the registry name or IP and port. This is similar to tagging an image and pushing it to a foreign registry.\n\nAfter you have created your local copy of the manifest list, you may optionally `annotate` it. Annotations allowed are the architecture and operating system (overriding the image’s current values), os features, and an architecture variant.\n\nFinally, you need to `push` your manifest list to the desired registry. Below are descriptions of these three commands, and an example putting them all together.\n\n``` \n$ docker manifest create 45.55.81.106:5000/coolapp:v1 \\\n    45.55.81.106:5000/coolapp-ppc64le-linux:v1 \\\n    45.55.81.106:5000/coolapp-arm-linux:v1 \\\n    45.55.81.106:5000/coolapp-amd64-linux:v1 \\\n    45.55.81.106:5000/coolapp-amd64-windows:v1\n\nCreated manifest list 45.55.81.106:5000/coolapp:v1\n```\n\n``` \n$ docker manifest annotate 45.55.81.106:5000/coolapp:v1 45.55.81.106:5000/coolapp-arm-linux --arch arm\n```\n\n``` \n$ docker manifest push 45.55.81.106:5000/coolapp:v1\nPushed manifest 45.55.81.106:5000/coolapp@sha256:9701edc932223a66e49dd6c894a11db8c2cf4eccd1414f1ec105a623bf16b426 with digest: sha256:f67dcc5fc786f04f0743abfe0ee5dae9bd8caf8efa6c8144f7f2a43889dc513b\nPushed manifest 45.55.81.106:5000/coolapp@sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f with digest: sha256:b64ca0b60356a30971f098c92200b1271257f100a55b351e6bbe985638352f3a\nPushed manifest 45.55.81.106:5000/coolapp@sha256:39dc41c658cf25f33681a41310372f02728925a54aac3598310bfb1770615fc9 with digest: sha256:df436846483aff62bad830b730a0d3b77731bcf98ba5e470a8bbb8e9e346e4e8\nPushed manifest 45.55.81.106:5000/coolapp@sha256:f91b1145cd4ac800b28122313ae9e88ac340bb3f1e3a4cd3e59a3648650f3275 with digest: sha256:5bb8e50aa2edd408bdf3ddf61efb7338ff34a07b762992c9432f1c02fc0e5e62\nsha256:050b213d49d7673ba35014f21454c573dcbec75254a08f4a7c34f66a47c06aba\n```\n\n### Inspect a manifest list\n\n``` \n$ docker manifest inspect coolapp:v1\n{\n   \"schemaVersion\": 2,\n   \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n   \"manifests\": [\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 424,\n         \"digest\": \"sha256:f67dcc5fc786f04f0743abfe0ee5dae9bd8caf8efa6c8144f7f2a43889dc513b\",\n         \"platform\": {\n            \"architecture\": \"arm\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 424,\n         \"digest\": \"sha256:b64ca0b60356a30971f098c92200b1271257f100a55b351e6bbe985638352f3a\",\n         \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 425,\n         \"digest\": \"sha256:df436846483aff62bad830b730a0d3b77731bcf98ba5e470a8bbb8e9e346e4e8\",\n         \"platform\": {\n            \"architecture\": \"ppc64le\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 425,\n         \"digest\": \"sha256:5bb8e50aa2edd408bdf3ddf61efb7338ff34a07b762992c9432f1c02fc0e5e62\",\n         \"platform\": {\n            \"architecture\": \"s390x\",\n            \"os\": \"linux\"\n         }\n      }\n   ]\n}\n```\n\n### Push to an insecure registry\n\nHere is an example of creating and pushing a manifest list using a known insecure registry.\n\n``` \n$ docker manifest create --insecure myprivateregistry.mycompany.com/repo/image:1.0 \\\n    myprivateregistry.mycompany.com/repo/image-linux-ppc64le:1.0 \\\n    myprivateregistry.mycompany.com/repo/image-linux-s390x:1.0 \\\n    myprivateregistry.mycompany.com/repo/image-linux-arm:1.0 \\\n    myprivateregistry.mycompany.com/repo/image-linux-armhf:1.0 \\\n    myprivateregistry.mycompany.com/repo/image-windows-amd64:1.0 \\\n    myprivateregistry.mycompany.com/repo/image-linux-amd64:1.0\n\n$ docker manifest push --insecure myprivateregistry.mycompany.com/repo/image:tag\n```\n\n> **Note**\n>\n> The `--insecure` flag is not required to annotate a manifest list, since annotations are to a locally-stored copy of a manifest list. You may also skip the `--insecure` flag if you are performing a `docker manifest inspect` on a locally-stored manifest list. Be sure to keep in mind that locally-stored manifest lists are never used by the engine on a `docker pull`.\n\n## Child commands\n\n| Command                                                | Description                                                           |\n|--------------------------------------------------------|-----------------------------------------------------------------------|\n| [docker manifest annotate](../manifest_annotate/index) | Add additional information to a local image manifest                  |\n| [docker manifest create](../manifest_create/index)     | Create a local manifest list for annotating and pushing to a registry |\n| [docker manifest inspect](../manifest_inspect/index)   | Display an image manifest, or manifest list                           |\n| [docker manifest push](../manifest_push/index)         | Push a manifest list to a repository                                  |\n| [docker manifest rm](../manifest_rm/index)             | Delete one or more manifest lists from local storage                  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/manifest/](https://docs.docker.com/engine/reference/commandline/manifest/)"
- name: docker manifest annotate
  id: engine/reference/commandline/manifest_annotate/index
  summary: This command is experimental
  description: "# docker manifest annotate\n\n  \n\nAdd additional information to a local image manifest\n\n> This command is experimental.\n>\n> [Experimental features](../cli/index#experimental-features) are intended for testing and feedback as their functionality or UX may change between releases without warning or can be removed entirely in a future release.\n\n## Usage\n\n``` \n$ docker manifest annotate [OPTIONS] MANIFEST_LIST MANIFEST\n```\n\n## Options\n\n| Name, shorthand | Default | Description                  |\n|-----------------|---------|------------------------------|\n| `--arch`        |         | Set architecture             |\n| `--os`          |         | Set operating system         |\n| `--os-features` |         | Set operating system feature |\n| `--os-version`  |         | Set operating system version |\n| `--variant`     |         | Set architecture variant     |\n\n## Parent command\n\n| Command                              | Description                                      |\n|:-------------------------------------|:-------------------------------------------------|\n| [docker manifest](../manifest/index) | Manage Docker image manifests and manifest lists |\n\n## Related commands\n\n| Command                                              | Description                                                           |\n|------------------------------------------------------|-----------------------------------------------------------------------|\n| [docker manifest annotate](index)                    | Add additional information to a local image manifest                  |\n| [docker manifest create](../manifest_create/index)   | Create a local manifest list for annotating and pushing to a registry |\n| [docker manifest inspect](../manifest_inspect/index) | Display an image manifest, or manifest list                           |\n| [docker manifest push](../manifest_push/index)       | Push a manifest list to a repository                                  |\n| [docker manifest rm](../manifest_rm/index)           | Delete one or more manifest lists from local storage                  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/manifest_annotate/](https://docs.docker.com/engine/reference/commandline/manifest_annotate/)"
- name: docker manifest create
  id: engine/reference/commandline/manifest_create/index
  summary: This command is experimental
  description: "# docker manifest create\n\n  \n\nCreate a local manifest list for annotating and pushing to a registry\n\n> This command is experimental.\n>\n> [Experimental features](../cli/index#experimental-features) are intended for testing and feedback as their functionality or UX may change between releases without warning or can be removed entirely in a future release.\n\n## Usage\n\n``` \n$ docker manifest create MANIFEST_LIST MANIFEST [MANIFEST...]\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                                   |\n|------------------|---------|-----------------------------------------------|\n| `--amend` , `-a` |         | Amend an existing manifest list               |\n| `--insecure`     |         | Allow communication with an insecure registry |\n\n## Parent command\n\n| Command                              | Description                                      |\n|:-------------------------------------|:-------------------------------------------------|\n| [docker manifest](../manifest/index) | Manage Docker image manifests and manifest lists |\n\n## Related commands\n\n| Command                                                | Description                                                           |\n|--------------------------------------------------------|-----------------------------------------------------------------------|\n| [docker manifest annotate](../manifest_annotate/index) | Add additional information to a local image manifest                  |\n| [docker manifest create](index)                        | Create a local manifest list for annotating and pushing to a registry |\n| [docker manifest inspect](../manifest_inspect/index)   | Display an image manifest, or manifest list                           |\n| [docker manifest push](../manifest_push/index)         | Push a manifest list to a repository                                  |\n| [docker manifest rm](../manifest_rm/index)             | Delete one or more manifest lists from local storage                  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/manifest_create/](https://docs.docker.com/engine/reference/commandline/manifest_create/)"
- name: docker manifest inspect
  id: engine/reference/commandline/manifest_inspect/index
  summary: This command is experimental
  description: "# docker manifest inspect\n\n  \n\nDisplay an image manifest, or manifest list\n\n> This command is experimental.\n>\n> [Experimental features](../cli/index#experimental-features) are intended for testing and feedback as their functionality or UX may change between releases without warning or can be removed entirely in a future release.\n\n## Usage\n\n``` \n$ docker manifest inspect [OPTIONS] [MANIFEST_LIST] MANIFEST\n```\n\n## Options\n\n| Name, shorthand    | Default | Description                                          |\n|--------------------|---------|------------------------------------------------------|\n| `--insecure`       |         | Allow communication with an insecure registry        |\n| `--verbose` , `-v` |         | Output additional info including layers and platform |\n\n## Parent command\n\n| Command                              | Description                                      |\n|:-------------------------------------|:-------------------------------------------------|\n| [docker manifest](../manifest/index) | Manage Docker image manifests and manifest lists |\n\n## Related commands\n\n| Command                                                | Description                                                           |\n|--------------------------------------------------------|-----------------------------------------------------------------------|\n| [docker manifest annotate](../manifest_annotate/index) | Add additional information to a local image manifest                  |\n| [docker manifest create](../manifest_create/index)     | Create a local manifest list for annotating and pushing to a registry |\n| [docker manifest inspect](index)                       | Display an image manifest, or manifest list                           |\n| [docker manifest push](../manifest_push/index)         | Push a manifest list to a repository                                  |\n| [docker manifest rm](../manifest_rm/index)             | Delete one or more manifest lists from local storage                  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/manifest_inspect/](https://docs.docker.com/engine/reference/commandline/manifest_inspect/)"
- name: docker manifest push
  id: engine/reference/commandline/manifest_push/index
  summary: This command is experimental
  description: "# docker manifest push\n\n  \n\nPush a manifest list to a repository\n\n> This command is experimental.\n>\n> [Experimental features](../cli/index#experimental-features) are intended for testing and feedback as their functionality or UX may change between releases without warning or can be removed entirely in a future release.\n\n## Usage\n\n``` \n$ docker manifest push [OPTIONS] MANIFEST_LIST\n```\n\n## Options\n\n| Name, shorthand  | Default | Description                               |\n|------------------|---------|-------------------------------------------|\n| `--insecure`     |         | Allow push to an insecure registry        |\n| `--purge` , `-p` |         | Remove the local manifest list after push |\n\n## Parent command\n\n| Command                              | Description                                      |\n|:-------------------------------------|:-------------------------------------------------|\n| [docker manifest](../manifest/index) | Manage Docker image manifests and manifest lists |\n\n## Related commands\n\n| Command                                                | Description                                                           |\n|--------------------------------------------------------|-----------------------------------------------------------------------|\n| [docker manifest annotate](../manifest_annotate/index) | Add additional information to a local image manifest                  |\n| [docker manifest create](../manifest_create/index)     | Create a local manifest list for annotating and pushing to a registry |\n| [docker manifest inspect](../manifest_inspect/index)   | Display an image manifest, or manifest list                           |\n| [docker manifest push](index)                          | Push a manifest list to a repository                                  |\n| [docker manifest rm](../manifest_rm/index)             | Delete one or more manifest lists from local storage                  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/manifest_push/](https://docs.docker.com/engine/reference/commandline/manifest_push/)"
- name: docker manifest rm
  id: engine/reference/commandline/manifest_rm/index
  summary: This command is experimental
  description: "# docker manifest rm\n\n  \n\nDelete one or more manifest lists from local storage\n\n> This command is experimental.\n>\n> [Experimental features](../cli/index#experimental-features) are intended for testing and feedback as their functionality or UX may change between releases without warning or can be removed entirely in a future release.\n\n## Usage\n\n``` \n$ docker manifest rm MANIFEST_LIST [MANIFEST_LIST...]\n```\n\n## Parent command\n\n| Command                              | Description                                      |\n|:-------------------------------------|:-------------------------------------------------|\n| [docker manifest](../manifest/index) | Manage Docker image manifests and manifest lists |\n\n## Related commands\n\n| Command                                                | Description                                                           |\n|--------------------------------------------------------|-----------------------------------------------------------------------|\n| [docker manifest annotate](../manifest_annotate/index) | Add additional information to a local image manifest                  |\n| [docker manifest create](../manifest_create/index)     | Create a local manifest list for annotating and pushing to a registry |\n| [docker manifest inspect](../manifest_inspect/index)   | Display an image manifest, or manifest list                           |\n| [docker manifest push](../manifest_push/index)         | Push a manifest list to a repository                                  |\n| [docker manifest rm](index)                            | Delete one or more manifest lists from local storage                  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/manifest_rm/](https://docs.docker.com/engine/reference/commandline/manifest_rm/)"
- name: docker network
  id: engine/reference/commandline/network/index
  summary: Manage networks
  description: "# docker network\n\n  \n\nManage networks\n\n## Usage\n\n``` \n$ docker network COMMAND\n```\n\n## Description\n\nManage networks. You can use subcommands to create, inspect, list, remove, prune, connect, and disconnect networks.\n\n## Child commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index)       | Connect a container to a network                     |\n| [docker network create](../network_create/index)         | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index)       | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)                 | List networks                                        |\n| [docker network prune](../network_prune/index)           | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)                 | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network/](https://docs.docker.com/engine/reference/commandline/network/)"
- name: docker network connect
  id: engine/reference/commandline/network_connect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker network connect\n\n  \n\nConnect a container to a network\n\n## Usage\n\n``` \n$ docker network connect [OPTIONS] NETWORK CONTAINER\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nConnects a container to a network. You can connect a container by name or by ID. Once connected, the container can communicate with other containers in the same network.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--alias`         |         | Add network-scoped alias for the container |\n| `--driver-opt`    |         | driver options for the network             |\n| `--ip`            |         | IPv4 address (e.g., 172.30.100.104)        |\n| `--ip6`           |         | IPv6 address (e.g., 2001:db8::33)          |\n| `--link`          |         | Add link to another container              |\n| `--link-local-ip` |         | Add a link-local address for the container |\n\n## Examples\n\n### Connect a running container to a network\n\n``` \n$ docker network connect multi-host-network container1\n```\n\n### Connect a container to a network when it starts\n\nYou can also use the `docker run --network=<network-name>` option to start a container and immediately connect it to a network.\n\n``` \n$ docker run -itd --network=multi-host-network busybox\n```\n\n### Specify the IP address a container will use on a given network\n\nYou can specify the IP address you want to be assigned to the container’s interface.\n\n``` \n$ docker network connect --ip 10.10.36.122 multi-host-network container2\n```\n\n### Use the legacy `--link` option\n\nYou can use `--link` option to link another container with a preferred alias\n\n``` \n$ docker network connect --link container1:c1 multi-host-network container2\n```\n\n### Create a network alias for a container\n\n`--alias` option can be used to resolve the container by another name in the network being connected to.\n\n``` \n$ docker network connect --alias db --alias mysql multi-host-network container2\n```\n\n### Network implications of stopping, pausing, or restarting containers\n\nYou can pause, restart, and stop containers that are connected to a network. A container connects to its configured networks when it runs.\n\nIf specified, the container’s IP address(es) is reapplied when a stopped container is restarted. If the IP address is no longer available, the container fails to start. One way to guarantee that the IP address is available is to specify an `--ip-range` when creating the network, and choose the static IP address(es) from outside that range. This ensures that the IP address is not given to another container while this container is not on the network.\n\n``` \n$ docker network create --subnet 172.20.0.0/16 --ip-range 172.20.240.0/20 multi-host-network\n```\n\n``` \n$ docker network connect --ip 172.20.128.2 multi-host-network container2\n```\n\nTo verify the container is connected, use the `docker network inspect` command. Use `docker network disconnect` to remove a container from the network.\n\nOnce connected in network, containers can communicate using only another container’s IP address or name. For `overlay` networks or custom plugins that support multi-host connectivity, containers connected to the same multi-host network but launched from different Engines can also communicate in this way.\n\nYou can connect a container to one or more networks. The networks need not be the same type. For example, you can connect a single container bridge and overlay networks.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](index)                          | Connect a container to a network                     |\n| [docker network create](../network_create/index)         | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index)       | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)                 | List networks                                        |\n| [docker network prune](../network_prune/index)           | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)                 | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_connect/](https://docs.docker.com/engine/reference/commandline/network_connect/)"
- name: docker network create
  id: engine/reference/commandline/network_create/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker network create\n\n  \n\nCreate a network\n\n## Usage\n\n``` \n$ docker network create [OPTIONS] NETWORK\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a new network. The `DRIVER` accepts `bridge` or `overlay` which are the built-in network drivers. If you have installed a third party or your own custom network driver you can specify that `DRIVER` here also. If you don’t specify the `--driver` option, the command automatically creates a `bridge` network for you. When you install Docker Engine it creates a `bridge` network automatically. This network corresponds to the `docker0` bridge that Engine has traditionally relied on. When you launch a new container with `docker run` it automatically connects to this bridge network. You cannot remove this default bridge network, but you can create new ones using the `network create` command.\n\n``` \n$ docker network create -d bridge my-bridge-network\n```\n\nBridge networks are isolated networks on a single Engine installation. If you want to create a network that spans multiple Docker hosts each running an Engine, you must create an `overlay` network. Unlike `bridge` networks, overlay networks require some pre-existing conditions before you can create one. These conditions are:\n\n- Access to a key-value store. Engine supports Consul, Etcd, and ZooKeeper (Distributed store) key-value stores.\n- A cluster of hosts with connectivity to the key-value store.\n- A properly configured Engine `daemon` on each host in the cluster.\n\nThe `dockerd` options that support the `overlay` network are:\n\n- `--cluster-store`\n- `--cluster-store-opt`\n- `--cluster-advertise`\n\nTo read more about these options and how to configure them, see [“*Get started with multi-host network*”](https://docs.docker.com/engine/userguide/networking/get-started-overlay).\n\nWhile not required, it is a good idea to install Docker Swarm to manage the cluster that makes up your network. Swarm provides sophisticated discovery and server management tools that can assist your implementation.\n\nOnce you have prepared the `overlay` network prerequisites you simply choose a Docker host in the cluster and issue the following to create the network:\n\n``` \n$ docker network create -d overlay my-multihost-network\n```\n\nNetwork names must be unique. The Docker daemon attempts to identify naming conflicts but this is not guaranteed. It is the user’s responsibility to avoid name conflicts.\n\n### Overlay network limitations\n\nYou should create overlay networks with `/24` blocks (the default), which limits you to 256 IP addresses, when you create networks using the default VIP-based endpoint-mode. This recommendation addresses [limitations with swarm mode](https://github.com/moby/moby/issues/30820). If you need more than 256 IP addresses, do not increase the IP block size. You can either use `dnsrr` endpoint mode with an external load balancer, or use multiple smaller overlay networks. See [Configure service discovery](https://docs.docker.com/network/overlay#configure-service-discovery) for more information about different endpoint modes.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default  | Description                                             |\n|-------------------|----------|---------------------------------------------------------|\n| `--attachable`    |          | Enable manual container attachment                      |\n| `--aux-address`   |          | Auxiliary IPv4 or IPv6 addresses used by Network driver |\n| `--config-from`   |          | The network from which to copy the configuration        |\n| `--config-only`   |          | Create a configuration only network                     |\n| `--driver` , `-d` | `bridge` | Driver to manage the Network                            |\n| `--gateway`       |          | IPv4 or IPv6 Gateway for the master subnet              |\n| `--ingress`       |          | Create swarm routing-mesh network                       |\n| `--internal`      |          | Restrict external access to the network                 |\n| `--ip-range`      |          | Allocate container ip from a sub-range                  |\n| `--ipam-driver`   |          | IP Address Management Driver                            |\n| `--ipam-opt`      |          | Set IPAM driver specific options                        |\n| `--ipv6`          |          | Enable IPv6 networking                                  |\n| `--label`         |          | Set metadata on a network                               |\n| `--opt` , `-o`    |          | Set driver specific options                             |\n| `--scope`         |          | Control the network's scope                             |\n| `--subnet`        |          | Subnet in CIDR format that represents a network segment |\n\n## Examples\n\n### Connect containers\n\nWhen you start a container, use the `--network` flag to connect it to a network. This example adds the `busybox` container to the `mynet` network:\n\n``` \n$ docker run -itd --network=mynet busybox\n```\n\nIf you want to add a container to a network after the container is already running, use the `docker network connect` subcommand.\n\nYou can connect multiple containers to the same network. Once connected, the containers can communicate using only another container’s IP address or name. For `overlay` networks or custom plugins that support multi-host connectivity, containers connected to the same multi-host network but launched from different Engines can also communicate in this way.\n\nYou can disconnect a container from a network using the `docker network disconnect` command.\n\n### Specify advanced options\n\nWhen you create a network, Engine creates a non-overlapping subnetwork for the network by default. This subnetwork is not a subdivision of an existing network. It is purely for ip-addressing purposes. You can override this default and specify subnetwork values directly using the `--subnet` option. On a `bridge` network you can only create a single subnet:\n\n``` \n$ docker network create --driver=bridge --subnet=192.168.0.0/16 br0\n```\n\nAdditionally, you also specify the `--gateway` `--ip-range` and `--aux-address` options.\n\n``` \n$ docker network create \\\n  --driver=bridge \\\n  --subnet=172.28.0.0/16 \\\n  --ip-range=172.28.5.0/24 \\\n  --gateway=172.28.5.254 \\\n  br0\n```\n\nIf you omit the `--gateway` flag the Engine selects one for you from inside a preferred pool. For `overlay` networks and for network driver plugins that support it you can create multiple subnetworks. This example uses two `/25` subnet mask to adhere to the current guidance of not having more than 256 IPs in a single overlay network. Each of the subnetworks has 126 usable addresses.\n\n``` \n$ docker network create -d overlay \\\n  --subnet=192.168.10.0/25 \\\n  --subnet=192.168.20.0/25 \\\n  --gateway=192.168.10.100 \\\n  --gateway=192.168.20.100 \\\n  --aux-address=\"my-router=192.168.10.5\" --aux-address=\"my-switch=192.168.10.6\" \\\n  --aux-address=\"my-printer=192.168.20.5\" --aux-address=\"my-nas=192.168.20.6\" \\\n  my-multihost-network\n```\n\nBe sure that your subnetworks do not overlap. If they do, the network create fails and Engine returns an error.\n\n### Bridge driver options\n\nWhen creating a custom network, the default network driver (i.e. `bridge`) has additional options that can be passed. The following are those options and the equivalent docker daemon flags used for docker0 bridge:\n\n| Option                                           | Equivalent  | Description                                           |\n|--------------------------------------------------|-------------|-------------------------------------------------------|\n| `com.docker.network.bridge.name`                 | \\-          | Bridge name to be used when creating the Linux bridge |\n| `com.docker.network.bridge.enable_ip_masquerade` | `--ip-masq` | Enable IP masquerading                                |\n| `com.docker.network.bridge.enable_icc`           | `--icc`     | Enable or Disable Inter Container Connectivity        |\n| `com.docker.network.bridge.host_binding_ipv4`    | `--ip`      | Default IP when binding container ports               |\n| `com.docker.network.driver.mtu`                  | `--mtu`     | Set the containers network MTU                        |\n| `com.docker.network.container_iface_prefix`      | \\-          | Set a custom prefix for container interfaces          |\n\nThe following arguments can be passed to `docker network create` for any network driver, again with their approximate equivalents to `docker daemon`.\n\n| Argument     | Equivalent     | Description                                |\n|--------------|----------------|--------------------------------------------|\n| `--gateway`  | \\-             | IPv4 or IPv6 Gateway for the master subnet |\n| `--ip-range` | `--fixed-cidr` | Allocate IPs from a range                  |\n| `--internal` | \\-             | Restrict external access to the network    |\n| `--ipv6`     | `--ipv6`       | Enable IPv6 networking                     |\n| `--subnet`   | `--bip`        | Subnet for network                         |\n\nFor example, let’s use `-o` or `--opt` options to specify an IP address binding when publishing ports:\n\n``` \n$ docker network create \\\n    -o \"com.docker.network.bridge.host_binding_ipv4\"=\"172.19.0.1\" \\\n    simple-network\n```\n\n### Network internal mode\n\nBy default, when you connect a container to an `overlay` network, Docker also connects a bridge network to it to provide external connectivity. If you want to create an externally isolated `overlay` network, you can specify the `--internal` option.\n\n### Network ingress mode\n\nYou can create the network which will be used to provide the routing-mesh in the swarm cluster. You do so by specifying `--ingress` when creating the network. Only one ingress network can be created at the time. The network can be removed only if no services depend on it. Any option available when creating an overlay network is also available when creating the ingress network, besides the `--attachable` option.\n\n``` \n$ docker network create -d overlay \\\n  --subnet=10.11.0.0/16 \\\n  --ingress \\\n  --opt com.docker.network.driver.mtu=9216 \\\n  --opt encrypted=true \\\n  my-ingress-network\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index)       | Connect a container to a network                     |\n| [docker network create](index)                           | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index)       | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)                 | List networks                                        |\n| [docker network prune](../network_prune/index)           | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)                 | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_create/](https://docs.docker.com/engine/reference/commandline/network_create/)"
- name: docker network disconnect
  id: engine/reference/commandline/network_disconnect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker network disconnect\n\n  \n\nDisconnect a container from a network\n\n## Usage\n\n``` \n$ docker network disconnect [OPTIONS] NETWORK CONTAINER\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nDisconnects a container from a network. The container must be running to disconnect it from the network.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                      |\n|------------------|---------|--------------------------------------------------|\n| `--force` , `-f` |         | Force the container to disconnect from a network |\n\n## Examples\n\n``` \n$ docker network disconnect multi-host-network container1\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index) | Connect a container to a network                     |\n| [docker network create](../network_create/index)   | Create a network                                     |\n| [docker network disconnect](index)                 | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index) | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)           | List networks                                        |\n| [docker network prune](../network_prune/index)     | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)           | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_disconnect/](https://docs.docker.com/engine/reference/commandline/network_disconnect/)"
- name: Docker network driver plugins
  id: engine/extend/plugins_network/index
  summary: This document describes Docker Engine network driver plugins generally available in Docker Engine
  description: "# Docker network driver plugins\n\nThis document describes Docker Engine network driver plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](../index).\n\nDocker Engine network plugins enable Engine deployments to be extended to support a wide range of networking technologies, such as VXLAN, IPVLAN, MACVLAN or something completely different. Network driver plugins are supported via the LibNetwork project. Each plugin is implemented as a “remote driver” for LibNetwork, which shares plugin infrastructure with Engine. Effectively, network driver plugins are activated in the same way as other plugins, and use the same kind of protocol.\n\n## Network plugins and swarm mode\n\n[Legacy plugins](../legacy_plugins/index) do not work in swarm mode. However, plugins written using the [v2 plugin system](../index) do work in swarm mode, as long as they are installed on each swarm worker node.\n\n## Use network driver plugins\n\nThe means of installing and running a network driver plugin depend on the particular plugin. So, be sure to install your plugin according to the instructions obtained from the plugin developer.\n\nOnce running however, network driver plugins are used just like the built-in network drivers: by being mentioned as a driver in network-oriented Docker commands. For example,\n\n``` \n$ docker network create --driver weave mynet\n```\n\nSome network driver plugins are listed in [plugins](../legacy_plugins/index)\n\nThe `mynet` network is now owned by `weave`, so subsequent commands referring to that network will be sent to the plugin,\n\n``` \n$ docker run --network=mynet busybox top\n```\n\n## Find network plugins\n\nNetwork plugins are written by third parties, and are published by those third parties, either on [Docker Store](https://store.docker.com/search?category=network&q=&type=plugin) or on the third party’s site.\n\n## Write a network plugin\n\nNetwork plugins implement the [Docker plugin API](../plugin_api/index) and the network plugin protocol\n\n## Network plugin protocol\n\nThe network driver protocol, in addition to the plugin activation call, is documented as part of libnetwork: [https://github.com/docker/libnetwork/blob/master/docs/remote.md](https://github.com/docker/libnetwork/blob/master/docs/remote/).\n\n## Related Information\n\nTo interact with the Docker maintainers and other interested users, see the IRC channel `#docker-network`.\n\n- [Docker networks feature overview](https://docs.docker.com/network/)\n- The [LibNetwork](https://github.com/docker/libnetwork) project\n\n[Examples](https://docs.docker.com/search/?q=Examples), [Usage](https://docs.docker.com/search/?q=Usage), [plugins](https://docs.docker.com/search/?q=plugins), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation), [user guide](https://docs.docker.com/search/?q=user%20guide)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/plugins_network/](https://docs.docker.com/engine/extend/plugins_network/)"
- name: docker network inspect
  id: engine/reference/commandline/network_inspect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker network inspect\n\n  \n\nDisplay detailed information on one or more networks\n\n## Usage\n\n``` \n$ docker network inspect [OPTIONS] NETWORK [NETWORK...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nReturns information about one or more networks. By default, this command renders all results in a JSON object.\n\n## Options\n\n| Name, shorthand    | Default | Description                                   |\n|--------------------|---------|-----------------------------------------------|\n| `--format` , `-f`  |         | Format the output using the given Go template |\n| `--verbose` , `-v` |         | Verbose output for diagnostics                |\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index)       | Connect a container to a network                     |\n| [docker network create](../network_create/index)         | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](index)                          | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)                 | List networks                                        |\n| [docker network prune](../network_prune/index)           | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)                 | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_inspect/](https://docs.docker.com/engine/reference/commandline/network_inspect/)"
- name: docker network ls
  id: engine/reference/commandline/network_ls/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker network ls\n\n  \n\nList networks\n\n## Usage\n\n``` \n$ docker network ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists all the networks the Engine `daemon` knows about. This includes the networks that span across multiple hosts in a cluster.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                  |\n|-------------------|---------|----------------------------------------------|\n| `--filter` , `-f` |         | Provide filter values (e.g. 'driver=bridge') |\n| `--format`        |         | Pretty-print networks using a Go template    |\n| `--no-trunc`      |         | Do not truncate the output                   |\n| `--quiet` , `-q`  |         | Only display network IDs                     |\n\n## Examples\n\n### List all networks\n\n``` \n$ docker network ls\nNETWORK ID          NAME                DRIVER          SCOPE\n7fca4eb8c647        bridge              bridge          local\n9f904ee27bf5        none                null            local\ncf03ee007fb4        host                host            local\n78b03ee04fc4        multi-host          overlay         swarm\n```\n\nUse the `--no-trunc` option to display the full network id:\n\n``` \n$ docker network ls --no-trunc\nNETWORK ID                                                         NAME                DRIVER           SCOPE\n18a2866682b85619a026c81b98a5e375bd33e1b0936a26cc497c283d27bae9b3   none                null             local\nc288470c46f6c8949c5f7e5099b5b7947b07eabe8d9a27d79a9cbf111adcbf47   host                host             local\n7b369448dccbf865d397c8d2be0cda7cf7edc6b0945f77d2529912ae917a0185   bridge              bridge           local\n95e74588f40db048e86320c6526440c504650a1ff3e9f7d60a497c4d2163e5bd   foo                 bridge           local\n63d1ff1f77b07ca51070a8c227e962238358bd310bde1529cf62e6c307ade161   dev                 bridge           local\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g. `--filter \"foo=bar\" --filter \"bif=baz\"`). Multiple filter flags are combined as an `OR` filter. For example, `-f type=custom -f type=builtin` returns both `custom` and `builtin` networks.\n\nThe currently supported filters are:\n\n- driver\n- id (network’s id)\n- label (`label=<key>` or `label=<key>=<value>`)\n- name (network’s name)\n- scope (`swarm|global|local`)\n- type (`custom|builtin`)\n\n#### Driver\n\nThe `driver` filter matches networks based on their driver.\n\nThe following example matches networks with the `bridge` driver:\n\n``` \n$ docker network ls --filter driver=bridge\nNETWORK ID          NAME                DRIVER            SCOPE\ndb9db329f835        test1               bridge            local\nf6e212da9dfd        test2               bridge            local\n```\n\n#### ID\n\nThe `id` filter matches on all or part of a network’s ID.\n\nThe following filter matches all networks with an ID containing the `63d1ff1f77b0...` string.\n\n``` \n$ docker network ls --filter id=63d1ff1f77b07ca51070a8c227e962238358bd310bde1529cf62e6c307ade161\nNETWORK ID          NAME                DRIVER           SCOPE\n63d1ff1f77b0        dev                 bridge           local\n```\n\nYou can also filter for a substring in an ID as this shows:\n\n``` \n$ docker network ls --filter id=95e74588f40d\nNETWORK ID          NAME                DRIVER          SCOPE\n95e74588f40d        foo                 bridge          local\n\n$ docker network ls --filter id=95e\nNETWORK ID          NAME                DRIVER          SCOPE\n95e74588f40d        foo                 bridge          local\n```\n\n#### Label\n\nThe `label` filter matches networks based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches networks with the `usage` label regardless of its value.\n\n``` \n$ docker network ls -f \"label=usage\"\nNETWORK ID          NAME                DRIVER         SCOPE\ndb9db329f835        test1               bridge         local\nf6e212da9dfd        test2               bridge         local\n```\n\nThe following filter matches networks with the `usage` label with the `prod` value.\n\n``` \n$ docker network ls -f \"label=usage=prod\"\nNETWORK ID          NAME                DRIVER        SCOPE\nf6e212da9dfd        test2               bridge        local\n```\n\n#### Name\n\nThe `name` filter matches on all or part of a network’s name.\n\nThe following filter matches all networks with a name containing the `foobar` string.\n\n``` \n$ docker network ls --filter name=foobar\nNETWORK ID          NAME                DRIVER       SCOPE\n06e7eef0a170        foobar              bridge       local\n```\n\nYou can also filter for a substring in a name as this shows:\n\n``` \n$ docker network ls --filter name=foo\nNETWORK ID          NAME                DRIVER       SCOPE\n95e74588f40d        foo                 bridge       local\n06e7eef0a170        foobar              bridge       local\n```\n\n#### Scope\n\nThe `scope` filter matches networks based on their scope.\n\nThe following example matches networks with the `swarm` scope:\n\n``` \n$ docker network ls --filter scope=swarm\nNETWORK ID          NAME                DRIVER              SCOPE\nxbtm0v4f1lfh        ingress             overlay             swarm\nic6r88twuu92        swarmnet            overlay             swarm\n```\n\nThe following example matches networks with the `local` scope:\n\n``` \n$ docker network ls --filter scope=local\nNETWORK ID          NAME                DRIVER              SCOPE\ne85227439ac7        bridge              bridge              local\n0ca0e19443ed        host                host                local\nca13cc149a36        localnet            bridge              local\nf9e115d2de35        none                null                local\n```\n\n#### Type\n\nThe `type` filter supports two values; `builtin` displays predefined networks (`bridge`, `none`, `host`), whereas `custom` displays user defined networks.\n\nThe following filter matches all user defined networks:\n\n``` \n$ docker network ls --filter type=custom\nNETWORK ID          NAME                DRIVER       SCOPE\n95e74588f40d        foo                 bridge       local\n63d1ff1f77b0        dev                 bridge       local\n```\n\nBy having this flag it allows for batch cleanup. For example, use this filter to delete all user defined networks:\n\n``` \n$ docker network rm `docker network ls --filter type=custom -q`\n```\n\nA warning will be issued when trying to remove a network that has containers attached.\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints networks output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder  | Description                                                                            |\n|--------------|----------------------------------------------------------------------------------------|\n| `.ID`        | Network ID                                                                             |\n| `.Name`      | Network name                                                                           |\n| `.Driver`    | Network driver                                                                         |\n| `.Scope`     | Network scope (local, global)                                                          |\n| `.IPv6`      | Whether IPv6 is enabled on the network or not.                                         |\n| `.Internal`  | Whether the network is internal or not.                                                |\n| `.Labels`    | All labels assigned to the network.                                                    |\n| `.Label`     | Value of a specific label for this network. For example `{{.Label \"project.version\"}}` |\n| `.CreatedAt` | Time when the network was created                                                      |\n\nWhen using the `--format` option, the `network ls` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `Driver` entries separated by a colon (`:`) for all networks:\n\n``` \n$ docker network ls --format \"{{.ID}}: {{.Driver}}\"\nafaaab448eb2: bridge\nd1584f8dc718: host\n391df270dc66: null\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index)       | Connect a container to a network                     |\n| [docker network create](../network_create/index)         | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index)       | Display detailed information on one or more networks |\n| [docker network ls](index)                               | List networks                                        |\n| [docker network prune](../network_prune/index)           | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)                 | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_ls/](https://docs.docker.com/engine/reference/commandline/network_ls/)"
- name: docker network prune
  id: engine/reference/commandline/network_prune/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker network prune\n\n  \n\nRemove all unused networks\n\n## Usage\n\n``` \n$ docker network prune [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemove all unused networks. Unused networks are those which are not referenced by any containers.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                        |\n|------------------|---------|----------------------------------------------------|\n| `--filter`       |         | Provide filter values (e.g. 'until=\\<timestamp\\>') |\n| `--force` , `-f` |         | Do not prompt for confirmation                     |\n\n## Examples\n\n``` \n$ docker network prune\n\nWARNING! This will remove all custom networks not used by at least one container.\nAre you sure you want to continue? [y/N] y\nDeleted Networks:\nn1\nn2\n```\n\n### Filtering\n\nThe filtering flag (`--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- until (`<timestamp>`) - only remove networks created before given timestamp\n- label (`label=<key>`, `label=<key>=<value>`, `label!=<key>`, or `label!=<key>=<value>`) - only remove networks with (or without, in case `label!=...` is used) the specified labels.\n\nThe `until` filter can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the daemon machine’s time. Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the daemon will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long.\n\nThe `label` filter accepts two formats. One is the `label=...` (`label=<key>` or `label=<key>=<value>`), which removes networks with the specified labels. The other format is the `label!=...` (`label!=<key>` or `label!=<key>=<value>`), which removes networks without the specified labels.\n\nThe following removes networks created more than 5 minutes ago. Note that system networks such as `bridge`, `host`, and `none` will never be pruned:\n\n``` \n$ docker network ls\n\nNETWORK ID          NAME                DRIVER              SCOPE\n7430df902d7a        bridge              bridge              local\nea92373fd499        foo-1-day-ago       bridge              local\nab53663ed3c7        foo-1-min-ago       bridge              local\n97b91972bc3b        host                host                local\nf949d337b1f5        none                null                local\n\n$ docker network prune --force --filter until=5m\n\nDeleted Networks:\nfoo-1-day-ago\n\n$ docker network ls\n\nNETWORK ID          NAME                DRIVER              SCOPE\n7430df902d7a        bridge              bridge              local\nab53663ed3c7        foo-1-min-ago       bridge              local\n97b91972bc3b        host                host                local\nf949d337b1f5        none                null                local\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index)       | Connect a container to a network                     |\n| [docker network create](../network_create/index)         | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index)       | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)                 | List networks                                        |\n| [docker network prune](index)                            | Remove all unused networks                           |\n| [docker network rm](../network_rm/index)                 | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_prune/](https://docs.docker.com/engine/reference/commandline/network_prune/)"
- name: docker network rm
  id: engine/reference/commandline/network_rm/index
  summary: Removes one or more networks by name or identifier
  description: "# docker network rm\n\n  \n\nRemove one or more networks\n\n## Usage\n\n``` \n$ docker network rm NETWORK [NETWORK...]\n```\n\n## Description\n\nRemoves one or more networks by name or identifier. To remove a network, you must first disconnect any containers connected to it.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n### Remove a network\n\nTo remove the network named ‘my-network’:\n\n``` \n$ docker network rm my-network\n```\n\n### Remove multiple networks\n\nTo delete multiple networks in a single `docker network rm` command, provide multiple network names or ids. The following example deletes a network with id `3695c422697f` and a network named `my-network`:\n\n``` \n$ docker network rm 3695c422697f my-network\n```\n\nWhen you specify multiple networks, the command attempts to delete each in turn. If the deletion of one network fails, the command continues to the next on the list and tries to delete that. The command reports success or failure for each deletion.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker network](../network/index) | Manage networks |\n\n## Related commands\n\n| Command                                                  | Description                                          |\n|----------------------------------------------------------|------------------------------------------------------|\n| [docker network connect](../network_connect/index)       | Connect a container to a network                     |\n| [docker network create](../network_create/index)         | Create a network                                     |\n| [docker network disconnect](../network_disconnect/index) | Disconnect a container from a network                |\n| [docker network inspect](../network_inspect/index)       | Display detailed information on one or more networks |\n| [docker network ls](../network_ls/index)                 | List networks                                        |\n| [docker network prune](../network_prune/index)           | Remove all unused networks                           |\n| [docker network rm](index)                               | Remove one or more networks                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/network_rm/](https://docs.docker.com/engine/reference/commandline/network_rm/)"
- name: docker node
  id: engine/reference/commandline/node/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node\n\n  \n\nManage Swarm nodes\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node COMMAND\n```\n\n## Description\n\nManage nodes.\n\n## Child commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node/](https://docs.docker.com/engine/reference/commandline/node/)"
- name: docker node demote
  id: engine/reference/commandline/node_demote/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node demote\n\n  \n\nDemote one or more nodes from manager in the swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node demote NODE [NODE...]\n```\n\n## Description\n\nDemotes an existing manager so that it is no longer a manager.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker node demote <node name>\n```\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](index)                  | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_demote/](https://docs.docker.com/engine/reference/commandline/node_demote/)"
- name: docker node inspect
  id: engine/reference/commandline/node_inspect/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node inspect\n\n  \n\nDisplay detailed information on one or more nodes\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node inspect [OPTIONS] self|NODE [NODE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nReturns information about a node. By default, this command renders all results in a JSON array. You can specify an alternate format to execute a given template for each result. Go’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                      |\n|-------------------|---------|--------------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template    |\n| `--pretty`        |         | Print the information in a human friendly format |\n\n## Examples\n\n### Inspect a node\n\n``` \n$ docker node inspect swarm-manager\n```\n\n``` \n[\n  {\n    \"ID\": \"e216jshn25ckzbvmwlnh5jr3g\",\n    \"Version\": {\n      \"Index\": 10\n    },\n    \"CreatedAt\": \"2017-05-16T22:52:44.9910662Z\",\n    \"UpdatedAt\": \"2017-05-16T22:52:45.230878043Z\",\n    \"Spec\": {\n      \"Role\": \"manager\",\n      \"Availability\": \"active\"\n    },\n    \"Description\": {\n      \"Hostname\": \"swarm-manager\",\n      \"Platform\": {\n        \"Architecture\": \"x86_64\",\n        \"OS\": \"linux\"\n      },\n      \"Resources\": {\n        \"NanoCPUs\": 1000000000,\n        \"MemoryBytes\": 1039843328\n      },\n      \"Engine\": {\n        \"EngineVersion\": \"17.06.0-ce\",\n        \"Plugins\": [\n          {\n            \"Type\": \"Volume\",\n            \"Name\": \"local\"\n          },\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"overlay\"\n          },\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"null\"\n          },\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"host\"\n          },\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"bridge\"\n          },\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"overlay\"\n          }\n        ]\n      },\n      \"TLSInfo\": {\n        \"TrustRoot\": \"-----BEGIN CERTIFICATE-----\\nMIIBazCCARCgAwIBAgIUOzgqU4tA2q5Yv1HnkzhSIwGyIBswCgYIKoZIzj0EAwIw\\nEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMTcwNTAyMDAyNDAwWhcNMzcwNDI3MDAy\\nNDAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH\\nA0IABMbiAmET+HZyve35ujrnL2kOLBEQhFDZ5MhxAuYs96n796sFlfxTxC1lM/2g\\nAh8DI34pm3JmHgZxeBPKUURJHKWjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB\\nAf8EBTADAQH/MB0GA1UdDgQWBBS3sjTJOcXdkls6WSY2rTx1KIJueTAKBggqhkjO\\nPQQDAgNJADBGAiEAoeVWkaXgSUAucQmZ3Yhmx22N/cq1EPBgYHOBZmHt0NkCIQC3\\nzONcJ/+WA21OXtb+vcijpUOXtNjyHfcox0N8wsLDqQ==\\n-----END CERTIFICATE-----\\n\",\n        \"CertIssuerSubject\": \"MBMxETAPBgNVBAMTCHN3YXJtLWNh\",\n        \"CertIssuerPublicKey\": \"MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAExuICYRP4dnK97fm6OucvaQ4sERCEUNnkyHEC5iz3qfv3qwWV/FPELWUz/aACHwMjfimbcmYeBnF4E8pRREkcpQ==\"\n      }\n    },\n    \"Status\": {\n      \"State\": \"ready\",\n      \"Addr\": \"168.0.32.137\"\n    },\n    \"ManagerStatus\": {\n      \"Leader\": true,\n      \"Reachability\": \"reachable\",\n      \"Addr\": \"168.0.32.137:2377\"\n    }\n  }\n]\n```\n\n### Specify an output format\n\n``` \n$ docker node inspect --format '{{ .ManagerStatus.Leader }}' self\n\nfalse\n```\n\nUse `--format=pretty` or the `--pretty` shorthand to pretty-print the output:\n\n``` \n$ docker node inspect --format=pretty self\n\nID:                     e216jshn25ckzbvmwlnh5jr3g\nHostname:               swarm-manager\nJoined at:              2017-05-16 22:52:44.9910662 +0000 utc\nStatus:\n State:                 Ready\n Availability:          Active\n Address:               172.17.0.2\nManager Status:\n Address:               172.17.0.2:2377\n Raft Status:           Reachable\n Leader:                Yes\nPlatform:\n Operating System:      linux\n Architecture:          x86_64\nResources:\n CPUs:                  4\n Memory:                7.704 GiB\nPlugins:\n  Network:              overlay, bridge, null, host, overlay\n  Volume:               local\nEngine Version:         17.06.0-ce\nTLS Info:\n TrustRoot:\n-----BEGIN CERTIFICATE-----\nMIIBazCCARCgAwIBAgIUOzgqU4tA2q5Yv1HnkzhSIwGyIBswCgYIKoZIzj0EAwIw\nEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMTcwNTAyMDAyNDAwWhcNMzcwNDI3MDAy\nNDAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH\nA0IABMbiAmET+HZyve35ujrnL2kOLBEQhFDZ5MhxAuYs96n796sFlfxTxC1lM/2g\nAh8DI34pm3JmHgZxeBPKUURJHKWjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBS3sjTJOcXdkls6WSY2rTx1KIJueTAKBggqhkjO\nPQQDAgNJADBGAiEAoeVWkaXgSUAucQmZ3Yhmx22N/cq1EPBgYHOBZmHt0NkCIQC3\nzONcJ/+WA21OXtb+vcijpUOXtNjyHfcox0N8wsLDqQ==\n-----END CERTIFICATE-----\n\n Issuer Public Key: MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAExuICYRP4dnK97fm6OucvaQ4sERCEUNnkyHEC5iz3qfv3qwWV/FPELWUz/aACHwMjfimbcmYeBnF4E8pRREkcpQ==\n Issuer Subject:    MBMxETAPBgNVBAMTCHN3YXJtLWNh\n```\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](index)                 | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_inspect/](https://docs.docker.com/engine/reference/commandline/node_inspect/)"
- name: docker node ls
  id: engine/reference/commandline/node_ls/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node ls\n\n  \n\nList nodes in the swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists all the nodes that the Docker Swarm manager knows about. You can filter using the `-f` or `--filter` flag. Refer to the [filtering](#filtering) section for more information about available filter options.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print nodes using a Go template     |\n| `--quiet` , `-q`  |         | Only display IDs                           |\n\n## Examples\n\n``` \n$ docker node ls\n\nID                           HOSTNAME        STATUS  AVAILABILITY  MANAGER STATUS\n1bcef6utixb0l0ca7gxuivsj0    swarm-worker2   Ready   Active\n38ciaotwjuritcdtn9npbnkuz    swarm-worker1   Ready   Active\ne216jshn25ckzbvmwlnh5jr3g *  swarm-manager1  Ready   Active        Leader\n```\n\n> **Note**\n>\n> In the above example output, there is a hidden column of `.Self` that indicates if the node is the same node as the current docker daemon. A `*` (e.g., `e216jshn25ckzbvmwlnh5jr3g *`) means this node is the current docker daemon.\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- [id](#id)\n- [label](#label)\n- [node.label](#nodelabel)\n- [membership](#membership)\n- [name](#name)\n- [role](#role)\n\n#### id\n\nThe `id` filter matches all or part of a node’s id.\n\n``` \n$ docker node ls -f id=1\n\nID                         HOSTNAME       STATUS  AVAILABILITY  MANAGER STATUS\n1bcef6utixb0l0ca7gxuivsj0  swarm-worker2  Ready   Active\n```\n\n#### label\n\nThe `label` filter matches nodes based on engine labels and on the presence of a `label` alone or a `label` and a value. Engine labels are configured in the [daemon configuration](../dockerd/index#daemon-configuration-file). To filter on Swarm `node` labels, use [`node.label` instead](#nodelabel).\n\nThe following filter matches nodes with the `foo` label regardless of its value.\n\n``` \n$ docker node ls -f \"label=foo\"\n\nID                         HOSTNAME       STATUS  AVAILABILITY  MANAGER STATUS\n1bcef6utixb0l0ca7gxuivsj0  swarm-worker2  Ready   Active\n```\n\n#### node.label\n\nThe `node.label` filter matches nodes based on node labels and on the presence of a `node.label` alone or a `node.label` and a value.\n\nThe following filter updates nodes to have a `region` node label:\n\n``` \n$ docker node update --label-add region=region-a swarm-test-01\n$ docker node update --label-add region=region-a swarm-test-02\n$ docker node update --label-add region=region-b swarm-test-03\n$ docker node update --label-add region=region-b swarm-test-04\n```\n\nShow all nodes that have a `region` node label set:\n\n``` \n$ docker node ls --filter node.label=region\n\nID                            HOSTNAME        STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION\nyg550ettvsjn6g6t840iaiwgb *   swarm-test-01   Ready     Active         Leader           20.10.2\n2lm9w9kbepgvkzkkeyku40e65     swarm-test-02   Ready     Active         Reachable        20.10.2\nhc0pu7ntc7s4uvj4pv7z7pz15     swarm-test-03   Ready     Active         Reachable        20.10.2\nn41b2cijmhifxxvz56vwrs12q     swarm-test-04   Ready     Active                          20.10.2\n```\n\nShow all nodes that have a `region` node label, with value `region-a`:\n\n``` \n$ docker node ls --filter node.label=region=region-a\n\nID                            HOSTNAME        STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION\nyg550ettvsjn6g6t840iaiwgb *   swarm-test-01   Ready     Active         Leader           20.10.2\n2lm9w9kbepgvkzkkeyku40e65     swarm-test-02   Ready     Active         Reachable        20.10.2\n```\n\n#### membership\n\nThe `membership` filter matches nodes based on the presence of a `membership` and a value `accepted` or `pending`.\n\nThe following filter matches nodes with the `membership` of `accepted`.\n\n``` \n$ docker node ls -f \"membership=accepted\"\n\nID                           HOSTNAME        STATUS  AVAILABILITY  MANAGER STATUS\n1bcef6utixb0l0ca7gxuivsj0    swarm-worker2   Ready   Active\n38ciaotwjuritcdtn9npbnkuz    swarm-worker1   Ready   Active\n```\n\n#### name\n\nThe `name` filter matches on all or part of a node hostname.\n\nThe following filter matches the nodes with a name equal to `swarm-master` string.\n\n``` \n$ docker node ls -f name=swarm-manager1\n\nID                           HOSTNAME        STATUS  AVAILABILITY  MANAGER STATUS\ne216jshn25ckzbvmwlnh5jr3g *  swarm-manager1  Ready   Active        Leader\n```\n\n#### role\n\nThe `role` filter matches nodes based on the presence of a `role` and a value `worker` or `manager`.\n\nThe following filter matches nodes with the `manager` role.\n\n``` \n$ docker node ls -f \"role=manager\"\n\nID                           HOSTNAME        STATUS  AVAILABILITY  MANAGER STATUS\ne216jshn25ckzbvmwlnh5jr3g *  swarm-manager1  Ready   Active        Leader\n```\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints nodes output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder      | Description                                                                                           |\n|------------------|-------------------------------------------------------------------------------------------------------|\n| `.ID`            | Node ID                                                                                               |\n| `.Self`          | Node of the daemon (`true/false`, `true`indicates that the node is the same as current docker daemon) |\n| `.Hostname`      | Node hostname                                                                                         |\n| `.Status`        | Node status                                                                                           |\n| `.Availability`  | Node availability (“active”, “pause”, or “drain”)                                                     |\n| `.ManagerStatus` | Manager status of the node                                                                            |\n| `.TLSStatus`     | TLS status of the node (“Ready”, or “Needs Rotation” has TLS certificate signed by an old CA)         |\n| `.EngineVersion` | Engine version                                                                                        |\n\nWhen using the `--format` option, the `node ls` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `ID`, `Hostname`, and `TLS Status` entries separated by a colon (`:`) for all nodes:\n\n``` \n$ docker node ls --format \"{{.ID}}: {{.Hostname}} {{.TLSStatus}}\"\n\ne216jshn25ckzbvmwlnh5jr3g: swarm-manager1 Ready\n35o6tiywb700jesrt3dmllaza: swarm-worker1 Needs Rotation\n```\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](index)                      | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_ls/](https://docs.docker.com/engine/reference/commandline/node_ls/)"
- name: docker node promote
  id: engine/reference/commandline/node_promote/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node promote\n\n  \n\nPromote one or more nodes to manager in the swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node promote NODE [NODE...]\n```\n\n## Description\n\nPromotes a node to manager. This command can only be executed on a manager node.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker node promote <node name>\n```\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](index)                 | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_promote/](https://docs.docker.com/engine/reference/commandline/node_promote/)"
- name: docker node ps
  id: engine/reference/commandline/node_ps/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node ps\n\n  \n\nList tasks running on one or more nodes, defaults to current node\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node ps [OPTIONS] [NODE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists all the tasks on a Node that Docker knows about. You can filter using the `-f` or `--filter` flag. Refer to the [filtering](#filtering) section for more information about available filter options.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print tasks using a Go template     |\n| `--no-resolve`    |         | Do not map IDs to Names                    |\n| `--no-trunc`      |         | Do not truncate output                     |\n| `--quiet` , `-q`  |         | Only display task IDs                      |\n\n## Examples\n\n``` \n$ docker node ps swarm-manager1\n\nNAME                                IMAGE        NODE            DESIRED STATE  CURRENT STATE\nredis.1.7q92v0nr1hcgts2amcjyqg3pq   redis:3.0.6  swarm-manager1  Running        Running 5 hours\nredis.6.b465edgho06e318egmgjbqo4o   redis:3.0.6  swarm-manager1  Running        Running 29 seconds\nredis.7.bg8c07zzg87di2mufeq51a2qp   redis:3.0.6  swarm-manager1  Running        Running 5 seconds\nredis.9.dkkual96p4bb3s6b10r7coxxt   redis:3.0.6  swarm-manager1  Running        Running 5 seconds\nredis.10.0tgctg8h8cech4w0k0gwrmr23  redis:3.0.6  swarm-manager1  Running        Running 5 seconds\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- [name](#name)\n- [id](#id)\n- [label](#label)\n- [desired-state](#desired-state)\n\n#### name\n\nThe `name` filter matches on all or part of a task’s name.\n\nThe following filter matches all tasks with a name containing the `redis` string.\n\n``` \n$ docker node ps -f name=redis swarm-manager1\n\nNAME                                IMAGE        NODE            DESIRED STATE  CURRENT STATE\nredis.1.7q92v0nr1hcgts2amcjyqg3pq   redis:3.0.6  swarm-manager1  Running        Running 5 hours\nredis.6.b465edgho06e318egmgjbqo4o   redis:3.0.6  swarm-manager1  Running        Running 29 seconds\nredis.7.bg8c07zzg87di2mufeq51a2qp   redis:3.0.6  swarm-manager1  Running        Running 5 seconds\nredis.9.dkkual96p4bb3s6b10r7coxxt   redis:3.0.6  swarm-manager1  Running        Running 5 seconds\nredis.10.0tgctg8h8cech4w0k0gwrmr23  redis:3.0.6  swarm-manager1  Running        Running 5 seconds\n```\n\n#### id\n\nThe `id` filter matches a task’s id.\n\n``` \n$ docker node ps -f id=bg8c07zzg87di2mufeq51a2qp swarm-manager1\n\nNAME                                IMAGE        NODE            DESIRED STATE  CURRENT STATE\nredis.7.bg8c07zzg87di2mufeq51a2qp   redis:3.0.6  swarm-manager1  Running        Running 5 seconds\n```\n\n#### label\n\nThe `label` filter matches tasks based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches tasks with the `usage` label regardless of its value.\n\n``` \n$ docker node ps -f \"label=usage\"\n\nNAME                               IMAGE        NODE            DESIRED STATE  CURRENT STATE\nredis.6.b465edgho06e318egmgjbqo4o  redis:3.0.6  swarm-manager1  Running        Running 10 minutes\nredis.7.bg8c07zzg87di2mufeq51a2qp  redis:3.0.6  swarm-manager1  Running        Running 9 minutes\n```\n\n#### desired-state\n\nThe `desired-state` filter can take the values `running`, `shutdown`, or `accepted`.\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints tasks output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder     | Description                                                      |\n|-----------------|------------------------------------------------------------------|\n| `.ID`           | Task ID                                                          |\n| `.Name`         | Task name                                                        |\n| `.Image`        | Task image                                                       |\n| `.Node`         | Node ID                                                          |\n| `.DesiredState` | Desired state of the task (`running`, `shutdown`, or `accepted`) |\n| `.CurrentState` | Current state of the task                                        |\n| `.Error`        | Error                                                            |\n| `.Ports`        | Task published ports                                             |\n\nWhen using the `--format` option, the `node ps` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `Name` and `Image` entries separated by a colon (`:`) for all tasks:\n\n``` \n$ docker node ps --format \"{{.Name}}: {{.Image}}\"\n\ntop.1: busybox\ntop.2: busybox\ntop.3: busybox\n```\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](index)                      | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_ps/](https://docs.docker.com/engine/reference/commandline/node_ps/)"
- name: docker node rm
  id: engine/reference/commandline/node_rm/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node rm\n\n  \n\nRemove one or more nodes from the swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node rm [OPTIONS] NODE [NODE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemoves the specified nodes from a swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                        |\n|------------------|---------|------------------------------------|\n| `--force` , `-f` |         | Force remove a node from the swarm |\n\n## Examples\n\n### Remove a stopped node from the swarm\n\n``` \n$ docker node rm swarm-node-02\n\nNode swarm-node-02 removed from swarm\n```\n\n### Attempt to remove a running node from a swarm\n\nRemoves the specified nodes from the swarm, but only if the nodes are in the down state. If you attempt to remove an active node you will receive an error:\n\n``` \n$ docker node rm swarm-node-03\n\nError response from daemon: rpc error: code = 9 desc = node swarm-node-03 is not\ndown and can't be removed\n```\n\n### Forcibly remove an inaccessible node from a swarm\n\nIf you lose access to a worker node or need to shut it down because it has been compromised or is not behaving as expected, you can use the `--force` option. This may cause transient errors or interruptions, depending on the type of task being run on the node.\n\n``` \n$ docker node rm --force swarm-node-03\n\nNode swarm-node-03 removed from swarm\n```\n\nA manager node must be demoted to a worker node (using `docker node demote`) before you can remove it from the swarm.\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](index)                      | Remove one or more nodes from the swarm                           |\n| [docker node update](../node_update/index)   | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_rm/](https://docs.docker.com/engine/reference/commandline/node_rm/)"
- name: docker node update
  id: engine/reference/commandline/node_update/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker node update\n\n  \n\nUpdate a node\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker node update [OPTIONS] NODE\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUpdate metadata about a node, such as its availability, labels, or roles.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                           |\n|------------------|---------|-------------------------------------------------------|\n| `--availability` |         | Availability of the node (\"active\"\\|\"pause\"\\|\"drain\") |\n| `--label-add`    |         | Add or update a node label (key=value)                |\n| `--label-rm`     |         | Remove a node label if exists                         |\n| `--role`         |         | Role of the node (\"worker\"\\|\"manager\")                |\n\n## Examples\n\n### Add label metadata to a node\n\nAdd metadata to a swarm node using node labels. You can specify a node label as a key with an empty value:\n\n``` \n$ docker node update --label-add foo worker1\n```\n\nTo add multiple labels to a node, pass the `--label-add` flag for each label:\n\n``` \n$ docker node update --label-add foo --label-add bar worker1\n```\n\nWhen you [create a service](../service_create/index), you can use node labels as a constraint. A constraint limits the nodes where the scheduler deploys tasks for a service.\n\nFor example, to add a `type` label to identify nodes where the scheduler should deploy message queue service tasks:\n\n``` \n$ docker node update --label-add type=queue worker1\n```\n\nThe labels you set for nodes using `docker node update` apply only to the node entity within the swarm. Do not confuse them with the docker daemon labels for [dockerd](../dockerd/index).\n\nFor more information about labels, refer to [apply custom metadata](https://docs.docker.com/config).\n\n## Parent command\n\n| Command                      | Description        |\n|:-----------------------------|:-------------------|\n| [docker node](../node/index) | Manage Swarm nodes |\n\n## Related commands\n\n| Command                                      | Description                                                       |\n|----------------------------------------------|-------------------------------------------------------------------|\n| [docker node demote](../node_demote/index)   | Demote one or more nodes from manager in the swarm                |\n| [docker node inspect](../node_inspect/index) | Display detailed information on one or more nodes                 |\n| [docker node ls](../node_ls/index)           | List nodes in the swarm                                           |\n| [docker node promote](../node_promote/index) | Promote one or more nodes to manager in the swarm                 |\n| [docker node ps](../node_ps/index)           | List tasks running on one or more nodes, defaults to current node |\n| [docker node rm](../node_rm/index)           | Remove one or more nodes from the swarm                           |\n| [docker node update](index)                  | Update a node                                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/node_update/](https://docs.docker.com/engine/reference/commandline/node_update/)"
- name: Docker overview
  id: get-started/overview/index
  summary: Docker is an open platform for developing, shipping, and running applications
  description: "# Docker overview\n\nDocker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker’s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.\n\n## The Docker platform\n\nDocker provides the ability to package and run an application in a loosely isolated environment called a container. The isolation and security allows you to run many containers simultaneously on a given host. Containers are lightweight and contain everything needed to run the application, so you do not need to rely on what is currently installed on the host. You can easily share containers while you work, and be sure that everyone you share with gets the same container that works in the same way.\n\nDocker provides tooling and a platform to manage the lifecycle of your containers:\n\n- Develop your application and its supporting components using containers.\n- The container becomes the unit for distributing and testing your application.\n- When you’re ready, deploy your application into your production environment, as a container or an orchestrated service. This works the same whether your production environment is a local data center, a cloud provider, or a hybrid of the two.\n\n## What can I use Docker for?\n\n**Fast, consistent delivery of your applications**\n\nDocker streamlines the development lifecycle by allowing developers to work in standardized environments using local containers which provide your applications and services. Containers are great for continuous integration and continuous delivery (CI/CD) workflows.\n\nConsider the following example scenario:\n\n- Your developers write code locally and share their work with their colleagues using Docker containers.\n- They use Docker to push their applications into a test environment and execute automated and manual tests.\n- When developers find bugs, they can fix them in the development environment and redeploy them to the test environment for testing and validation.\n- When testing is complete, getting the fix to the customer is as simple as pushing the updated image to the production environment.\n\n**Responsive deployment and scaling**\n\nDocker’s container-based platform allows for highly portable workloads. Docker containers can run on a developer’s local laptop, on physical or virtual machines in a data center, on cloud providers, or in a mixture of environments.\n\nDocker’s portability and lightweight nature also make it easy to dynamically manage workloads, scaling up or tearing down applications and services as business needs dictate, in near real time.\n\n**Running more workloads on the same hardware**\n\nDocker is lightweight and fast. It provides a viable, cost-effective alternative to hypervisor-based virtual machines, so you can use more of your compute capacity to achieve your business goals. Docker is perfect for high density environments and for small and medium deployments where you need to do more with fewer resources.\n\n## Docker architecture\n\nDocker uses a client-server architecture. The Docker *client* talks to the Docker *daemon*, which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon *can* run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface. Another Docker client is Docker Compose, that lets you work with applications consisting of a set of containers.\n\n### The Docker daemon\n\nThe Docker daemon (`dockerd`) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.\n\n### The Docker client\n\nThe Docker client (`docker`) is the primary way that many Docker users interact with Docker. When you use commands such as `docker run`, the client sends these commands to `dockerd`, which carries them out. The `docker` command uses the Docker API. The Docker client can communicate with more than one daemon.\n\n### Docker Desktop\n\nDocker Desktop is an easy-to-install application for your Mac or Windows environment that enables you to build and share containerized applications and microservices. Docker Desktop includes the Docker daemon (`dockerd`), the Docker client (`docker`), Docker Compose, Docker Content Trust, Kubernetes, and Credential Helper. For more information, see [Docker Desktop](https://docs.docker.com/desktop/).\n\n### Docker registries\n\nA Docker *registry* stores Docker images. Docker Hub is a public registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry.\n\nWhen you use the `docker pull` or `docker run` commands, the required images are pulled from your configured registry. When you use the `docker push` command, your image is pushed to your configured registry.\n\n### Docker objects\n\nWhen you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects. This section is a brief overview of some of those objects.\n\n#### Images\n\nAn *image* is a read-only template with instructions for creating a Docker container. Often, an image is *based on* another image, with some additional customization. For example, you may build an image which is based on the `ubuntu` image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.\n\nYou might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a *Dockerfile* with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.\n\n#### Containers\n\nA container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.\n\nBy default, a container is relatively well isolated from other containers and its host machine. You can control how isolated a container’s network, storage, or other underlying subsystems are from other containers or from the host machine.\n\nA container is defined by its image as well as any configuration options you provide to it when you create or start it. When a container is removed, any changes to its state that are not stored in persistent storage disappear.\n\n##### Example `docker run` command\n\nThe following command runs an `ubuntu` container, attaches interactively to your local command-line session, and runs `/bin/bash`.\n\n``` \n$ docker run -i -t ubuntu /bin/bash\n```\n\nWhen you run this command, the following happens (assuming you are using the default registry configuration):\n\n1.  If you do not have the `ubuntu` image locally, Docker pulls it from your configured registry, as though you had run `docker pull ubuntu` manually.\n\n2.  Docker creates a new container, as though you had run a `docker container create` command manually.\n\n3.  Docker allocates a read-write filesystem to the container, as its final layer. This allows a running container to create or modify files and directories in its local filesystem.\n\n4.  Docker creates a network interface to connect the container to the default network, since you did not specify any networking options. This includes assigning an IP address to the container. By default, containers can connect to external networks using the host machine’s network connection.\n\n5.  Docker starts the container and executes `/bin/bash`. Because the container is running interactively and attached to your terminal (due to the `-i` and `-t` flags), you can provide input using your keyboard while the output is logged to your terminal.\n\n6.  When you type `exit` to terminate the `/bin/bash` command, the container stops but is not removed. You can start it again or remove it.\n\n## The underlying technology\n\nDocker is written in the [Go programming language](https://golang.org/) and takes advantage of several features of the Linux kernel to deliver its functionality. Docker uses a technology called `namespaces` to provide the isolated workspace called the *container*. When you run a container, Docker creates a set of *namespaces* for that container.\n\nThese namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace.\n\n## Next steps\n\n- Read about [installing Docker](https://docs.docker.com/get-docker/).\n- Get hands-on experience with the [Getting started with Docker](../index) tutorial.\n\n[docker](https://docs.docker.com/search/?q=docker), [introduction](https://docs.docker.com/search/?q=introduction), [documentation](https://docs.docker.com/search/?q=documentation), [about](https://docs.docker.com/search/?q=about), [technology](https://docs.docker.com/search/?q=technology), [understanding](https://docs.docker.com/search/?q=understanding)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/overview/](https://docs.docker.com/get-started/overview/)"
- name: docker pause
  id: engine/reference/commandline/pause/index
  summary: The docker pause command suspends all processes in the specified containers
  description: "# docker pause\n\n  \n\nPause all processes within one or more containers\n\n## Usage\n\n``` \n$ docker pause CONTAINER [CONTAINER...]\n```\n\n## Description\n\nThe `docker pause` command suspends all processes in the specified containers. On Linux, this uses the freezer cgroup. Traditionally, when suspending a process the `SIGSTOP` signal is used, which is observable by the process being suspended. With the freezer cgroup the process is unaware, and unable to capture, that it is being suspended, and subsequently resumed. On Windows, only Hyper-V containers can be paused.\n\nSee the [freezer cgroup documentation](https://www.kernel.org/doc/Documentation/cgroup-v1/freezer-subsystem.txt) for further details.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker pause my_container\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/pause/](https://docs.docker.com/engine/reference/commandline/pause/)"
- name: docker plugin
  id: engine/reference/commandline/plugin/index
  summary: Manage plugins
  description: "# docker plugin\n\n  \n\nManage plugins\n\n## Usage\n\n``` \n$ docker plugin COMMAND\n```\n\n## Description\n\nManage plugins.\n\n## Child commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin/](https://docs.docker.com/engine/reference/commandline/plugin/)"
- name: Docker Plugin API
  id: engine/extend/plugin_api/index
  summary: Docker plugins are out-of-process extensions which add capabilities to the Docker Engine
  description: "# Docker Plugin API\n\nDocker plugins are out-of-process extensions which add capabilities to the Docker Engine.\n\nThis document describes the Docker Engine plugin API. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](../index).\n\nThis page is intended for people who want to develop their own Docker plugin. If you just want to learn about or use Docker plugins, look [here](../legacy_plugins/index).\n\n## What plugins are\n\nA plugin is a process running on the same or a different host as the docker daemon, which registers itself by placing a file on the same docker host in one of the plugin directories described in [Plugin discovery](#plugin-discovery).\n\nPlugins have human-readable names, which are short, lowercase strings. For example, `flocker` or `weave`.\n\nPlugins can run inside or outside containers. Currently running them outside containers is recommended.\n\n## Plugin discovery\n\nDocker discovers plugins by looking for them in the plugin directory whenever a user or container tries to use one by name.\n\nThere are three types of files which can be put in the plugin directory.\n\n- `.sock` files are UNIX domain sockets.\n- `.spec` files are text files containing a URL, such as `unix:///other.sock` or `tcp://localhost:8080`.\n- `.json` files are text files containing a full json specification for the plugin.\n\nPlugins with UNIX domain socket files must run on the same docker host, whereas plugins with spec or json files can run on a different host if a remote URL is specified.\n\nUNIX domain socket files must be located under `/run/docker/plugins`, whereas spec files can be located either under `/etc/docker/plugins` or `/usr/lib/docker/plugins`.\n\nThe name of the file (excluding the extension) determines the plugin name.\n\nFor example, the `flocker` plugin might create a UNIX socket at `/run/docker/plugins/flocker.sock`.\n\nYou can define each plugin into a separated subdirectory if you want to isolate definitions from each other. For example, you can create the `flocker` socket under `/run/docker/plugins/flocker/flocker.sock` and only mount `/run/docker/plugins/flocker` inside the `flocker` container.\n\nDocker always searches for unix sockets in `/run/docker/plugins` first. It checks for spec or json files under `/etc/docker/plugins` and `/usr/lib/docker/plugins` if the socket doesn’t exist. The directory scan stops as soon as it finds the first plugin definition with the given name.\n\n### JSON specification\n\nThis is the JSON format for a plugin:\n\n``` \n{\n  \"Name\": \"plugin-example\",\n  \"Addr\": \"https://example.com/docker/plugin\",\n  \"TLSConfig\": {\n    \"InsecureSkipVerify\": false,\n    \"CAFile\": \"/usr/shared/docker/certs/example-ca.pem\",\n    \"CertFile\": \"/usr/shared/docker/certs/example-cert.pem\",\n    \"KeyFile\": \"/usr/shared/docker/certs/example-key.pem\"\n  }\n}\n```\n\nThe `TLSConfig` field is optional and TLS will only be verified if this configuration is present.\n\n## Plugin lifecycle\n\nPlugins should be started before Docker, and stopped after Docker. For example, when packaging a plugin for a platform which supports `systemd`, you might use [`systemd` dependencies](https://www.freedesktop.org/software/systemd/man/systemd.unit.html#Before=) to manage startup and shutdown order.\n\nWhen upgrading a plugin, you should first stop the Docker daemon, upgrade the plugin, then start Docker again.\n\n## Plugin activation\n\nWhen a plugin is first referred to -- either by a user referring to it by name (e.g. `docker run --volume-driver=foo`) or a container already configured to use a plugin being started -- Docker looks for the named plugin in the plugin directory and activates it with a handshake. See Handshake API below.\n\nPlugins are *not* activated automatically at Docker daemon startup. Rather, they are activated only lazily, or on-demand, when they are needed.\n\n## Systemd socket activation\n\nPlugins may also be socket activated by `systemd`. The official [Plugins helpers](https://github.com/docker/go-plugins-helpers) natively supports socket activation. In order for a plugin to be socket activated it needs a `service` file and a `socket` file.\n\nThe `service` file (for example `/lib/systemd/system/your-plugin.service`):\n\n``` \n[Unit]\nDescription=Your plugin\nBefore=docker.service\nAfter=network.target your-plugin.socket\nRequires=your-plugin.socket docker.service\n\n[Service]\nExecStart=/usr/lib/docker/your-plugin\n\n[Install]\nWantedBy=multi-user.target\n```\n\nThe `socket` file (for example `/lib/systemd/system/your-plugin.socket`):\n\n``` \n[Unit]\nDescription=Your plugin\n\n[Socket]\nListenStream=/run/docker/plugins/your-plugin.sock\n\n[Install]\nWantedBy=sockets.target\n```\n\nThis will allow plugins to be actually started when the Docker daemon connects to the sockets they’re listening on (for instance the first time the daemon uses them or if one of the plugin goes down accidentally).\n\n## API design\n\nThe Plugin API is RPC-style JSON over HTTP, much like webhooks.\n\nRequests flow *from* the Docker daemon *to* the plugin. So the plugin needs to implement an HTTP server and bind this to the UNIX socket mentioned in the “plugin discovery” section.\n\nAll requests are HTTP `POST` requests.\n\nThe API is versioned via an Accept header, which currently is always set to `application/vnd.docker.plugins.v1+json`.\n\n## Handshake API\n\nPlugins are activated via the following “handshake” API call.\n\n### /Plugin.Activate\n\n**Request:** empty body\n\n**Response:**\n\n``` \n{\n    \"Implements\": [\"VolumeDriver\"]\n}\n```\n\nResponds with a list of Docker subsystems which this plugin implements. After activation, the plugin will then be sent events from this subsystem.\n\nPossible values are:\n\n- [`authz`](../plugins_authorization/index)\n- [`NetworkDriver`](../plugins_network/index)\n- [`VolumeDriver`](../plugins_volume/index)\n\n## Plugin retries\n\nAttempts to call a method on a plugin are retried with an exponential backoff for up to 30 seconds. This may help when packaging plugins as containers, since it gives plugin containers a chance to start up before failing any user containers which depend on them.\n\n## Plugins helpers\n\nTo ease plugins development, we’re providing an `sdk` for each kind of plugins currently supported by Docker at [docker/go-plugins-helpers](https://github.com/docker/go-plugins-helpers).\n\n[API](https://docs.docker.com/search/?q=API), [Usage](https://docs.docker.com/search/?q=Usage), [plugins](https://docs.docker.com/search/?q=plugins), [documentation](https://docs.docker.com/search/?q=documentation), [developer](https://docs.docker.com/search/?q=developer)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/plugin_api/](https://docs.docker.com/engine/extend/plugin_api/)"
- name: docker plugin create
  id: engine/reference/commandline/plugin_create/index
  summary: Create a plugin from a rootfs and configuration
  description: "# docker plugin create\n\n  \n\nCreate a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory.\n\n## Usage\n\n``` \n$ docker plugin create [OPTIONS] PLUGIN PLUGIN-DATA-DIR\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a plugin. Before creating the plugin, prepare the plugin’s root filesystem as well as [the config.json](../../../extend/config/index)\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                     |\n|-----------------|---------|---------------------------------|\n| `--compress`    |         | Compress the context using gzip |\n\n## Examples\n\nThe following example shows how to create a sample `plugin`.\n\n``` \n$ ls -ls /home/pluginDir\n\ntotal 4\n4 -rw-r--r--  1 root root 431 Nov  7 01:40 config.json\n0 drwxr-xr-x 19 root root 420 Nov  7 01:40 rootfs\n\n$ docker plugin create plugin /home/pluginDir\n\nplugin\n\n$ docker plugin ls\n\nID              NAME            DESCRIPTION                  ENABLED\n672d8144ec02    plugin:latest   A sample plugin for Docker   false\n```\n\nThe plugin can subsequently be enabled for local use or pushed to the public registry.\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](index)                    | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_create/](https://docs.docker.com/engine/reference/commandline/plugin_create/)"
- name: docker plugin disable
  id: engine/reference/commandline/plugin_disable/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin disable\n\n  \n\nDisable a plugin\n\n## Usage\n\n``` \n$ docker plugin disable [OPTIONS] PLUGIN\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nDisables a plugin. The plugin must be installed before it can be disabled, see [`docker plugin install`](../plugin_install/index). Without the `-f` option, a plugin that has references (e.g., volumes, networks) cannot be disabled.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                           |\n|------------------|---------|---------------------------------------|\n| `--force` , `-f` |         | Force the disable of an active plugin |\n\n## Examples\n\nThe following example shows that the `sample-volume-plugin` plugin is installed and enabled:\n\n``` \n$ docker plugin ls\n\nID            NAME                                    DESCRIPTION                ENABLED\n69553ca1d123  tiborvass/sample-volume-plugin:latest   A test plugin for Docker   true\n```\n\nTo disable the plugin, use the following command:\n\n``` \n$ docker plugin disable tiborvass/sample-volume-plugin\n\ntiborvass/sample-volume-plugin\n\n$ docker plugin ls\n\nID            NAME                                    DESCRIPTION                ENABLED\n69553ca1d123  tiborvass/sample-volume-plugin:latest   A test plugin for Docker   false\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](index)                   | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_disable/](https://docs.docker.com/engine/reference/commandline/plugin_disable/)"
- name: docker plugin enable
  id: engine/reference/commandline/plugin_enable/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin enable\n\n  \n\nEnable a plugin\n\n## Usage\n\n``` \n$ docker plugin enable [OPTIONS] PLUGIN\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nEnables a plugin. The plugin must be installed before it can be enabled, see [`docker plugin install`](../plugin_install/index).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                      |\n|-----------------|---------|----------------------------------|\n| `--timeout`     | `30`    | HTTP client timeout (in seconds) |\n\n## Examples\n\nThe following example shows that the `sample-volume-plugin` plugin is installed, but disabled:\n\n``` \n$ docker plugin ls\n\nID            NAME                                    DESCRIPTION                ENABLED\n69553ca1d123  tiborvass/sample-volume-plugin:latest   A test plugin for Docker   false\n```\n\nTo enable the plugin, use the following command:\n\n``` \n$ docker plugin enable tiborvass/sample-volume-plugin\n\ntiborvass/sample-volume-plugin\n\n$ docker plugin ls\n\nID            NAME                                    DESCRIPTION                ENABLED\n69553ca1d123  tiborvass/sample-volume-plugin:latest   A test plugin for Docker   true\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](index)                    | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_enable/](https://docs.docker.com/engine/reference/commandline/plugin_enable/)"
- name: docker plugin inspect
  id: engine/reference/commandline/plugin_inspect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin inspect\n\n  \n\nDisplay detailed information on one or more plugins\n\n## Usage\n\n``` \n$ docker plugin inspect [OPTIONS] PLUGIN [PLUGIN...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nReturns information about a plugin. By default, this command renders all results in a JSON array.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n\n## Examples\n\n### Inspect a plugin\n\nThe following example example inspects the `tiborvass/sample-volume-plugin` plugin:\n\n``` \n$ docker plugin inspect tiborvass/sample-volume-plugin:latest\n```\n\nOutput is in JSON format (output below is formatted for readability):\n\n``` \n{\n  \"Id\": \"8c74c978c434745c3ade82f1bc0acf38d04990eaf494fa507c16d9f1daa99c21\",\n  \"Name\": \"tiborvass/sample-volume-plugin:latest\",\n  \"PluginReference\": \"tiborvas/sample-volume-plugin:latest\",\n  \"Enabled\": true,\n  \"Config\": {\n    \"Mounts\": [\n      {\n        \"Name\": \"\",\n        \"Description\": \"\",\n        \"Settable\": null,\n        \"Source\": \"/data\",\n        \"Destination\": \"/data\",\n        \"Type\": \"bind\",\n        \"Options\": [\n          \"shared\",\n          \"rbind\"\n        ]\n      },\n      {\n        \"Name\": \"\",\n        \"Description\": \"\",\n        \"Settable\": null,\n        \"Source\": null,\n        \"Destination\": \"/foobar\",\n        \"Type\": \"tmpfs\",\n        \"Options\": null\n      }\n    ],\n    \"Env\": [\n      \"DEBUG=1\"\n    ],\n    \"Args\": null,\n    \"Devices\": null\n  },\n  \"Manifest\": {\n    \"ManifestVersion\": \"v0\",\n    \"Description\": \"A test plugin for Docker\",\n    \"Documentation\": \"https://docs.docker.com/engine/extend/plugins/\",\n    \"Interface\": {\n      \"Types\": [\n        \"docker.volumedriver/1.0\"\n      ],\n      \"Socket\": \"plugins.sock\"\n    },\n    \"Entrypoint\": [\n      \"plugin-sample-volume-plugin\",\n      \"/data\"\n    ],\n    \"Workdir\": \"\",\n    \"User\": {\n    },\n    \"Network\": {\n      \"Type\": \"host\"\n    },\n    \"Capabilities\": null,\n    \"Mounts\": [\n      {\n        \"Name\": \"\",\n        \"Description\": \"\",\n        \"Settable\": null,\n        \"Source\": \"/data\",\n        \"Destination\": \"/data\",\n        \"Type\": \"bind\",\n        \"Options\": [\n          \"shared\",\n          \"rbind\"\n        ]\n      },\n      {\n        \"Name\": \"\",\n        \"Description\": \"\",\n        \"Settable\": null,\n        \"Source\": null,\n        \"Destination\": \"/foobar\",\n        \"Type\": \"tmpfs\",\n        \"Options\": null\n      }\n    ],\n    \"Devices\": [\n      {\n        \"Name\": \"device\",\n        \"Description\": \"a host device to mount\",\n        \"Settable\": null,\n        \"Path\": \"/dev/cpu_dma_latency\"\n      }\n    ],\n    \"Env\": [\n      {\n        \"Name\": \"DEBUG\",\n        \"Description\": \"If set, prints debug messages\",\n        \"Settable\": null,\n        \"Value\": \"1\"\n      }\n    ],\n    \"Args\": {\n      \"Name\": \"args\",\n      \"Description\": \"command line arguments\",\n      \"Settable\": null,\n      \"Value\": [\n\n      ]\n    }\n  }\n}\n```\n\n### Formatting the output\n\n``` \n$ docker plugin inspect -f '{{.Id}}' tiborvass/sample-volume-plugin:latest\n\n8c74c978c434745c3ade82f1bc0acf38d04990eaf494fa507c16d9f1daa99c21\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](index)                   | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_inspect/](https://docs.docker.com/engine/reference/commandline/plugin_inspect/)"
- name: docker plugin install
  id: engine/reference/commandline/plugin_install/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin install\n\n  \n\nInstall a plugin\n\n## Usage\n\n``` \n$ docker plugin install [OPTIONS] PLUGIN [KEY=VALUE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nInstalls and enables a plugin. Docker looks first for the plugin on your Docker host. If the plugin does not exist locally, then the plugin is pulled from the registry. Note that the minimum required registry version to distribute plugins is 2.3.0\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default | Description                                       |\n|---------------------------|---------|---------------------------------------------------|\n| `--alias`                 |         | Local name for plugin                             |\n| `--disable`               |         | Do not enable the plugin on install               |\n| `--disable-content-trust` | `true`  | Skip image verification                           |\n| `--grant-all-permissions` |         | Grant all permissions necessary to run the plugin |\n\n## Examples\n\nThe following example installs `vieus/sshfs` plugin and [sets](../plugin_set/index) its `DEBUG` environment variable to `1`. To install, `pull` the plugin from Docker Hub and prompt the user to accept the list of privileges that the plugin needs, set the plugin’s parameters and enable the plugin.\n\n``` \n$ docker plugin install vieux/sshfs DEBUG=1\n\nPlugin \"vieux/sshfs\" is requesting the following privileges:\n - network: [host]\n - device: [/dev/fuse]\n - capabilities: [CAP_SYS_ADMIN]\nDo you grant the above permissions? [y/N] y\nvieux/sshfs\n```\n\nAfter the plugin is installed, it appears in the list of plugins:\n\n``` \n$ docker plugin ls\n\nID             NAME                  DESCRIPTION                ENABLED\n69553ca1d123   vieux/sshfs:latest    sshFS plugin for Docker    true\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](index)                   | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_install/](https://docs.docker.com/engine/reference/commandline/plugin_install/)"
- name: docker plugin ls
  id: engine/reference/commandline/plugin_ls/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin ls\n\n  \n\nList plugins\n\n## Usage\n\n``` \n$ docker plugin ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists all the plugins that are currently installed. You can install plugins using the [`docker plugin install`](../plugin_install/index) command. You can also filter using the `-f` or `--filter` flag. Refer to the [filtering](#filtering) section for more information about available filter options.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                 |\n|-------------------|---------|---------------------------------------------|\n| `--filter` , `-f` |         | Provide filter values (e.g. 'enabled=true') |\n| `--format`        |         | Pretty-print plugins using a Go template    |\n| `--no-trunc`      |         | Don't truncate output                       |\n| `--quiet` , `-q`  |         | Only display plugin IDs                     |\n\n## Examples\n\n``` \n$ docker plugin ls\n\nID            NAME                                    DESCRIPTION                ENABLED\n69553ca1d123  tiborvass/sample-volume-plugin:latest   A test plugin for Docker   true\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- enabled (boolean - true or false, 0 or 1)\n- capability (string - currently `volumedriver`, `networkdriver`, `ipamdriver`, `logdriver`, `metricscollector`, or `authz`)\n\n#### enabled\n\nThe `enabled` filter matches on plugins enabled or disabled.\n\n#### capability\n\nThe `capability` filter matches on plugin capabilities. One plugin might have multiple capabilities. Currently `volumedriver`, `networkdriver`, `ipamdriver`, `logdriver`, `metricscollector`, and `authz` are supported capabilities.\n\n``` \n$ docker plugin install --disable vieux/sshfs\n\nInstalled plugin vieux/sshfs\n\n$ docker plugin ls --filter enabled=true\n\nID                  NAME                DESCRIPTION         ENABLED\n```\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints plugins output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder        | Description                                     |\n|--------------------|-------------------------------------------------|\n| `.ID`              | Plugin ID                                       |\n| `.Name`            | Plugin name and tag                             |\n| `.Description`     | Plugin description                              |\n| `.Enabled`         | Whether plugin is enabled or not                |\n| `.PluginReference` | The reference used to push/pull from a registry |\n\nWhen using the `--format` option, the `plugin ls` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `Name` entries separated by a colon (`:`) for all plugins:\n\n``` \n$ docker plugin ls --format \"{{.ID}}: {{.Name}}\"\n\n4be01827a72e: vieux/sshfs:latest\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](index)                        | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_ls/](https://docs.docker.com/engine/reference/commandline/plugin_ls/)"
- name: docker plugin push
  id: engine/reference/commandline/plugin_push/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin push\n\n  \n\nPush a plugin to a registry\n\n## Usage\n\n``` \n$ docker plugin push [OPTIONS] PLUGIN[:TAG]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nAfter you have created a plugin using `docker plugin create` and the plugin is ready for distribution, use `docker plugin push` to share your images to Docker Hub or a self-hosted registry.\n\nRegistry credentials are managed by [docker login](../login/index).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default | Description        |\n|---------------------------|---------|--------------------|\n| `--disable-content-trust` | `true`  | Skip image signing |\n\n## Examples\n\nThe following example shows how to push a sample `user/plugin`.\n\n``` \n$ docker plugin ls\n\nID             NAME                    DESCRIPTION                  ENABLED\n69553ca1d456   user/plugin:latest      A sample plugin for Docker   false\n\n$ docker plugin push user/plugin\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](index)                      | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_push/](https://docs.docker.com/engine/reference/commandline/plugin_push/)"
- name: docker plugin rm
  id: engine/reference/commandline/plugin_rm/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin rm\n\n  \n\nRemove one or more plugins\n\n## Usage\n\n``` \n$ docker plugin rm [OPTIONS] PLUGIN [PLUGIN...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemoves a plugin. You cannot remove a plugin if it is enabled, you must disable a plugin using the [`docker plugin disable`](../plugin_disable/index) before removing it (or use --force, use of force is not recommended, since it can affect functioning of running containers using the plugin).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                           |\n|------------------|---------|---------------------------------------|\n| `--force` , `-f` |         | Force the removal of an active plugin |\n\n## Examples\n\nThe following example disables and removes the `sample-volume-plugin:latest` plugin:\n\n``` \n$ docker plugin disable tiborvass/sample-volume-plugin\n\ntiborvass/sample-volume-plugin\n\n$ docker plugin rm tiborvass/sample-volume-plugin:latest\n\ntiborvass/sample-volume-plugin\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](index)                        | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_rm/](https://docs.docker.com/engine/reference/commandline/plugin_rm/)"
- name: docker plugin set
  id: engine/reference/commandline/plugin_set/index
  summary: Change settings for a plugin
  description: "# docker plugin set\n\n  \n\nChange settings for a plugin\n\n## Usage\n\n``` \n$ docker plugin set PLUGIN KEY=VALUE [KEY=VALUE...]\n```\n\n## Description\n\nChange settings for a plugin. The plugin must be disabled.\n\nThe settings currently supported are:\n\n- env variables\n- source of mounts\n- path of devices\n- args\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n### Change an environment variable\n\nThe following example change the env variable `DEBUG` on the `sample-volume-plugin` plugin.\n\n``` \n$ docker plugin inspect -f {{.Settings.Env}} tiborvass/sample-volume-plugin\n[DEBUG=0]\n\n$ docker plugin set tiborvass/sample-volume-plugin DEBUG=1\n\n$ docker plugin inspect -f {{.Settings.Env}} tiborvass/sample-volume-plugin\n[DEBUG=1]\n```\n\n### Change the source of a mount\n\nThe following example change the source of the `mymount` mount on the `myplugin` plugin.\n\n``` \n$ docker plugin inspect -f '{{with $mount := index .Settings.Mounts 0}}{{$mount.Source}}{{end}}' myplugin\n/foo\n\n$ docker plugins set myplugin mymount.source=/bar\n\n$ docker plugin inspect -f '{{with $mount := index .Settings.Mounts 0}}{{$mount.Source}}{{end}}' myplugin\n/bar\n```\n\n> **Note**\n>\n> Since only `source` is settable in `mymount`, `docker plugins set mymount=/bar myplugin` would work too.\n\n### Change a device path\n\nThe following example change the path of the `mydevice` device on the `myplugin` plugin.\n\n``` \n$ docker plugin inspect -f '{{with $device := index .Settings.Devices 0}}{{$device.Path}}{{end}}' myplugin\n\n/dev/foo\n\n$ docker plugins set myplugin mydevice.path=/dev/bar\n\n$ docker plugin inspect -f '{{with $device := index .Settings.Devices 0}}{{$device.Path}}{{end}}' myplugin\n\n/dev/bar\n```\n\n> **Note** Since only `path` is settable in `mydevice`, `docker plugins set mydevice=/dev/bar myplugin` would work too.\n\n### Change the source of the arguments\n\nThe following example change the value of the args on the `myplugin` plugin.\n\n``` \n$ docker plugin inspect -f '{{.Settings.Args}}' myplugin\n\n[\"foo\", \"bar\"]\n\n$ docker plugins set myplugin myargs=\"foo bar baz\"\n\n$ docker plugin inspect -f '{{.Settings.Args}}' myplugin\n\n[\"foo\", \"bar\", \"baz\"]\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](index)                       | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](../plugin_upgrade/index) | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_set/](https://docs.docker.com/engine/reference/commandline/plugin_set/)"
- name: docker plugin upgrade
  id: engine/reference/commandline/plugin_upgrade/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker plugin upgrade\n\n  \n\nUpgrade an existing plugin\n\n## Usage\n\n``` \n$ docker plugin upgrade [OPTIONS] PLUGIN [REMOTE]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUpgrades an existing plugin to the specified remote plugin image. If no remote is specified, Docker will re-pull the current image and use the updated version. All existing references to the plugin will continue to work. The plugin must be disabled before running the upgrade.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default | Description                                                           |\n|---------------------------|---------|-----------------------------------------------------------------------|\n| `--disable-content-trust` | `true`  | Skip image verification                                               |\n| `--grant-all-permissions` |         | Grant all permissions necessary to run the plugin                     |\n| `--skip-remote-check`     |         | Do not check if specified remote plugin matches existing plugin image |\n\n## Examples\n\nThe following example installs `vieus/sshfs` plugin, uses it to create and use a volume, then upgrades the plugin.\n\n``` \n$ docker plugin install vieux/sshfs DEBUG=1\n\nPlugin \"vieux/sshfs:next\" is requesting the following privileges:\n - network: [host]\n - device: [/dev/fuse]\n - capabilities: [CAP_SYS_ADMIN]\nDo you grant the above permissions? [y/N] y\nvieux/sshfs:next\n\n$ docker volume create -d vieux/sshfs:next -o sshcmd=root@1.2.3.4:/tmp/shared -o password=XXX sshvolume\n\nsshvolume\n\n$ docker run -it -v sshvolume:/data alpine sh -c \"touch /data/hello\"\n\n$ docker plugin disable -f vieux/sshfs:next\n\nviex/sshfs:next\n\n# Here docker volume ls doesn't show 'sshfsvolume', since the plugin is disabled\n$ docker volume ls\n\nDRIVER              VOLUME NAME\n\n$ docker plugin upgrade vieux/sshfs:next vieux/sshfs:next\n\nPlugin \"vieux/sshfs:next\" is requesting the following privileges:\n - network: [host]\n - device: [/dev/fuse]\n - capabilities: [CAP_SYS_ADMIN]\nDo you grant the above permissions? [y/N] y\nUpgrade plugin vieux/sshfs:next to vieux/sshfs:next\n\n$ docker plugin enable vieux/sshfs:next\n\nviex/sshfs:next\n\n$ docker volume ls\n\nDRIVER              VOLUME NAME\nviuex/sshfs:next    sshvolume\n\n$ docker run -it -v sshvolume:/data alpine sh -c \"ls /data\"\n\nhello\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker plugin](../plugin/index) | Manage plugins |\n\n## Related commands\n\n| Command                                          | Description                                                                                                           |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [docker plugin create](../plugin_create/index)   | Create a plugin from a rootfs and configuration. Plugin data directory must contain config.json and rootfs directory. |\n| [docker plugin disable](../plugin_disable/index) | Disable a plugin                                                                                                      |\n| [docker plugin enable](../plugin_enable/index)   | Enable a plugin                                                                                                       |\n| [docker plugin inspect](../plugin_inspect/index) | Display detailed information on one or more plugins                                                                   |\n| [docker plugin install](../plugin_install/index) | Install a plugin                                                                                                      |\n| [docker plugin ls](../plugin_ls/index)           | List plugins                                                                                                          |\n| [docker plugin push](../plugin_push/index)       | Push a plugin to a registry                                                                                           |\n| [docker plugin rm](../plugin_rm/index)           | Remove one or more plugins                                                                                            |\n| [docker plugin set](../plugin_set/index)         | Change settings for a plugin                                                                                          |\n| [docker plugin upgrade](index)                   | Upgrade an existing plugin                                                                                            |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/plugin_upgrade/](https://docs.docker.com/engine/reference/commandline/plugin_upgrade/)"
- name: docker port
  id: engine/reference/commandline/port/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker port\n\n  \n\nList port mappings or a specific mapping for the container\n\n## Usage\n\n``` \n$ docker port CONTAINER [PRIVATE_PORT[/PROTO]]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n### Show all mapped ports\n\nYou can find out all the ports mapped by not specifying a `PRIVATE_PORT`, or just a specific mapping:\n\n``` \n$ docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                                            NAMES\nb650456536c7        busybox:latest      top                 54 minutes ago      Up 54 minutes       0.0.0.0:1234->9876/tcp, 0.0.0.0:4321->7890/tcp   test\n\n$ docker port test\n\n7890/tcp -> 0.0.0.0:4321\n9876/tcp -> 0.0.0.0:1234\n\n$ docker port test 7890/tcp\n\n0.0.0.0:4321\n\n$ docker port test 7890/udp\n\n2014/06/24 11:53:36 Error: No public port '7890/udp' published for test\n\n$ docker port test 7890\n\n0.0.0.0:4321\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/port/](https://docs.docker.com/engine/reference/commandline/port/)"
- name: docker ps
  id: engine/reference/commandline/ps/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker ps\n\n  \n\nList containers\n\n## Usage\n\n``` \n$ docker ps [OPTIONS]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                             |\n|-------------------|---------|---------------------------------------------------------|\n| `--all` , `-a`    |         | Show all containers (default shows just running)        |\n| `--filter` , `-f` |         | Filter output based on conditions provided              |\n| `--format`        |         | Pretty-print containers using a Go template             |\n| `--last` , `-n`   | `-1`    | Show n last created containers (includes all states)    |\n| `--latest` , `-l` |         | Show the latest created container (includes all states) |\n| `--no-trunc`      |         | Don't truncate output                                   |\n| `--quiet` , `-q`  |         | Only display container IDs                              |\n| `--size` , `-s`   |         | Display total file sizes                                |\n\n## Examples\n\n### Prevent truncating output\n\nRunning `docker ps --no-trunc` showing 2 linked containers.\n\n``` \n$ docker ps\n\nCONTAINER ID        IMAGE                        COMMAND                CREATED              STATUS              PORTS               NAMES\n4c01db0b339c        ubuntu:12.04                 bash                   17 seconds ago       Up 16 seconds       3300-3310/tcp       webapp\nd7886598dbe2        crosbymichael/redis:latest   /redis-server --dir    33 minutes ago       Up 33 minutes       6379/tcp            redis,webapp/db\n```\n\n### Show both running and stopped containers\n\nThe `docker ps` command only shows running containers by default. To see all containers, use the `-a` (or `--all`) flag:\n\n``` \n$ docker ps -a\n```\n\n`docker ps` groups exposed ports into a single range if possible. E.g., a container that exposes TCP ports `100, 101, 102` displays `100-102/tcp` in the `PORTS` column.\n\n### Show disk usage by container\n\nThe `docker ps -s` command displays two different on-disk-sizes for each container:\n\n``` \n$ docker ps -s\n\nCONTAINER ID   IMAGE          COMMAND                  CREATED        STATUS       PORTS   NAMES        SIZE                                                                                      SIZE\ne90b8831a4b8   nginx          \"/bin/bash -c 'mkdir \"   11 weeks ago   Up 4 hours           my_nginx     35.58 kB (virtual 109.2 MB)\n00c6131c5e30   telegraf:1.5   \"/entrypoint.sh\"         11 weeks ago   Up 11 weeks          my_telegraf  0 B (virtual 209.5 MB)\n```\n\n- The “size” information shows the amount of data (on disk) that is used for the *writable* layer of each container\n- The “virtual size” is the total amount of disk-space used for the read-only *image* data used by the container and the writable layer.\n\nFor more information, refer to the [container size on disk](https://docs.docker.com/storage/storagedriver/#container-size-on-disk) section.\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g. `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n| Filter                | Description                                                                                                                         |\n|:----------------------|:------------------------------------------------------------------------------------------------------------------------------------|\n| `id`                  | Container’s ID                                                                                                                      |\n| `name`                | Container’s name                                                                                                                    |\n| `label`               | An arbitrary string representing either a key or a key-value pair. Expressed as `<key>` or `<key>=<value>`                          |\n| `exited`              | An integer representing the container’s exit code. Only useful with `--all`.                                                        |\n| `status`              | One of `created`, `restarting`, `running`, `removing`, `paused`, `exited`, or `dead`                                                |\n| `ancestor`            | Filters containers which share a given image as an ancestor. Expressed as `<image-name>[:<tag>]`, `<image id>`, or `<image@digest>` |\n| `before` or `since`   | Filters containers created before or after a given container ID or name                                                             |\n| `volume`              | Filters running containers which have mounted a given volume or bind mount.                                                         |\n| `network`             | Filters running containers connected to a given network.                                                                            |\n| `publish` or `expose` | Filters containers which publish or expose a given port. Expressed as `<port>[/<proto>]` or `<startport-endport>/[<proto>]`         |\n| `health`              | Filters containers based on their healthcheck status. One of `starting`, `healthy`, `unhealthy` or `none`.                          |\n| `isolation`           | Windows daemon only. One of `default`, `process`, or `hyperv`.                                                                      |\n| `is-task`             | Filters containers that are a “task” for a service. Boolean option (`true` or `false`)                                              |\n\n#### label\n\nThe `label` filter matches containers based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches containers with the `color` label regardless of its value.\n\n``` \n$ docker ps --filter \"label=color\"\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n673394ef1d4c        busybox             \"top\"               47 seconds ago      Up 45 seconds                           nostalgic_shockley\nd85756f57265        busybox             \"top\"               52 seconds ago      Up 51 seconds                           high_albattani\n```\n\nThe following filter matches containers with the `color` label with the `blue` value.\n\n``` \n$ docker ps --filter \"label=color=blue\"\n\nCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES\nd85756f57265        busybox             \"top\"               About a minute ago   Up About a minute                       high_albattani\n```\n\n#### name\n\nThe `name` filter matches on all or part of a container’s name.\n\nThe following filter matches all containers with a name containing the `nostalgic_stallman` string.\n\n``` \n$ docker ps --filter \"name=nostalgic_stallman\"\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n9b6247364a03        busybox             \"top\"               2 minutes ago       Up 2 minutes                            nostalgic_stallman\n```\n\nYou can also filter for a substring in a name as this shows:\n\n``` \n$ docker ps --filter \"name=nostalgic\"\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n715ebfcee040        busybox             \"top\"               3 seconds ago       Up 1 second                             i_am_nostalgic\n9b6247364a03        busybox             \"top\"               7 minutes ago       Up 7 minutes                            nostalgic_stallman\n673394ef1d4c        busybox             \"top\"               38 minutes ago      Up 38 minutes                           nostalgic_shockley\n```\n\n#### exited\n\nThe `exited` filter matches containers by exist status code. For example, to filter for containers that have exited successfully:\n\n``` \n$ docker ps -a --filter 'exited=0'\n\nCONTAINER ID        IMAGE             COMMAND                CREATED             STATUS                   PORTS                      NAMES\nea09c3c82f6e        registry:latest   /srv/run.sh            2 weeks ago         Exited (0) 2 weeks ago   127.0.0.1:5000->5000/tcp   desperate_leakey\n106ea823fe4e        fedora:latest     /bin/sh -c 'bash -l'   2 weeks ago         Exited (0) 2 weeks ago                              determined_albattani\n48ee228c9464        fedora:20         bash                   2 weeks ago         Exited (0) 2 weeks ago                              tender_torvalds\n```\n\n#### Filter by exit signal\n\nYou can use a filter to locate containers that exited with status of `137` meaning a `SIGKILL(9)` killed them.\n\n``` \n$ docker ps -a --filter 'exited=137'\n\nCONTAINER ID        IMAGE               COMMAND                CREATED             STATUS                       PORTS               NAMES\nb3e1c0ed5bfe        ubuntu:latest       \"sleep 1000\"           12 seconds ago      Exited (137) 5 seconds ago                       grave_kowalevski\na2eb5558d669        redis:latest        \"/entrypoint.sh redi   2 hours ago         Exited (137) 2 hours ago                         sharp_lalande\n```\n\nAny of these events result in a `137` status:\n\n- the `init` process of the container is killed manually\n- `docker kill` kills the container\n- Docker daemon restarts which kills all running containers\n\n#### status\n\nThe `status` filter matches containers by status. You can filter using `created`, `restarting`, `running`, `removing`, `paused`, `exited` and `dead`. For example, to filter for `running` containers:\n\n``` \n$ docker ps --filter status=running\n\nCONTAINER ID        IMAGE                  COMMAND             CREATED             STATUS              PORTS               NAMES\n715ebfcee040        busybox                \"top\"               16 minutes ago      Up 16 minutes                           i_am_nostalgic\nd5c976d3c462        busybox                \"top\"               23 minutes ago      Up 23 minutes                           top\n9b6247364a03        busybox                \"top\"               24 minutes ago      Up 24 minutes                           nostalgic_stallman\n```\n\nTo filter for `paused` containers:\n\n``` \n$ docker ps --filter status=paused\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES\n673394ef1d4c        busybox             \"top\"               About an hour ago   Up About an hour (Paused)                       nostalgic_shockley\n```\n\n#### ancestor\n\nThe `ancestor` filter matches containers based on its image or a descendant of it. The filter supports the following image representation:\n\n- `image`\n- `image:tag`\n- `image:tag@digest`\n- `short-id`\n- `full-id`\n\nIf you don’t specify a `tag`, the `latest` tag is used. For example, to filter for containers that use the latest `ubuntu` image:\n\n``` \n$ docker ps --filter ancestor=ubuntu\n\nCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES\n919e1179bdb8        ubuntu-c1           \"top\"               About a minute ago   Up About a minute                       admiring_lovelace\n5d1e4a540723        ubuntu-c2           \"top\"               About a minute ago   Up About a minute                       admiring_sammet\n82a598284012        ubuntu              \"top\"               3 minutes ago        Up 3 minutes                            sleepy_bose\nbab2a34ba363        ubuntu              \"top\"               3 minutes ago        Up 3 minutes                            focused_yonath\n```\n\nMatch containers based on the `ubuntu-c1` image which, in this case, is a child of `ubuntu`:\n\n``` \n$ docker ps --filter ancestor=ubuntu-c1\n\nCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES\n919e1179bdb8        ubuntu-c1           \"top\"               About a minute ago   Up About a minute                       admiring_lovelace\n```\n\nMatch containers based on the `ubuntu` version `12.04.5` image:\n\n``` \n$ docker ps --filter ancestor=ubuntu:12.04.5\n\nCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES\n82a598284012        ubuntu:12.04.5      \"top\"               3 minutes ago        Up 3 minutes                            sleepy_bose\n```\n\nThe following matches containers based on the layer `d0e008c6cf02` or an image that have this layer in its layer stack.\n\n``` \n$ docker ps --filter ancestor=d0e008c6cf02\n\nCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES\n82a598284012        ubuntu:12.04.5      \"top\"               3 minutes ago        Up 3 minutes                            sleepy_bose\n```\n\n#### Create time\n\n##### before\n\nThe `before` filter shows only containers created before the container with given id or name. For example, having these containers created:\n\n``` \n$ docker ps\n\nCONTAINER ID        IMAGE       COMMAND       CREATED              STATUS              PORTS              NAMES\n9c3527ed70ce        busybox     \"top\"         14 seconds ago       Up 15 seconds                          desperate_dubinsky\n4aace5031105        busybox     \"top\"         48 seconds ago       Up 49 seconds                          focused_hamilton\n6e63f6ff38b0        busybox     \"top\"         About a minute ago   Up About a minute                      distracted_fermat\n```\n\nFiltering with `before` would give:\n\n``` \n$ docker ps -f before=9c3527ed70ce\n\nCONTAINER ID        IMAGE       COMMAND       CREATED              STATUS              PORTS              NAMES\n4aace5031105        busybox     \"top\"         About a minute ago   Up About a minute                      focused_hamilton\n6e63f6ff38b0        busybox     \"top\"         About a minute ago   Up About a minute                      distracted_fermat\n```\n\n##### since\n\nThe `since` filter shows only containers created since the container with given id or name. For example, with the same containers as in `before` filter:\n\n``` \n$ docker ps -f since=6e63f6ff38b0\n\nCONTAINER ID        IMAGE       COMMAND       CREATED             STATUS              PORTS               NAMES\n9c3527ed70ce        busybox     \"top\"         10 minutes ago      Up 10 minutes                           desperate_dubinsky\n4aace5031105        busybox     \"top\"         10 minutes ago      Up 10 minutes                           focused_hamilton\n```\n\n#### volume\n\nThe `volume` filter shows only containers that mount a specific volume or have a volume mounted in a specific path:\n\n``` \n$ docker ps --filter volume=remote-volume --format \"table {{.ID}}\\t{{.Mounts}}\"\n\nCONTAINER ID        MOUNTS\n9c3527ed70ce        remote-volume\n\n$ docker ps --filter volume=/data --format \"table {{.ID}}\\t{{.Mounts}}\"\n\nCONTAINER ID        MOUNTS\n9c3527ed70ce        remote-volume\n```\n\n#### network\n\nThe `network` filter shows only containers that are connected to a network with a given name or id.\n\nThe following filter matches all containers that are connected to a network with a name containing `net1`.\n\n``` \n$ docker run -d --net=net1 --name=test1 ubuntu top\n$ docker run -d --net=net2 --name=test2 ubuntu top\n\n$ docker ps --filter network=net1\n\nCONTAINER ID        IMAGE       COMMAND       CREATED             STATUS              PORTS               NAMES\n9d4893ed80fe        ubuntu      \"top\"         10 minutes ago      Up 10 minutes                           test1\n```\n\nThe network filter matches on both the network’s name and id. The following example shows all containers that are attached to the `net1` network, using the network id as a filter;\n\n``` \n$ docker network inspect --format \"{{.ID}}\" net1\n\n8c0b4110ae930dbe26b258de9bc34a03f98056ed6f27f991d32919bfe401d7c5\n\n$ docker ps --filter network=8c0b4110ae930dbe26b258de9bc34a03f98056ed6f27f991d32919bfe401d7c5\n\nCONTAINER ID        IMAGE       COMMAND       CREATED             STATUS              PORTS               NAMES\n9d4893ed80fe        ubuntu      \"top\"         10 minutes ago      Up 10 minutes                           test1\n```\n\n#### publish and expose\n\nThe `publish` and `expose` filters show only containers that have published or exposed port with a given port number, port range, and/or protocol. The default protocol is `tcp` when not specified.\n\nThe following filter matches all containers that have published port of 80:\n\n``` \n$ docker run -d --publish=80 busybox top\n$ docker run -d --expose=8080 busybox top\n\n$ docker ps -a\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                   NAMES\n9833437217a5        busybox             \"top\"               5 seconds ago       Up 4 seconds        8080/tcp                dreamy_mccarthy\nfc7e477723b7        busybox             \"top\"               50 seconds ago      Up 50 seconds       0.0.0.0:32768->80/tcp   admiring_roentgen\n\n$ docker ps --filter publish=80\n\nCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS                   NAMES\nfc7e477723b7        busybox             \"top\"               About a minute ago   Up About a minute   0.0.0.0:32768->80/tcp   admiring_roentgen\n```\n\nThe following filter matches all containers that have exposed TCP port in the range of `8000-8080`:\n\n``` \n$ docker ps --filter expose=8000-8080/tcp\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n9833437217a5        busybox             \"top\"               21 seconds ago      Up 19 seconds       8080/tcp            dreamy_mccarthy\n```\n\nThe following filter matches all containers that have exposed UDP port `80`:\n\n``` \n$ docker ps --filter publish=80/udp\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n```\n\n### Formatting\n\nThe formatting option (`--format`) pretty-prints container output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder   | Description                                                                                     |\n|:--------------|:------------------------------------------------------------------------------------------------|\n| `.ID`         | Container ID                                                                                    |\n| `.Image`      | Image ID                                                                                        |\n| `.Command`    | Quoted command                                                                                  |\n| `.CreatedAt`  | Time when the container was created.                                                            |\n| `.RunningFor` | Elapsed time since the container was started.                                                   |\n| `.Ports`      | Exposed ports.                                                                                  |\n| `.State`      | Container status (for example; “created”, “running”, “exited”).                                 |\n| `.Status`     | Container status with details about duration and health-status.                                 |\n| `.Size`       | Container disk size.                                                                            |\n| `.Names`      | Container names.                                                                                |\n| `.Labels`     | All labels assigned to the container.                                                           |\n| `.Label`      | Value of a specific label for this container. For example `'{{.Label \"com.docker.swarm.cpu\"}}'` |\n| `.Mounts`     | Names of the volumes mounted in this container.                                                 |\n| `.Networks`   | Names of the networks attached to this container.                                               |\n\nWhen using the `--format` option, the `ps` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `Command` entries separated by a colon (`:`) for all running containers:\n\n``` \n$ docker ps --format \"{{.ID}}: {{.Command}}\"\n\na87ecb4f327c: /bin/sh -c #(nop) MA\n01946d9d34d8: /bin/sh -c #(nop) MA\nc1d3b0166030: /bin/sh -c yum -y up\n41d50ecd2f57: /bin/sh -c #(nop) MA\n```\n\nTo list all running containers with their labels in a table format you can use:\n\n``` \n$ docker ps --format \"table {{.ID}}\\t{{.Labels}}\"\n\nCONTAINER ID        LABELS\na87ecb4f327c        com.docker.swarm.node=ubuntu,com.docker.swarm.storage=ssd\n01946d9d34d8\nc1d3b0166030        com.docker.swarm.node=debian,com.docker.swarm.cpu=6\n41d50ecd2f57        com.docker.swarm.node=fedora,com.docker.swarm.cpu=3,com.docker.swarm.storage=ssd\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/ps/](https://docs.docker.com/engine/reference/commandline/ps/)"
- name: docker pull
  id: engine/reference/commandline/pull/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker pull\n\n  \n\nPull an image or a repository from a registry\n\n## Usage\n\n``` \n$ docker pull [OPTIONS] NAME[:TAG|@DIGEST]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nMost of your images will be created on top of a base image from the [Docker Hub](https://hub.docker.com) registry.\n\n[Docker Hub](https://hub.docker.com) contains many pre-built images that you can `pull` and try without needing to define and configure your own.\n\nTo download a particular image, or set of images (i.e., a repository), use `docker pull`.\n\n### Proxy configuration\n\nIf you are behind an HTTP proxy server, for example in corporate settings, before open a connect to registry, you may need to configure the Docker daemon’s proxy settings, using the `HTTP_PROXY`, `HTTPS_PROXY`, and `NO_PROXY` environment variables. To set these environment variables on a host using `systemd`, refer to the [control and configure Docker with systemd](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) for variables configuration.\n\n### Concurrent downloads\n\nBy default the Docker daemon will pull three layers of an image at a time. If you are on a low bandwidth connection this may cause timeout issues and you may want to lower this via the `--max-concurrent-downloads` daemon option. See the [daemon documentation](../dockerd/index) for more details.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default | Description                                      |\n|---------------------------|---------|--------------------------------------------------|\n| `--all-tags` , `-a`       |         | Download all tagged images in the repository     |\n| `--disable-content-trust` | `true`  | Skip image verification                          |\n| `--platform`              |         | Set platform if server is multi-platform capable |\n| `--quiet` , `-q`          |         | Suppress verbose output                          |\n\n## Examples\n\n### Pull an image from Docker Hub\n\nTo download a particular image, or set of images (i.e., a repository), use `docker pull`. If no tag is provided, Docker Engine uses the `:latest` tag as a default. This command pulls the `debian:latest` image:\n\n``` \n$ docker pull debian\n\nUsing default tag: latest\nlatest: Pulling from library/debian\nfdd5d7827f33: Pull complete\na3ed95caeb02: Pull complete\nDigest: sha256:e7d38b3517548a1c71e41bffe9c8ae6d6d29546ce46bf62159837aad072c90aa\nStatus: Downloaded newer image for debian:latest\n```\n\nDocker images can consist of multiple layers. In the example above, the image consists of two layers; `fdd5d7827f33` and `a3ed95caeb02`.\n\nLayers can be reused by images. For example, the `debian:jessie` image shares both layers with `debian:latest`. Pulling the `debian:jessie` image therefore only pulls its metadata, but not its layers, because all layers are already present locally:\n\n``` \n$ docker pull debian:jessie\n\njessie: Pulling from library/debian\nfdd5d7827f33: Already exists\na3ed95caeb02: Already exists\nDigest: sha256:a9c958be96d7d40df920e7041608f2f017af81800ca5ad23e327bc402626b58e\nStatus: Downloaded newer image for debian:jessie\n```\n\nTo see which images are present locally, use the [`docker images`](../images/index) command:\n\n``` \n$ docker images\n\nREPOSITORY   TAG      IMAGE ID        CREATED      SIZE\ndebian       jessie   f50f9524513f    5 days ago   125.1 MB\ndebian       latest   f50f9524513f    5 days ago   125.1 MB\n```\n\nDocker uses a content-addressable image store, and the image ID is a SHA256 digest covering the image’s configuration and layers. In the example above, `debian:jessie` and `debian:latest` have the same image ID because they are actually the *same* image tagged with different names. Because they are the same image, their layers are stored only once and do not consume extra disk space.\n\nFor more information about images, layers, and the content-addressable store, refer to [understand images, containers, and storage drivers](https://docs.docker.com/storage/storagedriver/).\n\n### Pull an image by digest (immutable identifier)\n\nSo far, you’ve pulled images by their name (and “tag”). Using names and tags is a convenient way to work with images. When using tags, you can `docker pull` an image again to make sure you have the most up-to-date version of that image. For example, `docker pull ubuntu:20.04` pulls the latest version of the Ubuntu 20.04 image.\n\nIn some cases you don’t want images to be updated to newer versions, but prefer to use a fixed version of an image. Docker enables you to pull an image by its *digest*. When pulling an image by digest, you specify *exactly* which version of an image to pull. Doing so, allows you to “pin” an image to that version, and guarantee that the image you’re using is always the same.\n\nTo know the digest of an image, pull the image first. Let’s pull the latest `ubuntu:20.04` image from Docker Hub:\n\n``` \n$ docker pull ubuntu:20.04\n\n20.04: Pulling from library/ubuntu\n16ec32c2132b: Pull complete\nDigest: sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\nStatus: Downloaded newer image for ubuntu:20.04\ndocker.io/library/ubuntu:20.04\n```\n\nDocker prints the digest of the image after the pull has finished. In the example above, the digest of the image is:\n\n``` \nsha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\n```\n\nDocker also prints the digest of an image when *pushing* to a registry. This may be useful if you want to pin to a version of the image you just pushed.\n\nA digest takes the place of the tag when pulling an image, for example, to pull the above image by digest, run the following command:\n\n``` \n$ docker pull ubuntu@sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\n\ndocker.io/library/ubuntu@sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3: Pulling from library/ubuntu\nDigest: sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\nStatus: Image is up to date for ubuntu@sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\ndocker.io/library/ubuntu@sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\n```\n\nDigest can also be used in the `FROM` of a Dockerfile, for example:\n\n``` \nFROM ubuntu@sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3\nLABEL org.opencontainers.image.authors=\"some maintainer <maintainer@example.com>\"\n```\n\n> **Note**\n>\n> Using this feature “pins” an image to a specific version in time. Docker will therefore not pull updated versions of an image, which may include security updates. If you want to pull an updated image, you need to change the digest accordingly.\n\n### Pull from a different registry\n\nBy default, `docker pull` pulls images from [Docker Hub](https://hub.docker.com). It is also possible to manually specify the path of a registry to pull from. For example, if you have set up a local registry, you can specify its path to pull from it. A registry path is similar to a URL, but does not contain a protocol specifier (`https://`).\n\nThe following command pulls the `testing/test-image` image from a local registry listening on port 5000 (`myregistry.local:5000`):\n\n``` \n$ docker pull myregistry.local:5000/testing/test-image\n```\n\nRegistry credentials are managed by [docker login](../login/index).\n\nDocker uses the `https://` protocol to communicate with a registry, unless the registry is allowed to be accessed over an insecure connection. Refer to the [insecure registries](../dockerd/index#insecure-registries) section for more information.\n\n### Pull a repository with multiple images\n\nBy default, `docker pull` pulls a *single* image from the registry. A repository can contain multiple images. To pull all images from a repository, provide the `-a` (or `--all-tags`) option when using `docker pull`.\n\nThis command pulls all images from the `fedora` repository:\n\n``` \n$ docker pull --all-tags fedora\n\nPulling repository fedora\nad57ef8d78d7: Download complete\n105182bb5e8b: Download complete\n511136ea3c5a: Download complete\n73bd853d2ea5: Download complete\n....\n\nStatus: Downloaded newer image for fedora\n```\n\nAfter the pull has completed use the `docker images` command to see the images that were pulled. The example below shows all the `fedora` images that are present locally:\n\n``` \n$ docker images fedora\n\nREPOSITORY   TAG         IMAGE ID        CREATED      SIZE\nfedora       rawhide     ad57ef8d78d7    5 days ago   359.3 MB\nfedora       20          105182bb5e8b    5 days ago   372.7 MB\nfedora       heisenbug   105182bb5e8b    5 days ago   372.7 MB\nfedora       latest      105182bb5e8b    5 days ago   372.7 MB\n```\n\n### Cancel a pull\n\nKilling the `docker pull` process, for example by pressing `CTRL-c` while it is running in a terminal, will terminate the pull operation.\n\n``` \n$ docker pull fedora\n\nUsing default tag: latest\nlatest: Pulling from library/fedora\na3ed95caeb02: Pulling fs layer\n236608c7b546: Pulling fs layer\n^C\n```\n\n> **Note**\n>\n> The Engine terminates a pull operation when the connection between the Docker Engine daemon and the Docker Engine client initiating the pull is lost. If the connection with the Engine daemon is lost for other reasons than a manual interaction, the pull is also aborted.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/pull/](https://docs.docker.com/engine/reference/commandline/pull/)"
- name: docker push
  id: engine/reference/commandline/push/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker push\n\n  \n\nPush an image or a repository to a registry\n\n## Usage\n\n``` \n$ docker push [OPTIONS] NAME[:TAG]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUse `docker image push` to share your images to the [Docker Hub](https://hub.docker.com) registry or to a self-hosted one.\n\nRefer to the [`docker image tag`](../tag/index) reference for more information about valid image and tag names.\n\nKilling the `docker image push` process, for example by pressing `CTRL-c` while it is running in a terminal, terminates the push operation.\n\nProgress bars are shown during docker push, which show the uncompressed size. The actual amount of data that’s pushed will be compressed before sending, so the uploaded size will not be reflected by the progress bar.\n\nRegistry credentials are managed by [docker login](../login/index).\n\n### Concurrent uploads\n\nBy default the Docker daemon will push five layers of an image at a time. If you are on a low bandwidth connection this may cause timeout issues and you may want to lower this via the `--max-concurrent-uploads` daemon option. See the [daemon documentation](../dockerd/index) for more details.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default | Description                              |\n|---------------------------|---------|------------------------------------------|\n| `--all-tags` , `-a`       |         | Push all tagged images in the repository |\n| `--disable-content-trust` | `true`  | Skip image signing                       |\n| `--quiet` , `-q`          |         | Suppress verbose output                  |\n\n## Examples\n\n### Push a new image to a registry\n\nFirst save the new image by finding the container ID (using [`docker container ls`](../ps/index)) and then committing it to a new image name. Note that only `a-z0-9-_.` are allowed when naming images:\n\n``` \n$ docker container commit c16378f943fe rhel-httpd:latest\n```\n\nNow, push the image to the registry using the image ID. In this example the registry is on host named `registry-host` and listening on port `5000`. To do this, tag the image with the host name or IP address, and the port of the registry:\n\n``` \n$ docker image tag rhel-httpd:latest registry-host:5000/myadmin/rhel-httpd:latest\n\n$ docker image push registry-host:5000/myadmin/rhel-httpd:latest\n```\n\nCheck that this worked by running:\n\n``` \n$ docker image ls\n```\n\nYou should see both `rhel-httpd` and `registry-host:5000/myadmin/rhel-httpd` listed.\n\n### Push all tags of an image\n\nUse the `-a` (or `--all-tags`) option to push all tags of a local image.\n\nThe following example creates multiple tags for an image, and pushes all those tags to Docker Hub.\n\n``` \n$ docker image tag myimage registry-host:5000/myname/myimage:latest\n$ docker image tag myimage registry-host:5000/myname/myimage:v1.0.1\n$ docker image tag myimage registry-host:5000/myname/myimage:v1.0\n$ docker image tag myimage registry-host:5000/myname/myimage:v1\n```\n\nThe image is now tagged under multiple names:\n\n``` \n$ docker image ls\n\nREPOSITORY                          TAG        IMAGE ID       CREATED      SIZE\nmyimage                             latest     6d5fcfe5ff17   2 hours ago  1.22MB\nregistry-host:5000/myname/myimage   latest     6d5fcfe5ff17   2 hours ago  1.22MB\nregistry-host:5000/myname/myimage   v1         6d5fcfe5ff17   2 hours ago  1.22MB\nregistry-host:5000/myname/myimage   v1.0       6d5fcfe5ff17   2 hours ago  1.22MB\nregistry-host:5000/myname/myimage   v1.0.1     6d5fcfe5ff17   2 hours ago  1.22MB\n```\n\nWhen pushing with the `--all-tags` option, all tags of the `registry-host:5000/myname/myimage` image are pushed:\n\n``` \n$ docker image push --all-tags registry-host:5000/myname/myimage\n\nThe push refers to repository [registry-host:5000/myname/myimage]\n195be5f8be1d: Pushed\nlatest: digest: sha256:edafc0a0fb057813850d1ba44014914ca02d671ae247107ca70c94db686e7de6 size: 4527\n195be5f8be1d: Layer already exists\nv1: digest: sha256:edafc0a0fb057813850d1ba44014914ca02d671ae247107ca70c94db686e7de6 size: 4527\n195be5f8be1d: Layer already exists\nv1.0: digest: sha256:edafc0a0fb057813850d1ba44014914ca02d671ae247107ca70c94db686e7de6 size: 4527\n195be5f8be1d: Layer already exists\nv1.0.1: digest: sha256:edafc0a0fb057813850d1ba44014914ca02d671ae247107ca70c94db686e7de6 size: 4527\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/push/](https://docs.docker.com/engine/reference/commandline/push/)"
- name: docker rename
  id: engine/reference/commandline/rename/index
  summary: The docker rename command renames a container
  description: "# docker rename\n\n  \n\nRename a container\n\n## Usage\n\n``` \n$ docker rename CONTAINER NEW_NAME\n```\n\n## Description\n\nThe `docker rename` command renames a container.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker rename my_container my_new_container\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/rename/](https://docs.docker.com/engine/reference/commandline/rename/)"
- name: docker restart
  id: engine/reference/commandline/restart/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker restart\n\n  \n\nRestart one or more containers\n\n## Usage\n\n``` \n$ docker restart [OPTIONS] CONTAINER [CONTAINER...]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                                           |\n|-----------------|---------|-------------------------------------------------------|\n| `--time` , `-t` | `10`    | Seconds to wait for stop before killing the container |\n\n## Examples\n\n``` \n$ docker restart my_container\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/restart/](https://docs.docker.com/engine/reference/commandline/restart/)"
- name: docker rm
  id: engine/reference/commandline/rm/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker rm\n\n  \n\nRemove one or more containers\n\n## Usage\n\n``` \n$ docker rm [OPTIONS] CONTAINER [CONTAINER...]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand    | Default | Description                                             |\n|--------------------|---------|---------------------------------------------------------|\n| `--force` , `-f`   |         | Force the removal of a running container (uses SIGKILL) |\n| `--link` , `-l`    |         | Remove the specified link                               |\n| `--volumes` , `-v` |         | Remove anonymous volumes associated with the container  |\n\n## Examples\n\n### Remove a container\n\nThis removes the container referenced under the link `/redis`.\n\n``` \n$ docker rm /redis\n\n/redis\n```\n\n### Remove a link specified with `--link` on the default bridge network\n\nThis removes the underlying link between `/webapp` and the `/redis` containers on the default bridge network, removing all network communication between the two containers. This does not apply when `--link` is used with user-specified networks.\n\n``` \n$ docker rm --link /webapp/redis\n\n/webapp/redis\n```\n\n### Force-remove a running container\n\nThis command force-removes a running container.\n\n``` \n$ docker rm --force redis\n\nredis\n```\n\nThe main process inside the container referenced under the link `redis` will receive `SIGKILL`, then the container will be removed.\n\n### Remove all stopped containers\n\nUse the [`docker container prune`](../container_prune/index) command to remove all stopped containers, or refer to the [`docker system prune`](../system_prune/index) command to remove unused containers in addition to other Docker resources, such as (unused) images and networks.\n\nAlternatively, you can use the `docker ps` with the `-q` / `--quiet` option to generate a list of container IDs to remove, and use that list as argument for the `docker rm` command.\n\nCombining commands can be more flexible, but is less portable as it depends on features provided by the shell, and the exact syntax may differ depending on what shell is used. To use this approach on Windows, consider using PowerShell or Bash.\n\nThe example below uses `docker ps -q` to print the IDs of all containers that have exited (`--filter status=exited`), and removes those containers with the `docker rm` command:\n\n``` \n$ docker rm $(docker ps --filter status=exited -q)\n```\n\nOr, using the `xargs` Linux utility;\n\n``` \n$ docker ps --filter status=exited -q | xargs docker rm\n```\n\n### Remove a container and its volumes\n\n``` \n$ docker rm -v redis\nredis\n```\n\nThis command removes the container and any volumes associated with it. Note that if a volume was specified with a name, it will not be removed.\n\n### Remove a container and selectively remove volumes\n\n``` \n$ docker create -v awesome:/foo -v /bar --name hello redis\nhello\n\n$ docker rm -v hello\n```\n\nIn this example, the volume for `/foo` remains intact, but the volume for `/bar` is removed. The same behavior holds for volumes inherited with `--volumes-from`.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/rm/](https://docs.docker.com/engine/reference/commandline/rm/)"
- name: docker rmi
  id: engine/reference/commandline/rmi/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker rmi\n\n  \n\nRemove one or more images\n\n## Usage\n\n``` \n$ docker rmi [OPTIONS] IMAGE [IMAGE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemoves (and un-tags) one or more images from the host node. If an image has multiple tags, using this command with the tag as a parameter only removes the tag. If the tag is the only one for the image, both the image and the tag are removed.\n\nThis does not remove images from a registry. You cannot remove an image of a running container unless you use the `-f` option. To see all images on a host use the [`docker image ls`](../images/index) command.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                    |\n|------------------|---------|--------------------------------|\n| `--force` , `-f` |         | Force removal of the image     |\n| `--no-prune`     |         | Do not delete untagged parents |\n\n## Examples\n\nYou can remove an image using its short or long ID, its tag, or its digest. If an image has one or more tags referencing it, you must remove all of them before the image is removed. Digest references are removed automatically when an image is removed by tag.\n\n``` \n$ docker images\n\nREPOSITORY                TAG                 IMAGE ID            CREATED             SIZE\ntest1                     latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\ntest                      latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\ntest2                     latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\n\n$ docker rmi fd484f19954f\n\nError: Conflict, cannot delete image fd484f19954f because it is tagged in multiple repositories, use -f to force\n2013/12/11 05:47:16 Error: failed to remove one or more images\n\n$ docker rmi test1:latest\n\nUntagged: test1:latest\n\n$ docker rmi test2:latest\n\nUntagged: test2:latest\n\n\n$ docker images\n\nREPOSITORY                TAG                 IMAGE ID            CREATED             SIZE\ntest                      latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\n\n$ docker rmi test:latest\n\nUntagged: test:latest\nDeleted: fd484f19954f4920da7ff372b5067f5b7ddb2fd3830cecd17b96ea9e286ba5b8\n```\n\nIf you use the `-f` flag and specify the image’s short or long ID, then this command untags and removes all images that match the specified ID.\n\n``` \n$ docker images\n\nREPOSITORY                TAG                 IMAGE ID            CREATED             SIZE\ntest1                     latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\ntest                      latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\ntest2                     latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)\n\n$ docker rmi -f fd484f19954f\n\nUntagged: test1:latest\nUntagged: test:latest\nUntagged: test2:latest\nDeleted: fd484f19954f4920da7ff372b5067f5b7ddb2fd3830cecd17b96ea9e286ba5b8\n```\n\nAn image pulled by digest has no tag associated with it:\n\n``` \n$ docker images --digests\n\nREPOSITORY                     TAG       DIGEST                                                                    IMAGE ID        CREATED         SIZE\nlocalhost:5000/test/busybox    <none>    sha256:cbbf2f9a99b47fc460d422812b6a5adff7dfee951d8fa2e4a98caa0382cfbdbf   4986bf8c1536    9 weeks ago     2.43 MB\n```\n\nTo remove an image using its digest:\n\n``` \n$ docker rmi localhost:5000/test/busybox@sha256:cbbf2f9a99b47fc460d422812b6a5adff7dfee951d8fa2e4a98caa0382cfbdbf\nUntagged: localhost:5000/test/busybox@sha256:cbbf2f9a99b47fc460d422812b6a5adff7dfee951d8fa2e4a98caa0382cfbdbf\nDeleted: 4986bf8c15363d1c5d15512d5266f8777bfba4974ac56e3270e7760f6f0a8125\nDeleted: ea13149945cb6b1e746bf28032f02e9b5a793523481a0a18645fc77ad53c4ea2\nDeleted: df7546f9f060a2268024c8a230d8639878585defcc1bc6f79d2728a13957871b\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/rmi/](https://docs.docker.com/engine/reference/commandline/rmi/)"
- name: docker run
  id: engine/reference/commandline/run/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker run\n\n  \n\nRun a command in a new container\n\n## Usage\n\n``` \n$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker run` command first `creates` a writeable container layer over the specified image, and then `starts` it using the specified command. That is, `docker run` is equivalent to the API `/containers/create` then `/containers/(id)/start`. A stopped container can be restarted with all its previous changes intact using `docker start`. See `docker ps -a` to view a list of all containers.\n\nThe `docker run` command can be used in combination with `docker commit` to [*change the command that a container runs*](../commit/index). There is additional detailed information about `docker run` in the [Docker run reference](../../run/index).\n\nFor information on connecting a container to a network, see the [“*Docker network overview*”](https://docs.docker.com/network/).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand           | Default   | Description                                                                                                                                                                                                                                                                                                                            |\n|---------------------------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--add-host`              |           | Add a custom host-to-IP mapping (host:ip)                                                                                                                                                                                                                                                                                              |\n| `--attach` , `-a`         |           | Attach to STDIN, STDOUT or STDERR                                                                                                                                                                                                                                                                                                      |\n| `--blkio-weight`          |           | Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)                                                                                                                                                                                                                                                           |\n| `--blkio-weight-device`   |           | Block IO weight (relative device weight)                                                                                                                                                                                                                                                                                               |\n| `--cap-add`               |           | Add Linux capabilities                                                                                                                                                                                                                                                                                                                 |\n| `--cap-drop`              |           | Drop Linux capabilities                                                                                                                                                                                                                                                                                                                |\n| `--cgroup-parent`         |           | Optional parent cgroup for the container                                                                                                                                                                                                                                                                                               |\n| `--cgroupns`              |           | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Cgroup namespace to use (host\\|private) 'host': Run the container in the Docker host's cgroup namespace 'private': Run the container in its own private cgroup namespace '': Use the cgroup namespace as configured by the default-cgroupns-mode option on the daemon (default) |\n| `--cidfile`               |           | Write the container ID to the file                                                                                                                                                                                                                                                                                                     |\n| `--cpu-count`             |           | CPU count (Windows only)                                                                                                                                                                                                                                                                                                               |\n| `--cpu-percent`           |           | CPU percent (Windows only)                                                                                                                                                                                                                                                                                                             |\n| `--cpu-period`            |           | Limit CPU CFS (Completely Fair Scheduler) period                                                                                                                                                                                                                                                                                       |\n| `--cpu-quota`             |           | Limit CPU CFS (Completely Fair Scheduler) quota                                                                                                                                                                                                                                                                                        |\n| `--cpu-rt-period`         |           | Limit CPU real-time period in microseconds                                                                                                                                                                                                                                                                                             |\n| `--cpu-rt-runtime`        |           | Limit CPU real-time runtime in microseconds                                                                                                                                                                                                                                                                                            |\n| `--cpu-shares` , `-c`     |           | CPU shares (relative weight)                                                                                                                                                                                                                                                                                                           |\n| `--cpus`                  |           | Number of CPUs                                                                                                                                                                                                                                                                                                                         |\n| `--cpuset-cpus`           |           | CPUs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--cpuset-mems`           |           | MEMs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                                                                            |\n| `--detach` , `-d`         |           | Run container in background and print container ID                                                                                                                                                                                                                                                                                     |\n| `--detach-keys`           |           | Override the key sequence for detaching a container                                                                                                                                                                                                                                                                                    |\n| `--device`                |           | Add a host device to the container                                                                                                                                                                                                                                                                                                     |\n| `--device-cgroup-rule`    |           | Add a rule to the cgroup allowed devices list                                                                                                                                                                                                                                                                                          |\n| `--device-read-bps`       |           | Limit read rate (bytes per second) from a device                                                                                                                                                                                                                                                                                       |\n| `--device-read-iops`      |           | Limit read rate (IO per second) from a device                                                                                                                                                                                                                                                                                          |\n| `--device-write-bps`      |           | Limit write rate (bytes per second) to a device                                                                                                                                                                                                                                                                                        |\n| `--device-write-iops`     |           | Limit write rate (IO per second) to a device                                                                                                                                                                                                                                                                                           |\n| `--disable-content-trust` | `true`    | Skip image verification                                                                                                                                                                                                                                                                                                                |\n| `--dns`                   |           | Set custom DNS servers                                                                                                                                                                                                                                                                                                                 |\n| `--dns-opt`               |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-option`            |           | Set DNS options                                                                                                                                                                                                                                                                                                                        |\n| `--dns-search`            |           | Set custom DNS search domains                                                                                                                                                                                                                                                                                                          |\n| `--domainname`            |           | Container NIS domain name                                                                                                                                                                                                                                                                                                              |\n| `--entrypoint`            |           | Overwrite the default ENTRYPOINT of the image                                                                                                                                                                                                                                                                                          |\n| `--env` , `-e`            |           | Set environment variables                                                                                                                                                                                                                                                                                                              |\n| `--env-file`              |           | Read in a file of environment variables                                                                                                                                                                                                                                                                                                |\n| `--expose`                |           | Expose a port or a range of ports                                                                                                                                                                                                                                                                                                      |\n| `--gpus`                  |           | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) GPU devices to add to the container ('all' to pass all GPUs)                                                                                                                                                                                                                    |\n| `--group-add`             |           | Add additional groups to join                                                                                                                                                                                                                                                                                                          |\n| `--health-cmd`            |           | Command to run to check health                                                                                                                                                                                                                                                                                                         |\n| `--health-interval`       |           | Time between running the check (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                              |\n| `--health-retries`        |           | Consecutive failures needed to report unhealthy                                                                                                                                                                                                                                                                                        |\n| `--health-start-period`   |           | Start period for the container to initialize before starting health-retries countdown (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                       |\n| `--health-timeout`        |           | Maximum time to allow one check to run (ms\\|s\\|m\\|h) (default 0s)                                                                                                                                                                                                                                                                      |\n| `--help`                  |           | Print usage                                                                                                                                                                                                                                                                                                                            |\n| `--hostname` , `-h`       |           | Container host name                                                                                                                                                                                                                                                                                                                    |\n| `--init`                  |           | Run an init inside the container that forwards signals and reaps processes                                                                                                                                                                                                                                                             |\n| `--interactive` , `-i`    |           | Keep STDIN open even if not attached                                                                                                                                                                                                                                                                                                   |\n| `--io-maxbandwidth`       |           | Maximum IO bandwidth limit for the system drive (Windows only)                                                                                                                                                                                                                                                                         |\n| `--io-maxiops`            |           | Maximum IOps limit for the system drive (Windows only)                                                                                                                                                                                                                                                                                 |\n| `--ip`                    |           | IPv4 address (e.g., 172.30.100.104)                                                                                                                                                                                                                                                                                                    |\n| `--ip6`                   |           | IPv6 address (e.g., 2001:db8::33)                                                                                                                                                                                                                                                                                                      |\n| `--ipc`                   |           | IPC mode to use                                                                                                                                                                                                                                                                                                                        |\n| `--isolation`             |           | Container isolation technology                                                                                                                                                                                                                                                                                                         |\n| `--kernel-memory`         |           | Kernel memory limit                                                                                                                                                                                                                                                                                                                    |\n| `--label` , `-l`          |           | Set meta data on a container                                                                                                                                                                                                                                                                                                           |\n| `--label-file`            |           | Read in a line delimited file of labels                                                                                                                                                                                                                                                                                                |\n| `--link`                  |           | Add link to another container                                                                                                                                                                                                                                                                                                          |\n| `--link-local-ip`         |           | Container IPv4/IPv6 link-local addresses                                                                                                                                                                                                                                                                                               |\n| `--log-driver`            |           | Logging driver for the container                                                                                                                                                                                                                                                                                                       |\n| `--log-opt`               |           | Log driver options                                                                                                                                                                                                                                                                                                                     |\n| `--mac-address`           |           | Container MAC address (e.g., 92:d0:c6:0a:29:33)                                                                                                                                                                                                                                                                                        |\n| `--memory` , `-m`         |           | Memory limit                                                                                                                                                                                                                                                                                                                           |\n| `--memory-reservation`    |           | Memory soft limit                                                                                                                                                                                                                                                                                                                      |\n| `--memory-swap`           |           | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                                                                                                                                                                                                                                                    |\n| `--memory-swappiness`     | `-1`      | Tune container memory swappiness (0 to 100)                                                                                                                                                                                                                                                                                            |\n| `--mount`                 |           | Attach a filesystem mount to the container                                                                                                                                                                                                                                                                                             |\n| `--name`                  |           | Assign a name to the container                                                                                                                                                                                                                                                                                                         |\n| `--net`                   |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--net-alias`             |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--network`               |           | Connect a container to a network                                                                                                                                                                                                                                                                                                       |\n| `--network-alias`         |           | Add network-scoped alias for the container                                                                                                                                                                                                                                                                                             |\n| `--no-healthcheck`        |           | Disable any container-specified HEALTHCHECK                                                                                                                                                                                                                                                                                            |\n| `--oom-kill-disable`      |           | Disable OOM Killer                                                                                                                                                                                                                                                                                                                     |\n| `--oom-score-adj`         |           | Tune host's OOM preferences (-1000 to 1000)                                                                                                                                                                                                                                                                                            |\n| `--pid`                   |           | PID namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--pids-limit`            |           | Tune container pids limit (set -1 for unlimited)                                                                                                                                                                                                                                                                                       |\n| `--platform`              |           | Set platform if server is multi-platform capable                                                                                                                                                                                                                                                                                       |\n| `--privileged`            |           | Give extended privileges to this container                                                                                                                                                                                                                                                                                             |\n| `--publish` , `-p`        |           | Publish a container's port(s) to the host                                                                                                                                                                                                                                                                                              |\n| `--publish-all` , `-P`    |           | Publish all exposed ports to random ports                                                                                                                                                                                                                                                                                              |\n| `--pull`                  | `missing` | Pull image before running (\"always\"\\|\"missing\"\\|\"never\")                                                                                                                                                                                                                                                                               |\n| `--read-only`             |           | Mount the container's root filesystem as read only                                                                                                                                                                                                                                                                                     |\n| `--restart`               | `no`      | Restart policy to apply when a container exits                                                                                                                                                                                                                                                                                         |\n| `--rm`                    |           | Automatically remove the container when it exits                                                                                                                                                                                                                                                                                       |\n| `--runtime`               |           | Runtime to use for this container                                                                                                                                                                                                                                                                                                      |\n| `--security-opt`          |           | Security Options                                                                                                                                                                                                                                                                                                                       |\n| `--shm-size`              |           | Size of /dev/shm                                                                                                                                                                                                                                                                                                                       |\n| `--sig-proxy`             | `true`    | Proxy received signals to the process                                                                                                                                                                                                                                                                                                  |\n| `--stop-signal`           | `SIGTERM` | Signal to stop a container                                                                                                                                                                                                                                                                                                             |\n| `--stop-timeout`          |           | Timeout (in seconds) to stop a container                                                                                                                                                                                                                                                                                               |\n| `--storage-opt`           |           | Storage driver options for the container                                                                                                                                                                                                                                                                                               |\n| `--sysctl`                |           | Sysctl options                                                                                                                                                                                                                                                                                                                         |\n| `--tmpfs`                 |           | Mount a tmpfs directory                                                                                                                                                                                                                                                                                                                |\n| `--tty` , `-t`            |           | Allocate a pseudo-TTY                                                                                                                                                                                                                                                                                                                  |\n| `--ulimit`                |           | Ulimit options                                                                                                                                                                                                                                                                                                                         |\n| `--user` , `-u`           |           | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\])                                                                                                                                                                                                                                                                             |\n| `--userns`                |           | User namespace to use                                                                                                                                                                                                                                                                                                                  |\n| `--uts`                   |           | UTS namespace to use                                                                                                                                                                                                                                                                                                                   |\n| `--volume` , `-v`         |           | Bind mount a volume                                                                                                                                                                                                                                                                                                                    |\n| `--volume-driver`         |           | Optional volume driver for the container                                                                                                                                                                                                                                                                                               |\n| `--volumes-from`          |           | Mount volumes from the specified container(s)                                                                                                                                                                                                                                                                                          |\n| `--workdir` , `-w`        |           | Working directory inside the container                                                                                                                                                                                                                                                                                                 |\n\n## Examples\n\n### Assign name and allocate pseudo-TTY (--name, -it)\n\n``` \n$ docker run --name test -it debian\n\nroot@d6c0fe130dba:/# exit 13\n$ echo $?\n13\n$ docker ps -a | grep test\nd6c0fe130dba        debian:7            \"/bin/bash\"         26 seconds ago      Exited (13) 17 seconds ago                         test\n```\n\nThis example runs a container named `test` using the `debian:latest` image. The `-it` instructs Docker to allocate a pseudo-TTY connected to the container’s stdin; creating an interactive `bash` shell in the container. In the example, the `bash` shell is quit by entering `exit 13`. This exit code is passed on to the caller of `docker run`, and is recorded in the `test` container’s metadata.\n\n### Capture container ID (--cidfile)\n\n``` \n$ docker run --cidfile /tmp/docker_test.cid ubuntu echo \"test\"\n```\n\nThis will create a container and print `test` to the console. The `cidfile` flag makes Docker attempt to create a new file and write the container ID to it. If the file exists already, Docker will return an error. Docker will close this file when `docker run` exits.\n\n### Full container capabilities (--privileged)\n\n``` \n$ docker run -t -i --rm ubuntu bash\nroot@bc338942ef20:/# mount -t tmpfs none /mnt\nmount: permission denied\n```\n\nThis will *not* work, because by default, most potentially dangerous kernel capabilities are dropped; including `cap_sys_admin` (which is required to mount filesystems). However, the `--privileged` flag will allow it to run:\n\n``` \n$ docker run -t -i --privileged ubuntu bash\nroot@50e3f57e16e6:/# mount -t tmpfs none /mnt\nroot@50e3f57e16e6:/# df -h\nFilesystem      Size  Used Avail Use% Mounted on\nnone            1.9G     0  1.9G   0% /mnt\n```\n\nThe `--privileged` flag gives *all* capabilities to the container, and it also lifts all the limitations enforced by the `device` cgroup controller. In other words, the container can then do almost everything that the host can do. This flag exists to allow special use-cases, like running Docker within Docker.\n\n### Set working directory (-w)\n\n``` \n$ docker  run -w /path/to/dir/ -i -t  ubuntu pwd\n```\n\nThe `-w` lets the command being executed inside directory given, here `/path/to/dir/`. If the path does not exist it is created inside the container.\n\n### Set storage driver options per container\n\n``` \n$ docker run -it --storage-opt size=120G fedora /bin/bash\n```\n\nThis (size) will allow to set the container rootfs size to 120G at creation time. This option is only available for the `devicemapper`, `btrfs`, `overlay2`, `windowsfilter` and `zfs` graph drivers. For the `devicemapper`, `btrfs`, `windowsfilter` and `zfs` graph drivers, user cannot pass a size less than the Default BaseFS Size. For the `overlay2` storage driver, the size option is only available if the backing fs is `xfs` and mounted with the `pquota` mount option. Under these conditions, user can pass any size less than the backing fs size.\n\n### Mount tmpfs (--tmpfs)\n\n``` \n$ docker run -d --tmpfs /run:rw,noexec,nosuid,size=65536k my_image\n```\n\nThe `--tmpfs` flag mounts an empty tmpfs into the container with the `rw`, `noexec`, `nosuid`, `size=65536k` options.\n\n### Mount volume (-v, --read-only)\n\n``` \n$ docker  run  -v `pwd`:`pwd` -w `pwd` -i -t  ubuntu pwd\n```\n\nThe `-v` flag mounts the current working directory into the container. The `-w` lets the command being executed inside the current working directory, by changing into the directory to the value returned by `pwd`. So this combination executes the command using the container, but inside the current working directory.\n\n``` \n$ docker run -v /doesnt/exist:/foo -w /foo -i -t ubuntu bash\n```\n\nWhen the host directory of a bind-mounted volume doesn’t exist, Docker will automatically create this directory on the host for you. In the example above, Docker will create the `/doesnt/exist` folder before starting your container.\n\n``` \n$ docker run --read-only -v /icanwrite busybox touch /icanwrite/here\n```\n\nVolumes can be used in combination with `--read-only` to control where a container writes files. The `--read-only` flag mounts the container’s root filesystem as read only prohibiting writes to locations other than the specified volumes for the container.\n\n``` \n$ docker run -t -i -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/static-docker-binary:/usr/bin/docker busybox sh\n```\n\nBy bind-mounting the docker unix socket and statically linked docker binary (refer to [get the linux binary](../../../install/binaries/index#install-static-binaries)), you give the container the full access to create and manipulate the host’s Docker daemon.\n\nOn Windows, the paths must be specified using Windows-style semantics.\n\n``` \nPS C:\\> docker run -v c:\\foo:c:\\dest microsoft/nanoserver cmd /s /c type c:\\dest\\somefile.txt\nContents of file\n\nPS C:\\> docker run -v c:\\foo:d: microsoft/nanoserver cmd /s /c type d:\\somefile.txt\nContents of file\n```\n\nThe following examples will fail when using Windows-based containers, as the destination of a volume or bind mount inside the container must be one of: a non-existing or empty directory; or a drive other than C:. Further, the source of a bind mount must be a local directory, not a file.\n\n``` \nnet use z: \\\\remotemachine\\share\ndocker run -v z:\\foo:c:\\dest ...\ndocker run -v \\\\uncpath\\to\\directory:c:\\dest ...\ndocker run -v c:\\foo\\somefile.txt:c:\\dest ...\ndocker run -v c:\\foo:c: ...\ndocker run -v c:\\foo:c:\\existing-directory-with-contents ...\n```\n\nFor in-depth information about volumes, refer to [manage data in containers](https://docs.docker.com/storage/volumes/)\n\n### Add bind mounts or volumes using the --mount flag\n\nThe `--mount` flag allows you to mount volumes, host-directories and `tmpfs` mounts in a container.\n\nThe `--mount` flag supports most options that are supported by the `-v` or the `--volume` flag, but uses a different syntax. For in-depth information on the `--mount` flag, and a comparison between `--volume` and `--mount`, refer to the [service create command reference](../service_create/index#add-bind-mounts-volumes-or-memory-filesystems).\n\nEven though there is no plan to deprecate `--volume`, usage of `--mount` is recommended.\n\nExamples:\n\n``` \n$ docker run --read-only --mount type=volume,target=/icanwrite busybox touch /icanwrite/here\n```\n\n``` \n$ docker run -t -i --mount type=bind,src=/data,dst=/data busybox sh\n```\n\n### Publish or expose port (-p, --expose)\n\n``` \n$ docker run -p 127.0.0.1:80:8080/tcp ubuntu bash\n```\n\nThis binds port `8080` of the container to TCP port `80` on `127.0.0.1` of the host machine. You can also specify `udp` and `sctp` ports. The [Docker User Guide](https://docs.docker.com/network/links/) explains in detail how to manipulate ports in Docker.\n\nNote that ports which are not bound to the host (i.e., `-p 80:80` instead of `-p 127.0.0.1:80:80`) will be accessible from the outside. This also applies if you configured UFW to block this specific port, as Docker manages its own iptables rules. [Read more](https://docs.docker.com/network/iptables/)\n\n``` \n$ docker run --expose 80 ubuntu bash\n```\n\nThis exposes port `80` of the container without publishing the port to the host system’s interfaces.\n\n### Set the pull policy (--pull)\n\nUse the `--pull` flag to set the image pull policy when creating (and running) the container.\n\nThe `--pull` flag can take one of these values:\n\n| Value               | Description                                                                                                       |\n|:--------------------|:------------------------------------------------------------------------------------------------------------------|\n| `missing` (default) | Pull the image if it was not found in the image cache, or use the cached image otherwise.                         |\n| `never`             | Do not pull the image, even if it’s missing, and produce an error if the image does not exist in the image cache. |\n| `always`            | Always perform a pull before creating the container.                                                              |\n\nWhen creating (and running) a container from an image, the daemon checks if the image exists in the local image cache. If the image is missing, an error is returned to the cli, allowing it to initiate a pull.\n\nThe default (`missing`) is to only pull the image if it is not present in the daemon’s image cache. This default allows you to run images that only exist locally (for example, images you built from a Dockerfile, but that have not been pushed to a registry), and reduces networking.\n\nThe `always` option always initiates a pull before creating the container. This option makes sure the image is up-to-date, and prevents you from using outdated images, but may not be suitable in situations where you want to test a locally built image before pushing (as pulling the image overwrites the existing image in the image cache).\n\nThe `never` option disables (implicit) pulling images when creating containers, and only uses images that are available in the image cache. If the specified image is not found, an error is produced, and the container is not created. This option is useful in situations where networking is not available, or to prevent images from being pulled implicitly when creating containers.\n\nThe following example shows `docker run` with the `--pull=never` option set, which produces en error as the image is missing in the image-cache:\n\n``` \n$ docker run --pull=never hello-world\ndocker: Error response from daemon: No such image: hello-world:latest.\n```\n\n### Set environment variables (-e, --env, --env-file)\n\n``` \n$ docker run -e MYVAR1 --env MYVAR2=foo --env-file ./env.list ubuntu bash\n```\n\nUse the `-e`, `--env`, and `--env-file` flags to set simple (non-array) environment variables in the container you’re running, or overwrite variables that are defined in the Dockerfile of the image you’re running.\n\nYou can define the variable and its value when running the container:\n\n``` \n$ docker run --env VAR1=value1 --env VAR2=value2 ubuntu env | grep VAR\nVAR1=value1\nVAR2=value2\n```\n\nYou can also use variables that you’ve exported to your local environment:\n\n``` \nexport VAR1=value1\nexport VAR2=value2\n\n$ docker run --env VAR1 --env VAR2 ubuntu env | grep VAR\nVAR1=value1\nVAR2=value2\n```\n\nWhen running the command, the Docker CLI client checks the value the variable has in your local environment and passes it to the container. If no `=` is provided and that variable is not exported in your local environment, the variable won’t be set in the container.\n\nYou can also load the environment variables from a file. This file should use the syntax `<variable>=value` (which sets the variable to the given value) or `<variable>` (which takes the value from the local environment), and `#` for comments.\n\n``` \n$ cat env.list\n# This is a comment\nVAR1=value1\nVAR2=value2\nUSER\n\n$ docker run --env-file env.list ubuntu env | grep -E 'VAR|USER'\nVAR1=value1\nVAR2=value2\nUSER=jonzeolla\n```\n\n### Set metadata on container (-l, --label, --label-file)\n\nA label is a `key=value` pair that applies metadata to a container. To label a container with two labels:\n\n``` \n$ docker run -l my-label --label com.example.foo=bar ubuntu bash\n```\n\nThe `my-label` key doesn’t specify a value so the label defaults to an empty string (`\"\"`). To add multiple labels, repeat the label flag (`-l` or `--label`).\n\nThe `key=value` must be unique to avoid overwriting the label value. If you specify labels with identical keys but different values, each subsequent value overwrites the previous. Docker uses the last `key=value` you supply.\n\nUse the `--label-file` flag to load multiple labels from a file. Delimit each label in the file with an EOL mark. The example below loads labels from a labels file in the current directory:\n\n``` \n$ docker run --label-file ./labels ubuntu bash\n```\n\nThe label-file format is similar to the format for loading environment variables. (Unlike environment variables, labels are not visible to processes running inside a container.) The following example illustrates a label-file format:\n\n``` \ncom.example.label1=\"a label\"\n\n# this is a comment\ncom.example.label2=another\\ label\ncom.example.label3\n```\n\nYou can load multiple label-files by supplying multiple `--label-file` flags.\n\nFor additional information on working with labels, see [*Labels - custom metadata in Docker*](https://docs.docker.com/config/labels-custom-metadata/) in the Docker User Guide.\n\n### Connect a container to a network (--network)\n\nWhen you start a container use the `--network` flag to connect it to a network. This adds the `busybox` container to the `my-net` network.\n\n``` \n$ docker run -itd --network=my-net busybox\n```\n\nYou can also choose the IP addresses for the container with `--ip` and `--ip6` flags when you start the container on a user-defined network.\n\n``` \n$ docker run -itd --network=my-net --ip=10.10.9.75 busybox\n```\n\nIf you want to add a running container to a network use the `docker network connect` subcommand.\n\nYou can connect multiple containers to the same network. Once connected, the containers can communicate easily using only another container’s IP address or name. For `overlay` networks or custom plugins that support multi-host connectivity, containers connected to the same multi-host network but launched from different Engines can also communicate in this way.\n\n> **Note**\n>\n> Service discovery is unavailable on the default bridge network. Containers can communicate via their IP addresses by default. To communicate by name, they must be linked.\n\nYou can disconnect a container from a network using the `docker network disconnect` command.\n\n### Mount volumes from container (--volumes-from)\n\n``` \n$ docker run --volumes-from 777f7dc92da7 --volumes-from ba8c0c54f0f2:ro -i -t ubuntu pwd\n```\n\nThe `--volumes-from` flag mounts all the defined volumes from the referenced containers. Containers can be specified by repetitions of the `--volumes-from` argument. The container ID may be optionally suffixed with `:ro` or `:rw` to mount the volumes in read-only or read-write mode, respectively. By default, the volumes are mounted in the same mode (read write or read only) as the reference container.\n\nLabeling systems like SELinux require that proper labels are placed on volume content mounted into a container. Without a label, the security system might prevent the processes running inside the container from using the content. By default, Docker does not change the labels set by the OS.\n\nTo change the label in the container context, you can add either of two suffixes `:z` or `:Z` to the volume mount. These suffixes tell Docker to relabel file objects on the shared volumes. The `z` option tells Docker that two containers share the volume content. As a result, Docker labels the content with a shared content label. Shared volume labels allow all containers to read/write content. The `Z` option tells Docker to label the content with a private unshared label. Only the current container can use a private volume.\n\n### Attach to STDIN/STDOUT/STDERR (-a)\n\nThe `-a` flag tells `docker run` to bind to the container’s `STDIN`, `STDOUT` or `STDERR`. This makes it possible to manipulate the output and input as needed.\n\n``` \n$ echo \"test\" | docker run -i -a stdin ubuntu cat -\n```\n\nThis pipes data into a container and prints the container’s ID by attaching only to the container’s `STDIN`.\n\n``` \n$ docker run -a stderr ubuntu echo test\n```\n\nThis isn’t going to print anything unless there’s an error because we’ve only attached to the `STDERR` of the container. The container’s logs still store what’s been written to `STDERR` and `STDOUT`.\n\n``` \n$ cat somefile | docker run -i -a stdin mybuilder dobuild\n```\n\nThis is how piping a file into a container could be done for a build. The container’s ID will be printed after the build is done and the build logs could be retrieved using `docker logs`. This is useful if you need to pipe a file or something else into a container and retrieve the container’s ID once the container has finished running.\n\n### Add host device to container (--device)\n\n``` \n$ docker run --device=/dev/sdc:/dev/xvdc \\\n             --device=/dev/sdd --device=/dev/zero:/dev/nulo \\\n             -i -t \\\n             ubuntu ls -l /dev/{xvdc,sdd,nulo}\n\nbrw-rw---- 1 root disk 8, 2 Feb  9 16:05 /dev/xvdc\nbrw-rw---- 1 root disk 8, 3 Feb  9 16:05 /dev/sdd\ncrw-rw-rw- 1 root root 1, 5 Feb  9 16:05 /dev/nulo\n```\n\nIt is often necessary to directly expose devices to a container. The `--device` option enables that. For example, a specific block storage device or loop device or audio device can be added to an otherwise unprivileged container (without the `--privileged` flag) and have the application directly access it.\n\nBy default, the container will be able to `read`, `write` and `mknod` these devices. This can be overridden using a third `:rwm` set of options to each `--device` flag. If the container is running in privileged mode, then the permissions specified will be ignored.\n\n``` \n$ docker run --device=/dev/sda:/dev/xvdc --rm -it ubuntu fdisk  /dev/xvdc\n\nCommand (m for help): q\n$ docker run --device=/dev/sda:/dev/xvdc:r --rm -it ubuntu fdisk  /dev/xvdc\nYou will not be able to write the partition table.\n\nCommand (m for help): q\n\n$ docker run --device=/dev/sda:/dev/xvdc:rw --rm -it ubuntu fdisk  /dev/xvdc\n\nCommand (m for help): q\n\n$ docker run --device=/dev/sda:/dev/xvdc:m --rm -it ubuntu fdisk  /dev/xvdc\nfdisk: unable to open /dev/xvdc: Operation not permitted\n```\n\n> **Note**\n>\n> The `--device` option cannot be safely used with ephemeral devices. Block devices that may be removed should not be added to untrusted containers with `--device`.\n\nFor Windows, the format of the string passed to the `--device` option is in the form of `--device=<IdType>/<Id>`. Beginning with Windows Server 2019 and Windows 10 October 2018 Update, Windows only supports an IdType of `class` and the Id as a [device interface class GUID](https://docs.microsoft.com/en-us/windows-hardware/drivers/install/overview-of-device-interface-classes). Refer to the table defined in the [Windows container docs](https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/hardware-devices-in-containers) for a list of container-supported device interface class GUIDs.\n\nIf this option is specified for a process-isolated Windows container, *all* devices that implement the requested device interface class GUID are made available in the container. For example, the command below makes all COM ports on the host visible in the container.\n\n``` \nPS C:\\> docker run --device=class/86E0D1E0-8089-11D0-9CE4-08003E301F73 mcr.microsoft.com/windows/servercore:ltsc2019\n```\n\n> **Note**\n>\n> The `--device` option is only supported on process-isolated Windows containers. This option fails if the container isolation is `hyperv` or when running Linux Containers on Windows (LCOW).\n\n### Using dynamically created devices (--device-cgroup-rule)\n\nDevices available to a container are assigned at creation time. The assigned devices will both be added to the cgroup.allow file and created into the container once it is run. This poses a problem when a new device needs to be added to running container.\n\nOne of the solutions is to add a more permissive rule to a container allowing it access to a wider range of devices. For example, supposing our container needs access to a character device with major `42` and any number of minor number (added as new devices appear), the following rule would be added:\n\n``` \n$ docker run -d --device-cgroup-rule='c 42:* rmw' -name my-container my-image\n```\n\nThen, a user could ask `udev` to execute a script that would `docker exec my-container mknod newDevX c 42 <minor>` the required device when it is added.\n\n> **Note**: initially present devices still need to be explicitly added to the `docker run` / `docker create` command.\n\n### Access an NVIDIA GPU\n\nThe `--gpus` flag allows you to access NVIDIA GPU resources. First you need to install [nvidia-container-runtime](https://nvidia.github.io/nvidia-container-runtime/). Visit [Specify a container’s resources](https://docs.docker.com/config/containers/resource_constraints/) for more information.\n\nTo use `--gpus`, specify which GPUs (or all) to use. If no value is provied, all available GPUs are used. The example below exposes all available GPUs.\n\n``` \n$ docker run -it --rm --gpus all ubuntu nvidia-smi\n```\n\nUse the `device` option to specify GPUs. The example below exposes a specific GPU.\n\n``` \n$ docker run -it --rm --gpus device=GPU-3a23c669-1f69-c64e-cf85-44e9b07e7a2a ubuntu nvidia-smi\n```\n\nThe example below exposes the first and third GPUs.\n\n``` \n$ docker run -it --rm --gpus '\"device=0,2\"' nvidia-smi\n```\n\n### Restart policies (--restart)\n\nUse Docker’s `--restart` to specify a container’s *restart policy*. A restart policy controls whether the Docker daemon restarts a container after exit. Docker supports the following restart policies:\n\n| Policy                     | Result                                                                                                                                                                                                                                                           |\n|:---------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `no`                       | Do not automatically restart the container when it exits. This is the default.                                                                                                                                                                                   |\n| `on-failure[:max-retries]` | Restart only if the container exits with a non-zero exit status. Optionally, limit the number of restart retries the Docker daemon attempts.                                                                                                                     |\n| `unless-stopped`           | Restart the container unless it is explicitly stopped or Docker itself is stopped or restarted.                                                                                                                                                                  |\n| `always`                   | Always restart the container regardless of the exit status. When you specify always, the Docker daemon will try to restart the container indefinitely. The container will also always start on daemon startup, regardless of the current state of the container. |\n\n``` \n$ docker run --restart=always redis\n```\n\nThis will run the `redis` container with a restart policy of **always** so that if the container exits, Docker will restart it.\n\nMore detailed information on restart policies can be found in the [Restart Policies (--restart)](../../run/index#restart-policies---restart) section of the Docker run reference page.\n\n### Add entries to container hosts file (--add-host)\n\nYou can add other hosts into a container’s `/etc/hosts` file by using one or more `--add-host` flags. This example adds a static address for a host named `docker`:\n\n``` \n$ docker run --add-host=docker:93.184.216.34 --rm -it alpine\n\n/ # ping docker\nPING docker (93.184.216.34): 56 data bytes\n64 bytes from 93.184.216.34: seq=0 ttl=37 time=93.052 ms\n64 bytes from 93.184.216.34: seq=1 ttl=37 time=92.467 ms\n64 bytes from 93.184.216.34: seq=2 ttl=37 time=92.252 ms\n^C\n--- docker ping statistics ---\n4 packets transmitted, 4 packets received, 0% packet loss\nround-trip min/avg/max = 92.209/92.495/93.052 ms\n```\n\nSometimes you need to connect to the Docker host from within your container. To enable this, pass the Docker host’s IP address to the container using the `--add-host` flag. To find the host’s address, use the `ip addr show` command.\n\nThe flags you pass to `ip addr show` depend on whether you are using IPv4 or IPv6 networking in your containers. Use the following flags for IPv4 address retrieval for a network device named `eth0`:\n\n``` \n$ HOSTIP=`ip -4 addr show scope global dev eth0 | grep inet | awk '{print $2}' | cut -d / -f 1 | sed -n 1p`\n$ docker run  --add-host=docker:${HOSTIP} --rm -it debian\n```\n\nFor IPv6 use the `-6` flag instead of the `-4` flag. For other network devices, replace `eth0` with the correct device name (for example `docker0` for the bridge device).\n\n### Set ulimits in container (--ulimit)\n\nSince setting `ulimit` settings in a container requires extra privileges not available in the default container, you can set these using the `--ulimit` flag. `--ulimit` is specified with a soft and hard limit as such: `<type>=<soft limit>[:<hard limit>]`, for example:\n\n``` \n$ docker run --ulimit nofile=1024:1024 --rm debian sh -c \"ulimit -n\"\n1024\n```\n\n> **Note**\n>\n> If you do not provide a `hard limit`, the `soft limit` is used for both values. If no `ulimits` are set, they are inherited from the default `ulimits` set on the daemon. The `as` option is disabled now. In other words, the following script is not supported:\n>\n> ``` \n> $ docker run -it --ulimit as=1024 fedora /bin/bash\n> ```\n\nThe values are sent to the appropriate `syscall` as they are set. Docker doesn’t perform any byte conversion. Take this into account when setting the values.\n\n#### For `nproc` usage\n\nBe careful setting `nproc` with the `ulimit` flag as `nproc` is designed by Linux to set the maximum number of processes available to a user, not to a container. For example, start four containers with `daemon` user:\n\n``` \n$ docker run -d -u daemon --ulimit nproc=3 busybox top\n\n$ docker run -d -u daemon --ulimit nproc=3 busybox top\n\n$ docker run -d -u daemon --ulimit nproc=3 busybox top\n\n$ docker run -d -u daemon --ulimit nproc=3 busybox top\n```\n\nThe 4th container fails and reports “\\[8\\] System error: resource temporarily unavailable” error. This fails because the caller set `nproc=3` resulting in the first three containers using up the three processes quota set for the `daemon` user.\n\n### Stop container with signal (--stop-signal)\n\nThe `--stop-signal` flag sets the system call signal that will be sent to the container to exit. This signal can be a signal name in the format `SIG<NAME>`, for instance `SIGKILL`, or an unsigned number that matches a position in the kernel’s syscall table, for instance `9`.\n\nThe default is `SIGTERM` if not specified.\n\n### Optional security options (--security-opt)\n\nOn Windows, this flag can be used to specify the `credentialspec` option. The `credentialspec` must be in the format `file://spec.txt` or `registry://keyname`.\n\n### Stop container with timeout (--stop-timeout)\n\nThe `--stop-timeout` flag sets the number of seconds to wait for the container to stop after sending the pre-defined (see `--stop-signal`) system call signal. If the container does not exit after the timeout elapses, it is forcibly killed with a `SIGKILL` signal.\n\nIf `--stop-timeout` is set to `-1`, no timeout is applied, and the daemon will wait indefinitely for the container to exit.\n\nThe default is determined by the daemon, and is 10 seconds for Linux containers, and 30 seconds for Windows containers.\n\n### Specify isolation technology for container (--isolation)\n\nThis option is useful in situations where you are running Docker containers on Windows. The `--isolation=<value>` option sets a container’s isolation technology. On Linux, the only supported is the `default` option which uses Linux namespaces. These two commands are equivalent on Linux:\n\n``` \n$ docker run -d busybox top\n$ docker run -d --isolation default busybox top\n```\n\nOn Windows, `--isolation` can take one of these values:\n\n| Value     | Description                                                                                |\n|:----------|:-------------------------------------------------------------------------------------------|\n| `default` | Use the value specified by the Docker daemon’s `--exec-opt` or system default (see below). |\n| `process` | Shared-kernel namespace isolation.                                                         |\n| `hyperv`  | Hyper-V hypervisor partition-based isolation.                                              |\n\nThe default isolation on Windows server operating systems is `process`, and `hyperv` on Windows client operating systems, such as Windows 10. Process isolation is more performant, but requires the image to\n\nOn Windows server, assuming the default configuration, these commands are equivalent and result in `process` isolation:\n\n``` \nPS C:\\> docker run -d microsoft/nanoserver powershell echo process\nPS C:\\> docker run -d --isolation default microsoft/nanoserver powershell echo process\nPS C:\\> docker run -d --isolation process microsoft/nanoserver powershell echo process\n```\n\nIf you have set the `--exec-opt isolation=hyperv` option on the Docker `daemon`, or are running against a Windows client-based daemon, these commands are equivalent and result in `hyperv` isolation:\n\n``` \nPS C:\\> docker run -d microsoft/nanoserver powershell echo hyperv\nPS C:\\> docker run -d --isolation default microsoft/nanoserver powershell echo hyperv\nPS C:\\> docker run -d --isolation hyperv microsoft/nanoserver powershell echo hyperv\n```\n\n### Specify hard limits on memory available to containers (-m, --memory)\n\nThese parameters always set an upper limit on the memory available to the container. On Linux, this is set on the cgroup and applications in a container can query it at `/sys/fs/cgroup/memory/memory.limit_in_bytes`.\n\nOn Windows, this will affect containers differently depending on what type of isolation is used.\n\n- With `process` isolation, Windows will report the full memory of the host system, not the limit to applications running inside the container\n\n  ``` \n    PS C:\\> docker run -it -m 2GB --isolation=process microsoft/nanoserver powershell Get-ComputerInfo *memory*\n\n    CsTotalPhysicalMemory      : 17064509440\n    CsPhyicallyInstalledMemory : 16777216\n    OsTotalVisibleMemorySize   : 16664560\n    OsFreePhysicalMemory       : 14646720\n    OsTotalVirtualMemorySize   : 19154928\n    OsFreeVirtualMemory        : 17197440\n    OsInUseVirtualMemory       : 1957488\n    OsMaxProcessMemorySize     : 137438953344\n  ```\n\n- With `hyperv` isolation, Windows will create a utility VM that is big enough to hold the memory limit, plus the minimal OS needed to host the container. That size is reported as “Total Physical Memory.”\n\n  ``` \n    PS C:\\> docker run -it -m 2GB --isolation=hyperv microsoft/nanoserver powershell Get-ComputerInfo *memory*\n\n    CsTotalPhysicalMemory      : 2683355136\n    CsPhyicallyInstalledMemory :\n    OsTotalVisibleMemorySize   : 2620464\n    OsFreePhysicalMemory       : 2306552\n    OsTotalVirtualMemorySize   : 2620464\n    OsFreeVirtualMemory        : 2356692\n    OsInUseVirtualMemory       : 263772\n    OsMaxProcessMemorySize     : 137438953344\n  ```\n\n### Configure namespaced kernel parameters (sysctls) at runtime\n\nThe `--sysctl` sets namespaced kernel parameters (sysctls) in the container. For example, to turn on IP forwarding in the containers network namespace, run this command:\n\n``` \n$ docker run --sysctl net.ipv4.ip_forward=1 someimage\n```\n\n> **Note**\n>\n> Not all sysctls are namespaced. Docker does not support changing sysctls inside of a container that also modify the host system. As the kernel evolves we expect to see more sysctls become namespaced.\n\n#### Currently supported sysctls\n\nIPC Namespace:\n\n- `kernel.msgmax`, `kernel.msgmnb`, `kernel.msgmni`, `kernel.sem`, `kernel.shmall`, `kernel.shmmax`, `kernel.shmmni`, `kernel.shm_rmid_forced`.\n- Sysctls beginning with `fs.mqueue.*`\n- If you use the `--ipc=host` option these sysctls are not allowed.\n\nNetwork Namespace:\n\n- Sysctls beginning with `net.*`\n- If you use the `--network=host` option using these sysctls are not allowed.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/run/](https://docs.docker.com/engine/reference/commandline/run/)"
- name: Docker run reference
  id: engine/reference/run/index
  summary: Docker runs processes in isolated containers
  description: "# Docker run reference\n\nDocker runs processes in isolated containers. A container is a process which runs on a host. The host may be local or remote. When an operator executes `docker run`, the container process that runs is isolated in that it has its own file system, its own networking, and its own isolated process tree separate from the host.\n\nThis page details how to use the `docker run` command to define the container’s resources at runtime.\n\n## General form\n\nThe basic `docker run` command takes this form:\n\n``` \n$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]\n```\n\nThe `docker run` command must specify an [*IMAGE*](https://docs.docker.com/glossary/#image) to derive the container from. An image developer can define image defaults related to:\n\n- detached or foreground running\n- container identification\n- network settings\n- runtime constraints on CPU and memory\n\nWith the `docker run [OPTIONS]` an operator can add to or override the image defaults set by a developer. And, additionally, operators can override nearly all the defaults set by the Docker runtime itself. The operator’s ability to override image and Docker runtime defaults is why [*run*](../commandline/run/index) has more options than any other `docker` command.\n\nTo learn how to interpret the types of `[OPTIONS]`, see [*Option types*](../commandline/cli/index#option-types).\n\n> **Note**\n>\n> Depending on your Docker system configuration, you may be required to preface the `docker run` command with `sudo`. To avoid having to use `sudo` with the `docker` command, your system administrator can create a Unix group called `docker` and add users to it. For more information about this configuration, refer to the Docker installation documentation for your operating system.\n\n## Operator exclusive options\n\nOnly the operator (the person executing `docker run`) can set the following options.\n\n- [Detached vs foreground](#detached-vs-foreground)\n  - [Detached (-d)](#detached--d)\n  - [Foreground](#foreground)\n- [Container identification](#container-identification)\n  - [Name (--name)](#name---name)\n  - [PID equivalent](#pid-equivalent)\n- [IPC settings (--ipc)](#ipc-settings---ipc)\n- [Network settings](#network-settings)\n- [Restart policies (--restart)](#restart-policies---restart)\n- [Clean up (--rm)](#clean-up---rm)\n- [Runtime constraints on resources](#runtime-constraints-on-resources)\n- [Runtime privilege and Linux capabilities](#runtime-privilege-and-linux-capabilities)\n\n## Detached vs foreground\n\nWhen starting a Docker container, you must first decide if you want to run the container in the background in a “detached” mode or in the default foreground mode:\n\n``` \n-d=false: Detached mode: Run container in the background, print new container id\n```\n\n### Detached (-d)\n\nTo start a container in detached mode, you use `-d=true` or just `-d` option. By design, containers started in detached mode exit when the root process used to run the container exits, unless you also specify the `--rm` option. If you use `-d` with `--rm`, the container is removed when it exits **or** when the daemon exits, whichever happens first.\n\nDo not pass a `service x start` command to a detached container. For example, this command attempts to start the `nginx` service.\n\n``` \n$ docker run -d -p 80:80 my_image service nginx start\n```\n\nThis succeeds in starting the `nginx` service inside the container. However, it fails the detached container paradigm in that, the root process (`service nginx start`) returns and the detached container stops as designed. As a result, the `nginx` service is started but could not be used. Instead, to start a process such as the `nginx` web server do the following:\n\n``` \n$ docker run -d -p 80:80 my_image nginx -g 'daemon off;'\n```\n\nTo do input/output with a detached container use network connections or shared volumes. These are required because the container is no longer listening to the command line where `docker run` was run.\n\nTo reattach to a detached container, use `docker` [*attach*](../commandline/attach/index) command.\n\n### Foreground\n\nIn foreground mode (the default when `-d` is not specified), `docker run` can start the process in the container and attach the console to the process’s standard input, output, and standard error. It can even pretend to be a TTY (this is what most command line executables expect) and pass along signals. All of that is configurable:\n\n``` \n-a=[]           : Attach to `STDIN`, `STDOUT` and/or `STDERR`\n-t              : Allocate a pseudo-tty\n--sig-proxy=true: Proxy all received signals to the process (non-TTY mode only)\n-i              : Keep STDIN open even if not attached\n```\n\nIf you do not specify `-a` then Docker will [attach to both stdout and stderr](https://github.com/docker/docker/blob/4118e0c9eebda2412a09ae66e90c34b85fae3275/runconfig/opts/parse.go#L267) . You can specify to which of the three standard streams (`STDIN`, `STDOUT`, `STDERR`) you’d like to connect instead, as in:\n\n``` \n$ docker run -a stdin -a stdout -i -t ubuntu /bin/bash\n```\n\nFor interactive processes (like a shell), you must use `-i -t` together in order to allocate a tty for the container process. `-i -t` is often written `-it` as you’ll see in later examples. Specifying `-t` is forbidden when the client is receiving its standard input from a pipe, as in:\n\n``` \n$ echo test | docker run -i busybox cat\n```\n\n> **Note**\n>\n> A process running as PID 1 inside a container is treated specially by Linux: it ignores any signal with the default action. As a result, the process will not terminate on `SIGINT` or `SIGTERM` unless it is coded to do so.\n\n## Container identification\n\n### Name (--name)\n\nThe operator can identify a container in three ways:\n\n| Identifier type       | Example value                                                      |\n|:----------------------|:-------------------------------------------------------------------|\n| UUID long identifier  | “f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778” |\n| UUID short identifier | “f78375b1c487”                                                     |\n| Name                  | “evil_ptolemy”                                                     |\n\nThe UUID identifiers come from the Docker daemon. If you do not assign a container name with the `--name` option, then the daemon generates a random string name for you. Defining a `name` can be a handy way to add meaning to a container. If you specify a `name`, you can use it when referencing the container within a Docker network. This works for both background and foreground Docker containers.\n\n> **Note**\n>\n> Containers on the default bridge network must be linked to communicate by name.\n\n### PID equivalent\n\nFinally, to help with automation, you can have Docker write the container ID out to a file of your choosing. This is similar to how some programs might write out their process ID to a file (you’ve seen them as PID files):\n\n``` \n--cidfile=\"\": Write the container ID to the file\n```\n\n### Image\\[:tag\\]\n\nWhile not strictly a means of identifying a container, you can specify a version of an image you’d like to run the container with by adding `image[:tag]` to the command. For example, `docker run ubuntu:14.04`.\n\n### Image\\[@digest\\]\n\nImages using the v2 or later image format have a content-addressable identifier called a digest. As long as the input used to generate the image is unchanged, the digest value is predictable and referenceable.\n\nThe following example runs a container from the `alpine` image with the `sha256:9cacb71397b640eca97488cf08582ae4e4068513101088e9f96c9814bfda95e0` digest:\n\n``` \n$ docker run alpine@sha256:9cacb71397b640eca97488cf08582ae4e4068513101088e9f96c9814bfda95e0 date\n```\n\n## PID settings (--pid)\n\n``` \n--pid=\"\"  : Set the PID (Process) Namespace mode for the container,\n             'container:<name|id>': joins another container's PID namespace\n             'host': use the host's PID namespace inside the container\n```\n\nBy default, all containers have the PID namespace enabled.\n\nPID namespace provides separation of processes. The PID Namespace removes the view of the system processes, and allows process ids to be reused including pid 1.\n\nIn certain cases you want your container to share the host’s process namespace, basically allowing processes within the container to see all of the processes on the system. For example, you could build a container with debugging tools like `strace` or `gdb`, but want to use these tools when debugging processes within the container.\n\n### Example: run htop inside a container\n\nCreate this Dockerfile:\n\n``` \nFROM alpine:latest\nRUN apk add --update htop && rm -rf /var/cache/apk/*\nCMD [\"htop\"]\n```\n\nBuild the Dockerfile and tag the image as `myhtop`:\n\n``` \n$ docker build -t myhtop .\n```\n\nUse the following command to run `htop` inside a container:\n\n``` \n$ docker run -it --rm --pid=host myhtop\n```\n\nJoining another container’s pid namespace can be used for debugging that container.\n\n### Example\n\nStart a container running a redis server:\n\n``` \n$ docker run --name my-redis -d redis\n```\n\nDebug the redis container by running another container that has strace in it:\n\n``` \n$ docker run -it --pid=container:my-redis my_strace_docker_image bash\n$ strace -p 1\n```\n\n## UTS settings (--uts)\n\n``` \n--uts=\"\"  : Set the UTS namespace mode for the container,\n       'host': use the host's UTS namespace inside the container\n```\n\nThe UTS namespace is for setting the hostname and the domain that is visible to running processes in that namespace. By default, all containers, including those with `--network=host`, have their own UTS namespace. The `host` setting will result in the container using the same UTS namespace as the host. Note that `--hostname` and `--domainname` are invalid in `host` UTS mode.\n\nYou may wish to share the UTS namespace with the host if you would like the hostname of the container to change as the hostname of the host changes. A more advanced use case would be changing the host’s hostname from a container.\n\n## IPC settings (--ipc)\n\n``` \n--ipc=\"MODE\"  : Set the IPC mode for the container\n```\n\nThe following values are accepted:\n\n| Value                           | Description                                                                      |\n|:--------------------------------|:---------------------------------------------------------------------------------|\n| ””                              | Use daemon’s default.                                                            |\n| “none”                          | Own private IPC namespace, with /dev/shm not mounted.                            |\n| “private”                       | Own private IPC namespace.                                                       |\n| “shareable”                     | Own private IPC namespace, with a possibility to share it with other containers. |\n| “container: \\<\\_name-or-ID\\_\\>\" | Join another (“shareable”) container’s IPC namespace.                            |\n| “host”                          | Use the host system’s IPC namespace.                                             |\n\nIf not specified, daemon default is used, which can either be `\"private\"` or `\"shareable\"`, depending on the daemon version and configuration.\n\nIPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments, semaphores and message queues.\n\nShared memory segments are used to accelerate inter-process communication at memory speed, rather than through pipes or through the network stack. Shared memory is commonly used by databases and custom-built (typically C/OpenMPI, C++/using boost libraries) high performance applications for scientific computing and financial services industries. If these types of applications are broken into multiple containers, you might need to share the IPC mechanisms of the containers, using `\"shareable\"` mode for the main (i.e. “donor”) container, and `\"container:<donor-name-or-ID>\"` for other containers.\n\n## Network settings\n\n``` \n--dns=[]           : Set custom dns servers for the container\n--network=\"bridge\" : Connect a container to a network\n                      'bridge': create a network stack on the default Docker bridge\n                      'none': no networking\n                      'container:<name|id>': reuse another container's network stack\n                      'host': use the Docker host network stack\n                      '<network-name>|<network-id>': connect to a user-defined network\n--network-alias=[] : Add network-scoped alias for the container\n--add-host=\"\"      : Add a line to /etc/hosts (host:IP)\n--mac-address=\"\"   : Sets the container's Ethernet device's MAC address\n--ip=\"\"            : Sets the container's Ethernet device's IPv4 address\n--ip6=\"\"           : Sets the container's Ethernet device's IPv6 address\n--link-local-ip=[] : Sets one or more container's Ethernet device's link local IPv4/IPv6 addresses\n```\n\nBy default, all containers have networking enabled and they can make any outgoing connections. The operator can completely disable networking with `docker run --network none` which disables all incoming and outgoing networking. In cases like this, you would perform I/O through files or `STDIN` and `STDOUT` only.\n\nPublishing ports and linking to other containers only works with the default (bridge). The linking feature is a legacy feature. You should always prefer using Docker network drivers over linking.\n\nYour container will use the same DNS servers as the host by default, but you can override this with `--dns`.\n\nBy default, the MAC address is generated using the IP address allocated to the container. You can set the container’s MAC address explicitly by providing a MAC address via the `--mac-address` parameter (format:`12:34:56:78:9a:bc`).Be aware that Docker does not check if manually specified MAC addresses are unique.\n\nSupported networks :\n\n| Network                    | Description                                                                              |\n|----------------------------|------------------------------------------------------------------------------------------|\n| **none**                   | No networking in the container.                                                          |\n| **bridge** (default)       | Connect the container to the bridge via veth interfaces.                                 |\n| **host**                   | Use the host's network stack inside the container.                                       |\n| **container**:\\<name\\|id\\> | Use the network stack of another container, specified via its *name* or *id*.            |\n| **NETWORK**                | Connects the container to a user created network (using `docker network create` command) |\n\n#### Network: none\n\nWith the network is `none` a container will not have access to any external routes. The container will still have a `loopback` interface enabled in the container but it does not have any routes to external traffic.\n\n#### Network: bridge\n\nWith the network set to `bridge` a container will use docker’s default networking setup. A bridge is setup on the host, commonly named `docker0`, and a pair of `veth` interfaces will be created for the container. One side of the `veth` pair will remain on the host attached to the bridge while the other side of the pair will be placed inside the container’s namespaces in addition to the `loopback` interface. An IP address will be allocated for containers on the bridge’s network and traffic will be routed though this bridge to the container.\n\nContainers can communicate via their IP addresses by default. To communicate by name, they must be linked.\n\n#### Network: host\n\nWith the network set to `host` a container will share the host’s network stack and all interfaces from the host will be available to the container. The container’s hostname will match the hostname on the host system. Note that `--mac-address` is invalid in `host` netmode. Even in `host` network mode a container has its own UTS namespace by default. As such `--hostname` and `--domainname` are allowed in `host` network mode and will only change the hostname and domain name inside the container. Similar to `--hostname`, the `--add-host`, `--dns`, `--dns-search`, and `--dns-option` options can be used in `host` network mode. These options update `/etc/hosts` or `/etc/resolv.conf` inside the container. No change are made to `/etc/hosts` and `/etc/resolv.conf` on the host.\n\nCompared to the default `bridge` mode, the `host` mode gives *significantly* better networking performance since it uses the host’s native networking stack whereas the bridge has to go through one level of virtualization through the docker daemon. It is recommended to run containers in this mode when their networking performance is critical, for example, a production Load Balancer or a High Performance Web Server.\n\n> **Note**\n>\n> `--network=\"host\"` gives the container full access to local system services such as D-bus and is therefore considered insecure.\n\n#### Network: container\n\nWith the network set to `container` a container will share the network stack of another container. The other container’s name must be provided in the format of `--network container:<name|id>`. Note that `--add-host` `--hostname` `--dns` `--dns-search` `--dns-option` and `--mac-address` are invalid in `container` netmode, and `--publish` `--publish-all` `--expose` are also invalid in `container` netmode.\n\nExample running a Redis container with Redis binding to `localhost` then running the `redis-cli` command and connecting to the Redis server over the `localhost` interface.\n\n``` \n$ docker run -d --name redis example/redis --bind 127.0.0.1\n$ # use the redis container's network stack to access localhost\n$ docker run --rm -it --network container:redis example/redis-cli -h 127.0.0.1\n```\n\n#### User-defined network\n\nYou can create a network using a Docker network driver or an external network driver plugin. You can connect multiple containers to the same network. Once connected to a user-defined network, the containers can communicate easily using only another container’s IP address or name.\n\nFor `overlay` networks or custom plugins that support multi-host connectivity, containers connected to the same multi-host network but launched from different Engines can also communicate in this way.\n\nThe following example creates a network using the built-in `bridge` network driver and running a container in the created network\n\n``` \n$ docker network create -d bridge my-net\n$ docker run --network=my-net -itd --name=container3 busybox\n```\n\n### Managing /etc/hosts\n\nYour container will have lines in `/etc/hosts` which define the hostname of the container itself as well as `localhost` and a few other common things. The `--add-host` flag can be used to add additional lines to `/etc/hosts`.\n\n``` \n$ docker run -it --add-host db-static:86.75.30.9 ubuntu cat /etc/hosts\n\n172.17.0.22     09d03f76bf2c\nfe00::0         ip6-localnet\nff00::0         ip6-mcastprefix\nff02::1         ip6-allnodes\nff02::2         ip6-allrouters\n127.0.0.1       localhost\n::1             localhost ip6-localhost ip6-loopback\n86.75.30.9      db-static\n```\n\nIf a container is connected to the default bridge network and `linked` with other containers, then the container’s `/etc/hosts` file is updated with the linked container’s name.\n\n> **Note**\n>\n> Since Docker may live update the container’s `/etc/hosts` file, there may be situations when processes inside the container can end up reading an empty or incomplete `/etc/hosts` file. In most cases, retrying the read again should fix the problem.\n\n## Restart policies (--restart)\n\nUsing the `--restart` flag on Docker run you can specify a restart policy for how a container should or should not be restarted on exit.\n\nWhen a restart policy is active on a container, it will be shown as either `Up` or `Restarting` in [`docker ps`](../commandline/ps/index). It can also be useful to use [`docker events`](../commandline/events/index) to see the restart policy in effect.\n\nDocker supports the following restart policies:\n\n| Policy                           | Result                                                                                                                                                                                                                                                           |\n|----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **no**                           | Do not automatically restart the container when it exits. This is the default.                                                                                                                                                                                   |\n|  **on-failure**\\[:max-retries\\]  | Restart only if the container exits with a non-zero exit status. Optionally, limit the number of restart retries the Docker daemon attempts.                                                                                                                     |\n| **always**                       | Always restart the container regardless of the exit status. When you specify always, the Docker daemon will try to restart the container indefinitely. The container will also always start on daemon startup, regardless of the current state of the container. |\n| **unless-stopped**               | Always restart the container regardless of the exit status, including on daemon startup, except if the container was put into a stopped state before the Docker daemon was stopped.                                                                              |\n\nAn increasing delay (double the previous delay, starting at 100 milliseconds) is added before each restart to prevent flooding the server. This means the daemon will wait for 100 ms, then 200 ms, 400, 800, 1600, and so on until either the `on-failure` limit, the maximum delay of 1 minute is hit, or when you `docker stop` or `docker rm -f` the container.\n\nIf a container is successfully restarted (the container is started and runs for at least 10 seconds), the delay is reset to its default value of 100 ms.\n\nYou can specify the maximum amount of times Docker will try to restart the container when using the **on-failure** policy. The default is that Docker will try forever to restart the container. The number of (attempted) restarts for a container can be obtained via [`docker inspect`](../commandline/inspect/index). For example, to get the number of restarts for container “my-container”;\n\n``` \n$ docker inspect -f \"{{ .RestartCount }}\" my-container\n# 2\n```\n\nOr, to get the last time the container was (re)started;\n\n``` \n$ docker inspect -f \"{{ .State.StartedAt }}\" my-container\n# 2015-03-04T23:47:07.691840179Z\n```\n\nCombining `--restart` (restart policy) with the `--rm` (clean up) flag results in an error. On container restart, attached clients are disconnected. See the examples on using the [`--rm` (clean up)](#clean-up---rm) flag later in this page.\n\n### Examples\n\n``` \n$ docker run --restart=always redis\n```\n\nThis will run the `redis` container with a restart policy of **always** so that if the container exits, Docker will restart it.\n\n``` \n$ docker run --restart=on-failure:10 redis\n```\n\nThis will run the `redis` container with a restart policy of **on-failure** and a maximum restart count of 10. If the `redis` container exits with a non-zero exit status more than 10 times in a row Docker will abort trying to restart the container. Providing a maximum restart limit is only valid for the **on-failure** policy.\n\n## Exit Status\n\nThe exit code from `docker run` gives information about why the container failed to run or why it exited. When `docker run` exits with a non-zero code, the exit codes follow the `chroot` standard, see below:\n\n***125*** if the error is with Docker daemon ***itself***\n\n``` \n$ docker run --foo busybox; echo $?\n\nflag provided but not defined: --foo\nSee 'docker run --help'.\n125\n```\n\n***126*** if the ***contained command*** cannot be invoked\n\n``` \n$ docker run busybox /etc; echo $?\n\ndocker: Error response from daemon: Container command '/etc' could not be invoked.\n126\n```\n\n***127*** if the ***contained command*** cannot be found\n\n``` \n$ docker run busybox foo; echo $?\n\ndocker: Error response from daemon: Container command 'foo' not found or does not exist.\n127\n```\n\n***Exit code*** of ***contained command*** otherwise\n\n``` \n$ docker run busybox /bin/sh -c 'exit 3'\n$ echo $?\n3\n```\n\n## Clean up (--rm)\n\nBy default a container’s file system persists even after the container exits. This makes debugging a lot easier (since you can inspect the final state) and you retain all your data by default. But if you are running short-term **foreground** processes, these container file systems can really pile up. If instead you’d like Docker to **automatically clean up the container and remove the file system when the container exits**, you can add the `--rm` flag:\n\n``` \n--rm=false: Automatically remove the container when it exits\n```\n\n> **Note**\n>\n> If you set the `--rm` flag, Docker also removes the anonymous volumes associated with the container when the container is removed. This is similar to running `docker rm -v my-container`. Only volumes that are specified without a name are removed. For example, when running:\n>\n> ``` \n> $ docker run --rm -v /foo -v awesome:/bar busybox top\n> ```\n>\n> the volume for `/foo` will be removed, but the volume for `/bar` will not. Volumes inherited via `--volumes-from` will be removed with the same logic: if the original volume was specified with a name it will **not** be removed.\n\n## Security configuration\n\n| Option                                    | Description                                                            |\n|:------------------------------------------|:-----------------------------------------------------------------------|\n| `--security-opt=\"label=user:USER\"`        | Set the label user for the container                                   |\n| `--security-opt=\"label=role:ROLE\"`        | Set the label role for the container                                   |\n| `--security-opt=\"label=type:TYPE\"`        | Set the label type for the container                                   |\n| `--security-opt=\"label=level:LEVEL\"`      | Set the label level for the container                                  |\n| `--security-opt=\"label=disable\"`          | Turn off label confinement for the container                           |\n| `--security-opt=\"apparmor=PROFILE\"`       | Set the apparmor profile to be applied to the container                |\n| `--security-opt=\"no-new-privileges:true\"` | Disable container processes from gaining new privileges                |\n| `--security-opt=\"seccomp=unconfined\"`     | Turn off seccomp confinement for the container                         |\n| `--security-opt=\"seccomp=profile.json\"`   | White-listed syscalls seccomp Json file to be used as a seccomp filter |\n\nYou can override the default labeling scheme for each container by specifying the `--security-opt` flag. Specifying the level in the following command allows you to share the same content between containers.\n\n``` \n$ docker run --security-opt label=level:s0:c100,c200 -it fedora bash\n```\n\n> **Note**\n>\n> Automatic translation of MLS labels is not currently supported.\n\nTo disable the security labeling for this container versus running with the `--privileged` flag, use the following command:\n\n``` \n$ docker run --security-opt label=disable -it fedora bash\n```\n\nIf you want a tighter security policy on the processes within a container, you can specify an alternate type for the container. You could run a container that is only allowed to listen on Apache ports by executing the following command:\n\n``` \n$ docker run --security-opt label=type:svirt_apache_t -it centos bash\n```\n\n> **Note**\n>\n> You would have to write policy defining a `svirt_apache_t` type.\n\nIf you want to prevent your container processes from gaining additional privileges, you can execute the following command:\n\n``` \n$ docker run --security-opt no-new-privileges -it centos bash\n```\n\nThis means that commands that raise privileges such as `su` or `sudo` will no longer work. It also causes any seccomp filters to be applied later, after privileges have been dropped which may mean you can have a more restrictive set of filters. For more details, see the [kernel documentation](https://www.kernel.org/doc/Documentation/prctl/no_new_privs.txt).\n\n## Specify an init process\n\nYou can use the `--init` flag to indicate that an init process should be used as the PID 1 in the container. Specifying an init process ensures the usual responsibilities of an init system, such as reaping zombie processes, are performed inside the created container.\n\nThe default init process used is the first `docker-init` executable found in the system path of the Docker daemon process. This `docker-init` binary, included in the default installation, is backed by [tini](https://github.com/krallin/tini).\n\n## Specify custom cgroups\n\nUsing the `--cgroup-parent` flag, you can pass a specific cgroup to run a container in. This allows you to create and manage cgroups on their own. You can define custom resources for those cgroups and put containers under a common parent group.\n\n## Runtime constraints on resources\n\nThe operator can also adjust the performance parameters of the container:\n\n| Option                     | Description                                                                                                                                                                                                                                                                              |\n|:---------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `-m`, `--memory=\"\"`        | Memory limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. Minimum is 4M.                                                                                                                                                        |\n| `--memory-swap=\"\"`         | Total memory limit (memory + swap, format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`.                                                                                                                                                  |\n| `--memory-reservation=\"\"`  | Memory soft limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`.                                                                                                                                                                  |\n| `--kernel-memory=\"\"`       | Kernel memory limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. Minimum is 4M.                                                                                                                                                 |\n| `-c`, `--cpu-shares=0`     | CPU shares (relative weight)                                                                                                                                                                                                                                                             |\n| `--cpus=0.000`             | Number of CPUs. Number is a fractional number. 0.000 means no limit.                                                                                                                                                                                                                     |\n| `--cpu-period=0`           | Limit the CPU CFS (Completely Fair Scheduler) period                                                                                                                                                                                                                                     |\n| `--cpuset-cpus=\"\"`         | CPUs in which to allow execution (0-3, 0,1)                                                                                                                                                                                                                                              |\n| `--cpuset-mems=\"\"`         | Memory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems.                                                                                                                                                                                              |\n| `--cpu-quota=0`            | Limit the CPU CFS (Completely Fair Scheduler) quota                                                                                                                                                                                                                                      |\n| `--cpu-rt-period=0`        | Limit the CPU real-time period. In microseconds. Requires parent cgroups be set and cannot be higher than parent. Also check rtprio ulimits.                                                                                                                                             |\n| `--cpu-rt-runtime=0`       | Limit the CPU real-time runtime. In microseconds. Requires parent cgroups be set and cannot be higher than parent. Also check rtprio ulimits.                                                                                                                                            |\n| `--blkio-weight=0`         | Block IO weight (relative weight) accepts a weight value between 10 and 1000.                                                                                                                                                                                                            |\n| `--blkio-weight-device=\"\"` | Block IO weight (relative device weight, format: `DEVICE_NAME:WEIGHT`)                                                                                                                                                                                                                   |\n| `--device-read-bps=\"\"`     | Limit read rate from a device (format: `<device-path>:<number>[<unit>]`). Number is a positive integer. Unit can be one of `kb`, `mb`, or `gb`.                                                                                                                                          |\n| `--device-write-bps=\"\"`    | Limit write rate to a device (format: `<device-path>:<number>[<unit>]`). Number is a positive integer. Unit can be one of `kb`, `mb`, or `gb`.                                                                                                                                           |\n| `--device-read-iops=\"\"`    | Limit read rate (IO per second) from a device (format: `<device-path>:<number>`). Number is a positive integer.                                                                                                                                                                          |\n| `--device-write-iops=\"\"`   | Limit write rate (IO per second) to a device (format: `<device-path>:<number>`). Number is a positive integer.                                                                                                                                                                           |\n| `--oom-kill-disable=false` | Whether to disable OOM Killer for the container or not.                                                                                                                                                                                                                                  |\n| `--oom-score-adj=0`        | Tune container’s OOM preferences (-1000 to 1000)                                                                                                                                                                                                                                         |\n| `--memory-swappiness=\"\"`   | Tune a container’s memory swappiness behavior. Accepts an integer between 0 and 100.                                                                                                                                                                                                     |\n| `--shm-size=\"\"`            | Size of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`. |\n\n### User memory constraints\n\nWe have four ways to set user memory usage:\n\n| Option                                       | Result                                                                                                                                                                                  |\n|----------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **memory=inf, memory-swap=inf** (default)    | There is no memory limit for the container. The container can use as much memory as needed.                                                                                             |\n| **memory=L\\<inf, memory-swap=inf**           | (specify memory and set memory-swap as `-1`) The container is not allowed to use more than L bytes of memory, but can use as much swap as is needed (if the host supports swap memory). |\n| **memory=L\\<inf, memory-swap=2\\*L**          | (specify memory without memory-swap) The container is not allowed to use more than L bytes of memory, swap *plus* memory usage is double of that.                                       |\n| **memory=L\\<inf, memory-swap=S\\<inf, L\\<=S** | (specify both memory and memory-swap) The container is not allowed to use more than L bytes of memory, swap *plus* memory usage is limited by S.                                        |\n\nExamples:\n\n``` \n$ docker run -it ubuntu:14.04 /bin/bash\n```\n\nWe set nothing about memory, this means the processes in the container can use as much memory and swap memory as they need.\n\n``` \n$ docker run -it -m 300M --memory-swap -1 ubuntu:14.04 /bin/bash\n```\n\nWe set memory limit and disabled swap memory limit, this means the processes in the container can use 300M memory and as much swap memory as they need (if the host supports swap memory).\n\n``` \n$ docker run -it -m 300M ubuntu:14.04 /bin/bash\n```\n\nWe set memory limit only, this means the processes in the container can use 300M memory and 300M swap memory, by default, the total virtual memory size (--memory-swap) will be set as double of memory, in this case, memory + swap would be 2\\*300M, so processes can use 300M swap memory as well.\n\n``` \n$ docker run -it -m 300M --memory-swap 1G ubuntu:14.04 /bin/bash\n```\n\nWe set both memory and swap memory, so the processes in the container can use 300M memory and 700M swap memory.\n\nMemory reservation is a kind of memory soft limit that allows for greater sharing of memory. Under normal circumstances, containers can use as much of the memory as needed and are constrained only by the hard limits set with the `-m`/`--memory` option. When memory reservation is set, Docker detects memory contention or low memory and forces containers to restrict their consumption to a reservation limit.\n\nAlways set the memory reservation value below the hard limit, otherwise the hard limit takes precedence. A reservation of 0 is the same as setting no reservation. By default (without reservation set), memory reservation is the same as the hard memory limit.\n\nMemory reservation is a soft-limit feature and does not guarantee the limit won’t be exceeded. Instead, the feature attempts to ensure that, when memory is heavily contended for, memory is allocated based on the reservation hints/setup.\n\nThe following example limits the memory (`-m`) to 500M and sets the memory reservation to 200M.\n\n``` \n$ docker run -it -m 500M --memory-reservation 200M ubuntu:14.04 /bin/bash\n```\n\nUnder this configuration, when the container consumes memory more than 200M and less than 500M, the next system memory reclaim attempts to shrink container memory below 200M.\n\nThe following example set memory reservation to 1G without a hard memory limit.\n\n``` \n$ docker run -it --memory-reservation 1G ubuntu:14.04 /bin/bash\n```\n\nThe container can use as much memory as it needs. The memory reservation setting ensures the container doesn’t consume too much memory for long time, because every memory reclaim shrinks the container’s consumption to the reservation.\n\nBy default, kernel kills processes in a container if an out-of-memory (OOM) error occurs. To change this behaviour, use the `--oom-kill-disable` option. Only disable the OOM killer on containers where you have also set the `-m/--memory` option. If the `-m` flag is not set, this can result in the host running out of memory and require killing the host’s system processes to free memory.\n\nThe following example limits the memory to 100M and disables the OOM killer for this container:\n\n``` \n$ docker run -it -m 100M --oom-kill-disable ubuntu:14.04 /bin/bash\n```\n\nThe following example, illustrates a dangerous way to use the flag:\n\n``` \n$ docker run -it --oom-kill-disable ubuntu:14.04 /bin/bash\n```\n\nThe container has unlimited memory which can cause the host to run out memory and require killing system processes to free memory. The `--oom-score-adj` parameter can be changed to select the priority of which containers will be killed when the system is out of memory, with negative scores making them less likely to be killed, and positive scores more likely.\n\n### Kernel memory constraints\n\nKernel memory is fundamentally different than user memory as kernel memory can’t be swapped out. The inability to swap makes it possible for the container to block system services by consuming too much kernel memory. Kernel memory includes：\n\n- stack pages\n- slab pages\n- sockets memory pressure\n- tcp memory pressure\n\nYou can setup kernel memory limit to constrain these kinds of memory. For example, every process consumes some stack pages. By limiting kernel memory, you can prevent new processes from being created when the kernel memory usage is too high.\n\nKernel memory is never completely independent of user memory. Instead, you limit kernel memory in the context of the user memory limit. Assume “U” is the user memory limit and “K” the kernel limit. There are three possible ways to set limits:\n\n| Option                        | Result                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|-------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **U != 0, K = inf** (default) | This is the standard memory limitation mechanism already present before using kernel memory. Kernel memory is completely ignored.                                                                                                                                                                                                                                                                                                                        |\n| **U != 0, K \\< U**            | Kernel memory is a subset of the user memory. This setup is useful in deployments where the total amount of memory per-cgroup is overcommitted. Overcommitting kernel memory limits is definitely not recommended, since the box can still run out of non-reclaimable memory. In this case, you can configure K so that the sum of all groups is never greater than the total memory. Then, freely set U at the expense of the system's service quality. |\n| **U != 0, K \\> U**            | Since kernel memory charges are also fed to the user counter and reclamation is triggered for the container for both kinds of memory. This configuration gives the admin a unified view of memory. It is also useful for people who just want to track kernel memory usage.                                                                                                                                                                              |\n\nExamples:\n\n``` \n$ docker run -it -m 500M --kernel-memory 50M ubuntu:14.04 /bin/bash\n```\n\nWe set memory and kernel memory, so the processes in the container can use 500M memory in total, in this 500M memory, it can be 50M kernel memory tops.\n\n``` \n$ docker run -it --kernel-memory 50M ubuntu:14.04 /bin/bash\n```\n\nWe set kernel memory without **-m**, so the processes in the container can use as much memory as they want, but they can only use 50M kernel memory.\n\n### Swappiness constraint\n\nBy default, a container’s kernel can swap out a percentage of anonymous pages. To set this percentage for a container, specify a `--memory-swappiness` value between 0 and 100. A value of 0 turns off anonymous page swapping. A value of 100 sets all anonymous pages as swappable. By default, if you are not using `--memory-swappiness`, memory swappiness value will be inherited from the parent.\n\nFor example, you can set:\n\n``` \n$ docker run -it --memory-swappiness=0 ubuntu:14.04 /bin/bash\n```\n\nSetting the `--memory-swappiness` option is helpful when you want to retain the container’s working set and to avoid swapping performance penalties.\n\n### CPU share constraint\n\nBy default, all containers get the same proportion of CPU cycles. This proportion can be modified by changing the container’s CPU share weighting relative to the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the `-c` or `--cpu-shares` flag to set the weighting to 2 or higher. If 0 is set, the system will ignore the value and use the default of 1024.\n\nThe proportion will only apply when CPU-intensive processes are running. When tasks in one container are idle, other containers can use the left-over CPU time. The actual amount of CPU time will vary depending on the number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and two others have a cpu-share setting of 512. When processes in all three containers attempt to use 100% of CPU, the first container would receive 50% of the total CPU time. If you add a fourth container with a cpu-share of 1024, the first container only gets 33% of the CPU. The remaining containers receive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU cores. Even if a container is limited to less than 100% of CPU time, it can use 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one container `{C0}` with `-c=512` running one process, and another container `{C1}` with `-c=1024` running two processes, this can result in the following division of CPU shares:\n\n``` \nPID    container  CPU CPU share\n100    {C0}     0   100% of CPU0\n101    {C1}     1   100% of CPU1\n102    {C1}     2   100% of CPU2\n```\n\n### CPU period constraint\n\nThe default CPU CFS (Completely Fair Scheduler) period is 100ms. We can use `--cpu-period` to set the period of CPUs to limit the container’s CPU usage. And usually `--cpu-period` should work with `--cpu-quota`.\n\nExamples:\n\n``` \n$ docker run -it --cpu-period=50000 --cpu-quota=25000 ubuntu:14.04 /bin/bash\n```\n\nIf there is 1 CPU, this means the container can get 50% CPU worth of run-time every 50ms.\n\nIn addition to use `--cpu-period` and `--cpu-quota` for setting CPU period constraints, it is possible to specify `--cpus` with a float number to achieve the same purpose. For example, if there is 1 CPU, then `--cpus=0.5` will achieve the same result as setting `--cpu-period=50000` and `--cpu-quota=25000` (50% CPU).\n\nThe default value for `--cpus` is `0.000`, which means there is no limit.\n\nFor more information, see the [CFS documentation on bandwidth limiting](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt).\n\n### Cpuset constraint\n\nWe can set cpus in which to allow execution for containers.\n\nExamples:\n\n``` \n$ docker run -it --cpuset-cpus=\"1,3\" ubuntu:14.04 /bin/bash\n```\n\nThis means processes in container can be executed on cpu 1 and cpu 3.\n\n``` \n$ docker run -it --cpuset-cpus=\"0-2\" ubuntu:14.04 /bin/bash\n```\n\nThis means processes in container can be executed on cpu 0, cpu 1 and cpu 2.\n\nWe can set mems in which to allow execution for containers. Only effective on NUMA systems.\n\nExamples:\n\n``` \n$ docker run -it --cpuset-mems=\"1,3\" ubuntu:14.04 /bin/bash\n```\n\nThis example restricts the processes in the container to only use memory from memory nodes 1 and 3.\n\n``` \n$ docker run -it --cpuset-mems=\"0-2\" ubuntu:14.04 /bin/bash\n```\n\nThis example restricts the processes in the container to only use memory from memory nodes 0, 1 and 2.\n\n### CPU quota constraint\n\nThe `--cpu-quota` flag limits the container’s CPU usage. The default 0 value allows the container to take 100% of a CPU resource (1 CPU). The CFS (Completely Fair Scheduler) handles resource allocation for executing processes and is default Linux Scheduler used by the kernel. Set this value to 50000 to limit the container to 50% of a CPU resource. For multiple CPUs, adjust the `--cpu-quota` as necessary. For more information, see the [CFS documentation on bandwidth limiting](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt).\n\n### Block IO bandwidth (Blkio) constraint\n\nBy default, all containers get the same proportion of block IO bandwidth (blkio). This proportion is 500. To modify this proportion, change the container’s blkio weight relative to the weighting of all other running containers using the `--blkio-weight` flag.\n\n> **Note:**\n>\n> The blkio weight setting is only available for direct IO. Buffered IO is not currently supported.\n\nThe `--blkio-weight` flag can set the weighting to a value between 10 to 1000. For example, the commands below create two containers with different blkio weight:\n\n``` \n$ docker run -it --name c1 --blkio-weight 300 ubuntu:14.04 /bin/bash\n$ docker run -it --name c2 --blkio-weight 600 ubuntu:14.04 /bin/bash\n```\n\nIf you do block IO in the two containers at the same time, by, for example:\n\n``` \n$ time dd if=/mnt/zerofile of=test.out bs=1M count=1024 oflag=direct\n```\n\nYou’ll find that the proportion of time is the same as the proportion of blkio weights of the two containers.\n\nThe `--blkio-weight-device=\"DEVICE_NAME:WEIGHT\"` flag sets a specific device weight. The `DEVICE_NAME:WEIGHT` is a string containing a colon-separated device name and weight. For example, to set `/dev/sda` device weight to `200`:\n\n``` \n$ docker run -it \\\n    --blkio-weight-device \"/dev/sda:200\" \\\n    ubuntu\n```\n\nIf you specify both the `--blkio-weight` and `--blkio-weight-device`, Docker uses the `--blkio-weight` as the default weight and uses `--blkio-weight-device` to override this default with a new value on a specific device. The following example uses a default weight of `300` and overrides this default on `/dev/sda` setting that weight to `200`:\n\n``` \n$ docker run -it \\\n    --blkio-weight 300 \\\n    --blkio-weight-device \"/dev/sda:200\" \\\n    ubuntu\n```\n\nThe `--device-read-bps` flag limits the read rate (bytes per second) from a device. For example, this command creates a container and limits the read rate to `1mb` per second from `/dev/sda`:\n\n``` \n$ docker run -it --device-read-bps /dev/sda:1mb ubuntu\n```\n\nThe `--device-write-bps` flag limits the write rate (bytes per second) to a device. For example, this command creates a container and limits the write rate to `1mb` per second for `/dev/sda`:\n\n``` \n$ docker run -it --device-write-bps /dev/sda:1mb ubuntu\n```\n\nBoth flags take limits in the `<device-path>:<limit>[unit]` format. Both read and write rates must be a positive integer. You can specify the rate in `kb` (kilobytes), `mb` (megabytes), or `gb` (gigabytes).\n\nThe `--device-read-iops` flag limits read rate (IO per second) from a device. For example, this command creates a container and limits the read rate to `1000` IO per second from `/dev/sda`:\n\n``` \n$ docker run -ti --device-read-iops /dev/sda:1000 ubuntu\n```\n\nThe `--device-write-iops` flag limits write rate (IO per second) to a device. For example, this command creates a container and limits the write rate to `1000` IO per second to `/dev/sda`:\n\n``` \n$ docker run -ti --device-write-iops /dev/sda:1000 ubuntu\n```\n\nBoth flags take limits in the `<device-path>:<limit>` format. Both read and write rates must be a positive integer.\n\n## Additional groups\n\n``` \n--group-add: Add additional groups to run as\n```\n\nBy default, the docker container process runs with the supplementary groups looked up for the specified user. If one wants to add more to that list of groups, then one can use this flag:\n\n``` \n$ docker run --rm --group-add audio --group-add nogroup --group-add 777 busybox id\n\nuid=0(root) gid=0(root) groups=10(wheel),29(audio),99(nogroup),777\n```\n\n## Runtime privilege and Linux capabilities\n\n| Option         | Description                                                                   |\n|:---------------|:------------------------------------------------------------------------------|\n| `--cap-add`    | Add Linux capabilities                                                        |\n| `--cap-drop`   | Drop Linux capabilities                                                       |\n| `--privileged` | Give extended privileges to this container                                    |\n| `--device=[]`  | Allows you to run devices inside the container without the --privileged flag. |\n\nBy default, Docker containers are “unprivileged” and cannot, for example, run a Docker daemon inside a Docker container. This is because by default a container is not allowed to access any devices, but a “privileged” container is given access to all devices (see the documentation on [cgroups devices](https://www.kernel.org/doc/Documentation/cgroup-v1/devices.txt)).\n\nThe --privileged flag gives all capabilities to the container. When the operator executes `docker run --privileged`, Docker will enable access to all devices on the host as well as set some configuration in AppArmor or SELinux to allow the container nearly all the same access to the host as processes running outside containers on the host. Additional information about running with `--privileged` is available on the [Docker Blog](https://blog.docker.com/2013/09/docker-can-now-run-within-docker/).\n\nIf you want to limit access to a specific device or devices you can use the `--device` flag. It allows you to specify one or more devices that will be accessible within the container.\n\n``` \n$ docker run --device=/dev/snd:/dev/snd ...\n```\n\nBy default, the container will be able to `read`, `write`, and `mknod` these devices. This can be overridden using a third `:rwm` set of options to each `--device` flag:\n\n``` \n$ docker run --device=/dev/sda:/dev/xvdc --rm -it ubuntu fdisk  /dev/xvdc\n\nCommand (m for help): q\n$ docker run --device=/dev/sda:/dev/xvdc:r --rm -it ubuntu fdisk  /dev/xvdc\nYou will not be able to write the partition table.\n\nCommand (m for help): q\n\n$ docker run --device=/dev/sda:/dev/xvdc:w --rm -it ubuntu fdisk  /dev/xvdc\n    crash....\n\n$ docker run --device=/dev/sda:/dev/xvdc:m --rm -it ubuntu fdisk  /dev/xvdc\nfdisk: unable to open /dev/xvdc: Operation not permitted\n```\n\nIn addition to `--privileged`, the operator can have fine grain control over the capabilities using `--cap-add` and `--cap-drop`. By default, Docker has a default list of capabilities that are kept. The following table lists the Linux capability options which are allowed by default and can be dropped.\n\n| Capability Key   | Capability Description                                                                                                        |\n|:-----------------|:------------------------------------------------------------------------------------------------------------------------------|\n| AUDIT_WRITE      | Write records to kernel auditing log.                                                                                         |\n| CHOWN            | Make arbitrary changes to file UIDs and GIDs (see chown(2)).                                                                  |\n| DAC_OVERRIDE     | Bypass file read, write, and execute permission checks.                                                                       |\n| FOWNER           | Bypass permission checks on operations that normally require the file system UID of the process to match the UID of the file. |\n| FSETID           | Don’t clear set-user-ID and set-group-ID permission bits when a file is modified.                                             |\n| KILL             | Bypass permission checks for sending signals.                                                                                 |\n| MKNOD            | Create special files using mknod(2).                                                                                          |\n| NET_BIND_SERVICE | Bind a socket to internet domain privileged ports (port numbers less than 1024).                                              |\n| NET_RAW          | Use RAW and PACKET sockets.                                                                                                   |\n| SETFCAP          | Set file capabilities.                                                                                                        |\n| SETGID           | Make arbitrary manipulations of process GIDs and supplementary GID list.                                                      |\n| SETPCAP          | Modify process capabilities.                                                                                                  |\n| SETUID           | Make arbitrary manipulations of process UIDs.                                                                                 |\n| SYS_CHROOT       | Use chroot(2), change root directory.                                                                                         |\n\nThe next table shows the capabilities which are not granted by default and may be added.\n\n| Capability Key     | Capability Description                                                                                                    |\n|:-------------------|:--------------------------------------------------------------------------------------------------------------------------|\n| AUDIT_CONTROL      | Enable and disable kernel auditing; change auditing filter rules; retrieve auditing status and filtering rules.           |\n| AUDIT_READ         | Allow reading the audit log via multicast netlink socket.                                                                 |\n| BLOCK_SUSPEND      | Allow preventing system suspends.                                                                                         |\n| BPF                | Allow creating BPF maps, loading BPF Type Format (BTF) data, retrieve JITed code of BPF programs, and more.               |\n| CHECKPOINT_RESTORE | Allow checkpoint/restore related operations. Introduced in kernel 5.9.                                                    |\n| DAC_READ_SEARCH    | Bypass file read permission checks and directory read and execute permission checks.                                      |\n| IPC_LOCK           | Lock memory (mlock(2), mlockall(2), mmap(2), shmctl(2)).                                                                  |\n| IPC_OWNER          | Bypass permission checks for operations on System V IPC objects.                                                          |\n| LEASE              | Establish leases on arbitrary files (see fcntl(2)).                                                                       |\n| LINUX_IMMUTABLE    | Set the FS_APPEND_FL and FS_IMMUTABLE_FL i-node flags.                                                                    |\n| MAC_ADMIN          | Allow MAC configuration or state changes. Implemented for the Smack LSM.                                                  |\n| MAC_OVERRIDE       | Override Mandatory Access Control (MAC). Implemented for the Smack Linux Security Module (LSM).                           |\n| NET_ADMIN          | Perform various network-related operations.                                                                               |\n| NET_BROADCAST      | Make socket broadcasts, and listen to multicasts.                                                                         |\n| PERFMON            | Allow system performance and observability privileged operations using perf_events, i915_perf and other kernel subsystems |\n| SYS_ADMIN          | Perform a range of system administration operations.                                                                      |\n| SYS_BOOT           | Use reboot(2) and kexec_load(2), reboot and load a new kernel for later execution.                                        |\n| SYS_MODULE         | Load and unload kernel modules.                                                                                           |\n| SYS_NICE           | Raise process nice value (nice(2), setpriority(2)) and change the nice value for arbitrary processes.                     |\n| SYS_PACCT          | Use acct(2), switch process accounting on or off.                                                                         |\n| SYS_PTRACE         | Trace arbitrary processes using ptrace(2).                                                                                |\n| SYS_RAWIO          | Perform I/O port operations (iopl(2) and ioperm(2)).                                                                      |\n| SYS_RESOURCE       | Override resource Limits.                                                                                                 |\n| SYS_TIME           | Set system clock (settimeofday(2), stime(2), adjtimex(2)); set real-time (hardware) clock.                                |\n| SYS_TTY_CONFIG     | Use vhangup(2); employ various privileged ioctl(2) operations on virtual terminals.                                       |\n| SYSLOG             | Perform privileged syslog(2) operations.                                                                                  |\n| WAKE_ALARM         | Trigger something that will wake up the system.                                                                           |\n\nFurther reference information is available on the [capabilities(7) - Linux man page](https://man7.org/linux/man-pages/man7/capabilities.7.html), and in the [Linux kernel source code](https://github.com/torvalds/linux/blob/124ea650d3072b005457faed69909221c2905a1f/include/uapi/linux/capability.h).\n\nBoth flags support the value `ALL`, so to allow a container to use all capabilities except for `MKNOD`:\n\n``` \n$ docker run --cap-add=ALL --cap-drop=MKNOD ...\n```\n\nThe `--cap-add` and `--cap-drop` flags accept capabilities to be specified with a `CAP_` prefix. The following examples are therefore equivalent:\n\n``` \n$ docker run --cap-add=SYS_ADMIN ...\n$ docker run --cap-add=CAP_SYS_ADMIN ...\n```\n\nFor interacting with the network stack, instead of using `--privileged` they should use `--cap-add=NET_ADMIN` to modify the network interfaces.\n\n``` \n$ docker run -it --rm  ubuntu:14.04 ip link add dummy0 type dummy\n\nRTNETLINK answers: Operation not permitted\n\n$ docker run -it --rm --cap-add=NET_ADMIN ubuntu:14.04 ip link add dummy0 type dummy\n```\n\nTo mount a FUSE based filesystem, you need to combine both `--cap-add` and `--device`:\n\n``` \n$ docker run --rm -it --cap-add SYS_ADMIN sshfs sshfs sven@10.10.10.20:/home/sven /mnt\n\nfuse: failed to open /dev/fuse: Operation not permitted\n\n$ docker run --rm -it --device /dev/fuse sshfs sshfs sven@10.10.10.20:/home/sven /mnt\n\nfusermount: mount failed: Operation not permitted\n\n$ docker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs\n\n# sshfs sven@10.10.10.20:/home/sven /mnt\nThe authenticity of host '10.10.10.20 (10.10.10.20)' can't be established.\nECDSA key fingerprint is 25:34:85:75:25:b0:17:46:05:19:04:93:b5:dd:5f:c6.\nAre you sure you want to continue connecting (yes/no)? yes\nsven@10.10.10.20's password:\n\nroot@30aa0cfaf1b5:/# ls -la /mnt/src/docker\n\ntotal 1516\ndrwxrwxr-x 1 1000 1000   4096 Dec  4 06:08 .\ndrwxrwxr-x 1 1000 1000   4096 Dec  4 11:46 ..\n-rw-rw-r-- 1 1000 1000     16 Oct  8 00:09 .dockerignore\n-rwxrwxr-x 1 1000 1000    464 Oct  8 00:09 .drone.yml\ndrwxrwxr-x 1 1000 1000   4096 Dec  4 06:11 .git\n-rw-rw-r-- 1 1000 1000    461 Dec  4 06:08 .gitignore\n....\n```\n\nThe default seccomp profile will adjust to the selected capabilities, in order to allow use of facilities allowed by the capabilities, so you should not have to adjust this.\n\n## Logging drivers (--log-driver)\n\nThe container can have a different logging driver than the Docker daemon. Use the `--log-driver=VALUE` with the `docker run` command to configure the container’s logging driver. The following options are supported:\n\n| Driver       | Description                                                                                                                    |\n|:-------------|:-------------------------------------------------------------------------------------------------------------------------------|\n| `none`       | Disables any logging for the container. `docker logs` won’t be available with this driver.                                     |\n| `local`      | Logs are stored in a custom format designed for minimal overhead.                                                              |\n| `json-file`  | Default logging driver for Docker. Writes JSON messages to file. No logging options are supported for this driver.             |\n| `syslog`     | Syslog logging driver for Docker. Writes log messages to syslog.                                                               |\n| `journald`   | Journald logging driver for Docker. Writes log messages to `journald`.                                                         |\n| `gelf`       | Graylog Extended Log Format (GELF) logging driver for Docker. Writes log messages to a GELF endpoint likeGraylog or Logstash.  |\n| `fluentd`    | Fluentd logging driver for Docker. Writes log messages to `fluentd` (forward input).                                           |\n| `awslogs`    | Amazon CloudWatch Logs logging driver for Docker. Writes log messages to Amazon CloudWatch Logs.                               |\n| `splunk`     | Splunk logging driver for Docker. Writes log messages to `splunk` using Event Http Collector.                                  |\n| `etwlogs`    | Event Tracing for Windows (ETW) events. Writes log messages as Event Tracing for Windows (ETW) events. Only Windows platforms. |\n| `gcplogs`    | Google Cloud Platform (GCP) Logging. Writes log messages to Google Cloud Platform (GCP) Logging.                               |\n| `logentries` | Rapid7 Logentries. Writes log messages to Rapid7 Logentries.                                                                   |\n\nThe `docker logs` command is available only for the `json-file` and `journald` logging drivers. For detailed information on working with logging drivers, see [Configure logging drivers](https://docs.docker.com/config/containers/logging/configure/).\n\n## Overriding Dockerfile image defaults\n\nWhen a developer builds an image from a [*Dockerfile*](../builder/index) or when she commits it, the developer can set a number of default parameters that take effect when the image starts up as a container.\n\nFour of the Dockerfile commands cannot be overridden at runtime: `FROM`, `MAINTAINER`, `RUN`, and `ADD`. Everything else has a corresponding override in `docker run`. We’ll go through what the developer might have set in each Dockerfile instruction and how the operator can override that setting.\n\n- [CMD (Default Command or Options)](#cmd-default-command-or-options)\n- [ENTRYPOINT (Default Command to Execute at Runtime)](#entrypoint-default-command-to-execute-at-runtime)\n- [EXPOSE (Incoming Ports)](#expose-incoming-ports)\n- [ENV (Environment Variables)](#env-environment-variables)\n- [HEALTHCHECK](#healthcheck)\n- [VOLUME (Shared Filesystems)](#volume-shared-filesystems)\n- [USER](#user)\n- [WORKDIR](#workdir)\n\n### CMD (default command or options)\n\nRecall the optional `COMMAND` in the Docker commandline:\n\n``` \n$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]\n```\n\nThis command is optional because the person who created the `IMAGE` may have already provided a default `COMMAND` using the Dockerfile `CMD` instruction. As the operator (the person running a container from the image), you can override that `CMD` instruction just by specifying a new `COMMAND`.\n\nIf the image also specifies an `ENTRYPOINT` then the `CMD` or `COMMAND` get appended as arguments to the `ENTRYPOINT`.\n\n### ENTRYPOINT (default command to execute at runtime)\n\n``` \n    --entrypoint=\"\": Overwrite the default entrypoint set by the image\n```\n\nThe `ENTRYPOINT` of an image is similar to a `COMMAND` because it specifies what executable to run when the container starts, but it is (purposely) more difficult to override. The `ENTRYPOINT` gives a container its default nature or behavior, so that when you set an `ENTRYPOINT` you can run the container *as if it were that binary*, complete with default options, and you can pass in more options via the `COMMAND`. But, sometimes an operator may want to run something else inside the container, so you can override the default `ENTRYPOINT` at runtime by using a string to specify the new `ENTRYPOINT`. Here is an example of how to run a shell in a container that has been set up to automatically run something else (like `/usr/bin/redis-server`):\n\n``` \n$ docker run -it --entrypoint /bin/bash example/redis\n```\n\nor two examples of how to pass more parameters to that ENTRYPOINT:\n\n``` \n$ docker run -it --entrypoint /bin/bash example/redis -c ls -l\n$ docker run -it --entrypoint /usr/bin/redis-cli example/redis --help\n```\n\nYou can reset a containers entrypoint by passing an empty string, for example:\n\n``` \n$ docker run -it --entrypoint=\"\" mysql bash\n```\n\n> **Note**\n>\n> Passing `--entrypoint` will clear out any default command set on the image (i.e. any `CMD` instruction in the Dockerfile used to build it).\n\n### EXPOSE (incoming ports)\n\nThe following `run` command options work with container networking:\n\n``` \n--expose=[]: Expose a port or a range of ports inside the container.\n             These are additional to those exposed by the `EXPOSE` instruction\n-P         : Publish all exposed ports to the host interfaces\n-p=[]      : Publish a container's port or a range of ports to the host\n               format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort | containerPort\n               Both hostPort and containerPort can be specified as a\n               range of ports. When specifying ranges for both, the\n               number of container ports in the range must match the\n               number of host ports in the range, for example:\n                   -p 1234-1236:1234-1236/tcp\n\n               When specifying a range for hostPort only, the\n               containerPort must not be a range.  In this case the\n               container port is published somewhere within the\n               specified hostPort range. (e.g., `-p 1234-1236:1234/tcp`)\n\n               (use 'docker port' to see the actual mapping)\n\n--link=\"\"  : Add link to another container (<name or id>:alias or <name or id>)\n```\n\nWith the exception of the `EXPOSE` directive, an image developer hasn’t got much control over networking. The `EXPOSE` instruction defines the initial incoming ports that provide services. These ports are available to processes inside the container. An operator can use the `--expose` option to add to the exposed ports.\n\nTo expose a container’s internal port, an operator can start the container with the `-P` or `-p` flag. The exposed port is accessible on the host and the ports are available to any client that can reach the host.\n\nThe `-P` option publishes all the ports to the host interfaces. Docker binds each exposed port to a random port on the host. The range of ports are within an *ephemeral port range* defined by `/proc/sys/net/ipv4/ip_local_port_range`. Use the `-p` flag to explicitly map a single port or range of ports.\n\nThe port number inside the container (where the service listens) does not need to match the port number exposed on the outside of the container (where clients connect). For example, inside the container an HTTP service is listening on port 80 (and so the image developer specifies `EXPOSE 80` in the Dockerfile). At runtime, the port might be bound to 42800 on the host. To find the mapping between the host ports and the exposed ports, use `docker port`.\n\nIf the operator uses `--link` when starting a new client container in the default bridge network, then the client container can access the exposed port via a private networking interface. If `--link` is used when starting a container in a user-defined network as described in [*Networking overview*](https://docs.docker.com/network/), it will provide a named alias for the container being linked to.\n\n### ENV (environment variables)\n\nDocker automatically sets some environment variables when creating a Linux container. Docker does not set any environment variables when creating a Windows container.\n\nThe following environment variables are set for Linux containers:\n\n| Variable   | Value                                                                                                |\n|:-----------|:-----------------------------------------------------------------------------------------------------|\n| `HOME`     | Set based on the value of `USER`                                                                     |\n| `HOSTNAME` | The hostname associated with the container                                                           |\n| `PATH`     | Includes popular directories, such as `/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin` |\n| `TERM`     | `xterm` if the container is allocated a pseudo-TTY                                                   |\n\nAdditionally, the operator can **set any environment variable** in the container by using one or more `-e` flags, even overriding those mentioned above, or already defined by the developer with a Dockerfile `ENV`. If the operator names an environment variable without specifying a value, then the current value of the named variable is propagated into the container’s environment:\n\n``` \n$ export today=Wednesday\n$ docker run -e \"deep=purple\" -e today --rm alpine env\n\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nHOSTNAME=d2219b854598\ndeep=purple\ntoday=Wednesday\nHOME=/root\n```\n\n``` \nPS C:\\> docker run --rm -e \"foo=bar\" microsoft/nanoserver cmd /s /c set\nALLUSERSPROFILE=C:\\ProgramData\nAPPDATA=C:\\Users\\ContainerAdministrator\\AppData\\Roaming\nCommonProgramFiles=C:\\Program Files\\Common Files\nCommonProgramFiles(x86)=C:\\Program Files (x86)\\Common Files\nCommonProgramW6432=C:\\Program Files\\Common Files\nCOMPUTERNAME=C2FAEFCC8253\nComSpec=C:\\Windows\\system32\\cmd.exe\nfoo=bar\nLOCALAPPDATA=C:\\Users\\ContainerAdministrator\\AppData\\Local\nNUMBER_OF_PROCESSORS=8\nOS=Windows_NT\nPath=C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Users\\ContainerAdministrator\\AppData\\Local\\Microsoft\\WindowsApps\nPATHEXT=.COM;.EXE;.BAT;.CMD\nPROCESSOR_ARCHITECTURE=AMD64\nPROCESSOR_IDENTIFIER=Intel64 Family 6 Model 62 Stepping 4, GenuineIntel\nPROCESSOR_LEVEL=6\nPROCESSOR_REVISION=3e04\nProgramData=C:\\ProgramData\nProgramFiles=C:\\Program Files\nProgramFiles(x86)=C:\\Program Files (x86)\nProgramW6432=C:\\Program Files\nPROMPT=$P$G\nPUBLIC=C:\\Users\\Public\nSystemDrive=C:\nSystemRoot=C:\\Windows\nTEMP=C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\nTMP=C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\nUSERDOMAIN=User Manager\nUSERNAME=ContainerAdministrator\nUSERPROFILE=C:\\Users\\ContainerAdministrator\nwindir=C:\\Windows\n```\n\nSimilarly the operator can set the **HOSTNAME** (Linux) or **COMPUTERNAME** (Windows) with `-h`.\n\n### HEALTHCHECK\n\n``` \n  --health-cmd            Command to run to check health\n  --health-interval       Time between running the check\n  --health-retries        Consecutive failures needed to report unhealthy\n  --health-timeout        Maximum time to allow one check to run\n  --health-start-period   Start period for the container to initialize before starting health-retries countdown\n  --no-healthcheck        Disable any container-specified HEALTHCHECK\n```\n\nExample:\n\n``` \n$ docker run --name=test -d \\\n    --health-cmd='stat /etc/passwd || exit 1' \\\n    --health-interval=2s \\\n    busybox sleep 1d\n$ sleep 2; docker inspect --format='{{.State.Health.Status}}' test\nhealthy\n$ docker exec test rm /etc/passwd\n$ sleep 2; docker inspect --format='{{json .State.Health}}' test\n{\n  \"Status\": \"unhealthy\",\n  \"FailingStreak\": 3,\n  \"Log\": [\n    {\n      \"Start\": \"2016-05-25T17:22:04.635478668Z\",\n      \"End\": \"2016-05-25T17:22:04.7272552Z\",\n      \"ExitCode\": 0,\n      \"Output\": \"  File: /etc/passwd\\n  Size: 334       \\tBlocks: 8          IO Block: 4096   regular file\\nDevice: 32h/50d\\tInode: 12          Links: 1\\nAccess: (0664/-rw-rw-r--)  Uid: (    0/    root)   Gid: (    0/    root)\\nAccess: 2015-12-05 22:05:32.000000000\\nModify: 2015...\"\n    },\n    {\n      \"Start\": \"2016-05-25T17:22:06.732900633Z\",\n      \"End\": \"2016-05-25T17:22:06.822168935Z\",\n      \"ExitCode\": 0,\n      \"Output\": \"  File: /etc/passwd\\n  Size: 334       \\tBlocks: 8          IO Block: 4096   regular file\\nDevice: 32h/50d\\tInode: 12          Links: 1\\nAccess: (0664/-rw-rw-r--)  Uid: (    0/    root)   Gid: (    0/    root)\\nAccess: 2015-12-05 22:05:32.000000000\\nModify: 2015...\"\n    },\n    {\n      \"Start\": \"2016-05-25T17:22:08.823956535Z\",\n      \"End\": \"2016-05-25T17:22:08.897359124Z\",\n      \"ExitCode\": 1,\n      \"Output\": \"stat: can't stat '/etc/passwd': No such file or directory\\n\"\n    },\n    {\n      \"Start\": \"2016-05-25T17:22:10.898802931Z\",\n      \"End\": \"2016-05-25T17:22:10.969631866Z\",\n      \"ExitCode\": 1,\n      \"Output\": \"stat: can't stat '/etc/passwd': No such file or directory\\n\"\n    },\n    {\n      \"Start\": \"2016-05-25T17:22:12.971033523Z\",\n      \"End\": \"2016-05-25T17:22:13.082015516Z\",\n      \"ExitCode\": 1,\n      \"Output\": \"stat: can't stat '/etc/passwd': No such file or directory\\n\"\n    }\n  ]\n}\n```\n\nThe health status is also displayed in the `docker ps` output.\n\n### TMPFS (mount tmpfs filesystems)\n\n``` \n--tmpfs=[]: Create a tmpfs mount with: container-dir[:<options>],\n            where the options are identical to the Linux\n            'mount -t tmpfs -o' command.\n```\n\nThe example below mounts an empty tmpfs into the container with the `rw`, `noexec`, `nosuid`, and `size=65536k` options.\n\n``` \n$ docker run -d --tmpfs /run:rw,noexec,nosuid,size=65536k my_image\n```\n\n### VOLUME (shared filesystems)\n\n``` \n-v, --volume=[host-src:]container-dest[:<options>]: Bind mount a volume.\nThe comma-delimited `options` are [rw|ro], [z|Z],\n[[r]shared|[r]slave|[r]private], and [nocopy].\nThe 'host-src' is an absolute path or a name value.\n\nIf neither 'rw' or 'ro' is specified then the volume is mounted in\nread-write mode.\n\nThe `nocopy` mode is used to disable automatically copying the requested volume\npath in the container to the volume storage location.\nFor named volumes, `copy` is the default mode. Copy modes are not supported\nfor bind-mounted volumes.\n\n--volumes-from=\"\": Mount all volumes from the given container(s)\n```\n\n> **Note**\n>\n> When using systemd to manage the Docker daemon’s start and stop, in the systemd unit file there is an option to control mount propagation for the Docker daemon itself, called `MountFlags`. The value of this setting may cause Docker to not see mount propagation changes made on the mount point. For example, if this value is `slave`, you may not be able to use the `shared` or `rshared` propagation on a volume.\n\nThe volumes commands are complex enough to have their own documentation in section [*Use volumes*](https://docs.docker.com/storage/volumes/). A developer can define one or more `VOLUME`’s associated with an image, but only the operator can give access from one container to another (or from a container to a volume mounted on the host).\n\nThe `container-dest` must always be an absolute path such as `/src/docs`. The `host-src` can either be an absolute path or a `name` value. If you supply an absolute path for the `host-src`, Docker bind-mounts to the path you specify. If you supply a `name`, Docker creates a named volume by that `name`.\n\nA `name` value must start with an alphanumeric character, followed by `a-z0-9`, `_` (underscore), `.` (period) or `-` (hyphen). An absolute path starts with a `/` (forward slash).\n\nFor example, you can specify either `/foo` or `foo` for a `host-src` value. If you supply the `/foo` value, Docker creates a bind mount. If you supply the `foo` specification, Docker creates a named volume.\n\n### USER\n\n`root` (id = 0) is the default user within a container. The image developer can create additional users. Those users are accessible by name. When passing a numeric ID, the user does not have to exist in the container.\n\nThe developer can set a default user to run the first process with the Dockerfile `USER` instruction. When starting a container, the operator can override the `USER` instruction by passing the `-u` option.\n\n``` \n-u=\"\", --user=\"\": Sets the username or UID used and optionally the groupname or GID for the specified command.\n\nThe followings examples are all valid:\n--user=[ user | user:group | uid | uid:gid | user:gid | uid:group ]\n```\n\n> **Note:** if you pass a numeric uid, it must be in the range of 0-2147483647.\n\n### WORKDIR\n\nThe default working directory for running binaries within a container is the root directory (`/`). It is possible to set a different working directory with the Dockerfile `WORKDIR` command. The operator can override this with:\n\n``` \n-w=\"\", --workdir=\"\": Working directory inside the container\n```\n\n[docker](https://docs.docker.com/search/?q=docker), [run](https://docs.docker.com/search/?q=run), [configure](https://docs.docker.com/search/?q=configure), [runtime](https://docs.docker.com/search/?q=runtime)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/run/](https://docs.docker.com/engine/reference/run/)"
- name: docker save
  id: engine/reference/commandline/save/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker save\n\n  \n\nSave one or more images to a tar archive (streamed to STDOUT by default)\n\n## Usage\n\n``` \n$ docker save [OPTIONS] IMAGE [IMAGE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nProduces a tarred repository to the standard output stream. Contains all parent layers, and all tags + versions, or specified `repo:tag`, for each argument provided.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                        |\n|-------------------|---------|------------------------------------|\n| `--output` , `-o` |         | Write to a file, instead of STDOUT |\n\n## Examples\n\n### Create a backup that can then be used with `docker load`.\n\n``` \n$ docker save busybox > busybox.tar\n\n$ ls -sh busybox.tar\n\n2.7M busybox.tar\n\n$ docker save --output busybox.tar busybox\n\n$ ls -sh busybox.tar\n\n2.7M busybox.tar\n\n$ docker save -o fedora-all.tar fedora\n\n$ docker save -o fedora-latest.tar fedora:latest\n```\n\n### Save an image to a tar.gz file using gzip\n\nYou can use gzip to save the image file and make the backup smaller.\n\n``` \n$ docker save myimage:latest | gzip > myimage_latest.tar.gz\n```\n\n### Cherry-pick particular tags\n\nYou can even cherry-pick particular tags of an image repository.\n\n``` \n$ docker save -o ubuntu.tar ubuntu:lucid ubuntu:saucy\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/save/](https://docs.docker.com/engine/reference/commandline/save/)"
- name: docker search
  id: engine/reference/commandline/search/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker search\n\n  \n\nSearch the Docker Hub for images\n\n## Usage\n\n``` \n$ docker search [OPTIONS] TERM\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nSearch [Docker Hub](https://hub.docker.com) for images\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print search using a Go template    |\n| `--limit`         | `25`    | Max number of search results               |\n| `--no-trunc`      |         | Don't truncate output                      |\n\n## Examples\n\n### Search images by name\n\nThis example displays images with a name containing ‘busybox’:\n\n``` \n$ docker search busybox\n\nNAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nbusybox                          Busybox base image.                             316       [OK]\nprogrium/busybox                                                                 50                   [OK]\nradial/busyboxplus               Full-chain, Internet enabled, busybox made...   8                    [OK]\nodise/busybox-python                                                             2                    [OK]\nazukiapp/busybox                 This image is meant to be used as the base...   2                    [OK]\nofayau/busybox-jvm               Prepare busybox to install a 32 bits JVM.       1                    [OK]\nshingonoide/archlinux-busybox    Arch Linux, a lightweight and flexible Lin...   1                    [OK]\nodise/busybox-curl                                                               1                    [OK]\nofayau/busybox-libc32            Busybox with 32 bits (and 64 bits) libs         1                    [OK]\npeelsky/zulu-openjdk-busybox                                                     1                    [OK]\nskomma/busybox-data              Docker image suitable for data volume cont...   1                    [OK]\nelektritter/busybox-teamspeak    Lightweight teamspeak3 container based on...    1                    [OK]\nsocketplane/busybox                                                              1                    [OK]\noveits/docker-nginx-busybox      This is a tiny NginX docker image based on...   0                    [OK]\nggtools/busybox-ubuntu           Busybox ubuntu version with extra goodies       0                    [OK]\nnikfoundas/busybox-confd         Minimal busybox based distribution of confd     0                    [OK]\nopenshift/busybox-http-app                                                       0                    [OK]\njllopis/busybox                                                                  0                    [OK]\nswyckoff/busybox                                                                 0                    [OK]\npowellquiring/busybox                                                            0                    [OK]\nwilliamyeh/busybox-sh            Docker image for BusyBox's sh                   0                    [OK]\nsimplexsys/busybox-cli-powered   Docker busybox images, with a few often us...   0                    [OK]\nfhisamoto/busybox-java           Busybox java                                    0                    [OK]\nscottabernethy/busybox                                                           0                    [OK]\nmarclop/busybox-solr\n```\n\n### Display non-truncated description (--no-trunc)\n\nThis example displays images with a name containing ‘busybox’, at least 3 stars and the description isn’t truncated in the output:\n\n``` \n$ docker search --filter=stars=3 --no-trunc busybox\n\nNAME                 DESCRIPTION                                                                               STARS     OFFICIAL   AUTOMATED\nbusybox              Busybox base image.                                                                       325       [OK]\nprogrium/busybox                                                                                               50                   [OK]\nradial/busyboxplus   Full-chain, Internet enabled, busybox made from scratch. Comes in git and cURL flavors.   8                    [OK]\n```\n\n### Limit search results (--limit)\n\nThe flag `--limit` is the maximum number of results returned by a search. This value could be in the range between 1 and 100. The default value of `--limit` is 25.\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g. `--filter is-automated=true --filter stars=3`)\n\nThe currently supported filters are:\n\n- stars (int - number of stars the image has)\n- is-automated (boolean - true or false) - is the image automated or not\n- is-official (boolean - true or false) - is the image official or not\n\n#### stars\n\nThis example displays images with a name containing ‘busybox’ and at least 3 stars:\n\n``` \n$ docker search --filter stars=3 busybox\n\nNAME                 DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nbusybox              Busybox base image.                             325       [OK]\nprogrium/busybox                                                     50                   [OK]\nradial/busyboxplus   Full-chain, Internet enabled, busybox made...   8                    [OK]\n```\n\n#### is-automated\n\nThis example displays images with a name containing ‘busybox’ and are automated builds:\n\n``` \n$ docker search --filter is-automated=true busybox\n\nNAME                 DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nprogrium/busybox                                                     50                   [OK]\nradial/busyboxplus   Full-chain, Internet enabled, busybox made...   8                    [OK]\n```\n\n#### is-official\n\nThis example displays images with a name containing ‘busybox’, at least 3 stars and are official builds:\n\n``` \n$ docker search --filter is-official=true --filter stars=3 busybox\n\nNAME      DESCRIPTION           STARS     OFFICIAL   AUTOMATED\nbusybox   Busybox base image.   325       [OK]\n```\n\n### Format the output\n\nThe formatting option (`--format`) pretty-prints search output using a Go template.\n\nValid placeholders for the Go template are:\n\n| Placeholder    | Description                       |\n|----------------|-----------------------------------|\n| `.Name`        | Image Name                        |\n| `.Description` | Image description                 |\n| `.StarCount`   | Number of stars for the image     |\n| `.IsOfficial`  | “OK” if image is official         |\n| `.IsAutomated` | “OK” if image build was automated |\n\nWhen you use the `--format` option, the `search` command will output the data exactly as the template declares. If you use the `table` directive, column headers are included as well.\n\nThe following example uses a template without headers and outputs the `Name` and `StarCount` entries separated by a colon (`:`) for all images:\n\n``` \n$ docker search --format \"{{.Name}}: {{.StarCount}}\" nginx\n\nnginx: 5441\njwilder/nginx-proxy: 953\nricharvey/nginx-php-fpm: 353\nmillion12/nginx-php: 75\nwebdevops/php-nginx: 70\nh3nrik/nginx-ldap: 35\nbitnami/nginx: 23\nevild/alpine-nginx: 14\nmillion12/nginx: 9\nmaxexcloo/nginx: 7\n```\n\nThis example outputs a table format:\n\n``` \n$ docker search --format \"table {{.Name}}\\t{{.IsAutomated}}\\t{{.IsOfficial}}\" nginx\n\nNAME                                     AUTOMATED           OFFICIAL\nnginx                                                        [OK]\njwilder/nginx-proxy                      [OK]\nricharvey/nginx-php-fpm                  [OK]\njrcs/letsencrypt-nginx-proxy-companion   [OK]\nmillion12/nginx-php                      [OK]\nwebdevops/php-nginx                      [OK]\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/search/](https://docs.docker.com/engine/reference/commandline/search/)"
- name: docker secret
  id: engine/reference/commandline/secret/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker secret\n\n  \n\nManage Docker secrets\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker secret COMMAND\n```\n\n## Description\n\nManage secrets.\n\n## Child commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker secret create](../secret_create/index)   | Create a secret from a file or STDIN as content     |\n| [docker secret inspect](../secret_inspect/index) | Display detailed information on one or more secrets |\n| [docker secret ls](../secret_ls/index)           | List secrets                                        |\n| [docker secret rm](../secret_rm/index)           | Remove one or more secrets                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/secret/](https://docs.docker.com/engine/reference/commandline/secret/)"
- name: docker secret create
  id: engine/reference/commandline/secret_create/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker secret create\n\n  \n\nCreate a secret from a file or STDIN as content\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker secret create [OPTIONS] SECRET [file|-]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a secret using standard input or from a file for the secret content.\n\nFor detailed information about using secrets, refer to [manage sensitive data with Docker secrets](../../../swarm/secrets/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand     | Default | Description     |\n|---------------------|---------|-----------------|\n| `--driver` , `-d`   |         | Secret driver   |\n| `--label` , `-l`    |         | Secret labels   |\n| `--template-driver` |         | Template driver |\n\n## Examples\n\n### Create a secret\n\n``` \n$ printf \"my super secret password\" | docker secret create my_secret -\n\nonakdyv307se2tl7nl20anokv\n\n$ docker secret ls\n\nID                          NAME                CREATED             UPDATED\nonakdyv307se2tl7nl20anokv   my_secret           6 seconds ago       6 seconds ago\n```\n\n### Create a secret with a file\n\n``` \n$ docker secret create my_secret ./secret.json\n\ndg426haahpi5ezmkkj5kyl3sn\n\n$ docker secret ls\n\nID                          NAME                CREATED             UPDATED\ndg426haahpi5ezmkkj5kyl3sn   my_secret           7 seconds ago       7 seconds ago\n```\n\n### Create a secret with labels\n\n``` \n$ docker secret create \\\n  --label env=dev \\\n  --label rev=20170324 \\\n  my_secret ./secret.json\n\neo7jnzguqgtpdah3cm5srfb97\n```\n\n``` \n$ docker secret inspect my_secret\n\n[\n    {\n        \"ID\": \"eo7jnzguqgtpdah3cm5srfb97\",\n        \"Version\": {\n            \"Index\": 17\n        },\n        \"CreatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n        \"UpdatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n        \"Spec\": {\n            \"Name\": \"my_secret\",\n            \"Labels\": {\n                \"env\": \"dev\",\n                \"rev\": \"20170324\"\n            }\n        }\n    }\n]\n```\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker secret](../secret/index) | Manage Docker secrets |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker secret create](index)                    | Create a secret from a file or STDIN as content     |\n| [docker secret inspect](../secret_inspect/index) | Display detailed information on one or more secrets |\n| [docker secret ls](../secret_ls/index)           | List secrets                                        |\n| [docker secret rm](../secret_rm/index)           | Remove one or more secrets                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/secret_create/](https://docs.docker.com/engine/reference/commandline/secret_create/)"
- name: docker secret inspect
  id: engine/reference/commandline/secret_inspect/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker secret inspect\n\n  \n\nDisplay detailed information on one or more secrets\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker secret inspect [OPTIONS] SECRET [SECRET...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nInspects the specified secret.\n\nBy default, this renders all results in a JSON array. If a format is specified, the given template will be executed for each result.\n\nGo’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nFor detailed information about using secrets, refer to [manage sensitive data with Docker secrets](../../../swarm/secrets/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                      |\n|-------------------|---------|--------------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template    |\n| `--pretty`        |         | Print the information in a human friendly format |\n\n## Examples\n\n### Inspect a secret by name or ID\n\nYou can inspect a secret, either by its *name*, or *ID*\n\nFor example, given the following secret:\n\n``` \n$ docker secret ls\n\nID                          NAME                CREATED             UPDATED\neo7jnzguqgtpdah3cm5srfb97   my_secret           3 minutes ago       3 minutes ago\n```\n\n``` \n$ docker secret inspect secret.json\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"ID\": \"eo7jnzguqgtpdah3cm5srfb97\",\n    \"Version\": {\n      \"Index\": 17\n    },\n    \"CreatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n    \"UpdatedAt\": \"2017-03-24T08:15:09.735271783Z\",\n    \"Spec\": {\n      \"Name\": \"my_secret\",\n      \"Labels\": {\n        \"env\": \"dev\",\n        \"rev\": \"20170324\"\n      }\n    }\n  }\n]\n```\n\n### Formatting\n\nYou can use the --format option to obtain specific information about a secret. The following example command outputs the creation time of the secret.\n\n``` \n$ docker secret inspect --format='{{.CreatedAt}}' eo7jnzguqgtpdah3cm5srfb97\n\n2017-03-24 08:15:09.735271783 +0000 UTC\n```\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker secret](../secret/index) | Manage Docker secrets |\n\n## Related commands\n\n| Command                                        | Description                                         |\n|------------------------------------------------|-----------------------------------------------------|\n| [docker secret create](../secret_create/index) | Create a secret from a file or STDIN as content     |\n| [docker secret inspect](index)                 | Display detailed information on one or more secrets |\n| [docker secret ls](../secret_ls/index)         | List secrets                                        |\n| [docker secret rm](../secret_rm/index)         | Remove one or more secrets                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/secret_inspect/](https://docs.docker.com/engine/reference/commandline/secret_inspect/)"
- name: docker secret ls
  id: engine/reference/commandline/secret_ls/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker secret ls\n\n  \n\nList secrets\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker secret ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRun this command on a manager node to list the secrets in the swarm.\n\nFor detailed information about using secrets, refer to [manage sensitive data with Docker secrets](../../../swarm/secrets/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print secrets using a Go template   |\n| `--quiet` , `-q`  |         | Only display IDs                           |\n\n## Examples\n\n``` \n$ docker secret ls\n\nID                          NAME                        CREATED             UPDATED\n6697bflskwj1998km1gnnjr38   q5s5570vtvnimefos1fyeo2u2   6 weeks ago         6 weeks ago\n9u9hk4br2ej0wgngkga6rp4hq   my_secret                   5 weeks ago         5 weeks ago\nmem02h8n73mybpgqjf0kfi1n0   test_secret                 3 seconds ago       3 seconds ago\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- [id](#id) (secret’s ID)\n- [label](#label) (`label=<key>` or `label=<key>=<value>`)\n- [name](#name) (secret’s name)\n\n#### id\n\nThe `id` filter matches all or prefix of a secret’s id.\n\n``` \n$ docker secret ls -f \"id=6697bflskwj1998km1gnnjr38\"\n\nID                          NAME                        CREATED             UPDATED\n6697bflskwj1998km1gnnjr38   q5s5570vtvnimefos1fyeo2u2   6 weeks ago         6 weeks ago\n```\n\n#### label\n\nThe `label` filter matches secrets based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches all secrets with a `project` label regardless of its value:\n\n``` \n$ docker secret ls --filter label=project\n\nID                          NAME                        CREATED             UPDATED\nmem02h8n73mybpgqjf0kfi1n0   test_secret                 About an hour ago   About an hour ago\n```\n\nThe following filter matches only services with the `project` label with the `project-a` value.\n\n``` \n$ docker service ls --filter label=project=test\n\nID                          NAME                        CREATED             UPDATED\nmem02h8n73mybpgqjf0kfi1n0   test_secret                 About an hour ago   About an hour ago\n```\n\n#### name\n\nThe `name` filter matches on all or prefix of a secret’s name.\n\nThe following filter matches secret with a name containing a prefix of `test`.\n\n``` \n$ docker secret ls --filter name=test_secret\n\nID                          NAME                        CREATED             UPDATED\nmem02h8n73mybpgqjf0kfi1n0   test_secret                 About an hour ago   About an hour ago\n```\n\n### Format the output\n\nThe formatting option (`--format`) pretty prints secrets output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder  | Description                                                                          |\n|--------------|--------------------------------------------------------------------------------------|\n| `.ID`        | Secret ID                                                                            |\n| `.Name`      | Secret name                                                                          |\n| `.CreatedAt` | Time when the secret was created                                                     |\n| `.UpdatedAt` | Time when the secret was updated                                                     |\n| `.Labels`    | All labels assigned to the secret                                                    |\n| `.Label`     | Value of a specific label for this secret. For example `{{.Label \"secret.ssh.key\"}}` |\n\nWhen using the `--format` option, the `secret ls` command will either output the data exactly as the template declares or, when using the `table` directive, will include column headers as well.\n\nThe following example uses a template without headers and outputs the `ID` and `Name` entries separated by a colon (`:`) for all images:\n\n``` \n$ docker secret ls --format \"{{.ID}}: {{.Name}}\"\n\n77af4d6b9913: secret-1\nb6fa739cedf5: secret-2\n78a85c484f71: secret-3\n```\n\nTo list all secrets with their name and created date in a table format you can use:\n\n``` \n$ docker secret ls --format \"table {{.ID}}\\t{{.Name}}\\t{{.CreatedAt}}\"\n\nID                  NAME                      CREATED\n77af4d6b9913        secret-1                  5 minutes ago\nb6fa739cedf5        secret-2                  3 hours ago\n78a85c484f71        secret-3                  10 days ago\n```\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker secret](../secret/index) | Manage Docker secrets |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker secret create](../secret_create/index)   | Create a secret from a file or STDIN as content     |\n| [docker secret inspect](../secret_inspect/index) | Display detailed information on one or more secrets |\n| [docker secret ls](index)                        | List secrets                                        |\n| [docker secret rm](../secret_rm/index)           | Remove one or more secrets                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/secret_ls/](https://docs.docker.com/engine/reference/commandline/secret_ls/)"
- name: docker secret rm
  id: engine/reference/commandline/secret_rm/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker secret rm\n\n  \n\nRemove one or more secrets\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker secret rm SECRET [SECRET...]\n```\n\n## Description\n\nRemoves the specified secrets from the swarm.\n\nFor detailed information about using secrets, refer to [manage sensitive data with Docker secrets](../../../swarm/secrets/index).\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\nThis example removes a secret:\n\n``` \n$ docker secret rm secret.json\nsapth4csdo5b6wz2p5uimh5xg\n```\n\n> **Warning**\n>\n> Unlike `docker rm`, this command does not ask for confirmation before removing a secret.\n\n## Parent command\n\n| Command                          | Description           |\n|:---------------------------------|:----------------------|\n| [docker secret](../secret/index) | Manage Docker secrets |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker secret create](../secret_create/index)   | Create a secret from a file or STDIN as content     |\n| [docker secret inspect](../secret_inspect/index) | Display detailed information on one or more secrets |\n| [docker secret ls](../secret_ls/index)           | List secrets                                        |\n| [docker secret rm](index)                        | Remove one or more secrets                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/secret_rm/](https://docs.docker.com/engine/reference/commandline/secret_rm/)"
- name: Docker security
  id: engine/security/index
  summary: Docker containers are very similar to LXC containers, and they have similar security features
  description: "# Docker security\n\nThere are four major areas to consider when reviewing Docker security:\n\n- the intrinsic security of the kernel and its support for namespaces and cgroups;\n- the attack surface of the Docker daemon itself;\n- loopholes in the container configuration profile, either by default, or when customized by users.\n- the “hardening” security features of the kernel and how they interact with containers.\n\n## Kernel namespaces\n\nDocker containers are very similar to LXC containers, and they have similar security features. When you start a container with `docker run`, behind the scenes Docker creates a set of namespaces and control groups for the container.\n\n**Namespaces provide the first and most straightforward form of isolation**: processes running within a container cannot see, and even less affect, processes running in another container, or in the host system.\n\n**Each container also gets its own network stack**, meaning that a container doesn’t get privileged access to the sockets or interfaces of another container. Of course, if the host system is setup accordingly, containers can interact with each other through their respective network interfaces — just like they can interact with external hosts. When you specify public ports for your containers or use [*links*](https://docs.docker.com/network/links/) then IP traffic is allowed between containers. They can ping each other, send/receive UDP packets, and establish TCP connections, but that can be restricted if necessary. From a network architecture point of view, all containers on a given Docker host are sitting on bridge interfaces. This means that they are just like physical machines connected through a common Ethernet switch; no more, no less.\n\nHow mature is the code providing kernel namespaces and private networking? Kernel namespaces were introduced [between kernel version 2.6.15 and 2.6.26](https://man7.org/linux/man-pages/man7/namespaces.7.html). This means that since July 2008 (date of the 2.6.26 release ), namespace code has been exercised and scrutinized on a large number of production systems. And there is more: the design and inspiration for the namespaces code are even older. Namespaces are actually an effort to reimplement the features of [OpenVZ](https://en.wikipedia.org/wiki/OpenVZ) in such a way that they could be merged within the mainstream kernel. And OpenVZ was initially released in 2005, so both the design and the implementation are pretty mature.\n\n## Control groups\n\nControl Groups are another key component of Linux Containers. They implement resource accounting and limiting. They provide many useful metrics, but they also help ensure that each container gets its fair share of memory, CPU, disk I/O; and, more importantly, that a single container cannot bring the system down by exhausting one of those resources.\n\nSo while they do not play a role in preventing one container from accessing or affecting the data and processes of another container, they are essential to fend off some denial-of-service attacks. They are particularly important on multi-tenant platforms, like public and private PaaS, to guarantee a consistent uptime (and performance) even when some applications start to misbehave.\n\nControl Groups have been around for a while as well: the code was started in 2006, and initially merged in kernel 2.6.24.\n\n## Docker daemon attack surface\n\nRunning containers (and applications) with Docker implies running the Docker daemon. This daemon requires `root` privileges unless you opt-in to [Rootless mode](rootless/index), and you should therefore be aware of some important details.\n\nFirst of all, **only trusted users should be allowed to control your Docker daemon**. This is a direct consequence of some powerful Docker features. Specifically, Docker allows you to share a directory between the Docker host and a guest container; and it allows you to do so without limiting the access rights of the container. This means that you can start a container where the `/host` directory is the `/` directory on your host; and the container can alter your host filesystem without any restriction. This is similar to how virtualization systems allow filesystem resource sharing. Nothing prevents you from sharing your root filesystem (or even your root block device) with a virtual machine.\n\nThis has a strong security implication: for example, if you instrument Docker from a web server to provision containers through an API, you should be even more careful than usual with parameter checking, to make sure that a malicious user cannot pass crafted parameters causing Docker to create arbitrary containers.\n\nFor this reason, the REST API endpoint (used by the Docker CLI to communicate with the Docker daemon) changed in Docker 0.5.2, and now uses a UNIX socket instead of a TCP socket bound on 127.0.0.1 (the latter being prone to cross-site request forgery attacks if you happen to run Docker directly on your local machine, outside of a VM). You can then use traditional UNIX permission checks to limit access to the control socket.\n\nYou can also expose the REST API over HTTP if you explicitly decide to do so. However, if you do that, be aware of the above mentioned security implications. Note that even if you have a firewall to limit accesses to the REST API endpoint from other hosts in the network, the endpoint can be still accessible from containers, and it can easily result in the privilege escalation. Therefore it is *mandatory* to secure API endpoints with [HTTPS and certificates](protect-access/index). It is also recommended to ensure that it is reachable only from a trusted network or VPN.\n\nYou can also use `DOCKER_HOST=ssh://USER@HOST` or `ssh -L /path/to/docker.sock:/var/run/docker.sock` instead if you prefer SSH over TLS.\n\nThe daemon is also potentially vulnerable to other inputs, such as image loading from either disk with `docker load`, or from the network with `docker pull`. As of Docker 1.3.2, images are now extracted in a chrooted subprocess on Linux/Unix platforms, being the first-step in a wider effort toward privilege separation. As of Docker 1.10.0, all images are stored and accessed by the cryptographic checksums of their contents, limiting the possibility of an attacker causing a collision with an existing image.\n\nFinally, if you run Docker on a server, it is recommended to run exclusively Docker on the server, and move all other services within containers controlled by Docker. Of course, it is fine to keep your favorite admin tools (probably at least an SSH server), as well as existing monitoring/supervision processes, such as NRPE and collectd.\n\n## Linux kernel capabilities\n\nBy default, Docker starts containers with a restricted set of capabilities. What does that mean?\n\nCapabilities turn the binary “root/non-root” dichotomy into a fine-grained access control system. Processes (like web servers) that just need to bind on a port below 1024 do not need to run as root: they can just be granted the `net_bind_service` capability instead. And there are many other capabilities, for almost all the specific areas where root privileges are usually needed.\n\nThis means a lot for container security; let’s see why!\n\nTypical servers run several processes as `root`, including the SSH daemon, `cron` daemon, logging daemons, kernel modules, network configuration tools, and more. A container is different, because almost all of those tasks are handled by the infrastructure around the container:\n\n- SSH access are typically managed by a single server running on the Docker host;\n- `cron`, when necessary, should run as a user process, dedicated and tailored for the app that needs its scheduling service, rather than as a platform-wide facility;\n- log management is also typically handed to Docker, or to third-party services like Loggly or Splunk;\n- hardware management is irrelevant, meaning that you never need to run `udevd` or equivalent daemons within containers;\n- network management happens outside of the containers, enforcing separation of concerns as much as possible, meaning that a container should never need to perform `ifconfig`, `route`, or ip commands (except when a container is specifically engineered to behave like a router or firewall, of course).\n\nThis means that in most cases, containers do not need “real” root privileges *at all*. And therefore, containers can run with a reduced capability set; meaning that “root” within a container has much less privileges than the real “root”. For instance, it is possible to:\n\n- deny all “mount” operations;\n- deny access to raw sockets (to prevent packet spoofing);\n- deny access to some filesystem operations, like creating new device nodes, changing the owner of files, or altering attributes (including the immutable flag);\n- deny module loading;\n- and many others.\n\nThis means that even if an intruder manages to escalate to root within a container, it is much harder to do serious damage, or to escalate to the host.\n\nThis doesn’t affect regular web apps, but reduces the vectors of attack by malicious users considerably. By default Docker drops all capabilities except [those needed](https://github.com/moby/moby/blob/master/oci/caps/defaults.go#L6-L19), an allowlist instead of a denylist approach. You can see a full list of available capabilities in [Linux manpages](https://man7.org/linux/man-pages/man7/capabilities.7.html).\n\nOne primary risk with running Docker containers is that the default set of capabilities and mounts given to a container may provide incomplete isolation, either independently, or when used in combination with kernel vulnerabilities.\n\nDocker supports the addition and removal of capabilities, allowing use of a non-default profile. This may make Docker more secure through capability removal, or less secure through the addition of capabilities. The best practice for users would be to remove all capabilities except those explicitly required for their processes.\n\n## Docker Content Trust Signature Verification\n\nThe Docker Engine can be configured to only run signed images. The Docker Content Trust signature verification feature is built directly into the `dockerd` binary.  \nThis is configured in the Dockerd configuration file.\n\nTo enable this feature, trustpinning can be configured in `daemon.json`, whereby only repositories signed with a user-specified root key can be pulled and run.\n\nThis feature provides more insight to administrators than previously available with the CLI for enforcing and performing image signature verification.\n\nFor more information on configuring Docker Content Trust Signature Verificiation, go to [Content trust in Docker](trust/index).\n\n## Other kernel security features\n\nCapabilities are just one of the many security features provided by modern Linux kernels. It is also possible to leverage existing, well-known systems like TOMOYO, AppArmor, SELinux, GRSEC, etc. with Docker.\n\nWhile Docker currently only enables capabilities, it doesn’t interfere with the other systems. This means that there are many different ways to harden a Docker host. Here are a few examples.\n\n- You can run a kernel with GRSEC and PAX. This adds many safety checks, both at compile-time and run-time; it also defeats many exploits, thanks to techniques like address randomization. It doesn’t require Docker-specific configuration, since those security features apply system-wide, independent of containers.\n- If your distribution comes with security model templates for Docker containers, you can use them out of the box. For instance, we ship a template that works with AppArmor and Red Hat comes with SELinux policies for Docker. These templates provide an extra safety net (even though it overlaps greatly with capabilities).\n- You can define your own policies using your favorite access control mechanism.\n\nJust as you can use third-party tools to augment Docker containers, including special network topologies or shared filesystems, tools exist to harden Docker containers without the need to modify Docker itself.\n\nAs of Docker 1.10 User Namespaces are supported directly by the docker daemon. This feature allows for the root user in a container to be mapped to a non uid-0 user outside the container, which can help to mitigate the risks of container breakout. This facility is available but not enabled by default.\n\nRefer to the [daemon command](../reference/commandline/dockerd/index#daemon-user-namespace-options) in the command line reference for more information on this feature. Additional information on the implementation of User Namespaces in Docker can be found in [this blog post](https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/).\n\n## Conclusions\n\nDocker containers are, by default, quite secure; especially if you run your processes as non-privileged users inside the container.\n\nYou can add an extra layer of safety by enabling AppArmor, SELinux, GRSEC, or another appropriate hardening system.\n\nIf you think of ways to make docker more secure, we welcome feature requests, pull requests, or comments on the Docker community forums.\n\n## Related information\n\n- [Use trusted images](trust/index)\n- [Seccomp security profiles for Docker](seccomp/index)\n- [AppArmor security profiles for Docker](apparmor/index)\n- [On the Security of Containers (2014)](https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e)\n- [Docker swarm mode overlay network security model](https://docs.docker.com/network/overlay/)\n\n[Docker](https://docs.docker.com/search/?q=Docker), [Docker documentation](https://docs.docker.com/search/?q=Docker%20documentation), [security](https://docs.docker.com/search/?q=security)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/](https://docs.docker.com/engine/security/)"
- name: docker service
  id: engine/reference/commandline/service/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service\n\n  \n\nManage services\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service COMMAND\n```\n\n## Description\n\nManage services.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\n## Child commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service/](https://docs.docker.com/engine/reference/commandline/service/)"
- name: docker service create
  id: engine/reference/commandline/service_create/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service create\n\n  \n\nCreate a new service\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service create [OPTIONS] IMAGE [COMMAND] [ARG...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a service as described by the specified parameters.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand                | Default      | Description                                                                                                                  |\n|--------------------------------|--------------|------------------------------------------------------------------------------------------------------------------------------|\n| `--cap-add`                    |              | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Add Linux capabilities                                                |\n| `--cap-drop`                   |              | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Drop Linux capabilities                                               |\n| `--config`                     |              | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Specify configurations to expose to the service                       |\n| `--constraint`                 |              | Placement constraints                                                                                                        |\n| `--container-label`            |              | Container labels                                                                                                             |\n| `--credential-spec`            |              | Credential spec for managed service account (Windows only)                                                                   |\n| `--detach` , `-d`              |              | Exit immediately instead of waiting for the service to converge                                                              |\n| `--dns`                        |              | Set custom DNS servers                                                                                                       |\n| `--dns-option`                 |              | Set DNS options                                                                                                              |\n| `--dns-search`                 |              | Set custom DNS search domains                                                                                                |\n| `--endpoint-mode`              | `vip`        | Endpoint mode (vip or dnsrr)                                                                                                 |\n| `--entrypoint`                 |              | Overwrite the default ENTRYPOINT of the image                                                                                |\n| `--env` , `-e`                 |              | Set environment variables                                                                                                    |\n| `--env-file`                   |              | Read in a file of environment variables                                                                                      |\n| `--generic-resource`           |              | User defined resources                                                                                                       |\n| `--group`                      |              | Set one or more supplementary user groups for the container                                                                  |\n| `--health-cmd`                 |              | Command to run to check health                                                                                               |\n| `--health-interval`            |              | Time between running the check (ms\\|s\\|m\\|h)                                                                                 |\n| `--health-retries`             |              | Consecutive failures needed to report unhealthy                                                                              |\n| `--health-start-period`        |              | Start period for the container to initialize before counting retries towards unstable (ms\\|s\\|m\\|h)                          |\n| `--health-timeout`             |              | Maximum time to allow one check to run (ms\\|s\\|m\\|h)                                                                         |\n| `--host`                       |              | Set one or more custom host-to-IP mappings (host:ip)                                                                         |\n| `--hostname`                   |              | Container hostname                                                                                                           |\n| `--init`                       |              | Use an init inside each service container to forward signals and reap processes                                              |\n| `--isolation`                  |              | Service container isolation mode                                                                                             |\n| `--label` , `-l`               |              | Service labels                                                                                                               |\n| `--limit-cpu`                  |              | Limit CPUs                                                                                                                   |\n| `--limit-memory`               |              | Limit Memory                                                                                                                 |\n| `--limit-pids`                 |              | [API 1.41+](https://docs.docker.com/engine/api/v1.41/)Swarm Limit maximum number of processes (default 0 = unlimited)        |\n| `--log-driver`                 |              | Logging driver for service                                                                                                   |\n| `--log-opt`                    |              | Logging driver options                                                                                                       |\n| `--max-concurrent`             |              | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Number of job tasks to run concurrently (default equal to --replicas) |\n| `--mode`                       | `replicated` | Service mode (replicated, global, replicated-job, or global-job)                                                             |\n| `--mount`                      |              | Attach a filesystem mount to the service                                                                                     |\n| `--name`                       |              | Service name                                                                                                                 |\n| `--network`                    |              | Network attachments                                                                                                          |\n| `--no-healthcheck`             |              | Disable any container-specified HEALTHCHECK                                                                                  |\n| `--no-resolve-image`           |              | Do not query the registry to resolve image digest and supported platforms                                                    |\n| `--placement-pref`             |              | Add a placement preference                                                                                                   |\n| `--publish` , `-p`             |              | Publish a port as a node port                                                                                                |\n| `--quiet` , `-q`               |              | Suppress progress output                                                                                                     |\n| `--read-only`                  |              | Mount the container's root filesystem as read only                                                                           |\n| `--replicas`                   |              | Number of tasks                                                                                                              |\n| `--replicas-max-per-node`      |              | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Maximum number of tasks per node (default 0 = unlimited)              |\n| `--reserve-cpu`                |              | Reserve CPUs                                                                                                                 |\n| `--reserve-memory`             |              | Reserve Memory                                                                                                               |\n| `--restart-condition`          |              | Restart when condition is met (\"none\"\\|\"on-failure\"\\|\"any\") (default \"any\")                                                  |\n| `--restart-delay`              |              | Delay between restart attempts (ns\\|us\\|ms\\|s\\|m\\|h) (default 5s)                                                            |\n| `--restart-max-attempts`       |              | Maximum number of restarts before giving up                                                                                  |\n| `--restart-window`             |              | Window used to evaluate the restart policy (ns\\|us\\|ms\\|s\\|m\\|h)                                                             |\n| `--rollback-delay`             |              | Delay between task rollbacks (ns\\|us\\|ms\\|s\\|m\\|h) (default 0s)                                                              |\n| `--rollback-failure-action`    |              | Action on rollback failure (\"pause\"\\|\"continue\") (default \"pause\")                                                           |\n| `--rollback-max-failure-ratio` |              | Failure rate to tolerate during a rollback (default 0)                                                                       |\n| `--rollback-monitor`           |              | Duration after each task rollback to monitor for failure (ns\\|us\\|ms\\|s\\|m\\|h) (default 5s)                                  |\n| `--rollback-order`             |              | Rollback order (\"start-first\"\\|\"stop-first\") (default \"stop-first\")                                                          |\n| `--rollback-parallelism`       | `1`          | Maximum number of tasks rolled back simultaneously (0 to roll back all at once)                                              |\n| `--secret`                     |              | Specify secrets to expose to the service                                                                                     |\n| `--stop-grace-period`          |              | Time to wait before force killing a container (ns\\|us\\|ms\\|s\\|m\\|h) (default 10s)                                            |\n| `--stop-signal`                |              | Signal to stop the container                                                                                                 |\n| `--sysctl`                     |              | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Sysctl options                                                        |\n| `--tty` , `-t`                 |              | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Allocate a pseudo-TTY                                                 |\n| `--ulimit`                     |              | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Ulimit options                                                        |\n| `--update-delay`               |              | Delay between updates (ns\\|us\\|ms\\|s\\|m\\|h) (default 0s)                                                                     |\n| `--update-failure-action`      |              | Action on update failure (\"pause\"\\|\"continue\"\\|\"rollback\") (default \"pause\")                                                 |\n| `--update-max-failure-ratio`   |              | Failure rate to tolerate during an update (default 0)                                                                        |\n| `--update-monitor`             |              | Duration after each task update to monitor for failure (ns\\|us\\|ms\\|s\\|m\\|h) (default 5s)                                    |\n| `--update-order`               |              | Update order (\"start-first\"\\|\"stop-first\") (default \"stop-first\")                                                            |\n| `--update-parallelism`         | `1`          | Maximum number of tasks updated simultaneously (0 to update all at once)                                                     |\n| `--user` , `-u`                |              | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\])                                                                   |\n| `--with-registry-auth`         |              | Send registry authentication details to swarm agents                                                                         |\n| `--workdir` , `-w`             |              | Working directory inside the container                                                                                       |\n\n## Examples\n\n### Create a service\n\n``` \n$ docker service create --name redis redis:3.0.6\n\ndmu1ept4cxcfe8k8lhtux3ro3\n\n$ docker service create --mode global --name redis2 redis:3.0.6\n\na8q9dasaafudfs8q8w32udass\n\n$ docker service ls\n\nID            NAME    MODE        REPLICAS  IMAGE\ndmu1ept4cxcf  redis   replicated  1/1       redis:3.0.6\na8q9dasaafud  redis2  global      1/1       redis:3.0.6\n```\n\n#### Create a service using an image on a private registry\n\nIf your image is available on a private registry which requires login, use the `--with-registry-auth` flag with `docker service create`, after logging in. If your image is stored on `registry.example.com`, which is a private registry, use a command like the following:\n\n``` \n$ docker login registry.example.com\n\n$ docker service  create \\\n  --with-registry-auth \\\n  --name my_service \\\n  registry.example.com/acme/my_image:latest\n```\n\nThis passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes are able to log into the registry and pull the image.\n\n### Create a service with 5 replica tasks (--replicas)\n\nUse the `--replicas` flag to set the number of replica tasks for a replicated service. The following command creates a `redis` service with `5` replica tasks:\n\n``` \n$ docker service create --name redis --replicas=5 redis:3.0.6\n\n4cdgfyky7ozwh3htjfw0d12qv\n```\n\nThe above command sets the *desired* number of tasks for the service. Even though the command returns immediately, actual scaling of the service may take some time. The `REPLICAS` column shows both the *actual* and *desired* number of replica tasks for the service.\n\nIn the following example the desired state is `5` replicas, but the current number of `RUNNING` tasks is `3`:\n\n``` \n$ docker service ls\n\nID            NAME   MODE        REPLICAS  IMAGE\n4cdgfyky7ozw  redis  replicated  3/5       redis:3.0.7\n```\n\nOnce all the tasks are created and `RUNNING`, the actual number of tasks is equal to the desired number:\n\n``` \n$ docker service ls\n\nID            NAME   MODE        REPLICAS  IMAGE\n4cdgfyky7ozw  redis  replicated  5/5       redis:3.0.7\n```\n\n### Create a service with secrets\n\nUse the `--secret` flag to give a container access to a [secret](../secret_create/index).\n\nCreate a service specifying a secret:\n\n``` \n$ docker service create --name redis --secret secret.json redis:3.0.6\n\n4cdgfyky7ozwh3htjfw0d12qv\n```\n\nCreate a service specifying the secret, target, user/group ID, and mode:\n\n``` \n$ docker service create --name redis \\\n    --secret source=ssh-key,target=ssh \\\n    --secret source=app-key,target=app,uid=1000,gid=1001,mode=0400 \\\n    redis:3.0.6\n\n4cdgfyky7ozwh3htjfw0d12qv\n```\n\nTo grant a service access to multiple secrets, use multiple `--secret` flags.\n\nSecrets are located in `/run/secrets` in the container if no target is specified. If no target is specified, the name of the secret is used as the in memory file in the container. If a target is specified, that is used as the filename. In the example above, two files are created: `/run/secrets/ssh` and `/run/secrets/app` for each of the secret targets specified.\n\n### Create a service with configs\n\nUse the `--config` flag to give a container access to a [config](../config_create/index).\n\nCreate a service with a config. The config will be mounted into `redis-config`, be owned by the user who runs the command inside the container (often `root`), and have file mode `0444` or world-readable. You can specify the `uid` and `gid` as numerical IDs or names. When using names, the provided group/user names must pre-exist in the container. The `mode` is specified as a 4-number sequence such as `0755`.\n\n``` \n$ docker service create --name=redis --config redis-conf redis:3.0.6\n```\n\nCreate a service with a config and specify the target location and file mode:\n\n``` \n$ docker service create --name redis \\\n  --config source=redis-conf,target=/etc/redis/redis.conf,mode=0400 redis:3.0.6\n```\n\nTo grant a service access to multiple configs, use multiple `--config` flags.\n\nConfigs are located in `/` in the container if no target is specified. If no target is specified, the name of the config is used as the name of the file in the container. If a target is specified, that is used as the filename.\n\n### Create a service with a rolling update policy\n\n``` \n$ docker service create \\\n  --replicas 10 \\\n  --name redis \\\n  --update-delay 10s \\\n  --update-parallelism 2 \\\n  redis:3.0.6\n```\n\nWhen you run a [service update](../service_update/index), the scheduler updates a maximum of 2 tasks at a time, with `10s` between updates. For more information, refer to the [rolling updates tutorial](../../../swarm/swarm-tutorial/rolling-update/index).\n\n### Set environment variables (-e, --env)\n\nThis sets an environment variable for all tasks in a service. For example:\n\n``` \n$ docker service create \\\n  --name redis_2 \\\n  --replicas 5 \\\n  --env MYVAR=foo \\\n  redis:3.0.6\n```\n\nTo specify multiple environment variables, specify multiple `--env` flags, each with a separate key-value pair.\n\n``` \n$ docker service create \\\n  --name redis_2 \\\n  --replicas 5 \\\n  --env MYVAR=foo \\\n  --env MYVAR2=bar \\\n  redis:3.0.6\n```\n\n### Create a service with specific hostname (--hostname)\n\nThis option sets the docker service containers hostname to a specific string. For example:\n\n``` \n$ docker service create --name redis --hostname myredis redis:3.0.6\n```\n\n### Set metadata on a service (-l, --label)\n\nA label is a `key=value` pair that applies metadata to a service. To label a service with two labels:\n\n``` \n$ docker service create \\\n  --name redis_2 \\\n  --label com.example.foo=\"bar\"\n  --label bar=baz \\\n  redis:3.0.6\n```\n\nFor more information about labels, refer to [apply custom metadata](https://docs.docker.com/config/labels-custom-metadata/).\n\n### Add bind mounts, volumes or memory filesystems\n\nDocker supports three different kinds of mounts, which allow containers to read from or write to files or directories, either on the host operating system, or on memory filesystems. These types are *data volumes* (often referred to simply as volumes), *bind mounts*, *tmpfs*, and *named pipes*.\n\nA **bind mount** makes a file or directory on the host available to the container it is mounted within. A bind mount may be either read-only or read-write. For example, a container might share its host’s DNS information by means of a bind mount of the host’s `/etc/resolv.conf` or a container might write logs to its host’s `/var/log/myContainerLogs` directory. If you use bind mounts and your host and containers have different notions of permissions, access controls, or other such details, you will run into portability issues.\n\nA **named volume** is a mechanism for decoupling persistent data needed by your container from the image used to create the container and from the host machine. Named volumes are created and managed by Docker, and a named volume persists even when no container is currently using it. Data in named volumes can be shared between a container and the host machine, as well as between multiple containers. Docker uses a *volume driver* to create, manage, and mount volumes. You can back up or restore volumes using Docker commands.\n\nA **tmpfs** mounts a tmpfs inside a container for volatile data.\n\nA **npipe** mounts a named pipe from the host into the container.\n\nConsider a situation where your image starts a lightweight web server. You could use that image as a base image, copy in your website’s HTML files, and package that into another image. Each time your website changed, you’d need to update the new image and redeploy all of the containers serving your website. A better solution is to store the website in a named volume which is attached to each of your web server containers when they start. To update the website, you just update the named volume.\n\nFor more information about named volumes, see [Data Volumes](https://docs.docker.com/storage/volumes/).\n\nThe following table describes options which apply to both bind mounts and named volumes in a service:\n\n[TABLE]\n\n#### Options for Bind Mounts\n\nThe following options can only be used for bind mounts (`type=bind`):\n\n[TABLE]\n\n##### Bind propagation\n\nBind propagation refers to whether or not mounts created within a given bind mount or named volume can be propagated to replicas of that mount. Consider a mount point `/mnt`, which is also mounted on `/tmp`. The propagation settings control whether a mount on `/tmp/a` would also be available on `/mnt/a`. Each propagation setting has a recursive counterpoint. In the case of recursion, consider that `/tmp/a` is also mounted as `/foo`. The propagation settings control whether `/mnt/a` and/or `/tmp/a` would exist.\n\nThe `bind-propagation` option defaults to `rprivate` for both bind mounts and volume mounts, and is only configurable for bind mounts. In other words, named volumes do not support bind propagation.\n\n- **`shared`**: Sub-mounts of the original mount are exposed to replica mounts, and sub-mounts of replica mounts are also propagated to the original mount.\n- **`slave`**: similar to a shared mount, but only in one direction. If the original mount exposes a sub-mount, the replica mount can see it. However, if the replica mount exposes a sub-mount, the original mount cannot see it.\n- **`private`**: The mount is private. Sub-mounts within it are not exposed to replica mounts, and sub-mounts of replica mounts are not exposed to the original mount.\n- **`rshared`**: The same as shared, but the propagation also extends to and from mount points nested within any of the original or replica mount points.\n- **`rslave`**: The same as `slave`, but the propagation also extends to and from mount points nested within any of the original or replica mount points.\n- **`rprivate`**: The default. The same as `private`, meaning that no mount points anywhere within the original or replica mount points propagate in either direction.\n\nFor more information about bind propagation, see the [Linux kernel documentation for shared subtree](https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt).\n\n#### Options for named volumes\n\nThe following options can only be used for named volumes (`type=volume`):\n\n[TABLE]\n\n#### Options for tmpfs\n\nThe following options can only be used for tmpfs mounts (`type=tmpfs`);\n\n|                |                                                                                             |\n|----------------|---------------------------------------------------------------------------------------------|\n| Option         | Description                                                                                 |\n| **tmpfs-size** | Size of the tmpfs mount in bytes. Unlimited by default in Linux.                            |\n| **tmpfs-mode** | File mode of the tmpfs in octal. (e.g. `\"700\"` or `\"0700\"`.) Defaults to `\"1777\"` in Linux. |\n\n#### Differences between “--mount” and “--volume”\n\nThe `--mount` flag supports most options that are supported by the `-v` or `--volume` flag for `docker run`, with some important exceptions:\n\n- The `--mount` flag allows you to specify a volume driver and volume driver options *per volume*, without creating the volumes in advance. In contrast, `docker run` allows you to specify a single volume driver which is shared by all volumes, using the `--volume-driver` flag.\n\n- The `--mount` flag allows you to specify custom metadata (“labels”) for a volume, before the volume is created.\n\n- When you use `--mount` with `type=bind`, the host-path must refer to an *existing* path on the host. The path will not be created for you and the service will fail with an error if the path does not exist.\n\n- The `--mount` flag does not allow you to relabel a volume with `Z` or `z` flags, which are used for `selinux` labeling.\n\n#### Create a service using a named volume\n\nThe following example creates a service that uses a named volume:\n\n``` \n$ docker service create \\\n  --name my-service \\\n  --replicas 3 \\\n  --mount type=volume,source=my-volume,destination=/path/in/container,volume-label=\"color=red\",volume-label=\"shape=round\" \\\n  nginx:alpine\n```\n\nFor each replica of the service, the engine requests a volume named “my-volume” from the default (“local”) volume driver where the task is deployed. If the volume does not exist, the engine creates a new volume and applies the “color” and “shape” labels.\n\nWhen the task is started, the volume is mounted on `/path/in/container/` inside the container.\n\nBe aware that the default (“local”) volume is a locally scoped volume driver. This means that depending on where a task is deployed, either that task gets a *new* volume named “my-volume”, or shares the same “my-volume” with other tasks of the same service. Multiple containers writing to a single shared volume can cause data corruption if the software running inside the container is not designed to handle concurrent processes writing to the same location. Also take into account that containers can be re-scheduled by the Swarm orchestrator and be deployed on a different node.\n\n#### Create a service that uses an anonymous volume\n\nThe following command creates a service with three replicas with an anonymous volume on `/path/in/container`:\n\n``` \n$ docker service create \\\n  --name my-service \\\n  --replicas 3 \\\n  --mount type=volume,destination=/path/in/container \\\n  nginx:alpine\n```\n\nIn this example, no name (`source`) is specified for the volume, so a new volume is created for each task. This guarantees that each task gets its own volume, and volumes are not shared between tasks. Anonymous volumes are removed after the task using them is complete.\n\n#### Create a service that uses a bind-mounted host directory\n\nThe following example bind-mounts a host directory at `/path/in/container` in the containers backing the service:\n\n``` \n$ docker service create \\\n  --name my-service \\\n  --mount type=bind,source=/path/on/host,destination=/path/in/container \\\n  nginx:alpine\n```\n\n### Set service mode (--mode)\n\nThe service mode determines whether this is a *replicated* service or a *global* service. A replicated service runs as many tasks as specified, while a global service runs on each active node in the swarm.\n\nThe following command creates a global service:\n\n``` \n$ docker service create \\\n --name redis_2 \\\n --mode global \\\n redis:3.0.6\n```\n\n### Specify service constraints (--constraint)\n\nYou can limit the set of nodes where a task can be scheduled by defining constraint expressions. Constraint expressions can either use a *match* (`==`) or *exclude* (`!=`) rule. Multiple constraints find nodes that satisfy every expression (AND match). Constraints can match node or Docker Engine labels as follows:\n\n| node attribute       | matches                        | example                                       |\n|----------------------|--------------------------------|-----------------------------------------------|\n| `node.id`            | Node ID                        | `node.id==2ivku8v2gvtg4`                      |\n| `node.hostname`      | Node hostname                  | `node.hostname!=node-2`                       |\n| `node.role`          | Node role (`manager`/`worker`) | `node.role==manager`                          |\n| `node.platform.os`   | Node operating system          | `node.platform.os==windows`                   |\n| `node.platform.arch` | Node architecture              | `node.platform.arch==x86_64`                  |\n| `node.labels`        | User-defined node labels       | `node.labels.security==high`                  |\n| `engine.labels`      | Docker Engine’s labels         | `engine.labels.operatingsystem==ubuntu-14.04` |\n\n`engine.labels` apply to Docker Engine labels like operating system, drivers, etc. Swarm administrators add `node.labels` for operational purposes by using the [`docker node update`](../node_update/index) command.\n\nFor example, the following limits tasks for the redis service to nodes where the node type label equals queue:\n\n``` \n$ docker service create \\\n  --name redis_2 \\\n  --constraint node.platform.os==linux \\\n  --constraint node.labels.type==queue \\\n  redis:3.0.6\n```\n\nIf the service constraints exclude all nodes in the cluster, a message is printed that no suitable node is found, but the scheduler will start a reconciliation loop and deploy the service once a suitable node becomes available.\n\nIn the example below, no node satisfying the constraint was found, causing the service to not reconcile with the desired state:\n\n``` \n$ docker service create \\\n  --name web \\\n  --constraint node.labels.region==east \\\n  nginx:alpine\n\nlx1wrhhpmbbu0wuk0ybws30bc\noverall progress: 0 out of 1 tasks\n1/1: no suitable node (scheduling constraints not satisfied on 5 nodes)\n\n$ docker service ls\nID                  NAME     MODE         REPLICAS   IMAGE               PORTS\nb6lww17hrr4e        web      replicated   0/1        nginx:alpine\n```\n\nAfter adding the `region=east` label to a node in the cluster, the service reconciles, and the desired number of replicas are deployed:\n\n``` \n$ docker node update --label-add region=east yswe2dm4c5fdgtsrli1e8ya5l\nyswe2dm4c5fdgtsrli1e8ya5l\n\n$ docker service ls\nID                  NAME     MODE         REPLICAS   IMAGE               PORTS\nb6lww17hrr4e        web      replicated   1/1        nginx:alpine\n```\n\n### Specify service placement preferences (--placement-pref)\n\nYou can set up the service to divide tasks evenly over different categories of nodes. One example of where this can be useful is to balance tasks over a set of datacenters or availability zones. The example below illustrates this:\n\n``` \n$ docker service create \\\n  --replicas 9 \\\n  --name redis_2 \\\n  --placement-pref spread=node.labels.datacenter \\\n  redis:3.0.6\n```\n\nThis uses `--placement-pref` with a `spread` strategy (currently the only supported strategy) to spread tasks evenly over the values of the `datacenter` node label. In this example, we assume that every node has a `datacenter` node label attached to it. If there are three different values of this label among nodes in the swarm, one third of the tasks will be placed on the nodes associated with each value. This is true even if there are more nodes with one value than another. For example, consider the following set of nodes:\n\n- Three nodes with `node.labels.datacenter=east`\n- Two nodes with `node.labels.datacenter=south`\n- One node with `node.labels.datacenter=west`\n\nSince we are spreading over the values of the `datacenter` label and the service has 9 replicas, 3 replicas will end up in each datacenter. There are three nodes associated with the value `east`, so each one will get one of the three replicas reserved for this value. There are two nodes with the value `south`, and the three replicas for this value will be divided between them, with one receiving two replicas and another receiving just one. Finally, `west` has a single node that will get all three replicas reserved for `west`.\n\nIf the nodes in one category (for example, those with `node.labels.datacenter=south`) can’t handle their fair share of tasks due to constraints or resource limitations, the extra tasks will be assigned to other nodes instead, if possible.\n\nBoth engine labels and node labels are supported by placement preferences. The example above uses a node label, because the label is referenced with `node.labels.datacenter`. To spread over the values of an engine label, use `--placement-pref spread=engine.labels.<labelname>`.\n\nIt is possible to add multiple placement preferences to a service. This establishes a hierarchy of preferences, so that tasks are first divided over one category, and then further divided over additional categories. One example of where this may be useful is dividing tasks fairly between datacenters, and then splitting the tasks within each datacenter over a choice of racks. To add multiple placement preferences, specify the `--placement-pref` flag multiple times. The order is significant, and the placement preferences will be applied in the order given when making scheduling decisions.\n\nThe following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):\n\n``` \n$ docker service create \\\n  --replicas 9 \\\n  --name redis_2 \\\n  --placement-pref 'spread=node.labels.datacenter' \\\n  --placement-pref 'spread=node.labels.rack' \\\n  redis:3.0.6\n```\n\nWhen updating a service with `docker service update`, `--placement-pref-add` appends a new placement preference after all existing placement preferences. `--placement-pref-rm` removes an existing placement preference that matches the argument.\n\n### Specify memory requirements and constraints for a service (--reserve-memory and --limit-memory)\n\nIf your service needs a minimum amount of memory in order to run correctly, you can use `--reserve-memory` to specify that the service should only be scheduled on a node with this much memory available to reserve. If no node is available that meets the criteria, the task is not scheduled, but remains in a pending state.\n\nThe following example requires that 4GB of memory be available and reservable on a given node before scheduling the service to run on that node.\n\n``` \n$ docker service create --reserve-memory=4GB --name=too-big nginx:alpine\n```\n\nThe managers won’t schedule a set of containers on a single node whose combined reservations exceed the memory available on that node.\n\nAfter a task is scheduled and running, `--reserve-memory` does not enforce a memory limit. Use `--limit-memory` to ensure that a task uses no more than a given amount of memory on a node. This example limits the amount of memory used by the task to 4GB. The task will be scheduled even if each of your nodes has only 2GB of memory, because `--limit-memory` is an upper limit.\n\n``` \n$ docker service create --limit-memory=4GB --name=too-big nginx:alpine\n```\n\nUsing `--reserve-memory` and `--limit-memory` does not guarantee that Docker will not use more memory on your host than you want. For instance, you could create many services, the sum of whose memory usage could exhaust the available memory.\n\nYou can prevent this scenario from exhausting the available memory by taking into account other (non-containerized) software running on the host as well. If `--reserve-memory` is greater than or equal to `--limit-memory`, Docker won’t schedule a service on a host that doesn’t have enough memory. `--limit-memory` will limit the service’s memory to stay within that limit, so if every service has a memory-reservation and limit set, Docker services will be less likely to saturate the host. Other non-service containers or applications running directly on the Docker host could still exhaust memory.\n\nThere is a downside to this approach. Reserving memory also means that you may not make optimum use of the memory available on the node. Consider a service that under normal circumstances uses 100MB of memory, but depending on load can “peak” at 500MB. Reserving 500MB for that service (to guarantee can have 500MB for those “peaks”) results in 400MB of memory being wasted most of the time.\n\nIn short, you can take a more conservative or more flexible approach:\n\n- **Conservative**: reserve 500MB, and limit to 500MB. Basically you’re now treating the service containers as VMs, and you may be losing a big advantage containers, which is greater density of services per host.\n\n- **Flexible**: limit to 500MB in the assumption that if the service requires more than 500MB, it is malfunctioning. Reserve something between the 100MB “normal” requirement and the 500MB “peak” requirement”. This assumes that when this service is at “peak”, other services or non-container workloads probably won’t be.\n\nThe approach you take depends heavily on the memory-usage patterns of your workloads. You should test under normal and peak conditions before settling on an approach.\n\nOn Linux, you can also limit a service’s overall memory footprint on a given host at the level of the host operating system, using `cgroups` or other relevant operating system tools.\n\n### Specify maximum replicas per node (--replicas-max-per-node)\n\nUse the `--replicas-max-per-node` flag to set the maximum number of replica tasks that can run on a node. The following command creates a nginx service with 2 replica tasks but only one replica task per node.\n\nOne example where this can be useful is to balance tasks over a set of data centers together with `--placement-pref` and let `--replicas-max-per-node` setting make sure that replicas are not migrated to another datacenter during maintenance or datacenter failure.\n\nThe example below illustrates this:\n\n``` \n$ docker service create \\\n  --name nginx \\\n  --replicas 2 \\\n  --replicas-max-per-node 1 \\\n  --placement-pref 'spread=node.labels.datacenter' \\\n  nginx\n```\n\n### Attach a service to an existing network (--network)\n\nYou can use overlay networks to connect one or more services within the swarm.\n\nFirst, create an overlay network on a manager node the docker network create command:\n\n``` \n$ docker network create --driver overlay my-network\n\netjpu59cykrptrgw0z0hk5snf\n```\n\nAfter you create an overlay network in swarm mode, all manager nodes have access to the network.\n\nWhen you create a service and pass the `--network` flag to attach the service to the overlay network:\n\n``` \n$ docker service create \\\n  --replicas 3 \\\n  --network my-network \\\n  --name my-web \\\n  nginx\n\n716thylsndqma81j6kkkb5aus\n```\n\nThe swarm extends my-network to each node running the service.\n\nContainers on the same network can access each other using [service discovery](https://docs.docker.com/network/overlay/#container-discovery).\n\nLong form syntax of `--network` allows to specify list of aliases and driver options: `--network name=my-network,alias=web1,driver-opt=field1=value1`\n\n### Publish service ports externally to the swarm (-p, --publish)\n\nYou can publish service ports to make them available externally to the swarm using the `--publish` flag. The `--publish` flag can take two different styles of arguments. The short version is positional, and allows you to specify the published port and target port separated by a colon (`:`).\n\n``` \n$ docker service create --name my_web --replicas 3 --publish 8080:80 nginx\n```\n\nThere is also a long format, which is easier to read and allows you to specify more options. The long format is preferred. You cannot specify the service’s mode when using the short format. Here is an example of using the long format for the same service as above:\n\n``` \n$ docker service create --name my_web --replicas 3 --publish published=8080,target=80 nginx\n```\n\nThe options you can specify are:\n\n| Option                    | Short syntax                            | Long syntax                                       | Description                                                                                                                                                                                                                                                            |\n|---------------------------|-----------------------------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| published and target port | `--publish 8080:80`                     | `--publish published=8080,target=80`              | The target port within the container and the port to map it to on the nodes, using the routing mesh (`ingress`) or host-level networking. More options are available, later in this table. The key-value syntax is preferred, because it is somewhat self-documenting. |\n| mode                      | Not possible to set using short syntax. | `--publish published=8080,target=80,mode=host`    | The mode to use for binding the port, either `ingress` or `host`. Defaults to `ingress` to use the routing mesh.                                                                                                                                                       |\n| protocol                  | `--publish 8080:80/tcp`                 | `--publish published=8080,target=80,protocol=tcp` | The protocol to use, `tcp` , `udp`, or `sctp`. Defaults to `tcp`. To bind a port for both protocols, specify the `-p` or `--publish` flag twice.                                                                                                                       |\n\nWhen you publish a service port using `ingress` mode, the swarm routing mesh makes the service accessible at the published port on every node regardless if there is a task for the service running on the node. If you use `host` mode, the port is only bound on nodes where the service is running, and a given port on a node can only be bound once. You can only set the publication mode using the long syntax. For more information refer to [Use swarm mode routing mesh](../../../swarm/ingress/index).\n\n### Provide credential specs for managed service accounts (Windows only)\n\nThis option is only used for services using Windows containers. The `--credential-spec` must be in the format `file://<filename>` or `registry://<value-name>`.\n\nWhen using the `file://<filename>` format, the referenced file must be present in the `CredentialSpecs` subdirectory in the docker data directory, which defaults to `C:\\ProgramData\\Docker\\` on Windows. For example, specifying `file://spec.json` loads `C:\\ProgramData\\Docker\\CredentialSpecs\\spec.json`.\n\nWhen using the `registry://<value-name>` format, the credential spec is read from the Windows registry on the daemon’s host. The specified registry value must be located in:\n\n``` \nHKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Virtualization\\Containers\\CredentialSpecs\n```\n\n### Create services using templates\n\nYou can use templates for some flags of `service create`, using the syntax provided by the Go’s [text/template](https://golang.org/pkg/text/template/) package.\n\nThe supported flags are the following :\n\n- `--hostname`\n- `--mount`\n- `--env`\n\nValid placeholders for the Go template are listed below:\n\n|                   |                |\n|-------------------|----------------|\n| Placeholder       | Description    |\n| `.Service.ID`     | Service ID     |\n| `.Service.Name`   | Service name   |\n| `.Service.Labels` | Service labels |\n| `.Node.ID`        | Node ID        |\n| `.Node.Hostname`  | Node Hostname  |\n| `.Task.ID`        | Task ID        |\n| `.Task.Name`      | Task name      |\n| `.Task.Slot`      | Task slot      |\n\n#### Template example\n\nIn this example, we are going to set the template of the created containers based on the service’s name, the node’s ID and hostname where it sits.\n\n``` \n$ docker service create \\\n    --name hosttempl \\\n    --hostname=\"{{.Node.Hostname}}-{{.Node.ID}}-{{.Service.Name}}\"\\\n    busybox top\n\nva8ew30grofhjoychbr6iot8c\n\n$ docker service ps va8ew30grofhjoychbr6iot8c\n\nID            NAME         IMAGE                                                                                   NODE          DESIRED STATE  CURRENT STATE               ERROR  PORTS\nwo41w8hg8qan  hosttempl.1  busybox:latest@sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912  2e7a8a9c4da2  Running        Running about a minute ago\n\n$ docker inspect --format=\"{{.Config.Hostname}}\" 2e7a8a9c4da2-wo41w8hg8qanxwjwsg4kxpprj-hosttempl\n\nx3ti0erg11rjpg64m75kej2mz-hosttempl\n```\n\n### Specify isolation mode (Windows)\n\nBy default, tasks scheduled on Windows nodes are run using the default isolation mode configured for this particular node. To force a specific isolation mode, you can use the `--isolation` flag:\n\n``` \n$ docker service create --name myservice --isolation=process microsoft/nanoserver\n```\n\nSupported isolation modes on Windows are:\n\n- `default`: use default settings specified on the node running the task\n- `process`: use process isolation (Windows server only)\n- `hyperv`: use Hyper-V isolation\n\n### Create services requesting Generic Resources\n\nYou can narrow the kind of nodes your task can land on through the using the `--generic-resource` flag (if the nodes advertise these resources):\n\n``` \n$ docker service create \\\n    --name cuda \\\n    --generic-resource \"NVIDIA-GPU=2\" \\\n    --generic-resource \"SSD=1\" \\\n    nvidia/cuda\n```\n\n### Running as a job\n\nJobs are a special kind of service designed to run an operation to completion and then stop, as opposed to running long-running daemons. When a Task belonging to a job exits successfully (return value 0), the Task is marked as “Completed”, and is not run again.\n\nJobs are started by using one of two modes, `replicated-job` or `global-job`\n\n``` \n$ docker service create --name myjob \\\n                        --mode replicated-job \\\n                        bash \"true\"\n```\n\nThis command will run one Task, which will, using the `bash` image, execute the command `true`, which will return 0 and then exit.\n\nThough Jobs are ultimately a different kind of service, they a couple of caveats compared to other services:\n\n- None of the update or rollback configuration options are valid. Jobs can be updated, but cannot be rolled out or rolled back, making these configuration options moot.\n- Jobs are never restarted on reaching the `Complete` state. This means that for jobs, setting `--restart-condition` to `any` is the same as setting it to `on-failure`.\n\nJobs are available in both replicated and global modes.\n\n#### Replicated Jobs\n\nA replicated job is like a replicated service. Setting the `--replicas` flag will specify total number of iterations of a job to execute.\n\nBy default, all replicas of a replicated job will launch at once. To control the total number of replicas that are executing simultaneously at any one time, the `--max-concurrent` flag can be used:\n\n``` \n$ docker service create \\\n    --name mythrottledjob \\\n    --mode replicated-job \\\n    --replicas 10 \\\n    --max-concurrent 2 \\\n    bash \"true\"\n```\n\nThe above command will execute 10 Tasks in total, but only 2 of them will be run at any given time.\n\n#### Global Jobs\n\nGlobal jobs are like global services, in that a Task is executed once on each node matching placement constraints. Global jobs are represented by the mode `global-job`.\n\nNote that after a Global job is created, any new Nodes added to the cluster will have a Task from that job started on them. The Global Job does not as a whole have a “done” state, except insofar as every Node meeting the job’s constraints has a Completed task.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](index)                       | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_create/](https://docs.docker.com/engine/reference/commandline/service_create/)"
- name: docker service inspect
  id: engine/reference/commandline/service_inspect/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service inspect\n\n  \n\nDisplay detailed information on one or more services\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service inspect [OPTIONS] SERVICE [SERVICE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nInspects the specified service.\n\nBy default, this renders all results in a JSON array. If a format is specified, the given template will be executed for each result.\n\nGo’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                      |\n|-------------------|---------|--------------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template    |\n| `--pretty`        |         | Print the information in a human friendly format |\n\n## Examples\n\n### Inspect a service by name or ID\n\nYou can inspect a service, either by its *name*, or *ID*\n\nFor example, given the following service;\n\n``` \n$ docker service ls\nID            NAME   MODE        REPLICAS  IMAGE\ndmu1ept4cxcf  redis  replicated  3/3       redis:3.0.6\n```\n\nBoth `docker service inspect redis`, and `docker service inspect dmu1ept4cxcf` produce the same result:\n\n``` \n$ docker service inspect redis\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"ID\": \"dmu1ept4cxcfe8k8lhtux3ro3\",\n    \"Version\": {\n      \"Index\": 12\n    },\n    \"CreatedAt\": \"2016-06-17T18:44:02.558012087Z\",\n    \"UpdatedAt\": \"2016-06-17T18:44:02.558012087Z\",\n    \"Spec\": {\n      \"Name\": \"redis\",\n      \"TaskTemplate\": {\n        \"ContainerSpec\": {\n          \"Image\": \"redis:3.0.6\"\n        },\n        \"Resources\": {\n          \"Limits\": {},\n          \"Reservations\": {}\n        },\n        \"RestartPolicy\": {\n          \"Condition\": \"any\",\n          \"MaxAttempts\": 0\n        },\n        \"Placement\": {}\n      },\n      \"Mode\": {\n        \"Replicated\": {\n          \"Replicas\": 1\n        }\n      },\n      \"UpdateConfig\": {},\n      \"EndpointSpec\": {\n        \"Mode\": \"vip\"\n      }\n    },\n    \"Endpoint\": {\n      \"Spec\": {}\n    }\n  }\n]\n```\n\n``` \n$ docker service inspect dmu1ept4cxcf\n\n[\n  {\n    \"ID\": \"dmu1ept4cxcfe8k8lhtux3ro3\",\n    \"Version\": {\n      \"Index\": 12\n    },\n    ...\n  }\n]\n```\n\n### Formatting\n\nYou can print the inspect output in a human-readable format instead of the default JSON output, by using the `--pretty` option:\n\n``` \n$ docker service inspect --pretty frontend\n\nID:     c8wgl7q4ndfd52ni6qftkvnnp\nName:   frontend\nLabels:\n - org.example.projectname=demo-app\nService Mode:   REPLICATED\n Replicas:      5\nPlacement:\nUpdateConfig:\n Parallelism:   0\n On failure:    pause\n Max failure ratio: 0\nContainerSpec:\n Image:     nginx:alpine\nResources:\nNetworks:   net1\nEndpoint Mode:  vip\nPorts:\n PublishedPort = 4443\n  Protocol = tcp\n  TargetPort = 443\n  PublishMode = ingress\n```\n\nYou can also use `--format pretty` for the same effect.\n\n#### Find the number of tasks running as part of a service\n\nThe `--format` option can be used to obtain specific information about a service. For example, the following command outputs the number of replicas of the “redis” service.\n\n``` \n$ docker service inspect --format='{{.Spec.Mode.Replicated.Replicas}}' redis\n\n10\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](index)                      | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_inspect/](https://docs.docker.com/engine/reference/commandline/service_inspect/)"
- name: docker service logs
  id: engine/reference/commandline/service_logs/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service logs\n\n  \n\nFetch the logs of a service or task\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service logs [OPTIONS] SERVICE|TASK\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker service logs` command batch-retrieves logs present at the time of execution.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nThe `docker service logs` command can be used with either the name or ID of a service, or with the ID of a task. If a service is passed, it will display logs for all of the containers in that service. If a task is passed, it will only display logs from that particular task.\n\n> **Note**\n>\n> This command is only functional for services that are started with the `json-file` or `journald` logging driver.\n\nFor more information about selecting and configuring logging drivers, refer to [Configure logging drivers](https://docs.docker.com/config/containers/logging/configure/).\n\nThe `docker service logs --follow` command will continue streaming the new output from the service’s `STDOUT` and `STDERR`.\n\nPassing a negative number or a non-integer to `--tail` is invalid and the value is set to `all` in that case.\n\nThe `docker service logs --timestamps` command will add an [RFC3339Nano timestamp](https://golang.org/pkg/time/#pkg-constants) , for example `2014-09-16T06:17:46.000000000Z`, to each log entry. To ensure that the timestamps are aligned the nano-second part of the timestamp will be padded with zero when necessary.\n\nThe `docker service logs --details` command will add on extra attributes, such as environment variables and labels, provided to `--log-opt` when creating the service.\n\nThe `--since` option shows only the service logs generated after a given date. You can specify the date as an RFC 3339 date, a UNIX timestamp, or a Go duration string (e.g. `1m30s`, `3h`). Besides RFC3339 date format you may also use RFC3339Nano, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the client will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long. You can combine the `--since` option with either or both of the `--follow` or `--tail` options.\n\n## Options\n\n| Name, shorthand       | Default | Description                                                                                 |\n|-----------------------|---------|---------------------------------------------------------------------------------------------|\n| `--details`           |         | Show extra details provided to logs                                                         |\n| `--follow` , `-f`     |         | Follow log output                                                                           |\n| `--no-resolve`        |         | Do not map IDs to Names in output                                                           |\n| `--no-task-ids`       |         | Do not include task IDs in output                                                           |\n| `--no-trunc`          |         | Do not truncate output                                                                      |\n| `--raw`               |         | Do not neatly format logs                                                                   |\n| `--since`             |         | Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) |\n| `--tail` , `-n`       | `all`   | Number of lines to show from the end of the logs                                            |\n| `--timestamps` , `-t` |         | Show timestamps                                                                             |\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](index)                         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_logs/](https://docs.docker.com/engine/reference/commandline/service_logs/)"
- name: docker service ls
  id: engine/reference/commandline/service_ls/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service ls\n\n  \n\nList services\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThis command lists services are running in the swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print services using a Go template  |\n| `--quiet` , `-q`  |         | Only display IDs                           |\n\n## Examples\n\nOn a manager node:\n\n``` \n$ docker service ls\n\nID            NAME      MODE            REPLICAS             IMAGE\nc8wgl7q4ndfd  frontend  replicated      5/5                  nginx:alpine\ndmu1ept4cxcf  redis     replicated      3/3                  redis:3.0.6\niwe3278osahj  mongo     global          7/7                  mongo:3.3\nhh08h9uu8uwr  job       replicated-job  1/1 (3/5 completed)  nginx:latest\n```\n\nThe `REPLICAS` column shows both the *actual* and *desired* number of tasks for the service. If the service is in `replicated-job` or `global-job`, it will additionally show the completion status of the job as completed tasks over total tasks the job will execute.\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- [id](index#id)\n- [label](index#label)\n- [mode](index#mode)\n- [name](index#name)\n\n#### id\n\nThe `id` filter matches all or part of a service’s id.\n\n``` \n$ docker service ls -f \"id=0bcjw\"\nID            NAME   MODE        REPLICAS  IMAGE\n0bcjwfh8ychr  redis  replicated  1/1       redis:3.0.6\n```\n\n#### label\n\nThe `label` filter matches services based on the presence of a `label` alone or a `label` and a value.\n\nThe following filter matches all services with a `project` label regardless of its value:\n\n``` \n$ docker service ls --filter label=project\nID            NAME       MODE        REPLICAS  IMAGE\n01sl1rp6nj5u  frontend2  replicated  1/1       nginx:alpine\n36xvvwwauej0  frontend   replicated  5/5       nginx:alpine\n74nzcxxjv6fq  backend    replicated  3/3       redis:3.0.6\n```\n\nThe following filter matches only services with the `project` label with the `project-a` value.\n\n``` \n$ docker service ls --filter label=project=project-a\nID            NAME      MODE        REPLICAS  IMAGE\n36xvvwwauej0  frontend  replicated  5/5       nginx:alpine\n74nzcxxjv6fq  backend   replicated  3/3       redis:3.0.6\n```\n\n#### mode\n\nThe `mode` filter matches on the mode (either `replicated` or `global`) of a service.\n\nThe following filter matches only `global` services.\n\n``` \n$ docker service ls --filter mode=global\nID                  NAME                MODE                REPLICAS            IMAGE\nw7y0v2yrn620        top                 global              1/1                 busybox\n```\n\n#### name\n\nThe `name` filter matches on all or part of a service’s name.\n\nThe following filter matches services with a name containing `redis`.\n\n``` \n$ docker service ls --filter name=redis\nID            NAME   MODE        REPLICAS  IMAGE\n0bcjwfh8ychr  redis  replicated  1/1       redis:3.0.6\n```\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints services output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder | Description                             |\n|-------------|-----------------------------------------|\n| `.ID`       | Service ID                              |\n| `.Name`     | Service name                            |\n| `.Mode`     | Service mode (replicated, global)       |\n| `.Replicas` | Service replicas                        |\n| `.Image`    | Service image                           |\n| `.Ports`    | Service ports published in ingress mode |\n\nWhen using the `--format` option, the `service ls` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `ID`, `Mode`, and `Replicas` entries separated by a colon (`:`) for all services:\n\n``` \n$ docker service ls --format \"{{.ID}}: {{.Mode}} {{.Replicas}}\"\n\n0zmvwuiu3vue: replicated 10/10\nfm6uf97exkul: global 5/5\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](index)                           | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_ls/](https://docs.docker.com/engine/reference/commandline/service_ls/)"
- name: docker service ps
  id: engine/reference/commandline/service_ps/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service ps\n\n  \n\nList the tasks of one or more services\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service ps [OPTIONS] SERVICE [SERVICE...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists the tasks that are running as part of the specified services.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                |\n|-------------------|---------|--------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided |\n| `--format`        |         | Pretty-print tasks using a Go template     |\n| `--no-resolve`    |         | Do not map IDs to Names                    |\n| `--no-trunc`      |         | Do not truncate output                     |\n| `--quiet` , `-q`  |         | Only display task IDs                      |\n\n## Examples\n\n### List the tasks that are part of a service\n\nThe following command shows all the tasks that are part of the `redis` service:\n\n``` \n$ docker service ps redis\n\nID             NAME      IMAGE        NODE      DESIRED STATE  CURRENT STATE          ERROR  PORTS\n0qihejybwf1x   redis.1   redis:3.0.5  manager1  Running        Running 8 seconds\nbk658fpbex0d   redis.2   redis:3.0.5  worker2   Running        Running 9 seconds\n5ls5s5fldaqg   redis.3   redis:3.0.5  worker1   Running        Running 9 seconds\n8ryt076polmc   redis.4   redis:3.0.5  worker1   Running        Running 9 seconds\n1x0v8yomsncd   redis.5   redis:3.0.5  manager1  Running        Running 8 seconds\n71v7je3el7rr   redis.6   redis:3.0.5  worker2   Running        Running 9 seconds\n4l3zm9b7tfr7   redis.7   redis:3.0.5  worker2   Running        Running 9 seconds\n9tfpyixiy2i7   redis.8   redis:3.0.5  worker1   Running        Running 9 seconds\n3w1wu13yupln   redis.9   redis:3.0.5  manager1  Running        Running 8 seconds\n8eaxrb2fqpbn   redis.10  redis:3.0.5  manager1  Running        Running 8 seconds\n```\n\nIn addition to *running* tasks, the output also shows the task history. For example, after updating the service to use the `redis:3.0.6` image, the output may look like this:\n\n``` \n$ docker service ps redis\n\nID            NAME         IMAGE        NODE      DESIRED STATE  CURRENT STATE                   ERROR  PORTS\n50qe8lfnxaxk  redis.1      redis:3.0.6  manager1  Running        Running 6 seconds ago\nky2re9oz86r9   \\_ redis.1  redis:3.0.5  manager1  Shutdown       Shutdown 8 seconds ago\n3s46te2nzl4i  redis.2      redis:3.0.6  worker2   Running        Running less than a second ago\nnvjljf7rmor4   \\_ redis.2  redis:3.0.6  worker2   Shutdown       Rejected 23 seconds ago        \"No such image: redis@sha256:6…\"\nvtiuz2fpc0yb   \\_ redis.2  redis:3.0.5  worker2   Shutdown       Shutdown 1 second ago\njnarweeha8x4  redis.3      redis:3.0.6  worker1   Running        Running 3 seconds ago\nvs448yca2nz4   \\_ redis.3  redis:3.0.5  worker1   Shutdown       Shutdown 4 seconds ago\njf1i992619ir  redis.4      redis:3.0.6  worker1   Running        Running 10 seconds ago\nblkttv7zs8ee   \\_ redis.4  redis:3.0.5  worker1   Shutdown       Shutdown 11 seconds ago\n```\n\nThe number of items in the task history is determined by the `--task-history-limit` option that was set when initializing the swarm. You can change the task history retention limit using the [`docker swarm update`](../swarm_update/index) command.\n\nWhen deploying a service, docker resolves the digest for the service’s image, and pins the service to that digest. The digest is not shown by default, but is printed if `--no-trunc` is used. The `--no-trunc` option also shows the non-truncated task ID, and error-messages, as can be seen below;\n\n``` \n$ docker service ps --no-trunc redis\n\nID                          NAME         IMAGE                                                                                NODE      DESIRED STATE  CURRENT STATE            ERROR                                                                                           PORTS\n50qe8lfnxaxksi9w2a704wkp7   redis.1      redis:3.0.6@sha256:6a692a76c2081888b589e26e6ec835743119fe453d67ecf03df7de5b73d69842  manager1  Running        Running 5 minutes ago\nky2re9oz86r9556i2szb8a8af   \\_ redis.1   redis:3.0.5@sha256:f8829e00d95672c48c60f468329d6693c4bdd28d1f057e755f8ba8b40008682e  worker2   Shutdown       Shutdown 5 minutes ago\nbk658fpbex0d57cqcwoe3jthu   redis.2      redis:3.0.6@sha256:6a692a76c2081888b589e26e6ec835743119fe453d67ecf03df7de5b73d69842  worker2   Running        Running 5 seconds\nnvjljf7rmor4htv7l8rwcx7i7   \\_ redis.2   redis:3.0.6@sha256:6a692a76c2081888b589e26e6ec835743119fe453d67ecf03df7de5b73d69842  worker2   Shutdown       Rejected 5 minutes ago   \"No such image: redis@sha256:6a692a76c2081888b589e26e6ec835743119fe453d67ecf03df7de5b73d69842\"\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g. `--filter \"foo=bar\" --filter \"bif=baz\"`). Multiple filter flags are combined as an `OR` filter. For example, `-f name=redis.1 -f name=redis.7` returns both `redis.1` and `redis.7` tasks.\n\nThe currently supported filters are:\n\n- [id](#id)\n- [name](#name)\n- [node](#node)\n- [desired-state](#desired-state)\n\n#### id\n\nThe `id` filter matches on all or a prefix of a task’s ID.\n\n``` \n$ docker service ps -f \"id=8\" redis\n\nID             NAME      IMAGE        NODE      DESIRED STATE  CURRENT STATE      ERROR  PORTS\n8ryt076polmc   redis.4   redis:3.0.6  worker1   Running        Running 9 seconds\n8eaxrb2fqpbn   redis.10  redis:3.0.6  manager1  Running        Running 8 seconds\n```\n\n#### name\n\nThe `name` filter matches on task names.\n\n``` \n$ docker service ps -f \"name=redis.1\" redis\n\nID            NAME     IMAGE        NODE      DESIRED STATE  CURRENT STATE      ERROR  PORTS\nqihejybwf1x5  redis.1  redis:3.0.6  manager1  Running        Running 8 seconds\n```\n\n#### node\n\nThe `node` filter matches on a node name or a node ID.\n\n``` \n$ docker service ps -f \"node=manager1\" redis\n\nID            NAME      IMAGE        NODE      DESIRED STATE  CURRENT STATE      ERROR  PORTS\n0qihejybwf1x  redis.1   redis:3.0.6  manager1  Running        Running 8 seconds\n1x0v8yomsncd  redis.5   redis:3.0.6  manager1  Running        Running 8 seconds\n3w1wu13yupln  redis.9   redis:3.0.6  manager1  Running        Running 8 seconds\n8eaxrb2fqpbn  redis.10  redis:3.0.6  manager1  Running        Running 8 seconds\n```\n\n#### desired-state\n\nThe `desired-state` filter can take the values `running`, `shutdown`, or `accepted`.\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints tasks output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder     | Description                                                      |\n|-----------------|------------------------------------------------------------------|\n| `.ID`           | Task ID                                                          |\n| `.Name`         | Task name                                                        |\n| `.Image`        | Task image                                                       |\n| `.Node`         | Node ID                                                          |\n| `.DesiredState` | Desired state of the task (`running`, `shutdown`, or `accepted`) |\n| `.CurrentState` | Current state of the task                                        |\n| `.Error`        | Error                                                            |\n| `.Ports`        | Task published ports                                             |\n\nWhen using the `--format` option, the `service ps` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `Name` and `Image` entries separated by a colon (`:`) for all tasks:\n\n``` \n$ docker service ps --format \"{{.Name}}: {{.Image}}\" top\n\ntop.1: busybox\ntop.2: busybox\ntop.3: busybox\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](index)                           | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_ps/](https://docs.docker.com/engine/reference/commandline/service_ps/)"
- name: docker service rm
  id: engine/reference/commandline/service_rm/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service rm\n\n  \n\nRemove one or more services\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service rm SERVICE [SERVICE...]\n```\n\n## Description\n\nRemoves the specified services from the swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\nRemove the `redis` service:\n\n``` \n$ docker service rm redis\n\nredis\n\n$ docker service ls\n\nID  NAME  MODE  REPLICAS  IMAGE\n```\n\n> **Warning**\n>\n> Unlike `docker rm`, this command does not ask for confirmation before removing a running service.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](index)                           | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_rm/](https://docs.docker.com/engine/reference/commandline/service_rm/)"
- name: docker service rollback
  id: engine/reference/commandline/service_rollback/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service rollback\n\n  \n\nRevert changes to a service’s configuration\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service rollback [OPTIONS] SERVICE\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRoll back a specified service to its previous version from the swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                                     |\n|-------------------|---------|-----------------------------------------------------------------|\n| `--detach` , `-d` |         | Exit immediately instead of waiting for the service to converge |\n| `--quiet` , `-q`  |         | Suppress progress output                                        |\n\n## Examples\n\n### Roll back to the previous version of a service\n\nUse the `docker service rollback` command to roll back to the previous version of a service. After executing this command, the service is reverted to the configuration that was in place before the most recent `docker service update` command.\n\nThe following example creates a service with a single replica, updates the service to use three replicas, and then rolls back the service to the previous version, having one replica.\n\nCreate a service with a single replica:\n\n``` \n$ docker service create --name my-service -p 8080:80 nginx:alpine\n```\n\nConfirm that the service is running with a single replica:\n\n``` \n$ docker service ls\n\nID                  NAME                MODE                REPLICAS            IMAGE               PORTS\nxbw728mf6q0d        my-service          replicated          1/1                 nginx:alpine        *:8080->80/tcp\n```\n\nUpdate the service to use three replicas:\n\n``` \n$ docker service update --replicas=3 my-service\n\n$ docker service ls\n\nID                  NAME                MODE                REPLICAS            IMAGE               PORTS\nxbw728mf6q0d        my-service          replicated          3/3                 nginx:alpine        *:8080->80/tcp\n```\n\nNow roll back the service to its previous version, and confirm it is running a single replica again:\n\n``` \n$ docker service rollback my-service\n\n$ docker service ls\n\nID                  NAME                MODE                REPLICAS            IMAGE               PORTS\nxbw728mf6q0d        my-service          replicated          1/1                 nginx:alpine        *:8080->80/tcp\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                            | Description                                          |\n|----------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)   | Create a new service                                 |\n| [docker service inspect](../service_inspect/index) | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)       | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)           | List services                                        |\n| [docker service ps](../service_ps/index)           | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)           | Remove one or more services                          |\n| [docker service rollback](index)                   | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)     | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)   | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_rollback/](https://docs.docker.com/engine/reference/commandline/service_rollback/)"
- name: docker service scale
  id: engine/reference/commandline/service_scale/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service scale\n\n  \n\nScale one or multiple replicated services\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service scale SERVICE=REPLICAS [SERVICE=REPLICAS...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe scale command enables you to scale one or more replicated services either up or down to the desired number of replicas. This command cannot be applied on services which are global mode. The command will return immediately, but the actual scaling of the service may take some time. To stop all replicas of a service while keeping the service active in the swarm you can set the scale to 0.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                                     |\n|-------------------|---------|-----------------------------------------------------------------|\n| `--detach` , `-d` |         | Exit immediately instead of waiting for the service to converge |\n\n## Examples\n\n### Scale a single service\n\nThe following command scales the “frontend” service to 50 tasks.\n\n``` \n$ docker service scale frontend=50\n\nfrontend scaled to 50\n```\n\nThe following command tries to scale a global service to 10 tasks and returns an error.\n\n``` \n$ docker service create --mode global --name backend backend:latest\n\nb4g08uwuairexjub6ome6usqh\n\n$ docker service scale backend=10\n\nbackend: scale can only be used with replicated or replicated-job mode\n```\n\nDirectly afterwards, run `docker service ls`, to see the actual number of replicas.\n\n``` \n$ docker service ls --filter name=frontend\n\nID            NAME      MODE        REPLICAS  IMAGE\n3pr5mlvu3fh9  frontend  replicated  15/50     nginx:alpine\n```\n\nYou can also scale a service using the [`docker service update`](../service_update/index) command. The following commands are equivalent:\n\n``` \n$ docker service scale frontend=50\n$ docker service update --replicas=50 frontend\n```\n\n### Scale multiple services\n\nThe `docker service scale` command allows you to set the desired number of tasks for multiple services at once. The following example scales both the backend and frontend services:\n\n``` \n$ docker service scale backend=3 frontend=5\n\nbackend scaled to 3\nfrontend scaled to 5\n\n$ docker service ls\n\nID            NAME      MODE        REPLICAS  IMAGE\n3pr5mlvu3fh9  frontend  replicated  5/5       nginx:alpine\n74nzcxxjv6fq  backend   replicated  3/3       redis:3.0.6\n```\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](index)                        | Scale one or multiple replicated services            |\n| [docker service update](../service_update/index)     | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_scale/](https://docs.docker.com/engine/reference/commandline/service_scale/)"
- name: docker service update
  id: engine/reference/commandline/service_update/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker service update\n\n  \n\nUpdate a service\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker service update [OPTIONS] SERVICE\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUpdates a service as described by the specified parameters. The parameters are the same as [`docker service create`](../service_create/index). Refer to the description there for further information.\n\nNormally, updating a service will only cause the service’s tasks to be replaced with new ones if a change to the service requires recreating the tasks for it to take effect. For example, only changing the `--update-parallelism` setting will not recreate the tasks, because the individual tasks are not affected by this setting. However, the `--force` flag will cause the tasks to be recreated anyway. This can be used to perform a rolling restart without any changes to the service parameters.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand                | Default | Description                                                                                                                  |\n|--------------------------------|---------|------------------------------------------------------------------------------------------------------------------------------|\n| `--args`                       |         | Service command args                                                                                                         |\n| `--cap-add`                    |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Add Linux capabilities                                                |\n| `--cap-drop`                   |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Drop Linux capabilities                                               |\n| `--config-add`                 |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Add or update a config file on a service                              |\n| `--config-rm`                  |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Remove a configuration file                                           |\n| `--constraint-add`             |         | Add or update a placement constraint                                                                                         |\n| `--constraint-rm`              |         | Remove a constraint                                                                                                          |\n| `--container-label-add`        |         | Add or update a container label                                                                                              |\n| `--container-label-rm`         |         | Remove a container label by its key                                                                                          |\n| `--credential-spec`            |         | Credential spec for managed service account (Windows only)                                                                   |\n| `--detach` , `-d`              |         | Exit immediately instead of waiting for the service to converge                                                              |\n| `--dns-add`                    |         | Add or update a custom DNS server                                                                                            |\n| `--dns-option-add`             |         | Add or update a DNS option                                                                                                   |\n| `--dns-option-rm`              |         | Remove a DNS option                                                                                                          |\n| `--dns-rm`                     |         | Remove a custom DNS server                                                                                                   |\n| `--dns-search-add`             |         | Add or update a custom DNS search domain                                                                                     |\n| `--dns-search-rm`              |         | Remove a DNS search domain                                                                                                   |\n| `--endpoint-mode`              |         | Endpoint mode (vip or dnsrr)                                                                                                 |\n| `--entrypoint`                 |         | Overwrite the default ENTRYPOINT of the image                                                                                |\n| `--env-add`                    |         | Add or update an environment variable                                                                                        |\n| `--env-rm`                     |         | Remove an environment variable                                                                                               |\n| `--force`                      |         | Force update even if no changes require it                                                                                   |\n| `--generic-resource-add`       |         | Add a Generic resource                                                                                                       |\n| `--generic-resource-rm`        |         | Remove a Generic resource                                                                                                    |\n| `--group-add`                  |         | Add an additional supplementary user group to the container                                                                  |\n| `--group-rm`                   |         | Remove a previously added supplementary user group from the container                                                        |\n| `--health-cmd`                 |         | Command to run to check health                                                                                               |\n| `--health-interval`            |         | Time between running the check (ms\\|s\\|m\\|h)                                                                                 |\n| `--health-retries`             |         | Consecutive failures needed to report unhealthy                                                                              |\n| `--health-start-period`        |         | Start period for the container to initialize before counting retries towards unstable (ms\\|s\\|m\\|h)                          |\n| `--health-timeout`             |         | Maximum time to allow one check to run (ms\\|s\\|m\\|h)                                                                         |\n| `--host-add`                   |         | Add a custom host-to-IP mapping (host:ip)                                                                                    |\n| `--host-rm`                    |         | Remove a custom host-to-IP mapping (host:ip)                                                                                 |\n| `--hostname`                   |         | Container hostname                                                                                                           |\n| `--image`                      |         | Service image tag                                                                                                            |\n| `--init`                       |         | Use an init inside each service container to forward signals and reap processes                                              |\n| `--isolation`                  |         | Service container isolation mode                                                                                             |\n| `--label-add`                  |         | Add or update a service label                                                                                                |\n| `--label-rm`                   |         | Remove a label by its key                                                                                                    |\n| `--limit-cpu`                  |         | Limit CPUs                                                                                                                   |\n| `--limit-memory`               |         | Limit Memory                                                                                                                 |\n| `--limit-pids`                 |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/)Swarm Limit maximum number of processes (default 0 = unlimited)        |\n| `--log-driver`                 |         | Logging driver for service                                                                                                   |\n| `--log-opt`                    |         | Logging driver options                                                                                                       |\n| `--max-concurrent`             |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Number of job tasks to run concurrently (default equal to --replicas) |\n| `--mount-add`                  |         | Add or update a mount on a service                                                                                           |\n| `--mount-rm`                   |         | Remove a mount by its target path                                                                                            |\n| `--network-add`                |         | Add a network                                                                                                                |\n| `--network-rm`                 |         | Remove a network                                                                                                             |\n| `--no-healthcheck`             |         | Disable any container-specified HEALTHCHECK                                                                                  |\n| `--no-resolve-image`           |         | Do not query the registry to resolve image digest and supported platforms                                                    |\n| `--placement-pref-add`         |         | Add a placement preference                                                                                                   |\n| `--placement-pref-rm`          |         | Remove a placement preference                                                                                                |\n| `--publish-add`                |         | Add or update a published port                                                                                               |\n| `--publish-rm`                 |         | Remove a published port by its target port                                                                                   |\n| `--quiet` , `-q`               |         | Suppress progress output                                                                                                     |\n| `--read-only`                  |         | Mount the container's root filesystem as read only                                                                           |\n| `--replicas`                   |         | Number of tasks                                                                                                              |\n| `--replicas-max-per-node`      |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Maximum number of tasks per node (default 0 = unlimited)              |\n| `--reserve-cpu`                |         | Reserve CPUs                                                                                                                 |\n| `--reserve-memory`             |         | Reserve Memory                                                                                                               |\n| `--restart-condition`          |         | Restart when condition is met (\"none\"\\|\"on-failure\"\\|\"any\")                                                                  |\n| `--restart-delay`              |         | Delay between restart attempts (ns\\|us\\|ms\\|s\\|m\\|h)                                                                         |\n| `--restart-max-attempts`       |         | Maximum number of restarts before giving up                                                                                  |\n| `--restart-window`             |         | Window used to evaluate the restart policy (ns\\|us\\|ms\\|s\\|m\\|h)                                                             |\n| `--rollback`                   |         | Rollback to previous specification                                                                                           |\n| `--rollback-delay`             |         | Delay between task rollbacks (ns\\|us\\|ms\\|s\\|m\\|h)                                                                           |\n| `--rollback-failure-action`    |         | Action on rollback failure (\"pause\"\\|\"continue\")                                                                             |\n| `--rollback-max-failure-ratio` |         | Failure rate to tolerate during a rollback                                                                                   |\n| `--rollback-monitor`           |         | Duration after each task rollback to monitor for failure (ns\\|us\\|ms\\|s\\|m\\|h)                                               |\n| `--rollback-order`             |         | Rollback order (\"start-first\"\\|\"stop-first\")                                                                                 |\n| `--rollback-parallelism`       |         | Maximum number of tasks rolled back simultaneously (0 to roll back all at once)                                              |\n| `--secret-add`                 |         | Add or update a secret on a service                                                                                          |\n| `--secret-rm`                  |         | Remove a secret                                                                                                              |\n| `--stop-grace-period`          |         | Time to wait before force killing a container (ns\\|us\\|ms\\|s\\|m\\|h)                                                          |\n| `--stop-signal`                |         | Signal to stop the container                                                                                                 |\n| `--sysctl-add`                 |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Add or update a Sysctl option                                         |\n| `--sysctl-rm`                  |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Remove a Sysctl option                                                |\n| `--tty` , `-t`                 |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Allocate a pseudo-TTY                                                 |\n| `--ulimit-add`                 |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Add or update a ulimit option                                         |\n| `--ulimit-rm`                  |         | [API 1.41+](https://docs.docker.com/engine/api/v1.41/) Remove a ulimit option                                                |\n| `--update-delay`               |         | Delay between updates (ns\\|us\\|ms\\|s\\|m\\|h)                                                                                  |\n| `--update-failure-action`      |         | Action on update failure (\"pause\"\\|\"continue\"\\|\"rollback\")                                                                   |\n| `--update-max-failure-ratio`   |         | Failure rate to tolerate during an update                                                                                    |\n| `--update-monitor`             |         | Duration after each task update to monitor for failure (ns\\|us\\|ms\\|s\\|m\\|h)                                                 |\n| `--update-order`               |         | Update order (\"start-first\"\\|\"stop-first\")                                                                                   |\n| `--update-parallelism`         |         | Maximum number of tasks updated simultaneously (0 to update all at once)                                                     |\n| `--user` , `-u`                |         | Username or UID (format: \\<name\\|uid\\>\\[:\\<group\\|gid\\>\\])                                                                   |\n| `--with-registry-auth`         |         | Send registry authentication details to swarm agents                                                                         |\n| `--workdir` , `-w`             |         | Working directory inside the container                                                                                       |\n\n## Examples\n\n### Update a service\n\n``` \n$ docker service update --limit-cpu 2 redis\n```\n\n### Perform a rolling restart with no parameter changes\n\n``` \n$ docker service update --force --update-parallelism 1 --update-delay 30s redis\n```\n\nIn this example, the `--force` flag causes the service’s tasks to be shut down and replaced with new ones even though none of the other parameters would normally cause that to happen. The `--update-parallelism 1` setting ensures that only one task is replaced at a time (this is the default behavior). The `--update-delay 30s` setting introduces a 30 second delay between tasks, so that the rolling restart happens gradually.\n\n### Add or remove mounts\n\nUse the `--mount-add` or `--mount-rm` options add or remove a service’s bind mounts or volumes.\n\nThe following example creates a service which mounts the `test-data` volume to `/somewhere`. The next step updates the service to also mount the `other-volume` volume to `/somewhere-else`volume, The last step unmounts the `/somewhere` mount point, effectively removing the `test-data` volume. Each command returns the service name.\n\n- The `--mount-add` flag takes the same parameters as the `--mount` flag on `service create`. Refer to the [volumes and bind mounts](../service_create/index#add-bind-mounts-volumes-or-memory-filesystems) section in the `service create` reference for details.\n\n- The `--mount-rm` flag takes the `target` path of the mount.\n\n``` \n$ docker service create \\\n    --name=myservice \\\n    --mount type=volume,source=test-data,target=/somewhere \\\n    nginx:alpine\n\nmyservice\n\n$ docker service update \\\n    --mount-add type=volume,source=other-volume,target=/somewhere-else \\\n    myservice\n\nmyservice\n\n$ docker service update --mount-rm /somewhere myservice\n\nmyservice\n```\n\n### Add or remove published service ports\n\nUse the `--publish-add` or `--publish-rm` flags to add or remove a published port for a service. You can use the short or long syntax discussed in the [docker service create](../service_create/index#publish-service-ports-externally-to-the-swarm--p---publish) reference.\n\nThe following example adds a published service port to an existing service.\n\n``` \n$ docker service update \\\n  --publish-add published=8080,target=80 \\\n  myservice\n```\n\n### Add or remove network\n\nUse the `--network-add` or `--network-rm` flags to add or remove a network for a service. You can use the short or long syntax discussed in the [docker service create](../service_create/index#attach-a-service-to-an-existing-network---network) reference.\n\nThe following example adds a new alias name to an existing service already connected to network my-network:\n\n``` \n$ docker service update \\\n  --network-rm my-network \\\n  --network-add name=my-network,alias=web1 \\\n  myservice\n```\n\n### Roll back to the previous version of a service\n\nUse the `--rollback` option to roll back to the previous version of the service.\n\nThis will revert the service to the configuration that was in place before the most recent `docker service update` command.\n\nThe following example updates the number of replicas for the service from 4 to 5, and then rolls back to the previous configuration.\n\n``` \n$ docker service update --replicas=5 web\n\nweb\n\n$ docker service ls\n\nID            NAME  MODE        REPLICAS  IMAGE\n80bvrzp6vxf3  web   replicated  0/5       nginx:alpine\n```\n\nRoll back the `web` service...\n\n``` \n$ docker service update --rollback web\n\nweb\n\n$ docker service ls\n\nID            NAME  MODE        REPLICAS  IMAGE\n80bvrzp6vxf3  web   replicated  0/4       nginx:alpine\n```\n\nOther options can be combined with `--rollback` as well, for example, `--update-delay 0s` to execute the rollback without a delay between tasks:\n\n``` \n$ docker service update \\\n  --rollback \\\n  --update-delay 0s\n  web\n\nweb\n```\n\nServices can also be set up to roll back to the previous version automatically when an update fails. To set up a service for automatic rollback, use `--update-failure-action=rollback`. A rollback will be triggered if the fraction of the tasks which failed to update successfully exceeds the value given with `--update-max-failure-ratio`.\n\nThe rate, parallelism, and other parameters of a rollback operation are determined by the values passed with the following flags:\n\n- `--rollback-delay`\n- `--rollback-failure-action`\n- `--rollback-max-failure-ratio`\n- `--rollback-monitor`\n- `--rollback-parallelism`\n\nFor example, a service set up with `--update-parallelism 1 --rollback-parallelism 3` will update one task at a time during a normal update, but during a rollback, 3 tasks at a time will get rolled back. These rollback parameters are respected both during automatic rollbacks and for rollbacks initiated manually using `--rollback`.\n\n### Add or remove secrets\n\nUse the `--secret-add` or `--secret-rm` options add or remove a service’s secrets.\n\nThe following example adds a secret named `ssh-2` and removes `ssh-1`:\n\n``` \n$ docker service update \\\n    --secret-add source=ssh-2,target=ssh-2 \\\n    --secret-rm ssh-1 \\\n    myservice\n```\n\n### Update services using templates\n\nSome flags of `service update` support the use of templating. See [`service create`](../service_create/index#create-services-using-templates) for the reference.\n\n### Specify isolation mode (Windows)\n\n`service update` supports the same `--isolation` flag as `service create` See [`service create`](../service_create/index) for the reference.\n\n### Updating Jobs\n\nWhen a service is created as a job, by setting its mode to `replicated-job` or to `global-job` when doing `service create`, options for updating it are limited.\n\nUpdating a Job immediately stops any Tasks that are in progress. The operation creates a new set of Tasks for the job and effectively resets its completion status. If any Tasks were running before the update, they are stopped, and new Tasks are created.\n\nJobs cannot be rolled out or rolled back. None of the flags for configuring update or rollback settings are valid with job modes.\n\nTo run a job again with the same parameters that it was run previously, it can be force updated with the `--force` flag.\n\n## Parent command\n\n| Command                            | Description     |\n|:-----------------------------------|:----------------|\n| [docker service](../service/index) | Manage services |\n\n## Related commands\n\n| Command                                              | Description                                          |\n|------------------------------------------------------|------------------------------------------------------|\n| [docker service create](../service_create/index)     | Create a new service                                 |\n| [docker service inspect](../service_inspect/index)   | Display detailed information on one or more services |\n| [docker service logs](../service_logs/index)         | Fetch the logs of a service or task                  |\n| [docker service ls](../service_ls/index)             | List services                                        |\n| [docker service ps](../service_ps/index)             | List the tasks of one or more services               |\n| [docker service rm](../service_rm/index)             | Remove one or more services                          |\n| [docker service rollback](../service_rollback/index) | Revert changes to a service’s configuration          |\n| [docker service scale](../service_scale/index)       | Scale one or multiple replicated services            |\n| [docker service update](index)                       | Update a service                                     |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/service_update/](https://docs.docker.com/engine/reference/commandline/service_update/)"
- name: docker stack
  id: engine/reference/commandline/stack/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stack\n\n  \n\nManage Docker stacks\n\n## Usage\n\n``` \n$ docker stack [OPTIONS] COMMAND\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nManage stacks.\n\n## Options\n\n| Name, shorthand  | Default | Description                                                                          |\n|------------------|---------|--------------------------------------------------------------------------------------|\n| `--kubeconfig`   |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file             |\n| `--orchestrator` |         | [deprecated](../../../deprecated/index) Orchestrator to use (swarm\\|kubernetes\\|all) |\n\n## Child commands\n\n| Command                                          | Description                                    |\n|--------------------------------------------------|------------------------------------------------|\n| [docker stack deploy](../stack_deploy/index)     | Deploy a new stack or update an existing stack |\n| [docker stack ls](../stack_ls/index)             | List stacks                                    |\n| [docker stack ps](../stack_ps/index)             | List the tasks in the stack                    |\n| [docker stack rm](../stack_rm/index)             | Remove one or more stacks                      |\n| [docker stack services](../stack_services/index) | List the services in the stack                 |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stack/](https://docs.docker.com/engine/reference/commandline/stack/)"
- name: docker stack deploy
  id: engine/reference/commandline/stack_deploy/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stack deploy\n\n  \n\nDeploy a new stack or update an existing stack\n\n## Usage\n\n``` \n$ docker stack deploy [OPTIONS] STACK\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreate and update a stack from a `compose` file on the swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand         | Default  | Description                                                                                             |\n|-------------------------|----------|---------------------------------------------------------------------------------------------------------|\n| `--compose-file` , `-c` |          | Path to a Compose file, or \"-\" to read from stdin                                                       |\n| `--namespace`           |          | [deprecated](../../../deprecated/index)Kubernetes Kubernetes namespace to use                           |\n| `--prune`               |          | Swarm Prune services that are no longer referenced                                                      |\n| `--resolve-image`       | `always` | Swarm Query the registry to resolve image digest and supported platforms (\"always\"\\|\"changed\"\\|\"never\") |\n| `--with-registry-auth`  |          | Swarm Send registry authentication details to Swarm agents                                              |\n| `--kubeconfig`          |          | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file                                |\n| `--orchestrator`        |          | [deprecated](../../../deprecated/index) Orchestrator to use (swarm\\|kubernetes\\|all)                    |\n\n## Examples\n\n### Compose file\n\nThe `deploy` command supports compose file version `3.0` and above.\n\n``` \n$ docker stack deploy --compose-file docker-compose.yml vossibility\n\nIgnoring unsupported options: links\n\nCreating network vossibility_vossibility\nCreating network vossibility_default\nCreating service vossibility_nsqd\nCreating service vossibility_logstash\nCreating service vossibility_elasticsearch\nCreating service vossibility_kibana\nCreating service vossibility_ghollector\nCreating service vossibility_lookupd\n```\n\nThe Compose file can also be provided as standard input with `--compose-file -`:\n\n``` \n$ cat docker-compose.yml | docker stack deploy --compose-file - vossibility\n\nIgnoring unsupported options: links\n\nCreating network vossibility_vossibility\nCreating network vossibility_default\nCreating service vossibility_nsqd\nCreating service vossibility_logstash\nCreating service vossibility_elasticsearch\nCreating service vossibility_kibana\nCreating service vossibility_ghollector\nCreating service vossibility_lookupd\n```\n\nIf your configuration is split between multiple Compose files, e.g. a base configuration and environment-specific overrides, you can provide multiple `--compose-file` flags.\n\n``` \n$ docker stack deploy --compose-file docker-compose.yml -c docker-compose.prod.yml vossibility\n\nIgnoring unsupported options: links\n\nCreating network vossibility_vossibility\nCreating network vossibility_default\nCreating service vossibility_nsqd\nCreating service vossibility_logstash\nCreating service vossibility_elasticsearch\nCreating service vossibility_kibana\nCreating service vossibility_ghollector\nCreating service vossibility_lookupd\n```\n\nYou can verify that the services were correctly created:\n\n``` \n$ docker service ls\n\nID            NAME                               MODE        REPLICAS  IMAGE\n29bv0vnlm903  vossibility_lookupd                replicated  1/1       nsqio/nsq@sha256:eeba05599f31eba418e96e71e0984c3dc96963ceb66924dd37a47bf7ce18a662\n4awt47624qwh  vossibility_nsqd                   replicated  1/1       nsqio/nsq@sha256:eeba05599f31eba418e96e71e0984c3dc96963ceb66924dd37a47bf7ce18a662\n4tjx9biia6fs  vossibility_elasticsearch          replicated  1/1       elasticsearch@sha256:12ac7c6af55d001f71800b83ba91a04f716e58d82e748fa6e5a7359eed2301aa\n7563uuzr9eys  vossibility_kibana                 replicated  1/1       kibana@sha256:6995a2d25709a62694a937b8a529ff36da92ebee74bafd7bf00e6caf6db2eb03\n9gc5m4met4he  vossibility_logstash               replicated  1/1       logstash@sha256:2dc8bddd1bb4a5a34e8ebaf73749f6413c101b2edef6617f2f7713926d2141fe\naxqh55ipl40h  vossibility_vossibility-collector  replicated  1/1       icecrime/vossibility-collector@sha256:f03f2977203ba6253988c18d04061c5ec7aab46bca9dfd89a9a1fa4500989fba\n```\n\n## Parent command\n\n| Command                        | Description          |\n|:-------------------------------|:---------------------|\n| [docker stack](../stack/index) | Manage Docker stacks |\n\n## Related commands\n\n| Command                                          | Description                                    |\n|--------------------------------------------------|------------------------------------------------|\n| [docker stack deploy](index)                     | Deploy a new stack or update an existing stack |\n| [docker stack ls](../stack_ls/index)             | List stacks                                    |\n| [docker stack ps](../stack_ps/index)             | List the tasks in the stack                    |\n| [docker stack rm](../stack_rm/index)             | Remove one or more stacks                      |\n| [docker stack services](../stack_services/index) | List the services in the stack                 |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stack_deploy/](https://docs.docker.com/engine/reference/commandline/stack_deploy/)"
- name: docker stack ls
  id: engine/reference/commandline/stack_ls/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stack ls\n\n  \n\nList stacks\n\n## Usage\n\n``` \n$ docker stack ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists the stacks.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand    | Default | Description                                                                                  |\n|--------------------|---------|----------------------------------------------------------------------------------------------|\n| `--all-namespaces` |         | [deprecated](../../../deprecated/index)Kubernetes List stacks from all Kubernetes namespaces |\n| `--format`         |         | Pretty-print stacks using a Go template                                                      |\n| `--namespace`      |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes namespaces to use               |\n| `--kubeconfig`     |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file                     |\n| `--orchestrator`   |         | [deprecated](../../../deprecated/index) Orchestrator to use (swarm\\|kubernetes\\|all)         |\n\n## Examples\n\nThe following command shows all stacks and some additional information:\n\n``` \n$ docker stack ls\n\nID                 SERVICES            ORCHESTRATOR\nmyapp              2                   Kubernetes\nvossibility-stack  6                   Swarm\n```\n\n### Formatting\n\nThe formatting option (`--format`) pretty-prints stacks using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder     | Description        |\n|-----------------|--------------------|\n| `.Name`         | Stack name         |\n| `.Services`     | Number of services |\n| `.Orchestrator` | Orchestrator name  |\n| `.Namespace`    | Namespace          |\n\nWhen using the `--format` option, the `stack ls` command either outputs the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `Name` and `Services` entries separated by a colon (`:`) for all stacks:\n\n``` \n$ docker stack ls --format \"{{.Name}}: {{.Services}}\"\nweb-server: 1\nweb-cache: 4\n```\n\n## Parent command\n\n| Command                        | Description          |\n|:-------------------------------|:---------------------|\n| [docker stack](../stack/index) | Manage Docker stacks |\n\n## Related commands\n\n| Command                                          | Description                                    |\n|--------------------------------------------------|------------------------------------------------|\n| [docker stack deploy](../stack_deploy/index)     | Deploy a new stack or update an existing stack |\n| [docker stack ls](index)                         | List stacks                                    |\n| [docker stack ps](../stack_ps/index)             | List the tasks in the stack                    |\n| [docker stack rm](../stack_rm/index)             | Remove one or more stacks                      |\n| [docker stack services](../stack_services/index) | List the services in the stack                 |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stack_ls/](https://docs.docker.com/engine/reference/commandline/stack_ls/)"
- name: docker stack ps
  id: engine/reference/commandline/stack_ps/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stack ps\n\n  \n\nList the tasks in the stack\n\n## Usage\n\n``` \n$ docker stack ps [OPTIONS] STACK\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists the tasks that are running as part of the specified stack.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                                                          |\n|-------------------|---------|--------------------------------------------------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided                                           |\n| `--format`        |         | Pretty-print tasks using a Go template                                               |\n| `--namespace`     |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes namespace to use        |\n| `--no-resolve`    |         | Do not map IDs to Names                                                              |\n| `--no-trunc`      |         | Do not truncate output                                                               |\n| `--quiet` , `-q`  |         | Only display task IDs                                                                |\n| `--kubeconfig`    |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file             |\n| `--orchestrator`  |         | [deprecated](../../../deprecated/index) Orchestrator to use (swarm\\|kubernetes\\|all) |\n\n## Examples\n\n### List the tasks that are part of a stack\n\nThe following command shows all the tasks that are part of the `voting` stack:\n\n``` \n$ docker stack ps voting\n\nID                  NAME                  IMAGE                                          NODE   DESIRED STATE  CURRENT STATE          ERROR  PORTS\nxim5bcqtgk1b        voting_worker.1       dockersamples/examplevotingapp_worker:latest   node2  Running        Running 2 minutes ago\nq7yik0ks1in6        voting_result.1       dockersamples/examplevotingapp_result:before   node1  Running        Running 2 minutes ago\nrx5yo0866nfx        voting_vote.1         dockersamples/examplevotingapp_vote:before     node3  Running        Running 2 minutes ago\ntz6j82jnwrx7        voting_db.1           postgres:9.4                                   node1  Running        Running 2 minutes ago\nw48spazhbmxc        voting_redis.1        redis:alpine                                   node2  Running        Running 3 minutes ago\n6jj1m02freg1        voting_visualizer.1   dockersamples/visualizer:stable                node1  Running        Running 2 minutes ago\nkqgdmededccb        voting_vote.2         dockersamples/examplevotingapp_vote:before     node2  Running        Running 2 minutes ago\nt72q3z038jeh        voting_redis.2        redis:alpine                                   node3  Running        Running 3 minutes ago\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g. `--filter \"foo=bar\" --filter \"bif=baz\"`). Multiple filter flags are combined as an `OR` filter. For example, `-f name=redis.1 -f name=redis.7` returns both `redis.1` and `redis.7` tasks.\n\nThe currently supported filters are:\n\n- [id](#id)\n- [name](#name)\n- [node](#node)\n- [desired-state](#desired-state)\n\n#### id\n\nThe `id` filter matches on all or a prefix of a task’s ID.\n\n``` \n$ docker stack ps -f \"id=t\" voting\n\nID                  NAME                IMAGE               NODE         DESIRED STATE       CURRENTSTATE            ERROR  PORTS\ntz6j82jnwrx7        voting_db.1         postgres:9.4        node1        Running             Running 14 minutes ago\nt72q3z038jeh        voting_redis.2      redis:alpine        node3        Running             Running 14 minutes ago\n```\n\n#### name\n\nThe `name` filter matches on task names.\n\n``` \n$ docker stack ps -f \"name=voting_redis\" voting\n\nID                  NAME                IMAGE               NODE         DESIRED STATE       CURRENTSTATE            ERROR  PORTS\nw48spazhbmxc        voting_redis.1      redis:alpine        node2        Running             Running 17 minutes ago\nt72q3z038jeh        voting_redis.2      redis:alpine        node3        Running             Running 17 minutes ago\n```\n\n#### node\n\nThe `node` filter matches on a node name or a node ID.\n\n``` \n$ docker stack ps -f \"node=node1\" voting\n\nID                  NAME                  IMAGE                                          NODE   DESIRED STATE  CURRENT STATE          ERROR  PORTS\nq7yik0ks1in6        voting_result.1       dockersamples/examplevotingapp_result:before   node1  Running        Running 18 minutes ago\ntz6j82jnwrx7        voting_db.1           postgres:9.4                                   node1  Running        Running 18 minutes ago\n6jj1m02freg1        voting_visualizer.1   dockersamples/visualizer:stable                node1  Running        Running 18 minutes ago\n```\n\n#### desired-state\n\nThe `desired-state` filter can take the values `running`, `shutdown`, `ready` or `accepted`.\n\n``` \n$ docker stack ps -f \"desired-state=running\" voting\n\nID                  NAME                  IMAGE                                          NODE   DESIRED STATE  CURRENT STATE           ERROR  PORTS\nxim5bcqtgk1b        voting_worker.1       dockersamples/examplevotingapp_worker:latest   node2  Running        Running 21 minutes ago\nq7yik0ks1in6        voting_result.1       dockersamples/examplevotingapp_result:before   node1  Running        Running 21 minutes ago\nrx5yo0866nfx        voting_vote.1         dockersamples/examplevotingapp_vote:before     node3  Running        Running 21 minutes ago\ntz6j82jnwrx7        voting_db.1           postgres:9.4                                   node1  Running        Running 21 minutes ago\nw48spazhbmxc        voting_redis.1        redis:alpine                                   node2  Running        Running 21 minutes ago\n6jj1m02freg1        voting_visualizer.1   dockersamples/visualizer:stable                node1  Running        Running 21 minutes ago\nkqgdmededccb        voting_vote.2         dockersamples/examplevotingapp_vote:before     node2  Running        Running 21 minutes ago\nt72q3z038jeh        voting_redis.2        redis:alpine                                   node3  Running        Running 21 minutes ago\n```\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints tasks output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder     | Description                                                      |\n|-----------------|------------------------------------------------------------------|\n| `.ID`           | Task ID                                                          |\n| `.Name`         | Task name                                                        |\n| `.Image`        | Task image                                                       |\n| `.Node`         | Node ID                                                          |\n| `.DesiredState` | Desired state of the task (`running`, `shutdown`, or `accepted`) |\n| `.CurrentState` | Current state of the task                                        |\n| `.Error`        | Error                                                            |\n| `.Ports`        | Task published ports                                             |\n\nWhen using the `--format` option, the `stack ps` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `Name` and `Image` entries separated by a colon (`:`) for all tasks:\n\n``` \n$ docker stack ps --format \"{{.Name}}: {{.Image}}\" voting\n\nvoting_worker.1: dockersamples/examplevotingapp_worker:latest\nvoting_result.1: dockersamples/examplevotingapp_result:before\nvoting_vote.1: dockersamples/examplevotingapp_vote:before\nvoting_db.1: postgres:9.4\nvoting_redis.1: redis:alpine\nvoting_visualizer.1: dockersamples/visualizer:stable\nvoting_vote.2: dockersamples/examplevotingapp_vote:before\nvoting_redis.2: redis:alpine\n```\n\n### Do not map IDs to Names\n\nThe `--no-resolve` option shows IDs for task name, without mapping IDs to Names.\n\n``` \n$ docker stack ps --no-resolve voting\n\nID                  NAME                          IMAGE                                          NODE                        DESIRED STATE  CURRENT STATE            ERROR  PORTS\nxim5bcqtgk1b        10z9fjfqzsxnezo4hb81p8mqg.1   dockersamples/examplevotingapp_worker:latest   qaqt4nrzo775jrx6detglho01   Running        Running 30 minutes ago\nq7yik0ks1in6        hbxltua1na7mgqjnidldv5m65.1   dockersamples/examplevotingapp_result:before   mxpaef1tlh23s052erw88a4w5   Running        Running 30 minutes ago\nrx5yo0866nfx        qyprtqw1g5nrki557i974ou1d.1   dockersamples/examplevotingapp_vote:before     kanqcxfajd1r16wlnqcblobmm   Running        Running 31 minutes ago\ntz6j82jnwrx7        122f0xxngg17z52be7xspa72x.1   postgres:9.4                                   mxpaef1tlh23s052erw88a4w5   Running        Running 31 minutes ago\nw48spazhbmxc        tg61x8myx563ueo3urmn1ic6m.1   redis:alpine                                   qaqt4nrzo775jrx6detglho01   Running        Running 31 minutes ago\n6jj1m02freg1        8cqlyi444kzd3panjb7edh26v.1   dockersamples/visualizer:stable                mxpaef1tlh23s052erw88a4w5   Running        Running 31 minutes ago\nkqgdmededccb        qyprtqw1g5nrki557i974ou1d.2   dockersamples/examplevotingapp_vote:before     qaqt4nrzo775jrx6detglho01   Running        Running 31 minutes ago\nt72q3z038jeh        tg61x8myx563ueo3urmn1ic6m.2   redis:alpine                                   kanqcxfajd1r16wlnqcblobmm   Running        Running 31 minutes ago\n```\n\n### Do not truncate output\n\nWhen deploying a service, docker resolves the digest for the service’s image, and pins the service to that digest. The digest is not shown by default, but is printed if `--no-trunc` is used. The `--no-trunc` option also shows the non-truncated task IDs, and error-messages, as can be seen below:\n\n``` \n$ docker stack ps --no-trunc voting\n\nID                          NAME                  IMAGE                                                                                                                 NODE   DESIRED STATE  CURREN STATE           ERROR  PORTS\nxim5bcqtgk1bxqz91jzo4a1s5   voting_worker.1       dockersamples/examplevotingapp_worker:latest@sha256:3e4ddf59c15f432280a2c0679c4fc5a2ee5a797023c8ef0d3baf7b1385e9fed   node2  Running        Runnin 32 minutes ago\nq7yik0ks1in6kv32gg6y6yjf7   voting_result.1       dockersamples/examplevotingapp_result:before@sha256:83b56996e930c292a6ae5187fda84dd6568a19d97cdb933720be15c757b7463   node1  Running        Runnin 32 minutes ago\nrx5yo0866nfxc58zf4irsss6n   voting_vote.1         dockersamples/examplevotingapp_vote:before@sha256:8e64b182c87de902f2b72321c89b4af4e2b942d76d0b772532ff27ec4c6ebf6     node3  Running        Runnin 32 minutes ago\ntz6j82jnwrx7n2offljp3mn03   voting_db.1           postgres:9.4@sha256:6046af499eae34d2074c0b53f9a8b404716d415e4a03e68bc1d2f8064f2b027                                   node1  Running        Runnin 32 minutes ago\nw48spazhbmxcmbjfi54gs7x90   voting_redis.1        redis:alpine@sha256:9cd405cd1ec1410eaab064a1383d0d8854d1ef74a54e1e4a92fb4ec7bdc3ee7                                   node2  Running        Runnin 32 minutes ago\n6jj1m02freg1n3z9n1evrzsbl   voting_visualizer.1   dockersamples/visualizer:stable@sha256:f924ad66c8e94b10baaf7bdb9cd491ef4e982a1d048a56a17e02bf5945401e5                node1  Running        Runnin 32 minutes ago\nkqgdmededccbhz2wuc0e9hx7g   voting_vote.2         dockersamples/examplevotingapp_vote:before@sha256:8e64b182c87de902f2b72321c89b4af4e2b942d76d0b772532ff27ec4c6ebf6     node2  Running        Runnin 32 minutes ago\nt72q3z038jehe1wbh9gdum076   voting_redis.2        redis:alpine@sha256:9cd405cd1ec1410eaab064a1383d0d8854d1ef74a54e1e4a92fb4ec7bdc3ee7                                   node3  Running        Runnin 32 minutes ago\n```\n\n### Only display task IDs\n\nThe `-q` or `--quiet` option only shows IDs of the tasks in the stack. This example outputs all task IDs of the “voting” stack;\n\n``` \n$ docker stack ps -q voting\nxim5bcqtgk1b\nq7yik0ks1in6\nrx5yo0866nfx\ntz6j82jnwrx7\nw48spazhbmxc\n6jj1m02freg1\nkqgdmededccb\nt72q3z038jeh\n```\n\nThis option can be used to perform batch operations. For example, you can use the task IDs as input for other commands, such as `docker inspect`. The following example inspects all tasks of the “voting” stack;\n\n``` \n$ docker inspect $(docker stack ps -q voting)\n\n[\n    {\n        \"ID\": \"xim5bcqtgk1b1gk0krq1\",\n        \"Version\": {\n<...>\n```\n\n## Parent command\n\n| Command                        | Description          |\n|:-------------------------------|:---------------------|\n| [docker stack](../stack/index) | Manage Docker stacks |\n\n## Related commands\n\n| Command                                          | Description                                    |\n|--------------------------------------------------|------------------------------------------------|\n| [docker stack deploy](../stack_deploy/index)     | Deploy a new stack or update an existing stack |\n| [docker stack ls](../stack_ls/index)             | List stacks                                    |\n| [docker stack ps](index)                         | List the tasks in the stack                    |\n| [docker stack rm](../stack_rm/index)             | Remove one or more stacks                      |\n| [docker stack services](../stack_services/index) | List the services in the stack                 |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stack_ps/](https://docs.docker.com/engine/reference/commandline/stack_ps/)"
- name: docker stack rm
  id: engine/reference/commandline/stack_rm/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stack rm\n\n  \n\nRemove one or more stacks\n\n## Usage\n\n``` \n$ docker stack rm [OPTIONS] STACK [STACK...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemove the stack from the swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                                                          |\n|------------------|---------|--------------------------------------------------------------------------------------|\n| `--namespace`    |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes namespace to use        |\n| `--kubeconfig`   |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file             |\n| `--orchestrator` |         | [deprecated](../../../deprecated/index) Orchestrator to use (swarm\\|kubernetes\\|all) |\n\n## Examples\n\n### Remove a stack\n\nThis will remove the stack with the name `myapp`. Services, networks, and secrets associated with the stack will be removed.\n\n``` \n$ docker stack rm myapp\n\nRemoving service myapp_redis\nRemoving service myapp_web\nRemoving service myapp_lb\nRemoving network myapp_default\nRemoving network myapp_frontend\n```\n\n### Remove multiple stacks\n\nThis will remove all the specified stacks, `myapp` and `vossibility`. Services, networks, and secrets associated with all the specified stacks will be removed.\n\n``` \n$ docker stack rm myapp vossibility\n\nRemoving service myapp_redis\nRemoving service myapp_web\nRemoving service myapp_lb\nRemoving network myapp_default\nRemoving network myapp_frontend\nRemoving service vossibility_nsqd\nRemoving service vossibility_logstash\nRemoving service vossibility_elasticsearch\nRemoving service vossibility_kibana\nRemoving service vossibility_ghollector\nRemoving service vossibility_lookupd\nRemoving network vossibility_default\nRemoving network vossibility_vossibility\n```\n\n## Parent command\n\n| Command                        | Description          |\n|:-------------------------------|:---------------------|\n| [docker stack](../stack/index) | Manage Docker stacks |\n\n## Related commands\n\n| Command                                          | Description                                    |\n|--------------------------------------------------|------------------------------------------------|\n| [docker stack deploy](../stack_deploy/index)     | Deploy a new stack or update an existing stack |\n| [docker stack ls](../stack_ls/index)             | List stacks                                    |\n| [docker stack ps](../stack_ps/index)             | List the tasks in the stack                    |\n| [docker stack rm](index)                         | Remove one or more stacks                      |\n| [docker stack services](../stack_services/index) | List the services in the stack                 |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stack_rm/](https://docs.docker.com/engine/reference/commandline/stack_rm/)"
- name: docker stack services
  id: engine/reference/commandline/stack_services/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stack services\n\n  \n\nList the services in the stack\n\n## Usage\n\n``` \n$ docker stack services [OPTIONS] STACK\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nLists the services that are running as part of the specified stack.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                                                          |\n|-------------------|---------|--------------------------------------------------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided                                           |\n| `--format`        |         | Pretty-print services using a Go template                                            |\n| `--namespace`     |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes namespace to use        |\n| `--quiet` , `-q`  |         | Only display IDs                                                                     |\n| `--kubeconfig`    |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file             |\n| `--orchestrator`  |         | [deprecated](../../../deprecated/index) Orchestrator to use (swarm\\|kubernetes\\|all) |\n\n## Examples\n\nThe following command shows all services in the `myapp` stack:\n\n``` \n$ docker stack services myapp\n\nID            NAME            REPLICAS  IMAGE                                                                          COMMAND\n7be5ei6sqeye  myapp_web       1/1       nginx@sha256:23f809e7fd5952e7d5be065b4d3643fbbceccd349d537b62a123ef2201bc886f\ndn7m7nhhfb9y  myapp_db        1/1       mysql@sha256:a9a5b559f8821fe73d58c3606c812d1c044868d42c63817fa5125fd9d8b7b539\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is a `key=value` pair. If there is more than one filter, then pass multiple flags (e.g. `--filter \"foo=bar\" --filter \"bif=baz\"`). Multiple filter flags are combined as an `OR` filter.\n\nThe following command shows both the `web` and `db` services:\n\n``` \n$ docker stack services --filter name=myapp_web --filter name=myapp_db myapp\n\nID            NAME            REPLICAS  IMAGE                                                                          COMMAND\n7be5ei6sqeye  myapp_web       1/1       nginx@sha256:23f809e7fd5952e7d5be065b4d3643fbbceccd349d537b62a123ef2201bc886f\ndn7m7nhhfb9y  myapp_db        1/1       mysql@sha256:a9a5b559f8821fe73d58c3606c812d1c044868d42c63817fa5125fd9d8b7b539\n```\n\nThe currently supported filters are:\n\n- id / ID (`--filter id=7be5ei6sqeye`, or `--filter ID=7be5ei6sqeye`)\n  - Swarm: supported\n  - Kubernetes: not supported\n- label (`--filter label=key=value`)\n  - Swarm: supported\n  - Kubernetes: supported\n- mode (`--filter mode=replicated`, or `--filter mode=global`)\n  - Swarm: not supported\n  - Kubernetes: supported\n- name (`--filter name=myapp_web`)\n  - Swarm: supported\n  - Kubernetes: supported\n- node (`--filter node=mynode`)\n  - Swarm: not supported\n  - Kubernetes: supported\n- service (`--filter service=web`)\n  - Swarm: not supported\n  - Kubernetes: supported\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints services output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder | Description                       |\n|-------------|-----------------------------------|\n| `.ID`       | Service ID                        |\n| `.Name`     | Service name                      |\n| `.Mode`     | Service mode (replicated, global) |\n| `.Replicas` | Service replicas                  |\n| `.Image`    | Service image                     |\n\nWhen using the `--format` option, the `stack services` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `ID`, `Mode`, and `Replicas` entries separated by a colon (`:`) for all services:\n\n``` \n$ docker stack services --format \"{{.ID}}: {{.Mode}} {{.Replicas}}\"\n\n0zmvwuiu3vue: replicated 10/10\nfm6uf97exkul: global 5/5\n```\n\n## Parent command\n\n| Command                        | Description          |\n|:-------------------------------|:---------------------|\n| [docker stack](../stack/index) | Manage Docker stacks |\n\n## Related commands\n\n| Command                                      | Description                                    |\n|----------------------------------------------|------------------------------------------------|\n| [docker stack deploy](../stack_deploy/index) | Deploy a new stack or update an existing stack |\n| [docker stack ls](../stack_ls/index)         | List stacks                                    |\n| [docker stack ps](../stack_ps/index)         | List the tasks in the stack                    |\n| [docker stack rm](../stack_rm/index)         | Remove one or more stacks                      |\n| [docker stack services](index)               | List the services in the stack                 |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stack_services/](https://docs.docker.com/engine/reference/commandline/stack_services/)"
- name: docker start
  id: engine/reference/commandline/start/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker start\n\n  \n\nStart one or more stopped containers\n\n## Usage\n\n``` \n$ docker start [OPTIONS] CONTAINER [CONTAINER...]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand        | Default | Description                                                                                                   |\n|------------------------|---------|---------------------------------------------------------------------------------------------------------------|\n| `--attach` , `-a`      |         | Attach STDOUT/STDERR and forward signals                                                                      |\n| `--checkpoint`         |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Restore from this checkpoint              |\n| `--checkpoint-dir`     |         | [experimental (daemon)](../dockerd/index#daemon-configuration-file) Use a custom checkpoint storage directory |\n| `--detach-keys`        |         | Override the key sequence for detaching a container                                                           |\n| `--interactive` , `-i` |         | Attach container's STDIN                                                                                      |\n\n## Examples\n\n``` \n$ docker start my_container\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/start/](https://docs.docker.com/engine/reference/commandline/start/)"
- name: docker stats
  id: engine/reference/commandline/stats/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stats\n\n  \n\nDisplay a live stream of container(s) resource usage statistics\n\n## Usage\n\n``` \n$ docker stats [OPTIONS] [CONTAINER...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker stats` command returns a live data stream for running containers. To limit data to one or more specific containers, specify a list of container names or ids separated by a space. You can specify a stopped container but stopped containers do not return any data.\n\nIf you need more detailed information about a container’s resource usage, use the `/containers/(id)/stats` API endpoint.\n\n> **Note**\n>\n> On Linux, the Docker CLI reports memory usage by subtracting cache usage from the total memory usage. The API does not perform such a calculation but rather provides the total memory usage and the amount from the cache so that clients can use the data as needed. The cache usage is defined as the value of `total_inactive_file` field in the `memory.stat` file on cgroup v1 hosts.\n>\n> On Docker 19.03 and older, the cache usage was defined as the value of `cache` field. On cgroup v2 hosts, the cache usage is defined as the value of `inactive_file` field.\n\n> **Note**\n>\n> The `PIDS` column contains the number of processes and kernel threads created by that container. Threads is the term used by Linux kernel. Other equivalent terms are “lightweight process” or “kernel task”, etc. A large number in the `PIDS` column combined with a small number of processes (as reported by `ps` or `top`) may indicate that something in the container is creating many threads.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                                            |\n|-----------------|---------|--------------------------------------------------------|\n| `--all` , `-a`  |         | Show all containers (default shows just running)       |\n| `--format`      |         | Pretty-print images using a Go template                |\n| `--no-stream`   |         | Disable streaming stats and only pull the first result |\n| `--no-trunc`    |         | Do not truncate output                                 |\n\n## Examples\n\nRunning `docker stats` on all running containers against a Linux daemon.\n\n``` \n$ docker stats\n\nCONTAINER ID        NAME                                    CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS\nb95a83497c91        awesome_brattain                        0.28%               5.629MiB / 1.952GiB   0.28%               916B / 0B           147kB / 0B          9\n67b2525d8ad1        foobar                                  0.00%               1.727MiB / 1.952GiB   0.09%               2.48kB / 0B         4.11MB / 0B         2\ne5c383697914        test-1951.1.kay7x1lh1twk9c0oig50sd5tr   0.00%               196KiB / 1.952GiB     0.01%               71.2kB / 0B         770kB / 0B          1\n4bda148efbc0        random.1.vnc8on831idyr42slu578u3cr      0.00%               1.672MiB / 1.952GiB   0.08%               110kB / 0B          578kB / 0B          2\n```\n\nIf you don’t [specify a format string using `--format`](#formatting), the following columns are shown.\n\n| Column name               | Description                                                                                  |\n|---------------------------|----------------------------------------------------------------------------------------------|\n| `CONTAINER ID` and `Name` | the ID and name of the container                                                             |\n| `CPU %` and `MEM %`       | the percentage of the host’s CPU and memory the container is using                           |\n| `MEM USAGE / LIMIT`       | the total memory the container is using, and the total amount of memory it is allowed to use |\n| `NET I/O`                 | The amount of data the container has sent and received over its network interface            |\n| `BLOCK I/O`               | The amount of data the container has read to and written from block devices on the host      |\n| `PIDs`                    | the number of processes or threads the container has created                                 |\n\nRunning `docker stats` on multiple containers by name and id against a Linux daemon.\n\n``` \n$ docker stats awesome_brattain 67b2525d8ad1\n\nCONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS\nb95a83497c91        awesome_brattain    0.28%               5.629MiB / 1.952GiB   0.28%               916B / 0B           147kB / 0B          9\n67b2525d8ad1        foobar              0.00%               1.727MiB / 1.952GiB   0.09%               2.48kB / 0B         4.11MB / 0B         2\n```\n\nRunning `docker stats` on container with name nginx and getting output in `json` format.\n\n``` \n$ docker stats nginx --no-stream --format \"{{ json . }}\"\n{\"BlockIO\":\"0B / 13.3kB\",\"CPUPerc\":\"0.03%\",\"Container\":\"nginx\",\"ID\":\"ed37317fbf42\",\"MemPerc\":\"0.24%\",\"MemUsage\":\"2.352MiB / 982.5MiB\",\"Name\":\"nginx\",\"NetIO\":\"539kB / 606kB\",\"PIDs\":\"2\"}\n```\n\nRunning `docker stats` with customized format on all (Running and Stopped) containers.\n\n``` \n$ docker stats --all --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\" fervent_panini 5acfcb1b4fd1 drunk_visvesvaraya big_heisenberg\n\nCONTAINER                CPU %               MEM USAGE / LIMIT\nfervent_panini           0.00%               56KiB / 15.57GiB\n5acfcb1b4fd1             0.07%               32.86MiB / 15.57GiB\ndrunk_visvesvaraya       0.00%               0B / 0B\nbig_heisenberg           0.00%               0B / 0B\n```\n\n`drunk_visvesvaraya` and `big_heisenberg` are stopped containers in the above example.\n\nRunning `docker stats` on all running containers against a Windows daemon.\n\n``` \nPS E:\\> docker stats\nCONTAINER ID        CPU %               PRIV WORKING SET    NET I/O             BLOCK I/O\n09d3bb5b1604        6.61%               38.21 MiB           17.1 kB / 7.73 kB   10.7 MB / 3.57 MB\n9db7aa4d986d        9.19%               38.26 MiB           15.2 kB / 7.65 kB   10.6 MB / 3.3 MB\n3f214c61ad1d        0.00%               28.64 MiB           64 kB / 6.84 kB     4.42 MB / 6.93 MB\n```\n\nRunning `docker stats` on multiple containers by name and id against a Windows daemon.\n\n``` \nPS E:\\> docker ps -a\nCONTAINER ID        NAME                IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n3f214c61ad1d        awesome_brattain    nanoserver          \"cmd\"               2 minutes ago       Up 2 minutes                            big_minsky\n9db7aa4d986d        mad_wilson          windowsservercore   \"cmd\"               2 minutes ago       Up 2 minutes                            mad_wilson\n09d3bb5b1604        fervent_panini      windowsservercore   \"cmd\"               2 minutes ago       Up 2 minutes                            affectionate_easley\n\nPS E:\\> docker stats 3f214c61ad1d mad_wilson\nCONTAINER ID        NAME                CPU %               PRIV WORKING SET    NET I/O             BLOCK I/O\n3f214c61ad1d        awesome_brattain    0.00%               46.25 MiB           76.3 kB / 7.92 kB   10.3 MB / 14.7 MB\n9db7aa4d986d        mad_wilson          9.59%               40.09 MiB           27.6 kB / 8.81 kB   17 MB / 20.1 MB\n```\n\n### Formatting\n\nThe formatting option (`--format`) pretty prints container output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder  | Description                                  |\n|--------------|----------------------------------------------|\n| `.Container` | Container name or ID (user input)            |\n| `.Name`      | Container name                               |\n| `.ID`        | Container ID                                 |\n| `.CPUPerc`   | CPU percentage                               |\n| `.MemUsage`  | Memory usage                                 |\n| `.NetIO`     | Network IO                                   |\n| `.BlockIO`   | Block IO                                     |\n| `.MemPerc`   | Memory percentage (Not available on Windows) |\n| `.PIDs`      | Number of PIDs (Not available on Windows)    |\n\nWhen using the `--format` option, the `stats` command either outputs the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `Container` and `CPUPerc` entries separated by a colon (`:`) for all images:\n\n``` \n$ docker stats --format \"{{.Container}}: {{.CPUPerc}}\"\n\n09d3bb5b1604: 6.61%\n9db7aa4d986d: 9.19%\n3f214c61ad1d: 0.00%\n```\n\nTo list all containers statistics with their name, CPU percentage and memory usage in a table format you can use:\n\n``` \n$ docker stats --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\"\n\nCONTAINER           CPU %               PRIV WORKING SET\n1285939c1fd3        0.07%               796 KiB / 64 MiB\n9c76f7834ae2        0.07%               2.746 MiB / 64 MiB\nd1ea048f04e4        0.03%               4.583 MiB / 64 MiB\n```\n\nThe default format is as follows:\n\nOn Linux:\n\n``` \n\"table {{.ID}}\\t{{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.MemPerc}}\\t{{.NetIO}}\\t{{.BlockIO}}\\t{{.PIDs}}\"\n```\n\nOn Windows:\n\n``` \n\"table {{.ID}}\\t{{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.NetIO}}\\t{{.BlockIO}}\"\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stats/](https://docs.docker.com/engine/reference/commandline/stats/)"
- name: docker stop
  id: engine/reference/commandline/stop/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker stop\n\n  \n\nStop one or more running containers\n\n## Usage\n\n``` \n$ docker stop [OPTIONS] CONTAINER [CONTAINER...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe main process inside the container will receive `SIGTERM`, and after a grace period, `SIGKILL`. The first signal can be changed with the `STOPSIGNAL` instruction in the container’s Dockerfile, or the `--stop-signal` option to `docker run`.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                                |\n|-----------------|---------|--------------------------------------------|\n| `--time` , `-t` | `10`    | Seconds to wait for stop before killing it |\n\n## Examples\n\n``` \n$ docker stop my_container\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/stop/](https://docs.docker.com/engine/reference/commandline/stop/)"
- name: docker swarm
  id: engine/reference/commandline/swarm/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm\n\n  \n\nManage Swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm COMMAND\n```\n\n## Description\n\nManage the swarm.\n\n## Child commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm/](https://docs.docker.com/engine/reference/commandline/swarm/)"
- name: docker swarm ca
  id: engine/reference/commandline/swarm_ca/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm ca\n\n  \n\nDisplay and rotate the root CA\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm ca [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nView or rotate the current swarm CA certificate.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default     | Description                                                                             |\n|-------------------|-------------|-----------------------------------------------------------------------------------------|\n| `--ca-cert`       |             | Path to the PEM-formatted root CA certificate to use for the new cluster                |\n| `--ca-key`        |             | Path to the PEM-formatted root CA key to use for the new cluster                        |\n| `--cert-expiry`   | `2160h0m0s` | Validity period for node certificates (ns\\|us\\|ms\\|s\\|m\\|h)                             |\n| `--detach` , `-d` |             | Exit immediately instead of waiting for the root rotation to converge                   |\n| `--external-ca`   |             | Specifications of one or more certificate signing endpoints                             |\n| `--quiet` , `-q`  |             | Suppress progress output                                                                |\n| `--rotate`        |             | Rotate the swarm CA - if no certificate or key are provided, new ones will be generated |\n\n## Examples\n\nRun the `docker swarm ca` command without any options to view the current root CA certificate in PEM format.\n\n``` \n$ docker swarm ca\n\n-----BEGIN CERTIFICATE-----\nMIIBazCCARCgAwIBAgIUJPzo67QC7g8Ebg2ansjkZ8CbmaswCgYIKoZIzj0EAwIw\nEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMTcwNTAzMTcxMDAwWhcNMzcwNDI4MTcx\nMDAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH\nA0IABKL6/C0sihYEb935wVPRA8MqzPLn3jzou0OJRXHsCLcVExigrMdgmLCC+Va4\n+sJ+SLVO1eQbvLHH8uuDdF/QOU6jQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBSfUy5bjUnBAx/B0GkOBKp91XvxzjAKBggqhkjO\nPQQDAgNJADBGAiEAnbvh0puOS5R/qvy1PMHY1iksYKh2acsGLtL/jAIvO4ACIQCi\nlIwQqLkJ48SQqCjG1DBTSBsHmMSRT+6mE2My+Z3GKA==\n-----END CERTIFICATE-----\n```\n\nPass the `--rotate` flag (and optionally a `--ca-cert`, along with a `--ca-key` or `--external-ca` parameter flag), in order to rotate the current swarm root CA.\n\n``` \n$ docker swarm ca --rotate\ndesired root digest: sha256:05da740cf2577a25224c53019e2cce99bcc5ba09664ad6bb2a9425d9ebd1b53e\n  rotated TLS certificates:  [=========================>                         ] 1/2 nodes\n  rotated CA certificates:   [>                                                  ] 0/2 nodes\n```\n\nOnce the rotation os finished (all the progress bars have completed) the now-current CA certificate will be printed:\n\n``` \n$ docker swarm ca --rotate\ndesired root digest: sha256:05da740cf2577a25224c53019e2cce99bcc5ba09664ad6bb2a9425d9ebd1b53e\n  rotated TLS certificates:  [==================================================>] 2/2 nodes\n  rotated CA certificates:   [==================================================>] 2/2 nodes\n-----BEGIN CERTIFICATE-----\nMIIBazCCARCgAwIBAgIUFynG04h5Rrl4lKyA4/E65tYKg8IwCgYIKoZIzj0EAwIw\nEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMTcwNTE2MDAxMDAwWhcNMzcwNTExMDAx\nMDAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH\nA0IABC2DuNrIETP7C7lfiEPk39tWaaU0I2RumUP4fX4+3m+87j0DU0CsemUaaOG6\n+PxHhGu2VXQ4c9pctPHgf7vWeVajQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBSEL02z6mCI3SmMDmITMr12qCRY2jAKBggqhkjO\nPQQDAgNJADBGAiEA263Eb52+825EeNQZM0AME+aoH1319Zp9/J5ijILW+6ACIQCg\ngyg5u9Iliel99l7SuMhNeLkrU7fXs+Of1nTyyM73ig==\n-----END CERTIFICATE-----\n```\n\n### `--rotate`\n\nRoot CA Rotation is recommended if one or more of the swarm managers have been compromised, so that those managers can no longer connect to or be trusted by any other node in the cluster.\n\nAlternately, root CA rotation can be used to give control of the swarm CA to an external CA, or to take control back from an external CA.\n\nThe `--rotate` flag does not require any parameters to do a rotation, but you can optionally specify a certificate and key, or a certificate and external CA URL, and those will be used instead of an automatically-generated certificate/key pair.\n\nBecause the root CA key should be kept secret, if provided it will not be visible when viewing swarm any information via the CLI or API.\n\nThe root CA rotation will not be completed until all registered nodes have rotated their TLS certificates. If the rotation is not completing within a reasonable amount of time, try running `docker node ls --format '{{.ID}} {{.Hostname}} {{.Status}} {{.TLSStatus}}'` to see if any nodes are down or otherwise unable to rotate TLS certificates.\n\n### `--detach`\n\nInitiate the root CA rotation, but do not wait for the completion of or display the progress of the rotation.\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](index)                             | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_ca/](https://docs.docker.com/engine/reference/commandline/swarm_ca/)"
- name: docker swarm init
  id: engine/reference/commandline/swarm_init/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm init\n\n  \n\nInitialize a swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm init [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nInitialize a swarm. The docker engine targeted by this command becomes a manager in the newly created single-node swarm.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand                   | Default        | Description                                                                                                                                                                         |\n|-----------------------------------|----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--advertise-addr`                |                | Advertised address (format: \\<ip\\|interface\\>\\[:port\\])                                                                                                                             |\n| `--autolock`                      |                | Enable manager autolocking (requiring an unlock key to start a stopped manager)                                                                                                     |\n| `--availability`                  | `active`       | Availability of the node (\"active\"\\|\"pause\"\\|\"drain\")                                                                                                                               |\n| `--cert-expiry`                   | `2160h0m0s`    | Validity period for node certificates (ns\\|us\\|ms\\|s\\|m\\|h)                                                                                                                         |\n| `--data-path-addr`                |                | Address or interface to use for data path traffic (format: \\<ip\\|interface\\>)                                                                                                       |\n| `--data-path-port`                |                | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Port number to use for data path traffic (1024 - 49151). If no value is set or is set to 0, the default port (4789) is used. |\n| `--default-addr-pool`             |                | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) default address pool in CIDR format                                                                                          |\n| `--default-addr-pool-mask-length` | `24`           | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) default address pool subnet mask length                                                                                      |\n| `--dispatcher-heartbeat`          | `5s`           | Dispatcher heartbeat period (ns\\|us\\|ms\\|s\\|m\\|h)                                                                                                                                   |\n| `--external-ca`                   |                | Specifications of one or more certificate signing endpoints                                                                                                                         |\n| `--force-new-cluster`             |                | Force create a new cluster from current state                                                                                                                                       |\n| `--listen-addr`                   | `0.0.0.0:2377` | Listen address (format: \\<ip\\|interface\\>\\[:port\\])                                                                                                                                 |\n| `--max-snapshots`                 |                | Number of additional Raft snapshots to retain                                                                                                                                       |\n| `--snapshot-interval`             | `10000`        | Number of log entries between Raft snapshots                                                                                                                                        |\n| `--task-history-limit`            | `5`            | Task history retention limit                                                                                                                                                        |\n\n## Examples\n\n``` \n$ docker swarm init --advertise-addr 192.168.99.121\n\nSwarm initialized: current node (bvz81updecsj6wjz393c09vti) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-1awxwuwd3z9j1z3puu7rcgdbx \\\n    172.17.0.2:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n```\n\n`docker swarm init` generates two random tokens, a worker token and a manager token. When you join a new node to the swarm, the node joins as a worker or manager node based upon the token you pass to [swarm join](../swarm_join/index).\n\nAfter you create the swarm, you can display or rotate the token using [swarm join-token](../swarm_join-token/index).\n\n### `--autolock`\n\nThis flag enables automatic locking of managers with an encryption key. The private keys and data stored by all managers will be protected by the encryption key printed in the output, and will not be accessible without it. Thus, it is very important to store this key in order to activate a manager after it restarts. The key can be passed to `docker swarm unlock` to reactivate the manager. Autolock can be disabled by running `docker swarm update --autolock=false`. After disabling it, the encryption key is no longer required to start the manager, and it will start up on its own without user intervention.\n\n### `--cert-expiry`\n\nThis flag sets the validity period for node certificates.\n\n### `--dispatcher-heartbeat`\n\nThis flag sets the frequency with which nodes are told to use as a period to report their health.\n\n### `--external-ca`\n\nThis flag sets up the swarm to use an external CA to issue node certificates. The value takes the form `protocol=X,url=Y`. The value for `protocol` specifies what protocol should be used to send signing requests to the external CA. Currently, the only supported value is `cfssl`. The URL specifies the endpoint where signing requests should be submitted.\n\n### `--force-new-cluster`\n\nThis flag forces an existing node that was part of a quorum that was lost to restart as a single node Manager without losing its data.\n\n### `--listen-addr`\n\nThe node listens for inbound swarm manager traffic on this address. The default is to listen on 0.0.0.0:2377. It is also possible to specify a network interface to listen on that interface’s address; for example `--listen-addr eth0:2377`.\n\nSpecifying a port is optional. If the value is a bare IP address or interface name, the default port 2377 will be used.\n\n### `--advertise-addr`\n\nThis flag specifies the address that will be advertised to other members of the swarm for API access and overlay networking. If unspecified, Docker will check if the system has a single IP address, and use that IP address with the listening port (see `--listen-addr`). If the system has multiple IP addresses, `--advertise-addr` must be specified so that the correct address is chosen for inter-manager communication and overlay networking.\n\nIt is also possible to specify a network interface to advertise that interface’s address; for example `--advertise-addr eth0:2377`.\n\nSpecifying a port is optional. If the value is a bare IP address or interface name, the default port 2377 will be used.\n\n### `--data-path-addr`\n\nThis flag specifies the address that global scope network drivers will publish towards other nodes in order to reach the containers running on this node. Using this parameter it is then possible to separate the container’s data traffic from the management traffic of the cluster. If unspecified, Docker will use the same IP address or interface that is used for the advertise address.\n\n### `--data-path-port`\n\nThis flag allows you to configure the UDP port number to use for data path traffic. The provided port number must be within the 1024 - 49151 range. If this flag is not set or is set to 0, the default port number 4789 is used. The data path port can only be configured when initializing the swarm, and applies to all nodes that join the swarm. The following example initializes a new Swarm, and configures the data path port to UDP port 7777;\n\n``` \n$ docker swarm init --data-path-port=7777\n```\n\nAfter the swarm is initialized, use the `docker info` command to verify that the port is configured:\n\n``` \n$ docker info\n<...>\nClusterID: 9vs5ygs0gguyyec4iqf2314c0\nManagers: 1\nNodes: 1\nData Path Port: 7777\n<...>\n```\n\n### `--default-addr-pool`\n\nThis flag specifies default subnet pools for global scope networks. Format example is `--default-addr-pool 30.30.0.0/16 --default-addr-pool 40.40.0.0/16`\n\n### `--default-addr-pool-mask-length`\n\nThis flag specifies default subnet pools mask length for default-addr-pool. Format example is `--default-addr-pool-mask-length 24`\n\n### `--task-history-limit`\n\nThis flag sets up task history retention limit.\n\n### `--max-snapshots`\n\nThis flag sets the number of old Raft snapshots to retain in addition to the current Raft snapshots. By default, no old snapshots are retained. This option may be used for debugging, or to store old snapshots of the swarm state for disaster recovery purposes.\n\n### `--snapshot-interval`\n\nThis flag specifies how many log entries to allow in between Raft snapshots. Setting this to a higher number will trigger snapshots less frequently. Snapshots compact the Raft log and allow for more efficient transfer of the state to new managers. However, there is a performance cost to taking snapshots frequently.\n\n### `--availability`\n\nThis flag specifies the availability of the node at the time the node joins a master. Possible availability values are `active`, `pause`, or `drain`.\n\nThis flag is useful in certain situations. For example, a cluster may want to have dedicated manager nodes that are not served as worker nodes. This could be achieved by passing `--availability=drain` to `docker swarm init`.\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](index)                           | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_init/](https://docs.docker.com/engine/reference/commandline/swarm_init/)"
- name: docker swarm join
  id: engine/reference/commandline/swarm_join/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm join\n\n  \n\nJoin a swarm as a node and/or manager\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm join [OPTIONS] HOST:PORT\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nJoin a node to a swarm. The node joins as a manager node or worker node based upon the token you pass with the `--token` flag. If you pass a manager token, the node joins as a manager. If you pass a worker token, the node joins as a worker.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand    | Default        | Description                                                                   |\n|--------------------|----------------|-------------------------------------------------------------------------------|\n| `--advertise-addr` |                | Advertised address (format: \\<ip\\|interface\\>\\[:port\\])                       |\n| `--availability`   | `active`       | Availability of the node (\"active\"\\|\"pause\"\\|\"drain\")                         |\n| `--data-path-addr` |                | Address or interface to use for data path traffic (format: \\<ip\\|interface\\>) |\n| `--listen-addr`    | `0.0.0.0:2377` | Listen address (format: \\<ip\\|interface\\>\\[:port\\])                           |\n| `--token`          |                | Token for entry into the swarm                                                |\n\n## Examples\n\n### Join a node to swarm as a manager\n\nThe example below demonstrates joining a manager node using a manager token.\n\n``` \n$ docker swarm join --token SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-7p73s1dx5in4tatdymyhg9hu2 192.168.99.121:2377\nThis node joined a swarm as a manager.\n\n$ docker node ls\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\ndkp8vy1dq1kxleu9g4u78tlag *  manager2  Ready   Active        Reachable\ndvfxp4zseq4s0rih1selh0d20    manager1  Ready   Active        Leader\n```\n\nA cluster should only have 3-7 managers at most, because a majority of managers must be available for the cluster to function. Nodes that aren’t meant to participate in this management quorum should join as workers instead. Managers should be stable hosts that have static IP addresses.\n\n### Join a node to swarm as a worker\n\nThe example below demonstrates joining a worker node using a worker token.\n\n``` \n$ docker swarm join --token SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-1awxwuwd3z9j1z3puu7rcgdbx 192.168.99.121:2377\nThis node joined a swarm as a worker.\n\n$ docker node ls\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n7ln70fl22uw2dvjn2ft53m3q5    worker2   Ready   Active\ndkp8vy1dq1kxleu9g4u78tlag    worker1   Ready   Active        Reachable\ndvfxp4zseq4s0rih1selh0d20 *  manager1  Ready   Active        Leader\n```\n\n### `--listen-addr value`\n\nIf the node is a manager, it will listen for inbound swarm manager traffic on this address. The default is to listen on 0.0.0.0:2377. It is also possible to specify a network interface to listen on that interface’s address; for example `--listen-addr eth0:2377`.\n\nSpecifying a port is optional. If the value is a bare IP address, or interface name, the default port 2377 will be used.\n\nThis flag is generally not necessary when joining an existing swarm.\n\n### `--advertise-addr value`\n\nThis flag specifies the address that will be advertised to other members of the swarm for API access. If unspecified, Docker will check if the system has a single IP address, and use that IP address with the listening port (see `--listen-addr`). If the system has multiple IP addresses, `--advertise-addr` must be specified so that the correct address is chosen for inter-manager communication and overlay networking.\n\nIt is also possible to specify a network interface to advertise that interface’s address; for example `--advertise-addr eth0:2377`.\n\nSpecifying a port is optional. If the value is a bare IP address, or interface name, the default port 2377 will be used.\n\nThis flag is generally not necessary when joining an existing swarm. If you’re joining new nodes through a load balancer, you should use this flag to ensure the node advertises its IP address and not the IP address of the load balancer.\n\n### `--data-path-addr`\n\nThis flag specifies the address that global scope network drivers will publish towards other nodes in order to reach the containers running on this node. Using this parameter it is then possible to separate the container’s data traffic from the management traffic of the cluster. If unspecified, Docker will use the same IP address or interface that is used for the advertise address.\n\n### `--token string`\n\nSecret value required for nodes to join the swarm\n\n### `--availability`\n\nThis flag specifies the availability of the node at the time the node joins a master. Possible availability values are `active`, `pause`, or `drain`.\n\nThis flag is useful in certain situations. For example, a cluster may want to have dedicated manager nodes that are not served as worker nodes. This could be achieved by passing `--availability=drain` to `docker swarm join`.\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](index)                           | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_join/](https://docs.docker.com/engine/reference/commandline/swarm_join/)"
- name: docker swarm join-token
  id: engine/reference/commandline/swarm_join-token/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm join-token\n\n  \n\nManage join tokens\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm join-token [OPTIONS] (worker|manager)\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nJoin tokens are secrets that allow a node to join the swarm. There are two different join tokens available, one for the worker role and one for the manager role. You pass the token using the `--token` flag when you run [swarm join](../swarm_join/index). Nodes use the join token only when they join the swarm.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description        |\n|------------------|---------|--------------------|\n| `--quiet` , `-q` |         | Only display token |\n| `--rotate`       |         | Rotate join token  |\n\n## Examples\n\nYou can view or rotate the join tokens using `swarm join-token`.\n\nAs a convenience, you can pass `worker` or `manager` as an argument to `join-token` to print the full `docker swarm join` command to join a new node to the swarm:\n\n``` \n$ docker swarm join-token worker\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-1awxwuwd3z9j1z3puu7rcgdbx \\\n    172.17.0.2:2377\n\n$ docker swarm join-token manager\n\nTo add a manager to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-7p73s1dx5in4tatdymyhg9hu2 \\\n    172.17.0.2:2377\n```\n\nUse the `--rotate` flag to generate a new join token for the specified role:\n\n``` \n$ docker swarm join-token --rotate worker\n\nSuccessfully rotated worker join token.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-b30ljddcqhef9b9v4rs7mel7t \\\n    172.17.0.2:2377\n```\n\nAfter using `--rotate`, only the new token will be valid for joining with the specified role.\n\nThe `-q` (or `--quiet`) flag only prints the token:\n\n``` \n$ docker swarm join-token -q worker\n\nSWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-b30ljddcqhef9b9v4rs7mel7t\n```\n\n### `--rotate`\n\nBecause tokens allow new nodes to join the swarm, you should keep them secret. Be particularly careful with manager tokens since they allow new manager nodes to join the swarm. A rogue manager has the potential to disrupt the operation of your swarm.\n\nRotate your swarm’s join token if a token gets checked-in to version control, stolen, or a node is compromised. You may also want to periodically rotate the token to ensure any unknown token leaks do not allow a rogue node to join the swarm.\n\nTo rotate the join token and print the newly generated token, run `docker swarm join-token --rotate` and pass the role: `manager` or `worker`.\n\nRotating a join-token means that no new nodes will be able to join the swarm using the old token. Rotation does not affect existing nodes in the swarm because the join token is only used for authorizing new nodes joining the swarm.\n\n### `--quiet`\n\nOnly print the token. Do not print a complete command for joining.\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](index)                     | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_join-token/](https://docs.docker.com/engine/reference/commandline/swarm_join-token/)"
- name: docker swarm leave
  id: engine/reference/commandline/swarm_leave/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm leave\n\n  \n\nLeave the swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm leave [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nWhen you run this command on a worker, that worker leaves the swarm.\n\nYou can use the `--force` option on a manager to remove it from the swarm. However, this does not reconfigure the swarm to ensure that there are enough managers to maintain a quorum in the swarm. The safe way to remove a manager from a swarm is to demote it to a worker and then direct it to leave the quorum without using `--force`. Only use `--force` in situations where the swarm will no longer be used after the manager leaves, such as in a single-node swarm.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                           |\n|------------------|---------|-------------------------------------------------------|\n| `--force` , `-f` |         | Force this node to leave the swarm, ignoring warnings |\n\n## Examples\n\nConsider the following swarm, as seen from the manager:\n\n``` \n$ docker node ls\n\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n7ln70fl22uw2dvjn2ft53m3q5    worker2   Ready   Active\ndkp8vy1dq1kxleu9g4u78tlag    worker1   Ready   Active\ndvfxp4zseq4s0rih1selh0d20 *  manager1  Ready   Active        Leader\n```\n\nTo remove `worker2`, issue the following command from `worker2` itself:\n\n``` \n$ docker swarm leave\n\nNode left the default swarm.\n```\n\nThe node will still appear in the node list, and marked as `down`. It no longer affects swarm operation, but a long list of `down` nodes can clutter the node list. To remove an inactive node from the list, use the [`node rm`](../node_rm/index) command.\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](index)                          | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_leave/](https://docs.docker.com/engine/reference/commandline/swarm_leave/)"
- name: docker swarm unlock
  id: engine/reference/commandline/swarm_unlock/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm unlock\n\n  \n\nUnlock swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm unlock\n```\n\n## Description\n\nUnlocks a locked manager using a user-supplied unlock key. This command must be used to reactivate a manager after its Docker daemon restarts if the autolock setting is turned on. The unlock key is printed at the time when autolock is enabled, and is also available from the `docker swarm unlock-key` command.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker swarm unlock\nPlease enter unlock key:\n```\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](index)                         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_unlock/](https://docs.docker.com/engine/reference/commandline/swarm_unlock/)"
- name: docker swarm unlock-key
  id: engine/reference/commandline/swarm_unlock-key/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm unlock-key\n\n  \n\nManage the unlock key\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm unlock-key [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nAn unlock key is a secret key needed to unlock a manager after its Docker daemon restarts. These keys are only used when the autolock feature is enabled for the swarm.\n\nYou can view or rotate the unlock key using `swarm unlock-key`. To view the key, run the `docker swarm unlock-key` command without any arguments:\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description        |\n|------------------|---------|--------------------|\n| `--quiet` , `-q` |         | Only display token |\n| `--rotate`       |         | Rotate unlock key  |\n\n## Examples\n\n``` \n$ docker swarm unlock-key\n\nTo unlock a swarm manager after it restarts, run the `docker swarm unlock`\ncommand and provide the following key:\n\n    SWMKEY-1-fySn8TY4w5lKcWcJPIpKufejh9hxx5KYwx6XZigx3Q4\n\nPlease remember to store this key in a password manager, since without it you\nwill not be able to restart the manager.\n```\n\nUse the `--rotate` flag to rotate the unlock key to a new, randomly-generated key:\n\n``` \n$ docker swarm unlock-key --rotate\n\nSuccessfully rotated manager unlock key.\n\nTo unlock a swarm manager after it restarts, run the `docker swarm unlock`\ncommand and provide the following key:\n\n    SWMKEY-1-7c37Cc8654o6p38HnroywCi19pllOnGtbdZEgtKxZu8\n\nPlease remember to store this key in a password manager, since without it you\nwill not be able to restart the manager.\n```\n\nThe `-q` (or `--quiet`) flag only prints the key:\n\n``` \n$ docker swarm unlock-key -q\n\nSWMKEY-1-7c37Cc8654o6p38HnroywCi19pllOnGtbdZEgtKxZu8\n```\n\n### `--rotate`\n\nThis flag rotates the unlock key, replacing it with a new randomly-generated key. The old unlock key will no longer be accepted.\n\n### `--quiet`\n\nOnly print the unlock key, without instructions.\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](index)                     | Manage the unlock key                 |\n| [docker swarm update](../swarm_update/index)         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/](https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/)"
- name: docker swarm update
  id: engine/reference/commandline/swarm_update/index
  summary: Swarm This command works with the Swarm orchestrator
  description: "# docker swarm update\n\n  \n\nUpdate the swarm\n\nSwarm This command works with the Swarm orchestrator.\n\n## Usage\n\n``` \n$ docker swarm update [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUpdates a swarm with new parameter values.\n\n> **Note**\n>\n> This is a cluster management command, and must be executed on a swarm manager node. To learn about managers and workers, refer to the [Swarm mode section](../../../swarm/index) in the documentation.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand          | Default     | Description                                                 |\n|--------------------------|-------------|-------------------------------------------------------------|\n| `--autolock`             |             | Change manager autolocking setting (true\\|false)            |\n| `--cert-expiry`          | `2160h0m0s` | Validity period for node certificates (ns\\|us\\|ms\\|s\\|m\\|h) |\n| `--dispatcher-heartbeat` | `5s`        | Dispatcher heartbeat period (ns\\|us\\|ms\\|s\\|m\\|h)           |\n| `--external-ca`          |             | Specifications of one or more certificate signing endpoints |\n| `--max-snapshots`        |             | Number of additional Raft snapshots to retain               |\n| `--snapshot-interval`    | `10000`     | Number of log entries between Raft snapshots                |\n| `--task-history-limit`   | `5`         | Task history retention limit                                |\n\n## Examples\n\n``` \n$ docker swarm update --cert-expiry 720h\n```\n\n## Parent command\n\n| Command                        | Description  |\n|:-------------------------------|:-------------|\n| [docker swarm](../swarm/index) | Manage Swarm |\n\n## Related commands\n\n| Command                                              | Description                           |\n|------------------------------------------------------|---------------------------------------|\n| [docker swarm ca](../swarm_ca/index)                 | Display and rotate the root CA        |\n| [docker swarm init](../swarm_init/index)             | Initialize a swarm                    |\n| [docker swarm join](../swarm_join/index)             | Join a swarm as a node and/or manager |\n| [docker swarm join-token](../swarm_join-token/index) | Manage join tokens                    |\n| [docker swarm leave](../swarm_leave/index)           | Leave the swarm                       |\n| [docker swarm unlock](../swarm_unlock/index)         | Unlock swarm                          |\n| [docker swarm unlock-key](../swarm_unlock-key/index) | Manage the unlock key                 |\n| [docker swarm update](index)                         | Update the swarm                      |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/swarm_update/](https://docs.docker.com/engine/reference/commandline/swarm_update/)"
- name: docker system
  id: engine/reference/commandline/system/index
  summary: Manage Docker
  description: "# docker system\n\n  \n\nManage Docker\n\n## Usage\n\n``` \n$ docker system COMMAND\n```\n\n## Description\n\nManage Docker.\n\n## Child commands\n\n| Command                                        | Description                          |\n|------------------------------------------------|--------------------------------------|\n| [docker system df](../system_df/index)         | Show docker disk usage               |\n| [docker system events](../system_events/index) | Get real time events from the server |\n| [docker system info](../system_info/index)     | Display system-wide information      |\n| [docker system prune](../system_prune/index)   | Remove unused data                   |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/system/](https://docs.docker.com/engine/reference/commandline/system/)"
- name: docker system df
  id: engine/reference/commandline/system_df/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker system df\n\n  \n\nShow docker disk usage\n\n## Usage\n\n``` \n$ docker system df [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker system df` command displays information regarding the amount of disk space used by the docker daemon.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand    | Default | Description                              |\n|--------------------|---------|------------------------------------------|\n| `--format`         |         | Pretty-print images using a Go template  |\n| `--verbose` , `-v` |         | Show detailed information on space usage |\n\n## Examples\n\nBy default the command will just show a summary of the data used:\n\n``` \n$ docker system df\n\nTYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE\nImages              5                   2                   16.43 MB            11.63 MB (70%)\nContainers          2                   0                   212 B               212 B (100%)\nLocal Volumes       2                   1                   36 B                0 B (0%)\n```\n\nA more detailed view can be requested using the `-v, --verbose` flag:\n\n``` \n$ docker system df -v\n\nImages space usage:\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE                SHARED SIZE         UNIQUE SIZE         CONTAINERS\nmy-curl             latest              b2789dd875bf        6 minutes ago       11 MB               11 MB               5 B                 0\nmy-jq               latest              ae67841be6d0        6 minutes ago       9.623 MB            8.991 MB            632.1 kB            0\n<none>              <none>              a0971c4015c1        6 minutes ago       11 MB               11 MB               0 B                 0\nalpine              latest              4e38e38c8ce0        9 weeks ago         4.799 MB            0 B                 4.799 MB            1\nalpine              3.3                 47cf20d8c26c        9 weeks ago         4.797 MB            4.797 MB            0 B                 1\n\nContainers space usage:\n\nCONTAINER ID        IMAGE               COMMAND             LOCAL VOLUMES       SIZE                CREATED             STATUS                      NAMES\n4a7f7eebae0f        alpine:latest       \"sh\"                1                   0 B                 16 minutes ago      Exited (0) 5 minutes ago    hopeful_yalow\nf98f9c2aa1ea        alpine:3.3          \"sh\"                1                   212 B               16 minutes ago      Exited (0) 48 seconds ago   anon-vol\n\nLocal Volumes space usage:\n\nNAME                                                               LINKS               SIZE\n07c7bdf3e34ab76d921894c2b834f073721fccfbbcba792aa7648e3a7a664c2e   2                   36 B\nmy-named-vol                                                       0                   0 B\n```\n\n- `SHARED SIZE` is the amount of space that an image shares with another one (i.e. their common data)\n- `UNIQUE SIZE` is the amount of space that is only used by a given image\n- `SIZE` is the virtual size of the image, it is the sum of `SHARED SIZE` and `UNIQUE SIZE`\n\n> **Note**\n>\n> Network information is not shown because it does not consume disk space.\n\n## Parent command\n\n| Command                          | Description   |\n|:---------------------------------|:--------------|\n| [docker system](../system/index) | Manage Docker |\n\n## Related commands\n\n| Command                                        | Description                          |\n|------------------------------------------------|--------------------------------------|\n| [docker system df](index)                      | Show docker disk usage               |\n| [docker system events](../system_events/index) | Get real time events from the server |\n| [docker system info](../system_info/index)     | Display system-wide information      |\n| [docker system prune](../system_prune/index)   | Remove unused data                   |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/system_df/](https://docs.docker.com/engine/reference/commandline/system_df/)"
- name: docker system events
  id: engine/reference/commandline/system_events/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker system events\n\n  \n\nGet real time events from the server\n\n## Usage\n\n``` \n$ docker system events [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nUse `docker system events` to get real-time events from the server. These events differ per Docker object type.\n\n### Object types\n\n#### Containers\n\nDocker containers report the following events:\n\n- `attach`\n- `commit`\n- `copy`\n- `create`\n- `destroy`\n- `detach`\n- `die`\n- `exec_create`\n- `exec_detach`\n- `exec_start`\n- `export`\n- `health_status`\n- `kill`\n- `oom`\n- `pause`\n- `rename`\n- `resize`\n- `restart`\n- `start`\n- `stop`\n- `top`\n- `unpause`\n- `update`\n\n#### Images\n\nDocker images report the following events:\n\n- `delete`\n- `import`\n- `load`\n- `pull`\n- `push`\n- `save`\n- `tag`\n- `untag`\n\n#### Plugins\n\nDocker plugins report the following events:\n\n- `install`\n- `enable`\n- `disable`\n- `remove`\n\n#### Volumes\n\nDocker volumes report the following events:\n\n- `create`\n- `mount`\n- `unmount`\n- `destroy`\n\n#### Networks\n\nDocker networks report the following events:\n\n- `create`\n- `connect`\n- `disconnect`\n- `destroy`\n\n#### Daemons\n\nDocker daemons report the following events:\n\n- `reload`\n\n### Limiting, filtering, and formatting the output\n\n#### Limit events by time\n\nThe `--since` and `--until` parameters can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the client machine’s time. If you do not provide the `--since` option, the command returns only new and/or live events. Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the client will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long.\n\n#### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If you would like to use multiple filters, pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nUsing the same filter multiple times will be handled as a *OR*; for example `--filter container=588a23dac085 --filter container=a8f7720b8c22` will display events for container 588a23dac085 *OR* container a8f7720b8c22\n\nUsing multiple filters will be handled as a *AND*; for example `--filter container=588a23dac085 --filter event=start` will display events for container container 588a23dac085 *AND* the event type is *start*\n\nThe currently supported filters are:\n\n- container (`container=<name or id>`)\n- daemon (`daemon=<name or id>`)\n- event (`event=<event action>`)\n- image (`image=<tag or id>`)\n- label (`label=<key>` or `label=<key>=<value>`)\n- network (`network=<name or id>`)\n- plugin (`plugin=<name or id>`)\n- type (`type=<container or image or volume or network or daemon or plugin>`)\n- volume (`volume=<name or id>`)\n\n#### Format\n\nIf a format (`--format`) is specified, the given template will be executed instead of the default format. Go’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nIf a format is set to `{{json .}}`, the events are streamed as valid JSON Lines. For information about JSON Lines, please refer to https://jsonlines.org/ .\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--filter` , `-f` |         | Filter output based on conditions provided    |\n| `--format`        |         | Format the output using the given Go template |\n| `--since`         |         | Show all events created since timestamp       |\n| `--until`         |         | Stream events until this timestamp            |\n\n## Examples\n\n### Basic example\n\nYou’ll need two shells for this example.\n\n**Shell 1: Listening for events:**\n\n``` \n$ docker system events\n```\n\n**Shell 2: Start and Stop containers:**\n\n``` \n$ docker create --name test alpine:latest top\n$ docker start test\n$ docker stop test\n```\n\n**Shell 1: (Again .. now showing events):**\n\n``` \n2017-01-05T00:35:58.859401177+08:00 container create 0fdb48addc82871eb34eb23a847cfd033dedd1a0a37bef2e6d9eb3870fc7ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1f5ceda09d4300f3a846f0acfaa9a8bb0d89e775eb744c5acecd60e0529e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n```\n\nTo exit the `docker system events` command, use `CTRL+C`.\n\n### Filter events by time\n\nYou can filter the output by an absolute timestamp or relative time on the host machine, using the following different time syntaxes:\n\n``` \n$ docker system events --since 1483283804\n\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker system events --since '2017-01-05'\n\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker system events --since '2013-09-03T15:49:29'\n\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker system events --since '10m'\n\n2017-01-05T00:35:41.241772953+08:00 volume create testVol (driver=local)\n2017-01-05T00:35:58.859401177+08:00 container create d9cd...4d70 (image=alpine:latest, name=test)\n2017-01-05T00:36:04.703631903+08:00 network connect e2e1...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:04.795031609+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:36:09.830268747+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:36:09.840186338+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:36:09.880113663+08:00 network disconnect e2e...29e2 (container=0fdb...ff37, name=bridge, type=bridge)\n2017-01-05T00:36:09.890214053+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n```\n\n### Filter events by criteria\n\nThe following commands show several different ways to filter the `docker event` output.\n\n``` \n$ docker system events --filter 'event=stop'\n\n2017-01-05T00:40:22.880175420+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:41:17.888104182+08:00 container stop 2a8f...4e78 (image=alpine, name=kickass_brattain)\n\n$ docker system events --filter 'image=alpine'\n\n2017-01-05T00:41:55.784240236+08:00 container create d9cd...4d70 (image=alpine, name=happy_meitner)\n2017-01-05T00:41:55.913156783+08:00 container start d9cd...4d70 (image=alpine, name=happy_meitner)\n2017-01-05T00:42:01.106875249+08:00 container kill d9cd...4d70 (image=alpine, name=happy_meitner, signal=15)\n2017-01-05T00:42:11.111934041+08:00 container kill d9cd...4d70 (image=alpine, name=happy_meitner, signal=9)\n2017-01-05T00:42:11.119578204+08:00 container die d9cd...4d70 (exitCode=137, image=alpine, name=happy_meitner)\n2017-01-05T00:42:11.173276611+08:00 container stop d9cd...4d70 (image=alpine, name=happy_meitner)\n\n$ docker system events --filter 'container=test'\n\n2017-01-05T00:43:00.139719934+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:43:09.259951086+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=15)\n2017-01-05T00:43:09.270102715+08:00 container die 0fdb...ff37 (exitCode=143, image=alpine:latest, name=test)\n2017-01-05T00:43:09.312556440+08:00 container stop 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker system events --filter 'container=test' --filter 'container=d9cdb1525ea8'\n\n2017-01-05T00:44:11.517071981+08:00 container start 0fdb...ff37 (image=alpine:latest, name=test)\n2017-01-05T00:44:17.685870901+08:00 container start d9cd...4d70 (image=alpine, name=happy_meitner)\n2017-01-05T00:44:29.757658470+08:00 container kill 0fdb...ff37 (image=alpine:latest, name=test, signal=9)\n2017-01-05T00:44:29.767718510+08:00 container die 0fdb...ff37 (exitCode=137, image=alpine:latest, name=test)\n2017-01-05T00:44:29.815798344+08:00 container destroy 0fdb...ff37 (image=alpine:latest, name=test)\n\n$ docker system events --filter 'container=test' --filter 'event=stop'\n\n2017-01-05T00:46:13.664099505+08:00 container stop a9d1...e130 (image=alpine, name=test)\n\n$ docker system events --filter 'type=volume'\n\n2015-12-23T21:05:28.136212689Z volume create test-event-volume-local (driver=local)\n2015-12-23T21:05:28.383462717Z volume mount test-event-volume-local (read/write=true, container=562f...5025, destination=/foo, driver=local, propagation=rprivate)\n2015-12-23T21:05:28.650314265Z volume unmount test-event-volume-local (container=562f...5025, driver=local)\n2015-12-23T21:05:28.716218405Z volume destroy test-event-volume-local (driver=local)\n\n$ docker system events --filter 'type=network'\n\n2015-12-23T21:38:24.705709133Z network create 8b11...2c5b (name=test-event-network-local, type=bridge)\n2015-12-23T21:38:25.119625123Z network connect 8b11...2c5b (name=test-event-network-local, container=b4be...c54e, type=bridge)\n\n$ docker system events --filter 'container=container_1' --filter 'container=container_2'\n\n2014-09-03T15:49:29.999999999Z07:00 container die 4386fb97867d (image=ubuntu-1:14.04)\n2014-05-10T17:42:14.999999999Z07:00 container stop 4386fb97867d (image=ubuntu-1:14.04)\n2014-05-10T17:42:14.999999999Z07:00 container die 7805c1d35632 (imager=redis:2.8)\n2014-09-03T15:49:29.999999999Z07:00 container stop 7805c1d35632 (image=redis:2.8)\n\n$ docker system events --filter 'type=volume'\n\n2015-12-23T21:05:28.136212689Z volume create test-event-volume-local (driver=local)\n2015-12-23T21:05:28.383462717Z volume mount test-event-volume-local (read/write=true, container=562fe10671e9273da25eed36cdce26159085ac7ee6707105fd534866340a5025, destination=/foo, driver=local, propagation=rprivate)\n2015-12-23T21:05:28.650314265Z volume unmount test-event-volume-local (container=562fe10671e9273da25eed36cdce26159085ac7ee6707105fd534866340a5025, driver=local)\n2015-12-23T21:05:28.716218405Z volume destroy test-event-volume-local (driver=local)\n\n$ docker system events --filter 'type=network'\n\n2015-12-23T21:38:24.705709133Z network create 8b111217944ba0ba844a65b13efcd57dc494932ee2527577758f939315ba2c5b (name=test-event-network-local, type=bridge)\n2015-12-23T21:38:25.119625123Z network connect 8b111217944ba0ba844a65b13efcd57dc494932ee2527577758f939315ba2c5b (name=test-event-network-local, container=b4be644031a3d90b400f88ab3d4bdf4dc23adb250e696b6328b85441abe2c54e, type=bridge)\n\n$ docker system events --filter 'type=plugin'\n\n2016-07-25T17:30:14.825557616Z plugin pull ec7b87f2ce84330fe076e666f17dfc049d2d7ae0b8190763de94e1f2d105993f (name=tiborvass/sample-volume-plugin:latest)\n2016-07-25T17:30:14.888127370Z plugin enable ec7b87f2ce84330fe076e666f17dfc049d2d7ae0b8190763de94e1f2d105993f (name=tiborvass/sample-volume-plugin:latest)\n```\n\n### Format the output\n\n``` \n$ docker system events --filter 'type=container' --format 'Type={{.Type}}  Status={{.Status}}  ID={{.ID}}'\n\nType=container  Status=create  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=attach  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=start  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=resize  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=die  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\nType=container  Status=destroy  ID=2ee349dac409e97974ce8d01b70d250b85e0ba8189299c126a87812311951e26\n```\n\n#### Format as JSON\n\n``` \n$ docker system events --format '{{json .}}'\n\n{\"status\":\"create\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f4..\n{\"status\":\"attach\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f4..\n{\"Type\":\"network\",\"Action\":\"connect\",\"Actor\":{\"ID\":\"1b50a5bf755f6021dfa78e..\n{\"status\":\"start\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f42..\n{\"status\":\"resize\",\"id\":\"196016a57679bf42424484918746a9474cd905dd993c4d0f4..\n```\n\n## Parent command\n\n| Command                          | Description   |\n|:---------------------------------|:--------------|\n| [docker system](../system/index) | Manage Docker |\n\n## Related commands\n\n| Command                                      | Description                          |\n|----------------------------------------------|--------------------------------------|\n| [docker system df](../system_df/index)       | Show docker disk usage               |\n| [docker system events](index)                | Get real time events from the server |\n| [docker system info](../system_info/index)   | Display system-wide information      |\n| [docker system prune](../system_prune/index) | Remove unused data                   |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/system_events/](https://docs.docker.com/engine/reference/commandline/system_events/)"
- name: docker system info
  id: engine/reference/commandline/system_info/index
  summary: © 2019 Docker, Inc
  description: "# docker system info\n\n  \n\nDisplay system-wide information\n\n## Usage\n\n``` \n$ docker system info [OPTIONS]\n```\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n\n## Parent command\n\n| Command                          | Description   |\n|:---------------------------------|:--------------|\n| [docker system](../system/index) | Manage Docker |\n\n## Related commands\n\n| Command                                        | Description                          |\n|------------------------------------------------|--------------------------------------|\n| [docker system df](../system_df/index)         | Show docker disk usage               |\n| [docker system events](../system_events/index) | Get real time events from the server |\n| [docker system info](index)                    | Display system-wide information      |\n| [docker system prune](../system_prune/index)   | Remove unused data                   |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/system_info/](https://docs.docker.com/engine/reference/commandline/system_info/)"
- name: docker system prune
  id: engine/reference/commandline/system_prune/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker system prune\n\n  \n\nRemove unused data\n\n## Usage\n\n``` \n$ docker system prune [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemove all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                            |\n|------------------|---------|--------------------------------------------------------|\n| `--all` , `-a`   |         | Remove all unused images not just dangling ones        |\n| `--filter`       |         | Provide filter values (e.g. 'label=\\<key\\>=\\<value\\>') |\n| `--force` , `-f` |         | Do not prompt for confirmation                         |\n| `--volumes`      |         | Prune volumes                                          |\n\n## Examples\n\n``` \n$ docker system prune\n\nWARNING! This will remove:\n        - all stopped containers\n        - all networks not used by at least one container\n        - all dangling images\n        - all build cache\nAre you sure you want to continue? [y/N] y\n\nDeleted Containers:\nf44f9b81948b3919590d5f79a680d8378f1139b41952e219830a33027c80c867\n792776e68ac9d75bce4092bc1b5cc17b779bc926ab04f4185aec9bf1c0d4641f\n\nDeleted Networks:\nnetwork1\nnetwork2\n\nDeleted Images:\nuntagged: hello-world@sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f\ndeleted: sha256:1815c82652c03bfd8644afda26fb184f2ed891d921b20a0703b46768f9755c57\ndeleted: sha256:45761469c965421a92a69cc50e92c01e0cfa94fe026cdd1233445ea00e96289a\n\nTotal reclaimed space: 1.84kB\n```\n\nBy default, volumes are not removed to prevent important data from being deleted if there is currently no container using the volume. Use the `--volumes` flag when running the command to prune volumes as well:\n\n``` \n$ docker system prune -a --volumes\n\nWARNING! This will remove:\n        - all stopped containers\n        - all networks not used by at least one container\n        - all volumes not used by at least one container\n        - all images without at least one container associated to them\n        - all build cache\nAre you sure you want to continue? [y/N] y\n\nDeleted Containers:\n0998aa37185a1a7036b0e12cf1ac1b6442dcfa30a5c9650a42ed5010046f195b\n73958bfb884fa81fa4cc6baf61055667e940ea2357b4036acbbe25a60f442a4d\n\nDeleted Networks:\nmy-network-a\nmy-network-b\n\nDeleted Volumes:\nnamed-vol\n\nDeleted Images:\nuntagged: my-curl:latest\ndeleted: sha256:7d88582121f2a29031d92017754d62a0d1a215c97e8f0106c586546e7404447d\ndeleted: sha256:dd14a93d83593d4024152f85d7c63f76aaa4e73e228377ba1d130ef5149f4d8b\nuntagged: alpine:3.3\ndeleted: sha256:695f3d04125db3266d4ab7bbb3c6b23aa4293923e762aa2562c54f49a28f009f\nuntagged: alpine:latest\ndeleted: sha256:ee4603260daafe1a8c2f3b78fd760922918ab2441cbb2853ed5c439e59c52f96\ndeleted: sha256:9007f5987db353ec398a223bc5a135c5a9601798ba20a1abba537ea2f8ac765f\ndeleted: sha256:71fa90c8f04769c9721459d5aa0936db640b92c8c91c9b589b54abd412d120ab\ndeleted: sha256:bb1c3357b3c30ece26e6604aea7d2ec0ace4166ff34c3616701279c22444c0f3\nuntagged: my-jq:latest\ndeleted: sha256:6e66d724542af9bc4c4abf4a909791d7260b6d0110d8e220708b09e4ee1322e1\ndeleted: sha256:07b3fa89d4b17009eb3988dfc592c7d30ab3ba52d2007832dffcf6d40e3eda7f\ndeleted: sha256:3a88a5c81eb5c283e72db2dbc6d65cbfd8e80b6c89bb6e714cfaaa0eed99c548\n\nTotal reclaimed space: 13.5 MB\n```\n\n### Filtering\n\nThe filtering flag (`--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- until (`<timestamp>`) - only remove containers, images, and networks created before given timestamp\n- label (`label=<key>`, `label=<key>=<value>`, `label!=<key>`, or `label!=<key>=<value>`) - only remove containers, images, networks, and volumes with (or without, in case `label!=...` is used) the specified labels.\n\nThe `until` filter can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the daemon machine’s time. Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, `2006-01-02T15:04:05`, `2006-01-02T15:04:05.999999999`, `2006-01-02Z07:00`, and `2006-01-02`. The local timezone on the daemon will be used if you do not provide either a `Z` or a `+-00:00` timezone offset at the end of the timestamp. When providing Unix timestamps enter seconds\\[.nanoseconds\\], where seconds is the number of seconds that have elapsed since January 1, 1970 (midnight UTC/GMT), not counting leap seconds (aka Unix epoch or Unix time), and the optional .nanoseconds field is a fraction of a second no more than nine digits long.\n\nThe `label` filter accepts two formats. One is the `label=...` (`label=<key>` or `label=<key>=<value>`), which removes containers, images, networks, and volumes with the specified labels. The other format is the `label!=...` (`label!=<key>` or `label!=<key>=<value>`), which removes containers, images, networks, and volumes without the specified labels.\n\n## Parent command\n\n| Command                          | Description   |\n|:---------------------------------|:--------------|\n| [docker system](../system/index) | Manage Docker |\n\n## Related commands\n\n| Command                                        | Description                          |\n|------------------------------------------------|--------------------------------------|\n| [docker system df](../system_df/index)         | Show docker disk usage               |\n| [docker system events](../system_events/index) | Get real time events from the server |\n| [docker system info](../system_info/index)     | Display system-wide information      |\n| [docker system prune](index)                   | Remove unused data                   |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/system_prune/](https://docs.docker.com/engine/reference/commandline/system_prune/)"
- name: docker tag
  id: engine/reference/commandline/tag/index
  summary: An image name is made up of slash-separated name components, optionally prefixed by a registry hostname
  description: "# docker tag\n\n  \n\nCreate a tag TARGET_IMAGE that refers to SOURCE_IMAGE\n\n## Usage\n\n``` \n$ docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]\n```\n\n## Description\n\nAn image name is made up of slash-separated name components, optionally prefixed by a registry hostname. The hostname must comply with standard DNS rules, but may not contain underscores. If a hostname is present, it may optionally be followed by a port number in the format `:8080`. If not present, the command uses Docker’s public registry located at `registry-1.docker.io` by default. Name components may contain lowercase letters, digits and separators. A separator is defined as a period, one or two underscores, or one or more dashes. A name component may not start or end with a separator.\n\nA tag name must be valid ASCII and may contain lowercase and uppercase letters, digits, underscores, periods and dashes. A tag name may not start with a period or a dash and may contain a maximum of 128 characters.\n\nYou can group your images together using names and tags, and then upload them to [*Share images on Docker Hub*](../../../../get-started/04_sharing_app/index).\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n### Tag an image referenced by ID\n\nTo tag a local image with ID “0e5574283393” into the “fedora” repository with “version1.0”:\n\n``` \n$ docker tag 0e5574283393 fedora/httpd:version1.0\n```\n\n### Tag an image referenced by Name\n\nTo tag a local image with name “httpd” into the “fedora” repository with “version1.0”:\n\n``` \n$ docker tag httpd fedora/httpd:version1.0\n```\n\nNote that since the tag name is not specified, the alias is created for an existing local version `httpd:latest`.\n\n### Tag an image referenced by Name and Tag\n\nTo tag a local image with name “httpd” and tag “test” into the “fedora” repository with “version1.0.test”:\n\n``` \n$ docker tag httpd:test fedora/httpd:version1.0.test\n```\n\n### Tag an image for a private repository\n\nTo push an image to a private registry and not the central Docker registry you must tag it with the registry hostname and port (if needed).\n\n``` \n$ docker tag 0e5574283393 myregistryhost:5000/fedora/httpd:version1.0\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/tag/](https://docs.docker.com/engine/reference/commandline/tag/)"
- name: docker top
  id: engine/reference/commandline/top/index
  summary: © 2019 Docker, Inc
  description: "# docker top\n\n  \n\nDisplay the running processes of a container\n\n## Usage\n\n``` \n$ docker top CONTAINER [ps OPTIONS]\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/top/](https://docs.docker.com/engine/reference/commandline/top/)"
- name: docker trust
  id: engine/reference/commandline/trust/index
  summary: © 2019 Docker, Inc
  description: "# docker trust\n\n  \n\nManage trust on Docker images\n\n## Usage\n\n``` \n$ docker trust COMMAND\n```\n\n## Child commands\n\n| Command                                        | Description                                            |\n|------------------------------------------------|--------------------------------------------------------|\n| [docker trust inspect](../trust_inspect/index) | Return low-level information about keys and signatures |\n| [docker trust key](../trust_key/index)         | Manage keys for signing Docker images                  |\n| [docker trust revoke](../trust_revoke/index)   | Remove trust for an image                              |\n| [docker trust sign](../trust_sign/index)       | Sign an image                                          |\n| [docker trust signer](../trust_signer/index)   | Manage entities who can sign Docker images             |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust/](https://docs.docker.com/engine/reference/commandline/trust/)"
- name: docker trust inspect
  id: engine/reference/commandline/trust_inspect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust inspect\n\n  \n\nReturn low-level information about keys and signatures\n\n## Usage\n\n``` \n$ docker trust inspect IMAGE[:TAG] [IMAGE[:TAG]...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust inspect` provides low-level JSON information on signed repositories. This includes all image tags that are signed, who signed them, and who can sign new tags.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                                      |\n|-----------------|---------|--------------------------------------------------|\n| `--pretty`      |         | Print the information in a human friendly format |\n\n## Examples\n\n### Get low-level details about signatures for a single image tag\n\nUse the `docker trust inspect` to get trust information about an image. The following example prints trust information for the `alpine:latest` image:\n\n``` \n$ docker trust inspect alpine:latest\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"Name\": \"alpine:latest\",\n    \"SignedTags\": [\n      {\n        \"SignedTag\": \"latest\",\n        \"Digest\": \"d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      }\n    ],\n    \"Signers\": [],\n    \"AdministrativeKeys\": [\n      {\n        \"Name\": \"Repository\",\n        \"Keys\": [\n            {\n                \"ID\": \"5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\"\n            }\n        ]\n      },\n      {\n        \"Name\": \"Root\",\n        \"Keys\": [\n            {\n                \"ID\": \"a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\"\n            }\n        ]\n      }\n    ]\n  }\n]\n```\n\nThe `SignedTags` key will list the `SignedTag` name, its `Digest`, and the `Signers` responsible for the signature.\n\n`AdministrativeKeys` will list the `Repository` and `Root` keys.\n\nIf signers are set up for the repository via other `docker trust` commands, `docker trust inspect` includes a `Signers` key:\n\n``` \n$ docker trust inspect my-image:purple\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"Name\": \"my-image:purple\",\n    \"SignedTags\": [\n      {\n        \"SignedTag\": \"purple\",\n        \"Digest\": \"941d3dba358621ce3c41ef67b47cf80f701ff80cdf46b5cc86587eaebfe45557\",\n        \"Signers\": [\n          \"alice\",\n          \"bob\",\n          \"carol\"\n        ]\n      }\n    ],\n    \"Signers\": [\n      {\n        \"Name\": \"alice\",\n        \"Keys\": [\n            {\n                \"ID\": \"04dd031411ed671ae1e12f47ddc8646d98f135090b01e54c3561e843084484a3\"\n            },\n            {\n                \"ID\": \"6a11e4898a4014d400332ab0e096308c844584ff70943cdd1d6628d577f45fd8\"\n            }\n        ]\n      },\n      {\n        \"Name\": \"bob\",\n        \"Keys\": [\n            {\n                \"ID\": \"433e245c656ae9733cdcc504bfa560f90950104442c4528c9616daa45824ccba\"\n            }\n        ]\n      },\n      {\n        \"Name\": \"carol\",\n        \"Keys\": [\n            {\n                \"ID\": \"d32fa8b5ca08273a2880f455fcb318da3dc80aeae1a30610815140deef8f30d9\"\n            },\n            {\n                \"ID\": \"9a8bbec6ba2af88a5fad6047d428d17e6d05dbdd03d15b4fc8a9a0e8049cd606\"\n            }\n        ]\n      }\n    ],\n    \"AdministrativeKeys\": [\n      {\n        \"Name\": \"Repository\",\n        \"Keys\": [\n            {\n                \"ID\": \"27df2c8187e7543345c2e0bf3a1262e0bc63a72754e9a7395eac3f747ec23a44\"\n            }\n        ]\n      },\n      {\n        \"Name\": \"Root\",\n        \"Keys\": [\n            {\n                \"ID\": \"40b66ccc8b176be8c7d365a17f3e046d1c3494e053dd57cfeacfe2e19c4f8e8f\"\n            }\n        ]\n      }\n    ]\n  }\n]\n```\n\nIf the image tag is unsigned or unavailable, `docker trust inspect` does not display any signed tags.\n\n``` \n$ docker trust inspect unsigned-img\n\nNo signatures or cannot access unsigned-img\n```\n\nHowever, if other tags are signed in the same image repository, `docker trust inspect` reports relevant key information:\n\n``` \n$ docker trust inspect alpine:unsigned\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"Name\": \"alpine:unsigned\",\n    \"Signers\": [],\n    \"AdministrativeKeys\": [\n      {\n        \"Name\": \"Repository\",\n        \"Keys\": [\n          {\n            \"ID\": \"5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\"\n          }\n        ]\n      },\n      {\n        \"Name\": \"Root\",\n        \"Keys\": [\n          {\n            \"ID\": \"a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\"\n          }\n        ]\n      }\n    ]\n  }\n]\n```\n\n### Get details about signatures for all image tags in a repository\n\nIf no tag is specified, `docker trust inspect` will report details for all signed tags in the repository:\n\n``` \n$ docker trust inspect alpine\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"Name\": \"alpine\",\n    \"SignedTags\": [\n      {\n        \"SignedTag\": \"3.5\",\n        \"Digest\": \"b007a354427e1880de9cdba533e8e57382b7f2853a68a478a17d447b302c219c\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"3.6\",\n        \"Digest\": \"d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"edge\",\n        \"Digest\": \"23e7d843e63a3eee29b6b8cfcd10e23dd1ef28f47251a985606a31040bf8e096\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"latest\",\n        \"Digest\": \"d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      }\n    ],\n    \"Signers\": [],\n    \"AdministrativeKeys\": [\n      {\n        \"Name\": \"Repository\",\n        \"Keys\": [\n          {\n            \"ID\": \"5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\"\n          }\n        ]\n      },\n      {\n        \"Name\": \"Root\",\n        \"Keys\": [\n          {\n            \"ID\": \"a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\"\n          }\n        ]\n      }\n    ]\n  }\n]\n```\n\n### Get details about signatures for multiple images\n\n`docker trust inspect` can take multiple repositories and images as arguments, and reports the results in an ordered list:\n\n``` \n$ docker trust inspect alpine notary\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"Name\": \"alpine\",\n    \"SignedTags\": [\n      {\n        \"SignedTag\": \"3.5\",\n        \"Digest\": \"b007a354427e1880de9cdba533e8e57382b7f2853a68a478a17d447b302c219c\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"3.6\",\n        \"Digest\": \"d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"edge\",\n        \"Digest\": \"23e7d843e63a3eee29b6b8cfcd10e23dd1ef28f47251a985606a31040bf8e096\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"integ-test-base\",\n        \"Digest\": \"3952dc48dcc4136ccdde37fbef7e250346538a55a0366e3fccc683336377e372\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"latest\",\n        \"Digest\": \"d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      }\n    ],\n    \"Signers\": [],\n    \"AdministrativeKeys\": [\n      {\n        \"Name\": \"Repository\",\n        \"Keys\": [\n          {\n            \"ID\": \"5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\"\n          }\n        ]\n      },\n      {\n        \"Name\": \"Root\",\n        \"Keys\": [\n          {\n            \"ID\": \"a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\"\n          }\n        ]\n      }\n    ]\n  },\n  {\n    \"Name\": \"notary\",\n    \"SignedTags\": [\n      {\n        \"SignedTag\": \"server\",\n        \"Digest\": \"71f64ab718a3331dee103bc5afc6bc492914738ce37c2d2f127a8133714ecf5c\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      },\n      {\n        \"SignedTag\": \"signer\",\n        \"Digest\": \"a6122d79b1e74f70b5dd933b18a6d1f99329a4728011079f06b245205f158fe8\",\n        \"Signers\": [\n          \"Repo Admin\"\n        ]\n      }\n    ],\n    \"Signers\": [],\n    \"AdministrativeKeys\": [\n      {\n        \"Name\": \"Root\",\n        \"Keys\": [\n          {\n            \"ID\": \"8cdcdef5bd039f4ab5a029126951b5985eebf57cabdcdc4d21f5b3be8bb4ce92\"\n          }\n        ]\n      },\n      {\n        \"Name\": \"Repository\",\n        \"Keys\": [\n          {\n            \"ID\": \"85bfd031017722f950d480a721f845a2944db26a3dc084040a70f1b0d9bbb3df\"\n          }\n        ]\n      }\n    ]\n  }\n]\n```\n\n### Formatting\n\nYou can print the inspect output in a human-readable format instead of the default JSON output, by using the `--pretty` option:\n\n### Get details about signatures for a single image tag\n\n``` \n$ docker trust inspect --pretty alpine:latest\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nlatest              1072e499f3f655a032e88542330cf75b02e7bdf673278f701d7ba61629ee3ebe   (Repo Admin)\n\nAdministrative keys for alpine:latest:\nRepository Key: 5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\nRoot Key:       a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\n```\n\nThe `SIGNED TAG` is the signed image tag with a unique content-addressable `DIGEST`. `SIGNERS` lists all entities who have signed.\n\nThe administrative keys listed specify the root key of trust, as well as the administrative repository key. These keys are responsible for modifying signers, and rotating keys for the signed repository.\n\nIf signers are set up for the repository via other `docker trust` commands, `docker trust inspect --pretty` displays them appropriately as a `SIGNER` and specify their `KEYS`:\n\n``` \n$ docker trust inspect --pretty my-image:purple\n\nSIGNED TAG          DIGEST                                                              SIGNERS\npurple              941d3dba358621ce3c41ef67b47cf80f701ff80cdf46b5cc86587eaebfe45557    alice, bob, carol\n\nList of signers and their keys:\n\nSIGNER              KEYS\nalice               47caae5b3e61, a85aab9d20a4\nbob                 034370bcbd77, 82a66673242c\ncarol               b6f9f8e1aab0\n\nAdministrative keys for my-image:\nRepository Key: 27df2c8187e7543345c2e0bf3a1262e0bc63a72754e9a7395eac3f747ec23a44\nRoot Key:       40b66ccc8b176be8c7d365a17f3e046d1c3494e053dd57cfeacfe2e19c4f8e8f\n```\n\nHowever, if other tags are signed in the same image repository, `docker trust inspect` reports relevant key information.\n\n``` \n$ docker trust inspect --pretty alpine:unsigned\n\nNo signatures for alpine:unsigned\n\n\nAdministrative keys for alpine:unsigned:\nRepository Key: 5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\nRoot Key:       a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\n```\n\n### Get details about signatures for all image tags in a repository\n\n``` \n$ docker trust inspect --pretty alpine\n\nSIGNED TAG          DIGEST                                                             SIGNERS\n2.6                 9ace551613070689a12857d62c30ef0daa9a376107ec0fff0e34786cedb3399b   (Repo Admin)\n2.7                 9f08005dff552038f0ad2f46b8e65ff3d25641747d3912e3ea8da6785046561a   (Repo Admin)\n3.1                 d9477888b78e8c6392e0be8b2e73f8c67e2894ff9d4b8e467d1488fcceec21c8   (Repo Admin)\n3.2                 19826d59171c2eb7e90ce52bfd822993bef6a6fe3ae6bb4a49f8c1d0a01e99c7   (Repo Admin)\n3.3                 8fd4b76819e1e5baac82bd0a3d03abfe3906e034cc5ee32100d12aaaf3956dc7   (Repo Admin)\n3.4                 833ad81ace8277324f3ca8c91c02bdcf1d13988d8ecf8a3f97ecdd69d0390ce9   (Repo Admin)\n3.5                 af2a5bd2f8de8fc1ecabf1c76611cdc6a5f1ada1a2bdd7d3816e121b70300308   (Repo Admin)\n3.6                 1072e499f3f655a032e88542330cf75b02e7bdf673278f701d7ba61629ee3ebe   (Repo Admin)\nedge                79d50d15bd7ea48ea00cf3dd343b0e740c1afaa8e899bee475236ef338e1b53b   (Repo Admin)\nlatest              1072e499f3f655a032e88542330cf75b02e7bdf673278f701d7ba61629ee3ebe   (Repo Admin)\n\nAdministrative keys for alpine:\nRepository Key: 5a46c9aaa82ff150bb7305a2d17d0c521c2d784246807b2dc611f436a69041fd\nRoot Key:       a2489bcac7a79aa67b19b96c4a3bf0c675ffdf00c6d2fabe1a5df1115e80adce\n```\n\nHere’s an example with signers that are set up by `docker trust` commands:\n\n``` \n$ docker trust inspect --pretty my-image\n\nSIGNED TAG          DIGEST                                                              SIGNERS\nred                 852cc04935f930a857b630edc4ed6131e91b22073bcc216698842e44f64d2943    alice\nblue                f1c38dbaeeb473c36716f6494d803fbfbe9d8a76916f7c0093f227821e378197    alice, bob\ngreen               cae8fedc840f90c8057e1c24637d11865743ab1e61a972c1c9da06ec2de9a139    alice, bob\nyellow              9cc65fc3126790e683d1b92f307a71f48f75fa7dd47a7b03145a123eaf0b45ba    carol\npurple              941d3dba358621ce3c41ef67b47cf80f701ff80cdf46b5cc86587eaebfe45557    alice, bob, carol\norange              d6c271baa6d271bcc24ef1cbd65abf39123c17d2e83455bdab545a1a9093fc1c    alice\n\nList of signers and their keys for my-image:\n\nSIGNER              KEYS\nalice               47caae5b3e61, a85aab9d20a4\nbob                 034370bcbd77, 82a66673242c\ncarol               b6f9f8e1aab0\n\nAdministrative keys for my-image:\nRepository Key: 27df2c8187e7543345c2e0bf3a1262e0bc63a72754e9a7395eac3f747ec23a44\nRoot Key:       40b66ccc8b176be8c7d365a17f3e046d1c3494e053dd57cfeacfe2e19c4f8e8f\n```\n\n## Parent command\n\n| Command                        | Description                   |\n|:-------------------------------|:------------------------------|\n| [docker trust](../trust/index) | Manage trust on Docker images |\n\n## Related commands\n\n| Command                                      | Description                                            |\n|----------------------------------------------|--------------------------------------------------------|\n| [docker trust inspect](index)                | Return low-level information about keys and signatures |\n| [docker trust key](../trust_key/index)       | Manage keys for signing Docker images                  |\n| [docker trust revoke](../trust_revoke/index) | Remove trust for an image                              |\n| [docker trust sign](../trust_sign/index)     | Sign an image                                          |\n| [docker trust signer](../trust_signer/index) | Manage entities who can sign Docker images             |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_inspect/](https://docs.docker.com/engine/reference/commandline/trust_inspect/)"
- name: docker trust key
  id: engine/reference/commandline/trust_key/index
  summary: © 2019 Docker, Inc
  description: "# docker trust key\n\n  \n\nManage keys for signing Docker images\n\n## Usage\n\n``` \n$ docker trust key COMMAND\n```\n\n## Parent command\n\n| Command                        | Description                   |\n|:-------------------------------|:------------------------------|\n| [docker trust](../trust/index) | Manage trust on Docker images |\n\n## Child commands\n\n| Command                                                  | Description                          |\n|----------------------------------------------------------|--------------------------------------|\n| [docker trust key generate](../trust_key_generate/index) | Generate and load a signing key-pair |\n| [docker trust key load](../trust_key_load/index)         | Load a private key file for signing  |\n\n## Related commands\n\n| Command                                        | Description                                            |\n|------------------------------------------------|--------------------------------------------------------|\n| [docker trust inspect](../trust_inspect/index) | Return low-level information about keys and signatures |\n| [docker trust key](index)                      | Manage keys for signing Docker images                  |\n| [docker trust revoke](../trust_revoke/index)   | Remove trust for an image                              |\n| [docker trust sign](../trust_sign/index)       | Sign an image                                          |\n| [docker trust signer](../trust_signer/index)   | Manage entities who can sign Docker images             |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_key/](https://docs.docker.com/engine/reference/commandline/trust_key/)"
- name: docker trust key generate
  id: engine/reference/commandline/trust_key_generate/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust key generate\n\n  \n\nGenerate and load a signing key-pair\n\n## Usage\n\n``` \n$ docker trust key generate NAME\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust key generate` generates a key-pair to be used with signing, and loads the private key into the local docker trust keystore.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                                                 |\n|-----------------|---------|-------------------------------------------------------------|\n| `--dir`         |         | Directory to generate key in, defaults to current directory |\n\n## Examples\n\n### Generate a key-pair\n\n``` \n$ docker trust key generate alice\n\nGenerating key for alice...\nEnter passphrase for new alice key with ID 17acf3c:\nRepeat passphrase for new alice key with ID 17acf3c:\nSuccessfully generated and loaded private key. Corresponding public key available: alice.pub\n$ ls\nalice.pub\n```\n\nThe private signing key is encrypted by the passphrase and loaded into the docker trust keystore. All passphrase requests to sign with the key will be referred to by the provided `NAME`.\n\nThe public key component `alice.pub` will be available in the current working directory, and can be used directly by `docker trust signer add`.\n\nProvide the `--dir` argument to specify a directory to generate the key in:\n\n``` \n$ docker trust key generate alice --dir /foo\n\nGenerating key for alice...\nEnter passphrase for new alice key with ID 17acf3c:\nRepeat passphrase for new alice key with ID 17acf3c:\nSuccessfully generated and loaded private key. Corresponding public key available: alice.pub\n$ ls /foo\nalice.pub\n```\n\n## Parent command\n\n| Command                                | Description                           |\n|:---------------------------------------|:--------------------------------------|\n| [docker trust key](../trust_key/index) | Manage keys for signing Docker images |\n\n## Related commands\n\n| Command                                          | Description                          |\n|--------------------------------------------------|--------------------------------------|\n| [docker trust key generate](index)               | Generate and load a signing key-pair |\n| [docker trust key load](../trust_key_load/index) | Load a private key file for signing  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_key_generate/](https://docs.docker.com/engine/reference/commandline/trust_key_generate/)"
- name: docker trust key load
  id: engine/reference/commandline/trust_key_load/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust key load\n\n  \n\nLoad a private key file for signing\n\n## Usage\n\n``` \n$ docker trust key load [OPTIONS] KEYFILE\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust key load` adds private keys to the local docker trust keystore.\n\nTo add a signer to a repository use `docker trust signer add`.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default  | Description             |\n|-----------------|----------|-------------------------|\n| `--name`        | `signer` | Name for the loaded key |\n\n## Examples\n\n### Load a single private key\n\nFor a private key `alice.pem` with permissions `-rw-------`\n\n``` \n$ docker trust key load alice.pem\n\nLoading key from \"alice.pem\"...\nEnter passphrase for new signer key with ID f8097df:\nRepeat passphrase for new signer key with ID f8097df:\nSuccessfully imported key from alice.pem\n```\n\nTo specify a name use the `--name` flag:\n\n``` \n$ docker trust key load --name alice-key alice.pem\n\nLoading key from \"alice.pem\"...\nEnter passphrase for new alice-key key with ID f8097df:\nRepeat passphrase for new alice-key key with ID f8097df:\nSuccessfully imported key from alice.pem\n```\n\n## Parent command\n\n| Command                                | Description                           |\n|:---------------------------------------|:--------------------------------------|\n| [docker trust key](../trust_key/index) | Manage keys for signing Docker images |\n\n## Related commands\n\n| Command                                                  | Description                          |\n|----------------------------------------------------------|--------------------------------------|\n| [docker trust key generate](../trust_key_generate/index) | Generate and load a signing key-pair |\n| [docker trust key load](index)                           | Load a private key file for signing  |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_key_load/](https://docs.docker.com/engine/reference/commandline/trust_key_load/)"
- name: docker trust revoke
  id: engine/reference/commandline/trust_revoke/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust revoke\n\n  \n\nRemove trust for an image\n\n## Usage\n\n``` \n$ docker trust revoke [OPTIONS] IMAGE[:TAG]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust revoke` removes signatures from tags in signed repositories.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                    |\n|-----------------|---------|--------------------------------|\n| `--yes` , `-y`  |         | Do not prompt for confirmation |\n\n## Examples\n\n### Revoke signatures from a signed tag\n\nHere’s an example of a repo with two signed tags:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\nSIGNED TAG          DIGEST                                                              SIGNERS\nred                 852cc04935f930a857b630edc4ed6131e91b22073bcc216698842e44f64d2943    alice\nblue                f1c38dbaeeb473c36716f6494d803fbfbe9d8a76916f7c0093f227821e378197    alice, bob\n\nList of signers and their keys for example/trust-demo:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\nWhen `alice`, one of the signers, runs `docker trust revoke`:\n\n``` \n$ docker trust revoke example/trust-demo:red\nEnter passphrase for delegation key with ID 27d42a8:\nSuccessfully deleted signature for example/trust-demo:red\n```\n\nAfter revocation, the tag is removed from the list of released tags:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\nSIGNED TAG          DIGEST                                                              SIGNERS\nblue                f1c38dbaeeb473c36716f6494d803fbfbe9d8a76916f7c0093f227821e378197    alice, bob\n\nList of signers and their keys for example/trust-demo:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n### Revoke signatures on all tags in a repository\n\nWhen no tag is specified, `docker trust` revokes all signatures that you have a signing key for.\n\n``` \n$ docker trust inspect --pretty example/trust-demo\nSIGNED TAG          DIGEST                                                              SIGNERS\nred                 852cc04935f930a857b630edc4ed6131e91b22073bcc216698842e44f64d2943    alice\nblue                f1c38dbaeeb473c36716f6494d803fbfbe9d8a76916f7c0093f227821e378197    alice, bob\n\nList of signers and their keys for example/trust-demo:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\nWhen `alice`, one of the signers, runs `docker trust revoke`:\n\n``` \n$ docker trust revoke example/trust-demo\nPlease confirm you would like to delete all signature data for example/trust-demo? [y/N] y\nEnter passphrase for delegation key with ID 27d42a8:\nSuccessfully deleted signature for example/trust-demo\n```\n\nAll tags that have `alice`’s signature on them are removed from the list of released tags:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nNo signatures for example/trust-demo\n\n\nList of signers and their keys for example/trust-demo:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n## Parent command\n\n| Command                        | Description                   |\n|:-------------------------------|:------------------------------|\n| [docker trust](../trust/index) | Manage trust on Docker images |\n\n## Related commands\n\n| Command                                        | Description                                            |\n|------------------------------------------------|--------------------------------------------------------|\n| [docker trust inspect](../trust_inspect/index) | Return low-level information about keys and signatures |\n| [docker trust key](../trust_key/index)         | Manage keys for signing Docker images                  |\n| [docker trust revoke](index)                   | Remove trust for an image                              |\n| [docker trust sign](../trust_sign/index)       | Sign an image                                          |\n| [docker trust signer](../trust_signer/index)   | Manage entities who can sign Docker images             |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_revoke/](https://docs.docker.com/engine/reference/commandline/trust_revoke/)"
- name: docker trust sign
  id: engine/reference/commandline/trust_sign/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust sign\n\n  \n\nSign an image\n\n## Usage\n\n``` \n$ docker trust sign IMAGE:TAG\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust sign` adds signatures to tags to create signed repositories.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                 |\n|-----------------|---------|-----------------------------|\n| `--local`       |         | Sign a locally tagged image |\n\n## Examples\n\n### Sign a tag as a repo admin\n\nGiven an image:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  c24134c079c35e698060beabe110bb83ab285d0d978de7d92fed2c8c83570a41   (Repo Admin)\n\nAdministrative keys for example/trust-demo:\nRepository Key: 36d4c3601102fa7c5712a343c03b94469e5835fb27c191b529c06fd19c14a942\nRoot Key:       246d360f7c53a9021ee7d4259e3c5692f3f1f7ad4737b1ea8c7b8da741ad980b\n```\n\nSign a new tag with `docker trust sign`:\n\n``` \n$ docker trust sign example/trust-demo:v2\n\nSigning and pushing trust metadata for example/trust-demo:v2\nThe push refers to a repository [docker.io/example/trust-demo]\need4e566104a: Layer already exists\n77edfb6d1e3c: Layer already exists\nc69f806905c2: Layer already exists\n582f327616f1: Layer already exists\na3fbb648f0bd: Layer already exists\n5eac2de68a97: Layer already exists\n8d4d1ab5ff74: Layer already exists\nv2: digest: sha256:8f6f460abf0436922df7eb06d28b3cdf733d2cac1a185456c26debbff0839c56 size: 1787\nSigning and pushing trust metadata\nEnter passphrase for repository key with ID 36d4c36:\nSuccessfully signed docker.io/example/trust-demo:v2\n```\n\nUse `docker trust inspect --pretty` to list the new signature:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  c24134c079c35e698060beabe110bb83ab285d0d978de7d92fed2c8c83570a41   (Repo Admin)\nv2                  8f6f460abf0436922df7eb06d28b3cdf733d2cac1a185456c26debbff0839c56   (Repo Admin)\n\nAdministrative keys for example/trust-demo:\nRepository Key: 36d4c3601102fa7c5712a343c03b94469e5835fb27c191b529c06fd19c14a942\nRoot Key:       246d360f7c53a9021ee7d4259e3c5692f3f1f7ad4737b1ea8c7b8da741ad980b\n```\n\n### Sign a tag as a signer\n\nGiven an image:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nNo signatures for example/trust-demo\n\n\nList of signers and their keys for example/trust-demo:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\nSign a new tag with `docker trust sign`:\n\n``` \n$ docker trust sign example/trust-demo:v1\n\nSigning and pushing trust metadata for example/trust-demo:v1\nThe push refers to a repository [docker.io/example/trust-demo]\n26b126eb8632: Layer already exists\n220d34b5f6c9: Layer already exists\n8a5132998025: Layer already exists\naca233ed29c3: Layer already exists\ne5d2f035d7a4: Layer already exists\nv1: digest: sha256:74d4bfa917d55d53c7df3d2ab20a8d926874d61c3da5ef6de15dd2654fc467c4 size: 1357\nSigning and pushing trust metadata\nEnter passphrase for delegation key with ID 27d42a8:\nSuccessfully signed docker.io/example/trust-demo:v1\n```\n\n`docker trust inspect --pretty` lists the new signature:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  74d4bfa917d55d53c7df3d2ab20a8d926874d61c3da5ef6de15dd2654fc467c4   alice\n\nList of signers and their keys for example/trust-demo:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n## Parent command\n\n| Command                        | Description                   |\n|:-------------------------------|:------------------------------|\n| [docker trust](../trust/index) | Manage trust on Docker images |\n\n## Related commands\n\n| Command                                        | Description                                            |\n|------------------------------------------------|--------------------------------------------------------|\n| [docker trust inspect](../trust_inspect/index) | Return low-level information about keys and signatures |\n| [docker trust key](../trust_key/index)         | Manage keys for signing Docker images                  |\n| [docker trust revoke](../trust_revoke/index)   | Remove trust for an image                              |\n| [docker trust sign](index)                     | Sign an image                                          |\n| [docker trust signer](../trust_signer/index)   | Manage entities who can sign Docker images             |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_sign/](https://docs.docker.com/engine/reference/commandline/trust_sign/)"
- name: docker trust signer
  id: engine/reference/commandline/trust_signer/index
  summary: © 2019 Docker, Inc
  description: "# docker trust signer\n\n  \n\nManage entities who can sign Docker images\n\n## Usage\n\n``` \n$ docker trust signer COMMAND\n```\n\n## Parent command\n\n| Command                        | Description                   |\n|:-------------------------------|:------------------------------|\n| [docker trust](../trust/index) | Manage trust on Docker images |\n\n## Child commands\n\n| Command                                                    | Description     |\n|------------------------------------------------------------|-----------------|\n| [docker trust signer add](../trust_signer_add/index)       | Add a signer    |\n| [docker trust signer remove](../trust_signer_remove/index) | Remove a signer |\n\n## Related commands\n\n| Command                                        | Description                                            |\n|------------------------------------------------|--------------------------------------------------------|\n| [docker trust inspect](../trust_inspect/index) | Return low-level information about keys and signatures |\n| [docker trust key](../trust_key/index)         | Manage keys for signing Docker images                  |\n| [docker trust revoke](../trust_revoke/index)   | Remove trust for an image                              |\n| [docker trust sign](../trust_sign/index)       | Sign an image                                          |\n| [docker trust signer](index)                   | Manage entities who can sign Docker images             |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_signer/](https://docs.docker.com/engine/reference/commandline/trust_signer/)"
- name: docker trust signer add
  id: engine/reference/commandline/trust_signer_add/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust signer add\n\n  \n\nAdd a signer\n\n## Usage\n\n``` \n$ docker trust signer add OPTIONS NAME REPOSITORY [REPOSITORY...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust signer add` adds signers to signed repositories.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand | Default | Description                          |\n|-----------------|---------|--------------------------------------|\n| `--key`         |         | Path to the signer's public key file |\n\n## Examples\n\n### Add a signer to a repo\n\nTo add a new signer, `alice`, to this repository:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nNo signatures for example/trust-demo\n\n\nList of signers and their keys:\n\nSIGNER              KEYS\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: 642692c14c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\nAdd `alice` with `docker trust signer add`:\n\n``` \n$ docker trust signer add alice example/trust-demo --key alice.crt\n  Adding signer \"alice\" to example/trust-demo...\n  Enter passphrase for repository key with ID 642692c:\nSuccessfully added signer: alice to example/trust-demo\n```\n\n`docker trust inspect --pretty` now lists `alice` as a valid signer:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nNo signatures for example/trust-demo\n\n\nList of signers and their keys:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: 642692c14c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n## Parent command\n\n| Command                                      | Description                                |\n|:---------------------------------------------|:-------------------------------------------|\n| [docker trust signer](../trust_signer/index) | Manage entities who can sign Docker images |\n\n## Related commands\n\n| Command                                                    | Description     |\n|------------------------------------------------------------|-----------------|\n| [docker trust signer add](index)                           | Add a signer    |\n| [docker trust signer remove](../trust_signer_remove/index) | Remove a signer |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_signer_add/](https://docs.docker.com/engine/reference/commandline/trust_signer_add/)"
- name: docker trust signer remove
  id: engine/reference/commandline/trust_signer_remove/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker trust signer remove\n\n  \n\nRemove a signer\n\n## Usage\n\n``` \n$ docker trust signer remove [OPTIONS] NAME REPOSITORY [REPOSITORY...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\n`docker trust signer remove` removes signers from signed repositories.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                                           |\n|------------------|---------|-----------------------------------------------------------------------|\n| `--force` , `-f` |         | Do not prompt for confirmation before removing the most recent signer |\n\n## Examples\n\n### Remove a signer from a repo\n\nTo remove an existing signer, `alice`, from this repository:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nNo signatures for example/trust-demo\n\n\nList of signers and their keys:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\nRemove `alice` with `docker trust signer remove`:\n\n``` \n$ docker trust signer remove alice example/trust-demo\n\nRemoving signer \"alice\" from image example/trust-demo...\nEnter passphrase for repository key with ID 642692c:\nSuccessfully removed alice from example/trust-demo\n```\n\n`docker trust inspect --pretty` now does not list `alice` as a valid signer:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nNo signatures for example/trust-demo\n\n\nList of signers and their keys:\n\nSIGNER              KEYS\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n### Remove a signer from multiple repos\n\nTo remove an existing signer, `alice`, from multiple repositories:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  74d4bfa917d55d53c7df3d2ab20a8d926874d61c3da5ef6de15dd2654fc467c4   alice, bob\n\nList of signers and their keys:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: 95b9e5514c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n``` \n$ docker trust inspect --pretty example/trust-demo2\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  74d4bfa917d55d53c7df3d2ab20a8d926874d61c3da5ef6de15dd2654fc467c4   alice, bob\n\nList of signers and their keys:\n\nSIGNER              KEYS\nalice               05e87edcaecb\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo2:\nRepository Key: ece554f14c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4553d2ab20a8d9268\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\nRemove `alice` from both images with a single `docker trust signer remove` command:\n\n``` \n$ docker trust signer remove alice example/trust-demo example/trust-demo2\n\nRemoving signer \"alice\" from image example/trust-demo...\nEnter passphrase for repository key with ID 95b9e55:\nSuccessfully removed alice from example/trust-demo\n\nRemoving signer \"alice\" from image example/trust-demo2...\nEnter passphrase for repository key with ID ece554f:\nSuccessfully removed alice from example/trust-demo2\n```\n\nRun `docker trust inspect --pretty` to confirm that `alice` is no longer listed as a valid signer of either `example/trust-demo` or `example/trust-demo2`:\n\n``` \n$ docker trust inspect --pretty example/trust-demo\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  74d4bfa917d55d53c7df3d2ab20a8d926874d61c3da5ef6de15dd2654fc467c4   bob\n\nList of signers and their keys:\n\nSIGNER              KEYS\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo:\nRepository Key: ecc457614c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4555b3c6ab02f71e\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n``` \n$ docker trust inspect --pretty example/trust-demo2\n\nSIGNED TAG          DIGEST                                                             SIGNERS\nv1                  74d4bfa917d55d53c7df3d2ab20a8d926874d61c3da5ef6de15dd2654fc467c4   bob\n\nList of signers and their keys:\n\nSIGNER              KEYS\nbob                 5600f5ab76a2\n\nAdministrative keys for example/trust-demo2:\nRepository Key: ece554f14c9fc399da523a5f4e24fe306a0a6ee1cc79a10e4553d2ab20a8d9268\nRoot Key:       3cb2228f6561e58f46dbc4cda4fcaff9d5ef22e865a94636f82450d1d2234949\n```\n\n`docker trust signer remove` removes signers to repositories on a best effort basis, so it will continue to remove the signer from subsequent repositories if one attempt fails:\n\n``` \n$ docker trust signer remove alice example/unauthorized example/authorized\n\nRemoving signer \"alice\" from image example/unauthorized...\nNo signer alice for image example/unauthorized\n\nRemoving signer \"alice\" from image example/authorized...\nEnter passphrase for repository key with ID c6772a0:\nSuccessfully removed alice from example/authorized\n\nError removing signer from: example/unauthorized\n```\n\n## Parent command\n\n| Command                                      | Description                                |\n|:---------------------------------------------|:-------------------------------------------|\n| [docker trust signer](../trust_signer/index) | Manage entities who can sign Docker images |\n\n## Related commands\n\n| Command                                              | Description     |\n|------------------------------------------------------|-----------------|\n| [docker trust signer add](../trust_signer_add/index) | Add a signer    |\n| [docker trust signer remove](index)                  | Remove a signer |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/trust_signer_remove/](https://docs.docker.com/engine/reference/commandline/trust_signer_remove/)"
- name: docker unpause
  id: engine/reference/commandline/unpause/index
  summary: The docker unpause command un-suspends all processes in the specified containers
  description: "# docker unpause\n\n  \n\nUnpause all processes within one or more containers\n\n## Usage\n\n``` \n$ docker unpause CONTAINER [CONTAINER...]\n```\n\n## Description\n\nThe `docker unpause` command un-suspends all processes in the specified containers. On Linux, it does this using the freezer cgroup.\n\nSee the [freezer cgroup documentation](https://www.kernel.org/doc/Documentation/cgroup-v1/freezer-subsystem.txt) for further details.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\n``` \n$ docker unpause my_container\nmy_container\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/unpause/](https://docs.docker.com/engine/reference/commandline/unpause/)"
- name: docker update
  id: engine/reference/commandline/update/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker update\n\n  \n\nUpdate configuration of one or more containers\n\n## Usage\n\n``` \n$ docker update [OPTIONS] CONTAINER [CONTAINER...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nThe `docker update` command dynamically updates container configuration. You can use this command to prevent containers from consuming too many resources from their Docker host. With a single command, you can place limits on a single container or on many. To specify more than one container, provide space-separated list of container names or IDs.\n\nWith the exception of the `--kernel-memory` option, you can specify these options on a running or a stopped container. On kernel version older than 4.6, you can only update `--kernel-memory` on a stopped container or on a running container with kernel memory initialized.\n\n> **Warning**\n>\n> The `docker update` and `docker container update` commands are not supported for Windows containers.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand        | Default | Description                                                                                             |\n|------------------------|---------|---------------------------------------------------------------------------------------------------------|\n| `--blkio-weight`       |         | Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)                            |\n| `--cpu-period`         |         | Limit CPU CFS (Completely Fair Scheduler) period                                                        |\n| `--cpu-quota`          |         | Limit CPU CFS (Completely Fair Scheduler) quota                                                         |\n| `--cpu-rt-period`      |         | Limit the CPU real-time period in microseconds                                                          |\n| `--cpu-rt-runtime`     |         | Limit the CPU real-time runtime in microseconds                                                         |\n| `--cpu-shares` , `-c`  |         | CPU shares (relative weight)                                                                            |\n| `--cpus`               |         | Number of CPUs                                                                                          |\n| `--cpuset-cpus`        |         | CPUs in which to allow execution (0-3, 0,1)                                                             |\n| `--cpuset-mems`        |         | MEMs in which to allow execution (0-3, 0,1)                                                             |\n| `--kernel-memory`      |         | Kernel memory limit                                                                                     |\n| `--memory` , `-m`      |         | Memory limit                                                                                            |\n| `--memory-reservation` |         | Memory soft limit                                                                                       |\n| `--memory-swap`        |         | Swap limit equal to memory plus swap: '-1' to enable unlimited swap                                     |\n| `--pids-limit`         |         | [API 1.40+](https://docs.docker.com/engine/api/v1.40/) Tune container pids limit (set -1 for unlimited) |\n| `--restart`            |         | Restart policy to apply when a container exits                                                          |\n\n## Examples\n\nThe following sections illustrate ways to use this command.\n\n### Update a container’s cpu-shares\n\nTo limit a container’s cpu-shares to 512, first identify the container name or ID. You can use `docker ps` to find these values. You can also use the ID returned from the `docker run` command. Then, do the following:\n\n``` \n$ docker update --cpu-shares 512 abebf7571666\n```\n\n### Update a container with cpu-shares and memory\n\nTo update multiple resource configurations for multiple containers:\n\n``` \n$ docker update --cpu-shares 512 -m 300M abebf7571666 hopeful_morse\n```\n\n### Update a container’s kernel memory constraints\n\nYou can update a container’s kernel memory limit using the `--kernel-memory` option. On kernel version older than 4.6, this option can be updated on a running container only if the container was started with `--kernel-memory`. If the container was started *without* `--kernel-memory` you need to stop the container before updating kernel memory.\n\n> **Note**\n>\n> The `--kernel-memory` option has been deprecated since Docker 20.10.\n\nFor example, if you started a container with this command:\n\n``` \n$ docker run -dit --name test --kernel-memory 50M ubuntu bash\n```\n\nYou can update kernel memory while the container is running:\n\n``` \n$ docker update --kernel-memory 80M test\n```\n\nIf you started a container *without* kernel memory initialized:\n\n``` \n$ docker run -dit --name test2 --memory 300M ubuntu bash\n```\n\nUpdate kernel memory of running container `test2` will fail. You need to stop the container before updating the `--kernel-memory` setting. The next time you start it, the container uses the new value.\n\nKernel version newer than (include) 4.6 does not have this limitation, you can use `--kernel-memory` the same way as other options.\n\n### Update a container’s restart policy\n\nYou can change a container’s restart policy on a running container. The new restart policy takes effect instantly after you run `docker update` on a container.\n\nTo update restart policy for one or more containers:\n\n``` \n$ docker update --restart=on-failure:3 abebf7571666 hopeful_morse\n```\n\nNote that if the container is started with “--rm” flag, you cannot update the restart policy for it. The `AutoRemove` and `RestartPolicy` are mutually exclusive for the container.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/update/](https://docs.docker.com/engine/reference/commandline/update/)"
- name: docker version
  id: engine/reference/commandline/version/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker version\n\n  \n\nShow the Docker version information\n\n## Usage\n\n``` \n$ docker version [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nBy default, this will render all version information in an easy to read layout. If a format is specified, the given template will be executed instead.\n\nGo’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                                              |\n|-------------------|---------|--------------------------------------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template                            |\n| `--kubeconfig`    |         | [deprecated](../../../deprecated/index)Kubernetes Kubernetes config file |\n\n## Examples\n\n### Default output\n\n``` \n$ docker version\n\nClient:\n Version:           19.03.8\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        afacb8b\n Built:             Wed Mar 11 01:21:11 2020\n OS/Arch:           darwin/amd64\n Context:           default\n Experimental:      true\n\nServer:\n Engine:\n  Version:          19.03.8\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       afacb8b\n  Built:            Wed Mar 11 01:29:16 2020\n  OS/Arch:          linux/amd64\n  Experimental:     true\n containerd:\n  Version:          v1.2.13\n  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429\n runc:\n  Version:          1.0.0-rc10\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\n docker-init:\n  Version:          0.18.0\n  GitCommit:        fec3683\n```\n\n### Get the server version\n\n``` \n$ docker version --format '{{.Server.Version}}'\n\n19.03.8\n```\n\n### Dump raw JSON data\n\n``` \n$ docker version --format '{{json .}}'\n\n{\"Client\":{\"Platform\":{\"Name\":\"Docker Engine - Community\"},\"Version\":\"19.03.8\",\"ApiVersion\":\"1.40\",\"DefaultAPIVersion\":\"1.40\",\"GitCommit\":\"afacb8b\",\"GoVersion\":\"go1.12.17\",\"Os\":\"darwin\",\"Arch\":\"amd64\",\"BuildTime\":\"Wed Mar 11 01:21:11 2020\",\"Experimental\":true},\"Server\":{\"Platform\":{\"Name\":\"Docker Engine - Community\"},\"Components\":[{\"Name\":\"Engine\",\"Version\":\"19.03.8\",\"Details\":{\"ApiVersion\":\"1.40\",\"Arch\":\"amd64\",\"BuildTime\":\"Wed Mar 11 01:29:16 2020\",\"Experimental\":\"true\",\"GitCommit\":\"afacb8b\",\"GoVersion\":\"go1.12.17\",\"KernelVersion\":\"4.19.76-linuxkit\",\"MinAPIVersion\":\"1.12\",\"Os\":\"linux\"}},{\"Name\":\"containerd\",\"Version\":\"v1.2.13\",\"Details\":{\"GitCommit\":\"7ad184331fa3e55e52b890ea95e65ba581ae3429\"}},{\"Name\":\"runc\",\"Version\":\"1.0.0-rc10\",\"Details\":{\"GitCommit\":\"dc9208a3303feef5b3839f4323d9beb36df0a9dd\"}},{\"Name\":\"docker-init\",\"Version\":\"0.18.0\",\"Details\":{\"GitCommit\":\"fec3683\"}}],\"Version\":\"19.03.8\",\"ApiVersion\":\"1.40\",\"MinAPIVersion\":\"1.12\",\"GitCommit\":\"afacb8b\",\"GoVersion\":\"go1.12.17\",\"Os\":\"linux\",\"Arch\":\"amd64\",\"KernelVersion\":\"4.19.76-linuxkit\",\"Experimental\":true,\"BuildTime\":\"2020-03-11T01:29:16.000000000+00:00\"}}\n```\n\n### Print the current context\n\nThe following example prints the currently used [`docker context`](../context/index):\n\n``` \n$ docker version --format='{{.Client.Context}}'\ndefault\n```\n\nAs an example, this output can be used to dynamically change your shell prompt to indicate your active context. The example below illustrates how this output could be used when using Bash as your shell.\n\nDeclare a function to obtain the current context in your `~/.bashrc`, and set this command as your `PROMPT_COMMAND`\n\n``` \nfunction docker_context_prompt() {\n        PS1=\"context: $(docker version --format='{{.Client.Context}}')> \"\n}\n\nPROMPT_COMMAND=docker_context_prompt\n```\n\nAfter reloading the `~/.bashrc`, the prompt now shows the currently selected `docker context`:\n\n``` \n$ source ~/.bashrc\ncontext: default> docker context create --docker host=unix:///var/run/docker.sock my-context\nmy-context\nSuccessfully created context \"my-context\"\ncontext: default> docker context use my-context\nmy-context\nCurrent context is now \"my-context\"\ncontext: my-context> docker context use default\ndefault\nCurrent context is now \"default\"\ncontext: default>\n```\n\nRefer to the [`docker context` section](../context/index) in the command line reference for more information about `docker context`.\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/version/](https://docs.docker.com/engine/reference/commandline/version/)"
- name: docker volume
  id: engine/reference/commandline/volume/index
  summary: Manage volumes
  description: "# docker volume\n\n  \n\nManage volumes\n\n## Usage\n\n``` \n$ docker volume COMMAND COMMAND\n```\n\n## Description\n\nManage volumes. You can use subcommands to create, inspect, list, remove, or prune volumes.\n\n## Child commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker volume create](../volume_create/index)   | Create a volume                                     |\n| [docker volume inspect](../volume_inspect/index) | Display detailed information on one or more volumes |\n| [docker volume ls](../volume_ls/index)           | List volumes                                        |\n| [docker volume prune](../volume_prune/index)     | Remove all unused local volumes                     |\n| [docker volume rm](../volume_rm/index)           | Remove one or more volumes                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/volume/](https://docs.docker.com/engine/reference/commandline/volume/)"
- name: docker volume create
  id: engine/reference/commandline/volume_create/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker volume create\n\n  \n\nCreate a volume\n\n## Usage\n\n``` \n$ docker volume create [OPTIONS] [VOLUME]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nCreates a new volume that containers can consume and store data in. If a name is not specified, Docker generates a random name.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                 |\n|-------------------|---------|-----------------------------|\n| `--driver` , `-d` | `local` | Specify volume driver name  |\n| `--label`         |         | Set metadata for a volume   |\n| `--name`          |         | Specify volume name         |\n| `--opt` , `-o`    |         | Set driver specific options |\n\n## Examples\n\nCreate a volume and then configure the container to use it:\n\n``` \n$ docker volume create hello\n\nhello\n\n$ docker run -d -v hello:/world busybox ls /world\n```\n\nThe mount is created inside the container’s `/world` directory. Docker does not support relative paths for mount points inside the container.\n\nMultiple containers can use the same volume in the same time period. This is useful if two containers need access to shared data. For example, if one container writes and the other reads the data.\n\nVolume names must be unique among drivers. This means you cannot use the same volume name with two different drivers. If you attempt this `docker` returns an error:\n\n``` \nA volume named  \"hello\"  already exists with the \"some-other\" driver. Choose a different volume name.\n```\n\nIf you specify a volume name already in use on the current driver, Docker assumes you want to re-use the existing volume and does not return an error.\n\n### Driver-specific options\n\nSome volume drivers may take options to customize the volume creation. Use the `-o` or `--opt` flags to pass driver options:\n\n``` \n$ docker volume create --driver fake \\\n    --opt tardis=blue \\\n    --opt timey=wimey \\\n    foo\n```\n\nThese options are passed directly to the volume driver. Options for different volume drivers may do different things (or nothing at all).\n\nThe built-in `local` driver on Windows does not support any options.\n\nThe built-in `local` driver on Linux accepts options similar to the linux `mount` command. You can provide multiple options by passing the `--opt` flag multiple times. Some `mount` options (such as the `o` option) can take a comma-separated list of options. Complete list of available mount options can be found [here](https://man7.org/linux/man-pages/man8/mount.8.html).\n\nFor example, the following creates a `tmpfs` volume called `foo` with a size of 100 megabyte and `uid` of 1000.\n\n``` \n$ docker volume create --driver local \\\n    --opt type=tmpfs \\\n    --opt device=tmpfs \\\n    --opt o=size=100m,uid=1000 \\\n    foo\n```\n\nAnother example that uses `btrfs`:\n\n``` \n$ docker volume create --driver local \\\n    --opt type=btrfs \\\n    --opt device=/dev/sda2 \\\n    foo\n```\n\nAnother example that uses `nfs` to mount the `/path/to/dir` in `rw` mode from `192.168.1.1`:\n\n``` \n$ docker volume create --driver local \\\n    --opt type=nfs \\\n    --opt o=addr=192.168.1.1,rw \\\n    --opt device=:/path/to/dir \\\n    foo\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker volume](../volume/index) | Manage volumes |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker volume create](index)                    | Create a volume                                     |\n| [docker volume inspect](../volume_inspect/index) | Display detailed information on one or more volumes |\n| [docker volume ls](../volume_ls/index)           | List volumes                                        |\n| [docker volume prune](../volume_prune/index)     | Remove all unused local volumes                     |\n| [docker volume rm](../volume_rm/index)           | Remove one or more volumes                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/volume_create/](https://docs.docker.com/engine/reference/commandline/volume_create/)"
- name: docker volume inspect
  id: engine/reference/commandline/volume_inspect/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker volume inspect\n\n  \n\nDisplay detailed information on one or more volumes\n\n## Usage\n\n``` \n$ docker volume inspect [OPTIONS] VOLUME [VOLUME...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nReturns information about a volume. By default, this command renders all results in a JSON array. You can specify an alternate format to execute a given template for each result. Go’s [text/template](https://golang.org/pkg/text/template/) package describes all the details of the format.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                   |\n|-------------------|---------|-----------------------------------------------|\n| `--format` , `-f` |         | Format the output using the given Go template |\n\n## Examples\n\n``` \n$ docker volume create myvolume\n\nmyvolume\n```\n\nUse the `docker volume inspect` comment to inspect the configuration of the volume:\n\n``` \n$ docker volume inspect myvolume\n```\n\nThe output is in JSON format, for example:\n\n``` \n[\n  {\n    \"CreatedAt\": \"2020-04-19T11:00:21Z\",\n    \"Driver\": \"local\",\n    \"Labels\": {},\n    \"Mountpoint\": \"/var/lib/docker/volumes/8140a838303144125b4f54653b47ede0486282c623c3551fbc7f390cdc3e9cf5/_data\",\n    \"Name\": \"myvolume\",\n    \"Options\": {},\n    \"Scope\": \"local\"\n  }\n]\n```\n\nUse the `--format` flag to format the output using a Go template, for example, to print the `Mountpoint` property:\n\n``` \n$ docker volume inspect --format '{{ .Mountpoint }}' myvolume\n\n/var/lib/docker/volumes/myvolume/_data\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker volume](../volume/index) | Manage volumes |\n\n## Related commands\n\n| Command                                        | Description                                         |\n|------------------------------------------------|-----------------------------------------------------|\n| [docker volume create](../volume_create/index) | Create a volume                                     |\n| [docker volume inspect](index)                 | Display detailed information on one or more volumes |\n| [docker volume ls](../volume_ls/index)         | List volumes                                        |\n| [docker volume prune](../volume_prune/index)   | Remove all unused local volumes                     |\n| [docker volume rm](../volume_rm/index)         | Remove one or more volumes                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/volume_inspect/](https://docs.docker.com/engine/reference/commandline/volume_inspect/)"
- name: docker volume ls
  id: engine/reference/commandline/volume_ls/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker volume ls\n\n  \n\nList volumes\n\n## Usage\n\n``` \n$ docker volume ls [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nList all the volumes known to Docker. You can filter using the `-f` or `--filter` flag. Refer to the [filtering](#filtering) section for more information about available filter options.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand   | Default | Description                                  |\n|-------------------|---------|----------------------------------------------|\n| `--filter` , `-f` |         | Provide filter values (e.g. 'dangling=true') |\n| `--format`        |         | Pretty-print volumes using a Go template     |\n| `--quiet` , `-q`  |         | Only display volume names                    |\n\n## Examples\n\n### Create a volume\n\n``` \n$ docker volume create rosemary\n\nrosemary\n\n$ docker volume create tyler\n\ntyler\n\n$ docker volume ls\n\nDRIVER              VOLUME NAME\nlocal               rosemary\nlocal               tyler\n```\n\n### Filtering\n\nThe filtering flag (`-f` or `--filter`) format is of “key=value”. If there is more than one filter, then pass multiple flags (e.g., `--filter \"foo=bar\" --filter \"bif=baz\"`)\n\nThe currently supported filters are:\n\n- dangling (boolean - true or false, 0 or 1)\n- driver (a volume driver’s name)\n- label (`label=<key>` or `label=<key>=<value>`)\n- name (a volume’s name)\n\n#### dangling\n\nThe `dangling` filter matches on all volumes not referenced by any containers\n\n``` \n$ docker run -d  -v tyler:/tmpwork  busybox\n\nf86a7dd02898067079c99ceacd810149060a70528eff3754d0b0f1a93bd0af18\n$ docker volume ls -f dangling=true\nDRIVER              VOLUME NAME\nlocal               rosemary\n```\n\n#### driver\n\nThe `driver` filter matches volumes based on their driver.\n\nThe following example matches volumes that are created with the `local` driver:\n\n``` \n$ docker volume ls -f driver=local\n\nDRIVER              VOLUME NAME\nlocal               rosemary\nlocal               tyler\n```\n\n#### label\n\nThe `label` filter matches volumes based on the presence of a `label` alone or a `label` and a value.\n\nFirst, let’s create some volumes to illustrate this;\n\n``` \n$ docker volume create the-doctor --label is-timelord=yes\n\nthe-doctor\n$ docker volume create daleks --label is-timelord=no\n\ndaleks\n```\n\nThe following example filter matches volumes with the `is-timelord` label regardless of its value.\n\n``` \n$ docker volume ls --filter label=is-timelord\n\nDRIVER              VOLUME NAME\nlocal               daleks\nlocal               the-doctor\n```\n\nAs the above example demonstrates, both volumes with `is-timelord=yes`, and `is-timelord=no` are returned.\n\nFiltering on both `key` *and* `value` of the label, produces the expected result:\n\n``` \n$ docker volume ls --filter label=is-timelord=yes\n\nDRIVER              VOLUME NAME\nlocal               the-doctor\n```\n\nSpecifying multiple label filter produces an “and” search; all conditions should be met;\n\n``` \n$ docker volume ls --filter label=is-timelord=yes --filter label=is-timelord=no\n\nDRIVER              VOLUME NAME\n```\n\n#### name\n\nThe `name` filter matches on all or part of a volume’s name.\n\nThe following filter matches all volumes with a name containing the `rose` string.\n\n``` \n$ docker volume ls -f name=rose\n\nDRIVER              VOLUME NAME\nlocal               rosemary\n```\n\n### Formatting\n\nThe formatting options (`--format`) pretty-prints volumes output using a Go template.\n\nValid placeholders for the Go template are listed below:\n\n| Placeholder   | Description                                                                           |\n|---------------|---------------------------------------------------------------------------------------|\n| `.Name`       | Volume name                                                                           |\n| `.Driver`     | Volume driver                                                                         |\n| `.Scope`      | Volume scope (local, global)                                                          |\n| `.Mountpoint` | The mount point of the volume on the host                                             |\n| `.Labels`     | All labels assigned to the volume                                                     |\n| `.Label`      | Value of a specific label for this volume. For example `{{.Label \"project.version\"}}` |\n\nWhen using the `--format` option, the `volume ls` command will either output the data exactly as the template declares or, when using the `table` directive, includes column headers as well.\n\nThe following example uses a template without headers and outputs the `Name` and `Driver` entries separated by a colon (`:`) for all volumes:\n\n``` \n$ docker volume ls --format \"{{.Name}}: {{.Driver}}\"\n\nvol1: local\nvol2: local\nvol3: local\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker volume](../volume/index) | Manage volumes |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker volume create](../volume_create/index)   | Create a volume                                     |\n| [docker volume inspect](../volume_inspect/index) | Display detailed information on one or more volumes |\n| [docker volume ls](index)                        | List volumes                                        |\n| [docker volume prune](../volume_prune/index)     | Remove all unused local volumes                     |\n| [docker volume rm](../volume_rm/index)           | Remove one or more volumes                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/volume_ls/](https://docs.docker.com/engine/reference/commandline/volume_ls/)"
- name: Docker volume plugins
  id: engine/extend/plugins_volume/index
  summary: Docker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host
  description: "# Docker volume plugins\n\nDocker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host. See the [plugin documentation](../legacy_plugins/index) for more information.\n\n## Changelog\n\n### 1.13.0\n\n- If used as part of the v2 plugin architecture, mountpoints that are part of paths returned by the plugin must be mounted under the directory specified by `PropagatedMount` in the plugin configuration ([\\#26398](https://github.com/docker/docker/pull/26398))\n\n### 1.12.0\n\n- Add `Status` field to `VolumeDriver.Get` response ([\\#21006](https://github.com/docker/docker/pull/21006#))\n- Add `VolumeDriver.Capabilities` to get capabilities of the volume driver ([\\#22077](https://github.com/docker/docker/pull/22077))\n\n### 1.10.0\n\n- Add `VolumeDriver.Get` which gets the details about the volume ([\\#16534](https://github.com/docker/docker/pull/16534))\n- Add `VolumeDriver.List` which lists all volumes owned by the driver ([\\#16534](https://github.com/docker/docker/pull/16534))\n\n### 1.8.0\n\n- Initial support for volume driver plugins ([\\#14659](https://github.com/docker/docker/pull/14659))\n\n## Command-line changes\n\nTo give a container access to a volume, use the `--volume` and `--volume-driver` flags on the `docker container run` command. The `--volume` (or `-v`) flag accepts a volume name and path on the host, and the `--volume-driver` flag accepts a driver type.\n\n``` \n$ docker volume create --driver=flocker volumename\n\n$ docker container run -it --volume volumename:/data busybox sh\n```\n\n### `--volume`\n\nThe `--volume` (or `-v`) flag takes a value that is in the format `<volume_name>:<mountpoint>`. The two parts of the value are separated by a colon (`:`) character.\n\n- The volume name is a human-readable name for the volume, and cannot begin with a `/` character. It is referred to as `volume_name` in the rest of this topic.\n- The `Mountpoint` is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\n\n### `volumedriver`\n\nSpecifying a `volumedriver` in conjunction with a `volumename` allows you to use plugins such as [Flocker](https://github.com/ScatterHQ/flocker) to manage volumes external to a single host, such as those on EBS.\n\n## Create a VolumeDriver\n\nThe container creation endpoint (`/containers/create`) accepts a `VolumeDriver` field of type `string` allowing to specify the name of the driver. If not specified, it defaults to `\"local\"` (the default driver for local volumes).\n\n## Volume plugin protocol\n\nIf a plugin registers itself as a `VolumeDriver` when activated, it must provide the Docker Daemon with writeable paths on the host filesystem. The Docker daemon provides these paths to containers to consume. The Docker daemon makes the volumes available by bind-mounting the provided paths into the containers.\n\n> **Note**\n>\n> Volume plugins should *not* write data to the `/var/lib/docker/` directory, including `/var/lib/docker/volumes`. The `/var/lib/docker/` directory is reserved for Docker.\n\n### `/VolumeDriver.Create`\n\n**Request**:\n\n``` \n{\n    \"Name\": \"volume_name\",\n    \"Opts\": {}\n}\n```\n\nInstruct the plugin that the user wants to create a volume, given a user specified volume name. The plugin does not need to actually manifest the volume on the filesystem yet (until `Mount` is called). `Opts` is a map of driver specific options passed through from the user request.\n\n**Response**:\n\n``` \n{\n    \"Err\": \"\"\n}\n```\n\nRespond with a string error if an error occurred.\n\n### `/VolumeDriver.Remove`\n\n**Request**:\n\n``` \n{\n    \"Name\": \"volume_name\"\n}\n```\n\nDelete the specified volume from disk. This request is issued when a user invokes `docker rm -v` to remove volumes associated with a container.\n\n**Response**:\n\n``` \n{\n    \"Err\": \"\"\n}\n```\n\nRespond with a string error if an error occurred.\n\n### `/VolumeDriver.Mount`\n\n**Request**:\n\n``` \n{\n    \"Name\": \"volume_name\",\n    \"ID\": \"b87d7442095999a92b65b3d9691e697b61713829cc0ffd1bb72e4ccd51aa4d6c\"\n}\n```\n\nDocker requires the plugin to provide a volume, given a user specified volume name. `Mount` is called once per container start. If the same `volume_name` is requested more than once, the plugin may need to keep track of each new mount request and provision at the first mount request and deprovision at the last corresponding unmount request.\n\n`ID` is a unique ID for the caller that is requesting the mount.\n\n**Response**:\n\n- **v1**:\n\n  ``` \n  {\n      \"Mountpoint\": \"/path/to/directory/on/host\",\n      \"Err\": \"\"\n  }\n  ```\n\n- **v2**:\n\n  ``` \n  {\n      \"Mountpoint\": \"/path/under/PropagatedMount\",\n      \"Err\": \"\"\n  }\n  ```\n\n`Mountpoint` is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\n\n`Err` is either empty or contains an error string.\n\n### `/VolumeDriver.Path`\n\n**Request**:\n\n``` \n{\n    \"Name\": \"volume_name\"\n}\n```\n\nRequest the path to the volume with the given `volume_name`.\n\n**Response**:\n\n- **v1**:\n\n  ``` \n  {\n      \"Mountpoint\": \"/path/to/directory/on/host\",\n      \"Err\": \"\"\n  }\n  ```\n\n- **v2**:\n\n  ``` \n  {\n      \"Mountpoint\": \"/path/under/PropagatedMount\",\n      \"Err\": \"\"\n  }\n  ```\n\nRespond with the path on the host (v1) or inside the plugin (v2) where the volume has been made available, and/or a string error if an error occurred.\n\n`Mountpoint` is optional. However, the plugin may be queried again later if one is not provided.\n\n### `/VolumeDriver.Unmount`\n\n**Request**:\n\n``` \n{\n    \"Name\": \"volume_name\",\n    \"ID\": \"b87d7442095999a92b65b3d9691e697b61713829cc0ffd1bb72e4ccd51aa4d6c\"\n}\n```\n\nDocker is no longer using the named volume. `Unmount` is called once per container stop. Plugin may deduce that it is safe to deprovision the volume at this point.\n\n`ID` is a unique ID for the caller that is requesting the mount.\n\n**Response**:\n\n``` \n{\n    \"Err\": \"\"\n}\n```\n\nRespond with a string error if an error occurred.\n\n### `/VolumeDriver.Get`\n\n**Request**:\n\n``` \n{\n    \"Name\": \"volume_name\"\n}\n```\n\nGet info about `volume_name`.\n\n**Response**:\n\n- **v1**:\n\n  ``` \n  {\n    \"Volume\": {\n      \"Name\": \"volume_name\",\n      \"Mountpoint\": \"/path/to/directory/on/host\",\n      \"Status\": {}\n    },\n    \"Err\": \"\"\n  }\n  ```\n\n- **v2**:\n\n  ``` \n  {\n    \"Volume\": {\n      \"Name\": \"volume_name\",\n      \"Mountpoint\": \"/path/under/PropagatedMount\",\n      \"Status\": {}\n    },\n    \"Err\": \"\"\n  }\n  ```\n\nRespond with a string error if an error occurred. `Mountpoint` and `Status` are optional.\n\n### /VolumeDriver.List\n\n**Request**:\n\n``` \n{}\n```\n\nGet the list of volumes registered with the plugin.\n\n**Response**:\n\n- **v1**:\n\n  ``` \n  {\n    \"Volumes\": [\n      {\n        \"Name\": \"volume_name\",\n        \"Mountpoint\": \"/path/to/directory/on/host\"\n      }\n    ],\n    \"Err\": \"\"\n  }\n  ```\n\n- **v2**:\n\n  ``` \n  {\n    \"Volumes\": [\n      {\n        \"Name\": \"volume_name\",\n        \"Mountpoint\": \"/path/under/PropagatedMount\"\n      }\n    ],\n    \"Err\": \"\"\n  }\n  ```\n\nRespond with a string error if an error occurred. `Mountpoint` is optional.\n\n### /VolumeDriver.Capabilities\n\n**Request**:\n\n``` \n{}\n```\n\nGet the list of capabilities the driver supports.\n\nThe driver is not required to implement `Capabilities`. If it is not implemented, the default values are used.\n\n**Response**:\n\n``` \n{\n  \"Capabilities\": {\n    \"Scope\": \"global\"\n  }\n}\n```\n\nSupported scopes are `global` and `local`. Any other value in `Scope` will be ignored, and `local` is used. `Scope` allows cluster managers to handle the volume in different ways. For instance, a scope of `global`, signals to the cluster manager that it only needs to create the volume once instead of on each Docker host. More capabilities may be added in the future.\n\n[Examples](https://docs.docker.com/search/?q=Examples), [Usage](https://docs.docker.com/search/?q=Usage), [volume](https://docs.docker.com/search/?q=volume), [docker](https://docs.docker.com/search/?q=docker), [data](https://docs.docker.com/search/?q=data), [volumes](https://docs.docker.com/search/?q=volumes), [plugin](https://docs.docker.com/search/?q=plugin), [api](https://docs.docker.com/search/?q=api)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/plugins_volume/](https://docs.docker.com/engine/extend/plugins_volume/)"
- name: docker volume prune
  id: engine/reference/commandline/volume_prune/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker volume prune\n\n  \n\nRemove all unused local volumes\n\n## Usage\n\n``` \n$ docker volume prune [OPTIONS]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemove all unused local volumes. Unused local volumes are those which are not referenced by any containers\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                                    |\n|------------------|---------|------------------------------------------------|\n| `--filter`       |         | Provide filter values (e.g. 'label=\\<label\\>') |\n| `--force` , `-f` |         | Do not prompt for confirmation                 |\n\n## Examples\n\n``` \n$ docker volume prune\n\nWARNING! This will remove all local volumes not used by at least one container.\nAre you sure you want to continue? [y/N] y\nDeleted Volumes:\n07c7bdf3e34ab76d921894c2b834f073721fccfbbcba792aa7648e3a7a664c2e\nmy-named-vol\n\nTotal reclaimed space: 36 B\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker volume](../volume/index) | Manage volumes |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker volume create](../volume_create/index)   | Create a volume                                     |\n| [docker volume inspect](../volume_inspect/index) | Display detailed information on one or more volumes |\n| [docker volume ls](../volume_ls/index)           | List volumes                                        |\n| [docker volume prune](index)                     | Remove all unused local volumes                     |\n| [docker volume rm](../volume_rm/index)           | Remove one or more volumes                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/volume_prune/](https://docs.docker.com/engine/reference/commandline/volume_prune/)"
- name: docker volume rm
  id: engine/reference/commandline/volume_rm/index
  summary: Refer to the options section for an overview of available OPTIONS for this command
  description: "# docker volume rm\n\n  \n\nRemove one or more volumes\n\n## Usage\n\n``` \n$ docker volume rm [OPTIONS] VOLUME [VOLUME...]\n```\n\nRefer to the [options section](#options) for an overview of available [`OPTIONS`](#options) for this command.\n\n## Description\n\nRemove one or more volumes. You cannot remove a volume that is in use by a container.\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Options\n\n| Name, shorthand  | Default | Description                              |\n|------------------|---------|------------------------------------------|\n| `--force` , `-f` |         | Force the removal of one or more volumes |\n\n## Examples\n\n``` \n$ docker volume rm hello\n\nhello\n```\n\n## Parent command\n\n| Command                          | Description    |\n|:---------------------------------|:---------------|\n| [docker volume](../volume/index) | Manage volumes |\n\n## Related commands\n\n| Command                                          | Description                                         |\n|--------------------------------------------------|-----------------------------------------------------|\n| [docker volume create](../volume_create/index)   | Create a volume                                     |\n| [docker volume inspect](../volume_inspect/index) | Display detailed information on one or more volumes |\n| [docker volume ls](../volume_ls/index)           | List volumes                                        |\n| [docker volume prune](../volume_prune/index)     | Remove all unused local volumes                     |\n| [docker volume rm](index)                        | Remove one or more volumes                          |\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/volume_rm/](https://docs.docker.com/engine/reference/commandline/volume_rm/)"
- name: docker wait
  id: engine/reference/commandline/wait/index
  summary: For example uses of this command, refer to the examples section below
  description: "# docker wait\n\n  \n\nBlock until one or more containers stop, then print their exit codes\n\n## Usage\n\n``` \n$ docker wait CONTAINER [CONTAINER...]\n```\n\nFor example uses of this command, refer to the [examples section](#examples) below.\n\n## Examples\n\nStart a container in the background.\n\n``` \n$ docker run -dit --name=my_container ubuntu bash\n```\n\nRun `docker wait`, which should block until the container exits.\n\n``` \n$ docker wait my_container\n```\n\nIn another terminal, stop the first container. The `docker wait` command above returns the exit code.\n\n``` \n$ docker stop my_container\n```\n\nThis is the same `docker wait` command from above, but it now exits, returning `0`.\n\n``` \n$ docker wait my_container\n\n0\n```\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/wait/](https://docs.docker.com/engine/reference/commandline/wait/)"
- name: docker-compose config
  id: compose/reference/config/index
  summary: Validate and view the Compose file
  description: "# docker-compose config\n\n``` \nUsage: docker-compose config [options]\n\nOptions:\n    --resolve-image-digests  Pin image tags to digests.\n    --no-interpolate         Don't interpolate environment variables.\n    -q, --quiet              Only validate the configuration, don't print\n                             anything.\n    --services               Print the service names, one per line.\n    --volumes                Print the volume names, one per line.\n    --hash=\"*\"               Print the service config hash, one per line.\n                             Set \"service1,service2\" for a list of specified services\n                             or use the wildcard symbol to display all services.\n```\n\nValidate and view the Compose file.\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [cli](https://docs.docker.com/search/?q=cli), [config](https://docs.docker.com/search/?q=config)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/reference/config/](https://docs.docker.com/compose/reference/config/)"
- name: docker-compose pull
  id: compose/reference/pull/index
  summary: Pulls an image associated with a service defined in a docker-compose.yml or docker-stack.yml file, but does not start containers based on those images
  description: "# docker-compose pull\n\n``` \nUsage: docker-compose pull [options] [SERVICE...]\n\nOptions:\n    --ignore-pull-failures  Pull what it can and ignores images with pull failures.\n    --parallel              Deprecated, pull multiple images in parallel (enabled by default).\n    --no-parallel           Disable parallel pulling.\n    -q, --quiet             Pull without printing progress information\n    --include-deps          Also pull services declared as dependencies\n```\n\nPulls an image associated with a service defined in a `docker-compose.yml` or `docker-stack.yml` file, but does not start containers based on those images.\n\nFor example, suppose you have this `docker-compose.yml` file from the [Quickstart: Compose and Rails](https://docs.docker.com/samples/rails/) sample.\n\n``` \nversion: '2'\nservices:\n  db:\n    image: postgres\n  web:\n    build: .\n    command: bundle exec rails s -p 3000 -b '0.0.0.0'\n    volumes:\n      - .:/myapp\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - db\n```\n\nIf you run `docker-compose pull ServiceName` in the same directory as the `docker-compose.yml` file that defines the service, Docker pulls the associated image. For example, to call the `postgres` image configured as the `db` service in our example, you would run `docker-compose pull db`.\n\n``` \n$ docker-compose pull db\nPulling db (postgres:latest)...\nlatest: Pulling from library/postgres\ncd0a524342ef: Pull complete\n9c784d04dcb0: Pull complete\nd99dddf7e662: Pull complete\ne5bff71e3ce6: Pull complete\ncb3e0a865488: Pull complete\n31295d654cd5: Pull complete\nfc930a4e09f5: Pull complete\n8650cce8ef01: Pull complete\n61949acd8e52: Pull complete\n527a203588c0: Pull complete\n26dec14ac775: Pull complete\n0efc0ed5a9e5: Pull complete\n40cd26695b38: Pull complete\nDigest: sha256:fd6c0e2a9d053bebb294bb13765b3e01be7817bf77b01d58c2377ff27a4a46dc\nStatus: Downloaded newer image for postgres:latest\n```\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [cli](https://docs.docker.com/search/?q=cli), [pull](https://docs.docker.com/search/?q=pull)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/reference/pull/](https://docs.docker.com/compose/reference/pull/)"
- name: docker-compose stop
  id: compose/reference/stop/index
  summary: Stops running containers without removing them
  description: "# docker-compose stop\n\n``` \nUsage: docker-compose stop [options] [SERVICE...]\n\nOptions:\n  -t, --timeout TIMEOUT      Specify a shutdown timeout in seconds.\n                             (default: 10)\n```\n\nStops running containers without removing them. They can be started again with `docker-compose start`.\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [cli](https://docs.docker.com/search/?q=cli), [stop](https://docs.docker.com/search/?q=stop)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/reference/stop/](https://docs.docker.com/compose/reference/stop/)"
- name: docker-compose up
  id: compose/reference/up/index
  summary: Builds, (re)creates, starts, and attaches to containers for a service
  description: "# docker-compose up\n\n``` \nUsage: docker-compose up [options] [--scale SERVICE=NUM...] [SERVICE...]\n\nOptions:\n    -d, --detach               Detached mode: Run containers in the background,\n                               print new container names. Incompatible with\n                               --abort-on-container-exit.\n    --no-color                 Produce monochrome output.\n    --quiet-pull               Pull without printing progress information\n    --no-deps                  Don't start linked services.\n    --force-recreate           Recreate containers even if their configuration\n                               and image haven't changed.\n    --always-recreate-deps     Recreate dependent containers.\n                               Incompatible with --no-recreate.\n    --no-recreate              If containers already exist, don't recreate\n                               them. Incompatible with --force-recreate and \n                               --renew-anon-volumes.\n    --no-build                 Don't build an image, even if it's missing.\n    --no-start                 Don't start the services after creating them.\n    --build                    Build images before starting containers.\n    --abort-on-container-exit  Stops all containers if any container was\n                               stopped. Incompatible with --detach.\n    --attach-dependencies      Attach to dependent containers.\n    -t, --timeout TIMEOUT      Use this timeout in seconds for container\n                               shutdown when attached or when containers are\n                               already running. (default: 10)\n    -V, --renew-anon-volumes   Recreate anonymous volumes instead of retrieving\n                               data from the previous containers.\n    --remove-orphans           Remove containers for services not defined\n                               in the Compose file.\n    --exit-code-from SERVICE   Return the exit code of the selected service\n                               container. Implies --abort-on-container-exit.\n    --scale SERVICE=NUM        Scale SERVICE to NUM instances. Overrides the\n                               `scale` setting in the Compose file if present.\n```\n\nBuilds, (re)creates, starts, and attaches to containers for a service.\n\nUnless they are already running, this command also starts any linked services.\n\nThe `docker-compose up` command aggregates the output of each container (essentially running `docker-compose logs --follow`). When the command exits, all containers are stopped. Running `docker-compose up --detach` starts the containers in the background and leaves them running.\n\nIf there are existing containers for a service, and the service’s configuration or image was changed after the container’s creation, `docker-compose up` picks up the changes by stopping and recreating the containers (preserving mounted volumes). To prevent Compose from picking up changes, use the `--no-recreate` flag.\n\nIf you want to force Compose to stop and recreate all containers, use the `--force-recreate` flag.\n\nIf the process encounters an error, the exit code for this command is `1`.  \nIf the process is interrupted using `SIGINT` (`ctrl` + `C`) or `SIGTERM`, the containers are stopped, and the exit code is `0`.  \nIf `SIGINT` or `SIGTERM` is sent again during this shutdown phase, the running containers are killed, and the exit code is `2`.\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [cli](https://docs.docker.com/search/?q=cli), [up](https://docs.docker.com/search/?q=up)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/reference/up/](https://docs.docker.com/compose/reference/up/)"
- name: dockerd
  id: engine/reference/commandline/dockerd/index
  summary: Options with [] may be specified multiple times
  description: "# dockerd\n\n## daemon\n\n``` \nUsage: dockerd COMMAND\n\nA self-sufficient runtime for containers.\n\nOptions:\n      --add-runtime runtime                   Register an additional OCI compatible runtime (default [])\n      --allow-nondistributable-artifacts list Allow push of nondistributable artifacts to registry\n      --api-cors-header string                Set CORS headers in the Engine API\n      --authorization-plugin list             Authorization plugins to load\n      --bip string                            Specify network bridge IP\n  -b, --bridge string                         Attach containers to a network bridge\n      --cgroup-parent string                  Set parent cgroup for all containers\n      --config-file string                    Daemon configuration file (default \"/etc/docker/daemon.json\")\n      --containerd string                     containerd grpc address\n      --containerd-namespace string           Containerd namespace to use (default \"moby\")\n      --containerd-plugins-namespace string   Containerd namespace to use for plugins (default \"plugins.moby\")\n      --cpu-rt-period int                     Limit the CPU real-time period in microseconds for the\n                                              parent cgroup for all containers\n      --cpu-rt-runtime int                    Limit the CPU real-time runtime in microseconds for the\n                                              parent cgroup for all containers\n      --cri-containerd                        start containerd with cri\n      --data-root string                      Root directory of persistent Docker state (default \"/var/lib/docker\")\n  -D, --debug                                 Enable debug mode\n      --default-address-pool pool-options     Default address pools for node specific local networks\n      --default-cgroupns-mode string          Default mode for containers cgroup namespace (\"host\" | \"private\") (default \"host\")\n      --default-gateway ip                    Container default gateway IPv4 address\n      --default-gateway-v6 ip                 Container default gateway IPv6 address\n      --default-ipc-mode string               Default mode for containers ipc (\"shareable\" | \"private\") (default \"private\")\n      --default-runtime string                Default OCI runtime for containers (default \"runc\")\n      --default-shm-size bytes                Default shm size for containers (default 64MiB)\n      --default-ulimit ulimit                 Default ulimits for containers (default [])\n      --dns list                              DNS server to use\n      --dns-opt list                          DNS options to use\n      --dns-search list                       DNS search domains to use\n      --exec-opt list                         Runtime execution options\n      --exec-root string                      Root directory for execution state files (default \"/var/run/docker\")\n      --experimental                          Enable experimental features\n      --fixed-cidr string                     IPv4 subnet for fixed IPs\n      --fixed-cidr-v6 string                  IPv6 subnet for fixed IPs\n  -G, --group string                          Group for the unix socket (default \"docker\")\n      --help                                  Print usage\n  -H, --host list                             Daemon socket(s) to connect to\n      --host-gateway-ip ip                    IP address that the special 'host-gateway' string in --add-host resolves to.\n                                              Defaults to the IP address of the default bridge\n      --icc                                   Enable inter-container communication (default true)\n      --init                                  Run an init in the container to forward signals and reap processes\n      --init-path string                      Path to the docker-init binary\n      --insecure-registry list                Enable insecure registry communication\n      --ip ip                                 Default IP when binding container ports (default 0.0.0.0)\n      --ip-forward                            Enable net.ipv4.ip_forward (default true)\n      --ip-masq                               Enable IP masquerading (default true)\n      --iptables                              Enable addition of iptables rules (default true)\n      --ip6tables                             Enable addition of ip6tables rules (default false)\n      --ipv6                                  Enable IPv6 networking\n      --label list                            Set key=value labels to the daemon\n      --live-restore                          Enable live restore of docker when containers are still running\n      --log-driver string                     Default driver for container logs (default \"json-file\")\n  -l, --log-level string                      Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\")\n      --log-opt map                           Default log driver options for containers (default map[])\n      --max-concurrent-downloads int          Set the max concurrent downloads for each pull (default 3)\n      --max-concurrent-uploads int            Set the max concurrent uploads for each push (default 5)\n      --max-download-attempts int             Set the max download attempts for each pull (default 5)\n      --metrics-addr string                   Set default address and port to serve the metrics api on\n      --mtu int                               Set the containers network MTU\n      --network-control-plane-mtu int         Network Control plane MTU (default 1500)\n      --no-new-privileges                     Set no-new-privileges by default for new containers\n      --node-generic-resource list            Advertise user-defined resource\n      --oom-score-adjust int                  Set the oom_score_adj for the daemon (default -500)\n  -p, --pidfile string                        Path to use for daemon PID file (default \"/var/run/docker.pid\")\n      --raw-logs                              Full timestamps without ANSI coloring\n      --registry-mirror list                  Preferred Docker registry mirror\n      --rootless                              Enable rootless mode; typically used with RootlessKit\n      --seccomp-profile string                Path to seccomp profile\n      --selinux-enabled                       Enable selinux support\n      --shutdown-timeout int                  Set the default shutdown timeout (default 15)\n  -s, --storage-driver string                 Storage driver to use\n      --storage-opt list                      Storage driver options\n      --swarm-default-advertise-addr string   Set default address or interface for swarm advertised address\n      --tls                                   Use TLS; implied by --tlsverify\n      --tlscacert string                      Trust certs signed only by this CA (default \"~/.docker/ca.pem\")\n      --tlscert string                        Path to TLS certificate file (default \"~/.docker/cert.pem\")\n      --tlskey string                         Path to TLS key file (default \"~/.docker/key.pem\")\n      --tlsverify                             Use TLS and verify the remote\n      --userland-proxy                        Use userland proxy for loopback traffic (default true)\n      --userland-proxy-path string            Path to the userland proxy binary\n      --userns-remap string                   User/Group setting for user namespaces\n  -v, --version                               Print version information and quit\n```\n\nOptions with \\[\\] may be specified multiple times.\n\n## Description\n\n`dockerd` is the persistent process that manages containers. Docker uses different binaries for the daemon and client. To run the daemon you type `dockerd`.\n\nTo run the daemon with debug output, use `dockerd --debug` or add `\"debug\": true` to [the `daemon.json` file](#daemon-configuration-file).\n\n> **Enabling experimental features**\n>\n> Enable experimental features by starting `dockerd` with the `--experimental` flag or adding `\"experimental\": true` to the `daemon.json` file.\n\n### Environment variables\n\nFor easy reference, the following list of environment variables are supported by the `dockerd` command line:\n\n- `DOCKER_DRIVER` The graph driver to use.\n- `DOCKER_NOWARN_KERNEL_VERSION` Prevent warnings that your Linux kernel is unsuitable for Docker.\n- `DOCKER_RAMDISK` If set this will disable ‘pivot_root’.\n- `DOCKER_TMPDIR` Location for temporary Docker files.\n- `MOBY_DISABLE_PIGZ` Do not use [`unpigz`](https://linux.die.net/man/1/pigz) to decompress layers in parallel when pulling images, even if it is installed.\n\n## Examples\n\n### Daemon socket option\n\nThe Docker daemon can listen for [Docker Engine API](../../../api/index) requests via three different types of Socket: `unix`, `tcp`, and `fd`.\n\nBy default, a `unix` domain socket (or IPC socket) is created at `/var/run/docker.sock`, requiring either `root` permission, or `docker` group membership.\n\nIf you need to access the Docker daemon remotely, you need to enable the `tcp` Socket. Beware that the default setup provides un-encrypted and un-authenticated direct access to the Docker daemon - and should be secured either using the [built in HTTPS encrypted socket](../../../security/protect-access/index), or by putting a secure web proxy in front of it. You can listen on port `2375` on all network interfaces with `-H tcp://0.0.0.0:2375`, or on a particular network interface using its IP address: `-H tcp://192.168.59.103:2375`. It is conventional to use port `2375` for un-encrypted, and port `2376` for encrypted communication with the daemon.\n\n> **Note**\n>\n> If you’re using an HTTPS encrypted socket, keep in mind that only TLS1.0 and greater are supported. Protocols SSLv3 and under are not supported anymore for security reasons.\n\nOn Systemd based systems, you can communicate with the daemon via [Systemd socket activation](https://0pointer.de/blog/projects/socket-activation.html), use `dockerd -H fd://`. Using `fd://` will work perfectly for most setups but you can also specify individual sockets: `dockerd -H fd://3`. If the specified socket activated files aren’t found, then Docker will exit. You can find examples of using Systemd socket activation with Docker and Systemd in the [Docker source tree](https://github.com/docker/docker/tree/master/contrib/init/systemd/).\n\nYou can configure the Docker daemon to listen to multiple sockets at the same time using multiple `-H` options:\n\nThe example below runs the daemon listenin on the default unix socket, and on 2 specific IP addresses on this host:\n\n``` \n$ sudo dockerd -H unix:///var/run/docker.sock -H tcp://192.168.59.106 -H tcp://10.10.10.2\n```\n\nThe Docker client will honor the `DOCKER_HOST` environment variable to set the `-H` flag for the client. Use **one** of the following commands:\n\n``` \n$ docker -H tcp://0.0.0.0:2375 ps\n```\n\n``` \n$ export DOCKER_HOST=\"tcp://0.0.0.0:2375\"\n\n$ docker ps\n```\n\nSetting the `DOCKER_TLS_VERIFY` environment variable to any value other than the empty string is equivalent to setting the `--tlsverify` flag. The following are equivalent:\n\n``` \n$ docker --tlsverify ps\n# or\n$ export DOCKER_TLS_VERIFY=1\n$ docker ps\n```\n\nThe Docker client will honor the `HTTP_PROXY`, `HTTPS_PROXY`, and `NO_PROXY` environment variables (or the lowercase versions thereof). `HTTPS_PROXY` takes precedence over `HTTP_PROXY`.\n\nThe Docker client supports connecting to a remote daemon via SSH:\n\n``` \n$ docker -H ssh://me@example.com:22 ps\n$ docker -H ssh://me@example.com ps\n$ docker -H ssh://example.com ps\n```\n\nTo use SSH connection, you need to set up `ssh` so that it can reach the remote host with public key authentication. Password authentication is not supported. If your key is protected with passphrase, you need to set up `ssh-agent`.\n\n#### Bind Docker to another host/port or a Unix socket\n\n> **Warning**\n>\n> Changing the default `docker` daemon binding to a TCP port or Unix *docker* user group will increase your security risks by allowing non-root users to gain *root* access on the host. Make sure you control access to `docker`. If you are binding to a TCP port, anyone with access to that port has full Docker access; so it is not advisable on an open network.\n\nWith `-H` it is possible to make the Docker daemon to listen on a specific IP and port. By default, it will listen on `unix:///var/run/docker.sock` to allow only local connections by the *root* user. You *could* set it to `0.0.0.0:2375` or a specific host IP to give access to everybody, but that is **not recommended** because then it is trivial for someone to gain root access to the host where the daemon is running.\n\nSimilarly, the Docker client can use `-H` to connect to a custom port. The Docker client will default to connecting to `unix:///var/run/docker.sock` on Linux, and `tcp://127.0.0.1:2376` on Windows.\n\n`-H` accepts host and port assignment in the following format:\n\n``` \ntcp://[host]:[port][path] or unix://path\n```\n\nFor example:\n\n- `tcp://` -\\> TCP connection to `127.0.0.1` on either port `2376` when TLS encryption is on, or port `2375` when communication is in plain text.\n- `tcp://host:2375` -\\> TCP connection on host:2375\n- `tcp://host:2375/path` -\\> TCP connection on host:2375 and prepend path to all requests\n- `unix://path/to/socket` -\\> Unix socket located at `path/to/socket`\n\n`-H`, when empty, will default to the same value as when no `-H` was passed in.\n\n`-H` also accepts short form for TCP bindings: `host:` or `host:port` or `:port`\n\nRun Docker in daemon mode:\n\n``` \n$ sudo <path to>/dockerd -H 0.0.0.0:5555 &\n```\n\nDownload an `ubuntu` image:\n\n``` \n$ docker -H :5555 pull ubuntu\n```\n\nYou can use multiple `-H`, for example, if you want to listen on both TCP and a Unix socket\n\n``` \n$ sudo dockerd -H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock &\n# Download an ubuntu image, use default Unix socket\n$ docker pull ubuntu\n# OR use the TCP port\n$ docker -H tcp://127.0.0.1:2375 pull ubuntu\n```\n\n### Daemon storage-driver\n\nOn Linux, the Docker daemon has support for several different image layer storage drivers: `aufs`, `devicemapper`, `btrfs`, `zfs`, `overlay`, `overlay2`, and `fuse-overlayfs`.\n\nThe `aufs` driver is the oldest, but is based on a Linux kernel patch-set that is unlikely to be merged into the main kernel. These are also known to cause some serious kernel crashes. However `aufs` allows containers to share executable and shared library memory, so is a useful choice when running thousands of containers with the same program or libraries.\n\nThe `devicemapper` driver uses thin provisioning and Copy on Write (CoW) snapshots. For each devicemapper graph location – typically `/var/lib/docker/devicemapper` – a thin pool is created based on two block devices, one for data and one for metadata. By default, these block devices are created automatically by using loopback mounts of automatically created sparse files. Refer to [Devicemapper options](#devicemapper-options) below for a way how to customize this setup. [~jpetazzo/Resizing Docker containers with the Device Mapper plugin](https://jpetazzo.github.io/2014/01/29/docker-device-mapper-resize/) article explains how to tune your existing setup without the use of options.\n\nThe `btrfs` driver is very fast for `docker build` - but like `devicemapper` does not share executable memory between devices. Use `dockerd --storage-driver btrfs --data-root /mnt/btrfs_partition`.\n\nThe `zfs` driver is probably not as fast as `btrfs` but has a longer track record on stability. Thanks to `Single Copy ARC` shared blocks between clones will be cached only once. Use `dockerd -s zfs`. To select a different zfs filesystem set `zfs.fsname` option as described in [ZFS options](#zfs-options).\n\nThe `overlay` is a very fast union filesystem. It is now merged in the main Linux kernel as of [3.18.0](https://lkml.org/lkml/2014/10/26/137). `overlay` also supports page cache sharing, this means multiple containers accessing the same file can share a single page cache entry (or entries), it makes `overlay` as efficient with memory as `aufs` driver. Call `dockerd -s overlay` to use it.\n\nThe `overlay2` uses the same fast union filesystem but takes advantage of [additional features](https://lkml.org/lkml/2015/2/11/106) added in Linux kernel 4.0 to avoid excessive inode consumption. Call `dockerd -s overlay2` to use it.\n\n> **Note**\n>\n> The `overlay` storage driver can cause excessive inode consumption (especially as the number of images grows). We recommend using the `overlay2` storage driver instead.\n\n> **Note**\n>\n> Both `overlay` and `overlay2` are currently unsupported on `btrfs` or any Copy on Write filesystem and should only be used over `ext4` partitions.\n\nThe `fuse-overlayfs` driver is similar to `overlay2` but works in userspace. The `fuse-overlayfs` driver is expected to be used for [Rootless mode](../../../security/rootless/index).\n\nOn Windows, the Docker daemon supports a single image layer storage driver depending on the image platform: `windowsfilter` for Windows images, and `lcow` for Linux containers on Windows.\n\n### Options per storage driver\n\nParticular storage-driver can be configured with options specified with `--storage-opt` flags. Options for `devicemapper` are prefixed with `dm`, options for `zfs` start with `zfs`, options for `btrfs` start with `btrfs` and options for `lcow` start with `lcow`.\n\n#### Devicemapper options\n\nThis is an example of the configuration file for devicemapper on Linux:\n\n``` \n{\n  \"storage-driver\": \"devicemapper\",\n  \"storage-opts\": [\n    \"dm.thinpooldev=/dev/mapper/thin-pool\",\n    \"dm.use_deferred_deletion=true\",\n    \"dm.use_deferred_removal=true\"\n  ]\n}\n```\n\n##### `dm.thinpooldev`\n\nSpecifies a custom block storage device to use for the thin pool.\n\nIf using a block device for device mapper storage, it is best to use `lvm` to create and manage the thin-pool volume. This volume is then handed to Docker to exclusively create snapshot volumes needed for images and containers.\n\nManaging the thin-pool outside of Engine makes for the most feature-rich method of having Docker utilize device mapper thin provisioning as the backing storage for Docker containers. The highlights of the lvm-based thin-pool management feature include: automatic or interactive thin-pool resize support, dynamically changing thin-pool features, automatic thinp metadata checking when lvm activates the thin-pool, etc.\n\nAs a fallback if no thin pool is provided, loopback files are created. Loopback is very slow, but can be used without any pre-configuration of storage. It is strongly recommended that you do not use loopback in production. Ensure your Engine daemon has a `--storage-opt dm.thinpooldev` argument provided.\n\n###### Example:\n\n``` \n$ sudo dockerd --storage-opt dm.thinpooldev=/dev/mapper/thin-pool\n```\n\n##### `dm.directlvm_device`\n\nAs an alternative to providing a thin pool as above, Docker can setup a block device for you.\n\n###### Example:\n\n``` \n$ sudo dockerd --storage-opt dm.directlvm_device=/dev/xvdf\n```\n\n##### `dm.thinp_percent`\n\nSets the percentage of passed in block device to use for storage.\n\n###### Example:\n\n``` \n$ sudo dockerd --storage-opt dm.thinp_percent=95\n```\n\n##### `dm.thinp_metapercent`\n\nSets the percentage of the passed in block device to use for metadata storage.\n\n###### Example:\n\n``` \n$ sudo dockerd --storage-opt dm.thinp_metapercent=1\n```\n\n##### `dm.thinp_autoextend_threshold`\n\nSets the value of the percentage of space used before `lvm` attempts to autoextend the available space \\[100 = disabled\\]\n\n###### Example:\n\n``` \n$ sudo dockerd --storage-opt dm.thinp_autoextend_threshold=80\n```\n\n##### `dm.thinp_autoextend_percent`\n\nSets the value percentage value to increase the thin pool by when `lvm` attempts to autoextend the available space \\[100 = disabled\\]\n\n###### Example:\n\n``` \n$ sudo dockerd --storage-opt dm.thinp_autoextend_percent=20\n```\n\n##### `dm.basesize`\n\nSpecifies the size to use when creating the base device, which limits the size of images and containers. The default value is 10G. Note, thin devices are inherently “sparse”, so a 10G device which is mostly empty doesn’t use 10 GB of space on the pool. However, the filesystem will use more space for the empty case the larger the device is.\n\nThe base device size can be increased at daemon restart which will allow all future images and containers (based on those new images) to be of the new base device size.\n\n###### Examples\n\n``` \n$ sudo dockerd --storage-opt dm.basesize=50G\n```\n\nThis will increase the base device size to 50G. The Docker daemon will throw an error if existing base device size is larger than 50G. A user can use this option to expand the base device size however shrinking is not permitted.\n\nThis value affects the system-wide “base” empty filesystem that may already be initialized and inherited by pulled images. Typically, a change to this value requires additional steps to take effect:\n\n``` \n$ sudo service docker stop\n\n$ sudo rm -rf /var/lib/docker\n\n$ sudo service docker start\n```\n\n##### `dm.loopdatasize`\n\n> **Note**\n>\n> This option configures devicemapper loopback, which should not be used in production.\n\nSpecifies the size to use when creating the loopback file for the “data” device which is used for the thin pool. The default size is 100G. The file is sparse, so it will not initially take up this much space.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.loopdatasize=200G\n```\n\n##### `dm.loopmetadatasize`\n\n> **Note**\n>\n> This option configures devicemapper loopback, which should not be used in production.\n\nSpecifies the size to use when creating the loopback file for the “metadata” device which is used for the thin pool. The default size is 2G. The file is sparse, so it will not initially take up this much space.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.loopmetadatasize=4G\n```\n\n##### `dm.fs`\n\nSpecifies the filesystem type to use for the base device. The supported options are “ext4” and “xfs”. The default is “xfs”\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.fs=ext4\n```\n\n##### `dm.mkfsarg`\n\nSpecifies extra mkfs arguments to be used when creating the base device.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt \"dm.mkfsarg=-O ^has_journal\"\n```\n\n##### `dm.mountopt`\n\nSpecifies extra mount options used when mounting the thin devices.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.mountopt=nodiscard\n```\n\n##### `dm.datadev`\n\n(Deprecated, use `dm.thinpooldev`)\n\nSpecifies a custom blockdevice to use for data for the thin pool.\n\nIf using a block device for device mapper storage, ideally both `datadev` and `metadatadev` should be specified to completely avoid using the loopback device.\n\n###### Example\n\n``` \n$ sudo dockerd \\\n      --storage-opt dm.datadev=/dev/sdb1 \\\n      --storage-opt dm.metadatadev=/dev/sdc1\n```\n\n##### `dm.metadatadev`\n\n(Deprecated, use `dm.thinpooldev`)\n\nSpecifies a custom blockdevice to use for metadata for the thin pool.\n\nFor best performance the metadata should be on a different spindle than the data, or even better on an SSD.\n\nIf setting up a new metadata pool it is required to be valid. This can be achieved by zeroing the first 4k to indicate empty metadata, like this:\n\n``` \n$ dd if=/dev/zero of=$metadata_dev bs=4096 count=1\n```\n\n###### Example\n\n``` \n$ sudo dockerd \\\n      --storage-opt dm.datadev=/dev/sdb1 \\\n      --storage-opt dm.metadatadev=/dev/sdc1\n```\n\n##### `dm.blocksize`\n\nSpecifies a custom blocksize to use for the thin pool. The default blocksize is 64K.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.blocksize=512K\n```\n\n##### `dm.blkdiscard`\n\nEnables or disables the use of `blkdiscard` when removing devicemapper devices. This is enabled by default (only) if using loopback devices and is required to resparsify the loopback file on image/container removal.\n\nDisabling this on loopback can lead to *much* faster container removal times, but will make the space used in `/var/lib/docker` directory not be returned to the system for other use when containers are removed.\n\n###### Examples\n\n``` \n$ sudo dockerd --storage-opt dm.blkdiscard=false\n```\n\n##### `dm.override_udev_sync_check`\n\nOverrides the `udev` synchronization checks between `devicemapper` and `udev`. `udev` is the device manager for the Linux kernel.\n\nTo view the `udev` sync support of a Docker daemon that is using the `devicemapper` driver, run:\n\n``` \n$ docker info\n<...>\nUdev Sync Supported: true\n<...>\n```\n\nWhen `udev` sync support is `true`, then `devicemapper` and udev can coordinate the activation and deactivation of devices for containers.\n\nWhen `udev` sync support is `false`, a race condition occurs between the`devicemapper` and `udev` during create and cleanup. The race condition results in errors and failures. (For information on these failures, see [docker#4036](https://github.com/docker/docker/issues/4036))\n\nTo allow the `docker` daemon to start, regardless of `udev` sync not being supported, set `dm.override_udev_sync_check` to true:\n\n``` \n$ sudo dockerd --storage-opt dm.override_udev_sync_check=true\n```\n\nWhen this value is `true`, the `devicemapper` continues and simply warns you the errors are happening.\n\n> **Note**\n>\n> The ideal is to pursue a `docker` daemon and environment that does support synchronizing with `udev`. For further discussion on this topic, see [docker#4036](https://github.com/docker/docker/issues/4036). Otherwise, set this flag for migrating existing Docker daemons to a daemon with a supported environment.\n\n##### `dm.use_deferred_removal`\n\nEnables use of deferred device removal if `libdm` and the kernel driver support the mechanism.\n\nDeferred device removal means that if device is busy when devices are being removed/deactivated, then a deferred removal is scheduled on device. And devices automatically go away when last user of the device exits.\n\nFor example, when a container exits, its associated thin device is removed. If that device has leaked into some other mount namespace and can’t be removed, the container exit still succeeds and this option causes the system to schedule the device for deferred removal. It does not wait in a loop trying to remove a busy device.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.use_deferred_removal=true\n```\n\n##### `dm.use_deferred_deletion`\n\nEnables use of deferred device deletion for thin pool devices. By default, thin pool device deletion is synchronous. Before a container is deleted, the Docker daemon removes any associated devices. If the storage driver can not remove a device, the container deletion fails and daemon returns.\n\n``` \nError deleting container: Error response from daemon: Cannot destroy container\n```\n\nTo avoid this failure, enable both deferred device deletion and deferred device removal on the daemon.\n\n``` \n$ sudo dockerd \\\n      --storage-opt dm.use_deferred_deletion=true \\\n      --storage-opt dm.use_deferred_removal=true\n```\n\nWith these two options enabled, if a device is busy when the driver is deleting a container, the driver marks the device as deleted. Later, when the device isn’t in use, the driver deletes it.\n\nIn general it should be safe to enable this option by default. It will help when unintentional leaking of mount point happens across multiple mount namespaces.\n\n##### `dm.min_free_space`\n\nSpecifies the min free space percent in a thin pool require for new device creation to succeed. This check applies to both free data space as well as free metadata space. Valid values are from 0% - 99%. Value 0% disables free space checking logic. If user does not specify a value for this option, the Engine uses a default value of 10%.\n\nWhenever a new a thin pool device is created (during `docker pull` or during container creation), the Engine checks if the minimum free space is available. If sufficient space is unavailable, then device creation fails and any relevant `docker` operation fails.\n\nTo recover from this error, you must create more free space in the thin pool to recover from the error. You can create free space by deleting some images and containers from the thin pool. You can also add more storage to the thin pool.\n\nTo add more space to a LVM (logical volume management) thin pool, just add more storage to the volume group container thin pool; this should automatically resolve any errors. If your configuration uses loop devices, then stop the Engine daemon, grow the size of loop files and restart the daemon to resolve the issue.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.min_free_space=10%\n```\n\n##### `dm.xfs_nospace_max_retries`\n\nSpecifies the maximum number of retries XFS should attempt to complete IO when ENOSPC (no space) error is returned by underlying storage device.\n\nBy default XFS retries infinitely for IO to finish and this can result in unkillable process. To change this behavior one can set xfs_nospace_max_retries to say 0 and XFS will not retry IO after getting ENOSPC and will shutdown filesystem.\n\n###### Example\n\n``` \n$ sudo dockerd --storage-opt dm.xfs_nospace_max_retries=0\n```\n\n##### `dm.libdm_log_level`\n\nSpecifies the maxmimum `libdm` log level that will be forwarded to the `dockerd` log (as specified by `--log-level`). This option is primarily intended for debugging problems involving `libdm`. Using values other than the defaults may cause false-positive warnings to be logged.\n\nValues specified must fall within the range of valid `libdm` log levels. At the time of writing, the following is the list of `libdm` log levels as well as their corresponding levels when output by `dockerd`.\n\n| `libdm` Level | Value | `--log-level` |\n|---------------|------:|---------------|\n| `_LOG_FATAL`  |     2 | error         |\n| `_LOG_ERR`    |     3 | error         |\n| `_LOG_WARN`   |     4 | warn          |\n| `_LOG_NOTICE` |     5 | info          |\n| `_LOG_INFO`   |     6 | info          |\n| `_LOG_DEBUG`  |     7 | debug         |\n\n###### Example\n\n``` \n$ sudo dockerd \\\n      --log-level debug \\\n      --storage-opt dm.libdm_log_level=7\n```\n\n#### ZFS options\n\n##### `zfs.fsname`\n\nSet zfs filesystem under which docker will create its own datasets. By default docker will pick up the zfs filesystem where docker graph (`/var/lib/docker`) is located.\n\n###### Example\n\n``` \n$ sudo dockerd -s zfs --storage-opt zfs.fsname=zroot/docker\n```\n\n#### Btrfs options\n\n##### `btrfs.min_space`\n\nSpecifies the minimum size to use when creating the subvolume which is used for containers. If user uses disk quota for btrfs when creating or running a container with **--storage-opt size** option, docker should ensure the **size** cannot be smaller than **btrfs.min_space**.\n\n###### Example\n\n``` \n$ sudo dockerd -s btrfs --storage-opt btrfs.min_space=10G\n```\n\n#### Overlay2 options\n\n##### `overlay2.override_kernel_check`\n\nOverrides the Linux kernel version check allowing overlay2. Support for specifying multiple lower directories needed by overlay2 was added to the Linux kernel in 4.0.0. However, some older kernel versions may be patched to add multiple lower directory support for OverlayFS. This option should only be used after verifying this support exists in the kernel. Applying this option on a kernel without this support will cause failures on mount.\n\n##### `overlay2.size`\n\nSets the default max size of the container. It is supported only when the backing fs is `xfs` and mounted with `pquota` mount option. Under these conditions the user can pass any size less then the backing fs size.\n\n###### Example\n\n``` \n$ sudo dockerd -s overlay2 --storage-opt overlay2.size=1G\n```\n\n#### Windowsfilter options\n\n##### `size`\n\nSpecifies the size to use when creating the sandbox which is used for containers. Defaults to 20G.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt size=40G\n```\n\n#### LCOW (Linux Containers on Windows) options\n\n##### `lcow.globalmode`\n\nSpecifies whether the daemon instantiates utility VM instances as required (recommended and default if omitted), or uses single global utility VM (better performance, but has security implications and not recommended for production deployments).\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.globalmode=false\n```\n\n##### `lcow.kirdpath`\n\nSpecifies the folder path to the location of a pair of kernel and initrd files used for booting a utility VM. Defaults to `%ProgramFiles%\\Linux Containers`.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.kirdpath=c:\\path\\to\\files\n```\n\n##### `lcow.kernel`\n\nSpecifies the filename of a kernel file located in the `lcow.kirdpath` path. Defaults to `bootx64.efi`.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.kernel=kernel.efi\n```\n\n##### `lcow.initrd`\n\nSpecifies the filename of an initrd file located in the `lcow.kirdpath` path. Defaults to `initrd.img`.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.initrd=myinitrd.img\n```\n\n##### `lcow.bootparameters`\n\nSpecifies additional boot parameters for booting utility VMs when in kernel/ initrd mode. Ignored if the utility VM is booting from VHD. These settings are kernel specific.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt \"lcow.bootparameters='option=value'\"\n```\n\n##### `lcow.vhdx`\n\nSpecifies a custom VHDX to boot a utility VM, as an alternate to kernel and initrd booting. Defaults to `uvm.vhdx` under `lcow.kirdpath`.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.vhdx=custom.vhdx\n```\n\n##### `lcow.timeout`\n\nSpecifies the timeout for utility VM operations in seconds. Defaults to 300.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.timeout=240\n```\n\n##### `lcow.sandboxsize`\n\nSpecifies the size in GB to use when creating the sandbox which is used for containers. Defaults to 20. Cannot be less than 20.\n\n###### Example\n\n``` \nC:\\> dockerd --storage-opt lcow.sandboxsize=40\n```\n\n### Docker runtime execution options\n\nThe Docker daemon relies on a [OCI](https://github.com/opencontainers/runtime-spec) compliant runtime (invoked via the `containerd` daemon) as its interface to the Linux kernel `namespaces`, `cgroups`, and `SELinux`.\n\nBy default, the Docker daemon automatically starts `containerd`. If you want to control `containerd` startup, manually start `containerd` and pass the path to the `containerd` socket using the `--containerd` flag. For example:\n\n``` \n$ sudo dockerd --containerd /var/run/dev/docker-containerd.sock\n```\n\nRuntimes can be registered with the daemon either via the configuration file or using the `--add-runtime` command line argument.\n\nThe following is an example adding 2 runtimes via the configuration:\n\n``` \n{\n  \"default-runtime\": \"runc\",\n  \"runtimes\": {\n    \"custom\": {\n      \"path\": \"/usr/local/bin/my-runc-replacement\",\n      \"runtimeArgs\": [\n        \"--debug\"\n      ]\n    },\n    \"runc\": {\n      \"path\": \"runc\"\n    }\n  }\n}\n```\n\nThis is the same example via the command line:\n\n``` \n$ sudo dockerd --add-runtime runc=runc --add-runtime custom=/usr/local/bin/my-runc-replacement\n```\n\n> **Note**\n>\n> Defining runtime arguments via the command line is not supported.\n\n#### Options for the runtime\n\nYou can configure the runtime using options specified with the `--exec-opt` flag. All the flag’s options have the `native` prefix. A single `native.cgroupdriver` option is available.\n\nThe `native.cgroupdriver` option specifies the management of the container’s cgroups. You can only specify `cgroupfs` or `systemd`. If you specify `systemd` and it is not available, the system errors out. If you omit the `native.cgroupdriver` option,`cgroupfs` is used on cgroup v1 hosts, `systemd` is used on cgroup v2 hosts with systemd available.\n\nThis example sets the `cgroupdriver` to `systemd`:\n\n``` \n$ sudo dockerd --exec-opt native.cgroupdriver=systemd\n```\n\nSetting this option applies to all containers the daemon launches.\n\nAlso Windows Container makes use of `--exec-opt` for special purpose. Docker user can specify default container isolation technology with this, for example:\n\n``` \n> dockerd --exec-opt isolation=hyperv\n```\n\nWill make `hyperv` the default isolation technology on Windows. If no isolation value is specified on daemon start, on Windows client, the default is `hyperv`, and on Windows server, the default is `process`.\n\n### Daemon DNS options\n\nTo set the DNS server for all Docker containers, use:\n\n``` \n$ sudo dockerd --dns 8.8.8.8\n```\n\nTo set the DNS search domain for all Docker containers, use:\n\n``` \n$ sudo dockerd --dns-search example.com\n```\n\n### Allow push of nondistributable artifacts\n\nSome images (e.g., Windows base images) contain artifacts whose distribution is restricted by license. When these images are pushed to a registry, restricted artifacts are not included.\n\nTo override this behavior for specific registries, use the `--allow-nondistributable-artifacts` option in one of the following forms:\n\n- `--allow-nondistributable-artifacts myregistry:5000` tells the Docker daemon to push nondistributable artifacts to myregistry:5000.\n- `--allow-nondistributable-artifacts 10.1.0.0/16` tells the Docker daemon to push nondistributable artifacts to all registries whose resolved IP address is within the subnet described by the CIDR syntax.\n\nThis option can be used multiple times.\n\nThis option is useful when pushing images containing nondistributable artifacts to a registry on an air-gapped network so hosts on that network can pull the images without connecting to another server.\n\n> **Warning**: Nondistributable artifacts typically have restrictions on how and where they can be distributed and shared. Only use this feature to push artifacts to private registries and ensure that you are in compliance with any terms that cover redistributing nondistributable artifacts.\n\n### Insecure registries\n\nDocker considers a private registry either secure or insecure. In the rest of this section, *registry* is used for *private registry*, and `myregistry:5000` is a placeholder example for a private registry.\n\nA secure registry uses TLS and a copy of its CA certificate is placed on the Docker host at `/etc/docker/certs.d/myregistry:5000/ca.crt`. An insecure registry is either not using TLS (i.e., listening on plain text HTTP), or is using TLS with a CA certificate not known by the Docker daemon. The latter can happen when the certificate was not found under `/etc/docker/certs.d/myregistry:5000/`, or if the certificate verification failed (i.e., wrong CA).\n\nBy default, Docker assumes all, but local (see local registries below), registries are secure. Communicating with an insecure registry is not possible if Docker assumes that registry is secure. In order to communicate with an insecure registry, the Docker daemon requires `--insecure-registry` in one of the following two forms:\n\n- `--insecure-registry myregistry:5000` tells the Docker daemon that myregistry:5000 should be considered insecure.\n- `--insecure-registry 10.1.0.0/16` tells the Docker daemon that all registries whose domain resolve to an IP address is part of the subnet described by the CIDR syntax, should be considered insecure.\n\nThe flag can be used multiple times to allow multiple registries to be marked as insecure.\n\nIf an insecure registry is not marked as insecure, `docker pull`, `docker push`, and `docker search` will result in an error message prompting the user to either secure or pass the `--insecure-registry` flag to the Docker daemon as described above.\n\nLocal registries, whose IP address falls in the 127.0.0.0/8 range, are automatically marked as insecure as of Docker 1.3.2. It is not recommended to rely on this, as it may change in the future.\n\nEnabling `--insecure-registry`, i.e., allowing un-encrypted and/or untrusted communication, can be useful when running a local registry. However, because its use creates security vulnerabilities it should ONLY be enabled for testing purposes. For increased security, users should add their CA to their system’s list of trusted CAs instead of enabling `--insecure-registry`.\n\n#### Legacy Registries\n\nOperations against registries supporting only the legacy v1 protocol are no longer supported. Specifically, the daemon will not attempt `push`, `pull` and `login` to v1 registries. The exception to this is `search` which can still be performed on v1 registries.\n\n### Running a Docker daemon behind an HTTPS_PROXY\n\nWhen running inside a LAN that uses an `HTTPS` proxy, the Docker Hub certificates will be replaced by the proxy’s certificates. These certificates need to be added to your Docker host’s configuration:\n\n1.  Install the `ca-certificates` package for your distribution\n2.  Ask your network admin for the proxy’s CA certificate and append them to `/etc/pki/tls/certs/ca-bundle.crt`\n3.  Then start your Docker daemon with `HTTPS_PROXY=http://username:password@proxy:port/ dockerd`. The `username:` and `password@` are optional - and are only needed if your proxy is set up to require authentication.\n\nThis will only add the proxy and authentication to the Docker daemon’s requests - your `docker build`s and running containers will need extra configuration to use the proxy\n\n### Default `ulimit` settings\n\n`--default-ulimit` allows you to set the default `ulimit` options to use for all containers. It takes the same options as `--ulimit` for `docker run`. If these defaults are not set, `ulimit` settings will be inherited, if not set on `docker run`, from the Docker daemon. Any `--ulimit` options passed to `docker run` will overwrite these defaults.\n\nBe careful setting `nproc` with the `ulimit` flag as `nproc` is designed by Linux to set the maximum number of processes available to a user, not to a container. For details please check the [run](../run/index) reference.\n\n### Node discovery\n\nThe `--cluster-advertise` option specifies the `host:port` or `interface:port` combination that this particular daemon instance should use when advertising itself to the cluster. The daemon is reached by remote hosts through this value. If you specify an interface, make sure it includes the IP address of the actual Docker host. For Engine installation created through `docker-machine`, the interface is typically `eth1`.\n\nThe daemon uses [libkv](https://github.com/docker/libkv/) to advertise the node within the cluster. Some key-value backends support mutual TLS. To configure the client TLS settings used by the daemon can be configured using the `--cluster-store-opt` flag, specifying the paths to PEM encoded files. For example:\n\n``` \n$ sudo dockerd \\\n    --cluster-advertise 192.168.1.2:2376 \\\n    --cluster-store etcd://192.168.1.2:2379 \\\n    --cluster-store-opt kv.cacertfile=/path/to/ca.pem \\\n    --cluster-store-opt kv.certfile=/path/to/cert.pem \\\n    --cluster-store-opt kv.keyfile=/path/to/key.pem\n```\n\nThe currently supported cluster store options are:\n\n| Option                | Description                                                                                                                                                                                                                   |\n|:----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `discovery.heartbeat` | Specifies the heartbeat timer in seconds which is used by the daemon as a `keepalive` mechanism to make sure discovery module treats the node as alive in the cluster. If not configured, the default value is 20 seconds.    |\n| `discovery.ttl`       | Specifies the TTL (time-to-live) in seconds which is used by the discovery module to timeout a node if a valid heartbeat is not received within the configured ttl value. If not configured, the default value is 60 seconds. |\n| `kv.cacertfile`       | Specifies the path to a local file with PEM encoded CA certificates to trust.                                                                                                                                                 |\n| `kv.certfile`         | Specifies the path to a local file with a PEM encoded certificate. This certificate is used as the client cert for communication with the Key/Value store.                                                                    |\n| `kv.keyfile`          | Specifies the path to a local file with a PEM encoded private key. This private key is used as the client key for communication with the Key/Value store.                                                                     |\n| `kv.path`             | Specifies the path in the Key/Value store. If not configured, the default value is ‘docker/nodes’.                                                                                                                            |\n\n### Access authorization\n\nDocker’s access authorization can be extended by authorization plugins that your organization can purchase or build themselves. You can install one or more authorization plugins when you start the Docker `daemon` using the `--authorization-plugin=PLUGIN_ID` option.\n\n``` \n$ sudo dockerd --authorization-plugin=plugin1 --authorization-plugin=plugin2,...\n```\n\nThe `PLUGIN_ID` value is either the plugin’s name or a path to its specification file. The plugin’s implementation determines whether you can specify a name or path. Consult with your Docker administrator to get information about the plugins available to you.\n\nOnce a plugin is installed, requests made to the `daemon` through the command line or Docker’s Engine API are allowed or denied by the plugin. If you have multiple plugins installed, each plugin, in order, must allow the request for it to complete.\n\nFor information about how to create an authorization plugin, refer to the [authorization plugin](../../../extend/plugins_authorization/index) section.\n\n### Daemon user namespace options\n\nThe Linux kernel [user namespace support](https://man7.org/linux/man-pages/man7/user_namespaces.7.html) provides additional security by enabling a process, and therefore a container, to have a unique range of user and group IDs which are outside the traditional user and group range utilized by the host system. Potentially the most important security improvement is that, by default, container processes running as the `root` user will have expected administrative privilege (with some restrictions) inside the container but will effectively be mapped to an unprivileged `uid` on the host.\n\nFor details about how to use this feature, as well as limitations, see [Isolate containers with a user namespace](../../../security/userns-remap/index).\n\n### Miscellaneous options\n\nIP masquerading uses address translation to allow containers without a public IP to talk to other machines on the Internet. This may interfere with some network topologies and can be disabled with `--ip-masq=false`.\n\nDocker supports softlinks for the Docker data directory (`/var/lib/docker`) and for `/var/lib/docker/tmp`. The `DOCKER_TMPDIR` and the data directory can be set like this:\n\n``` \n$ DOCKER_TMPDIR=/mnt/disk2/tmp /usr/local/bin/dockerd --data-root /var/lib/docker -H unix:// > /var/lib/docker-machine/docker.log 2>&1\n```\n\nor\n\n``` \n$ export DOCKER_TMPDIR=/mnt/disk2/tmp\n$ /usr/local/bin/dockerd --data-root /var/lib/docker -H unix:// > /var/lib/docker-machine/docker.log 2>&1\n```\n\n#### Default cgroup parent\n\nThe `--cgroup-parent` option allows you to set the default cgroup parent to use for containers. If this option is not set, it defaults to `/docker` for fs cgroup driver and `system.slice` for systemd cgroup driver.\n\nIf the cgroup has a leading forward slash (`/`), the cgroup is created under the root cgroup, otherwise the cgroup is created under the daemon cgroup.\n\nAssuming the daemon is running in cgroup `daemoncgroup`, `--cgroup-parent=/foobar` creates a cgroup in `/sys/fs/cgroup/memory/foobar`, whereas using `--cgroup-parent=foobar` creates the cgroup in `/sys/fs/cgroup/memory/daemoncgroup/foobar`\n\nThe systemd cgroup driver has different rules for `--cgroup-parent`. Systemd represents hierarchy by slice and the name of the slice encodes the location in the tree. So `--cgroup-parent` for systemd cgroups should be a slice name. A name can consist of a dash-separated series of names, which describes the path to the slice from the root slice. For example, `--cgroup-parent=user-a-b.slice` means the memory cgroup for the container is created in `/sys/fs/cgroup/memory/user.slice/user-a.slice/user-a-b.slice/docker-<id>.scope`.\n\nThis setting can also be set per container, using the `--cgroup-parent` option on `docker create` and `docker run`, and takes precedence over the `--cgroup-parent` option on the daemon.\n\n#### Daemon metrics\n\nThe `--metrics-addr` option takes a tcp address to serve the metrics API. This feature is still experimental, therefore, the daemon must be running in experimental mode for this feature to work.\n\nTo serve the metrics API on `localhost:9323` you would specify `--metrics-addr 127.0.0.1:9323`, allowing you to make requests on the API at `127.0.0.1:9323/metrics` to receive metrics in the [prometheus](https://prometheus.io/docs/instrumenting/exposition_formats/) format.\n\nPort `9323` is the [default port associated with Docker metrics](https://github.com/prometheus/prometheus/wiki/Default-port-allocations) to avoid collisions with other prometheus exporters and services.\n\nIf you are running a prometheus server you can add this address to your scrape configs to have prometheus collect metrics on Docker. For more information on prometheus refer to the [prometheus website](https://prometheus.io/).\n\n``` \nscrape_configs:\n  - job_name: 'docker'\n    static_configs:\n      - targets: ['127.0.0.1:9323']\n```\n\nPlease note that this feature is still marked as experimental as metrics and metric names could change while this feature is still in experimental. Please provide feedback on what you would like to see collected in the API.\n\n#### Node Generic Resources\n\nThe `--node-generic-resources` option takes a list of key-value pair (`key=value`) that allows you to advertise user defined resources in a swarm cluster.\n\nThe current expected use case is to advertise NVIDIA GPUs so that services requesting `NVIDIA-GPU=[0-16]` can land on a node that has enough GPUs for the task to run.\n\nExample of usage:\n\n``` \n{\n  \"node-generic-resources\": [\n    \"NVIDIA-GPU=UUID1\",\n    \"NVIDIA-GPU=UUID2\"\n  ]\n}\n```\n\n### Daemon configuration file\n\nThe `--config-file` option allows you to set any configuration option for the daemon in a JSON format. This file uses the same flag names as keys, except for flags that allow several entries, where it uses the plural of the flag name, e.g., `labels` for the `label` flag.\n\nThe options set in the configuration file must not conflict with options set via flags. The docker daemon fails to start if an option is duplicated between the file and the flags, regardless their value. We do this to avoid silently ignore changes introduced in configuration reloads. For example, the daemon fails to start if you set daemon labels in the configuration file and also set daemon labels via the `--label` flag. Options that are not present in the file are ignored when the daemon starts.\n\n##### On Linux\n\nThe default location of the configuration file on Linux is `/etc/docker/daemon.json`. The `--config-file` flag can be used to specify a non-default location.\n\nThis is a full example of the allowed configuration options on Linux:\n\n``` \n{\n  \"allow-nondistributable-artifacts\": [],\n  \"api-cors-header\": \"\",\n  \"authorization-plugins\": [],\n  \"bip\": \"\",\n  \"bridge\": \"\",\n  \"cgroup-parent\": \"\",\n  \"cluster-advertise\": \"\",\n  \"cluster-store\": \"\",\n  \"cluster-store-opts\": {},\n  \"containerd\": \"/run/containerd/containerd.sock\",\n  \"containerd-namespace\": \"docker\",\n  \"containerd-plugin-namespace\": \"docker-plugins\",\n  \"data-root\": \"\",\n  \"debug\": true,\n  \"default-address-pools\": [\n    {\n      \"base\": \"172.30.0.0/16\",\n      \"size\": 24\n    },\n    {\n      \"base\": \"172.31.0.0/16\",\n      \"size\": 24\n    }\n  ],\n  \"default-cgroupns-mode\": \"private\",\n  \"default-gateway\": \"\",\n  \"default-gateway-v6\": \"\",\n  \"default-runtime\": \"runc\",\n  \"default-shm-size\": \"64M\",\n  \"default-ulimits\": {\n    \"nofile\": {\n      \"Hard\": 64000,\n      \"Name\": \"nofile\",\n      \"Soft\": 64000\n    }\n  },\n  \"dns\": [],\n  \"dns-opts\": [],\n  \"dns-search\": [],\n  \"exec-opts\": [],\n  \"exec-root\": \"\",\n  \"experimental\": false,\n  \"features\": {},\n  \"fixed-cidr\": \"\",\n  \"fixed-cidr-v6\": \"\",\n  \"group\": \"\",\n  \"hosts\": [],\n  \"icc\": false,\n  \"init\": false,\n  \"init-path\": \"/usr/libexec/docker-init\",\n  \"insecure-registries\": [],\n  \"ip\": \"0.0.0.0\",\n  \"ip-forward\": false,\n  \"ip-masq\": false,\n  \"iptables\": false,\n  \"ip6tables\": false,\n  \"ipv6\": false,\n  \"labels\": [],\n  \"live-restore\": true,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"\",\n  \"log-opts\": {\n    \"cache-disabled\": \"false\",\n    \"cache-max-file\": \"5\",\n    \"cache-max-size\": \"20m\",\n    \"cache-compress\": \"true\",\n    \"env\": \"os,customer\",\n    \"labels\": \"somelabel\",\n    \"max-file\": \"5\",\n    \"max-size\": \"10m\"\n  },\n  \"max-concurrent-downloads\": 3,\n  \"max-concurrent-uploads\": 5,\n  \"max-download-attempts\": 5,\n  \"mtu\": 0,\n  \"no-new-privileges\": false,\n  \"node-generic-resources\": [\n    \"NVIDIA-GPU=UUID1\",\n    \"NVIDIA-GPU=UUID2\"\n  ],\n  \"oom-score-adjust\": -500,\n  \"pidfile\": \"\",\n  \"raw-logs\": false,\n  \"registry-mirrors\": [],\n  \"runtimes\": {\n    \"cc-runtime\": {\n      \"path\": \"/usr/bin/cc-runtime\"\n    },\n    \"custom\": {\n      \"path\": \"/usr/local/bin/my-runc-replacement\",\n      \"runtimeArgs\": [\n        \"--debug\"\n      ]\n    }\n  },\n  \"seccomp-profile\": \"\",\n  \"selinux-enabled\": false,\n  \"shutdown-timeout\": 15,\n  \"storage-driver\": \"\",\n  \"storage-opts\": [],\n  \"swarm-default-advertise-addr\": \"\",\n  \"tls\": true,\n  \"tlscacert\": \"\",\n  \"tlscert\": \"\",\n  \"tlskey\": \"\",\n  \"tlsverify\": true,\n  \"userland-proxy\": false,\n  \"userland-proxy-path\": \"/usr/libexec/docker-proxy\",\n  \"userns-remap\": \"\"\n}\n```\n\n> **Note:**\n>\n> You cannot set options in `daemon.json` that have already been set on daemon startup as a flag. On systems that use `systemd` to start the Docker daemon, `-H` is already set, so you cannot use the `hosts` key in `daemon.json` to add listening addresses. See [“custom Docker daemon options”](https://docs.docker.com/config/daemon/systemd/#custom-docker-daemon-options) for how to accomplish this task with a systemd drop-in file.\n\n##### On Windows\n\nThe default location of the configuration file on Windows is `%programdata%\\docker\\config\\daemon.json`. The `--config-file` flag can be used to specify a non-default location.\n\nThis is a full example of the allowed configuration options on Windows:\n\n``` \n{\n  \"allow-nondistributable-artifacts\": [],\n  \"authorization-plugins\": [],\n  \"bridge\": \"\",\n  \"cluster-advertise\": \"\",\n  \"cluster-store\": \"\",\n  \"containerd\": \"\\\\\\\\.\\\\pipe\\\\containerd-containerd\",\n  \"containerd-namespace\": \"docker\",\n  \"containerd-plugin-namespace\": \"docker-plugins\",\n  \"data-root\": \"\",\n  \"debug\": true,\n  \"default-ulimits\": {},\n  \"dns\": [],\n  \"dns-opts\": [],\n  \"dns-search\": [],\n  \"exec-opts\": [],\n  \"experimental\": false,\n  \"features\": {},\n  \"fixed-cidr\": \"\",\n  \"group\": \"\",\n  \"hosts\": [],\n  \"insecure-registries\": [],\n  \"labels\": [],\n  \"log-driver\": \"\",\n  \"log-level\": \"\",\n  \"max-concurrent-downloads\": 3,\n  \"max-concurrent-uploads\": 5,\n  \"max-download-attempts\": 5,\n  \"mtu\": 0,\n  \"pidfile\": \"\",\n  \"raw-logs\": false,\n  \"registry-mirrors\": [],\n  \"shutdown-timeout\": 15,\n  \"storage-driver\": \"\",\n  \"storage-opts\": [],\n  \"swarm-default-advertise-addr\": \"\",\n  \"tlscacert\": \"\",\n  \"tlscert\": \"\",\n  \"tlskey\": \"\",\n  \"tlsverify\": true\n}\n```\n\n#### Feature options\n\nThe optional field `features` in `daemon.json` allows users to enable or disable specific daemon features. For example, `{\"features\":{\"buildkit\": true}}` enables `buildkit` as the default docker image builder.\n\nThe list of currently supported feature options:\n\n- `buildkit`: It enables `buildkit` as default builder when set to `true` or disables it by `false`. Note that if this option is not explicitly set in the daemon config file, then it is up to the cli to determine which builder to invoke.\n\n#### Configuration reload behavior\n\nSome options can be reconfigured when the daemon is running without requiring to restart the process. We use the `SIGHUP` signal in Linux to reload, and a global event in Windows with the key `Global\\docker-daemon-config-$PID`. The options can be modified in the configuration file but still will check for conflicts with the provided flags. The daemon fails to reconfigure itself if there are conflicts, but it won’t stop execution.\n\nThe list of currently supported options that can be reconfigured is this:\n\n- `debug`: it changes the daemon to debug mode when set to true.\n- `cluster-store`: it reloads the discovery store with the new address.\n- `cluster-store-opts`: it uses the new options to reload the discovery store.\n- `cluster-advertise`: it modifies the address advertised after reloading.\n- `labels`: it replaces the daemon labels with a new set of labels.\n- `live-restore`: Enables [keeping containers alive during daemon downtime](https://docs.docker.com/config/containers/live-restore/).\n- `max-concurrent-downloads`: it updates the max concurrent downloads for each pull.\n- `max-concurrent-uploads`: it updates the max concurrent uploads for each push.\n- `max-download-attempts`: it updates the max download attempts for each pull.\n- `default-runtime`: it updates the runtime to be used if not is specified at container creation. It defaults to “default” which is the runtime shipped with the official docker packages.\n- `runtimes`: it updates the list of available OCI runtimes that can be used to run containers.\n- `authorization-plugin`: it specifies the authorization plugins to use.\n- `allow-nondistributable-artifacts`: Replaces the set of registries to which the daemon will push nondistributable artifacts with a new set of registries.\n- `insecure-registries`: it replaces the daemon insecure registries with a new set of insecure registries. If some existing insecure registries in daemon’s configuration are not in newly reloaded insecure registries, these existing ones will be removed from daemon’s config.\n- `registry-mirrors`: it replaces the daemon registry mirrors with a new set of registry mirrors. If some existing registry mirrors in daemon’s configuration are not in newly reloaded registry mirrors, these existing ones will be removed from daemon’s config.\n- `shutdown-timeout`: it replaces the daemon’s existing configuration timeout with a new timeout for shutting down all containers.\n- `features`: it explicitly enables or disables specific features.\n\nUpdating and reloading the cluster configurations such as `--cluster-store`, `--cluster-advertise` and `--cluster-store-opts` will take effect only if these configurations were not previously configured. If `--cluster-store` has been provided in flags and `cluster-advertise` not, `cluster-advertise` can be added in the configuration file without accompanied by `--cluster-store`. Configuration reload will log a warning message if it detects a change in previously configured cluster configurations.\n\n### Run multiple daemons\n\n> **Note:**\n>\n> Running multiple daemons on a single host is considered as “experimental”. The user should be aware of unsolved problems. This solution may not work properly in some cases. Solutions are currently under development and will be delivered in the near future.\n\nThis section describes how to run multiple Docker daemons on a single host. To run multiple daemons, you must configure each daemon so that it does not conflict with other daemons on the same host. You can set these options either by providing them as flags, or by using a [daemon configuration file](#daemon-configuration-file).\n\nThe following daemon options must be configured for each daemon:\n\n``` \n-b, --bridge=                          Attach containers to a network bridge\n--exec-root=/var/run/docker            Root of the Docker execdriver\n--data-root=/var/lib/docker            Root of persisted Docker data\n-p, --pidfile=/var/run/docker.pid      Path to use for daemon PID file\n-H, --host=[]                          Daemon socket(s) to connect to\n--iptables=true                        Enable addition of iptables rules\n--config-file=/etc/docker/daemon.json  Daemon configuration file\n--tlscacert=\"~/.docker/ca.pem\"         Trust certs signed only by this CA\n--tlscert=\"~/.docker/cert.pem\"         Path to TLS certificate file\n--tlskey=\"~/.docker/key.pem\"           Path to TLS key file\n```\n\nWhen your daemons use different values for these flags, you can run them on the same host without any problems. It is very important to properly understand the meaning of those options and to use them correctly.\n\n- The `-b, --bridge=` flag is set to `docker0` as default bridge network. It is created automatically when you install Docker. If you are not using the default, you must create and configure the bridge manually or just set it to ‘none’: `--bridge=none`\n- `--exec-root` is the path where the container state is stored. The default value is `/var/run/docker`. Specify the path for your running daemon here.\n- `--data-root` is the path where persisted data such as images, volumes, and cluster state are stored. The default value is `/var/lib/docker`. To avoid any conflict with other daemons, set this parameter separately for each daemon.\n- `-p, --pidfile=/var/run/docker.pid` is the path where the process ID of the daemon is stored. Specify the path for your pid file here.\n- `--host=[]` specifies where the Docker daemon will listen for client connections. If unspecified, it defaults to `/var/run/docker.sock`.\n- `--iptables=false` prevents the Docker daemon from adding iptables rules. If multiple daemons manage iptables rules, they may overwrite rules set by another daemon. Be aware that disabling this option requires you to manually add iptables rules to expose container ports. If you prevent Docker from adding iptables rules, Docker will also not add IP masquerading rules, even if you set `--ip-masq` to `true`. Without IP masquerading rules, Docker containers will not be able to connect to external hosts or the internet when using network other than default bridge.\n- `--config-file=/etc/docker/daemon.json` is the path where configuration file is stored. You can use it instead of daemon flags. Specify the path for each daemon.\n- `--tls*` Docker daemon supports `--tlsverify` mode that enforces encrypted and authenticated remote connections. The `--tls*` options enable use of specific certificates for individual daemons.\n\nExample script for a separate “bootstrap” instance of the Docker daemon without network:\n\n``` \n$ sudo dockerd \\\n        -H unix:///var/run/docker-bootstrap.sock \\\n        -p /var/run/docker-bootstrap.pid \\\n        --iptables=false \\\n        --ip-masq=false \\\n        --bridge=none \\\n        --data-root=/var/lib/docker-bootstrap \\\n        --exec-root=/var/run/docker-bootstrap\n```\n\n[container](https://docs.docker.com/search/?q=container), [daemon](https://docs.docker.com/search/?q=daemon), [runtime](https://docs.docker.com/search/?q=runtime)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/dockerd/](https://docs.docker.com/engine/reference/commandline/dockerd/)"
- name: Dockerfile reference
  id: engine/reference/builder/index
  summary: Docker can build images automatically by reading the instructions from a Dockerfile
  description: "# Dockerfile reference\n\nDocker can build images automatically by reading the instructions from a `Dockerfile`. A `Dockerfile` is a text document that contains all the commands a user could call on the command line to assemble an image. Using `docker build` users can create an automated build that executes several command-line instructions in succession.\n\nThis page describes the commands you can use in a `Dockerfile`. When you are done reading this page, refer to the [`Dockerfile` Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) for a tip-oriented guide.\n\n## Usage\n\nThe [docker build](../commandline/build/index) command builds an image from a `Dockerfile` and a *context*. The build’s context is the set of files at a specified location `PATH` or `URL`. The `PATH` is a directory on your local filesystem. The `URL` is a Git repository location.\n\nThe build context is processed recursively. So, a `PATH` includes any subdirectories and the `URL` includes the repository and its submodules. This example shows a build command that uses the current directory (`.`) as build context:\n\n``` \n$ docker build .\n\nSending build context to Docker daemon  6.51 MB\n...\n```\n\nThe build is run by the Docker daemon, not by the CLI. The first thing a build process does is send the entire context (recursively) to the daemon. In most cases, it’s best to start with an empty directory as context and keep your Dockerfile in that directory. Add only the files needed for building the Dockerfile.\n\n> **Warning**\n>\n> Do not use your root directory, `/`, as the `PATH` for your build context, as it causes the build to transfer the entire contents of your hard drive to the Docker daemon.\n\nTo use a file in the build context, the `Dockerfile` refers to the file specified in an instruction, for example, a `COPY` instruction. To increase the build’s performance, exclude files and directories by adding a `.dockerignore` file to the context directory. For information about how to [create a `.dockerignore` file](#dockerignore-file) see the documentation on this page.\n\nTraditionally, the `Dockerfile` is called `Dockerfile` and located in the root of the context. You use the `-f` flag with `docker build` to point to a Dockerfile anywhere in your file system.\n\n``` \n$ docker build -f /path/to/a/Dockerfile .\n```\n\nYou can specify a repository and tag at which to save the new image if the build succeeds:\n\n``` \n$ docker build -t shykes/myapp .\n```\n\nTo tag the image into multiple repositories after the build, add multiple `-t` parameters when you run the `build` command:\n\n``` \n$ docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .\n```\n\nBefore the Docker daemon runs the instructions in the `Dockerfile`, it performs a preliminary validation of the `Dockerfile` and returns an error if the syntax is incorrect:\n\n``` \n$ docker build -t test/myapp .\n\n[+] Building 0.3s (2/2) FINISHED\n => [internal] load build definition from Dockerfile                       0.1s\n => => transferring dockerfile: 60B                                        0.0s\n => [internal] load .dockerignore                                          0.1s\n => => transferring context: 2B                                            0.0s\nerror: failed to solve: rpc error: code = Unknown desc = failed to solve with frontend dockerfile.v0: failed to create LLB definition:\ndockerfile parse error line 2: unknown instruction: RUNCMD\n```\n\nThe Docker daemon runs the instructions in the `Dockerfile` one-by-one, committing the result of each instruction to a new image if necessary, before finally outputting the ID of your new image. The Docker daemon will automatically clean up the context you sent.\n\nNote that each instruction is run independently, and causes a new image to be created - so `RUN cd /tmp` will not have any effect on the next instructions.\n\nWhenever possible, Docker uses a build-cache to accelerate the `docker build` process significantly. This is indicated by the `CACHED` message in the console output. (For more information, see the [`Dockerfile` best practices guide](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)):\n\n``` \n$ docker build -t svendowideit/ambassador .\n\n[+] Building 0.7s (6/6) FINISHED\n => [internal] load build definition from Dockerfile                       0.1s\n => => transferring dockerfile: 286B                                       0.0s\n => [internal] load .dockerignore                                          0.1s\n => => transferring context: 2B                                            0.0s\n => [internal] load metadata for docker.io/library/alpine:3.2              0.4s\n => CACHED [1/2] FROM docker.io/library/alpine:3.2@sha256:e9a2035f9d0d7ce  0.0s\n => CACHED [2/2] RUN apk add --no-cache socat                              0.0s\n => exporting to image                                                     0.0s\n => => exporting layers                                                    0.0s\n => => writing image sha256:1affb80ca37018ac12067fa2af38cc5bcc2a8f09963de  0.0s\n => => naming to docker.io/svendowideit/ambassador                         0.0s\n```\n\nBy default, the build cache is based on results from previous builds on the machine on which you are building. The `--cache-from` option also allows you to use a build-cache that’s distributed through an image registry refer to the [specifying external cache sources](../commandline/build/index#specifying-external-cache-sources) section in the `docker build` command reference.\n\nWhen you’re done with your build, you’re ready to look into [scanning your image with `docker scan`](../../scan/index), and [pushing your image to Docker Hub](https://docs.docker.com/docker-hub/repos/).\n\n## BuildKit\n\nStarting with version 18.09, Docker supports a new backend for executing your builds that is provided by the [moby/buildkit](https://github.com/moby/buildkit) project. The BuildKit backend provides many benefits compared to the old implementation. For example, BuildKit can:\n\n- Detect and skip executing unused build stages\n- Parallelize building independent build stages\n- Incrementally transfer only the changed files in your build context between builds\n- Detect and skip transferring unused files in your build context\n- Use external Dockerfile implementations with many new features\n- Avoid side-effects with rest of the API (intermediate images and containers)\n- Prioritize your build cache for automatic pruning\n\nTo use the BuildKit backend, you need to set an environment variable `DOCKER_BUILDKIT=1` on the CLI before invoking `docker build`.\n\nTo learn about the Dockerfile syntax available to BuildKit-based builds [refer to the documentation in the BuildKit repository](https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/syntax/).\n\n## Format\n\nHere is the format of the `Dockerfile`:\n\n``` \n# Comment\nINSTRUCTION arguments\n```\n\nThe instruction is not case-sensitive. However, convention is for them to be UPPERCASE to distinguish them from arguments more easily.\n\nDocker runs instructions in a `Dockerfile` in order. A `Dockerfile` **must begin with a `FROM` instruction**. This may be after [parser directives](#parser-directives), [comments](#format), and globally scoped [ARGs](#arg). The `FROM` instruction specifies the [*Parent Image*](https://docs.docker.com/glossary/#parent-image) from which you are building. `FROM` may only be preceded by one or more `ARG` instructions, which declare arguments that are used in `FROM` lines in the `Dockerfile`.\n\nDocker treats lines that *begin* with `#` as a comment, unless the line is a valid [parser directive](#parser-directives). A `#` marker anywhere else in a line is treated as an argument. This allows statements like:\n\n``` \n# Comment\nRUN echo 'we are running some # of cool things'\n```\n\nComment lines are removed before the Dockerfile instructions are executed, which means that the comment in the following example is not handled by the shell executing the `echo` command, and both examples below are equivalent:\n\n``` \nRUN echo hello \\\n# comment\nworld\n```\n\n``` \nRUN echo hello \\\nworld\n```\n\nLine continuation characters are not supported in comments.\n\n> **Note on whitespace**\n>\n> For backward compatibility, leading whitespace before comments (`#`) and instructions (such as `RUN`) are ignored, but discouraged. Leading whitespace is not preserved in these cases, and the following examples are therefore equivalent:\n>\n> ``` \n>         # this is a comment-line\n>     RUN echo hello\n> RUN echo world\n> ```\n>\n> ``` \n> # this is a comment-line\n> RUN echo hello\n> RUN echo world\n> ```\n>\n> Note however, that whitespace in instruction *arguments*, such as the commands following `RUN`, are preserved, so the following example prints \\` hello world\\` with leading whitespace as specified:\n>\n> ``` \n> RUN echo \"\\\n>      hello\\\n>      world\"\n> ```\n\n## Parser directives\n\nParser directives are optional, and affect the way in which subsequent lines in a `Dockerfile` are handled. Parser directives do not add layers to the build, and will not be shown as a build step. Parser directives are written as a special type of comment in the form `# directive=value`. A single directive may only be used once.\n\nOnce a comment, empty line or builder instruction has been processed, Docker no longer looks for parser directives. Instead it treats anything formatted as a parser directive as a comment and does not attempt to validate if it might be a parser directive. Therefore, all parser directives must be at the very top of a `Dockerfile`.\n\nParser directives are not case-sensitive. However, convention is for them to be lowercase. Convention is also to include a blank line following any parser directives. Line continuation characters are not supported in parser directives.\n\nDue to these rules, the following examples are all invalid:\n\nInvalid due to line continuation:\n\n``` \n# direc \\\ntive=value\n```\n\nInvalid due to appearing twice:\n\n``` \n# directive=value1\n# directive=value2\n\nFROM ImageName\n```\n\nTreated as a comment due to appearing after a builder instruction:\n\n``` \nFROM ImageName\n# directive=value\n```\n\nTreated as a comment due to appearing after a comment which is not a parser directive:\n\n``` \n# About my dockerfile\n# directive=value\nFROM ImageName\n```\n\nThe unknown directive is treated as a comment due to not being recognized. In addition, the known directive is treated as a comment due to appearing after a comment which is not a parser directive.\n\n``` \n# unknowndirective=value\n# knowndirective=value\n```\n\nNon line-breaking whitespace is permitted in a parser directive. Hence, the following lines are all treated identically:\n\n``` \n#directive=value\n# directive =value\n#   directive= value\n# directive = value\n#     dIrEcTiVe=value\n```\n\nThe following parser directives are supported:\n\n- `syntax`\n- `escape`\n\n## syntax\n\n``` \n# syntax=[remote image reference]\n```\n\nFor example:\n\n``` \n# syntax=docker/dockerfile:1\n# syntax=docker.io/docker/dockerfile:1\n# syntax=example.com/user/repo:tag@sha256:abcdef...\n```\n\nThis feature is only available when using the [BuildKit](#buildkit) backend, and is ignored when using the classic builder backend.\n\nThe syntax directive defines the location of the Dockerfile syntax that is used to build the Dockerfile. The BuildKit backend allows to seamlessly use external implementations that are distributed as Docker images and execute inside a container sandbox environment.\n\nCustom Dockerfile implementations allows you to:\n\n- Automatically get bugfixes without updating the Docker daemon\n- Make sure all users are using the same implementation to build your Dockerfile\n- Use the latest features without updating the Docker daemon\n- Try out new features or third-party features before they are integrated in the Docker daemon\n- Use [alternative build definitions, or create your own](https://github.com/moby/buildkit#exploring-llb)\n\n### Official releases\n\nDocker distributes official versions of the images that can be used for building Dockerfiles under `docker/dockerfile` repository on Docker Hub. There are two channels where new images are released: `stable` and `labs`.\n\nStable channel follows [semantic versioning](https://semver.org). For example:\n\n- `docker/dockerfile:1` - kept updated with the latest `1.x.x` minor *and* patch release\n- `docker/dockerfile:1.2` - kept updated with the latest `1.2.x` patch release, and stops receiving updates once version `1.3.0` is released.\n- `docker/dockerfile:1.2.1` - immutable: never updated\n\nWe recommend using `docker/dockerfile:1`, which always points to the latest stable release of the version 1 syntax, and receives both “minor” and “patch” updates for the version 1 release cycle. BuildKit automatically checks for updates of the syntax when performing a build, making sure you are using the most current version.\n\nIf a specific version is used, such as `1.2` or `1.2.1`, the Dockerfile needs to be updated manually to continue receiving bugfixes and new features. Old versions of the Dockerfile remain compatible with the new versions of the builder.\n\n**labs channel**\n\nThe “labs” channel provides early access to Dockerfile features that are not yet available in the stable channel. Labs channel images are released in conjunction with the stable releases, and follow the same versioning with the `-labs` suffix, for example:\n\n- `docker/dockerfile:labs` - latest release on labs channel\n- `docker/dockerfile:1-labs` - same as `dockerfile:1` in the stable channel, with labs features enabled\n- `docker/dockerfile:1.2-labs` - same as `dockerfile:1.2` in the stable channel, with labs features enabled\n- `docker/dockerfile:1.2.1-labs` - immutable: never updated. Same as `dockerfile:1.2.1` in the stable channel, with labs features enabled\n\nChoose a channel that best fits your needs; if you want to benefit from new features, use the labs channel. Images in the labs channel provide a superset of the features in the stable channel; note that `stable` features in the labs channel images follow [semantic versioning](https://semver.org), but “labs” features do not, and newer releases may not be backwards compatible, so it is recommended to use an immutable full version variant.\n\nFor documentation on “labs” features, master builds, and nightly feature releases, refer to the description in [the BuildKit source repository on GitHub](https://github.com/moby/buildkit/blob/master/README/). For a full list of available images, visit the [image repository on Docker Hub](https://hub.docker.com/r/docker/dockerfile), and the [docker/dockerfile-upstream image repository](https://hub.docker.com/r/docker/dockerfile-upstream) for development builds.\n\n## escape\n\n``` \n# escape=\\ (backslash)\n```\n\nOr\n\n``` \n# escape=` (backtick)\n```\n\nThe `escape` directive sets the character used to escape characters in a `Dockerfile`. If not specified, the default escape character is `\\`.\n\nThe escape character is used both to escape characters in a line, and to escape a newline. This allows a `Dockerfile` instruction to span multiple lines. Note that regardless of whether the `escape` parser directive is included in a `Dockerfile`, *escaping is not performed in a `RUN` command, except at the end of a line.*\n\nSetting the escape character to `` ` `` is especially useful on `Windows`, where `\\` is the directory path separator. `` ` `` is consistent with [Windows PowerShell](https://technet.microsoft.com/en-us/library/hh847755.aspx).\n\nConsider the following example which would fail in a non-obvious way on `Windows`. The second `\\` at the end of the second line would be interpreted as an escape for the newline, instead of a target of the escape from the first `\\`. Similarly, the `\\` at the end of the third line would, assuming it was actually handled as an instruction, cause it be treated as a line continuation. The result of this dockerfile is that second and third lines are considered a single instruction:\n\n``` \nFROM microsoft/nanoserver\nCOPY testfile.txt c:\\\\\nRUN dir c:\\\n```\n\nResults in:\n\n``` \nPS E:\\myproject> docker build -t cmd .\n\nSending build context to Docker daemon 3.072 kB\nStep 1/2 : FROM microsoft/nanoserver\n ---> 22738ff49c6d\nStep 2/2 : COPY testfile.txt c:\\RUN dir c:\nGetFileAttributesEx c:RUN: The system cannot find the file specified.\nPS E:\\myproject>\n```\n\nOne solution to the above would be to use `/` as the target of both the `COPY` instruction, and `dir`. However, this syntax is, at best, confusing as it is not natural for paths on `Windows`, and at worst, error prone as not all commands on `Windows` support `/` as the path separator.\n\nBy adding the `escape` parser directive, the following `Dockerfile` succeeds as expected with the use of natural platform semantics for file paths on `Windows`:\n\n``` \n# escape=`\n\nFROM microsoft/nanoserver\nCOPY testfile.txt c:\\\nRUN dir c:\\\n```\n\nResults in:\n\n``` \nPS E:\\myproject> docker build -t succeeds --no-cache=true .\n\nSending build context to Docker daemon 3.072 kB\nStep 1/3 : FROM microsoft/nanoserver\n ---> 22738ff49c6d\nStep 2/3 : COPY testfile.txt c:\\\n ---> 96655de338de\nRemoving intermediate container 4db9acbb1682\nStep 3/3 : RUN dir c:\\\n ---> Running in a2c157f842f5\n Volume in drive C has no label.\n Volume Serial Number is 7E6D-E0F7\n\n Directory of c:\\\n\n10/05/2016  05:04 PM             1,894 License.txt\n10/05/2016  02:22 PM    <DIR>          Program Files\n10/05/2016  02:14 PM    <DIR>          Program Files (x86)\n10/28/2016  11:18 AM                62 testfile.txt\n10/28/2016  11:20 AM    <DIR>          Users\n10/28/2016  11:20 AM    <DIR>          Windows\n           2 File(s)          1,956 bytes\n           4 Dir(s)  21,259,096,064 bytes free\n ---> 01c7f3bef04f\nRemoving intermediate container a2c157f842f5\nSuccessfully built 01c7f3bef04f\nPS E:\\myproject>\n```\n\n## Environment replacement\n\nEnvironment variables (declared with [the `ENV` statement](#env)) can also be used in certain instructions as variables to be interpreted by the `Dockerfile`. Escapes are also handled for including variable-like syntax into a statement literally.\n\nEnvironment variables are notated in the `Dockerfile` either with `$variable_name` or `${variable_name}`. They are treated equivalently and the brace syntax is typically used to address issues with variable names with no whitespace, like `${foo}_bar`.\n\nThe `${variable_name}` syntax also supports a few of the standard `bash` modifiers as specified below:\n\n- `${variable:-word}` indicates that if `variable` is set then the result will be that value. If `variable` is not set then `word` will be the result.\n- `${variable:+word}` indicates that if `variable` is set then `word` will be the result, otherwise the result is the empty string.\n\nIn all cases, `word` can be any string, including additional environment variables.\n\nEscaping is possible by adding a `\\` before the variable: `\\$foo` or `\\${foo}`, for example, will translate to `$foo` and `${foo}` literals respectively.\n\nExample (parsed representation is displayed after the `#`):\n\n``` \nFROM busybox\nENV FOO=/bar\nWORKDIR ${FOO}   # WORKDIR /bar\nADD . $FOO       # ADD . /bar\nCOPY \\$FOO /quux # COPY $FOO /quux\n```\n\nEnvironment variables are supported by the following list of instructions in the `Dockerfile`:\n\n- `ADD`\n- `COPY`\n- `ENV`\n- `EXPOSE`\n- `FROM`\n- `LABEL`\n- `STOPSIGNAL`\n- `USER`\n- `VOLUME`\n- `WORKDIR`\n- `ONBUILD` (when combined with one of the supported instructions above)\n\nEnvironment variable substitution will use the same value for each variable throughout the entire instruction. In other words, in this example:\n\n``` \nENV abc=hello\nENV abc=bye def=$abc\nENV ghi=$abc\n```\n\nwill result in `def` having a value of `hello`, not `bye`. However, `ghi` will have a value of `bye` because it is not part of the same instruction that set `abc` to `bye`.\n\n## .dockerignore file\n\nBefore the docker CLI sends the context to the docker daemon, it looks for a file named `.dockerignore` in the root directory of the context. If this file exists, the CLI modifies the context to exclude files and directories that match patterns in it. This helps to avoid unnecessarily sending large or sensitive files and directories to the daemon and potentially adding them to images using `ADD` or `COPY`.\n\nThe CLI interprets the `.dockerignore` file as a newline-separated list of patterns similar to the file globs of Unix shells. For the purposes of matching, the root of the context is considered to be both the working and the root directory. For example, the patterns `/foo/bar` and `foo/bar` both exclude a file or directory named `bar` in the `foo` subdirectory of `PATH` or in the root of the git repository located at `URL`. Neither excludes anything else.\n\nIf a line in `.dockerignore` file starts with `#` in column 1, then this line is considered as a comment and is ignored before interpreted by the CLI.\n\nHere is an example `.dockerignore` file:\n\n``` \n# comment\n*/temp*\n*/*/temp*\ntemp?\n```\n\nThis file causes the following build behavior:\n\n| Rule        | Behavior                                                                                                                                                                                                      |\n|:------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `# comment` | Ignored.                                                                                                                                                                                                      |\n| `*/temp*`   | Exclude files and directories whose names start with `temp` in any immediate subdirectory of the root. For example, the plain file `/somedir/temporary.txt` is excluded, as is the directory `/somedir/temp`. |\n| `*/*/temp*` | Exclude files and directories starting with `temp` from any subdirectory that is two levels below the root. For example, `/somedir/subdir/temporary.txt` is excluded.                                         |\n| `temp?`     | Exclude files and directories in the root directory whose names are a one-character extension of `temp`. For example, `/tempa` and `/tempb` are excluded.                                                     |\n\nMatching is done using Go’s [filepath.Match](https://golang.org/pkg/path/filepath#Match) rules. A preprocessing step removes leading and trailing whitespace and eliminates `.` and `..` elements using Go’s [filepath.Clean](https://golang.org/pkg/path/filepath/#Clean). Lines that are blank after preprocessing are ignored.\n\nBeyond Go’s filepath.Match rules, Docker also supports a special wildcard string `**` that matches any number of directories (including zero). For example, `**/*.go` will exclude all files that end with `.go` that are found in all directories, including the root of the build context.\n\nLines starting with `!` (exclamation mark) can be used to make exceptions to exclusions. The following is an example `.dockerignore` file that uses this mechanism:\n\n``` \n*.md\n!README.md\n```\n\nAll markdown files *except* `README.md` are excluded from the context.\n\nThe placement of `!` exception rules influences the behavior: the last line of the `.dockerignore` that matches a particular file determines whether it is included or excluded. Consider the following example:\n\n``` \n*.md\n!README*.md\nREADME-secret.md\n```\n\nNo markdown files are included in the context except README files other than `README-secret.md`.\n\nNow consider this example:\n\n``` \n*.md\nREADME-secret.md\n!README*.md\n```\n\nAll of the README files are included. The middle line has no effect because `!README*.md` matches `README-secret.md` and comes last.\n\nYou can even use the `.dockerignore` file to exclude the `Dockerfile` and `.dockerignore` files. These files are still sent to the daemon because it needs them to do its job. But the `ADD` and `COPY` instructions do not copy them to the image.\n\nFinally, you may want to specify which files to include in the context, rather than which to exclude. To achieve this, specify `*` as the first pattern, followed by one or more `!` exception patterns.\n\n> **Note**\n>\n> For historical reasons, the pattern `.` is ignored.\n\n## FROM\n\n``` \nFROM [--platform=<platform>] <image> [AS <name>]\n```\n\nOr\n\n``` \nFROM [--platform=<platform>] <image>[:<tag>] [AS <name>]\n```\n\nOr\n\n``` \nFROM [--platform=<platform>] <image>[@<digest>] [AS <name>]\n```\n\nThe `FROM` instruction initializes a new build stage and sets the [*Base Image*](https://docs.docker.com/glossary/#base-image) for subsequent instructions. As such, a valid `Dockerfile` must start with a `FROM` instruction. The image can be any valid image – it is especially easy to start by **pulling an image** from the [*Public Repositories*](https://docs.docker.com/docker-hub/repos/).\n\n- `ARG` is the only instruction that may precede `FROM` in the `Dockerfile`. See [Understand how ARG and FROM interact](#understand-how-arg-and-from-interact).\n- `FROM` can appear multiple times within a single `Dockerfile` to create multiple images or use one build stage as a dependency for another. Simply make a note of the last image ID output by the commit before each new `FROM` instruction. Each `FROM` instruction clears any state created by previous instructions.\n- Optionally a name can be given to a new build stage by adding `AS name` to the `FROM` instruction. The name can be used in subsequent `FROM` and `COPY --from=<name>` instructions to refer to the image built in this stage.\n- The `tag` or `digest` values are optional. If you omit either of them, the builder assumes a `latest` tag by default. The builder returns an error if it cannot find the `tag` value.\n\nThe optional `--platform` flag can be used to specify the platform of the image in case `FROM` references a multi-platform image. For example, `linux/amd64`, `linux/arm64`, or `windows/amd64`. By default, the target platform of the build request is used. Global build arguments can be used in the value of this flag, for example [automatic platform ARGs](#automatic-platform-args-in-the-global-scope) allow you to force a stage to native build platform (`--platform=$BUILDPLATFORM`), and use it to cross-compile to the target platform inside the stage.\n\n### Understand how ARG and FROM interact\n\n`FROM` instructions support variables that are declared by any `ARG` instructions that occur before the first `FROM`.\n\n``` \nARG  CODE_VERSION=latest\nFROM base:${CODE_VERSION}\nCMD  /code/run-app\n\nFROM extras:${CODE_VERSION}\nCMD  /code/run-extras\n```\n\nAn `ARG` declared before a `FROM` is outside of a build stage, so it can’t be used in any instruction after a `FROM`. To use the default value of an `ARG` declared before the first `FROM` use an `ARG` instruction without a value inside of a build stage:\n\n``` \nARG VERSION=latest\nFROM busybox:$VERSION\nARG VERSION\nRUN echo $VERSION > image_version\n```\n\n## RUN\n\nRUN has 2 forms:\n\n- `RUN <command>` (*shell* form, the command is run in a shell, which by default is `/bin/sh -c` on Linux or `cmd /S /C` on Windows)\n- `RUN [\"executable\", \"param1\", \"param2\"]` (*exec* form)\n\nThe `RUN` instruction will execute any commands in a new layer on top of the current image and commit the results. The resulting committed image will be used for the next step in the `Dockerfile`.\n\nLayering `RUN` instructions and generating commits conforms to the core concepts of Docker where commits are cheap and containers can be created from any point in an image’s history, much like source control.\n\nThe *exec* form makes it possible to avoid shell string munging, and to `RUN` commands using a base image that does not contain the specified shell executable.\n\nThe default shell for the *shell* form can be changed using the `SHELL` command.\n\nIn the *shell* form you can use a `\\` (backslash) to continue a single RUN instruction onto the next line. For example, consider these two lines:\n\n``` \nRUN /bin/bash -c 'source $HOME/.bashrc; \\\necho $HOME'\n```\n\nTogether they are equivalent to this single line:\n\n``` \nRUN /bin/bash -c 'source $HOME/.bashrc; echo $HOME'\n```\n\nTo use a different shell, other than ‘/bin/sh’, use the *exec* form passing in the desired shell. For example:\n\n``` \nRUN [\"/bin/bash\", \"-c\", \"echo hello\"]\n```\n\n> **Note**\n>\n> The *exec* form is parsed as a JSON array, which means that you must use double-quotes (“) around words not single-quotes (‘).\n\nUnlike the *shell* form, the *exec* form does not invoke a command shell. This means that normal shell processing does not happen. For example, `RUN [ \"echo\", \"$HOME\" ]` will not do variable substitution on `$HOME`. If you want shell processing then either use the *shell* form or execute a shell directly, for example: `RUN [ \"sh\", \"-c\", \"echo $HOME\" ]`. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.\n\n> **Note**\n>\n> In the *JSON* form, it is necessary to escape backslashes. This is particularly relevant on Windows where the backslash is the path separator. The following line would otherwise be treated as *shell* form due to not being valid JSON, and fail in an unexpected way:\n>\n> ``` \n> RUN [\"c:\\windows\\system32\\tasklist.exe\"]\n> ```\n>\n> The correct syntax for this example is:\n>\n> ``` \n> RUN [\"c:\\\\windows\\\\system32\\\\tasklist.exe\"]\n> ```\n\nThe cache for `RUN` instructions isn’t invalidated automatically during the next build. The cache for an instruction like `RUN apt-get dist-upgrade -y` will be reused during the next build. The cache for `RUN` instructions can be invalidated by using the `--no-cache` flag, for example `docker build --no-cache`.\n\nSee the [`Dockerfile` Best Practices guide](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) for more information.\n\nThe cache for `RUN` instructions can be invalidated by [`ADD`](#add) and [`COPY`](#copy) instructions.\n\n### Known issues (RUN)\n\n- [Issue 783](https://github.com/docker/docker/issues/783) is about file permissions problems that can occur when using the AUFS file system. You might notice it during an attempt to `rm` a file, for example.\n\n  For systems that have recent aufs version (i.e., `dirperm1` mount option can be set), docker will attempt to fix the issue automatically by mounting the layers with `dirperm1` option. More details on `dirperm1` option can be found at [`aufs` man page](https://github.com/sfjro/aufs3-linux/tree/aufs3.18/Documentation/filesystems/aufs)\n\n  If your system doesn’t have support for `dirperm1`, the issue describes a workaround.\n\n## CMD\n\nThe `CMD` instruction has three forms:\n\n- `CMD [\"executable\",\"param1\",\"param2\"]` (*exec* form, this is the preferred form)\n- `CMD [\"param1\",\"param2\"]` (as *default parameters to ENTRYPOINT*)\n- `CMD command param1 param2` (*shell* form)\n\nThere can only be one `CMD` instruction in a `Dockerfile`. If you list more than one `CMD` then only the last `CMD` will take effect.\n\n**The main purpose of a `CMD` is to provide defaults for an executing container.** These defaults can include an executable, or they can omit the executable, in which case you must specify an `ENTRYPOINT` instruction as well.\n\nIf `CMD` is used to provide default arguments for the `ENTRYPOINT` instruction, both the `CMD` and `ENTRYPOINT` instructions should be specified with the JSON array format.\n\n> **Note**\n>\n> The *exec* form is parsed as a JSON array, which means that you must use double-quotes (“) around words not single-quotes (‘).\n\nUnlike the *shell* form, the *exec* form does not invoke a command shell. This means that normal shell processing does not happen. For example, `CMD [ \"echo\", \"$HOME\" ]` will not do variable substitution on `$HOME`. If you want shell processing then either use the *shell* form or execute a shell directly, for example: `CMD [ \"sh\", \"-c\", \"echo $HOME\" ]`. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.\n\nWhen used in the shell or exec formats, the `CMD` instruction sets the command to be executed when running the image.\n\nIf you use the *shell* form of the `CMD`, then the `<command>` will execute in `/bin/sh -c`:\n\n``` \nFROM ubuntu\nCMD echo \"This is a test.\" | wc -\n```\n\nIf you want to **run your** `<command>` **without a shell** then you must express the command as a JSON array and give the full path to the executable. **This array form is the preferred format of `CMD`.** Any additional parameters must be individually expressed as strings in the array:\n\n``` \nFROM ubuntu\nCMD [\"/usr/bin/wc\",\"--help\"]\n```\n\nIf you would like your container to run the same executable every time, then you should consider using `ENTRYPOINT` in combination with `CMD`. See [*ENTRYPOINT*](#entrypoint).\n\nIf the user specifies arguments to `docker run` then they will override the default specified in `CMD`.\n\n> **Note**\n>\n> Do not confuse `RUN` with `CMD`. `RUN` actually runs a command and commits the result; `CMD` does not execute anything at build time, but specifies the intended command for the image.\n\n## LABEL\n\n``` \nLABEL <key>=<value> <key>=<value> <key>=<value> ...\n```\n\nThe `LABEL` instruction adds metadata to an image. A `LABEL` is a key-value pair. To include spaces within a `LABEL` value, use quotes and backslashes as you would in command-line parsing. A few usage examples:\n\n``` \nLABEL \"com.example.vendor\"=\"ACME Incorporated\"\nLABEL com.example.label-with-value=\"foo\"\nLABEL version=\"1.0\"\nLABEL description=\"This text illustrates \\\nthat label-values can span multiple lines.\"\n```\n\nAn image can have more than one label. You can specify multiple labels on a single line. Prior to Docker 1.10, this decreased the size of the final image, but this is no longer the case. You may still choose to specify multiple labels in a single instruction, in one of the following two ways:\n\n``` \nLABEL multi.label1=\"value1\" multi.label2=\"value2\" other=\"value3\"\n```\n\n``` \nLABEL multi.label1=\"value1\" \\\n      multi.label2=\"value2\" \\\n      other=\"value3\"\n```\n\nLabels included in base or parent images (images in the `FROM` line) are inherited by your image. If a label already exists but with a different value, the most-recently-applied value overrides any previously-set value.\n\nTo view an image’s labels, use the `docker image inspect` command. You can use the `--format` option to show just the labels;\n\n``` \n$ docker image inspect --format='' myimage\n```\n\n``` \n{\n  \"com.example.vendor\": \"ACME Incorporated\",\n  \"com.example.label-with-value\": \"foo\",\n  \"version\": \"1.0\",\n  \"description\": \"This text illustrates that label-values can span multiple lines.\",\n  \"multi.label1\": \"value1\",\n  \"multi.label2\": \"value2\",\n  \"other\": \"value3\"\n}\n```\n\n## MAINTAINER (deprecated)\n\n``` \nMAINTAINER <name>\n```\n\nThe `MAINTAINER` instruction sets the *Author* field of the generated images. The `LABEL` instruction is a much more flexible version of this and you should use it instead, as it enables setting any metadata you require, and can be viewed easily, for example with `docker inspect`. To set a label corresponding to the `MAINTAINER` field you could use:\n\n``` \nLABEL org.opencontainers.image.authors=\"SvenDowideit@home.org.au\"\n```\n\nThis will then be visible from `docker inspect` with the other labels.\n\n## EXPOSE\n\n``` \nEXPOSE <port> [<port>/<protocol>...]\n```\n\nThe `EXPOSE` instruction informs Docker that the container listens on the specified network ports at runtime. You can specify whether the port listens on TCP or UDP, and the default is TCP if the protocol is not specified.\n\nThe `EXPOSE` instruction does not actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published. To actually publish the port when running the container, use the `-p` flag on `docker run` to publish and map one or more ports, or the `-P` flag to publish all exposed ports and map them to high-order ports.\n\nBy default, `EXPOSE` assumes TCP. You can also specify UDP:\n\n``` \nEXPOSE 80/udp\n```\n\nTo expose on both TCP and UDP, include two lines:\n\n``` \nEXPOSE 80/tcp\nEXPOSE 80/udp\n```\n\nIn this case, if you use `-P` with `docker run`, the port will be exposed once for TCP and once for UDP. Remember that `-P` uses an ephemeral high-ordered host port on the host, so the port will not be the same for TCP and UDP.\n\nRegardless of the `EXPOSE` settings, you can override them at runtime by using the `-p` flag. For example\n\n``` \n$ docker run -p 80:80/tcp -p 80:80/udp ...\n```\n\nTo set up port redirection on the host system, see [using the -P flag](../run/index#expose-incoming-ports). The `docker network` command supports creating networks for communication among containers without the need to expose or publish specific ports, because the containers connected to the network can communicate with each other over any port. For detailed information, see the [overview of this feature](https://docs.docker.com/network/).\n\n## ENV\n\n``` \nENV <key>=<value> ...\n```\n\nThe `ENV` instruction sets the environment variable `<key>` to the value `<value>`. This value will be in the environment for all subsequent instructions in the build stage and can be [replaced inline](#environment-replacement) in many as well. The value will be interpreted for other environment variables, so quote characters will be removed if they are not escaped. Like command line parsing, quotes and backslashes can be used to include spaces within values.\n\nExample:\n\n``` \nENV MY_NAME=\"John Doe\"\nENV MY_DOG=Rex\\ The\\ Dog\nENV MY_CAT=fluffy\n```\n\nThe `ENV` instruction allows for multiple `<key>=<value> ...` variables to be set at one time, and the example below will yield the same net results in the final image:\n\n``` \nENV MY_NAME=\"John Doe\" MY_DOG=Rex\\ The\\ Dog \\\n    MY_CAT=fluffy\n```\n\nThe environment variables set using `ENV` will persist when a container is run from the resulting image. You can view the values using `docker inspect`, and change them using `docker run --env <key>=<value>`.\n\nEnvironment variable persistence can cause unexpected side effects. For example, setting `ENV DEBIAN_FRONTEND=noninteractive` changes the behavior of `apt-get`, and may confuse users of your image.\n\nIf an environment variable is only needed during build, and not in the final image, consider setting a value for a single command instead:\n\n``` \nRUN DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y ...\n```\n\nOr using [`ARG`](#arg), which is not persisted in the final image:\n\n``` \nARG DEBIAN_FRONTEND=noninteractive\nRUN apt-get update && apt-get install -y ...\n```\n\n> **Alternative syntax**\n>\n> The `ENV` instruction also allows an alternative syntax `ENV <key> <value>`, omitting the `=`. For example:\n>\n> ``` \n> ENV MY_VAR my-value\n> ```\n>\n> This syntax does not allow for multiple environment-variables to be set in a single `ENV` instruction, and can be confusing. For example, the following sets a single environment variable (`ONE`) with value `\"TWO= THREE=world\"`:\n>\n> ``` \n> ENV ONE TWO= THREE=world\n> ```\n>\n> The alternative syntax is supported for backward compatibility, but discouraged for the reasons outlined above, and may be removed in a future release.\n\n## ADD\n\nADD has two forms:\n\n``` \nADD [--chown=<user>:<group>] <src>... <dest>\nADD [--chown=<user>:<group>] [\"<src>\",... \"<dest>\"]\n```\n\nThe latter form is required for paths containing whitespace.\n\n> **Note**\n>\n> The `--chown` feature is only supported on Dockerfiles used to build Linux containers, and will not work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of `/etc/passwd` and `/etc/group` for translating user and group names to IDs restricts this feature to only be viable for Linux OS-based containers.\n\nThe `ADD` instruction copies new files, directories or remote file URLs from `<src>` and adds them to the filesystem of the image at the path `<dest>`.\n\nMultiple `<src>` resources may be specified but if they are files or directories, their paths are interpreted as relative to the source of the context of the build.\n\nEach `<src>` may contain wildcards and matching will be done using Go’s [filepath.Match](https://golang.org/pkg/path/filepath#Match) rules. For example:\n\nTo add all files starting with “hom”:\n\n``` \nADD hom* /mydir/\n```\n\nIn the example below, `?` is replaced with any single character, e.g., “home.txt”.\n\n``` \nADD hom?.txt /mydir/\n```\n\nThe `<dest>` is an absolute path, or a path relative to `WORKDIR`, into which the source will be copied inside the destination container.\n\nThe example below uses a relative path, and adds “test.txt” to `<WORKDIR>/relativeDir/`:\n\n``` \nADD test.txt relativeDir/\n```\n\nWhereas this example uses an absolute path, and adds “test.txt” to `/absoluteDir/`\n\n``` \nADD test.txt /absoluteDir/\n```\n\nWhen adding files or directories that contain special characters (such as `[` and `]`), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to add a file named `arr[0].txt`, use the following;\n\n``` \nADD arr[[]0].txt /mydir/\n```\n\nAll new files and directories are created with a UID and GID of 0, unless the optional `--chown` flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the content added. The format of the `--chown` flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container’s root filesystem `/etc/passwd` and `/etc/group` files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the `--chown` flag:\n\n``` \nADD --chown=55:mygroup files* /somedir/\nADD --chown=bin files* /somedir/\nADD --chown=1 files* /somedir/\nADD --chown=10:11 files* /somedir/\n```\n\nIf the container root filesystem does not contain either `/etc/passwd` or `/etc/group` files and either user or group names are used in the `--chown` flag, the build will fail on the `ADD` operation. Using numeric IDs requires no lookup and will not depend on container root filesystem content.\n\nIn the case where `<src>` is a remote file URL, the destination will have permissions of 600. If the remote file being retrieved has an HTTP `Last-Modified` header, the timestamp from that header will be used to set the `mtime` on the destination file. However, like any other file processed during an `ADD`, `mtime` will not be included in the determination of whether or not the file has changed and the cache should be updated.\n\n> **Note**\n>\n> If you build by passing a `Dockerfile` through STDIN (`docker build - < somefile`), there is no build context, so the `Dockerfile` can only contain a URL based `ADD` instruction. You can also pass a compressed archive through STDIN: (`docker build - < archive.tar.gz`), the `Dockerfile` at the root of the archive and the rest of the archive will be used as the context of the build.\n\nIf your URL files are protected using authentication, you need to use `RUN wget`, `RUN curl` or use another tool from within the container as the `ADD` instruction does not support authentication.\n\n> **Note**\n>\n> The first encountered `ADD` instruction will invalidate the cache for all following instructions from the Dockerfile if the contents of `<src>` have changed. This includes invalidating the cache for `RUN` instructions. See the [`Dockerfile` Best Practices guide – Leverage build cache](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache) for more information.\n\n`ADD` obeys the following rules:\n\n- The `<src>` path must be inside the *context* of the build; you cannot `ADD ../something /something`, because the first step of a `docker build` is to send the context directory (and subdirectories) to the docker daemon.\n\n- If `<src>` is a URL and `<dest>` does not end with a trailing slash, then a file is downloaded from the URL and copied to `<dest>`.\n\n- If `<src>` is a URL and `<dest>` does end with a trailing slash, then the filename is inferred from the URL and the file is downloaded to `<dest>/<filename>`. For instance, `ADD http://example.com/foobar /` would create the file `/foobar`. The URL must have a nontrivial path so that an appropriate filename can be discovered in this case (`http://example.com` will not work).\n\n- If `<src>` is a directory, the entire contents of the directory are copied, including filesystem metadata.\n\n> **Note**\n>\n> The directory itself is not copied, just its contents.\n\n- If `<src>` is a *local* tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from *remote* URLs are **not** decompressed. When a directory is copied or unpacked, it has the same behavior as `tar -x`, the result is the union of:\n\n  1.  Whatever existed at the destination path and\n  2.  The contents of the source tree, with conflicts resolved in favor of “2.” on a file-by-file basis.\n\n  > **Note**\n  >\n  > Whether a file is identified as a recognized compression format or not is done solely based on the contents of the file, not the name of the file. For example, if an empty file happens to end with `.tar.gz` this will not be recognized as a compressed file and **will not** generate any kind of decompression error message, rather the file will simply be copied to the destination.\n\n- If `<src>` is any other kind of file, it is copied individually along with its metadata. In this case, if `<dest>` ends with a trailing slash `/`, it will be considered a directory and the contents of `<src>` will be written at `<dest>/base(<src>)`.\n\n- If multiple `<src>` resources are specified, either directly or due to the use of a wildcard, then `<dest>` must be a directory, and it must end with a slash `/`.\n\n- If `<dest>` does not end with a trailing slash, it will be considered a regular file and the contents of `<src>` will be written at `<dest>`.\n\n- If `<dest>` doesn’t exist, it is created along with all missing directories in its path.\n\n## COPY\n\nCOPY has two forms:\n\n``` \nCOPY [--chown=<user>:<group>] <src>... <dest>\nCOPY [--chown=<user>:<group>] [\"<src>\",... \"<dest>\"]\n```\n\nThis latter form is required for paths containing whitespace\n\n> **Note**\n>\n> The `--chown` feature is only supported on Dockerfiles used to build Linux containers, and will not work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of `/etc/passwd` and `/etc/group` for translating user and group names to IDs restricts this feature to only be viable for Linux OS-based containers.\n\nThe `COPY` instruction copies new files or directories from `<src>` and adds them to the filesystem of the container at the path `<dest>`.\n\nMultiple `<src>` resources may be specified but the paths of files and directories will be interpreted as relative to the source of the context of the build.\n\nEach `<src>` may contain wildcards and matching will be done using Go’s [filepath.Match](https://golang.org/pkg/path/filepath#Match) rules. For example:\n\nTo add all files starting with “hom”:\n\n``` \nCOPY hom* /mydir/\n```\n\nIn the example below, `?` is replaced with any single character, e.g., “home.txt”.\n\n``` \nCOPY hom?.txt /mydir/\n```\n\nThe `<dest>` is an absolute path, or a path relative to `WORKDIR`, into which the source will be copied inside the destination container.\n\nThe example below uses a relative path, and adds “test.txt” to `<WORKDIR>/relativeDir/`:\n\n``` \nCOPY test.txt relativeDir/\n```\n\nWhereas this example uses an absolute path, and adds “test.txt” to `/absoluteDir/`\n\n``` \nCOPY test.txt /absoluteDir/\n```\n\nWhen copying files or directories that contain special characters (such as `[` and `]`), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to copy a file named `arr[0].txt`, use the following;\n\n``` \nCOPY arr[[]0].txt /mydir/\n```\n\nAll new files and directories are created with a UID and GID of 0, unless the optional `--chown` flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the copied content. The format of the `--chown` flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container’s root filesystem `/etc/passwd` and `/etc/group` files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the `--chown` flag:\n\n``` \nCOPY --chown=55:mygroup files* /somedir/\nCOPY --chown=bin files* /somedir/\nCOPY --chown=1 files* /somedir/\nCOPY --chown=10:11 files* /somedir/\n```\n\nIf the container root filesystem does not contain either `/etc/passwd` or `/etc/group` files and either user or group names are used in the `--chown` flag, the build will fail on the `COPY` operation. Using numeric IDs requires no lookup and does not depend on container root filesystem content.\n\n> **Note**\n>\n> If you build using STDIN (`docker build - < somefile`), there is no build context, so `COPY` can’t be used.\n\nOptionally `COPY` accepts a flag `--from=<name>` that can be used to set the source location to a previous build stage (created with `FROM .. AS <name>`) that will be used instead of a build context sent by the user. In case a build stage with a specified name can’t be found an image with the same name is attempted to be used instead.\n\n`COPY` obeys the following rules:\n\n- The `<src>` path must be inside the *context* of the build; you cannot `COPY ../something /something`, because the first step of a `docker build` is to send the context directory (and subdirectories) to the docker daemon.\n\n- If `<src>` is a directory, the entire contents of the directory are copied, including filesystem metadata.\n\n> **Note**\n>\n> The directory itself is not copied, just its contents.\n\n- If `<src>` is any other kind of file, it is copied individually along with its metadata. In this case, if `<dest>` ends with a trailing slash `/`, it will be considered a directory and the contents of `<src>` will be written at `<dest>/base(<src>)`.\n\n- If multiple `<src>` resources are specified, either directly or due to the use of a wildcard, then `<dest>` must be a directory, and it must end with a slash `/`.\n\n- If `<dest>` does not end with a trailing slash, it will be considered a regular file and the contents of `<src>` will be written at `<dest>`.\n\n- If `<dest>` doesn’t exist, it is created along with all missing directories in its path.\n\n> **Note**\n>\n> The first encountered `COPY` instruction will invalidate the cache for all following instructions from the Dockerfile if the contents of `<src>` have changed. This includes invalidating the cache for `RUN` instructions. See the [`Dockerfile` Best Practices guide – Leverage build cache](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache) for more information.\n\n## ENTRYPOINT\n\nENTRYPOINT has two forms:\n\nThe *exec* form, which is the preferred form:\n\n``` \nENTRYPOINT [\"executable\", \"param1\", \"param2\"]\n```\n\nThe *shell* form:\n\n``` \nENTRYPOINT command param1 param2\n```\n\nAn `ENTRYPOINT` allows you to configure a container that will run as an executable.\n\nFor example, the following starts nginx with its default content, listening on port 80:\n\n``` \n$ docker run -i -t --rm -p 80:80 nginx\n```\n\nCommand line arguments to `docker run <image>` will be appended after all elements in an *exec* form `ENTRYPOINT`, and will override all elements specified using `CMD`. This allows arguments to be passed to the entry point, i.e., `docker run <image> -d` will pass the `-d` argument to the entry point. You can override the `ENTRYPOINT` instruction using the `docker run --entrypoint` flag.\n\nThe *shell* form prevents any `CMD` or `run` command line arguments from being used, but has the disadvantage that your `ENTRYPOINT` will be started as a subcommand of `/bin/sh -c`, which does not pass signals. This means that the executable will not be the container’s `PID 1` - and will *not* receive Unix signals - so your executable will not receive a `SIGTERM` from `docker stop <container>`.\n\nOnly the last `ENTRYPOINT` instruction in the `Dockerfile` will have an effect.\n\n### Exec form ENTRYPOINT example\n\nYou can use the *exec* form of `ENTRYPOINT` to set fairly stable default commands and arguments and then use either form of `CMD` to set additional defaults that are more likely to be changed.\n\n``` \nFROM ubuntu\nENTRYPOINT [\"top\", \"-b\"]\nCMD [\"-c\"]\n```\n\nWhen you run the container, you can see that `top` is the only process:\n\n``` \n$ docker run -it --rm --name test  top -H\n\ntop - 08:25:00 up  7:27,  0 users,  load average: 0.00, 0.01, 0.05\nThreads:   1 total,   1 running,   0 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0.1 us,  0.1 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem:   2056668 total,  1616832 used,   439836 free,    99352 buffers\nKiB Swap:  1441840 total,        0 used,  1441840 free.  1324440 cached Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND\n    1 root      20   0   19744   2336   2080 R  0.0  0.1   0:00.04 top\n```\n\nTo examine the result further, you can use `docker exec`:\n\n``` \n$ docker exec -it test ps aux\n\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  2.6  0.1  19752  2352 ?        Ss+  08:24   0:00 top -b -H\nroot         7  0.0  0.1  15572  2164 ?        R+   08:25   0:00 ps aux\n```\n\nAnd you can gracefully request `top` to shut down using `docker stop test`.\n\nThe following `Dockerfile` shows using the `ENTRYPOINT` to run Apache in the foreground (i.e., as `PID 1`):\n\n``` \nFROM debian:stable\nRUN apt-get update && apt-get install -y --force-yes apache2\nEXPOSE 80 443\nVOLUME [\"/var/www\", \"/var/log/apache2\", \"/etc/apache2\"]\nENTRYPOINT [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"]\n```\n\nIf you need to write a starter script for a single executable, you can ensure that the final executable receives the Unix signals by using `exec` and `gosu` commands:\n\n``` \n#!/usr/bin/env bash\nset -e\n\nif [ \"$1\" = 'postgres' ]; then\n    chown -R postgres \"$PGDATA\"\n\n    if [ -z \"$(ls -A \"$PGDATA\")\" ]; then\n        gosu postgres initdb\n    fi\n\n    exec gosu postgres \"$@\"\nfi\n\nexec \"$@\"\n```\n\nLastly, if you need to do some extra cleanup (or communicate with other containers) on shutdown, or are co-ordinating more than one executable, you may need to ensure that the `ENTRYPOINT` script receives the Unix signals, passes them on, and then does some more work:\n\n``` \n#!/bin/sh\n# Note: I've written this using sh so it works in the busybox container too\n\n# USE the trap if you need to also do manual cleanup after the service is stopped,\n#     or need to start multiple services in the one container\ntrap \"echo TRAPed signal\" HUP INT QUIT TERM\n\n# start service in background here\n/usr/sbin/apachectl start\n\necho \"[hit enter key to exit] or run 'docker stop <container>'\"\nread\n\n# stop service and clean up here\necho \"stopping apache\"\n/usr/sbin/apachectl stop\n\necho \"exited $0\"\n```\n\nIf you run this image with `docker run -it --rm -p 80:80 --name test apache`, you can then examine the container’s processes with `docker exec`, or `docker top`, and then ask the script to stop Apache:\n\n``` \n$ docker exec -it test ps aux\n\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.1  0.0   4448   692 ?        Ss+  00:42   0:00 /bin/sh /run.sh 123 cmd cmd2\nroot        19  0.0  0.2  71304  4440 ?        Ss   00:42   0:00 /usr/sbin/apache2 -k start\nwww-data    20  0.2  0.2 360468  6004 ?        Sl   00:42   0:00 /usr/sbin/apache2 -k start\nwww-data    21  0.2  0.2 360468  6000 ?        Sl   00:42   0:00 /usr/sbin/apache2 -k start\nroot        81  0.0  0.1  15572  2140 ?        R+   00:44   0:00 ps aux\n\n$ docker top test\n\nPID                 USER                COMMAND\n10035               root                {run.sh} /bin/sh /run.sh 123 cmd cmd2\n10054               root                /usr/sbin/apache2 -k start\n10055               33                  /usr/sbin/apache2 -k start\n10056               33                  /usr/sbin/apache2 -k start\n\n$ /usr/bin/time docker stop test\n\ntest\nreal    0m 0.27s\nuser    0m 0.03s\nsys 0m 0.03s\n```\n\n> **Note**\n>\n> You can override the `ENTRYPOINT` setting using `--entrypoint`, but this can only set the binary to *exec* (no `sh -c` will be used).\n\n> **Note**\n>\n> The *exec* form is parsed as a JSON array, which means that you must use double-quotes (“) around words not single-quotes (‘).\n\nUnlike the *shell* form, the *exec* form does not invoke a command shell. This means that normal shell processing does not happen. For example, `ENTRYPOINT [ \"echo\", \"$HOME\" ]` will not do variable substitution on `$HOME`. If you want shell processing then either use the *shell* form or execute a shell directly, for example: `ENTRYPOINT [ \"sh\", \"-c\", \"echo $HOME\" ]`. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.\n\n### Shell form ENTRYPOINT example\n\nYou can specify a plain string for the `ENTRYPOINT` and it will execute in `/bin/sh -c`. This form will use shell processing to substitute shell environment variables, and will ignore any `CMD` or `docker run` command line arguments. To ensure that `docker stop` will signal any long running `ENTRYPOINT` executable correctly, you need to remember to start it with `exec`:\n\n``` \nFROM ubuntu\nENTRYPOINT exec top -b\n```\n\nWhen you run this image, you’ll see the single `PID 1` process:\n\n``` \n$ docker run -it --rm --name test top\n\nMem: 1704520K used, 352148K free, 0K shrd, 0K buff, 140368121167873K cached\nCPU:   5% usr   0% sys   0% nic  94% idle   0% io   0% irq   0% sirq\nLoad average: 0.08 0.03 0.05 2/98 6\n  PID  PPID USER     STAT   VSZ %VSZ %CPU COMMAND\n    1     0 root     R     3164   0%   0% top -b\n```\n\nWhich exits cleanly on `docker stop`:\n\n``` \n$ /usr/bin/time docker stop test\n\ntest\nreal    0m 0.20s\nuser    0m 0.02s\nsys 0m 0.04s\n```\n\nIf you forget to add `exec` to the beginning of your `ENTRYPOINT`:\n\n``` \nFROM ubuntu\nENTRYPOINT top -b\nCMD -- --ignored-param1\n```\n\nYou can then run it (giving it a name for the next step):\n\n``` \n$ docker run -it --name test top --ignored-param2\n\ntop - 13:58:24 up 17 min,  0 users,  load average: 0.00, 0.00, 0.00\nTasks:   2 total,   1 running,   1 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 16.7 us, 33.3 sy,  0.0 ni, 50.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nMiB Mem :   1990.8 total,   1354.6 free,    231.4 used,    404.7 buff/cache\nMiB Swap:   1024.0 total,   1024.0 free,      0.0 used.   1639.8 avail Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n    1 root      20   0    2612    604    536 S   0.0   0.0   0:00.02 sh\n    6 root      20   0    5956   3188   2768 R   0.0   0.2   0:00.00 top\n```\n\nYou can see from the output of `top` that the specified `ENTRYPOINT` is not `PID 1`.\n\nIf you then run `docker stop test`, the container will not exit cleanly - the `stop` command will be forced to send a `SIGKILL` after the timeout:\n\n``` \n$ docker exec -it test ps waux\n\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.4  0.0   2612   604 pts/0    Ss+  13:58   0:00 /bin/sh -c top -b --ignored-param2\nroot         6  0.0  0.1   5956  3188 pts/0    S+   13:58   0:00 top -b\nroot         7  0.0  0.1   5884  2816 pts/1    Rs+  13:58   0:00 ps waux\n\n$ /usr/bin/time docker stop test\n\ntest\nreal    0m 10.19s\nuser    0m 0.04s\nsys 0m 0.03s\n```\n\n### Understand how CMD and ENTRYPOINT interact\n\nBoth `CMD` and `ENTRYPOINT` instructions define what command gets executed when running a container. There are few rules that describe their co-operation.\n\n1.  Dockerfile should specify at least one of `CMD` or `ENTRYPOINT` commands.\n\n2.  `ENTRYPOINT` should be defined when using the container as an executable.\n\n3.  `CMD` should be used as a way of defining default arguments for an `ENTRYPOINT` command or for executing an ad-hoc command in a container.\n\n4.  `CMD` will be overridden when running the container with alternative arguments.\n\nThe table below shows what command is executed for different `ENTRYPOINT` / `CMD` combinations:\n\n|                                  | No ENTRYPOINT              | ENTRYPOINT exec_entry p1_entry | ENTRYPOINT \\[“exec_entry”, “p1_entry”\\]        |\n|:---------------------------------|:---------------------------|:-------------------------------|:-----------------------------------------------|\n| **No CMD**                       | *error, not allowed*       | /bin/sh -c exec_entry p1_entry | exec_entry p1_entry                            |\n| **CMD \\[“exec_cmd”, “p1_cmd”\\]** | exec_cmd p1_cmd            | /bin/sh -c exec_entry p1_entry | exec_entry p1_entry exec_cmd p1_cmd            |\n| **CMD \\[“p1_cmd”, “p2_cmd”\\]**   | p1_cmd p2_cmd              | /bin/sh -c exec_entry p1_entry | exec_entry p1_entry p1_cmd p2_cmd              |\n| **CMD exec_cmd p1_cmd**          | /bin/sh -c exec_cmd p1_cmd | /bin/sh -c exec_entry p1_entry | exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd |\n\n> **Note**\n>\n> If `CMD` is defined from the base image, setting `ENTRYPOINT` will reset `CMD` to an empty value. In this scenario, `CMD` must be defined in the current image to have a value.\n\n## VOLUME\n\n``` \nVOLUME [\"/data\"]\n```\n\nThe `VOLUME` instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array, `VOLUME [\"/var/log/\"]`, or a plain string with multiple arguments, such as `VOLUME /var/log` or `VOLUME /var/log /var/db`. For more information/examples and mounting instructions via the Docker client, refer to [*Share Directories via Volumes*](https://docs.docker.com/storage/volumes/) documentation.\n\nThe `docker run` command initializes the newly created volume with any data that exists at the specified location within the base image. For example, consider the following Dockerfile snippet:\n\n``` \nFROM ubuntu\nRUN mkdir /myvol\nRUN echo \"hello world\" > /myvol/greeting\nVOLUME /myvol\n```\n\nThis Dockerfile results in an image that causes `docker run` to create a new mount point at `/myvol` and copy the `greeting` file into the newly created volume.\n\n### Notes about specifying volumes\n\nKeep the following things in mind about volumes in the `Dockerfile`.\n\n- **Volumes on Windows-based containers**: When using Windows-based containers, the destination of a volume inside the container must be one of:\n\n  - a non-existing or empty directory\n  - a drive other than `C:`\n\n- **Changing the volume from within the Dockerfile**: If any build steps change the data within the volume after it has been declared, those changes will be discarded.\n\n- **JSON formatting**: The list is parsed as a JSON array. You must enclose words with double quotes (`\"`) rather than single quotes (`'`).\n\n- **The host directory is declared at container run-time**: The host directory (the mountpoint) is, by its nature, host-dependent. This is to preserve image portability, since a given host directory can’t be guaranteed to be available on all hosts. For this reason, you can’t mount a host directory from within the Dockerfile. The `VOLUME` instruction does not support specifying a `host-dir` parameter. You must specify the mountpoint when you create or run the container.\n\n## USER\n\n``` \nUSER <user>[:<group>]\n```\n\nor\n\n``` \nUSER <UID>[:<GID>]\n```\n\nThe `USER` instruction sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any `RUN`, `CMD` and `ENTRYPOINT` instructions that follow it in the `Dockerfile`.\n\n> Note that when specifying a group for the user, the user will have *only* the specified group membership. Any other configured group memberships will be ignored.\n\n> **Warning**\n>\n> When the user doesn’t have a primary group then the image (or the next instructions) will be run with the `root` group.\n>\n> On Windows, the user must be created first if it’s not a built-in account. This can be done with the `net user` command called as part of a Dockerfile.\n\n``` \nFROM microsoft/windowsservercore\n# Create Windows user in the container\nRUN net user /add patrick\n# Set it for subsequent commands\nUSER patrick\n```\n\n## WORKDIR\n\n``` \nWORKDIR /path/to/workdir\n```\n\nThe `WORKDIR` instruction sets the working directory for any `RUN`, `CMD`, `ENTRYPOINT`, `COPY` and `ADD` instructions that follow it in the `Dockerfile`. If the `WORKDIR` doesn’t exist, it will be created even if it’s not used in any subsequent `Dockerfile` instruction.\n\nThe `WORKDIR` instruction can be used multiple times in a `Dockerfile`. If a relative path is provided, it will be relative to the path of the previous `WORKDIR` instruction. For example:\n\n``` \nWORKDIR /a\nWORKDIR b\nWORKDIR c\nRUN pwd\n```\n\nThe output of the final `pwd` command in this `Dockerfile` would be `/a/b/c`.\n\nThe `WORKDIR` instruction can resolve environment variables previously set using `ENV`. You can only use environment variables explicitly set in the `Dockerfile`. For example:\n\n``` \nENV DIRPATH=/path\nWORKDIR $DIRPATH/$DIRNAME\nRUN pwd\n```\n\nThe output of the final `pwd` command in this `Dockerfile` would be `/path/$DIRNAME`\n\nIf not specified, the default working directory is `/`. In practice, if you aren’t building a Dockerfile from scratch (`FROM scratch`), the `WORKDIR` may likely be set by the base image you’re using.\n\nTherefore, to avoid unintended operations in unknown directories, it is best practice to set your `WORKDIR` explicitly.\n\n## ARG\n\n``` \nARG <name>[=<default value>]\n```\n\nThe `ARG` instruction defines a variable that users can pass at build-time to the builder with the `docker build` command using the `--build-arg <varname>=<value>` flag. If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning.\n\n``` \n[Warning] One or more build-args [foo] were not consumed.\n```\n\nA Dockerfile may include one or more `ARG` instructions. For example, the following is a valid Dockerfile:\n\n``` \nFROM busybox\nARG user1\nARG buildno\n# ...\n```\n\n> **Warning:**\n>\n> It is not recommended to use build-time variables for passing secrets like github keys, user credentials etc. Build-time variable values are visible to any user of the image with the `docker history` command.\n>\n> Refer to the [“build images with BuildKit”](https://docs.docker.com/develop/develop-images/build_enhancements/#new-docker-build-secret-information) section to learn about secure ways to use secrets when building images.\n\n### Default values\n\nAn `ARG` instruction can optionally include a default value:\n\n``` \nFROM busybox\nARG user1=someuser\nARG buildno=1\n# ...\n```\n\nIf an `ARG` instruction has a default value and if there is no value passed at build-time, the builder uses the default.\n\n### Scope\n\nAn `ARG` variable definition comes into effect from the line on which it is defined in the `Dockerfile` not from the argument’s use on the command-line or elsewhere. For example, consider this Dockerfile:\n\n``` \nFROM busybox\nUSER ${user:-some_user}\nARG user\nUSER $user\n# ...\n```\n\nA user builds this file by calling:\n\n``` \n$ docker build --build-arg user=what_user .\n```\n\nThe `USER` at line 2 evaluates to `some_user` as the `user` variable is defined on the subsequent line 3. The `USER` at line 4 evaluates to `what_user` as `user` is defined and the `what_user` value was passed on the command line. Prior to its definition by an `ARG` instruction, any use of a variable results in an empty string.\n\nAn `ARG` instruction goes out of scope at the end of the build stage where it was defined. To use an arg in multiple stages, each stage must include the `ARG` instruction.\n\n``` \nFROM busybox\nARG SETTINGS\nRUN ./run/setup $SETTINGS\n\nFROM busybox\nARG SETTINGS\nRUN ./run/other $SETTINGS\n```\n\n### Using ARG variables\n\nYou can use an `ARG` or an `ENV` instruction to specify variables that are available to the `RUN` instruction. Environment variables defined using the `ENV` instruction always override an `ARG` instruction of the same name. Consider this Dockerfile with an `ENV` and `ARG` instruction.\n\n``` \nFROM ubuntu\nARG CONT_IMG_VER\nENV CONT_IMG_VER=v1.0.0\nRUN echo $CONT_IMG_VER\n```\n\nThen, assume this image is built with this command:\n\n``` \n$ docker build --build-arg CONT_IMG_VER=v2.0.1 .\n```\n\nIn this case, the `RUN` instruction uses `v1.0.0` instead of the `ARG` setting passed by the user:`v2.0.1` This behavior is similar to a shell script where a locally scoped variable overrides the variables passed as arguments or inherited from environment, from its point of definition.\n\nUsing the example above but a different `ENV` specification you can create more useful interactions between `ARG` and `ENV` instructions:\n\n``` \nFROM ubuntu\nARG CONT_IMG_VER\nENV CONT_IMG_VER=${CONT_IMG_VER:-v1.0.0}\nRUN echo $CONT_IMG_VER\n```\n\nUnlike an `ARG` instruction, `ENV` values are always persisted in the built image. Consider a docker build without the `--build-arg` flag:\n\n``` \n$ docker build .\n```\n\nUsing this Dockerfile example, `CONT_IMG_VER` is still persisted in the image but its value would be `v1.0.0` as it is the default set in line 3 by the `ENV` instruction.\n\nThe variable expansion technique in this example allows you to pass arguments from the command line and persist them in the final image by leveraging the `ENV` instruction. Variable expansion is only supported for [a limited set of Dockerfile instructions.](#environment-replacement)\n\n### Predefined ARGs\n\nDocker has a set of predefined `ARG` variables that you can use without a corresponding `ARG` instruction in the Dockerfile.\n\n- `HTTP_PROXY`\n- `http_proxy`\n- `HTTPS_PROXY`\n- `https_proxy`\n- `FTP_PROXY`\n- `ftp_proxy`\n- `NO_PROXY`\n- `no_proxy`\n\nTo use these, pass them on the command line using the `--build-arg` flag, for example:\n\n``` \n$ docker build --build-arg HTTPS_PROXY=https://my-proxy.example.com .\n```\n\nBy default, these pre-defined variables are excluded from the output of `docker history`. Excluding them reduces the risk of accidentally leaking sensitive authentication information in an `HTTP_PROXY` variable.\n\nFor example, consider building the following Dockerfile using `--build-arg HTTP_PROXY=http://user:pass@proxy.lon.example.com`\n\n``` \nFROM ubuntu\nRUN echo \"Hello World\"\n```\n\nIn this case, the value of the `HTTP_PROXY` variable is not available in the `docker history` and is not cached. If you were to change location, and your proxy server changed to `http://user:pass@proxy.sfo.example.com`, a subsequent build does not result in a cache miss.\n\nIf you need to override this behaviour then you may do so by adding an `ARG` statement in the Dockerfile as follows:\n\n``` \nFROM ubuntu\nARG HTTP_PROXY\nRUN echo \"Hello World\"\n```\n\nWhen building this Dockerfile, the `HTTP_PROXY` is preserved in the `docker history`, and changing its value invalidates the build cache.\n\n### Automatic platform ARGs in the global scope\n\nThis feature is only available when using the [BuildKit](#buildkit) backend.\n\nDocker predefines a set of `ARG` variables with information on the platform of the node performing the build (build platform) and on the platform of the resulting image (target platform). The target platform can be specified with the `--platform` flag on `docker build`.\n\nThe following `ARG` variables are set automatically:\n\n- `TARGETPLATFORM` - platform of the build result. Eg `linux/amd64`, `linux/arm/v7`, `windows/amd64`.\n- `TARGETOS` - OS component of TARGETPLATFORM\n- `TARGETARCH` - architecture component of TARGETPLATFORM\n- `TARGETVARIANT` - variant component of TARGETPLATFORM\n- `BUILDPLATFORM` - platform of the node performing the build.\n- `BUILDOS` - OS component of BUILDPLATFORM\n- `BUILDARCH` - architecture component of BUILDPLATFORM\n- `BUILDVARIANT` - variant component of BUILDPLATFORM\n\nThese arguments are defined in the global scope so are not automatically available inside build stages or for your `RUN` commands. To expose one of these arguments inside the build stage redefine it without value.\n\nFor example:\n\n``` \nFROM alpine\nARG TARGETPLATFORM\nRUN echo \"I'm building for $TARGETPLATFORM\"\n```\n\n### Impact on build caching\n\n`ARG` variables are not persisted into the built image as `ENV` variables are. However, `ARG` variables do impact the build cache in similar ways. If a Dockerfile defines an `ARG` variable whose value is different from a previous build, then a “cache miss” occurs upon its first usage, not its definition. In particular, all `RUN` instructions following an `ARG` instruction use the `ARG` variable implicitly (as an environment variable), thus can cause a cache miss. All predefined `ARG` variables are exempt from caching unless there is a matching `ARG` statement in the `Dockerfile`.\n\nFor example, consider these two Dockerfile:\n\n``` \nFROM ubuntu\nARG CONT_IMG_VER\nRUN echo $CONT_IMG_VER\n```\n\n``` \nFROM ubuntu\nARG CONT_IMG_VER\nRUN echo hello\n```\n\nIf you specify `--build-arg CONT_IMG_VER=<value>` on the command line, in both cases, the specification on line 2 does not cause a cache miss; line 3 does cause a cache miss.`ARG CONT_IMG_VER` causes the RUN line to be identified as the same as running `CONT_IMG_VER=<value> echo hello`, so if the `<value>` changes, we get a cache miss.\n\nConsider another example under the same command line:\n\n``` \nFROM ubuntu\nARG CONT_IMG_VER\nENV CONT_IMG_VER=$CONT_IMG_VER\nRUN echo $CONT_IMG_VER\n```\n\nIn this example, the cache miss occurs on line 3. The miss happens because the variable’s value in the `ENV` references the `ARG` variable and that variable is changed through the command line. In this example, the `ENV` command causes the image to include the value.\n\nIf an `ENV` instruction overrides an `ARG` instruction of the same name, like this Dockerfile:\n\n``` \nFROM ubuntu\nARG CONT_IMG_VER\nENV CONT_IMG_VER=hello\nRUN echo $CONT_IMG_VER\n```\n\nLine 3 does not cause a cache miss because the value of `CONT_IMG_VER` is a constant (`hello`). As a result, the environment variables and values used on the `RUN` (line 4) doesn’t change between builds.\n\n## ONBUILD\n\n``` \nONBUILD <INSTRUCTION>\n```\n\nThe `ONBUILD` instruction adds to the image a *trigger* instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the `FROM` instruction in the downstream `Dockerfile`.\n\nAny build instruction can be registered as a trigger.\n\nThis is useful if you are building an image which will be used as a base to build other images, for example an application build environment or a daemon which may be customized with user-specific configuration.\n\nFor example, if your image is a reusable Python application builder, it will require application source code to be added in a particular directory, and it might require a build script to be called *after* that. You can’t just call `ADD` and `RUN` now, because you don’t yet have access to the application source code, and it will be different for each application build. You could simply provide application developers with a boilerplate `Dockerfile` to copy-paste into their application, but that is inefficient, error-prone and difficult to update because it mixes with application-specific code.\n\nThe solution is to use `ONBUILD` to register advance instructions to run later, during the next build stage.\n\nHere’s how it works:\n\n1.  When it encounters an `ONBUILD` instruction, the builder adds a trigger to the metadata of the image being built. The instruction does not otherwise affect the current build.\n2.  At the end of the build, a list of all triggers is stored in the image manifest, under the key `OnBuild`. They can be inspected with the `docker inspect` command.\n3.  Later the image may be used as a base for a new build, using the `FROM` instruction. As part of processing the `FROM` instruction, the downstream builder looks for `ONBUILD` triggers, and executes them in the same order they were registered. If any of the triggers fail, the `FROM` instruction is aborted which in turn causes the build to fail. If all triggers succeed, the `FROM` instruction completes and the build continues as usual.\n4.  Triggers are cleared from the final image after being executed. In other words they are not inherited by “grand-children” builds.\n\nFor example you might add something like this:\n\n``` \nONBUILD ADD . /app/src\nONBUILD RUN /usr/local/bin/python-build --dir /app/src\n```\n\n> **Warning**\n>\n> Chaining `ONBUILD` instructions using `ONBUILD ONBUILD` isn’t allowed.\n\n> **Warning**\n>\n> The `ONBUILD` instruction may not trigger `FROM` or `MAINTAINER` instructions.\n\n## STOPSIGNAL\n\n``` \nSTOPSIGNAL signal\n```\n\nThe `STOPSIGNAL` instruction sets the system call signal that will be sent to the container to exit. This signal can be a signal name in the format `SIG<NAME>`, for instance `SIGKILL`, or an unsigned number that matches a position in the kernel’s syscall table, for instance `9`. The default is `SIGTERM` if not defined.\n\nThe image’s default stopsignal can be overridden per container, using the `--stop-signal` flag on `docker run` and `docker create`.\n\n## HEALTHCHECK\n\nThe `HEALTHCHECK` instruction has two forms:\n\n- `HEALTHCHECK [OPTIONS] CMD command` (check container health by running a command inside the container)\n- `HEALTHCHECK NONE` (disable any healthcheck inherited from the base image)\n\nThe `HEALTHCHECK` instruction tells Docker how to test a container to check that it is still working. This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running.\n\nWhen a container has a healthcheck specified, it has a *health status* in addition to its normal status. This status is initially `starting`. Whenever a health check passes, it becomes `healthy` (whatever state it was previously in). After a certain number of consecutive failures, it becomes `unhealthy`.\n\nThe options that can appear before `CMD` are:\n\n- `--interval=DURATION` (default: `30s`)\n- `--timeout=DURATION` (default: `30s`)\n- `--start-period=DURATION` (default: `0s`)\n- `--retries=N` (default: `3`)\n\nThe health check will first run **interval** seconds after the container is started, and then again **interval** seconds after each previous check completes.\n\nIf a single run of the check takes longer than **timeout** seconds then the check is considered to have failed.\n\nIt takes **retries** consecutive failures of the health check for the container to be considered `unhealthy`.\n\n**start period** provides initialization time for containers that need time to bootstrap. Probe failure during that period will not be counted towards the maximum number of retries. However, if a health check succeeds during the start period, the container is considered started and all consecutive failures will be counted towards the maximum number of retries.\n\nThere can only be one `HEALTHCHECK` instruction in a Dockerfile. If you list more than one then only the last `HEALTHCHECK` will take effect.\n\nThe command after the `CMD` keyword can be either a shell command (e.g. `HEALTHCHECK CMD /bin/check-running`) or an *exec* array (as with other Dockerfile commands; see e.g. `ENTRYPOINT` for details).\n\nThe command’s exit status indicates the health status of the container. The possible values are:\n\n- 0: success - the container is healthy and ready for use\n- 1: unhealthy - the container is not working correctly\n- 2: reserved - do not use this exit code\n\nFor example, to check every five minutes or so that a web-server is able to serve the site’s main page within three seconds:\n\n``` \nHEALTHCHECK --interval=5m --timeout=3s \\\n  CMD curl -f http://localhost/ || exit 1\n```\n\nTo help debug failing probes, any output text (UTF-8 encoded) that the command writes on stdout or stderr will be stored in the health status and can be queried with `docker inspect`. Such output should be kept short (only the first 4096 bytes are stored currently).\n\nWhen the health status of a container changes, a `health_status` event is generated with the new status.\n\n## SHELL\n\n``` \nSHELL [\"executable\", \"parameters\"]\n```\n\nThe `SHELL` instruction allows the default shell used for the *shell* form of commands to be overridden. The default shell on Linux is `[\"/bin/sh\", \"-c\"]`, and on Windows is `[\"cmd\", \"/S\", \"/C\"]`. The `SHELL` instruction *must* be written in JSON form in a Dockerfile.\n\nThe `SHELL` instruction is particularly useful on Windows where there are two commonly used and quite different native shells: `cmd` and `powershell`, as well as alternate shells available including `sh`.\n\nThe `SHELL` instruction can appear multiple times. Each `SHELL` instruction overrides all previous `SHELL` instructions, and affects all subsequent instructions. For example:\n\n``` \nFROM microsoft/windowsservercore\n\n# Executed as cmd /S /C echo default\nRUN echo default\n\n# Executed as cmd /S /C powershell -command Write-Host default\nRUN powershell -command Write-Host default\n\n# Executed as powershell -command Write-Host hello\nSHELL [\"powershell\", \"-command\"]\nRUN Write-Host hello\n\n# Executed as cmd /S /C echo hello\nSHELL [\"cmd\", \"/S\", \"/C\"]\nRUN echo hello\n```\n\nThe following instructions can be affected by the `SHELL` instruction when the *shell* form of them is used in a Dockerfile: `RUN`, `CMD` and `ENTRYPOINT`.\n\nThe following example is a common pattern found on Windows which can be streamlined by using the `SHELL` instruction:\n\n``` \nRUN powershell -command Execute-MyCmdlet -param1 \"c:\\foo.txt\"\n```\n\nThe command invoked by docker will be:\n\n``` \ncmd /S /C powershell -command Execute-MyCmdlet -param1 \"c:\\foo.txt\"\n```\n\nThis is inefficient for two reasons. First, there is an un-necessary cmd.exe command processor (aka shell) being invoked. Second, each `RUN` instruction in the *shell* form requires an extra `powershell -command` prefixing the command.\n\nTo make this more efficient, one of two mechanisms can be employed. One is to use the JSON form of the RUN command such as:\n\n``` \nRUN [\"powershell\", \"-command\", \"Execute-MyCmdlet\", \"-param1 \\\"c:\\\\foo.txt\\\"\"]\n```\n\nWhile the JSON form is unambiguous and does not use the un-necessary cmd.exe, it does require more verbosity through double-quoting and escaping. The alternate mechanism is to use the `SHELL` instruction and the *shell* form, making a more natural syntax for Windows users, especially when combined with the `escape` parser directive:\n\n``` \n# escape=`\n\nFROM microsoft/nanoserver\nSHELL [\"powershell\",\"-command\"]\nRUN New-Item -ItemType Directory C:\\Example\nADD Execute-MyCmdlet.ps1 c:\\example\\\nRUN c:\\example\\Execute-MyCmdlet -sample 'hello world'\n```\n\nResulting in:\n\n``` \nPS E:\\myproject> docker build -t shell .\n\nSending build context to Docker daemon 4.096 kB\nStep 1/5 : FROM microsoft/nanoserver\n ---> 22738ff49c6d\nStep 2/5 : SHELL powershell -command\n ---> Running in 6fcdb6855ae2\n ---> 6331462d4300\nRemoving intermediate container 6fcdb6855ae2\nStep 3/5 : RUN New-Item -ItemType Directory C:\\Example\n ---> Running in d0eef8386e97\n\n\n    Directory: C:\\\n\n\nMode         LastWriteTime              Length Name\n----         -------------              ------ ----\nd-----       10/28/2016  11:26 AM              Example\n\n\n ---> 3f2fbf1395d9\nRemoving intermediate container d0eef8386e97\nStep 4/5 : ADD Execute-MyCmdlet.ps1 c:\\example\\\n ---> a955b2621c31\nRemoving intermediate container b825593d39fc\nStep 5/5 : RUN c:\\example\\Execute-MyCmdlet 'hello world'\n ---> Running in be6d8e63fe75\nhello world\n ---> 8e559e9bf424\nRemoving intermediate container be6d8e63fe75\nSuccessfully built 8e559e9bf424\nPS E:\\myproject>\n```\n\nThe `SHELL` instruction could also be used to modify the way in which a shell operates. For example, using `SHELL cmd /S /C /V:ON|OFF` on Windows, delayed environment variable expansion semantics could be modified.\n\nThe `SHELL` instruction can also be used on Linux should an alternate shell be required such as `zsh`, `csh`, `tcsh` and others.\n\n## Dockerfile examples\n\nFor examples of Dockerfiles, refer to:\n\n- The [“build images” section](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)\n- The [“get started](../../../get-started/index)\n- The [language-specific getting started guides](https://docs.docker.com/language/)\n\n[builder](https://docs.docker.com/search/?q=builder), [docker](https://docs.docker.com/search/?q=docker), [Dockerfile](https://docs.docker.com/search/?q=Dockerfile), [automation](https://docs.docker.com/search/?q=automation), [image creation](https://docs.docker.com/search/?q=image%20creation)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)"
- name: Drain a node on the swarm
  id: engine/swarm/swarm-tutorial/drain-node/index
  summary: In earlier steps of the tutorial, all the nodes have been running with ACTIVE availability
  description: "# Drain a node on the swarm\n\nIn earlier steps of the tutorial, all the nodes have been running with `ACTIVE` availability. The swarm manager can assign tasks to any `ACTIVE` node, so up to now all nodes have been available to receive tasks.\n\nSometimes, such as planned maintenance times, you need to set a node to `DRAIN` availability. `DRAIN` availability prevents a node from receiving new tasks from the swarm manager. It also means the manager stops tasks running on the node and launches replica tasks on a node with `ACTIVE` availability.\n\n> **Important**: Setting a node to `DRAIN` does not remove standalone containers from that node, such as those created with `docker run`, `docker-compose up`, or the Docker Engine API. A node’s status, including `DRAIN`, only affects the node’s ability to schedule swarm service workloads.\n\n1.  If you haven’t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n\n2.  Verify that all your nodes are actively available.\n\n    ``` \n    $ docker node ls\n\n    ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n    1bcef6utixb0l0ca7gxuivsj0    worker2   Ready   Active\n    38ciaotwjuritcdtn9npbnkuz    worker1   Ready   Active\n    e216jshn25ckzbvmwlnh5jr3g *  manager1  Ready   Active        Leader\n    ```\n\n3.  If you aren’t still running the `redis` service from the [rolling update](../rolling-update/index) tutorial, start it now:\n\n    ``` \n    $ docker service create --replicas 3 --name redis --update-delay 10s redis:3.0.6\n\n    c5uo6kdmzpon37mgj9mwglcfw\n    ```\n\n4.  Run `docker service ps redis` to see how the swarm manager assigned the tasks to different nodes:\n\n    ``` \n    $ docker service ps redis\n\n    NAME                               IMAGE        NODE     DESIRED STATE  CURRENT STATE\n    redis.1.7q92v0nr1hcgts2amcjyqg3pq  redis:3.0.6  manager1 Running        Running 26 seconds\n    redis.2.7h2l8h3q3wqy5f66hlv9ddmi6  redis:3.0.6  worker1  Running        Running 26 seconds\n    redis.3.9bg7cezvedmkgg6c8yzvbhwsd  redis:3.0.6  worker2  Running        Running 26 seconds\n    ```\n\n    In this case the swarm manager distributed one task to each node. You may see the tasks distributed differently among the nodes in your environment.\n\n5.  Run `docker node update --availability drain <NODE-ID>` to drain a node that had a task assigned to it:\n\n    ``` \n    $ docker node update --availability drain worker1\n\n    worker1\n    ```\n\n6.  Inspect the node to check its availability:\n\n    ``` \n    $ docker node inspect --pretty worker1\n\n    ID:         38ciaotwjuritcdtn9npbnkuz\n    Hostname:       worker1\n    Status:\n     State:         Ready\n     Availability:      Drain\n    ...snip...\n    ```\n\n    The drained node shows `Drain` for `AVAILABILITY`.\n\n7.  Run `docker service ps redis` to see how the swarm manager updated the task assignments for the `redis` service:\n\n    ``` \n    $ docker service ps redis\n\n    NAME                                    IMAGE        NODE      DESIRED STATE  CURRENT STATE           ERROR\n    redis.1.7q92v0nr1hcgts2amcjyqg3pq       redis:3.0.6  manager1  Running        Running 4 minutes\n    redis.2.b4hovzed7id8irg1to42egue8       redis:3.0.6  worker2   Running        Running About a minute\n     \\_ redis.2.7h2l8h3q3wqy5f66hlv9ddmi6   redis:3.0.6  worker1   Shutdown       Shutdown 2 minutes ago\n    redis.3.9bg7cezvedmkgg6c8yzvbhwsd       redis:3.0.6  worker2   Running        Running 4 minutes\n    ```\n\n    The swarm manager maintains the desired state by ending the task on a node with `Drain` availability and creating a new task on a node with `Active` availability.\n\n8.  Run `docker node update --availability active <NODE-ID>` to return the drained node to an active state:\n\n    ``` \n    $ docker node update --availability active worker1\n\n    worker1\n    ```\n\n9.  Inspect the node to see the updated state:\n\n    ``` \n    $ docker node inspect --pretty worker1\n\n    ID:         38ciaotwjuritcdtn9npbnkuz\n    Hostname:       worker1\n    Status:\n     State:         Ready\n     Availability:      Active\n    ...snip...\n    ```\n\n    When you set the node back to `Active` availability, it can receive new tasks:\n\n    - during a service update to scale up\n    - during a rolling update\n    - when you set another node to `Drain` availability\n    - when a task fails on another active node\n\n## What’s next?\n\nLearn how to [use a swarm mode routing mesh](../../ingress/index).\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm](https://docs.docker.com/search/?q=swarm), [service](https://docs.docker.com/search/?q=service), [drain](https://docs.docker.com/search/?q=drain)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/drain-node/](https://docs.docker.com/engine/swarm/swarm-tutorial/drain-node/)"
- name: Educational resources
  id: get-started/resources/index
  summary: Docker and the broader community of Docker experts have put together many different ways to get further training and hands-on experience with Docker
  description: "# Educational resources\n\nDocker and the broader community of Docker experts have put together many different ways to get further training and hands-on experience with Docker. Expand your understanding of Docker and Kubernetes with these additional free and paid resources.\n\n## Hosted labs\n\nThese self-paced and hands-on workshops use a free, hosted environment ([Play with Kubernetes](https://labs.play-with-k8s.com/)) that does not require any installation. Follow along and learn more about Kubernetes.\n\n- [Kubernetes Workshop](https://training.play-with-kubernetes.com/kubernetes-workshop/)\n\n- Labs are free but require registration with a Docker ID.\n\n## Self-guided tutorials\n\nCreated by experts in the Docker community, these free tutorials provide guided step-by-step workflows for working with the Docker platform.\n\n- **Integrating Docker with Your IDE**\n  - [Java Development: Eclipse](https://training.play-with-docker.com/java-debugging-eclipse/)\n  - [Java Development: IntelliJ](https://training.play-with-docker.com/java-debugging-intellij/)\n  - [Java Development: Netbeans](https://training.play-with-docker.com/java-debugging-netbeans/)\n  - [Live Debugging Node.js with Docker and Visual Studio Code](https://training.play-with-docker.com/nodejs-live-debugging/)\n- **Windows Containers**\n  - [Windows Container Setup](https://training.play-with-docker.com/windows-containers-setup/)\n  - [Windows Container Basics](https://training.play-with-docker.com/windows-containers-basics/)\n  - [Windows Containers Multi-Container Applications](https://training.play-with-docker.com/windows-containers-multicontainer/)\n\n## Books\n\nIf books are your preferred learning style, check out these written by the [Docker Captains](https://www.docker.com/community/captains). Docker Captain is a distinction that Docker awards to select members of the community that are both experts in their field and are committed to sharing their Docker knowledge with others.\n\n- [Learn Docker in a Month of Lunches](https://www.manning.com/books/learn-docker-in-a-month-of-lunches), Elton Stoneman. Use the code `stonemanpc` for a 40% discount.\n- [Docker on Windows: From 101 to Production with Docker on Windows](https://www.amazon.com/Docker-Windows-Elton-Stoneman-ebook/dp/B0711Y4J9K/), Elton Stoneman\n- [Learn Kubernetes in a Month of Lunches](https://www.manning.com/books/learn-kubernetes-in-a-month-of-lunches), Elton Stoneman. Use the code `stonemanpc` for a 40% discount.\n- [Docker in Action 2nd Edition](https://www.manning.com/books/docker-in-action-second-edition) Jeff Nickoloff, Oct 2019\n- [The Kubernetes Book](https://www.amazon.com/Kubernetes-Book-Nigel-Poulton/dp/1521823634/ref=sr_1_3?ie=UTF8&qid=1509660871&sr=8-3&keywords=nigel+poulton), Nigel Poulton, Nov 2018\n- [Docker Deep Dive](https://www.amazon.com/Docker-Deep-Dive-Nigel-Poulton/dp/1521822808/ref=sr_1_1?ie=UTF8&qid=1509660871&sr=8-1&keywords=nigel+poulton), Nigel Poulton, March 2018\n- \\[Portuguese\\] [Docker para desenvolvedores](https://leanpub.com/dockerparadesenvolvedores) (2017) by Rafael Gomes\n\n## Self-Paced online learning\n\nA number of Docker Captains have also created video courses on Docker and Kubernetes.\n\n- [Bret Fisher](https://www.bretfisher.com/courses/): Docker Mastery, Docker Swarm Mastery, Docker Mastery for Node.js Projects\n- [Elton Stoneman](https://docker4.net/udemy): Docker for .NET Apps - on Linux and Windows. Includes the discount code `644ABCBC33F474541885`.\n- [Nick Janetakis](https://nickjanetakis.com/courses/) Dive into Docker, Docker for DevOps\n- [Nigel Poulton](https://nigelpoulton.com/video-courses): Kubernetes 101, Getting Started with Kubernetes, Docker and Kubernetes: The Big Picture, Kubernetes Deep Dive, Docker Deep Dive\n- [Arun Gupta](https://www.lynda.com/Docker-tutorials/Docker-Java-developers/576584-2.html): Docker for Java Developers\n- [Ajeet Singh Raina](https://collabnix.com/): Docker and Kubernetes Labs\n- \\[French\\] [Luc Juggery](https://www.udemy.com/user/lucjuggery/): Introduction to Kubernetes, The Docker Platform\n\n\\* Many of the courses are fee-based\n\n[get started](https://docs.docker.com/search/?q=get%20started), [setup](https://docs.docker.com/search/?q=setup), [orientation](https://docs.docker.com/search/?q=orientation), [quickstart](https://docs.docker.com/search/?q=quickstart), [intro](https://docs.docker.com/search/?q=intro), [concepts](https://docs.docker.com/search/?q=concepts), [kubernetes](https://docs.docker.com/search/?q=kubernetes), [docker desktop](https://docs.docker.com/search/?q=docker%20desktop)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/resources/](https://docs.docker.com/get-started/resources/)"
- name: Enabling GPU access with Compose
  id: compose/gpu-support/index
  summary: Compose services can define GPU device reservations if the Docker host contains such devices and the Docker Daemon is set accordingly
  description: "# Enabling GPU access with Compose\n\nCompose services can define GPU device reservations if the Docker host contains such devices and the Docker Daemon is set accordingly. For this, make sure to install the [prerequisites](https://docs.docker.com/config/containers/resource_constraints/#gpu) if you have not already done so.\n\nThe examples in the following sections focus specifically on providing service containers access to GPU devices with Docker Compose. You can use either `docker-compose` or `docker compose` commands.\n\n### Use of service `runtime` property from Compose v2.3 format (legacy)\n\nDocker Compose v1.27.0+ switched to using the Compose Specification schema which is a combination of all properties from 2.x and 3.x versions. This re-enabled the use of service properties as [runtime](../compose-file/compose-file-v2/index#runtime) to provide GPU access to service containers. However, this does not allow to have control over specific properties of the GPU devices.\n\n``` \nservices:\n  test:\n    image: nvidia/cuda:10.2-base\n    command: nvidia-smi\n    runtime: nvidia\n```\n\n### Enabling GPU access to service containers\n\nDocker Compose v1.28.0+ allows to define GPU reservations using the [device](https://github.com/compose-spec/compose-spec/blob/master/deploy/#devices) structure defined in the Compose Specification. This provides more granular control over a GPU reservation as custom values can be set for the following device properties:\n\n- [capabilities](https://github.com/compose-spec/compose-spec/blob/master/deploy/#capabilities) - value specifies as a list of strings (eg. `capabilities: [gpu]`). You must set this field in the Compose file. Otherwise, it returns an error on service deployment.\n- [count](https://github.com/compose-spec/compose-spec/blob/master/deploy/#count) - value specified as an int or the value `all` representing the number of GPU devices that should be reserved ( providing the host holds that number of GPUs).\n- [device_ids](https://github.com/compose-spec/compose-spec/blob/master/deploy/#device_ids) - value specified as a list of strings representing GPU device IDs from the host. You can find the device ID in the output of `nvidia-smi` on the host.\n- [driver](https://github.com/compose-spec/compose-spec/blob/master/deploy/#driver) - value specified as a string (eg. `driver: 'nvidia'`)\n- [options](https://github.com/compose-spec/compose-spec/blob/master/deploy/#options) - key-value pairs representing driver specific options.\n\n> **Note**\n>\n> You must set the `capabilities` field. Otherwise, it returns an error on service deployment.\n>\n> `count` and `device_ids` are mutually exclusive. You must only define one field at a time.\n\nFor more information on these properties, see the `deploy` section in the [Compose Specification](https://github.com/compose-spec/compose-spec/blob/master/deploy/#devices).\n\nExample of a Compose file for running a service with access to 1 GPU device:\n\n``` \nservices:\n  test:\n    image: nvidia/cuda:10.2-base\n    command: nvidia-smi\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n```\n\nRun with Docker Compose:\n\n``` \n$ docker-compose up\nCreating network \"gpu_default\" with the default driver\nCreating gpu_test_1 ... done\nAttaching to gpu_test_1    \ntest_1  | +-----------------------------------------------------------------------------+\ntest_1  | | NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.1     |\ntest_1  | |-------------------------------+----------------------+----------------------+\ntest_1  | | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\ntest_1  | | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\ntest_1  | |                               |                      |               MIG M. |\ntest_1  | |===============================+======================+======================|\ntest_1  | |   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\ntest_1  | | N/A   23C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\ntest_1  | |                               |                      |                  N/A |\ntest_1  | +-------------------------------+----------------------+----------------------+\ntest_1  |                                                                                \ntest_1  | +-----------------------------------------------------------------------------+\ntest_1  | | Processes:                                                                  |\ntest_1  | |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\ntest_1  | |        ID   ID                                                   Usage      |\ntest_1  | |=============================================================================|\ntest_1  | |  No running processes found                                                 |\ntest_1  | +-----------------------------------------------------------------------------+\ngpu_test_1 exited with code 0\n```\n\nIf no `count` or `device_ids` are set, all GPUs available on the host are going to be used by default.\n\n``` \nservices:\n  test:\n    image: tensorflow/tensorflow:latest-gpu\n    command: python -c \"import tensorflow as tf;tf.test.gpu_device_name()\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - capabilities: [gpu]\n```\n\n``` \n$ docker-compose up\nCreating network \"gpu_default\" with the default driver\nCreating gpu_test_1 ... done\nAttaching to gpu_test_1\ntest_1  | I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n.....\ntest_1  | I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402]\nCreated TensorFlow device (/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\ntest_1  | /device:GPU:0\ngpu_test_1 exited with code 0\n```\n\nOn machines hosting multiple GPUs, `device_ids` field can be set to target specific GPU devices and `count` can be used to limit the number of GPU devices assigned to a service container. If `count` exceeds the number of available GPUs on the host, the deployment will error out.\n\n``` \n$ nvidia-smi   \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            On   | 00000000:00:1B.0 Off |                    0 |\n| N/A   72C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            On   | 00000000:00:1C.0 Off |                    0 |\n| N/A   67C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla T4            On   | 00000000:00:1D.0 Off |                    0 |\n| N/A   74C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n| N/A   62C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n```\n\nTo enable access only to GPU-0 and GPU-3 devices:\n\n``` \nservices:\n  test:\n    image: tensorflow/tensorflow:latest-gpu\n    command: python -c \"import tensorflow as tf;tf.test.gpu_device_name()\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - driver: nvidia\n            device_ids: ['0', '3']\n            capabilities: [gpu]\n```\n\n``` \n$ docker-compose up\n...\nCreated TensorFlow device (/device:GPU:0 with 13970 MB memory -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1b.0, compute capability: 7.5)\n...\nCreated TensorFlow device (/device:GPU:1 with 13970 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n...\ngpu_test_1 exited with code 0\n```\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [GPU access](https://docs.docker.com/search/?q=GPU%20access), [NVIDIA](https://docs.docker.com/search/?q=NVIDIA), [samples](https://docs.docker.com/search/?q=samples)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/gpu-support/](https://docs.docker.com/compose/gpu-support/)"
- name: Engine
  id: engine/index
  summary: Docker Engine is an open source containerization technology for building and containerizing your applications
  description: "# Docker Engine overview\n\nDocker Engine is an open source containerization technology for building and containerizing your applications. Docker Engine acts as a client-server application with:\n\n- A server with a long-running daemon process [`dockerd`](reference/commandline/dockerd/index).\n- APIs which specify interfaces that programs can use to talk to and instruct the Docker daemon.\n- A command line interface (CLI) client [`docker`](reference/commandline/cli/index).\n\nThe CLI uses [Docker APIs](api/index) to control or interact with the Docker daemon through scripting or direct CLI commands. Many other Docker applications use the underlying API and CLI. The daemon creates and manage Docker objects, such as images, containers, networks, and volumes.\n\nFor more details, see [Docker Architecture](../get-started/overview/index#docker-architecture).\n\n## Docker user guide\n\nTo learn about Docker in more detail and to answer questions about usage and implementation, check out the [overview page in “get started”](../get-started/overview/index).\n\n## Installation guides\n\nThe [installation section](install/index) shows you how to install Docker on a variety of platforms.\n\n## Release notes\n\nA summary of the changes in each release in the current series can now be found on the separate [Release Notes page](release-notes/index)\n\n## Feature Deprecation Policy\n\nAs changes are made to Docker there may be times when existing features need to be removed or replaced with newer features. Before an existing feature is removed it is labeled as “deprecated” within the documentation and remains in Docker for at least 3 stable releases unless specified explicitly otherwise. After that time it may be removed.\n\nUsers are expected to take note of the list of deprecated features each release and plan their migration away from those features, and (if applicable) towards the replacement features as soon as possible.\n\nThe complete list of deprecated features can be found on the [Deprecated Features page](deprecated/index).\n\n## Licensing\n\nDocker is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full license text.\n\n[Engine](https://docs.docker.com/search/?q=Engine)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/](https://docs.docker.com/engine/)"
- name: Environment variables in Compose
  id: compose/environment-variables/index
  summary: There are multiple parts of Compose that deal with environment variables in one sense or another
  description: "# Environment variables in Compose\n\nThere are multiple parts of Compose that deal with environment variables in one sense or another. This page should help you find the information you need.\n\n## Substitute environment variables in Compose files\n\nIt’s possible to use environment variables in your shell to populate values inside a Compose file:\n\n``` \nweb:\n  image: \"webapp:${TAG}\"\n```\n\nIf you have multiple environment variables, you can substitute them by adding them to a default environment variable file named `.env` or by providing a path to your environment variables file using the `--env-file` command line option.\n\nYour configuration options can contain environment variables. Compose uses the variable values from the shell environment in which `docker-compose` is run. For example, suppose the shell contains `POSTGRES_VERSION=9.3` and you supply this configuration:\n\n``` \ndb:\n  image: \"postgres:${POSTGRES_VERSION}\"\n```\n\nWhen you run `docker-compose up` with this configuration, Compose looks for the `POSTGRES_VERSION` environment variable in the shell and substitutes its value in. For this example, Compose resolves the `image` to `postgres:9.3` before running the configuration.\n\nIf an environment variable is not set, Compose substitutes with an empty string. In the example above, if `POSTGRES_VERSION` is not set, the value for the `image` option is `postgres:`.\n\nYou can set default values for environment variables using a [`.env` file](../env-file/index), which Compose automatically looks for in project directory (parent folder of your Compose file). Values set in the shell environment override those set in the `.env` file.\n\n> Note when using docker stack deploy\n>\n> The `.env file` feature only works when you use the `docker-compose up` command and does not work with `docker stack deploy`.\n\nBoth `$VARIABLE` and `${VARIABLE}` syntax are supported. Additionally when using the [2.1 file format](../compose-file/compose-versioning/index#version-21), it is possible to provide inline default values using typical shell syntax:\n\n- `${VARIABLE:-default}` evaluates to `default` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE-default}` evaluates to `default` only if `VARIABLE` is unset in the environment.\n\nSimilarly, the following syntax allows you to specify mandatory variables:\n\n- `${VARIABLE:?err}` exits with an error message containing `err` if `VARIABLE` is unset or empty in the environment.\n- `${VARIABLE?err}` exits with an error message containing `err` if `VARIABLE` is unset in the environment.\n\nOther extended shell-style features, such as `${VARIABLE/foo/bar}`, are not supported.\n\nYou can use a `$$` (double-dollar sign) when your configuration needs a literal dollar sign. This also prevents Compose from interpolating a value, so a `$$` allows you to refer to environment variables that you don’t want processed by Compose.\n\n``` \nweb:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n```\n\nIf you forget and use a single dollar sign (`$`), Compose interprets the value as an environment variable and warns you:\n\n``` \nThe VAR_NOT_INTERPOLATED_BY_COMPOSE is not set. Substituting an empty string.\n```\n\n### The “.env” file\n\nYou can set default values for any environment variables referenced in the Compose file, or used to configure Compose, in an [environment file](../env-file/index) named `.env`. The `.env` file path is as follows:\n\n- Starting with `+v1.28`, `.env` file is placed at the base of the project directory\n- Project directory can be explicitly defined with the `--file` option or `COMPOSE_FILE` environment variable. Otherwise, it is the current working directory where the `docker compose` command is executed (`+1.28`).\n- For previous versions, it might have trouble resolving `.env` file with `--file` or `COMPOSE_FILE`. To work around it, it is recommended to use `--project-directory`, which overrides the path for the `.env` file. This inconsistency is addressed in `+v1.28` by limiting the filepath to the project directory.\n\n``` \n$ cat .env\nTAG=v1.5\n\n$ cat docker-compose.yml\nversion: '3'\nservices:\n  web:\n    image: \"webapp:${TAG}\"\n```\n\nWhen you run `docker-compose up`, the `web` service defined above uses the image `webapp:v1.5`. You can verify this with the [config command](../reference/config/index), which prints your resolved application config to the terminal:\n\n``` \n$ docker-compose config\n\nversion: '3'\nservices:\n  web:\n    image: 'webapp:v1.5'\n```\n\nValues in the shell take precedence over those specified in the `.env` file.\n\nIf you set `TAG` to a different value in your shell, the substitution in `image` uses that instead:\n\n``` \n$ export TAG=v2.0\n$ docker-compose config\n\nversion: '3'\nservices:\n  web:\n    image: 'webapp:v2.0'\n```\n\nYou can override the environment file path using a command line argument `--env-file`.\n\n### Using the “--env-file” option\n\nBy passing the file as an argument, you can store it anywhere and name it appropriately, for example, `.env.ci`, `.env.dev`, `.env.prod`. Passing the file path is done using the `--env-file` option:\n\n``` \n$ docker-compose --env-file ./config/.env.dev up \n```\n\nThis file path is relative to the current working directory where the Docker Compose command is executed.\n\n``` \n$ cat .env\nTAG=v1.5\n\n$ cat ./config/.env.dev\nTAG=v1.6\n\n\n$ cat docker-compose.yml\nversion: '3'\nservices:\n  web:\n    image: \"webapp:${TAG}\"\n```\n\nThe `.env` file is loaded by default:\n\n``` \n$ docker-compose config \nversion: '3'\nservices:\n  web:\n    image: 'webapp:v1.5'\n```\n\nPassing the `--env-file` argument overrides the default file path:\n\n``` \n$ docker-compose --env-file ./config/.env.dev config \nversion: '3'\nservices:\n  web:\n    image: 'webapp:v1.6'\n```\n\nWhen an invalid file path is being passed as `--env-file` argument, Compose returns an error:\n\n``` \n$ docker-compose --env-file ./doesnotexist/.env.dev  config\nERROR: Couldn't find env file: /home/user/./doesnotexist/.env.dev\n```\n\nFor more information, see the [Variable substitution](../compose-file/compose-file-v3/index#variable-substitution) section in the Compose file reference.\n\n## Set environment variables in containers\n\nYou can set environment variables in a service’s containers with the [‘environment’ key](../compose-file/compose-file-v3/index#environment), just like with `docker run -e VARIABLE=VALUE ...`:\n\n``` \nweb:\n  environment:\n    - DEBUG=1\n```\n\n## Pass environment variables to containers\n\nYou can pass environment variables from your shell straight through to a service’s containers with the [‘environment’ key](../compose-file/compose-file-v3/index#environment) by not giving them a value, just like with `docker run -e VARIABLE ...`:\n\n``` \nweb:\n  environment:\n    - DEBUG\n```\n\nThe value of the `DEBUG` variable in the container is taken from the value for the same variable in the shell in which Compose is run.\n\n## The “env_file” configuration option\n\nYou can pass multiple environment variables from an external file through to a service’s containers with the [‘env_file’ option](../compose-file/compose-file-v3/index#env_file), just like with `docker run --env-file=FILE ...`:\n\n``` \nweb:\n  env_file:\n    - web-variables.env\n```\n\n## Set environment variables with ‘docker-compose run’\n\nSimilar to `docker run -e`, you can set environment variables on a one-off container with `docker-compose run -e`:\n\n``` \n$ docker-compose run -e DEBUG=1 web python console.py\n```\n\nYou can also pass a variable from the shell by not giving it a value:\n\n``` \n$ docker-compose run -e DEBUG web python console.py\n```\n\nThe value of the `DEBUG` variable in the container is taken from the value for the same variable in the shell in which Compose is run.\n\nWhen you set the same environment variable in multiple files, here’s the priority used by Compose to choose which value to use:\n\n1.  Compose file\n2.  Shell environment variables\n3.  Environment file\n4.  Dockerfile\n5.  Variable is not defined\n\nIn the example below, we set the same environment variable on an Environment file, and the Compose file:\n\n``` \n$ cat ./Docker/api/api.env\nNODE_ENV=test\n\n$ cat docker-compose.yml\nversion: '3'\nservices:\n  api:\n    image: 'node:6-alpine'\n    env_file:\n     - ./Docker/api/api.env\n    environment:\n     - NODE_ENV=production\n```\n\nWhen you run the container, the environment variable defined in the Compose file takes precedence.\n\n``` \n$ docker-compose exec api node\n\n> process.env.NODE_ENV\n'production'\n```\n\nHaving any `ARG` or `ENV` setting in a `Dockerfile` evaluates only if there is no Docker Compose entry for `environment` or `env_file`.\n\n> Specifics for NodeJS containers\n>\n> If you have a `package.json` entry for `script:start` like `NODE_ENV=test node server.js`, then this overrules any setting in your `docker-compose.yml` file.\n\n## Configure Compose using environment variables\n\nSeveral environment variables are available for you to configure the Docker Compose command-line behavior. They begin with `COMPOSE_` or `DOCKER_`, and are documented in [CLI Environment Variables](../reference/envvars/index).\n\n[compose](https://docs.docker.com/search/?q=compose), [orchestration](https://docs.docker.com/search/?q=orchestration), [environment](https://docs.docker.com/search/?q=environment), [env file](https://docs.docker.com/search/?q=env%20file)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/environment-variables/](https://docs.docker.com/compose/environment-variables/)"
- name: Examples using the Docker Engine SDKs and Docker API
  id: engine/api/sdk/examples/index
  summary: After you install Docker, you can install the Go or Python SDK and also try out the Docker Engine API
  description: "# Examples using the Docker Engine SDKs and Docker API\n\nAfter you [install Docker](https://docs.docker.com/get-docker/), you can [install the Go or Python SDK](../index#install-the-sdks) and also try out the Docker Engine API.\n\nEach of these examples show how to perform a given Docker operation using the Go and Python SDKs and the HTTP API using `curl`.\n\n## Run a container\n\nThis first example shows how to run a container using the Docker API. On the command line, you would use the `docker run` command, but this is just as easy to do from your own apps too.\n\nThis is the equivalent of typing `docker run alpine echo hello world` at the command prompt:\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"io\"\n    \"os\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/api/types/container\"\n    \"github.com/docker/docker/client\"\n    \"github.com/docker/docker/pkg/stdcopy\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    reader, err := cli.ImagePull(ctx, \"docker.io/library/alpine\", types.ImagePullOptions{})\n    if err != nil {\n        panic(err)\n    }\n\n    defer reader.Close()\n    io.Copy(os.Stdout, reader)\n\n    resp, err := cli.ContainerCreate(ctx, &container.Config{\n        Image: \"alpine\",\n        Cmd:   []string{\"echo\", \"hello world\"},\n        Tty:   false,\n    }, nil, nil, nil, \"\")\n    if err != nil {\n        panic(err)\n    }\n\n    if err := cli.ContainerStart(ctx, resp.ID, types.ContainerStartOptions{}); err != nil {\n        panic(err)\n    }\n\n    statusCh, errCh := cli.ContainerWait(ctx, resp.ID, container.WaitConditionNotRunning)\n    select {\n    case err := <-errCh:\n        if err != nil {\n            panic(err)\n        }\n    case <-statusCh:\n    }\n\n    out, err := cli.ContainerLogs(ctx, resp.ID, types.ContainerLogsOptions{ShowStdout: true})\n    if err != nil {\n        panic(err)\n    }\n\n    stdcopy.StdCopy(os.Stdout, os.Stderr, out)\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\nprint(client.containers.run(\"alpine\", [\"echo\", \"hello\", \"world\"]))\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock -H \"Content-Type: application/json\" \\\n  -d '{\"Image\": \"alpine\", \"Cmd\": [\"echo\", \"hello world\"]}' \\\n  -X POST http://localhost/v1.41/containers/create\n{\"Id\":\"1c6594faf5\",\"Warnings\":null}\n\n$ curl --unix-socket /var/run/docker.sock -X POST http://localhost/v1.41/containers/1c6594faf5/start\n\n$ curl --unix-socket /var/run/docker.sock -X POST http://localhost/v1.41/containers/1c6594faf5/wait\n{\"StatusCode\":0}\n\n$ curl --unix-socket /var/run/docker.sock \"http://localhost/v1.41/containers/1c6594faf5/logs?stdout=1\"\nhello world\n```\n\nWhen using cURL to connect over a unix socket, the hostname is not important. The examples above use `localhost`, but any hostname would work.\n\n> **Using cURL 7.47.0 or below?**\n>\n> The examples above assume you are using cURL 7.50.0 or above. Older versions of cURL used a [non-standard URL notation](https://github.com/moby/moby/issues/17960) when using a socket connection.\n>\n> If you are using an older version of cURL, use `http:/<API version>/` instead, for example, `http:/v1.41/containers/1c6594faf5/start`\n\n## Run a container in the background\n\nYou can also run containers in the background, the equivalent of typing `docker run -d bfirsh/reticulate-splines`:\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"os\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/api/types/container\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    imageName := \"bfirsh/reticulate-splines\"\n\n    out, err := cli.ImagePull(ctx, imageName, types.ImagePullOptions{})\n    if err != nil {\n        panic(err)\n    }\n    defer out.Close()\n    io.Copy(os.Stdout, out)\n\n    resp, err := cli.ContainerCreate(ctx, &container.Config{\n        Image: imageName,\n    }, nil, nil, nil, \"\")\n    if err != nil {\n        panic(err)\n    }\n\n    if err := cli.ContainerStart(ctx, resp.ID, types.ContainerStartOptions{}); err != nil {\n        panic(err)\n    }\n\n    fmt.Println(resp.ID)\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\ncontainer = client.containers.run(\"bfirsh/reticulate-splines\", detach=True)\nprint(container.id)\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock -H \"Content-Type: application/json\" \\\n  -d '{\"Image\": \"bfirsh/reticulate-splines\"}' \\\n  -X POST http://localhost/v1.41/containers/create\n{\"Id\":\"1c6594faf5\",\"Warnings\":null}\n\n$ curl --unix-socket /var/run/docker.sock -X POST http://localhost/v1.41/containers/1c6594faf5/start\n```\n\n## List and manage containers\n\nYou can use the API to list containers that are running, just like using `docker ps`:\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    containers, err := cli.ContainerList(ctx, types.ContainerListOptions{})\n    if err != nil {\n        panic(err)\n    }\n\n    for _, container := range containers {\n        fmt.Println(container.ID)\n    }\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\nfor container in client.containers.list():\n  print(container.id)\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock http://localhost/v1.41/containers/json\n[{\n  \"Id\":\"ae63e8b89a26f01f6b4b2c9a7817c31a1b6196acf560f66586fbc8809ffcd772\",\n  \"Names\":[\"/tender_wing\"],\n  \"Image\":\"bfirsh/reticulate-splines\",\n  ...\n}]\n```\n\n## Stop all running containers\n\nNow that you know what containers exist, you can perform operations on them. This example stops all running containers.\n\n> **Note**: Don’t run this on a production server. Also, if you are using swarm services, the containers stop, but Docker creates new ones to keep the service running in its configured state.\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    containers, err := cli.ContainerList(ctx, types.ContainerListOptions{})\n    if err != nil {\n        panic(err)\n    }\n\n    for _, container := range containers {\n        fmt.Print(\"Stopping container \", container.ID[:10], \"... \")\n        if err := cli.ContainerStop(ctx, container.ID, nil); err != nil {\n            panic(err)\n        }\n        fmt.Println(\"Success\")\n    }\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\nfor container in client.containers.list():\n  container.stop()\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock http://localhost/v1.41/containers/json\n[{\n  \"Id\":\"ae63e8b89a26f01f6b4b2c9a7817c31a1b6196acf560f66586fbc8809ffcd772\",\n  \"Names\":[\"/tender_wing\"],\n  \"Image\":\"bfirsh/reticulate-splines\",\n  ...\n}]\n\n$ curl --unix-socket /var/run/docker.sock \\\n  -X POST http://localhost/v1.41/containers/ae63e8b89a26/stop\n```\n\n## Print the logs of a specific container\n\nYou can also perform actions on individual containers. This example prints the logs of a container given its ID. You need to modify the code before running it to change the hard-coded ID of the container to print the logs for.\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"io\"\n    \"os\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    options := types.ContainerLogsOptions{ShowStdout: true}\n    // Replace this ID with a container that really exists\n    out, err := cli.ContainerLogs(ctx, \"f1064a8a4c82\", options)\n    if err != nil {\n        panic(err)\n    }\n\n    io.Copy(os.Stdout, out)\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\ncontainer = client.containers.get('f1064a8a4c82')\nprint(container.logs())\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock \"http://localhost/v1.41/containers/ca5f55cdb/logs?stdout=1\"\nReticulating spline 1...\nReticulating spline 2...\nReticulating spline 3...\nReticulating spline 4...\nReticulating spline 5...\n```\n\n## List all images\n\nList the images on your Engine, similar to `docker image ls`:\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    images, err := cli.ImageList(ctx, types.ImageListOptions{})\n    if err != nil {\n        panic(err)\n    }\n\n    for _, image := range images {\n        fmt.Println(image.ID)\n    }\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\nfor image in client.images.list():\n  print(image.id)\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock http://localhost/v1.41/images/json\n[{\n  \"Id\":\"sha256:31d9a31e1dd803470c5a151b8919ef1988ac3efd44281ac59d43ad623f275dcd\",\n  \"ParentId\":\"sha256:ee4603260daafe1a8c2f3b78fd760922918ab2441cbb2853ed5c439e59c52f96\",\n  ...\n}]\n```\n\n## Pull an image\n\nPull an image, like `docker pull`:\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"io\"\n    \"os\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    out, err := cli.ImagePull(ctx, \"alpine\", types.ImagePullOptions{})\n    if err != nil {\n        panic(err)\n    }\n\n    defer out.Close()\n\n    io.Copy(os.Stdout, out)\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\nimage = client.images.pull(\"alpine\")\nprint(image.id)\n```\n\n``` \n$ curl --unix-socket /var/run/docker.sock \\\n  -X POST \"http://localhost/v1.41/images/create?fromImage=alpine\"\n{\"status\":\"Pulling from library/alpine\",\"id\":\"3.1\"}\n{\"status\":\"Pulling fs layer\",\"progressDetail\":{},\"id\":\"8f13703509f7\"}\n{\"status\":\"Downloading\",\"progressDetail\":{\"current\":32768,\"total\":2244027},\"progress\":\"[\\u003e                                                  ] 32.77 kB/2.244 MB\",\"id\":\"8f13703509f7\"}\n...\n```\n\n## Pull an image with authentication\n\nPull an image, like `docker pull`, with authentication:\n\n> **Note**: Credentials are sent in the clear. Docker’s official registries use HTTPS. Private registries should also be configured to use HTTPS.\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"encoding/base64\"\n    \"encoding/json\"\n    \"io\"\n    \"os\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    authConfig := types.AuthConfig{\n        Username: \"username\",\n        Password: \"password\",\n    }\n    encodedJSON, err := json.Marshal(authConfig)\n    if err != nil {\n        panic(err)\n    }\n    authStr := base64.URLEncoding.EncodeToString(encodedJSON)\n\n    out, err := cli.ImagePull(ctx, \"alpine\", types.ImagePullOptions{RegistryAuth: authStr})\n    if err != nil {\n        panic(err)\n    }\n\n    defer out.Close()\n    io.Copy(os.Stdout, out)\n}\n```\n\nThe Python SDK retrieves authentication information from the [credentials store](../../../reference/commandline/login/index#credentials-store) file and integrates with [credential helpers](https://github.com/docker/docker-credential-helpers). It is possible to override these credentials, but that is out of scope for this Getting Started guide. After using `docker login`, the Python SDK uses these credentials automatically.\n\n``` \nimport docker\nclient = docker.from_env()\nimage = client.images.pull(\"alpine\")\nprint(image.id)\n```\n\nThis example leaves the credentials in your shell’s history, so consider this a naive implementation. The credentials are passed as a Base-64-encoded JSON structure.\n\n``` \n$ JSON=$(echo '{\"username\": \"string\", \"password\": \"string\", \"serveraddress\": \"string\"}' | base64)\n\n$ curl --unix-socket /var/run/docker.sock \\\n  -H \"Content-Type: application/tar\"\n  -X POST \"http://localhost/v1.41/images/create?fromImage=alpine\"\n  -H \"X-Registry-Auth\"\n  -d \"$JSON\"\n{\"status\":\"Pulling from library/alpine\",\"id\":\"3.1\"}\n{\"status\":\"Pulling fs layer\",\"progressDetail\":{},\"id\":\"8f13703509f7\"}\n{\"status\":\"Downloading\",\"progressDetail\":{\"current\":32768,\"total\":2244027},\"progress\":\"[\\u003e                                                  ] 32.77 kB/2.244 MB\",\"id\":\"8f13703509f7\"}\n...\n```\n\n## Commit a container\n\nCommit a container to create an image from its contents:\n\n- Go\n- Python\n- HTTP\n\n``` \npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/docker/docker/api/types\"\n    \"github.com/docker/docker/api/types/container\"\n    \"github.com/docker/docker/client\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        panic(err)\n    }\n\n    createResp, err := cli.ContainerCreate(ctx, &container.Config{\n        Image: \"alpine\",\n        Cmd:   []string{\"touch\", \"/helloworld\"},\n    }, nil, nil, nil, \"\")\n    if err != nil {\n        panic(err)\n    }\n\n    if err := cli.ContainerStart(ctx, createResp.ID, types.ContainerStartOptions{}); err != nil {\n        panic(err)\n    }\n\n    statusCh, errCh := cli.ContainerWait(ctx, createResp.ID, container.WaitConditionNotRunning)\n    select {\n    case err := <-errCh:\n        if err != nil {\n            panic(err)\n        }\n    case <-statusCh:\n    }\n\n    commitResp, err := cli.ContainerCommit(ctx, createResp.ID, types.ContainerCommitOptions{Reference: \"helloworld\"})\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(commitResp.ID)\n}\n```\n\n``` \nimport docker\nclient = docker.from_env()\ncontainer = client.containers.run(\"alpine\", [\"touch\", \"/helloworld\"], detach=True)\ncontainer.wait()\nimage = container.commit(\"helloworld\")\nprint(image.id)\n```\n\n``` \n$ docker run -d alpine touch /helloworld\n0888269a9d584f0fa8fc96b3c0d8d57969ceea3a64acf47cd34eebb4744dbc52\n$ curl --unix-socket /var/run/docker.sock\\\n  -X POST \"http://localhost/v1.41/commit?container=0888269a9d&repo=helloworld\"\n{\"Id\":\"sha256:6c86a5cd4b87f2771648ce619e319f3e508394b5bfc2cdbd2d60f59d52acda6c\"}\n```\n\n[developing](https://docs.docker.com/search/?q=developing), [api](https://docs.docker.com/search/?q=api), [sdk](https://docs.docker.com/search/?q=sdk), [developers](https://docs.docker.com/search/?q=developers), [rest](https://docs.docker.com/search/?q=rest), [curl](https://docs.docker.com/search/?q=curl), [python](https://docs.docker.com/search/?q=python), [go](https://docs.docker.com/search/?q=go)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/api/sdk/examples/](https://docs.docker.com/engine/api/sdk/examples/)"
- name: Frequently asked questions
  id: compose/faq/index
  summary: 'If you don’t see your question here, feel free to drop by #docker-compose on the Docker Community Slack'
  description: "# Frequently asked questions\n\nIf you don’t see your question here, feel free to drop by [\\#docker-compose](https://dockercommunity.slack.com/archives/C2X82D9PA) on the [Docker Community Slack](https://dockr.ly/slack).\n\n## Can I control service startup order?\n\nYes - see [Controlling startup order](../startup-order/index).\n\n## Why do my services take 10 seconds to recreate or stop?\n\nCompose stop attempts to stop a container by sending a `SIGTERM`. It then waits for a [default timeout of 10 seconds](../reference/stop/index). After the timeout, a `SIGKILL` is sent to the container to forcefully kill it. If you are waiting for this timeout, it means that your containers aren’t shutting down when they receive the `SIGTERM` signal.\n\nThere has already been a lot written about this problem of [processes handling signals](https://medium.com/@gchudnov/trapping-signals-in-docker-containers-7a57fdda7d86) in containers.\n\nTo fix this problem, try the following:\n\n- Make sure you’re using the exec form of `CMD` and `ENTRYPOINT` in your Dockerfile.\n\n  For example use `[\"program\", \"arg1\", \"arg2\"]` not `\"program arg1 arg2\"`. Using the string form causes Docker to run your process using `bash` which doesn’t handle signals properly. Compose always uses the JSON form, so don’t worry if you override the command or entrypoint in your Compose file.\n\n- If you are able, modify the application that you’re running to add an explicit signal handler for `SIGTERM`.\n\n- Set the `stop_signal` to a signal which the application knows how to handle:\n\n``` \nservices:\n  web:\n    build: .\n    stop_signal: SIGINT\n```\n\n- If you can’t modify the application, wrap the application in a lightweight init system (like [s6](https://skarnet.org/software/s6/)) or a signal proxy (like [dumb-init](https://github.com/Yelp/dumb-init) or [tini](https://github.com/krallin/tini)). Either of these wrappers takes care of handling `SIGTERM` properly.\n\n## How do I run multiple copies of a Compose file on the same host?\n\nCompose uses the project name to create unique identifiers for all of a project’s containers and other resources. To run multiple copies of a project, set a custom project name using the [`-p` command line option](../reference/index) or the [`COMPOSE_PROJECT_NAME` environment variable](../reference/envvars/index#compose_project_name).\n\n## What’s the difference between `up`, `run`, and `start`?\n\nTypically, you want `docker-compose up`. Use `up` to start or restart all the services defined in a `docker-compose.yml`. In the default “attached” mode, you see all the logs from all the containers. In “detached” mode (`-d`), Compose exits after starting the containers, but the containers continue to run in the background.\n\nThe `docker-compose run` command is for running “one-off” or “adhoc” tasks. It requires the service name you want to run and only starts containers for services that the running service depends on. Use `run` to run tests or perform an administrative task such as removing or adding data to a data volume container. The `run` command acts like `docker run -ti` in that it opens an interactive terminal to the container and returns an exit status matching the exit status of the process in the container.\n\nThe `docker-compose start` command is useful only to restart containers that were previously created, but were stopped. It never creates new containers.\n\n## Can I use json instead of yaml for my Compose file?\n\nYes. [Yaml is a superset of json](https://stackoverflow.com/a/1729545/444646) so any JSON file should be valid Yaml. To use a JSON file with Compose, specify the filename to use, for example:\n\n``` \n$ docker-compose -f docker-compose.json up\n```\n\n## Should I include my code with `COPY`/`ADD` or a volume?\n\nYou can add your code to the image using `COPY` or `ADD` directive in a `Dockerfile`. This is useful if you need to relocate your code along with the Docker image, for example when you’re sending code to another environment (production, CI, etc).\n\nYou should use a `volume` if you want to make changes to your code and see them reflected immediately, for example when you’re developing code and your server supports hot code reloading or live-reload.\n\nThere may be cases where you want to use both. You can have the image include the code using a `COPY`, and use a `volume` in your Compose file to include the code from the host during development. The volume overrides the directory contents of the image.\n\n## Where can I find example compose files?\n\nThere are [many examples of Compose files on GitHub](https://github.com/search?q=in%3Apath+docker-compose.yml+extension%3Ayml&type=Code).\n\n## Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [faq](https://docs.docker.com/search/?q=faq)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/faq/](https://docs.docker.com/compose/faq/)"
- name: Get started with Docker Compose
  id: compose/gettingstarted/index
  summary: On this page you build a simple Python web application running on Docker Compose
  description: "# Get started with Docker Compose\n\nOn this page you build a simple Python web application running on Docker Compose. The application uses the Flask framework and maintains a hit counter in Redis. While the sample uses Python, the concepts demonstrated here should be understandable even if you’re not familiar with it.\n\n## Prerequisites\n\nMake sure you have already installed both [Docker Engine](https://docs.docker.com/get-docker/) and [Docker Compose](../install/index). You don’t need to install Python or Redis, as both are provided by Docker images.\n\n## Step 1: Setup\n\nDefine the application dependencies.\n\n1.  Create a directory for the project:\n\n    ``` \n    $ mkdir composetest\n    $ cd composetest\n    ```\n\n2.  Create a file called `app.py` in your project directory and paste this in:\n\n    ``` \n    import time\n\n    import redis\n    from flask import Flask\n\n    app = Flask(__name__)\n    cache = redis.Redis(host='redis', port=6379)\n\n    def get_hit_count():\n        retries = 5\n        while True:\n            try:\n                return cache.incr('hits')\n            except redis.exceptions.ConnectionError as exc:\n                if retries == 0:\n                    raise exc\n                retries -= 1\n                time.sleep(0.5)\n\n    @app.route('/')\n    def hello():\n        count = get_hit_count()\n        return 'Hello World! I have been seen {} times.\\n'.format(count)\n    ```\n\n    In this example, `redis` is the hostname of the redis container on the application’s network. We use the default port for Redis, `6379`.\n\n    > Handling transient errors\n    >\n    > Note the way the `get_hit_count` function is written. This basic retry loop lets us attempt our request multiple times if the redis service is not available. This is useful at startup while the application comes online, but also makes our application more resilient if the Redis service needs to be restarted anytime during the app’s lifetime. In a cluster, this also helps handling momentary connection drops between nodes.\n\n3.  Create another file called `requirements.txt` in your project directory and paste this in:\n\n    ``` \n    flask\n    redis\n    ```\n\n## Step 2: Create a Dockerfile\n\nIn this step, you write a Dockerfile that builds a Docker image. The image contains all the dependencies the Python application requires, including Python itself.\n\nIn your project directory, create a file named `Dockerfile` and paste the following:\n\n``` \n# syntax=docker/dockerfile:1\nFROM python:3.7-alpine\nWORKDIR /code\nENV FLASK_APP=app.py\nENV FLASK_RUN_HOST=0.0.0.0\nRUN apk add --no-cache gcc musl-dev linux-headers\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nEXPOSE 5000\nCOPY . .\nCMD [\"flask\", \"run\"]\n```\n\nThis tells Docker to:\n\n- Build an image starting with the Python 3.7 image.\n- Set the working directory to `/code`.\n- Set environment variables used by the `flask` command.\n- Install gcc and other dependencies\n- Copy `requirements.txt` and install the Python dependencies.\n- Add metadata to the image to describe that the container is listening on port 5000\n- Copy the current directory `.` in the project to the workdir `.` in the image.\n- Set the default command for the container to `flask run`.\n\nFor more information on how to write Dockerfiles, see the [Docker user guide](https://docs.docker.com/develop/) and the [Dockerfile reference](../../engine/reference/builder/index).\n\n## Step 3: Define services in a Compose file\n\nCreate a file called `docker-compose.yml` in your project directory and paste the following:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:5000\"\n  redis:\n    image: \"redis:alpine\"\n```\n\nThis Compose file defines two services: `web` and `redis`.\n\n### Web service\n\nThe `web` service uses an image that’s built from the `Dockerfile` in the current directory. It then binds the container and the host machine to the exposed port, `8000`. This example service uses the default port for the Flask web server, `5000`.\n\n### Redis service\n\nThe `redis` service uses a public [Redis](https://registry.hub.docker.com/_/redis/) image pulled from the Docker Hub registry.\n\n## Step 4: Build and run your app with Compose\n\n1.  From your project directory, start up your application by running `docker-compose up`.\n\n    ``` \n    $ docker-compose up\n\n    Creating network \"composetest_default\" with the default driver\n    Creating composetest_web_1 ...\n    Creating composetest_redis_1 ...\n    Creating composetest_web_1\n    Creating composetest_redis_1 ... done\n    Attaching to composetest_web_1, composetest_redis_1\n    web_1    |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n    redis_1  | 1:C 17 Aug 22:11:10.480 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n    redis_1  | 1:C 17 Aug 22:11:10.480 # Redis version=4.0.1, bits=64, commit=00000000, modified=0, pid=1, just started\n    redis_1  | 1:C 17 Aug 22:11:10.480 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n    web_1    |  * Restarting with stat\n    redis_1  | 1:M 17 Aug 22:11:10.483 * Running mode=standalone, port=6379.\n    redis_1  | 1:M 17 Aug 22:11:10.483 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n    web_1    |  * Debugger is active!\n    redis_1  | 1:M 17 Aug 22:11:10.483 # Server initialized\n    redis_1  | 1:M 17 Aug 22:11:10.483 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n    web_1    |  * Debugger PIN: 330-787-903\n    redis_1  | 1:M 17 Aug 22:11:10.483 * Ready to accept connections\n    ```\n\n    Compose pulls a Redis image, builds an image for your code, and starts the services you defined. In this case, the code is statically copied into the image at build time.\n\n2.  Enter http://localhost:8000/ in a browser to see the application running.\n\n    If you’re using Docker natively on Linux, Docker Desktop for Mac, or Docker Desktop for Windows, then the web app should now be listening on port 8000 on your Docker daemon host. Point your web browser to http://localhost:8000 to find the `Hello World` message. If this doesn’t resolve, you can also try http://127.0.0.1:8000.\n\n    You should see a message in your browser saying:\n\n    ``` \n    Hello World! I have been seen 1 times.\n    ```\n\n3.  Refresh the page.\n\n    The number should increment.\n\n    ``` \n    Hello World! I have been seen 2 times.\n    ```\n\n4.  Switch to another terminal window, and type `docker image ls` to list local images.\n\n    Listing images at this point should return `redis` and `web`.\n\n    ``` \n    $ docker image ls\n\n    REPOSITORY        TAG           IMAGE ID      CREATED        SIZE\n    composetest_web   latest        e2c21aa48cc1  4 minutes ago  93.8MB\n    python            3.4-alpine    84e6077c7ab6  7 days ago     82.5MB\n    redis             alpine        9d8fa9aa0e5b  3 weeks ago    27.5MB\n    ```\n\n    You can inspect images with `docker inspect <tag or id>`.\n\n5.  Stop the application, either by running `docker-compose down` from within your project directory in the second terminal, or by hitting CTRL+C in the original terminal where you started the app.\n\n## Step 5: Edit the Compose file to add a bind mount\n\nEdit `docker-compose.yml` in your project directory to add a [bind mount](https://docs.docker.com/storage/bind-mounts/) for the `web` service:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:5000\"\n    volumes:\n      - .:/code\n    environment:\n      FLASK_ENV: development\n  redis:\n    image: \"redis:alpine\"\n```\n\nThe new `volumes` key mounts the project directory (current directory) on the host to `/code` inside the container, allowing you to modify the code on the fly, without having to rebuild the image. The `environment` key sets the `FLASK_ENV` environment variable, which tells `flask run` to run in development mode and reload the code on change. This mode should only be used in development.\n\n## Step 6: Re-build and run the app with Compose\n\nFrom your project directory, type `docker-compose up` to build the app with the updated Compose file, and run it.\n\n``` \n$ docker-compose up\n\nCreating network \"composetest_default\" with the default driver\nCreating composetest_web_1 ...\nCreating composetest_redis_1 ...\nCreating composetest_web_1\nCreating composetest_redis_1 ... done\nAttaching to composetest_web_1, composetest_redis_1\nweb_1    |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n...\n```\n\nCheck the `Hello World` message in a web browser again, and refresh to see the count increment.\n\n> Shared folders, volumes, and bind mounts\n>\n> - If your project is outside of the `Users` directory (`cd ~`), then you need to share the drive or location of the Dockerfile and volume you are using. If you get runtime errors indicating an application file is not found, a volume mount is denied, or a service cannot start, try enabling file or drive sharing. Volume mounting requires shared drives for projects that live outside of `C:\\Users` (Windows) or `/Users` (Mac), and is required for *any* project on Docker Desktop for Windows that uses [Linux containers](https://docs.docker.com/desktop/windows/#switch-between-windows-and-linux-containers). For more information, see [File sharing](https://docs.docker.com/desktop/mac/#file-sharing) on Docker for Mac, and the general examples on how to [Manage data in containers](https://docs.docker.com/storage/volumes/).\n>\n> - If you are using Oracle VirtualBox on an older Windows OS, you might encounter an issue with shared folders as described in this [VB trouble ticket](https://www.virtualbox.org/ticket/14920). Newer Windows systems meet the requirements for [Docker Desktop for Windows](https://docs.docker.com/desktop/windows/install/) and do not need VirtualBox.\n\n## Step 7: Update the application\n\nBecause the application code is now mounted into the container using a volume, you can make changes to its code and see the changes instantly, without having to rebuild the image.\n\nChange the greeting in `app.py` and save it. For example, change the `Hello World!` message to `Hello from Docker!`:\n\n``` \nreturn 'Hello from Docker! I have been seen {} times.\\n'.format(count)\n```\n\nRefresh the app in your browser. The greeting should be updated, and the counter should still be incrementing.\n\n## Step 8: Experiment with some other commands\n\nIf you want to run your services in the background, you can pass the `-d` flag (for “detached” mode) to `docker-compose up` and use `docker-compose ps` to see what is currently running:\n\n``` \n$ docker-compose up -d\n\nStarting composetest_redis_1...\nStarting composetest_web_1...\n\n$ docker-compose ps\n\n       Name                      Command               State           Ports         \n-------------------------------------------------------------------------------------\ncomposetest_redis_1   docker-entrypoint.sh redis ...   Up      6379/tcp              \ncomposetest_web_1     flask run                        Up      0.0.0.0:8000->5000/tcp\n```\n\nThe `docker-compose run` command allows you to run one-off commands for your services. For example, to see what environment variables are available to the `web` service:\n\n``` \n$ docker-compose run web env\n```\n\nSee `docker-compose --help` to see other available commands.\n\nIf you started Compose with `docker-compose up -d`, stop your services once you’ve finished with them:\n\n``` \n$ docker-compose stop\n```\n\nYou can bring everything down, removing the containers entirely, with the `down` command. Pass `--volumes` to also remove the data volume used by the Redis container:\n\n``` \n$ docker-compose down --volumes\n```\n\nAt this point, you have seen the basics of how Compose works.\n\n## Where to go next\n\n- Next, try the [Sample apps with Compose](../samples-for-compose/index)\n- [Explore the full list of Compose commands](../reference/index)\n- [Compose configuration file reference](../compose-file/index)\n- To learn more about volumes and bind mounts, see [Manage data in Docker](https://docs.docker.com/storage/)\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [orchestration](https://docs.docker.com/search/?q=orchestration), [containers](https://docs.docker.com/search/?q=containers)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/gettingstarted/](https://docs.docker.com/compose/gettingstarted/)"
- name: Getting started with swarm mode
  id: engine/swarm/swarm-tutorial/index
  summary: This tutorial introduces you to the features of Docker Engine Swarm mode
  description: "# Getting started with swarm mode\n\nThis tutorial introduces you to the features of Docker Engine Swarm mode. You may want to familiarize yourself with the [key concepts](../key-concepts/index) before you begin.\n\nThe tutorial guides you through the following activities:\n\n- initializing a cluster of Docker Engines in swarm mode\n- adding nodes to the swarm\n- deploying application services to the swarm\n- managing the swarm once you have everything running\n\nThis tutorial uses Docker Engine CLI commands entered on the command line of a terminal window.\n\nIf you are brand new to Docker, see [About Docker Engine](../../index).\n\n## Set up\n\nTo run this tutorial, you need the following:\n\n- [three Linux hosts which can communicate over a network, with Docker installed](#three-networked-host-machines)\n- [the IP address of the manager machine](#the-ip-address-of-the-manager-machine)\n- [open ports between the hosts](#open-protocols-and-ports-between-the-hosts)\n\n### Three networked host machines\n\nThis tutorial requires three Linux hosts which have Docker installed and can communicate over a network. These can be physical machines, virtual machines, Amazon EC2 instances, or hosted in some other way. Check out [Getting started - Swarms](../../../get-started/swarm-deploy/index#prerequisites) for one possible set-up for the hosts.\n\nOne of these machines is a manager (called `manager1`) and two of them are workers (`worker1` and `worker2`).\n\n> **Note**: You can follow many of the tutorial steps to test single-node swarm as well, in which case you need only one host. Multi-node commands do not work, but you can initialize a swarm, create services, and scale them.\n\n#### Install Docker Engine on Linux machines\n\nIf you are using Linux based physical computers or cloud-provided computers as hosts, simply follow the [Linux install instructions](../../install/index) for your platform. Spin up the three machines, and you are ready. You can test both single-node and multi-node swarm scenarios on Linux machines.\n\n#### Use Docker Desktop for Mac or Docker Desktop for Windows\n\nAlternatively, install the latest [Docker Desktop for Mac](https://docs.docker.com/desktop/mac/) or [Docker Desktop for Windows](https://docs.docker.com/desktop/windows/) application on one computer. You can test both single-node and multi-node swarm from this computer.\n\n- You can use Docker Desktop for Mac or Windows to test *single-node* features of swarm mode, including initializing a swarm with a single node, creating services, and scaling services.\n- Currently, you cannot use Docker Desktop for Mac or Docker Desktop for Windows alone to test a *multi-node* swarm, but many examples are applicable to a single-node Swarm setup.\n\n### The IP address of the manager machine\n\nThe IP address must be assigned to a network interface available to the host operating system. All nodes in the swarm need to connect to the manager at the IP address.\n\nBecause other nodes contact the manager node on its IP address, you should use a fixed IP address.\n\nYou can run `ifconfig` on Linux or macOS to see a list of the available network interfaces.\n\nThe tutorial uses `manager1` : `192.168.99.100`.\n\n### Open protocols and ports between the hosts\n\nThe following ports must be available. On some systems, these ports are open by default.\n\n- **TCP port 2377** for cluster management communications\n- **TCP** and **UDP port 7946** for communication among nodes\n- **UDP port 4789** for overlay network traffic\n\nIf you plan on creating an overlay network with encryption (`--opt encrypted`), you also need to ensure **ip protocol 50** (**ESP**) traffic is allowed.\n\n## What’s next?\n\nAfter you have set up your environment, you are ready to [create a swarm](create-swarm/index).\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/](https://docs.docker.com/engine/swarm/swarm-tutorial/)"
- name: How nodes work
  id: engine/swarm/how-swarm-mode-works/nodes/index
  summary: Docker Engine 1.12 introduces swarm mode that enables you to create a cluster of one or more Docker Engines called a swarm
  description: "# How nodes work\n\nDocker Engine 1.12 introduces swarm mode that enables you to create a cluster of one or more Docker Engines called a swarm. A swarm consists of one or more nodes: physical or virtual machines running Docker Engine 1.12 or later in swarm mode.\n\nThere are two types of nodes: [**managers**](#manager-nodes) and [**workers**](#worker-nodes).\n\nIf you haven’t already, read through the [swarm mode overview](../../index) and [key concepts](../../key-concepts/index).\n\n## Manager nodes\n\nManager nodes handle cluster management tasks:\n\n- maintaining cluster state\n- scheduling services\n- serving swarm mode [HTTP API endpoints](../../../api/index)\n\nUsing a [Raft](https://raft.github.io/raft.pdf) implementation, the managers maintain a consistent internal state of the entire swarm and all the services running on it. For testing purposes it is OK to run a swarm with a single manager. If the manager in a single-manager swarm fails, your services continue to run, but you need to create a new cluster to recover.\n\nTo take advantage of swarm mode’s fault-tolerance features, Docker recommends you implement an odd number of nodes according to your organization’s high-availability requirements. When you have multiple managers you can recover from the failure of a manager node without downtime.\n\n- A three-manager swarm tolerates a maximum loss of one manager.\n\n- A five-manager swarm tolerates a maximum simultaneous loss of two manager nodes.\n\n- An `N` manager cluster tolerates the loss of at most `(N-1)/2` managers.\n\n- Docker recommends a maximum of seven manager nodes for a swarm.\n\n  > **Important Note**: Adding more managers does NOT mean increased scalability or higher performance. In general, the opposite is true.\n\n## Worker nodes\n\nWorker nodes are also instances of Docker Engine whose sole purpose is to execute containers. Worker nodes don’t participate in the Raft distributed state, make scheduling decisions, or serve the swarm mode HTTP API.\n\nYou can create a swarm of one manager node, but you cannot have a worker node without at least one manager node. By default, all managers are also workers. In a single manager node cluster, you can run commands like `docker service create` and the scheduler places all tasks on the local Engine.\n\nTo prevent the scheduler from placing tasks on a manager node in a multi-node swarm, set the availability for the manager node to `Drain`. The scheduler gracefully stops tasks on nodes in `Drain` mode and schedules the tasks on an `Active` node. The scheduler does not assign new tasks to nodes with `Drain` availability.\n\nRefer to the [`docker node update`](../../../reference/commandline/node_update/index) command line reference to see how to change node availability.\n\n## Change roles\n\nYou can promote a worker node to be a manager by running `docker node promote`. For example, you may want to promote a worker node when you take a manager node offline for maintenance. See [node promote](../../../reference/commandline/node_promote/index).\n\nYou can also demote a manager node to a worker node. See [node demote](../../../reference/commandline/node_demote/index).\n\n## Learn more\n\n- Read about how swarm mode [services](../services/index) work.\n- Learn how [PKI](../pki/index) works in swarm mode.\n\n[docker](https://docs.docker.com/search/?q=docker), [container](https://docs.docker.com/search/?q=container), [cluster](https://docs.docker.com/search/?q=cluster), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [node](https://docs.docker.com/search/?q=node)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/)"
- name: How services work
  id: engine/swarm/how-swarm-mode-works/services/index
  summary: To deploy an application image when Docker Engine is in swarm mode, you create a service
  description: "# How services work\n\nTo deploy an application image when Docker Engine is in swarm mode, you create a service. Frequently a service is the image for a microservice within the context of some larger application. Examples of services might include an HTTP server, a database, or any other type of executable program that you wish to run in a distributed environment.\n\nWhen you create a service, you specify which container image to use and which commands to execute inside running containers. You also define options for the service including:\n\n- the port where the swarm makes the service available outside the swarm\n- an overlay network for the service to connect to other services in the swarm\n- CPU and memory limits and reservations\n- a rolling update policy\n- the number of replicas of the image to run in the swarm\n\n## Services, tasks, and containers\n\nWhen you deploy the service to the swarm, the swarm manager accepts your service definition as the desired state for the service. Then it schedules the service on nodes in the swarm as one or more replica tasks. The tasks run independently of each other on nodes in the swarm.\n\nFor example, imagine you want to load balance between three instances of an HTTP listener. The diagram below shows an HTTP listener service with three replicas. Each of the three instances of the listener is a task in the swarm.\n\nA container is an isolated process. In the swarm mode model, each task invokes exactly one container. A task is analogous to a “slot” where the scheduler places a container. Once the container is live, the scheduler recognizes that the task is in a running state. If the container fails health checks or terminates, the task terminates.\n\n## Tasks and scheduling\n\nA task is the atomic unit of scheduling within a swarm. When you declare a desired service state by creating or updating a service, the orchestrator realizes the desired state by scheduling tasks. For instance, you define a service that instructs the orchestrator to keep three instances of an HTTP listener running at all times. The orchestrator responds by creating three tasks. Each task is a slot that the scheduler fills by spawning a container. The container is the instantiation of the task. If an HTTP listener task subsequently fails its health check or crashes, the orchestrator creates a new replica task that spawns a new container.\n\nA task is a one-directional mechanism. It progresses monotonically through a series of states: assigned, prepared, running, etc. If the task fails the orchestrator removes the task and its container and then creates a new task to replace it according to the desired state specified by the service.\n\nThe underlying logic of Docker swarm mode is a general purpose scheduler and orchestrator. The service and task abstractions themselves are unaware of the containers they implement. Hypothetically, you could implement other types of tasks such as virtual machine tasks or non-containerized process tasks. The scheduler and orchestrator are agnostic about the type of task. However, the current version of Docker only supports container tasks.\n\nThe diagram below shows how swarm mode accepts service create requests and schedules tasks to worker nodes.\n\n### Pending services\n\nA service may be configured in such a way that no node currently in the swarm can run its tasks. In this case, the service remains in state `pending`. Here are a few examples of when a service might remain in state `pending`.\n\n> **Note**: If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in `pending`.\n\n- If all nodes are paused or drained, and you create a service, it is pending until a node becomes available. In reality, the first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.\n\n- You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks. If you specify a very large value, such as 500 GB, the task stays pending forever, unless you really have a node which can satisfy it.\n\n- You can impose placement constraints on the service, and the constraints may not be able to be honored at a given time.\n\nThis behavior illustrates that the requirements and configuration of your tasks are not tightly tied to the current state of the swarm. As the administrator of a swarm, you declare the desired state of your swarm, and the manager works with the nodes in the swarm to create that state. You do not need to micro-manage the tasks on the swarm.\n\n## Replicated and global services\n\nThere are two types of service deployments, replicated and global.\n\nFor a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.\n\nA global service is a service that runs one task on every node. There is no pre-specified number of tasks. Each time you add a node to the swarm, the orchestrator creates a task and the scheduler assigns the task to the new node. Good candidates for global services are monitoring agents, an anti-virus scanners or other types of containers that you want to run on every node in the swarm.\n\nThe diagram below shows a three-service replica in yellow and a global service in gray.\n\n## Learn more\n\n- Read about how swarm mode [nodes](../nodes/index) work.\n- Learn how [PKI](../pki/index) works in swarm mode.\n\n[docker](https://docs.docker.com/search/?q=docker), [container](https://docs.docker.com/search/?q=container), [cluster](https://docs.docker.com/search/?q=cluster), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [node](https://docs.docker.com/search/?q=node)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/)"
- name: Inspect a service on the swarm
  id: engine/swarm/swarm-tutorial/inspect-service/index
  summary: When you have deployed a service to your swarm, you can use the Docker CLI to see details about the service running in the swarm
  description: "# Inspect a service on the swarm\n\nWhen you have [deployed a service](../deploy-service/index) to your swarm, you can use the Docker CLI to see details about the service running in the swarm.\n\n1.  If you haven’t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n\n2.  Run `docker service inspect --pretty <SERVICE-ID>` to display the details about a service in an easily readable format.\n\n    To see the details on the `helloworld` service:\n\n    ``` \n    [manager1]$ docker service inspect --pretty helloworld\n\n    ID:     9uk4639qpg7npwf3fn2aasksr\n    Name:       helloworld\n    Service Mode:   REPLICATED\n     Replicas:      1\n    Placement:\n    UpdateConfig:\n     Parallelism:   1\n    ContainerSpec:\n     Image:     alpine\n     Args:  ping docker.com\n    Resources:\n    Endpoint Mode:  vip\n    ```\n\n    > **Tip**: To return the service details in json format, run the same command without the `--pretty` flag.\n\n    ``` \n    [manager1]$ docker service inspect helloworld\n    [\n    {\n        \"ID\": \"9uk4639qpg7npwf3fn2aasksr\",\n        \"Version\": {\n            \"Index\": 418\n        },\n        \"CreatedAt\": \"2016-06-16T21:57:11.622222327Z\",\n        \"UpdatedAt\": \"2016-06-16T21:57:11.622222327Z\",\n        \"Spec\": {\n            \"Name\": \"helloworld\",\n            \"TaskTemplate\": {\n                \"ContainerSpec\": {\n                    \"Image\": \"alpine\",\n                    \"Args\": [\n                        \"ping\",\n                        \"docker.com\"\n                    ]\n                },\n                \"Resources\": {\n                    \"Limits\": {},\n                    \"Reservations\": {}\n                },\n                \"RestartPolicy\": {\n                    \"Condition\": \"any\",\n                    \"MaxAttempts\": 0\n                },\n                \"Placement\": {}\n            },\n            \"Mode\": {\n                \"Replicated\": {\n                    \"Replicas\": 1\n                }\n            },\n            \"UpdateConfig\": {\n                \"Parallelism\": 1\n            },\n            \"EndpointSpec\": {\n                \"Mode\": \"vip\"\n            }\n        },\n        \"Endpoint\": {\n            \"Spec\": {}\n        }\n    }\n    ]\n    ```\n\n3.  Run `docker service ps <SERVICE-ID>` to see which nodes are running the service:\n\n    ``` \n    [manager1]$ docker service ps helloworld\n\n    NAME                                    IMAGE   NODE     DESIRED STATE  CURRENT STATE           ERROR               PORTS\n    helloworld.1.8p1vev3fq5zm0mi8g0as41w35  alpine  worker2  Running        Running 3 minutes\n    ```\n\n    In this case, the one instance of the `helloworld` service is running on the `worker2` node. You may see the service running on your manager node. By default, manager nodes in a swarm can execute tasks just like worker nodes.\n\n    Swarm also shows you the `DESIRED STATE` and `CURRENT STATE` of the service task so you can see if tasks are running according to the service definition.\n\n4.  Run `docker ps` on the node where the task is running to see details about the container for the task.\n\n    > **Tip**: If `helloworld` is running on a node other than your manager node, you must ssh to that node.\n\n    ``` \n    [worker2]$ docker ps\n\n    CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n    e609dde94e47        alpine:latest       \"ping docker.com\"   3 minutes ago       Up 3 minutes                            helloworld.1.8p1vev3fq5zm0mi8g0as41w35\n    ```\n\n## What’s next?\n\nNext, you can [change the scale](../scale-service/index) for the service running in the swarm.\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/](https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/)"
- name: Install Docker Compose
  id: compose/install/index
  summary: This page contains information on how to install Docker Compose
  description: "# Install Docker Compose\n\nThis page contains information on how to install Docker Compose. You can run Compose on macOS, Windows, and 64-bit Linux.\n\n## Prerequisites\n\nDocker Compose relies on Docker Engine for any meaningful work, so make sure you have Docker Engine installed either locally or remote, depending on your setup.\n\n- On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs.\n\n- On Linux systems, you can install Docker Compose with the Docker Engine using the [convenience script](../../engine/install/index#server). Select the install Docker Engine page for your distribution and then look for instructions on installing using the convenience script.  \n  Otherwise, you should first install the [Docker Engine](../../engine/install/index#server) for your OS and then refer to this page for instructions on installing Compose on Linux systems.\n\n- To run Compose as a non-root user, see [Manage Docker as a non-root user](../../engine/install/linux-postinstall/index).\n\n## Install Compose\n\nFollow the instructions below to install Compose on Mac, Windows, Windows Server, or Linux systems.\n\n> Install a different version\n>\n> The instructions below outline installation of the current stable release (**v2.5.0**) of Compose. To install a different version of Compose, replace the given release number with the one that you want.\n>\n> Compose releases are also listed and available for direct download on the [Compose repository release page on GitHub](https://github.com/docker/compose/releases).\n>\n> To install the Python version of Compose, follow instructions in the [Compose v1 GitHub branch](https://github.com/docker/compose/blob/master/INSTALL/).\n\n- Mac\n- Windows\n- Windows Server\n- Linux\n- Linux Standalone binary\n\n### Install Compose on macOS\n\n**Docker Desktop for Mac** includes Compose along with other Docker apps, so Mac users do not need to install Compose separately. For installation instructions, see [Install Docker Desktop on Mac](https://docs.docker.com/desktop/mac/install/).\n\n### Install Compose on Windows desktop systems\n\n**Docker Desktop for Windows** includes Compose along with other Docker apps, so most Windows users do not need to install Compose separately. For install instructions, see [Install Docker Desktop on Windows](https://docs.docker.com/desktop/windows/install/).\n\nIf you are running the Docker daemon and client directly on Microsoft Windows Server, follow the instructions in the Windows Server tab.\n\n### Install Compose on Windows Server\n\nFollow these instructions if you are running the Docker daemon and client directly on Microsoft Windows Server and want to install Docker Compose.\n\n1.  Start an “elevated” PowerShell (run it as administrator). Search for PowerShell, right-click, and choose **Run as administrator**. When asked if you want to allow this app to make changes to your device, click **Yes**.\n\n2.  In PowerShell, since GitHub now requires TLS1.2, run the following:\n\n    ``` \n    [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12\n    ```\n\n    Then run the following command to download the current stable release of Compose (v2.5.0):\n\n    ``` \n    Invoke-WebRequest \"https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-Windows-x86_64.exe\" -UseBasicParsing -OutFile $Env:ProgramFiles\\Docker\\docker-compose.exe\n    ```\n\n    > **Note**\n    >\n    > On Windows Server 2019, you can add the Compose executable to `$Env:ProgramFiles\\Docker`. Because this directory is registered in the system `PATH`, you can run the `docker-compose --version` command on the subsequent step with no additional configuration.\n\n    > To install a different version of Compose, substitute `v2.5.0` with the version of Compose you want to use.\n\n3.  Test the installation.\n\n    ``` \n    $ docker compose version\n    Docker Compose version v2.5.0\n    ```\n\n### Install Compose on Linux systems\n\nYou can install Docker Compose in different ways, depending on your needs:\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n- Some users [download and install the binary](#install-the-binary-manually), and manage upgrades manually.\n\n#### Install using the convenience script\n\nAs Docker Compose is now part of the Docker CLI it can be installed via a convenience script with Docker Engine and the CLI.  \n[Choose your Linux distribution](../../engine/install/index#server) and follow the instructions.\n\n#### Install using the repository\n\nIf you already follow the instructions to install Docker Engine, Docker Compose should already be installed.  \nOtherwise, you can set up the Docker repository as mentioned in the Docker Engine installation, [choose your Linux distribution](../../engine/install/index#server) and go to the `Set up the repository` section.\n\nWhen finished\n\n1.  Update the `apt` package index, and install the *latest version* of Docker Compose, or go to the next step to install a specific version:\n\n    ``` \n     $ sudo apt-get update\n     $ sudo apt-get install docker-compose-plugin\n    ```\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List the versions available in your repo:\n\n    ``` \n    $ apt-cache madison docker-compose-plugin\n\n      docker-compose-plugin | 2.3.3~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable arm64 Packages\n    ```\n\n    b\\. Install a specific version using the version string from the second column, for example, `2.3.3~ubuntu-focal`.\n\n    ``` \n    $ sudo apt-get install docker-compose-plugin=<VERSION_STRING>\n    ```\n\n3.  Verify that Docker Compose is installed correctly by checking the version.\n\n    ``` \n    $ docker compose version\n    Docker Compose version v2.3.3\n    ```\n\n#### Install the binary manually\n\nOn Linux, you can download the Docker Compose binary from the [Compose repository release page on GitHub](https://github.com/docker/compose/releases) and copying it into `$HOME/.docker/cli-plugins` as `docker-compose`. Follow the instructions from the link, which involve running the `curl` command in your terminal to download the binaries. These step-by-step instructions are also included below.\n\n1.  Run this command to download the current stable release of Docker Compose:\n\n    ``` \n    $ DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}\n    $ mkdir -p $DOCKER_CONFIG/cli-plugins\n    $ curl -SL https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-linux-x86_64 -o $DOCKER_CONFIG/cli-plugins/docker-compose\n    ```\n\n    This command installs Compose for the active user under `$HOME` directory. To install Docker Compose for all users on your system, replace `~/.docker/cli-plugins` with `/usr/local/lib/docker/cli-plugins`.\n\n    > To install a different version of Compose, substitute `v2.5.0` with the version of Compose you want to use.\n\n2.  Apply executable permissions to the binary:\n\n    ``` \n     $ chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose\n    ```\n\n    or if you choose to install Compose for all users\n\n    ``` \n     $ sudo chmod +x /usr/local/lib/docker/cli-plugins/docker-compose\n    ```\n\n3.  Test the installation.\n\n    ``` \n     $ docker compose version\n     Docker Compose version v2.5.0\n    ```\n\n### Install Compose as standalone binary on Linux systems\n\nYou can use Compose as a standalone binary without installing the Docker CLI.\n\n1.  Run this command to download the current stable release of Docker Compose:\n\n``` \n  $ curl -SL https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose\n```\n\n> To install a different version of Compose, substitute `v2.5.0` with the version of Compose you want to use.\n\n1.  Apply executable permissions to the binary:\n\n``` \n  $ sudo chmod +x /usr/local/bin/docker-compose\n```\n\n> **Note**:\n>\n> If the command `docker-compose` fails after installation, check your path. You can also create a symbolic link to `/usr/bin` or any other directory in your path.\n>\n> For example:\n>\n> ``` \n> $ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n> ```\n\n1.  Test the installation.\n\n    ``` \n     $ docker-compose --version\n     Docker Compose version v2.5.0\n    ```\n\n## Uninstallation\n\nTo uninstall Docker Compose if you installed using `curl`:\n\n``` \n$ rm $DOCKER_CONFIG/cli-plugins/docker-compose\n```\n\nor if you choose to install Compose for all users\n\n``` \n$ sudo rm /usr/local/lib/docker/cli-plugins/docker-compose\n```\n\n> Got a “Permission denied” error?\n>\n> If you get a “Permission denied” error using either of the above methods, you probably do not have the proper permissions to remove `docker-compose`. To force the removal, prepend `sudo` to either of the above commands and run again.\n\n## Where to go next\n\n- [User guide](../index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[compose](https://docs.docker.com/search/?q=compose), [orchestration](https://docs.docker.com/search/?q=orchestration), [install](https://docs.docker.com/search/?q=install), [installation](https://docs.docker.com/search/?q=installation), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/)"
- name: Install Docker Engine
  id: engine/install/index
  summary: Docker Desktop helps you build, share, and run containers easily on Mac and Windows as you do on Linux
  description: "# Install Docker Engine\n\n> **Docker Desktop for Linux**\n>\n> Docker Desktop helps you build, share, and run containers easily on Mac and Windows as you do on Linux. We are excited to share that Docker Desktop for Linux is now GA. For more information, see [Docker Desktop for Linux](https://docs.docker.com/desktop/linux/install/).\n\n## Supported platforms\n\nDocker Engine is available on a variety of [Linux platforms](https://docs.docker.com/desktop/linux/install/), [macOS](https://docs.docker.com/desktop/mac/install/) and [Windows 10](https://docs.docker.com/desktop/windows/install/) through Docker Desktop, and as a [static binary installation](binaries/index). Find your preferred operating system below.\n\n### Desktop\n\n| Platform                                                                       |                    x86_64 / amd64                    |              arm64 (Apple Silicon)               |\n|:-------------------------------------------------------------------------------|:----------------------------------------------------:|:------------------------------------------------:|\n| [Docker Desktop for Linux](https://docs.docker.com/desktop/linux/install/)     |  [](https://docs.docker.com/desktop/linux/install/)  |                                                  |\n| [Docker Desktop for Mac (macOS)](https://docs.docker.com/desktop/mac/install/) |   [](https://docs.docker.com/desktop/mac/install/)   | [](https://docs.docker.com/desktop/mac/install/) |\n| [Docker Desktop for Windows](https://docs.docker.com/desktop/windows/install/) | [](https://docs.docker.com/desktop/windows/install/) |                                                  |\n\n### Server\n\nDocker provides `.deb` and `.rpm` packages from the following Linux distributions and architectures:\n\n| Platform                   | x86_64 / amd64     | arm64 / aarch64    | arm (32-bit)       | s390x            |\n|:---------------------------|:-------------------|:-------------------|:-------------------|:-----------------|\n| [CentOS](centos/index)     | [](centos/index)   | [](centos/index)   |                    |                  |\n| [Debian](debian/index)     | [](debian/index)   | [](debian/index)   | [](debian/index)   |                  |\n| [Fedora](fedora/index)     | [](fedora/index)   | [](fedora/index)   |                    |                  |\n| [Raspbian](debian/index)   |                    |                    | [](debian/index)   |                  |\n| [RHEL](rhel/index)         |                    |                    |                    | [](rhel/index)   |\n| [SLES](sles/index)         |                    |                    |                    | [](sles/index)   |\n| [Ubuntu](ubuntu/index)     | [](ubuntu/index)   | [](ubuntu/index)   | [](ubuntu/index)   | [](ubuntu/index) |\n| [Binaries](binaries/index) | [](binaries/index) | [](binaries/index) | [](binaries/index) |                  |\n\n### Other Linux distributions\n\n> **Note**\n>\n> While the instructions below may work, Docker does not test or verify installation on derivatives.\n\n- Users of Debian derivatives such as “BunsenLabs Linux”, “Kali Linux” or “LMDE” (Debian-based Mint) should follow the installation instructions for [Debian](debian/index), substituting the version of their distro for the corresponding Debian release. Refer to the documentation of your distro to find which Debian release corresponds with your derivative version.\n- Likewise, users of Ubuntu derivatives such as “Kubuntu”, “Lubuntu” or “Xubuntu” should follow the installation instructions for [Ubuntu](ubuntu/index), substituting the version of their distro for the corresponding Ubuntu release. Refer to the documentation of your distro to find which Ubuntu release corresponds with your derivative version.\n- Some Linux distributions are providing a package of Docker Engine through their package repositories. These packages are built and maintained by the Linux distribution’s package maintainers and may have differences in configuration or built from modified source code. Docker is not involved in releasing these packages and bugs or issues involving these packages should be reported in your Linux distribution’s issue tracker.\n\nDocker provides [binaries](binaries/index) for manual installation of Docker Engine. These binaries are statically linked and can be used on any Linux distribution.\n\n## Release channels\n\nDocker Engine has two types of update channels, **stable** and **test**:\n\n- The **Stable** channel gives you latest releases for general availability.\n- The **Test** channel gives pre-releases that are ready for testing before general availability (GA).\n\n### Stable\n\nYear-month releases are made from a release branch diverged from the master branch. The branch is created with format `<year>.<month>`, for example `20.10`. The year-month name indicates the earliest possible calendar month to expect the release to be generally available. All further patch releases are performed from that branch. For example, once `v20.10.0` is released, all subsequent patch releases are built from the `20.10` branch.\n\n### Test\n\nIn preparation for a new year-month release, a branch is created from the master branch with format `YY.mm` when the milestones desired by Docker for the release have achieved feature-complete. Pre-releases such as betas and release candidates are conducted from their respective release branches. Patch releases and the corresponding pre-releases are performed from within the corresponding release branch.\n\n## Support\n\nDocker Engine releases of a year-month branch are supported with patches as needed for one month after the next year-month general availability release.\n\nThis means bug reports and backports to release branches are assessed until the end-of-life date.\n\nAfter the year-month branch has reached end-of-life, the branch may be deleted from the repository.\n\n### Backporting\n\nBackports to the Docker products are prioritized by the Docker company. A Docker employee or repository maintainer will endeavour to ensure sensible bugfixes make it into *active* releases.\n\nIf there are important fixes that ought to be considered for backport to active release branches, be sure to highlight this in the PR description or by adding a comment to the PR.\n\n### Upgrade path\n\nPatch releases are always backward compatible with its year-month version.\n\n### Licensing\n\nDocker is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full license text.\n\n## Reporting security issues\n\nThe Docker maintainers take security seriously. If you discover a security issue, please bring it to their attention right away!\n\nPlease DO NOT file a public issue; instead send your report privately to security@docker.com.\n\nSecurity reports are greatly appreciated, and Docker will publicly thank you for it.\n\n## Get started\n\nAfter setting up Docker, you can learn the basics with [Getting started with Docker](../../get-started/index).\n\n[docker](https://docs.docker.com/search/?q=docker), [installation](https://docs.docker.com/search/?q=installation), [install](https://docs.docker.com/search/?q=install), [Docker Engine](https://docs.docker.com/search/?q=Docker%20Engine), [Docker Engine](https://docs.docker.com/search/?q=Docker%20Engine), [docker editions](https://docs.docker.com/search/?q=docker%20editions), [stable](https://docs.docker.com/search/?q=stable), [edge](https://docs.docker.com/search/?q=edge)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)"
- name: Install Docker Engine from binaries
  id: engine/install/binaries/index
  summary: This page contains information on how to install Docker using binaries
  description: "# Install Docker Engine from binaries\n\n> **Important**\n>\n> This page contains information on how to install Docker using binaries. These instructions are mostly suitable for testing purposes. We do not recommend installing Docker using binaries in production environments as they will not be updated automatically with security updates. The Linux binaries described on this page are statically linked, which means that vulnerabilities in build-time dependencies are not automatically patched by security updates of your Linux distribution.\n>\n> Updating binaries is also slightly more involved when compared to Docker packages installed using a package manager or through Docker Desktop, as it requires (manually) updating the installed version whenever there is a new release of Docker.\n>\n> Also, static binaries may not include all functionalities provided by the dynamic packages.\n>\n> On Windows and Mac, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead. For Linux, we recommend that you follow the instructions specific for your distribution.\n\nIf you want to try Docker or use it in a testing environment, but you’re not on a supported platform, you can try installing from static binaries. If possible, you should use packages built for your operating system, and use your operating system’s package management system to manage Docker installation and upgrades.\n\nStatic binaries for the Docker daemon binary are only available for Linux (as `dockerd`) and Windows (as `dockerd.exe`). Static binaries for the Docker client are available for Linux, Windows, and macOS (as `docker`).\n\nThis topic discusses binary installation for Linux, Windows, and macOS:\n\n- [Install daemon and client binaries on Linux](#install-daemon-and-client-binaries-on-linux)\n- [Install client binaries on macOS](#install-client-binaries-on-macos)\n- [Install server and client binaries on Windows](#install-server-and-client-binaries-on-windows)\n\n## Install daemon and client binaries on Linux\n\n### Prerequisites\n\nBefore attempting to install Docker from binaries, be sure your host machine meets the prerequisites:\n\n- A 64-bit installation\n- Version 3.10 or higher of the Linux kernel. The latest version of the kernel available for your platform is recommended.\n- `iptables` version 1.4 or higher\n- `git` version 1.7 or higher\n- A `ps` executable, usually provided by `procps` or a similar package.\n- [XZ Utils](https://tukaani.org/xz/) 4.9 or higher\n- A [properly mounted](https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount) `cgroupfs` hierarchy; a single, all-encompassing `cgroup` mount point is not sufficient. See Github issues [\\#2683](https://github.com/moby/moby/issues/2683), [\\#3485](https://github.com/moby/moby/issues/3485), [\\#4568](https://github.com/moby/moby/issues/4568)).\n\n#### Secure your environment as much as possible\n\n##### OS considerations\n\nEnable SELinux or AppArmor if possible.\n\nIt is recommended to use AppArmor or SELinux if your Linux distribution supports either of the two. This helps improve security and blocks certain types of exploits. Review the documentation for your Linux distribution for instructions for enabling and configuring AppArmor or SELinux.\n\n> Security Warning\n>\n> If either of the security mechanisms is enabled, do not disable it as a work-around to make Docker or its containers run. Instead, configure it correctly to fix any problems.\n\n##### Docker daemon considerations\n\n- Enable `seccomp` security profiles if possible. See [Enabling `seccomp` for Docker](../../security/seccomp/index).\n\n- Enable user namespaces if possible. See the [Daemon user namespace options](../../reference/commandline/dockerd/index#daemon-user-namespace-options).\n\n### Install static binaries\n\n1.  Download the static binary archive. Go to <https://download.docker.com/linux/static/stable/>, choose your hardware platform, and download the `.tgz` file relating to the version of Docker Engine you want to install.\n\n2.  Extract the archive using the `tar` utility. The `dockerd` and `docker` binaries are extracted.\n\n    ``` \n    $ tar xzvf /path/to/<FILE>.tar.gz\n    ```\n\n3.  **Optional**: Move the binaries to a directory on your executable path, such as `/usr/bin/`. If you skip this step, you must provide the path to the executable when you invoke `docker` or `dockerd` commands.\n\n    ``` \n    $ sudo cp docker/* /usr/bin/\n    ```\n\n4.  Start the Docker daemon:\n\n    ``` \n    $ sudo dockerd &\n    ```\n\n    If you need to start the daemon with additional options, modify the above command accordingly or create and edit the file `/etc/docker/daemon.json` to add the custom configuration options.\n\n5.  Verify that Docker is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\n## Install client binaries on macOS\n\n> **Note**\n>\n> The following instructions are mostly suitable for testing purposes. The macOS binary includes the Docker client only. It does not include the `dockerd` daemon which is required to run containers. Therefore, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead.\n\nThe binaries for Mac also do not contain:\n\n- A runtime environment. You must set up a functional engine either in a Virtual Machine, or on a remote Linux machine.\n- Docker components such as `buildx`, `docker scan`, and `docker compose`.\n\nTo install client binaries, perform the following steps:\n\n1.  Download the static binary archive. Go to <https://download.docker.com/mac/static/stable/> and select `x86_64` (for Mac on Intel chip) or `aarch64` (for Mac on Apple silicon), and then download the `.tgz` file relating to the version of Docker Engine you want to install.\n\n2.  Extract the archive using the `tar` utility. The `docker` binary is extracted.\n\n    ``` \n    $ tar xzvf /path/to/<FILE>.tar.gz\n    ```\n\n3.  Clear the extended attributes to allow it run.\n\n    ``` \n    $ sudo xattr -rc docker\n    ```\n\n    Now, when you run the following command, you can see the Docker CLI usage instructions:\n\n    ``` \n    $ docker/docker\n    ```\n\n4.  **Optional**: Move the binary to a directory on your executable path, such as `/usr/local/bin/`. If you skip this step, you must provide the path to the executable when you invoke `docker` or `dockerd` commands.\n\n    ``` \n    $ sudo cp docker/docker /usr/local/bin/\n    ```\n\n5.  Verify that Docker is installed correctly by running the `hello-world` image. The value of `<hostname>` is a hostname or IP address running the Docker daemon and accessible to the client.\n\n    ``` \n    $ sudo docker -H <hostname> run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\n## Install server and client binaries on Windows\n\n> **Note**\n>\n> The following section describes how to install the Docker daemon on Windows Server which allows you to run Windows containers only. The binaries for Windows do not contain Docker components such as `buildx`, `docker scan`, and `docker compose`. If you are running Windows 10 or 11, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead.\n\nBinary packages on Windows include both `dockerd.exe` and `docker.exe`. On Windows, these binaries only provide the ability to run native Windows containers (not Linux containers).\n\nTo install server and client binaries, perform the following steps:\n\n1.  Download the static binary archive. Go to <https://download.docker.com/win/static/stable/x86_64> and select the latest version from the list.\n\n2.  Run the following PowerShell commands to install and extract the archive to your program files:\n\n    ``` \n     PS C:\\> Expand-Archive /path/to/<FILE>.zip -DestinationPath $Env:ProgramFiles\n    ```\n\n3.  Register the service and start the Docker Engine:\n\n    ``` \n     PS C:\\> &$Env:ProgramFiles\\Docker\\dockerd --register-service\n     PS C:\\> Start-Service docker\n    ```\n\n4.  Verify that Docker is installed correctly by running the `hello-world` image.\n\n    ``` \n    PS C:\\> &$Env:ProgramFiles\\Docker\\docker run hello-world:nanoserver\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\n## Upgrade static binaries\n\nTo upgrade your manual installation of Docker Engine, first stop any `dockerd` or `dockerd.exe` processes running locally, then follow the regular installation steps to install the new version on top of the existing version.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Take a look at the [Get started](../../../get-started/index) training modules to learn how to build an image and run it as a containerized application.\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[binaries](https://docs.docker.com/search/?q=binaries), [installation](https://docs.docker.com/search/?q=installation), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation), [linux](https://docs.docker.com/search/?q=linux)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/binaries/](https://docs.docker.com/engine/install/binaries/)"
- name: Install Docker Engine on CentOS
  id: engine/install/centos/index
  summary: To get started with Docker Engine on CentOS, make sure you meet the prerequisites, then install Docker
  description: "# Install Docker Engine on CentOS\n\nTo get started with Docker Engine on CentOS, make sure you [meet the prerequisites](#prerequisites), then [install Docker](#installation-methods).\n\n## Prerequisites\n\n### OS requirements\n\nTo install Docker Engine, you need a maintained version of CentOS 7, CentOS 8 (stream), or CentOS 9 (stream). Archived versions aren’t supported or tested.\n\nThe `centos-extras` repository must be enabled. This repository is enabled by default, but if you have disabled it, you need to [re-enable it](https://wiki.centos.org/AdditionalResources/Repositories).\n\nThe `overlay2` storage driver is recommended.\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker` or `docker-engine`. If these are installed, uninstall them, along with associated dependencies.\n\n``` \n$ sudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine\n```\n\nIt’s OK if `yum` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. The Docker Engine package is now called `docker-ce`.\n\n## Installation methods\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n\n- Some users download the RPM package and [install it manually](#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n\n### Install using the repository\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### Set up the repository\n\nInstall the `yum-utils` package (which provides the `yum-config-manager` utility) and set up the repository.\n\n``` \n$ sudo yum install -y yum-utils\n\n$ sudo yum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo\n```\n\n#### Install Docker Engine\n\n1.  Install the *latest version* of Docker Engine, containerd, and Docker Compose or go to the next step to install a specific version:\n\n    ``` \n    $ sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:\n\n    ``` \n    $ yum list docker-ce --showduplicates | sort -r\n\n    docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable\n    docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable\n    docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable\n    docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable\n    ```\n\n    The list returned depends on which repositories are enabled, and is specific to your version of CentOS (indicated by the `.el7` suffix in this example).\n\n    b\\. Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column) starting at the first colon (`:`), up to the first hyphen, separated by a hyphen (`-`). For example, `docker-ce-18.09.1`.\n\n    ``` \n    $ sudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io docker-compose-plugin\n    ```\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Linux postinstall](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### Install from a package\n\nIf you cannot use Docker’s repository to install Docker, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/centos/](https://download.docker.com/linux/centos/) and choose your version of CentOS. Then browse to `x86_64/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n\n2.  Install Docker Engine, changing the path below to the path where you downloaded the Docker package.\n\n    ``` \n    $ sudo yum install /path/to/package.rpm\n    ```\n\n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Post-installation steps for Linux](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, download the newer package file and repeat the [installation procedure](#install-from-a-package), using `yum -y upgrade` instead of `yum -y install`, and point to the new file.\n\n### Install using the convenience script\n\nDocker provides a convenience script at [get.docker.com](https://get.docker.com/) to install Docker into development environments quickly and non-interactively. The convenience script is not recommended for production environments, but can be used as an example to create a provisioning script that is tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and can be found in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n- The script requires `root` or `sudo` privileges to run.\n- The script attempts to detect your Linux distribution and version and configure your package management system for you, and does not allow you to customize most installation parameters.\n- The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n- By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test (major) upgrades in a test environment before deploying to your production systems.\n- The script is not designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, causing outdated versions to be used.\n\n> Tip: preview script steps before running\n>\n> You can run the script with the `DRY_RUN=1` option to learn what steps the script will execute during installation:\n>\n> ``` \n> $ curl -fsSL https://get.docker.com -o get-docker.sh\n> $ DRY_RUN=1 sh ./get-docker.sh\n> ```\n\nThis example downloads the script from [get.docker.com](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\n``` \n$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ sudo sh get-docker.sh\nExecuting docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737\n<...>\n```\n\nDocker is installed. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users cannot run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n>\n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](../linux-postinstall/index#manage-docker-as-a-non-root-user). Docker can also be installed without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](../../security/rootless/index).\n\n#### Install pre-releases\n\nDocker also provides a convenience script at [test.docker.com](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equivalent to the script at `get.docker.com`, but configures your package manager to enable the “test” channel from our package repository, which includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they are released as stable.\n\nTo install the latest version of Docker on Linux from the “test” channel, run:\n\n``` \n$ curl -fsSL https://test.docker.com -o test-docker.sh\n$ sudo sh test-docker.sh\n<...>\n```\n\n#### Upgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There is no advantage to re-running the convenience script, and it can cause issues if it attempts to re-add repositories which have already been added to the host machine.\n\n## Uninstall Docker Engine\n\n1.  Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:\n\n    ``` \n    $ sudo yum remove docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n2.  Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n    ``` \n    $ sudo rm -rf /var/lib/docker\n    $ sudo rm -rf /var/lib/containerd\n    ```\n\nYou must delete any edited configuration files manually.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [centos](https://docs.docker.com/search/?q=centos), [rpm](https://docs.docker.com/search/?q=rpm), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/centos/](https://docs.docker.com/engine/install/centos/)"
- name: Install Docker Engine on Debian
  id: engine/install/debian/index
  summary: To get started with Docker Engine on Debian, make sure you meet the prerequisites, then install Docker
  description: "# Install Docker Engine on Debian\n\nTo get started with Docker Engine on Debian, make sure you [meet the prerequisites](#prerequisites), then [install Docker](#installation-methods).\n\n## Prerequisites\n\n### OS requirements\n\nTo install Docker Engine, you need the 64-bit version of one of these Debian or Raspbian versions:\n\n- Debian Bullseye 11 (stable)\n- Debian Buster 10 (oldstable)\n- Raspbian Bullseye 11 (stable)\n- Raspbian Buster 10 (oldstable)\n\nDocker Engine is supported on `x86_64` (or `amd64`), `armhf`, and `arm64` architectures.\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker`, `docker.io`, or `docker-engine`. If these are installed, uninstall them:\n\n``` \n$ sudo apt-get remove docker docker-engine docker.io containerd runc\n```\n\nIt’s OK if `apt-get` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. If you do not need to save your existing data, and want to start with a clean installation, refer to the [uninstall Docker Engine](#uninstall-docker-engine) section at the bottom of this page.\n\n## Installation methods\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach, except for Raspbian.\n\n- Some users download the DEB package and [install it manually](#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker. This is currently the only approach for Raspbian.\n\n### Install using the repository\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n> **Raspbian users cannot use this method!**\n>\n> For Raspbian, installing using the repository is not yet supported. You must instead use the [convenience script](#install-using-the-convenience-script).\n\n#### Set up the repository\n\n1.  Update the `apt` package index and install packages to allow `apt` to use a repository over HTTPS:\n\n    ``` \n    $ sudo apt-get update\n\n    $ sudo apt-get install \\\n        ca-certificates \\\n        curl \\\n        gnupg \\\n        lsb-release\n    ```\n\n2.  Add Docker’s official GPG key:\n\n    ``` \n    $ sudo mkdir -p /etc/apt/keyrings\n    $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n    ```\n\n3.  Use the following command to set up the repository:\n\n    ``` \n    $ echo \\\n      \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n      $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n    ```\n\n#### Install Docker Engine\n\nThis procedure works for Debian on `x86_64` / `amd64`, `armhf`, `arm64`, and Raspbian.\n\n1.  Update the `apt` package index, and install the *latest version* of Docker Engine, containerd, and Docker Compose, or go to the next step to install a specific version:\n\n    ``` \n     $ sudo apt-get update\n     $ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n    > Receiving a GPG error when running `apt-get update`?\n    >\n    > Your default umask may not be set correctly, causing the public key file for the repo to not be detected. Run the following command and then try to update your repo again: `sudo chmod a+r /etc/apt/keyrings/docker.gpg`.\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List the versions available in your repo:\n\n    ``` \n    $ apt-cache madison docker-ce\n\n      docker-ce | 5:18.09.1~3-0~debian-stretch | https://download.docker.com/linux/debian stretch/stable amd64 Packages\n      docker-ce | 5:18.09.0~3-0~debian-stretch | https://download.docker.com/linux/debian stretch/stable amd64 Packages\n      docker-ce | 18.06.1~ce~3-0~debian        | https://download.docker.com/linux/debian stretch/stable amd64 Packages\n      docker-ce | 18.06.0~ce~3-0~debian        | https://download.docker.com/linux/debian stretch/stable amd64 Packages\n    ```\n\n    b\\. Install a specific version using the version string from the second column, for example, `5:18.09.1~3-0~debian-stretch`.\n\n    ``` \n    $ sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io docker-compose-plugin\n    ```\n\n3.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nDocker Engine is installed and running. The `docker` group is created but no users are added to it. You need to use `sudo` to run Docker commands. Continue to [Linux postinstall](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, first run `sudo apt-get update`, then follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### Install from a package\n\nIf you cannot use Docker’s repository to install Docker Engine, you can download the `.deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker.\n\n1.  Go to [`https://download.docker.com/linux/debian/dists/`](https://download.docker.com/linux/debian/dists/), choose your Debian version, then browse to `pool/stable/`, choose `amd64`, `armhf`, or `arm64`, and download the `.deb` file for the Docker Engine version you want to install.\n\n2.  Install Docker Engine, changing the path below to the path where you downloaded the Docker package.\n\n    ``` \n    $ sudo dpkg -i /path/to/package.deb\n    ```\n\n    The Docker daemon starts automatically.\n\n3.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nDocker Engine is installed and running. The `docker` group is created but no users are added to it. You need to use `sudo` to run Docker commands. Continue to [Post-installation steps for Linux](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, download the newer package file and repeat the [installation procedure](#install-from-a-package), pointing to the new file.\n\n### Install using the convenience script\n\nDocker provides a convenience script at [get.docker.com](https://get.docker.com/) to install Docker into development environments quickly and non-interactively. The convenience script is not recommended for production environments, but can be used as an example to create a provisioning script that is tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and can be found in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n- The script requires `root` or `sudo` privileges to run.\n- The script attempts to detect your Linux distribution and version and configure your package management system for you, and does not allow you to customize most installation parameters.\n- The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n- By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test (major) upgrades in a test environment before deploying to your production systems.\n- The script is not designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, causing outdated versions to be used.\n\n> Tip: preview script steps before running\n>\n> You can run the script with the `DRY_RUN=1` option to learn what steps the script will execute during installation:\n>\n> ``` \n> $ curl -fsSL https://get.docker.com -o get-docker.sh\n> $ DRY_RUN=1 sh ./get-docker.sh\n> ```\n\nThis example downloads the script from [get.docker.com](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\n``` \n$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ sudo sh get-docker.sh\nExecuting docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737\n<...>\n```\n\nDocker is installed. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users cannot run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n>\n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](../linux-postinstall/index#manage-docker-as-a-non-root-user). Docker can also be installed without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](../../security/rootless/index).\n\n#### Install pre-releases\n\nDocker also provides a convenience script at [test.docker.com](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equivalent to the script at `get.docker.com`, but configures your package manager to enable the “test” channel from our package repository, which includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they are released as stable.\n\nTo install the latest version of Docker on Linux from the “test” channel, run:\n\n``` \n$ curl -fsSL https://test.docker.com -o test-docker.sh\n$ sudo sh test-docker.sh\n<...>\n```\n\n#### Upgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There is no advantage to re-running the convenience script, and it can cause issues if it attempts to re-add repositories which have already been added to the host machine.\n\n## Uninstall Docker Engine\n\n1.  Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:\n\n    ``` \n    $ sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n2.  Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n    ``` \n    $ sudo rm -rf /var/lib/docker\n    $ sudo rm -rf /var/lib/containerd\n    ```\n\nYou must delete any edited configuration files manually.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [debian](https://docs.docker.com/search/?q=debian), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/debian/](https://docs.docker.com/engine/install/debian/)"
- name: Install Docker Engine on Fedora
  id: engine/install/fedora/index
  summary: To get started with Docker Engine on Fedora, make sure you meet the prerequisites, then install Docker
  description: "# Install Docker Engine on Fedora\n\nTo get started with Docker Engine on Fedora, make sure you [meet the prerequisites](#prerequisites), then [install Docker](#installation-methods).\n\n## Prerequisites\n\n### OS requirements\n\nTo install Docker Engine, you need the 64-bit version of one of these Fedora versions:\n\n- Fedora 34\n- Fedora 35\n- Fedora 36\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker` or `docker-engine`. If these are installed, uninstall them, along with associated dependencies.\n\n``` \n$ sudo dnf remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\n```\n\nIt’s OK if `dnf` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. The Docker Engine package is now called `docker-ce`.\n\n## Installation methods\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n\n- Some users download the RPM package and [install it manually](#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n\n### Install using the repository\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### Set up the repository\n\nInstall the `dnf-plugins-core` package (which provides the commands to manage your DNF repositories) and set up the repository.\n\n``` \n$ sudo dnf -y install dnf-plugins-core\n\n$ sudo dnf config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/fedora/docker-ce.repo\n```\n\n#### Install Docker Engine\n\n1.  Install the *latest version* of Docker Engine, containerd, and Docker Compose or go to the next step to install a specific version:\n\n    ``` \n    $ sudo dnf install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:\n\n    ``` \n    $ dnf list docker-ce  --showduplicates | sort -r\n\n    docker-ce.x86_64  3:18.09.1-3.fc28                 docker-ce-stable\n    docker-ce.x86_64  3:18.09.0-3.fc28                 docker-ce-stable\n    docker-ce.x86_64  18.06.1.ce-3.fc28                docker-ce-stable\n    docker-ce.x86_64  18.06.0.ce-3.fc28                docker-ce-stable\n    ```\n\n    The list returned depends on which repositories are enabled, and is specific to your version of Fedora (indicated by the `.fc28` suffix in this example).\n\n    b\\. Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column) up to the first hyphen, separated by a hyphen (`-`), for example, `docker-ce-3:18.09.1`.\n\n    ``` \n    $ sudo dnf -y install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io docker-compose-plugin\n    ```\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Linux postinstall](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### Install from a package\n\nIf you cannot use Docker’s repository to install Docker, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/fedora/](https://download.docker.com/linux/fedora/) and choose your version of Fedora. Then browse to `x86_64/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n\n2.  Install Docker Engine, changing the path below to the path where you downloaded the Docker package.\n\n    ``` \n    $ sudo dnf -y install /path/to/package.rpm\n    ```\n\n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Post-installation steps for Linux](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, download the newer package file and repeat the [installation procedure](#install-from-a-package), using `dnf -y upgrade` instead of `dnf -y install`, and point to the new file.\n\n### Install using the convenience script\n\nDocker provides a convenience script at [get.docker.com](https://get.docker.com/) to install Docker into development environments quickly and non-interactively. The convenience script is not recommended for production environments, but can be used as an example to create a provisioning script that is tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and can be found in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n- The script requires `root` or `sudo` privileges to run.\n- The script attempts to detect your Linux distribution and version and configure your package management system for you, and does not allow you to customize most installation parameters.\n- The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n- By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test (major) upgrades in a test environment before deploying to your production systems.\n- The script is not designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, causing outdated versions to be used.\n\n> Tip: preview script steps before running\n>\n> You can run the script with the `DRY_RUN=1` option to learn what steps the script will execute during installation:\n>\n> ``` \n> $ curl -fsSL https://get.docker.com -o get-docker.sh\n> $ DRY_RUN=1 sh ./get-docker.sh\n> ```\n\nThis example downloads the script from [get.docker.com](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\n``` \n$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ sudo sh get-docker.sh\nExecuting docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737\n<...>\n```\n\nDocker is installed. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users cannot run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n>\n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](../linux-postinstall/index#manage-docker-as-a-non-root-user). Docker can also be installed without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](../../security/rootless/index).\n\n#### Install pre-releases\n\nDocker also provides a convenience script at [test.docker.com](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equivalent to the script at `get.docker.com`, but configures your package manager to enable the “test” channel from our package repository, which includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they are released as stable.\n\nTo install the latest version of Docker on Linux from the “test” channel, run:\n\n``` \n$ curl -fsSL https://test.docker.com -o test-docker.sh\n$ sudo sh test-docker.sh\n<...>\n```\n\n#### Upgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There is no advantage to re-running the convenience script, and it can cause issues if it attempts to re-add repositories which have already been added to the host machine.\n\n## Uninstall Docker Engine\n\n1.  Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:\n\n    ``` \n    $ sudo dnf remove docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n2.  Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n    ``` \n    $ sudo rm -rf /var/lib/docker\n    $ sudo rm -rf /var/lib/containerd\n    ```\n\nYou must delete any edited configuration files manually.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [fedora](https://docs.docker.com/search/?q=fedora), [rpm](https://docs.docker.com/search/?q=rpm), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/fedora/](https://docs.docker.com/engine/install/fedora/)"
- name: Install Docker Engine on RHEL
  id: engine/install/rhel/index
  summary: To get started with Docker Engine on RHEL, make sure you meet the prerequisites, then install Docker
  description: "# Install Docker Engine on RHEL\n\nTo get started with Docker Engine on RHEL, make sure you [meet the prerequisites](#prerequisites), then [install Docker](#installation-methods).\n\n## Prerequisites\n\n> **Note**\n>\n> We currently only provide packages for RHEL on s390x (IBM Z). Other architectures are not yet supported for RHEL, but you may be able to install the CentOS packages on RHEL. Refer to the [Install Docker Engine on CentOS](../centos/index) page for details.\n\n### OS requirements\n\nTo install Docker Engine, you need a maintained version of RHEL 7 or 8 on s390x (IBM Z). Archived versions aren’t supported or tested.\n\nThe `overlay2` storage driver is recommended.\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker` or `docker-engine`. If these are installed, uninstall them, along with associated dependencies. Also uninstall `Podman` and the associated dependencies if installed already.\n\n``` \n$ sudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine \\\n                  podman \\\n                  runc\n```\n\nIt’s OK if `yum` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. The Docker Engine package is now called `docker-ce`.\n\n## Installation methods\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n\n- Some users download the RPM package and [install it manually](#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n\n### Install using the repository\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### Set up the repository\n\nInstall the `yum-utils` package (which provides the `yum-config-manager` utility) and set up the repository.\n\n``` \n$ sudo yum install -y yum-utils\n\n$ sudo yum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/rhel/docker-ce.repo\n```\n\n#### Install Docker Engine\n\n1.  Install the *latest version* of Docker Engine, containerd, and Docker Compose or go to the next step to install a specific version:\n\n    ``` \n    $ sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:\n\n    ``` \n    $ yum list docker-ce --showduplicates | sort -r\n\n    docker-ce.s390x                3:20.10.8-3.el8                 docker-ce-stable\n    docker-ce.s390x                3:20.10.7-3.el8                 docker-ce-stable\n    <...>\n    ```\n\n    The list returned depends on which repositories are enabled, and is specific to your version of RHEL (indicated by the `.el8` suffix in this example).\n\n    b\\. Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column) starting at the first colon (`:`), up to the first hyphen, separated by a hyphen (`-`). For example, `docker-ce-20.10.7`.\n\n    ``` \n    $ sudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io docker-compose-plugin\n    ```\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Linux postinstall](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### Install from a package\n\nIf you cannot use Docker’s repository to install Docker, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/rhel/](https://download.docker.com/linux/rhel/) and choose your version of RHEL. Then browse to `s390x/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n\n2.  Install Docker Engine, changing the path below to the path where you downloaded the Docker package.\n\n    ``` \n    $ sudo yum install /path/to/package.rpm\n    ```\n\n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Post-installation steps for Linux](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, download the newer package file and repeat the [installation procedure](#install-from-a-package), using `yum -y upgrade` instead of `yum -y install`, and point to the new file.\n\n### Install using the convenience script\n\nDocker provides a convenience script at [get.docker.com](https://get.docker.com/) to install Docker into development environments quickly and non-interactively. The convenience script is not recommended for production environments, but can be used as an example to create a provisioning script that is tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and can be found in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n- The script requires `root` or `sudo` privileges to run.\n- The script attempts to detect your Linux distribution and version and configure your package management system for you, and does not allow you to customize most installation parameters.\n- The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n- By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test (major) upgrades in a test environment before deploying to your production systems.\n- The script is not designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, causing outdated versions to be used.\n\n> Tip: preview script steps before running\n>\n> You can run the script with the `DRY_RUN=1` option to learn what steps the script will execute during installation:\n>\n> ``` \n> $ curl -fsSL https://get.docker.com -o get-docker.sh\n> $ DRY_RUN=1 sh ./get-docker.sh\n> ```\n\nThis example downloads the script from [get.docker.com](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\n``` \n$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ sudo sh get-docker.sh\nExecuting docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737\n<...>\n```\n\nDocker is installed. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users cannot run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n>\n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](../linux-postinstall/index#manage-docker-as-a-non-root-user). Docker can also be installed without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](../../security/rootless/index).\n\n#### Install pre-releases\n\nDocker also provides a convenience script at [test.docker.com](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equivalent to the script at `get.docker.com`, but configures your package manager to enable the “test” channel from our package repository, which includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they are released as stable.\n\nTo install the latest version of Docker on Linux from the “test” channel, run:\n\n``` \n$ curl -fsSL https://test.docker.com -o test-docker.sh\n$ sudo sh test-docker.sh\n<...>\n```\n\n#### Upgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There is no advantage to re-running the convenience script, and it can cause issues if it attempts to re-add repositories which have already been added to the host machine.\n\n## Uninstall Docker Engine\n\n1.  Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:\n\n    ``` \n    $ sudo yum remove docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n2.  Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n    ``` \n    $ sudo rm -rf /var/lib/docker\n    $ sudo rm -rf /var/lib/containerd\n    ```\n\nYou must delete any edited configuration files manually.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [rhel](https://docs.docker.com/search/?q=rhel), [rpm](https://docs.docker.com/search/?q=rpm), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update), [s390x](https://docs.docker.com/search/?q=s390x), [ibm-z](https://docs.docker.com/search/?q=ibm-z)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/rhel/](https://docs.docker.com/engine/install/rhel/)"
- name: Install Docker Engine on SLES
  id: engine/install/sles/index
  summary: To get started with Docker Engine on SLES, make sure you meet the prerequisites, then install Docker
  description: "# Install Docker Engine on SLES\n\nTo get started with Docker Engine on SLES, make sure you [meet the prerequisites](#prerequisites), then [install Docker](#installation-methods).\n\n## Prerequisites\n\n> **Note**\n>\n> We currently only provide packages for SLES on s390x (IBM Z). Other architectures are not yet supported for SLES.\n\n### OS requirements\n\nTo install Docker Engine, you need a maintained version of SLES 15-SP2 or SLES 15-SP3 on s390x (IBM Z). Archived versions aren’t supported or tested.\n\nThe [`SCC SUSE`](https://scc.suse.com/packages?name=SUSE%20Linux%20Enterprise%20Server&version=15.2&arch=s390x) repositories must be enabled.\n\nThe [OpenSUSE `SELinux` repository](https://download.opensuse.org/repositories/security) must be enabled. This repository is not added by default, and you need to enable it for the version of SLES you are running. Run the following commands to add it:\n\n``` \n$ sles_version=\"$(. /etc/os-release && echo \"${VERSION_ID##*.}\")\"\n$ opensuse_repo=\"https://download.opensuse.org/repositories/security:SELinux/SLE_15_SP$sles_version/security:SELinux.repo\"\n$ sudo zypper addrepo $opensuse_repo \n```\n\nThe `overlay2` storage driver is recommended.\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker` or `docker-engine`. If these are installed, uninstall them, along with associated dependencies.\n\n``` \n$ sudo zypper remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine \\\n                  runc\n```\n\nIt’s OK if `zypper` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. The Docker Engine package is now called `docker-ce`.\n\n## Installation methods\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n\n- Some users download the RPM package and [install it manually](#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n\n### Install using the repository\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### Set up the repository\n\nSet up the repository.\n\n``` \n$ sudo zypper addrepo https://download.docker.com/linux/sles/docker-ce.repo\n```\n\n#### Install Docker Engine\n\n1.  Install the *latest version* of Docker Engine, containerd, and Docker Compose or go to the next step to install a specific version:\n\n    ``` \n    $ sudo zypper install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:\n\n    ``` \n    $ sudo zypper search -s --match-exact docker-ce | sort -r\n        \n      v  | docker-ce | package | 3:20.10.8-3 | s390x | Docker CE Stable - s390x\n      v  | docker-ce | package | 3:20.10.7-3 | s390x | Docker CE Stable - s390x\n    ```\n\n    The list returned depends on which repositories are enabled, and is specific to your version of SLES.\n\n    b\\. Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (fourth column), separated by a hyphen (`-`). For example, `docker-ce-3:20.10.8`.\n\n    ``` \n    $ sudo zypper install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io docker-compose-plugin\n    ```\n\n    This command installs Docker, but it doesn’t start Docker. It also creates a `docker` group, however, it doesn’t add any users to the group by default.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Linux postinstall](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### Install from a package\n\nIf you cannot use Docker’s repository to install Docker, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/sles/](https://download.docker.com/linux/sles/) and choose your version of SLES. Then browse to `15/s390x/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n\n2.  Install Docker Engine, changing the path below to the path where you downloaded the Docker package.\n\n    ``` \n    $ sudo zypper install /path/to/package.rpm\n    ```\n\n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n\n3.  Start Docker.\n\n    ``` \n    $ sudo systemctl start docker\n    ```\n\n4.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nThis installs and runs Docker Engine. Use `sudo` to run Docker commands. Continue to [Post-installation steps for Linux](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, download the newer package file and repeat the [installation procedure](#install-from-a-package), using `zypper -y upgrade` instead of `zypper -y install`, and point to the new file.\n\n### Install using the convenience script\n\nDocker provides a convenience script at [get.docker.com](https://get.docker.com/) to install Docker into development environments quickly and non-interactively. The convenience script is not recommended for production environments, but can be used as an example to create a provisioning script that is tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and can be found in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n- The script requires `root` or `sudo` privileges to run.\n- The script attempts to detect your Linux distribution and version and configure your package management system for you, and does not allow you to customize most installation parameters.\n- The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n- By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test (major) upgrades in a test environment before deploying to your production systems.\n- The script is not designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, causing outdated versions to be used.\n\n> Tip: preview script steps before running\n>\n> You can run the script with the `DRY_RUN=1` option to learn what steps the script will execute during installation:\n>\n> ``` \n> $ curl -fsSL https://get.docker.com -o get-docker.sh\n> $ DRY_RUN=1 sh ./get-docker.sh\n> ```\n\nThis example downloads the script from [get.docker.com](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\n``` \n$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ sudo sh get-docker.sh\nExecuting docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737\n<...>\n```\n\nDocker is installed. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users cannot run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n>\n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](../linux-postinstall/index#manage-docker-as-a-non-root-user). Docker can also be installed without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](../../security/rootless/index).\n\n#### Install pre-releases\n\nDocker also provides a convenience script at [test.docker.com](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equivalent to the script at `get.docker.com`, but configures your package manager to enable the “test” channel from our package repository, which includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they are released as stable.\n\nTo install the latest version of Docker on Linux from the “test” channel, run:\n\n``` \n$ curl -fsSL https://test.docker.com -o test-docker.sh\n$ sudo sh test-docker.sh\n<...>\n```\n\n#### Upgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There is no advantage to re-running the convenience script, and it can cause issues if it attempts to re-add repositories which have already been added to the host machine.\n\n## Uninstall Docker Engine\n\n1.  Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:\n\n    ``` \n    $ sudo zypper remove docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n2.  Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n    ``` \n    $ sudo rm -rf /var/lib/docker\n    $ sudo rm -rf /var/lib/containerd\n    ```\n\nYou must delete any edited configuration files manually.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [centos](https://docs.docker.com/search/?q=centos), [rpm](https://docs.docker.com/search/?q=rpm), [sles](https://docs.docker.com/search/?q=sles), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update), [s390x](https://docs.docker.com/search/?q=s390x), [ibm-z](https://docs.docker.com/search/?q=ibm-z)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/sles/](https://docs.docker.com/engine/install/sles/)"
- name: Install Docker Engine on Ubuntu
  id: engine/install/ubuntu/index
  summary: Docker Desktop helps you build, share, and run containers easily on Mac and Windows as you do on Linux
  description: "# Install Docker Engine on Ubuntu\n\n> **Docker Desktop for Linux**\n>\n> Docker Desktop helps you build, share, and run containers easily on Mac and Windows as you do on Linux. We are excited to share that Docker Desktop for Linux is now GA. For more information, see [Docker Desktop for Linux](https://docs.docker.com/desktop/linux/install/).\n\nTo get started with Docker Engine on Ubuntu, make sure you [meet the prerequisites](#prerequisites), then [install Docker](#installation-methods).\n\n## Prerequisites\n\n### OS requirements\n\nTo install Docker Engine, you need the 64-bit version of one of these Ubuntu versions:\n\n- Ubuntu Jammy 22.04 (LTS)\n- Ubuntu Impish 21.10\n- Ubuntu Focal 20.04 (LTS)\n- Ubuntu Bionic 18.04 (LTS)\n\nDocker Engine is supported on `x86_64` (or `amd64`), `armhf`, `arm64`, and `s390x` architectures.\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker`, `docker.io`, or `docker-engine`. If these are installed, uninstall them:\n\n``` \n$ sudo apt-get remove docker docker-engine docker.io containerd runc\n```\n\nIt’s OK if `apt-get` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. If you do not need to save your existing data, and want to start with a clean installation, refer to the [uninstall Docker Engine](#uninstall-docker-engine) section at the bottom of this page.\n\n## Installation methods\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n\n- Some users download the DEB package and [install it manually](#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n\n- In testing and development environments, some users choose to use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n\n### Install using the repository\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### Set up the repository\n\n1.  Update the `apt` package index and install packages to allow `apt` to use a repository over HTTPS:\n\n    ``` \n    $ sudo apt-get update\n\n    $ sudo apt-get install \\\n        ca-certificates \\\n        curl \\\n        gnupg \\\n        lsb-release\n    ```\n\n2.  Add Docker’s official GPG key:\n\n    ``` \n    $ sudo mkdir -p /etc/apt/keyrings\n    $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n    ```\n\n3.  Use the following command to set up the repository:\n\n    ``` \n    $ echo \\\n      \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n      $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n    ```\n\n#### Install Docker Engine\n\n1.  Update the `apt` package index, and install the *latest version* of Docker Engine, containerd, and Docker Compose, or go to the next step to install a specific version:\n\n    ``` \n     $ sudo apt-get update\n     $ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n    > Receiving a GPG error when running `apt-get update`?\n    >\n    > Your default umask may not be set correctly, causing the public key file for the repo to not be detected. Run the following command and then try to update your repo again: `sudo chmod a+r /etc/apt/keyrings/docker.gpg`.\n\n2.  To install a *specific version* of Docker Engine, list the available versions in the repo, then select and install:\n\n    a\\. List the versions available in your repo:\n\n    ``` \n    $ apt-cache madison docker-ce\n\n    docker-ce | 5:20.10.16~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\n    docker-ce | 5:20.10.15~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\n    docker-ce | 5:20.10.14~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\n    docker-ce | 5:20.10.13~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\n    ```\n\n    b\\. Install a specific version using the version string from the second column, for example, `5:20.10.16~3-0~ubuntu-jammy`.\n\n    ``` \n    $ sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io docker-compose-plugin\n    ```\n\n3.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nDocker Engine is installed and running. The `docker` group is created but no users are added to it. You need to use `sudo` to run Docker commands. Continue to [Linux postinstall](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, first run `sudo apt-get update`, then follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### Install from a package\n\nIf you cannot use Docker’s repository to install Docker Engine, you can download the `.deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker.\n\n1.  Go to [`https://download.docker.com/linux/ubuntu/dists/`](https://download.docker.com/linux/ubuntu/dists/), choose your Ubuntu version, then browse to `pool/stable/`, choose `amd64`, `armhf`, `arm64`, or `s390x`, and download the `.deb` file for the Docker Engine version you want to install.\n\n2.  Install Docker Engine, changing the path below to the path where you downloaded the Docker package.\n\n    ``` \n    $ sudo dpkg -i /path/to/package.deb\n    ```\n\n    The Docker daemon starts automatically.\n\n3.  Verify that Docker Engine is installed correctly by running the `hello-world` image.\n\n    ``` \n    $ sudo docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\nDocker Engine is installed and running. The `docker` group is created but no users are added to it. You need to use `sudo` to run Docker commands. Continue to [Post-installation steps for Linux](../linux-postinstall/index) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### Upgrade Docker Engine\n\nTo upgrade Docker Engine, download the newer package file and repeat the [installation procedure](#install-from-a-package), pointing to the new file.\n\n### Install using the convenience script\n\nDocker provides a convenience script at [get.docker.com](https://get.docker.com/) to install Docker into development environments quickly and non-interactively. The convenience script is not recommended for production environments, but can be used as an example to create a provisioning script that is tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and can be found in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n- The script requires `root` or `sudo` privileges to run.\n- The script attempts to detect your Linux distribution and version and configure your package management system for you, and does not allow you to customize most installation parameters.\n- The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n- By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test (major) upgrades in a test environment before deploying to your production systems.\n- The script is not designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, causing outdated versions to be used.\n\n> Tip: preview script steps before running\n>\n> You can run the script with the `DRY_RUN=1` option to learn what steps the script will execute during installation:\n>\n> ``` \n> $ curl -fsSL https://get.docker.com -o get-docker.sh\n> $ DRY_RUN=1 sh ./get-docker.sh\n> ```\n\nThis example downloads the script from [get.docker.com](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\n``` \n$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ sudo sh get-docker.sh\nExecuting docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737\n<...>\n```\n\nDocker is installed. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users cannot run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n>\n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](../linux-postinstall/index#manage-docker-as-a-non-root-user). Docker can also be installed without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](../../security/rootless/index).\n\n#### Install pre-releases\n\nDocker also provides a convenience script at [test.docker.com](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equivalent to the script at `get.docker.com`, but configures your package manager to enable the “test” channel from our package repository, which includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they are released as stable.\n\nTo install the latest version of Docker on Linux from the “test” channel, run:\n\n``` \n$ curl -fsSL https://test.docker.com -o test-docker.sh\n$ sudo sh test-docker.sh\n<...>\n```\n\n#### Upgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There is no advantage to re-running the convenience script, and it can cause issues if it attempts to re-add repositories which have already been added to the host machine.\n\n## Uninstall Docker Engine\n\n1.  Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:\n\n    ``` \n    $ sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-compose-plugin\n    ```\n\n2.  Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n    ``` \n    $ sudo rm -rf /var/lib/docker\n    $ sudo rm -rf /var/lib/containerd\n    ```\n\nYou must delete any edited configuration files manually.\n\n## Next steps\n\n- Continue to [Post-installation steps for Linux](../linux-postinstall/index).\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [ubuntu](https://docs.docker.com/search/?q=ubuntu), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/ubuntu/](https://docs.docker.com/engine/install/ubuntu/)"
- name: Isolate containers with a user namespace
  id: engine/security/userns-remap/index
  summary: Linux namespaces provide isolation for running processes, limiting their access to system resources without the running process being aware of the limitations
  description: "# Isolate containers with a user namespace\n\nLinux namespaces provide isolation for running processes, limiting their access to system resources without the running process being aware of the limitations. For more information on Linux namespaces, see [Linux namespaces](https://www.linux.com/news/understanding-and-securing-linux-namespaces).\n\nThe best way to prevent privilege-escalation attacks from within a container is to configure your container’s applications to run as unprivileged users. For containers whose processes must run as the `root` user within the container, you can re-map this user to a less-privileged user on the Docker host. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself.\n\n## About remapping and subordinate user and group IDs\n\nThe remapping itself is handled by two files: `/etc/subuid` and `/etc/subgid`. Each file works the same, but one is concerned with the user ID range, and the other with the group ID range. Consider the following entry in `/etc/subuid`:\n\n``` \ntestuser:231072:65536\n```\n\nThis means that `testuser` is assigned a subordinate user ID range of `231072` and the next 65536 integers in sequence. UID `231072` is mapped within the namespace (within the container, in this case) as UID `0` (`root`). UID `231073` is mapped as UID `1`, and so forth. If a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, which does not even map to a real user. This means the process has no privileges on the host system at all.\n\n> Multiple ranges\n>\n> It is possible to assign multiple subordinate ranges for a given user or group by adding multiple non-overlapping mappings for the same user or group in the `/etc/subuid` or `/etc/subgid` file. In this case, Docker uses only the first five mappings, in accordance with the kernel’s limitation of only five entries in `/proc/self/uid_map` and `/proc/self/gid_map`.\n\nWhen you configure Docker to use the `userns-remap` feature, you can optionally specify an existing user and/or group, or you can specify `default`. If you specify `default`, a user and group `dockremap` is created and used for this purpose.\n\n> **Warning**: Some distributions, such as RHEL and CentOS 7.3, do not automatically add the new group to the `/etc/subuid` and `/etc/subgid` files. You are responsible for editing these files and assigning non-overlapping ranges, in this case. This step is covered in [Prerequisites](#prerequisites).\n\nIt is very important that the ranges do not overlap, so that a process cannot gain access in a different namespace. On most Linux distributions, system utilities manage the ranges for you when you add or remove users.\n\nThis re-mapping is transparent to the container, but introduces some configuration complexity in situations where the container needs access to resources on the Docker host, such as bind mounts into areas of the filesystem that the system user cannot write to. From a security standpoint, it is best to avoid these situations.\n\n## Prerequisites\n\n1.  The subordinate UID and GID ranges must be associated with an existing user, even though the association is an implementation detail. The user owns the namespaced storage directories under `/var/lib/docker/`. If you don’t want to use an existing user, Docker can create one for you and use that. If you want to use an existing username or user ID, it must already exist. Typically, this means that the relevant entries need to be in `/etc/passwd` and `/etc/group`, but if you are using a different authentication back-end, this requirement may translate differently.\n\n    To verify this, use the `id` command:\n\n    ``` \n    $ id testuser\n\n    uid=1001(testuser) gid=1001(testuser) groups=1001(testuser)\n    ```\n\n2.  The way the namespace remapping is handled on the host is using two files, `/etc/subuid` and `/etc/subgid`. These files are typically managed automatically when you add or remove users or groups, but on a few distributions such as RHEL and CentOS 7.3, you may need to manage these files manually.\n\n    Each file contains three fields: the username or ID of the user, followed by a beginning UID or GID (which is treated as UID or GID 0 within the namespace) and a maximum number of UIDs or GIDs available to the user. For instance, given the following entry:\n\n        testuser:231072:65536\n\n    This means that user-namespaced processes started by `testuser` are owned by host UID `231072` (which looks like UID `0` inside the namespace) through 296607 (231072 + 65536 - 1). These ranges should not overlap, to ensure that namespaced processes cannot access each other’s namespaces.\n\n    After adding your user, check `/etc/subuid` and `/etc/subgid` to see if your user has an entry in each. If not, you need to add it, being careful to avoid overlap.\n\n    If you want to use the `dockremap` user automatically created by Docker, check for the `dockremap` entry in these files **after** configuring and restarting Docker.\n\n3.  If there are any locations on the Docker host where the unprivileged user needs to write, adjust the permissions of those locations accordingly. This is also true if you want to use the `dockremap` user automatically created by Docker, but you can’t modify the permissions until after configuring and restarting Docker.\n\n4.  Enabling `userns-remap` effectively masks existing image and container layers, as well as other Docker objects within `/var/lib/docker/`. This is because Docker needs to adjust the ownership of these resources and actually stores them in a subdirectory within `/var/lib/docker/`. It is best to enable this feature on a new Docker installation rather than an existing one.\n\n    Along the same lines, if you disable `userns-remap` you can’t access any of the resources created while it was enabled.\n\n5.  Check the [limitations](#user-namespace-known-limitations) on user namespaces to be sure your use case is possible.\n\n## Enable userns-remap on the daemon\n\nYou can start `dockerd` with the `--userns-remap` flag or follow this procedure to configure the daemon using the `daemon.json` configuration file. The `daemon.json` method is recommended. If you use the flag, use the following command as a model:\n\n``` \n$ dockerd --userns-remap=\"testuser:testuser\"\n```\n\n1.  Edit `/etc/docker/daemon.json`. Assuming the file was previously empty, the following entry enables `userns-remap` using user and group called `testuser`. You can address the user and group by ID or name. You only need to specify the group name or ID if it is different from the user name or ID. If you provide both the user and group name or ID, separate them by a colon (`:`) character. The following formats all work for the value, assuming the UID and GID of `testuser` are `1001`:\n\n    - `testuser`\n    - `testuser:testuser`\n    - `1001`\n    - `1001:1001`\n    - `testuser:1001`\n    - `1001:testuser`\n\n    ``` \n    {\n      \"userns-remap\": \"testuser\"\n    }\n    ```\n\n    > **Note**: To use the `dockremap` user and have Docker create it for you, set the value to `default` rather than `testuser`.\n\n    Save the file and restart Docker.\n\n2.  If you are using the `dockremap` user, verify that Docker created it using the `id` command.\n\n    ``` \n    $ id dockremap\n\n    uid=112(dockremap) gid=116(dockremap) groups=116(dockremap)\n    ```\n\n    Verify that the entry has been added to `/etc/subuid` and `/etc/subgid`:\n\n    ``` \n    $ grep dockremap /etc/subuid\n\n    dockremap:231072:65536\n\n    $ grep dockremap /etc/subgid\n\n    dockremap:231072:65536\n    ```\n\n    If these entries are not present, edit the files as the `root` user and assign a starting UID and GID that is the highest-assigned one plus the offset (in this case, `65536`). Be careful not to allow any overlap in the ranges.\n\n3.  Verify that previous images are not available using the `docker image ls` command. The output should be empty.\n\n4.  Start a container from the `hello-world` image.\n\n    ``` \n    $ docker run hello-world\n    ```\n\n5.  Verify that a namespaced directory exists within `/var/lib/docker/` named with the UID and GID of the namespaced user, owned by that UID and GID, and not group-or-world-readable. Some of the subdirectories are still owned by `root` and have different permissions.\n\n    ``` \n    $ sudo ls -ld /var/lib/docker/231072.231072/\n\n    drwx------ 11 231072 231072 11 Jun 21 21:19 /var/lib/docker/231072.231072/\n\n    $ sudo ls -l /var/lib/docker/231072.231072/\n\n    total 14\n    drwx------ 5 231072 231072 5 Jun 21 21:19 aufs\n    drwx------ 3 231072 231072 3 Jun 21 21:21 containers\n    drwx------ 3 root   root   3 Jun 21 21:19 image\n    drwxr-x--- 3 root   root   3 Jun 21 21:19 network\n    drwx------ 4 root   root   4 Jun 21 21:19 plugins\n    drwx------ 2 root   root   2 Jun 21 21:19 swarm\n    drwx------ 2 231072 231072 2 Jun 21 21:21 tmp\n    drwx------ 2 root   root   2 Jun 21 21:19 trust\n    drwx------ 2 231072 231072 3 Jun 21 21:19 volumes\n    ```\n\n    Your directory listing may have some differences, especially if you use a different container storage driver than `aufs`.\n\n    The directories which are owned by the remapped user are used instead of the same directories directly beneath `/var/lib/docker/` and the unused versions (such as `/var/lib/docker/tmp/` in the example here) can be removed. Docker does not use them while `userns-remap` is enabled.\n\n## Disable namespace remapping for a container\n\nIf you enable user namespaces on the daemon, all containers are started with user namespaces enabled by default. In some situations, such as privileged containers, you may need to disable user namespaces for a specific container. See [user namespace known limitations](#user-namespace-known-limitations) for some of these limitations.\n\nTo disable user namespaces for a specific container, add the `--userns=host` flag to the `docker container create`, `docker container run`, or `docker container exec` command.\n\nThere is a side effect when using this flag: user remapping will not be enabled for that container but, because the read-only (image) layers are shared between containers, ownership of the containers filesystem will still be remapped.\n\nWhat this means is that the whole container filesystem will belong to the user specified in the `--userns-remap` daemon config (`231072` in the example above). This can lead to unexpected behavior of programs inside the container. For instance `sudo` (which checks that its binaries belong to user `0`) or binaries with a `setuid` flag.\n\n## User namespace known limitations\n\nThe following standard Docker features are incompatible with running a Docker daemon with user namespaces enabled:\n\n- sharing PID or NET namespaces with the host (`--pid=host` or `--network=host`).\n- external (volume or storage) drivers which are unaware or incapable of using daemon user mappings.\n- Using the `--privileged` mode flag on `docker run` without also specifying `--userns=host`.\n\nUser namespaces are an advanced feature and require coordination with other capabilities. For example, if volumes are mounted from the host, file ownership must be pre-arranged need read or write access to the volume contents.\n\nWhile the root user inside a user-namespaced container process has many of the expected privileges of the superuser within the container, the Linux kernel imposes restrictions based on internal knowledge that this is a user-namespaced process. One notable restriction is the inability to use the `mknod` command. Permission is denied for device creation within the container when run by the `root` user.\n\n[security](https://docs.docker.com/search/?q=security), [namespaces](https://docs.docker.com/search/?q=namespaces)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/userns-remap/](https://docs.docker.com/engine/security/userns-remap/)"
- name: Join nodes to a swarm
  id: engine/swarm/join-nodes/index
  summary: When you first create a swarm, you place a single Docker Engine into swarm mode
  description: "# Join nodes to a swarm\n\nWhen you first create a swarm, you place a single Docker Engine into swarm mode. To take full advantage of swarm mode you can add nodes to the swarm:\n\n- Adding worker nodes increases capacity. When you deploy a service to a swarm, the Engine schedules tasks on available nodes whether they are worker nodes or manager nodes. When you add workers to your swarm, you increase the scale of the swarm to handle tasks without affecting the manager raft consensus.\n- Manager nodes increase fault-tolerance. Manager nodes perform the orchestration and cluster management functions for the swarm. Among manager nodes, a single leader node conducts orchestration tasks. If a leader node goes down, the remaining manager nodes elect a new leader and resume orchestration and maintenance of the swarm state. By default, manager nodes also run tasks.\n\nThe Docker Engine joins the swarm depending on the **join-token** you provide to the `docker swarm join` command. The node only uses the token at join time. If you subsequently rotate the token, it doesn’t affect existing swarm nodes. Refer to [Run Docker Engine in swarm mode](../swarm-mode/index#view-the-join-command-or-update-a-swarm-join-token).\n\n## Join as a worker node\n\nTo retrieve the join command including the join token for worker nodes, run the following command on a manager node:\n\n``` \n$ docker swarm join-token worker\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n    192.168.99.100:2377\n```\n\nRun the command from the output on the worker to join the swarm:\n\n``` \n$ docker swarm join \\\n  --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n  192.168.99.100:2377\n\nThis node joined a swarm as a worker.\n```\n\nThe `docker swarm join` command does the following:\n\n- switches the Docker Engine on the current node into swarm mode.\n- requests a TLS certificate from the manager.\n- names the node with the machine hostname\n- joins the current node to the swarm at the manager listen address based upon the swarm token.\n- sets the current node to `Active` availability, meaning it can receive tasks from the scheduler.\n- extends the `ingress` overlay network to the current node.\n\n## Join as a manager node\n\nWhen you run `docker swarm join` and pass the manager token, the Docker Engine switches into swarm mode the same as for workers. Manager nodes also participate in the raft consensus. The new nodes should be `Reachable`, but the existing manager remains the swarm `Leader`.\n\nDocker recommends three or five manager nodes per cluster to implement high availability. Because swarm mode manager nodes share data using Raft, there must be an odd number of managers. The swarm can continue to function after as long as a quorum of more than half of the manager nodes are available.\n\nFor more detail about swarm managers and administering a swarm, see [Administer and maintain a swarm of Docker Engines](../admin_guide/index).\n\nTo retrieve the join command including the join token for manager nodes, run the following command on a manager node:\n\n``` \n$ docker swarm join-token manager\n\nTo add a manager to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-61ztec5kyafptydic6jfc1i33t37flcl4nuipzcusor96k7kby-5vy9t8u35tuqm7vh67lrz9xp6 \\\n    192.168.99.100:2377\n```\n\nRun the command from the output on the new manager node to join it to the swarm:\n\n``` \n$ docker swarm join \\\n  --token SWMTKN-1-61ztec5kyafptydic6jfc1i33t37flcl4nuipzcusor96k7kby-5vy9t8u35tuqm7vh67lrz9xp6 \\\n  192.168.99.100:2377\n\nThis node joined a swarm as a manager.\n```\n\n## Learn More\n\n- `swarm join` [command line reference](../../reference/commandline/swarm_join/index)\n- [Swarm mode tutorial](../swarm-tutorial/index)\n\n[guide](https://docs.docker.com/search/?q=guide), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [node](https://docs.docker.com/search/?q=node)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/join-nodes/](https://docs.docker.com/engine/swarm/join-nodes/)"
- name: Lock your swarm to protect its encryption key
  id: engine/swarm/swarm_manager_locking/index
  summary: The Raft logs used by swarm managers are encrypted on disk by default
  description: "# Lock your swarm to protect its encryption key\n\nThe Raft logs used by swarm managers are encrypted on disk by default. This at-rest encryption protects your service’s configuration and data from attackers who gain access to the encrypted Raft logs. One of the reasons this feature was introduced was in support of the [Docker secrets](../secrets/index) feature.\n\nWhen Docker restarts, both the TLS key used to encrypt communication among swarm nodes, and the key used to encrypt and decrypt Raft logs on disk, are loaded into each manager node’s memory. Docker has the ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called *autolock*.\n\nWhen Docker restarts, you must [unlock the swarm](#unlock-a-swarm) first, using a *key encryption key* generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.\n\n> **Note**: You don’t need to unlock the swarm when a new node joins the swarm, because the key is propagated to it over mutual TLS.\n\n## Initialize a swarm with autolocking enabled\n\nWhen you initialize a new swarm, you can use the `--autolock` flag to enable autolocking of swarm manager nodes when Docker restarts.\n\n``` \n$ docker swarm init --autolock\n\nSwarm initialized: current node (k1q27tfyx9rncpixhk69sa61v) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-0j52ln6hxjpxk2wgk917abcnxywj3xed0y8vi1e5m9t3uttrtu-7bnxvvlz2mrcpfonjuztmtts9 \\\n    172.31.46.109:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n\nTo unlock a swarm manager after it restarts, run the `docker swarm unlock`\ncommand and provide the following key:\n\n    SWMKEY-1-WuYH/IX284+lRcXuoVf38viIDK3HJEKY13MIHX+tTt8\n```\n\nStore the key in a safe place, such as in a password manager.\n\nWhen Docker restarts, you need to [unlock the swarm](#unlock-a-swarm). A locked swarm causes an error like the following when you try to start or restart a service:\n\n``` \n$ sudo service docker restart\n\n$ docker service ls\n\nError response from daemon: Swarm is encrypted and needs to be unlocked before it can be used. Use \"docker swarm unlock\" to unlock it.\n```\n\n## Enable or disable autolock on an existing swarm\n\nTo enable autolock on an existing swarm, set the `autolock` flag to `true`.\n\n``` \n$ docker swarm update --autolock=true\n\nSwarm updated.\nTo unlock a swarm manager after it restarts, run the `docker swarm unlock`\ncommand and provide the following key:\n\n    SWMKEY-1-+MrE8NgAyKj5r3NcR4FiQMdgu+7W72urH0EZeSmP/0Y\n\nPlease remember to store this key in a password manager, since without it you\nwill not be able to restart the manager.\n```\n\nTo disable autolock, set `--autolock` to `false`. The mutual TLS key and the encryption key used to read and write Raft logs are stored unencrypted on disk. There is a trade-off between the risk of storing the encryption key unencrypted at rest and the convenience of restarting a swarm without needing to unlock each manager.\n\n``` \n$ docker swarm update --autolock=false\n```\n\nKeep the unlock key around for a short time after disabling autolocking, in case a manager goes down while it is still configured to lock using the old key.\n\n## Unlock a swarm\n\nTo unlock a locked swarm, use `docker swarm unlock`.\n\n``` \n$ docker swarm unlock\n\nPlease enter unlock key:\n```\n\nEnter the encryption key that was generated and shown in the command output when you locked the swarm or rotated the key, and the swarm unlocks.\n\n## View the current unlock key for a running swarm\n\nConsider a situation where your swarm is running as expected, then a manager node becomes unavailable. You troubleshoot the problem and bring the physical node back online, but you need to unlock the manager by providing the unlock key to read the encrypted credentials and Raft logs.\n\nIf the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using `docker swarm unlock-key` without any arguments.\n\n``` \n$ docker swarm unlock-key\n\nTo unlock a swarm manager after it restarts, run the `docker swarm unlock`\ncommand and provide the following key:\n\n    SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA\n\nPlease remember to store this key in a password manager, since without it you\nwill not be able to restart the manager.\n```\n\nIf the key was rotated after the swarm node became unavailable and you do not have a record of the previous key, you may need to force the manager to leave the swarm and join it back to the swarm as a new manager.\n\n## Rotate the unlock key\n\nYou should rotate the locked swarm’s unlock key on a regular schedule.\n\n``` \n$ docker swarm unlock-key --rotate\n\nSuccessfully rotated manager unlock key.\n\nTo unlock a swarm manager after it restarts, run the `docker swarm unlock`\ncommand and provide the following key:\n\n    SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA\n\nPlease remember to store this key in a password manager, since without it you\nwill not be able to restart the manager.\n```\n\n> **Warning**: When you rotate the unlock key, keep a record of the old key around for a few minutes, so that if a manager goes down before it gets the new key, it may still be unlocked with the old one.\n\n[swarm](https://docs.docker.com/search/?q=swarm), [manager](https://docs.docker.com/search/?q=manager), [lock](https://docs.docker.com/search/?q=lock), [unlock](https://docs.docker.com/search/?q=unlock), [autolock](https://docs.docker.com/search/?q=autolock), [encryption](https://docs.docker.com/search/?q=encryption)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm_manager_locking/](https://docs.docker.com/engine/swarm/swarm_manager_locking/)"
- name: Machine
  id: machine/index
  summary: Docker Machine has been deprecated
  description: "# Docker Machine\n\n> **Deprecated**\n>\n> Docker Machine has been deprecated. Please use Docker Desktop instead. See [Docker Desktop for Mac](https://docs.docker.com/desktop/mac/) and [Docker Desktop for Windows](https://docs.docker.com/desktop/windows/). You can also use other cloud provisioning tools.\n\nThe source code for Docker Machine has been archived. You can find the source code on [GitHub](https://github.com/docker/machine).\n\n[docker](https://docs.docker.com/search/?q=docker), [machine](https://docs.docker.com/search/?q=machine)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/machine/](https://docs.docker.com/machine/)"
- name: Manage keys for content trust
  id: engine/security/trust/trust_key_mng/index
  summary: Trust for an image tag is managed through the use of keys
  description: "# Manage keys for content trust\n\nTrust for an image tag is managed through the use of keys. Docker’s content trust makes use of five different types of keys:\n\n| Key        | Description                                                                                                                                                                                                                         |\n|:-----------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| root key   | Root of content trust for an image tag. When content trust is enabled, you create the root key once. Also known as the offline key, because it should be kept offline.                                                              |\n| targets    | This key allows you to sign image tags, to manage delegations including delegated keys or permitted delegation paths. Also known as the repository key, since this key determines what tags can be signed into an image repository. |\n| snapshot   | This key signs the current collection of image tags, preventing mix and match attacks.                                                                                                                                              |\n| timestamp  | This key allows Docker image repositories to have freshness security guarantees without requiring periodic content refreshes on the client’s side.                                                                                  |\n| delegation | Delegation keys are optional tagging keys and allow you to delegate signing image tags to other publishers without having to share your targets key.                                                                                |\n\nWhen doing a `docker push` with Content Trust enabled for the first time, the root, targets, snapshot, and timestamp keys are generated automatically for the image repository:\n\n- The root and targets key are generated and stored locally client-side.\n\n- The timestamp and snapshot keys are safely generated and stored in a signing server that is deployed alongside the Docker registry. These keys are generated in a backend service that isn’t directly exposed to the internet and are encrypted at rest.\n\nDelegation keys are optional, and not generated as part of the normal `docker` workflow. They need to be [manually generated and added to the repository](../trust_delegation/index#creating-delegation-keys).\n\n**Note**: Prior to Docker Engine 1.11, the snapshot key was also generated and stored locally client-side. Use the Notary CLI to [manage your snapshot key locally again](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage/#rotate-keys) for repositories created with newer versions of Docker.\n\n## Choose a passphrase\n\nThe passphrases you chose for both the root key and your repository key should be randomly generated and stored in a password manager. Having the repository key allows users to sign image tags on a repository. Passphrases are used to encrypt your keys at rest and ensure that a lost laptop or an unintended backup doesn’t put the private key material at risk.\n\n## Back up your keys\n\nAll the Docker trust keys are stored encrypted using the passphrase you provide on creation. Even so, you should still take care of the location where you back them up. Good practice is to create two encrypted USB keys.\n\nIt is very important that you back up your keys to a safe, secure location. Loss of the repository key is recoverable; loss of the root key is not.\n\nThe Docker client stores the keys in the `~/.docker/trust/private` directory. Before backing them up, you should `tar` them into an archive:\n\n``` \n$ umask 077; tar -zcvf private_keys_backup.tar.gz ~/.docker/trust/private; umask 022\n```\n\n## Hardware storage and signing\n\nDocker Content Trust can store and sign with root keys from a Yubikey 4. The Yubikey is prioritized over keys stored in the filesystem. When you initialize a new repository with content trust, Docker Engine looks for a root key locally. If a key is not found and the Yubikey 4 exists, Docker Engine creates a root key in the Yubikey 4. Consult the [Notary documentation](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage/#use-a-yubikey) for more details.\n\nPrior to Docker Engine 1.11, this feature was only in the experimental branch.\n\n## Lost keys\n\nIf a publisher loses keys it means losing the ability to sign trusted content for your repositories. If you lose a key, send an email to [Docker Hub Support](mailto:hub-support@docker.com) to reset the repository state.\n\nThis loss also requires **manual intervention** from every consumer that pulled the tagged image prior to the loss. Image consumers would get an error for content that they already downloaded:\n\n``` \nWarning: potential malicious behavior - trust data has insufficient signatures for remote repository docker.io/my/image: valid signatures did not meet threshold\n```\n\nTo correct this, they need to download a new image tag that is signed with the new key.\n\n## Related information\n\n- [Content trust in Docker](../index)\n- [Automation with content trust](../trust_automation/index)\n- [Delegations for content trust](../trust_delegation/index)\n- [Play in a content trust sandbox](../trust_sandbox/index)\n\n[trust](https://docs.docker.com/search/?q=trust), [security](https://docs.docker.com/search/?q=security), [root](https://docs.docker.com/search/?q=root), [keys](https://docs.docker.com/search/?q=keys), [repository](https://docs.docker.com/search/?q=repository)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/trust/trust_key_mng/](https://docs.docker.com/engine/security/trust/trust_key_mng/)"
- name: Manage nodes in a swarm
  id: engine/swarm/manage-nodes/index
  summary: For more information on swarm administration refer to the Swarm administration guide
  description: "# Manage nodes in a swarm\n\nAs part of the swarm management lifecycle, you may need to view or update a node as follows:\n\n- [list nodes in the swarm](#list-nodes)\n- [inspect an individual node](#inspect-an-individual-node)\n- [update a node](#update-a-node)\n- [leave the swarm](#leave-the-swarm)\n\n## List nodes\n\nTo view a list of nodes in the swarm run `docker node ls` from a manager node:\n\n``` \n$ docker node ls\n\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n46aqrk4e473hjbt745z53cr3t    node-5    Ready   Active        Reachable\n61pi3d91s0w3b90ijw3deeb2q    node-4    Ready   Active        Reachable\na5b2m3oghd48m8eu391pefq5u    node-3    Ready   Active\ne7p8btxeu3ioshyuj6lxiv6g0    node-2    Ready   Active\nehkv3bcimagdese79dn78otj5 *  node-1    Ready   Active        Leader\n```\n\nThe `AVAILABILITY` column shows whether or not the scheduler can assign tasks to the node:\n\n- `Active` means that the scheduler can assign tasks to the node.\n- `Pause` means the scheduler doesn’t assign new tasks to the node, but existing tasks remain running.\n- `Drain` means the scheduler doesn’t assign new tasks to the node. The scheduler shuts down any existing tasks and schedules them on an available node.\n\nThe `MANAGER STATUS` column shows node participation in the Raft consensus:\n\n- No value indicates a worker node that does not participate in swarm management.\n- `Leader` means the node is the primary manager node that makes all swarm management and orchestration decisions for the swarm.\n- `Reachable` means the node is a manager node participating in the Raft consensus quorum. If the leader node becomes unavailable, the node is eligible for election as the new leader.\n- `Unavailable` means the node is a manager that can’t communicate with other managers. If a manager node becomes unavailable, you should either join a new manager node to the swarm or promote a worker node to be a manager.\n\nFor more information on swarm administration refer to the [Swarm administration guide](../admin_guide/index).\n\n## Inspect an individual node\n\nYou can run `docker node inspect <NODE-ID>` on a manager node to view the details for an individual node. The output defaults to JSON format, but you can pass the `--pretty` flag to print the results in human-readable format. For example:\n\n``` \n$ docker node inspect self --pretty\n\nID:                     ehkv3bcimagdese79dn78otj5\nHostname:               node-1\nJoined at:              2016-06-16 22:52:44.9910662 +0000 utc\nStatus:\n State:                 Ready\n Availability:          Active\nManager Status:\n Address:               172.17.0.2:2377\n Raft Status:           Reachable\n Leader:                Yes\nPlatform:\n Operating System:      linux\n Architecture:          x86_64\nResources:\n CPUs:                  2\n Memory:                1.954 GiB\nPlugins:\n  Network:              overlay, host, bridge, overlay, null\n  Volume:               local\nEngine Version:         1.12.0-dev\n```\n\n## Update a node\n\nYou can modify node attributes as follows:\n\n- [change node availability](#change-node-availability)\n- [add or remove label metadata](#add-or-remove-label-metadata)\n- [change a node role](#promote-or-demote-a-node)\n\n### Change node availability\n\nChanging node availability lets you:\n\n- drain a manager node so that only performs swarm management tasks and is unavailable for task assignment.\n- drain a node so you can take it down for maintenance.\n- pause a node so it can’t receive new tasks.\n- restore unavailable or paused nodes available status.\n\nFor example, to change a manager node to `Drain` availability:\n\n``` \n$ docker node update --availability drain node-1\n\nnode-1\n```\n\nSee [list nodes](#list-nodes) for descriptions of the different availability options.\n\n### Add or remove label metadata\n\nNode labels provide a flexible method of node organization. You can also use node labels in service constraints. Apply constraints when you create a service to limit the nodes where the scheduler assigns tasks for the service.\n\nRun `docker node update --label-add` on a manager node to add label metadata to a node. The `--label-add` flag supports either a `<key>` or a `<key>=<value>` pair.\n\nPass the `--label-add` flag once for each node label you want to add:\n\n``` \n$ docker node update --label-add foo --label-add bar=baz node-1\n\nnode-1\n```\n\nThe labels you set for nodes using docker node update apply only to the node entity within the swarm. Do not confuse them with the docker daemon labels for [dockerd](https://docs.docker.com/config/labels-custom-metadata/).\n\nTherefore, node labels can be used to limit critical tasks to nodes that meet certain requirements. For example, schedule only on machines where special workloads should be run, such as machines that meet [PCI-SS compliance](https://www.pcisecuritystandards.org/).\n\nA compromised worker could not compromise these special workloads because it cannot change node labels.\n\nEngine labels, however, are still useful because some features that do not affect secure orchestration of containers might be better off set in a decentralized manner. For instance, an engine could have a label to indicate that it has a certain type of disk device, which may not be relevant to security directly. These labels are more easily “trusted” by the swarm orchestrator.\n\nRefer to the `docker service create` [CLI reference](../../reference/commandline/service_create/index) for more information about service constraints.\n\n### Promote or demote a node\n\nYou can promote a worker node to the manager role. This is useful when a manager node becomes unavailable or if you want to take a manager offline for maintenance. Similarly, you can demote a manager node to the worker role.\n\n> **Note**: Regardless of your reason to promote or demote a node, you must always maintain a quorum of manager nodes in the swarm. For more information refer to the [Swarm administration guide](../admin_guide/index).\n\nTo promote a node or set of nodes, run `docker node promote` from a manager node:\n\n``` \n$ docker node promote node-3 node-2\n\nNode node-3 promoted to a manager in the swarm.\nNode node-2 promoted to a manager in the swarm.\n```\n\nTo demote a node or set of nodes, run `docker node demote` from a manager node:\n\n``` \n$ docker node demote node-3 node-2\n\nManager node-3 demoted in the swarm.\nManager node-2 demoted in the swarm.\n```\n\n`docker node promote` and `docker node demote` are convenience commands for `docker node update --role manager` and `docker node update --role worker` respectively.\n\n## Install plugins on swarm nodes\n\nIf your swarm service relies on one or more [plugins](../../extend/plugin_api/index), these plugins need to be available on every node where the service could potentially be deployed. You can manually install the plugin on each node or script the installation. You can also deploy the plugin in a similar way as a global service using the Docker API, by specifying a `PluginSpec` instead of a `ContainerSpec`.\n\n> **Note**\n>\n> There is currently no way to deploy a plugin to a swarm using the Docker CLI or Docker Compose. In addition, it is not possible to install plugins from a private repository.\n\nThe [`PluginSpec`](../../extend/plugin_api/index#json-specification) is defined by the plugin developer. To add the plugin to all Docker nodes, use the [`service/create`](https://docs.docker.com/engine/api/v1.31/#operation/ServiceCreate) API, passing the `PluginSpec` JSON defined in the `TaskTemplate`.\n\n## Leave the swarm\n\nRun the `docker swarm leave` command on a node to remove it from the swarm.\n\nFor example to leave the swarm on a worker node:\n\n``` \n$ docker swarm leave\n\nNode left the swarm.\n```\n\nWhen a node leaves the swarm, the Docker Engine stops running in swarm mode. The orchestrator no longer schedules tasks to the node.\n\nIf the node is a manager node, you receive a warning about maintaining the quorum. To override the warning, pass the `--force` flag. If the last manager node leaves the swarm, the swarm becomes unavailable requiring you to take disaster recovery measures.\n\nFor information about maintaining a quorum and disaster recovery, refer to the [Swarm administration guide](../admin_guide/index).\n\nAfter a node leaves the swarm, you can run the `docker node rm` command on a manager node to remove the node from the node list.\n\nFor instance:\n\n``` \n$ docker node rm node-2\n```\n\n## Learn more\n\n- [Swarm administration guide](../admin_guide/index)\n- [Docker Engine command line reference](../../reference/commandline/docker/index)\n- [Swarm mode tutorial](../swarm-tutorial/index)\n\n[guide](https://docs.docker.com/search/?q=guide), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [node](https://docs.docker.com/search/?q=node)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/manage-nodes/](https://docs.docker.com/engine/swarm/manage-nodes/)"
- name: Manage sensitive data with Docker secrets
  id: engine/swarm/secrets/index
  summary: In terms of Docker Swarm services, a secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application’s source code
  description: "# Manage sensitive data with Docker secrets\n\n## About secrets\n\nIn terms of Docker Swarm services, a *secret* is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application’s source code. You can use Docker *secrets* to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running.\n\nYou can use secrets to manage any sensitive data which a container needs at runtime but you don’t want to store in the image or in source control, such as:\n\n- Usernames and passwords\n- TLS certificates and keys\n- SSH keys\n- Other important data such as the name of a database or internal server\n- Generic strings or binary content (up to 500 kb in size)\n\n> **Note**: Docker secrets are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service. Stateful containers can typically run with a scale of 1 without changing the container code.\n\nAnother use case for using secrets is to provide a layer of abstraction between the container and a set of credentials. Consider a scenario where you have separate development, test, and production environments for your application. Each of these environments can have different credentials, stored in the development, test, and production swarms with the same secret name. Your containers only need to know the name of the secret to function in all three environments.\n\nYou can also use secrets to manage non-sensitive data, such as configuration files. However, Docker supports the use of [configs](../configs/index) for storing non-sensitive data. Configs are mounted into the container’s filesystem directly, without the use of a RAM disk.\n\n### Windows support\n\nDocker includes support for secrets on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:\n\n- Microsoft Windows has no built-in driver for managing RAM disks, so within running Windows containers, secrets **are** persisted in clear text to the container’s root disk. However, the secrets are explicitly removed when a container stops. In addition, Windows does not support persisting a running container as an image using `docker commit` or similar commands.\n\n- On Windows, we recommend enabling [BitLocker](https://technet.microsoft.com/en-us/library/cc732774(v=ws.11).aspx) on the volume containing the Docker root directory on the host machine to ensure that secrets for running containers are encrypted at rest.\n\n- Secret files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, secrets for a container are all mounted in `C:\\ProgramData\\Docker\\internal\\secrets` (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the secret within the container. The default target is `C:\\ProgramData\\Docker\\secrets`.\n\n- When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for secrets. Secrets are currently only accessible by administrators and users with `system` access within the container.\n\n## How Docker manages secrets\n\nWhen you add a secret to the swarm, Docker sends the secret to the swarm manager over a mutual TLS connection. The secret is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for secrets as for the rest of the swarm management data.\n\nWhen you grant a newly-created or running service access to a secret, the decrypted secret is mounted into the container in an in-memory filesystem. The location of the mount point within the container defaults to `/run/secrets/<secret_name>` in Linux containers, or `C:\\ProgramData\\Docker\\secrets` in Windows containers. You can also specify a custom location.\n\nYou can update a service to grant it access to additional secrets or revoke its access to a given secret at any time.\n\nA node only has access to (encrypted) secrets if the node is a swarm manager or if it is running service tasks which have been granted access to the secret. When a container task stops running, the decrypted secrets shared to it are unmounted from the in-memory filesystem for that container and flushed from the node’s memory.\n\nIf a node loses connectivity to the swarm while it is running a task container with access to a secret, the task container still has access to its secrets, but cannot receive updates until the node reconnects to the swarm.\n\nYou can add or inspect an individual secret at any time, or list all secrets. You cannot remove a secret that a running service is using. See [Rotate a secret](index#example-rotate-a-secret) for a way to remove a secret without disrupting running services.\n\nTo update or roll back secrets more easily, consider adding a version number or date to the secret name. This is made easier by the ability to control the mount point of the secret within a given container.\n\n## Read more about `docker secret` commands\n\nUse these links to read about specific commands, or continue to the [example about using secrets with a service](index#simple-example-get-started-with-secrets).\n\n- [`docker secret create`](../../reference/commandline/secret_create/index)\n- [`docker secret inspect`](../../reference/commandline/secret_inspect/index)\n- [`docker secret ls`](../../reference/commandline/secret_ls/index)\n- [`docker secret rm`](../../reference/commandline/secret_rm/index)\n- [`--secret`](../../reference/commandline/service_create/index#create-a-service-with-secrets) flag for `docker service create`\n- [`--secret-add` and `--secret-rm`](../../reference/commandline/service_update/index#add-or-remove-secrets) flags for `docker service update`\n\n## Examples\n\nThis section includes three graduated examples which illustrate how to use Docker secrets. The images used in these examples have been updated to make it easier to use Docker secrets. To find out how to modify your own images in a similar way, see [Build support for Docker Secrets into your images](#build-support-for-docker-secrets-into-your-images).\n\n> **Note**: These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support secrets. See [Windows support](#windows-support).\n\n### Defining and using secrets in compose files\n\nBoth the `docker-compose` and `docker stack` commands support defining secrets in a compose file. See [the Compose file reference](../../../compose/compose-file/compose-file-v3/index#secrets) for details.\n\n### Simple example: Get started with secrets\n\nThis simple example shows how secrets work in just a few commands. For a real-world example, continue to [Intermediate example: Use secrets with a Nginx service](#intermediate-example-use-secrets-with-a-nginx-service).\n\n1.  Add a secret to Docker. The `docker secret create` command reads standard input because the last argument, which represents the file to read the secret from, is set to `-`.\n\n    ``` \n    $ printf \"This is a secret\" | docker secret create my_secret_data -\n    ```\n\n2.  Create a `redis` service and grant it access to the secret. By default, the container can access the secret at `/run/secrets/<secret_name>`, but you can customize the file name on the container using the `target` option.\n\n    ``` \n    $ docker service  create --name redis --secret my_secret_data redis:alpine\n    ```\n\n3.  Verify that the task is running without issues using `docker service ps`. If everything is working, the output looks similar to this:\n\n    ``` \n    $ docker service ps redis\n\n    ID            NAME     IMAGE         NODE              DESIRED STATE  CURRENT STATE          ERROR  PORTS\n    bkna6bpn8r1a  redis.1  redis:alpine  ip-172-31-46-109  Running        Running 8 seconds ago  \n    ```\n\n    If there were an error, and the task were failing and repeatedly restarting, you would see something like this:\n\n    ``` \n    $ docker service ps redis\n\n    NAME                      IMAGE         NODE  DESIRED STATE  CURRENT STATE          ERROR                      PORTS\n    redis.1.siftice35gla      redis:alpine  moby  Running        Running 4 seconds ago                             \n     \\_ redis.1.whum5b7gu13e  redis:alpine  moby  Shutdown       Failed 20 seconds ago      \"task: non-zero exit (1)\"  \n     \\_ redis.1.2s6yorvd9zow  redis:alpine  moby  Shutdown       Failed 56 seconds ago      \"task: non-zero exit (1)\"  \n     \\_ redis.1.ulfzrcyaf6pg  redis:alpine  moby  Shutdown       Failed about a minute ago  \"task: non-zero exit (1)\"  \n     \\_ redis.1.wrny5v4xyps6  redis:alpine  moby  Shutdown       Failed 2 minutes ago       \"task: non-zero exit (1)\"\n    ```\n\n4.  Get the ID of the `redis` service task container using `docker ps` , so that you can use `docker container exec` to connect to the container and read the contents of the secret data file, which defaults to being readable by all and has the same name as the name of the secret. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\n\n    ``` \n    $ docker ps --filter name=redis -q\n\n    5cb1c2348a59\n\n    $ docker container exec $(docker ps --filter name=redis -q) ls -l /run/secrets\n\n    total 4\n    -r--r--r--    1 root     root            17 Dec 13 22:48 my_secret_data\n\n    $ docker container exec $(docker ps --filter name=redis -q) cat /run/secrets/my_secret_data\n\n    This is a secret\n    ```\n\n5.  Verify that the secret is **not** available if you commit the container.\n\n        $ docker commit $(docker ps --filter name=redis -q) committed_redis\n\n        $ docker run --rm -it committed_redis cat /run/secrets/my_secret_data\n\n        cat: can't open '/run/secrets/my_secret_data': No such file or directory\n\n6.  Try removing the secret. The removal fails because the `redis` service is running and has access to the secret.\n\n    ``` \n    $ docker secret ls\n\n    ID                          NAME                CREATED             UPDATED\n    wwwrxza8sxy025bas86593fqs   my_secret_data      4 hours ago         4 hours ago\n\n\n    $ docker secret rm my_secret_data\n\n    Error response from daemon: rpc error: code = 3 desc = secret\n    'my_secret_data' is in use by the following service: redis\n    ```\n\n7.  Remove access to the secret from the running `redis` service by updating the service.\n\n    ``` \n    $ docker service update --secret-rm my_secret_data redis\n    ```\n\n8.  Repeat steps 3 and 4 again, verifying that the service no longer has access to the secret. The container ID is different, because the `service update` command redeploys the service.\n\n        $ docker container exec -it $(docker ps --filter name=redis -q) cat /run/secrets/my_secret_data\n\n        cat: can't open '/run/secrets/my_secret_data': No such file or directory\n\n9.  Stop and remove the service, and remove the secret from Docker.\n\n    ``` \n    $ docker service rm redis\n\n    $ docker secret rm my_secret_data\n    ```\n\n### Simple example: Use secrets in a Windows service\n\nThis is a very simple example which shows how to use secrets with a Microsoft IIS service running on Docker for Windows running Windows containers on Microsoft Windows 10. It is a naive example that stores the webpage in a secret.\n\nThis example assumes that you have PowerShell installed.\n\n1.  Save the following into a new file `index.html`.\n\n    ``` \n    <html lang=\"en\">\n      <head><title>Hello Docker</title></head>\n      <body>\n        <p>Hello Docker! You have deployed a HTML page.</p>\n      </body>\n    </html>\n    ```\n\n2.  If you have not already done so, initialize or join the swarm.\n\n    ``` \n    docker swarm init\n    ```\n\n3.  Save the `index.html` file as a swarm secret named `homepage`.\n\n    ``` \n    docker secret create homepage index.html\n    ```\n\n4.  Create an IIS service and grant it access to the `homepage` secret.\n\n    ``` \n    docker service create\n        --name my-iis\n        --publish published=8000,target=8000\n        --secret src=homepage,target=\"\\inetpub\\wwwroot\\index.html\"\n        microsoft/iis:nanoserver  \n    ```\n\n    > **Note**: There is technically no reason to use secrets for this example; [configs](../configs/index) are a better fit. This example is for illustration only.\n\n5.  Access the IIS service at `http://localhost:8000/`. It should serve the HTML content from the first step.\n\n6.  Remove the service and the secret.\n\n    ``` \n    docker service rm my-iis\n    docker secret rm homepage\n    docker image remove secret-test\n    ```\n\n### Intermediate example: Use secrets with a Nginx service\n\nThis example is divided into two parts. [The first part](#generate-the-site-certificate) is all about generating the site certificate and does not directly involve Docker secrets at all, but it sets up [the second part](#configure-the-nginx-container), where you store and use the site certificate and Nginx configuration as secrets.\n\n#### Generate the site certificate\n\nGenerate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as `Let’s Encrypt` to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can [use Let’s Encrypt](https://letsencrypt.org/getting-started/) to generate the site key and certificate, name the files `site.key` and `site.crt`, and skip to [Configure the Nginx container](#configure-the-nginx-container).\n\n1.  Generate a root key.\n\n    ``` \n    $ openssl genrsa -out \"root-ca.key\" 4096\n    ```\n\n2.  Generate a CSR using the root key.\n\n    ``` \n    $ openssl req \\\n              -new -key \"root-ca.key\" \\\n              -out \"root-ca.csr\" -sha256 \\\n              -subj '/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA'\n    ```\n\n3.  Configure the root CA. Edit a new file called `root-ca.cnf` and paste the following contents into it. This constrains the root CA to signing leaf certificates and not intermediate CAs.\n\n        [root_ca]\n        basicConstraints = critical,CA:TRUE,pathlen:1\n        keyUsage = critical, nonRepudiation, cRLSign, keyCertSign\n        subjectKeyIdentifier=hash\n\n4.  Sign the certificate.\n\n    ``` \n    $ openssl x509 -req  -days 3650  -in \"root-ca.csr\" \\\n                   -signkey \"root-ca.key\" -sha256 -out \"root-ca.crt\" \\\n                   -extfile \"root-ca.cnf\" -extensions \\\n                   root_ca\n    ```\n\n5.  Generate the site key.\n\n    ``` \n    $ openssl genrsa -out \"site.key\" 4096\n    ```\n\n6.  Generate the site certificate and sign it with the site key.\n\n    ``` \n    $ openssl req -new -key \"site.key\" -out \"site.csr\" -sha256 \\\n              -subj '/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost'\n    ```\n\n7.  Configure the site certificate. Edit a new file called `site.cnf` and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can’t be used to sign certificates.\n\n        [server]\n        authorityKeyIdentifier=keyid,issuer\n        basicConstraints = critical,CA:FALSE\n        extendedKeyUsage=serverAuth\n        keyUsage = critical, digitalSignature, keyEncipherment\n        subjectAltName = DNS:localhost, IP:127.0.0.1\n        subjectKeyIdentifier=hash\n\n8.  Sign the site certificate.\n\n    ``` \n    $ openssl x509 -req -days 750 -in \"site.csr\" -sha256 \\\n        -CA \"root-ca.crt\" -CAkey \"root-ca.key\"  -CAcreateserial \\\n        -out \"site.crt\" -extfile \"site.cnf\" -extensions server\n    ```\n\n9.  The `site.csr` and `site.cnf` files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the `root-ca.key` file.\n\n#### Configure the Nginx container\n\n1.  Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\n\n    In the current directory, create a new file called `site.conf` with the following contents:\n\n        server {\n            listen                443 ssl;\n            server_name           localhost;\n            ssl_certificate       /run/secrets/site.crt;\n            ssl_certificate_key   /run/secrets/site.key;\n\n            location / {\n                root   /usr/share/nginx/html;\n                index  index.html index.htm;\n            }\n        }\n\n2.  Create three secrets, representing the key, the certificate, and the `site.conf`. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key, certificate, and configuration from the services that use them. In each of these commands, the last argument represents the path to the file to read the secret from on the host machine’s filesystem. In these examples, the secret name and the file name are the same.\n\n    ``` \n    $ docker secret create site.key site.key\n\n    $ docker secret create site.crt site.crt\n\n    $ docker secret create site.conf site.conf\n    ```\n\n    ``` \n    $ docker secret ls\n\n    ID                          NAME                  CREATED             UPDATED\n    2hvoi9mnnaof7olr3z5g3g7fp   site.key       58 seconds ago      58 seconds ago\n    aya1dh363719pkiuoldpter4b   site.crt       24 seconds ago      24 seconds ago\n    zoa5df26f7vpcoz42qf2csth8   site.conf      11 seconds ago      11 seconds ago\n    ```\n\n3.  Create a service that runs Nginx and has access to the three secrets. The last part of the `docker service create` command creates a symbolic link from the location of the `site.conf` secret to `/etc/nginx.conf.d/`, where Nginx looks for extra configuration files. This step happens before Nginx actually starts, so you don’t need to rebuild your image if you change the Nginx configuration.\n\n    > **Note**: Normally you would create a Dockerfile which copies the `site.conf` into place, build the image, and run a container using your custom image. This example does not require a custom image. It puts the `site.conf` into place and runs the container all in one step.\n\n    Secrets are located within the `/run/secrets/` directory in the container by default, which may require extra steps in the container to make the secret available in a different path. The example below creates a symbolic link to the true location of the `site.conf` file so that Nginx can read it:\n\n    ``` \n    $ docker service create \\\n         --name nginx \\\n         --secret site.key \\\n         --secret site.crt \\\n         --secret site.conf \\\n         --publish published=3000,target=443 \\\n         nginx:latest \\\n         sh -c \"ln -s /run/secrets/site.conf /etc/nginx/conf.d/site.conf && exec nginx -g 'daemon off;'\"\n    ```\n\n    Instead of creating symlinks, secrets allow you to specify a custom location using the `target` option. The example below illustrates how the `site.conf` secret is made available at `/etc/nginx/conf.d/site.conf` inside the container without the use of symbolic links:\n\n    ``` \n    $ docker service create \\\n         --name nginx \\\n         --secret site.key \\\n         --secret site.crt \\\n         --secret source=site.conf,target=/etc/nginx/conf.d/site.conf \\\n         --publish published=3000,target=443 \\\n         nginx:latest \\\n         sh -c \"exec nginx -g 'daemon off;'\"\n    ```\n\n    The `site.key` and `site.crt` secrets use the short-hand syntax, without a custom `target` location set. The short syntax mounts the secrets in \\`/run/secrets/ with the same name as the secret. Within the running containers, the following three files now exist:\n\n    - `/run/secrets/site.key`\n    - `/run/secrets/site.crt`\n    - `/etc/nginx/conf.d/site.conf`\n\n4.  Verify that the Nginx service is running.\n\n    ``` \n    $ docker service ls\n\n    ID            NAME   MODE        REPLICAS  IMAGE\n    zeskcec62q24  nginx  replicated  1/1       nginx:latest\n\n    $ docker service ps nginx\n\n    NAME                  IMAGE         NODE  DESIRED STATE  CURRENT STATE          ERROR  PORTS\n    nginx.1.9ls3yo9ugcls  nginx:latest  moby  Running        Running 3 minutes ago\n    ```\n\n5.  Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\n\n    ``` \n    $ curl --cacert root-ca.crt https://localhost:3000\n\n    <!DOCTYPE html>\n    <html>\n    <head>\n    <title>Welcome to nginx!</title>\n    <style>\n        body {\n            width: 35em;\n            margin: 0 auto;\n            font-family: Tahoma, Verdana, Arial, sans-serif;\n        }\n    </style>\n    </head>\n    <body>\n    <h1>Welcome to nginx!</h1>\n    <p>If you see this page, the nginx web server is successfully installed and\n    working. Further configuration is required.</p>\n\n    <p>For online documentation and support. refer to\n    <a href=\"https://nginx.org\">nginx.org</a>.<br/>\n    Commercial support is available at\n    <a href=\"https://www.nginx.com\">nginx.com</a>.</p>\n\n    <p><em>Thank you for using nginx.</em></p>\n    </body>\n    </html>\n    ```\n\n    ``` \n    $ openssl s_client -connect localhost:3000 -CAfile root-ca.crt\n\n    CONNECTED(00000003)\n    depth=1 /C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\n    verify return:1\n    depth=0 /C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\n    verify return:1\n    ---\n    Certificate chain\n     0 s:/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\n       i:/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\n    ---\n    Server certificate\n    -----BEGIN CERTIFICATE-----\n    …\n    -----END CERTIFICATE-----\n    subject=/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\n    issuer=/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\n    ---\n    No client certificate CA names sent\n    ---\n    SSL handshake has read 1663 bytes and written 712 bytes\n    ---\n    New, TLSv1/SSLv3, Cipher is AES256-SHA\n    Server public key is 4096 bit\n    Secure Renegotiation IS supported\n    Compression: NONE\n    Expansion: NONE\n    SSL-Session:\n        Protocol  : TLSv1\n        Cipher    : AES256-SHA\n        Session-ID: A1A8BF35549C5715648A12FD7B7E3D861539316B03440187D9DA6C2E48822853\n        Session-ID-ctx:\n        Master-Key: F39D1B12274BA16D3A906F390A61438221E381952E9E1E05D3DD784F0135FB81353DA38C6D5C021CB926E844DFC49FC4\n        Key-Arg   : None\n        Start Time: 1481685096\n        Timeout   : 300 (sec)\n        Verify return code: 0 (ok)\n    ```\n\n6.  To clean up after running this example, remove the `nginx` service and the stored secrets.\n\n    ``` \n    $ docker service rm nginx\n\n    $ docker secret rm site.crt site.key site.conf\n    ```\n\n### Advanced example: Use secrets with a WordPress service\n\nIn this example, you create a single-node MySQL service with a custom root password, add the credentials as secrets, and create a single-node WordPress service which uses these credentials to connect to MySQL. The [next example](#example-rotate-a-secret) builds on this one and shows you how to rotate the MySQL password and update the services so that the WordPress service can still connect to MySQL.\n\nThis example illustrates some techniques to use Docker secrets to avoid saving sensitive credentials within your image or passing them directly on the command line.\n\n> **Note**: This example uses a single-Engine swarm for simplicity, and uses a single-node MySQL service because a single MySQL server instance cannot be scaled by simply using a replicated service, and setting up a MySQL cluster is beyond the scope of this example.\n>\n> Also, changing a MySQL root passphrase isn’t as simple as changing a file on disk. You must use a query or a `mysqladmin` command to change the password in MySQL.\n\n1.  Generate a random alphanumeric password for MySQL and store it as a Docker secret with the name `mysql_password` using the `docker secret create` command. To make the password shorter or longer, adjust the last argument of the `openssl` command. This is just one way to create a relatively random password. You can use another command to generate the password if you choose.\n\n    > **Note**: After you create a secret, you cannot update it. You can only remove and re-create it, and you cannot remove a secret that a service is using. However, you can grant or revoke a running service’s access to secrets using `docker service update`. If you need the ability to update a secret, consider adding a version component to the secret name, so that you can later add a new version, update the service to use it, then remove the old version.\n\n    The last argument is set to `-`, which indicates that the input is read from standard input.\n\n    ``` \n    $ openssl rand -base64 20 | docker secret create mysql_password -\n\n    l1vinzevzhj4goakjap5ya409\n    ```\n\n    The value returned is not the password, but the ID of the secret. In the remainder of this tutorial, the ID output is omitted.\n\n    Generate a second secret for the MySQL `root` user. This secret isn’t shared with the WordPress service created later. It’s only needed to bootstrap the `mysql` service.\n\n    ``` \n    $ openssl rand -base64 20 | docker secret create mysql_root_password -\n    ```\n\n    List the secrets managed by Docker using `docker secret ls`:\n\n    ``` \n    $ docker secret ls\n\n    ID                          NAME                  CREATED             UPDATED\n    l1vinzevzhj4goakjap5ya409   mysql_password        41 seconds ago      41 seconds ago\n    yvsczlx9votfw3l0nz5rlidig   mysql_root_password   12 seconds ago      12 seconds ago\n    ```\n\n    The secrets are stored in the encrypted Raft logs for the swarm.\n\n2.  Create a user-defined overlay network which is used for communication between the MySQL and WordPress services. There is no need to expose the MySQL service to any external host or container.\n\n    ``` \n    $ docker network create -d overlay mysql_private\n    ```\n\n3.  Create the MySQL service. The MySQL service has the following characteristics:\n\n    - Because the scale is set to `1`, only a single MySQL task runs. Load-balancing MySQL is left as an exercise to the reader and involves more than just scaling the service.\n\n    - Only reachable by other containers on the `mysql_private` network.\n\n    - Uses the volume `mydata` to store the MySQL data, so that it persists across restarts to the `mysql` service.\n\n    - The secrets are each mounted in a `tmpfs` filesystem at `/run/secrets/mysql_password` and `/run/secrets/mysql_root_password`. They are never exposed as environment variables, nor can they be committed to an image if the `docker commit` command is run. The `mysql_password` secret is the one used by the non-privileged WordPress container to connect to MySQL.\n\n    - Sets the environment variables `MYSQL_PASSWORD_FILE` and `MYSQL_ROOT_PASSWORD_FILE` to point to the files `/run/secrets/mysql_password` and `/run/secrets/mysql_root_password`. The `mysql` image reads the password strings from those files when initializing the system database for the first time. Afterward, the passwords are stored in the MySQL system database itself.\n\n    - Sets environment variables `MYSQL_USER` and `MYSQL_DATABASE`. A new database called `wordpress` is created when the container starts, and the `wordpress` user has full permissions for this database only. This user cannot create or drop databases or change the MySQL configuration.\n\n      ``` \n      $ docker service create \\\n           --name mysql \\\n           --replicas 1 \\\n           --network mysql_private \\\n           --mount type=volume,source=mydata,destination=/var/lib/mysql \\\n           --secret source=mysql_root_password,target=mysql_root_password \\\n           --secret source=mysql_password,target=mysql_password \\\n           -e MYSQL_ROOT_PASSWORD_FILE=\"/run/secrets/mysql_root_password\" \\\n           -e MYSQL_PASSWORD_FILE=\"/run/secrets/mysql_password\" \\\n           -e MYSQL_USER=\"wordpress\" \\\n           -e MYSQL_DATABASE=\"wordpress\" \\\n           mysql:latest\n      ```\n\n4.  Verify that the `mysql` container is running using the `docker service ls` command.\n\n    ``` \n    $ docker service ls\n\n    ID            NAME   MODE        REPLICAS  IMAGE\n    wvnh0siktqr3  mysql  replicated  1/1       mysql:latest\n    ```\n\n    At this point, you could actually revoke the `mysql` service’s access to the `mysql_password` and `mysql_root_password` secrets because the passwords have been saved in the MySQL system database. Don’t do that for now, because we use them later to facilitate rotating the MySQL password.\n\n5.  Now that MySQL is set up, create a WordPress service that connects to the MySQL service. The WordPress service has the following characteristics:\n\n    - Because the scale is set to `1`, only a single WordPress task runs. Load-balancing WordPress is left as an exercise to the reader, because of limitations with storing WordPress session data on the container filesystem.\n    - Exposes WordPress on port 30000 of the host machine, so that you can access it from external hosts. You can expose port 80 instead if you do not have a web server running on port 80 of the host machine.\n    - Connects to the `mysql_private` network so it can communicate with the `mysql` container, and also publishes port 80 to port 30000 on all swarm nodes.\n    - Has access to the `mysql_password` secret, but specifies a different target file name within the container. The WordPress container uses the mount point `/run/secrets/wp_db_password`. Also specifies that the secret is not group-or-world-readable, by setting the mode to `0400`.\n    - Sets the environment variable `WORDPRESS_DB_PASSWORD_FILE` to the file path where the secret is mounted. The WordPress service reads the MySQL password string from that file and add it to the `wp-config.php` configuration file.\n    - Connects to the MySQL container using the username `wordpress` and the password in `/run/secrets/wp_db_password` and creates the `wordpress` database if it does not yet exist.\n    - Stores its data, such as themes and plugins, in a volume called `wpdata` so these files persist when the service restarts.\n\n    ``` \n    $ docker service create \\\n         --name wordpress \\\n         --replicas 1 \\\n         --network mysql_private \\\n         --publish published=30000,target=80 \\\n         --mount type=volume,source=wpdata,destination=/var/www/html \\\n         --secret source=mysql_password,target=wp_db_password,mode=0400 \\\n         -e WORDPRESS_DB_USER=\"wordpress\" \\\n         -e WORDPRESS_DB_PASSWORD_FILE=\"/run/secrets/wp_db_password\" \\\n         -e WORDPRESS_DB_HOST=\"mysql:3306\" \\\n         -e WORDPRESS_DB_NAME=\"wordpress\" \\\n         wordpress:latest\n    ```\n\n6.  Verify the service is running using `docker service ls` and `docker service ps` commands.\n\n    ``` \n    $ docker service ls\n\n    ID            NAME       MODE        REPLICAS  IMAGE\n    wvnh0siktqr3  mysql      replicated  1/1       mysql:latest\n    nzt5xzae4n62  wordpress  replicated  1/1       wordpress:latest\n    ```\n\n    ``` \n    $ docker service ps wordpress\n\n    ID            NAME         IMAGE             NODE  DESIRED STATE  CURRENT STATE           ERROR  PORTS\n    aukx6hgs9gwc  wordpress.1  wordpress:latest  moby  Running        Running 52 seconds ago   \n    ```\n\n    At this point, you could actually revoke the WordPress service’s access to the `mysql_password` secret, because WordPress has copied the secret to its configuration file `wp-config.php`. Don’t do that for now, because we use it later to facilitate rotating the MySQL password.\n\n7.  Access `http://localhost:30000/` from any swarm node and set up WordPress using the web-based wizard. All of these settings are stored in the MySQL `wordpress` database. WordPress automatically generates a password for your WordPress user, which is completely different from the password WordPress uses to access MySQL. Store this password securely, such as in a password manager. You need it to log into WordPress after [rotating the secret](#example-rotate-a-secret).\n\n    Go ahead and write a blog post or two and install a WordPress plugin or theme to verify that WordPress is fully operational and its state is saved across service restarts.\n\n8.  Do not clean up any services or secrets if you intend to proceed to the next example, which demonstrates how to rotate the MySQL root password.\n\n### Example: Rotate a secret\n\nThis example builds upon the previous one. In this scenario, you create a new secret with a new MySQL password, update the `mysql` and `wordpress` services to use it, then remove the old secret.\n\n> **Note**: Changing the password on a MySQL database involves running extra queries or commands, as opposed to just changing a single environment variable or a file, since the image only sets the MySQL password if the database doesn’t already exist, and MySQL stores the password within a MySQL database by default. Rotating passwords or other secrets may involve additional steps outside of Docker.\n\n1.  Create the new password and store it as a secret named `mysql_password_v2`.\n\n    ``` \n    $ openssl rand -base64 20 | docker secret create mysql_password_v2 -\n    ```\n\n2.  Update the MySQL service to give it access to both the old and new secrets. Remember that you cannot update or rename a secret, but you can revoke a secret and grant access to it using a new target filename.\n\n    ``` \n    $ docker service update \\\n         --secret-rm mysql_password mysql\n\n    $ docker service update \\\n         --secret-add source=mysql_password,target=old_mysql_password \\\n         --secret-add source=mysql_password_v2,target=mysql_password \\\n         mysql\n    ```\n\n    Updating a service causes it to restart, and when the MySQL service restarts the second time, it has access to the old secret under `/run/secrets/old_mysql_password` and the new secret under `/run/secrets/mysql_password`.\n\n    Even though the MySQL service has access to both the old and new secrets now, the MySQL password for the WordPress user has not yet been changed.\n\n    > **Note**: This example does not rotate the MySQL `root` password.\n\n3.  Now, change the MySQL password for the `wordpress` user using the `mysqladmin` CLI. This command reads the old and new password from the files in `/run/secrets` but does not expose them on the command line or save them in the shell history.\n\n    Do this quickly and move on to the next step, because WordPress loses the ability to connect to MySQL.\n\n    First, find the ID of the `mysql` container task.\n\n    ``` \n    $ docker ps --filter name=mysql -q\n\n    c7705cf6176f\n    ```\n\n    Substitute the ID in the command below, or use the second variant which uses shell expansion to do it all in a single step.\n\n    ``` \n    $ docker container exec <CONTAINER_ID> \\\n        bash -c 'mysqladmin --user=wordpress --password=\"$(< /run/secrets/old_mysql_password)\" password \"$(< /run/secrets/mysql_password)\"'\n    ```\n\n    **or**:\n\n    ``` \n    $ docker container exec $(docker ps --filter name=mysql -q) \\\n        bash -c 'mysqladmin --user=wordpress --password=\"$(< /run/secrets/old_mysql_password)\" password \"$(< /run/secrets/mysql_password)\"'\n    ```\n\n4.  Update the `wordpress` service to use the new password, keeping the target path at `/run/secrets/wp_db_password` and keeping the file permissions at `0400`. This triggers a rolling restart of the WordPress service and the new secret is used.\n\n    ``` \n    $ docker service update \\\n         --secret-rm mysql_password \\\n         --secret-add source=mysql_password_v2,target=wp_db_password,mode=0400 \\\n         wordpress    \n    ```\n\n5.  Verify that WordPress works by browsing to http://localhost:30000/ on any swarm node again. Use the WordPress username and password from when you ran through the WordPress wizard in the previous task.\n\n    Verify that the blog post you wrote still exists, and if you changed any configuration values, verify that they are still changed.\n\n6.  Revoke access to the old secret from the MySQL service and remove the old secret from Docker.\n\n    ``` \n    $ docker service update \\\n         --secret-rm mysql_password \\\n         mysql\n\n    $ docker secret rm mysql_password\n    ```\n\n7.  If you want to try the running all of these examples again or just want to clean up after running through them, use these commands to remove the WordPress service, the MySQL container, the `mydata` and `wpdata` volumes, and the Docker secrets.\n\n    ``` \n    $ docker service rm wordpress mysql\n\n    $ docker volume rm mydata wpdata\n\n    $ docker secret rm mysql_password_v2 mysql_root_password\n    ```\n\n## Build support for Docker Secrets into your images\n\nIf you develop a container that can be deployed as a service and requires sensitive data, such as a credential, as an environment variable, consider adapting your image to take advantage of Docker secrets. One way to do this is to ensure that each parameter you pass to the image when creating the container can also be read from a file.\n\nMany of the Docker Official Images in the [Docker library](https://github.com/docker-library/), such as the [wordpress](https://github.com/docker-library/wordpress/) image used in the above examples, have been updated in this way.\n\nWhen you start a WordPress container, you provide it with the parameters it needs by setting them as environment variables. The WordPress image has been updated so that the environment variables which contain important data for WordPress, such as `WORDPRESS_DB_PASSWORD`, also have variants which can read their values from a file (`WORDPRESS_DB_PASSWORD_FILE`). This strategy ensures that backward compatibility is preserved, while allowing your container to read the information from a Docker-managed secret instead of being passed directly.\n\n> **Note**\n>\n> Docker secrets do not set environment variables directly. This was a conscious decision, because environment variables can unintentionally be leaked between containers (for instance, if you use `--link`).\n\n## Use Secrets in Compose\n\n``` \nversion: \"3.9\"\n\nservices:\n   db:\n     image: mysql:latest\n     volumes:\n       - db_data:/var/lib/mysql\n     environment:\n       MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password\n       MYSQL_DATABASE: wordpress\n       MYSQL_USER: wordpress\n       MYSQL_PASSWORD_FILE: /run/secrets/db_password\n     secrets:\n       - db_root_password\n       - db_password\n\n   wordpress:\n     depends_on:\n       - db\n     image: wordpress:latest\n     ports:\n       - \"8000:80\"\n     environment:\n       WORDPRESS_DB_HOST: db:3306\n       WORDPRESS_DB_USER: wordpress\n       WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password\n     secrets:\n       - db_password\n\n\nsecrets:\n   db_password:\n     file: db_password.txt\n   db_root_password:\n     file: db_root_password.txt\n\nvolumes:\n    db_data:\n```\n\nThis example creates a simple WordPress site using two secrets in a compose file.\n\nThe keyword `secrets:` defines two secrets `db_password:` and `db_root_password:`.\n\nWhen deploying, Docker creates these two secrets and populates them with the content from the file specified in the compose file.\n\nThe db service uses both secrets, and the wordpress is using one.\n\nWhen you deploy, Docker mounts a file under `/run/secrets/<secret_name>` in the services. These files are never persisted in disk, but are managed in memory.\n\nEach service uses environment variables to specify where the service should look for that secret data.\n\nMore information on short and long syntax for secrets can be found at [Compose file version 3 reference](../../../compose/compose-file/compose-file-v3/index#secrets).\n\n[swarm](https://docs.docker.com/search/?q=swarm), [secrets](https://docs.docker.com/search/?q=secrets), [credentials](https://docs.docker.com/search/?q=credentials), [sensitive strings](https://docs.docker.com/search/?q=sensitive%20strings), [sensitive data](https://docs.docker.com/search/?q=sensitive%20data), [security](https://docs.docker.com/search/?q=security), [encryption](https://docs.docker.com/search/?q=encryption), [encryption at rest](https://docs.docker.com/search/?q=encryption%20at%20rest)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/secrets/](https://docs.docker.com/engine/swarm/secrets/)"
- name: Manage swarm security with public key infrastructure (PKI)
  id: engine/swarm/how-swarm-mode-works/pki/index
  summary: The swarm mode public key infrastructure (PKI) system built into Docker makes it simple to securely deploy a container orchestration system
  description: "# Manage swarm security with public key infrastructure (PKI)\n\nThe swarm mode public key infrastructure (PKI) system built into Docker makes it simple to securely deploy a container orchestration system. The nodes in a swarm use mutual Transport Layer Security (TLS) to authenticate, authorize, and encrypt the communications with other nodes in the swarm.\n\nWhen you create a swarm by running `docker swarm init`, Docker designates itself as a manager node. By default, the manager node generates a new root Certificate Authority (CA) along with a key pair, which are used to secure communications with other nodes that join the swarm. If you prefer, you can specify your own externally-generated root CA, using the `--external-ca` flag of the [docker swarm init](../../../reference/commandline/swarm_init/index) command.\n\nThe manager node also generates two tokens to use when you join additional nodes to the swarm: one **worker token** and one **manager token**. Each token includes the digest of the root CA’s certificate and a randomly generated secret. When a node joins the swarm, the joining node uses the digest to validate the root CA certificate from the remote manager. The remote manager uses the secret to ensure the joining node is an approved node.\n\nEach time a new node joins the swarm, the manager issues a certificate to the node. The certificate contains a randomly generated node ID to identify the node under the certificate common name (CN) and the role under the organizational unit (OU). The node ID serves as the cryptographically secure node identity for the lifetime of the node in the current swarm.\n\nThe diagram below illustrates how manager nodes and worker nodes encrypt communications using a minimum of TLS 1.2.\n\nThe example below shows the information from a certificate from a worker node:\n\n``` \nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number:\n            3b:1c:06:91:73:fb:16:ff:69:c3:f7:a2:fe:96:c1:73:e2:80:97:3b\n        Signature Algorithm: ecdsa-with-SHA256\n        Issuer: CN=swarm-ca\n        Validity\n            Not Before: Aug 30 02:39:00 2016 GMT\n            Not After : Nov 28 03:39:00 2016 GMT\n        Subject: O=ec2adilxf4ngv7ev8fwsi61i7, OU=swarm-worker, CN=dw02poa4vqvzxi5c10gm4pq2g\n...snip...\n```\n\nBy default, each node in the swarm renews its certificate every three months. You can configure this interval by running the `docker swarm update --cert-expiry <TIME PERIOD>` command. The minimum rotation value is 1 hour. Refer to the [docker swarm update](../../../reference/commandline/swarm_update/index) CLI reference for details.\n\n## Rotating the CA certificate\n\nIn the event that a cluster CA key or a manager node is compromised, you can rotate the swarm root CA so that none of the nodes trust certificates signed by the old root CA anymore.\n\nRun `docker swarm ca --rotate` to generate a new CA certificate and key. If you prefer, you can pass the `--ca-cert` and `--external-ca` flags to specify the root certificate and to use a root CA external to the swarm. Alternately, you can pass the `--ca-cert` and `--ca-key` flags to specify the exact certificate and key you would like the swarm to use.\n\nWhen you issue the `docker swarm ca --rotate` command, the following things happen in sequence:\n\n1.  Docker generates a cross-signed certificate. This means that a version of the new root CA certificate is signed with the old root CA certificate. This cross-signed certificate is used as an intermediate certificate for all new node certificates. This ensures that nodes that still trust the old root CA can still validate a certificate signed by the new CA.\n\n2.  Docker also tells all nodes to immediately renew their TLS certificates. This process may take several minutes, depending on the number of nodes in the swarm.\n\n3.  After every node in the swarm has a new TLS certificate signed by the new CA, Docker forgets about the old CA certificate and key material, and tells all the nodes to trust the new CA certificate only.\n\n    This also causes a change in the swarm’s join tokens. The previous join tokens are no longer valid.\n\nFrom this point on, all new node certificates issued are signed with the new root CA, and do not contain any intermediates.\n\n## Learn More\n\n- Read about how [nodes](../nodes/index) work.\n- Learn how swarm mode [services](../services/index) work.\n\n[swarm](https://docs.docker.com/search/?q=swarm), [security](https://docs.docker.com/search/?q=security), [tls](https://docs.docker.com/search/?q=tls), [pki](https://docs.docker.com/search/?q=pki)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/](https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/)"
- name: Networking in Compose
  id: compose/networking/index
  summary: This page applies to Compose file formats version 2 and higher
  description: "# Networking in Compose\n\n> This page applies to Compose file formats [version 2](../compose-file/compose-file-v2/index) and [higher](../compose-file/index). Networking features are not supported for Compose file version 1 (deprecated).\n\nBy default Compose sets up a single [network](../../engine/reference/commandline/network_create/index) for your app. Each container for a service joins the default network and is both *reachable* by other containers on that network, and *discoverable* by them at a hostname identical to the container name.\n\n> **Note**\n>\n> Your app’s network is given a name based on the “project name”, which is based on the name of the directory it lives in. You can override the project name with either the [`--project-name` flag](../reference/index) or the [`COMPOSE_PROJECT_NAME` environment variable](../reference/envvars/index#compose_project_name).\n\nFor example, suppose your app is in a directory called `myapp`, and your `docker-compose.yml` looks like this:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:8000\"\n  db:\n    image: postgres\n    ports:\n      - \"8001:5432\"\n```\n\nWhen you run `docker-compose up`, the following happens:\n\n1.  A network called `myapp_default` is created.\n2.  A container is created using `web`’s configuration. It joins the network `myapp_default` under the name `web`.\n3.  A container is created using `db`’s configuration. It joins the network `myapp_default` under the name `db`.\n\n> **In v2.1+, overlay networks are always `attachable`**\n>\n> Starting in Compose file format 2.1, overlay networks are always created as `attachable`, and this is not configurable. This means that standalone containers can connect to overlay networks.\n>\n> In Compose file format 3.x, you can optionally set the `attachable` property to `false`.\n\nEach container can now look up the hostname `web` or `db` and get back the appropriate container’s IP address. For example, `web`’s application code could connect to the URL `postgres://db:5432` and start using the Postgres database.\n\nIt is important to note the distinction between `HOST_PORT` and `CONTAINER_PORT`. In the above example, for `db`, the `HOST_PORT` is `8001` and the container port is `5432` (postgres default). Networked service-to-service communication uses the `CONTAINER_PORT`. When `HOST_PORT` is defined, the service is accessible outside the swarm as well.\n\nWithin the `web` container, your connection string to `db` would look like `postgres://db:5432`, and from the host machine, the connection string would look like `postgres://{DOCKER_IP}:8001`.\n\n## Update containers\n\nIf you make a configuration change to a service and run `docker-compose up` to update it, the old container is removed and the new one joins the network under a different IP address but the same name. Running containers can look up that name and connect to the new address, but the old address stops working.\n\nIf any containers have connections open to the old container, they are closed. It is a container’s responsibility to detect this condition, look up the name again and reconnect.\n\n## Links\n\nLinks allow you to define extra aliases by which a service is reachable from another service. They are not required to enable services to communicate - by default, any service can reach any other service at that service’s name. In the following example, `db` is reachable from `web` at the hostnames `db` and `database`:\n\n``` \nversion: \"3.9\"\nservices:\n\n  web:\n    build: .\n    links:\n      - \"db:database\"\n  db:\n    image: postgres\n```\n\nSee the [links reference](../compose-file/compose-file-v2/index#links) for more information.\n\n## Multi-host networking\n\nWhen deploying a Compose application on a Docker Engine with [Swarm mode enabled](../../engine/swarm/index), you can make use of the built-in `overlay` driver to enable multi-host communication.\n\nConsult the [Swarm mode section](../../engine/swarm/index), to see how to set up a Swarm cluster, and the [Getting started with multi-host networking](https://docs.docker.com/network/network-tutorial-overlay/) to learn about multi-host overlay networks.\n\n## Specify custom networks\n\nInstead of just using the default app network, you can specify your own networks with the top-level `networks` key. This lets you create more complex topologies and specify [custom network drivers](../../engine/extend/plugins_network/index) and options. You can also use it to connect services to externally-created networks which aren’t managed by Compose.\n\nEach service can specify what networks to connect to with the *service-level* `networks` key, which is a list of names referencing entries under the *top-level* `networks` key.\n\nHere’s an example Compose file defining two custom networks. The `proxy` service is isolated from the `db` service, because they do not share a network in common - only `app` can talk to both.\n\n``` \nversion: \"3.9\"\n\nservices:\n  proxy:\n    build: ./proxy\n    networks:\n      - frontend\n  app:\n    build: ./app\n    networks:\n      - frontend\n      - backend\n  db:\n    image: postgres\n    networks:\n      - backend\n\nnetworks:\n  frontend:\n    # Use a custom driver\n    driver: custom-driver-1\n  backend:\n    # Use a custom driver which takes special options\n    driver: custom-driver-2\n    driver_opts:\n      foo: \"1\"\n      bar: \"2\"\n```\n\nNetworks can be configured with static IP addresses by setting the [ipv4_address and/or ipv6_address](../compose-file/compose-file-v2/index#ipv4_address-ipv6_address) for each attached network.\n\nNetworks can also be given a [custom name](../compose-file/compose-file-v3/index#network-configuration-reference) (since version 3.5):\n\n``` \nversion: \"3.9\"\nservices:\n  # ...\nnetworks:\n  frontend:\n    name: custom_frontend\n    driver: custom-driver-1\n```\n\nFor full details of the network configuration options available, see the following references:\n\n- [Top-level `networks` key](../compose-file/compose-file-v2/index#network-configuration-reference)\n- [Service-level `networks` key](../compose-file/compose-file-v2/index#networks)\n\n## Configure the default network\n\nInstead of (or as well as) specifying your own networks, you can also change the settings of the app-wide default network by defining an entry under `networks` named `default`:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:8000\"\n  db:\n    image: postgres\n\nnetworks:\n  default:\n    # Use a custom driver\n    driver: custom-driver-1\n```\n\n## Use a pre-existing network\n\nIf you want your containers to join a pre-existing network, use the [`external` option](../compose-file/compose-file-v2/index#network-configuration-reference):\n\n``` \nservices:\n  # ...\nnetworks:\n  default:\n    name: my-pre-existing-network\n    external: true\n```\n\nInstead of attempting to create a network called `[projectname]_default`, Compose looks for a network called `my-pre-existing-network` and connect your app’s containers to it.\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [orchestration](https://docs.docker.com/search/?q=orchestration), [containers](https://docs.docker.com/search/?q=containers), [networking](https://docs.docker.com/search/?q=networking)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/networking/](https://docs.docker.com/compose/networking/)"
- name: Orchestration
  id: get-started/orchestration/index
  summary: The portability and reproducibility of a containerized process provides an opportunity to move and scale our containerized applications across clouds and datacenters
  description: "# Orchestration\n\nThe portability and reproducibility of a containerized process provides an opportunity to move and scale our containerized applications across clouds and datacenters. Containers effectively guarantee that those applications run the same way anywhere, allowing us to quickly and easily take advantage of all these environments. Additionally, as we scale our applications up, we need some tooling to help automate the maintenance of those applications, enable the replacement of failed containers automatically, and manage the rollout of updates and reconfigurations of those containers during their lifecycle.\n\nTools to manage, scale, and maintain containerized applications are called *orchestrators*, and the most common examples of these are *Kubernetes* and *Docker Swarm*. Development environment deployments of both of these orchestrators are provided by Docker Desktop, which we’ll use throughout this guide to create our first orchestrated, containerized application.\n\nThe advanced modules teach you how to:\n\n1.  [Set up and use a Kubernetes environment on your development machine](../kube-deploy/index)\n2.  [Set up and use a Swarm environment on your development machine](../swarm-deploy/index)\n\n## Enable Kubernetes\n\nDocker Desktop will set up Kubernetes for you quickly and easily. Follow the setup and validation instructions appropriate for your operating system:\n\n- [Mac](#kubeosx)\n- [Windows](#kubewin)\n\n### Mac\n\n1.  After installing Docker Desktop, you should see a Docker icon in your menu bar. Click on it, and navigate to **Preferences** \\> **Kubernetes**.\n\n2.  Check the checkbox labeled **Enable Kubernetes**, and click **Apply & Restart**. Docker Desktop will automatically set up Kubernetes for you. You’ll know that Kubernetes has been successfully enabled when you see a green light beside ‘Kubernetes *running*’ in the Preferences menu.\n\n3.  In order to confirm that Kubernetes is up and running, create a text file called `pod.yaml` with the following content:\n\n    ``` \n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: demo\n    spec:\n      containers:\n      - name: testpod\n        image: alpine:latest\n        command: [\"ping\", \"8.8.8.8\"]\n    ```\n\n    This describes a pod with a single container, isolating a simple ping to 8.8.8.8.\n\n4.  In a terminal, navigate to where you created `pod.yaml` and create your pod:\n\n    ``` \n    $ kubectl apply -f pod.yaml\n    ```\n\n5.  Check that your pod is up and running:\n\n    ``` \n    $ kubectl get pods\n    ```\n\n    You should see something like:\n\n    ``` \n    NAME      READY     STATUS    RESTARTS   AGE\n    demo      1/1       Running   0          4s\n    ```\n\n6.  Check that you get the logs you’d expect for a ping process:\n\n    ``` \n    $ kubectl logs demo\n    ```\n\n    You should see the output of a healthy ping process:\n\n    ``` \n    PING 8.8.8.8 (8.8.8.8): 56 data bytes\n    64 bytes from 8.8.8.8: seq=0 ttl=37 time=21.393 ms\n    64 bytes from 8.8.8.8: seq=1 ttl=37 time=15.320 ms\n    64 bytes from 8.8.8.8: seq=2 ttl=37 time=11.111 ms\n    ...\n    ```\n\n7.  Finally, tear down your test pod:\n\n    ``` \n    $ kubectl delete -f pod.yaml\n    ```\n\n### Windows\n\n1.  After installing Docker Desktop, you should see a Docker icon in your system tray. Right-click on it, and navigate **Settings** \\> **Kubernetes**.\n\n2.  Check the checkbox labeled **Enable Kubernetes**, and click **Apply & Restart**. Docker Desktop will automatically set up Kubernetes for you. You’ll know that Kubernetes has been successfully enabled when you see a green light beside ‘Kubernetes *running*’ in the **Settings** menu.\n\n3.  In order to confirm that Kubernetes is up and running, create a text file called `pod.yaml` with the following content:\n\n    ``` \n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: demo\n    spec:\n      containers:\n      - name: testpod\n        image: alpine:latest\n        command: [\"ping\", \"8.8.8.8\"]\n    ```\n\n    This describes a pod with a single container, isolating a simple ping to 8.8.8.8.\n\n4.  In PowerShell, navigate to where you created `pod.yaml` and create your pod:\n\n    ``` \n    $ kubectl apply -f pod.yaml\n    ```\n\n5.  Check that your pod is up and running:\n\n    ``` \n    $ kubectl get pods\n    ```\n\n    You should see something like:\n\n    ``` \n    NAME      READY     STATUS    RESTARTS   AGE\n    demo      1/1       Running   0          4s\n    ```\n\n6.  Check that you get the logs you’d expect for a ping process:\n\n    ``` \n    $ kubectl logs demo\n    ```\n\n    You should see the output of a healthy ping process:\n\n    ``` \n    PING 8.8.8.8 (8.8.8.8): 56 data bytes\n    64 bytes from 8.8.8.8: seq=0 ttl=37 time=21.393 ms\n    64 bytes from 8.8.8.8: seq=1 ttl=37 time=15.320 ms\n    64 bytes from 8.8.8.8: seq=2 ttl=37 time=11.111 ms\n    ...\n    ```\n\n7.  Finally, tear down your test pod:\n\n    ``` \n    $ kubectl delete -f pod.yaml\n    ```\n\n## Enable Docker Swarm\n\nDocker Desktop runs primarily on Docker Engine, which has everything you need to run a Swarm built in. Follow the setup and validation instructions appropriate for your operating system:\n\n- [Mac](#swarmosx)\n- [Windows](#swarmwin)\n\n### Mac\n\n1.  Open a terminal, and initialize Docker Swarm mode:\n\n    ``` \n    $ docker swarm init\n    ```\n\n    If all goes well, you should see a message similar to the following:\n\n    ``` \n    Swarm initialized: current node (tjjggogqpnpj2phbfbz8jd5oq) is now a manager.\n\n    To add a worker to this swarm, run the following command:\n\n        docker swarm join --token SWMTKN-1-3e0hh0jd5t4yjg209f4g5qpowbsczfahv2dea9a1ay2l8787cf-2h4ly330d0j917ocvzw30j5x9 192.168.65.3:2377\n\n    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n    ```\n\n2.  Run a simple Docker service that uses an alpine-based filesystem, and isolates a ping to 8.8.8.8:\n\n    ``` \n    $ docker service create --name demo alpine:latest ping 8.8.8.8\n    ```\n\n3.  Check that your service created one running container:\n\n    ``` \n    $ docker service ps demo\n    ```\n\n    You should see something like:\n\n    ``` \n    ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS\n    463j2s3y4b5o        demo.1              alpine:latest       docker-desktop      Running             Running 8 seconds ago\n    ```\n\n4.  Check that you get the logs you’d expect for a ping process:\n\n    ``` \n    $ docker service logs demo\n    ```\n\n    You should see the output of a healthy ping process:\n\n    ``` \n    demo.1.463j2s3y4b5o@docker-desktop    | PING 8.8.8.8 (8.8.8.8): 56 data bytes\n    demo.1.463j2s3y4b5o@docker-desktop    | 64 bytes from 8.8.8.8: seq=0 ttl=37 time=13.005 ms\n    demo.1.463j2s3y4b5o@docker-desktop    | 64 bytes from 8.8.8.8: seq=1 ttl=37 time=13.847 ms\n    demo.1.463j2s3y4b5o@docker-desktop    | 64 bytes from 8.8.8.8: seq=2 ttl=37 time=41.296 ms\n    ...\n    ```\n\n5.  Finally, tear down your test service:\n\n    ``` \n    $ docker service rm demo\n    ```\n\n### Windows\n\n1.  Open a powershell, and initialize Docker Swarm mode:\n\n    ``` \n    $ docker swarm init\n    ```\n\n    If all goes well, you should see a message similar to the following:\n\n    ``` \n    Swarm initialized: current node (tjjggogqpnpj2phbfbz8jd5oq) is now a manager.\n\n    To add a worker to this swarm, run the following command:\n\n        docker swarm join --token SWMTKN-1-3e0hh0jd5t4yjg209f4g5qpowbsczfahv2dea9a1ay2l8787cf-2h4ly330d0j917ocvzw30j5x9 192.168.65.3:2377\n\n    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n    ```\n\n2.  Run a simple Docker service that uses an alpine-based filesystem, and isolates a ping to 8.8.8.8:\n\n    ``` \n    $ docker service create --name demo alpine:latest ping 8.8.8.8\n    ```\n\n3.  Check that your service created one running container:\n\n    ``` \n    $ docker service ps demo\n    ```\n\n    You should see something like:\n\n    ``` \n    ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS\n    463j2s3y4b5o        demo.1              alpine:latest       docker-desktop      Running             Running 8 seconds ago\n    ```\n\n4.  Check that you get the logs you’d expect for a ping process:\n\n    ``` \n    $ docker service logs demo\n    ```\n\n    You should see the output of a healthy ping process:\n\n    ``` \n    demo.1.463j2s3y4b5o@docker-desktop    | PING 8.8.8.8 (8.8.8.8): 56 data bytes\n    demo.1.463j2s3y4b5o@docker-desktop    | 64 bytes from 8.8.8.8: seq=0 ttl=37 time=13.005 ms\n    demo.1.463j2s3y4b5o@docker-desktop    | 64 bytes from 8.8.8.8: seq=1 ttl=37 time=13.847 ms\n    demo.1.463j2s3y4b5o@docker-desktop    | 64 bytes from 8.8.8.8: seq=2 ttl=37 time=41.296 ms\n    ...\n    ```\n\n5.  Finally, tear down your test service:\n\n    ``` \n    $ docker service rm demo\n    ```\n\n## Conclusion\n\nAt this point, you’ve confirmed that you can run simple containerized workloads in Kubernetes and Swarm. The next step will be to write the Kubernetes yaml that describes how to run and manage these containers on Kubernetes.\n\n[On to deploying to Kubernetes \\>\\>](../kube-deploy/index)\n\nTo learn how to write the stack file to help you run and manage containers on Swarm, see [Deploying to Swarm](../swarm-deploy/index).\n\n## CLI references\n\nFurther documentation for all CLI commands used in this article are available here:\n\n- [`kubectl apply`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#apply)\n- [`kubectl get`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#get)\n- [`kubectl logs`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs)\n- [`kubectl delete`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete)\n- [`docker swarm init`](../../engine/reference/commandline/swarm_init/index)\n- [`docker service *`](../../engine/reference/commandline/service/index)\n\n[orchestration](https://docs.docker.com/search/?q=orchestration), [deploy](https://docs.docker.com/search/?q=deploy), [kubernetes](https://docs.docker.com/search/?q=kubernetes), [swarm](https://docs.docker.com/search/?q=swarm)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/orchestration/](https://docs.docker.com/get-started/orchestration/)"
- name: Orientation and setup
  id: get-started/index
  summary: Commercial use of Docker Desktop in larger enterprises (more than 250 employees OR more than $10 million USD in annual revenue) now requires a paid subscription
  description: "# Orientation and setup\n\n> **Update to the Docker Desktop terms**\n>\n> Commercial use of Docker Desktop in larger enterprises (more than 250 employees OR more than $10 million USD in annual revenue) now requires a paid subscription.\n\nWelcome! We are excited that you want to learn Docker.\n\nThis page contains step-by-step instructions on how to get started with Docker. In this tutorial, you’ll learn how to:\n\n- Build and run an image as a container\n- Share images using Docker Hub\n- Deploy Docker applications using multiple containers with a database\n- Running applications using Docker Compose\n\nIn addition, you’ll also learn about the best practices for building images, including instructions on how to scan your images for security vulnerabilities.\n\nIf you are looking for information on how to containerize an application using your favorite language, see [Language-specific getting started guides](https://docs.docker.com/language/).\n\nWe also recommend the video walkthrough from DockerCon 2020.\n\n## Download and install Docker\n\nThis tutorial assumes you have a current version of Docker installed on your machine. If you do not have Docker installed, choose your preferred operating system below to download Docker:\n\n[Mac with Intel chip](https://desktop.docker.com/mac/main/amd64/Docker.dmg?utm_source=docker&utm_medium=webreferral&utm_campaign=docs-driven-download-mac-amd64) [Mac with Apple chip](https://desktop.docker.com/mac/main/arm64/Docker.dmg?utm_source=docker&utm_medium=webreferral&utm_campaign=docs-driven-download-mac-arm64) [Windows](https://desktop.docker.com/win/main/amd64/Docker%20Desktop%20Installer.exe?utm_source=docker&utm_medium=webreferral&utm_campaign=docs-driven-download-win-amd64) [Linux](https://docs.docker.com/desktop/linux/install/)\n\nFor Docker Desktop installation instructions, see:\n\n- [Install Docker Desktop on Mac](https://docs.docker.com/desktop/mac/install/)\n- [Install Docker Desktop on Windows](https://docs.docker.com/desktop/windows/install/)\n- [Install Docker Desktop on Linux](https://docs.docker.com/desktop/linux/install/)\n\n## Start the tutorial\n\nIf you’ve already run the command to get started with the tutorial, congratulations! If not, open a command prompt or bash window, and run the command:\n\n``` \n$ docker run -d -p 80:80 docker/getting-started\n```\n\nYou’ll notice a few flags being used. Here’s some more info on them:\n\n- `-d` - run the container in detached mode (in the background)\n- `-p 80:80` - map port 80 of the host to port 80 in the container\n- `docker/getting-started` - the image to use\n\n> **Tip**\n>\n> You can combine single character flags to shorten the full command. As an example, the command above could be written as:\n>\n> ``` \n> $ docker run -dp 80:80 docker/getting-started\n> ```\n\n## The Docker Dashboard\n\nBefore going too far, we want to highlight the Docker Dashboard, which gives you a quick view of the containers running on your machine. The Docker Dashboard is available for Mac and Windows. It gives you quick access to container logs, lets you get a shell inside the container, and lets you easily manage container lifecycle (stop, remove, etc.).\n\nTo access the dashboard, follow the instructions in the [Docker Desktop manual](https://docs.docker.com/desktop/dashboard/). If you open the dashboard now, you will see this tutorial running! The container name (`jolly_bouman` below) is a randomly created name. So, you’ll most likely have a different name.\n\n## What is a container?\n\nNow that you’ve run a container, what *is* a container? Simply put, a container is a sandboxed process on your machine that is isolated from all other processes on the host machine. That isolation leverages [kernel namespaces and cgroups](https://medium.com/@saschagrunert/demystifying-containers-part-i-kernel-space-2c53d6979504), features that have been in Linux for a long time. Docker has worked to make these capabilities approachable and easy to use. To summarize, a container:\n\n- is a runnable instance of an image. You can create, start, stop, move, or delete a container using the DockerAPI or CLI.\n- can be run on local machines, virtual machines or deployed to the cloud.\n- is portable (can be run on any OS)\n- Containers are isolated from each other and run their own software, binaries, and configurations.\n\n> **Creating containers from scratch**\n>\n> If you’d like to see how containers are built from scratch, Liz Rice from Aqua Security has a fantastic talk in which she creates a container from scratch in Go. While the talk does not go into networking, using images for the filesystem, and other advanced topics, it gives a *fantastic* deep dive into how things are working.\n\n## What is a container image?\n\nWhen running a container, it uses an isolated filesystem. This custom filesystem is provided by a **container image**. Since the image contains the container’s filesystem, it must contain everything needed to run an application - all dependencies, configuration, scripts, binaries, etc. The image also contains other configuration for the container, such as environment variables, a default command to run, and other metadata.\n\nWe’ll dive deeper into images later on, covering topics such as layering, best practices, and more.\n\n> **Info**\n>\n> If you’re familiar with `chroot`, think of a container as an extended version of `chroot`. The filesystem is simply coming from the image. But, a container adds additional isolation not available when simply using chroot.\n\n## CLI references\n\nRefer to the following topics for further documentation on all CLI commands used in this article:\n\n- [docker version](../engine/reference/commandline/version/index)\n- [docker run](../engine/reference/commandline/run/index)\n- [docker image](../engine/reference/commandline/image/index)\n- [docker container](../engine/reference/commandline/container/index)\n\n[get started](https://docs.docker.com/search/?q=get%20started), [setup](https://docs.docker.com/search/?q=setup), [orientation](https://docs.docker.com/search/?q=orientation), [quickstart](https://docs.docker.com/search/?q=quickstart), [intro](https://docs.docker.com/search/?q=intro), [concepts](https://docs.docker.com/search/?q=concepts), [containers](https://docs.docker.com/search/?q=containers), [docker desktop](https://docs.docker.com/search/?q=docker%20desktop)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/](https://docs.docker.com/get-started/)"
- name: Overview of docker-compose CLI
  id: compose/reference/index
  summary: This page provides the usage information for the docker-compose Command
  description: "# Overview of docker-compose CLI\n\nThis page provides the usage information for the `docker-compose` Command.\n\n## Command options overview and help\n\nYou can also see this information by running `docker-compose --help` from the command line.\n\n``` \nDefine and run multi-container applications with Docker.\n\nUsage:\n  docker-compose [-f <arg>...] [--profile <name>...] [options] [COMMAND] [ARGS...]\n  docker-compose -h|--help\n\nOptions:\n  -f, --file FILE             Specify an alternate compose file\n                              (default: docker-compose.yml)\n  -p, --project-name NAME     Specify an alternate project name\n                              (default: directory name)\n  --profile NAME              Specify a profile to enable\n  --verbose                   Show more output\n  --log-level LEVEL           DEPRECATED and not working from 2.0 - Set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n  --no-ansi                   Do not print ANSI control characters\n  -v, --version               Print version and exit\n  -H, --host HOST             Daemon socket to connect to\n\n  --tls                       Use TLS; implied by --tlsverify\n  --tlscacert CA_PATH         Trust certs signed only by this CA\n  --tlscert CLIENT_CERT_PATH  Path to TLS certificate file\n  --tlskey TLS_KEY_PATH       Path to TLS key file\n  --tlsverify                 Use TLS and verify the remote\n  --skip-hostname-check       Don't check the daemon's hostname against the\n                              name specified in the client certificate\n  --project-directory PATH    Specify an alternate working directory\n                              (default: the path of the Compose file)\n  --compatibility             If set, Compose will attempt to convert deploy\n                              keys in v3 files to their non-Swarm equivalent\n\nCommands:\n  build              Build or rebuild services\n  bundle             Generate a Docker bundle from the Compose file\n  config             Validate and view the Compose file\n  create             Create services\n  down               Stop and remove containers, networks, images, and volumes\n  events             Receive real time events from containers\n  exec               Execute a command in a running container\n  help               Get help on a command\n  images             List images\n  kill               Kill containers\n  logs               View output from containers\n  pause              Pause services\n  port               Print the public port for a port binding\n  ps                 List containers\n  pull               Pull service images\n  push               Push service images\n  restart            Restart services\n  rm                 Remove stopped containers\n  run                Run a one-off command\n  scale              Set number of containers for a service\n  start              Start services\n  stop               Stop services\n  top                Display the running processes\n  unpause            Unpause services\n  up                 Create and start containers\n  version            Show the Docker-Compose version information\n```\n\nYou can use Docker Compose binary, `docker-compose [-f <arg>...] [options] [COMMAND] [ARGS...]`, to build and manage multiple services in Docker containers.\n\n## Use `-f` to specify name and path of one or more Compose files\n\nUse the `-f` flag to specify the location of a Compose configuration file.\n\n### Specifying multiple Compose files\n\nYou can supply multiple `-f` configuration files. When you supply multiple files, Compose combines them into a single configuration. Compose builds the configuration in the order you supply the files. Subsequent files override and add to their predecessors.\n\nFor example, consider this command line:\n\n``` \n$ docker-compose -f docker-compose.yml -f docker-compose.admin.yml run backup_db\n```\n\nThe `docker-compose.yml` file might specify a `webapp` service.\n\n``` \nwebapp:\n  image: examples/web\n  ports:\n    - \"8000:8000\"\n  volumes:\n    - \"/data\"\n```\n\nIf the `docker-compose.admin.yml` also specifies this same service, any matching fields override the previous file. New values, add to the `webapp` service configuration.\n\n``` \nwebapp:\n  build: .\n  environment:\n    - DEBUG=1\n```\n\nWhen you use multiple Compose files, all paths in the files are relative to the first configuration file specified with `-f`. You can use the `--project-directory` option to override this base path.\n\nUse a `-f` with `-` (dash) as the filename to read the configuration from `stdin`. When `stdin` is used all paths in the configuration are relative to the current working directory.\n\nThe `-f` flag is optional. If you don’t provide this flag on the command line, Compose traverses the working directory and its parent directories looking for a `docker-compose.yml` and a `docker-compose.override.yml` file. You must supply at least the `docker-compose.yml` file. If both files are present on the same directory level, Compose combines the two files into a single configuration.\n\nThe configuration in the `docker-compose.override.yml` file is applied over and in addition to the values in the `docker-compose.yml` file.\n\n### Specifying a path to a single Compose file\n\nYou can use the `-f` flag to specify a path to a Compose file that is not located in the current directory, either from the command line or by setting up a [COMPOSE_FILE environment variable](envvars/index#compose_file) in your shell or in an environment file.\n\nFor an example of using the `-f` option at the command line, suppose you are running the [Compose Rails sample](https://docs.docker.com/samples/rails/), and have a `docker-compose.yml` file in a directory called `sandbox/rails`. You can use a command like [docker-compose pull](pull/index) to get the postgres image for the `db` service from anywhere by using the `-f` flag as follows: `docker-compose -f ~/sandbox/rails/docker-compose.yml pull db`\n\nHere’s the full example:\n\n``` \n$ docker-compose -f ~/sandbox/rails/docker-compose.yml pull db\nPulling db (postgres:latest)...\nlatest: Pulling from library/postgres\nef0380f84d05: Pull complete\n50cf91dc1db8: Pull complete\nd3add4cd115c: Pull complete\n467830d8a616: Pull complete\n089b9db7dc57: Pull complete\n6fba0a36935c: Pull complete\n81ef0e73c953: Pull complete\n338a6c4894dc: Pull complete\n15853f32f67c: Pull complete\n044c83d92898: Pull complete\n17301519f133: Pull complete\ndcca70822752: Pull complete\ncecf11b8ccf3: Pull complete\nDigest: sha256:1364924c753d5ff7e2260cd34dc4ba05ebd40ee8193391220be0f9901d4e1651\nStatus: Downloaded newer image for postgres:latest\n```\n\n## Use `-p` to specify a project name\n\nEach configuration has a project name. If you supply a `-p` flag, you can specify a project name. If you don’t specify the flag, Compose uses the current directory name. See also the [COMPOSE_PROJECT_NAME environment variable](envvars/index#compose_project_name).\n\n## Use `--profile` to specify one or more active profiles\n\nCalling `docker-compose --profile frontend up` will start the services with the profile `frontend` and services without specified profiles. You can also enable multiple profiles, e.g. with `docker-compose --profile frontend --profile debug up` the profiles `frontend` and `debug` will be enabled.\n\nSee also [*Using profiles with Compose*](../profiles/index) and the [`COMPOSE_PROFILES` environment variable](envvars/index#compose_profiles).\n\n## Set up environment variables\n\nYou can set [environment variables](envvars/index) for various `docker-compose` options, including the `-f` and `-p` flags.\n\nFor example, the [COMPOSE_FILE environment variable](envvars/index#compose_file) relates to the `-f` flag, and `COMPOSE_PROJECT_NAME` [environment variable](envvars/index#compose_project_name) relates to the `-p` flag.\n\nAlso, you can set some of these variables in an [environment file](../env-file/index).\n\n## Where to go next\n\n- [CLI environment variables](envvars/index)\n- [Declare default environment variables in file](../env-file/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [cli](https://docs.docker.com/search/?q=cli), [reference](https://docs.docker.com/search/?q=reference), [docker-compose](https://docs.docker.com/search/?q=docker-compose)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/reference/](https://docs.docker.com/compose/reference/)"
- name: Play in a content trust sandbox
  id: engine/security/trust/trust_sandbox/index
  summary: This page explains how to set up and use a sandbox for experimenting with trust
  description: "# Play in a content trust sandbox\n\nThis page explains how to set up and use a sandbox for experimenting with trust. The sandbox allows you to configure and try trust operations locally without impacting your production images.\n\nBefore working through this sandbox, you should have read through the [trust overview](../index).\n\n### Prerequisites\n\nThese instructions assume you are running in Linux or macOS. You can run this sandbox on a local machine or on a virtual machine. You need to have privileges to run docker commands on your local machine or in the VM.\n\nThis sandbox requires you to install two Docker tools: Docker Engine \\>= 1.10.0 and Docker Compose \\>= 1.6.0. To install the Docker Engine, choose from the [list of supported platforms](../../../install/index). To install Docker Compose, see the [detailed instructions here](../../../../compose/install/index).\n\n## What is in the sandbox?\n\nIf you are just using trust out-of-the-box you only need your Docker Engine client and access to the Docker Hub. The sandbox mimics a production trust environment, and sets up these additional components.\n\n| Container       | Description                                                                                                                                                                         |\n|-----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| trustsandbox    | A container with the latest version of Docker Engine and with some preconfigured certificates. This is your sandbox where you can use the `docker` client to test trust operations. |\n| Registry server | A local registry service.                                                                                                                                                           |\n| Notary server   | The service that does all the heavy-lifting of managing trust                                                                                                                       |\n\nThis means you run your own content trust (Notary) server and registry. If you work exclusively with the Docker Hub, you would not need these components. They are built into the Docker Hub for you. For the sandbox, however, you build your own entire, mock production environment.\n\nWithin the `trustsandbox` container, you interact with your local registry rather than the Docker Hub. This means your everyday image repositories are not used. They are protected while you play.\n\nWhen you play in the sandbox, you also create root and repository keys. The sandbox is configured to store all the keys and files inside the `trustsandbox` container. Since the keys you create in the sandbox are for play only, destroying the container destroys them as well.\n\nBy using a docker-in-docker image for the `trustsandbox` container, you also don’t pollute your real Docker daemon cache with any images you push and pull. The images are stored in an anonymous volume attached to this container, and can be destroyed after you destroy the container.\n\n## Build the sandbox\n\nIn this section, you use Docker Compose to specify how to set up and link together the `trustsandbox` container, the Notary server, and the Registry server.\n\n1.  Create a new `trustsandbox` directory and change into it.\n\n    ``` \n     $ mkdir trustsandbox\n     $ cd trustsandbox\n    ```\n\n2.  Create a file called `docker-compose.yml` with your favorite editor. For example, using vim:\n\n    ``` \n     $ touch docker-compose.yml\n     $ vim docker-compose.yml\n    ```\n\n3.  Add the following to the new file.\n\n    ``` \n     version: \"2\"\n     services:\n       notaryserver:\n         image: dockersecurity/notary_autobuilds:server-v0.5.1\n         volumes:\n           - notarycerts:/var/lib/notary/fixtures\n         networks:\n           - sandbox\n         environment:\n           - NOTARY_SERVER_STORAGE_TYPE=memory\n           - NOTARY_SERVER_TRUST_SERVICE_TYPE=local\n       sandboxregistry:\n         image: registry:2.4.1\n         networks:\n           - sandbox\n         container_name: sandboxregistry\n       trustsandbox:\n         image: docker:dind\n         networks:\n           - sandbox\n         volumes:\n           - notarycerts:/notarycerts\n         privileged: true\n         container_name: trustsandbox\n         entrypoint: \"\"\n         command: |-\n             sh -c '\n                 cp /notarycerts/root-ca.crt /usr/local/share/ca-certificates/root-ca.crt &&\n                 update-ca-certificates &&\n                 dockerd-entrypoint.sh --insecure-registry sandboxregistry:5000'\n     volumes:\n       notarycerts:\n         external: false\n     networks:\n       sandbox:\n         external: false\n    ```\n\n4.  Save and close the file.\n\n5.  Run the containers on your local system.\n\n    ``` \n     $ docker-compose up -d\n    ```\n\n    The first time you run this, the docker-in-docker, Notary server, and registry images are downloaded from Docker Hub.\n\n## Play in the sandbox\n\nNow that everything is setup, you can go into your `trustsandbox` container and start testing Docker content trust. From your host machine, obtain a shell in the `trustsandbox` container.\n\n``` \n$ docker container exec -it trustsandbox sh\n/ #\n```\n\n### Test some trust operations\n\nNow, pull some images from within the `trustsandbox` container.\n\n1.  Download a `docker` image to test with.\n\n    ``` \n     / # docker pull docker/trusttest\n     docker pull docker/trusttest\n     Using default tag: latest\n     latest: Pulling from docker/trusttest\n\n     b3dbab3810fc: Pull complete\n     a9539b34a6ab: Pull complete\n     Digest: sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a\n     Status: Downloaded newer image for docker/trusttest:latest\n    ```\n\n2.  Tag it to be pushed to our sandbox registry:\n\n    ``` \n     / # docker tag docker/trusttest sandboxregistry:5000/test/trusttest:latest\n    ```\n\n3.  Enable content trust.\n\n    ``` \n     / # export DOCKER_CONTENT_TRUST=1\n    ```\n\n4.  Identify the trust server.\n\n    ``` \n     / # export DOCKER_CONTENT_TRUST_SERVER=https://notaryserver:4443\n    ```\n\n    This step is only necessary because the sandbox is using its own server. Normally, if you are using the Docker Public Hub this step isn’t necessary.\n\n5.  Pull the test image.\n\n    ``` \n     / # docker pull sandboxregistry:5000/test/trusttest\n     Using default tag: latest\n     Error: remote trust data does not exist for sandboxregistry:5000/test/trusttest: notaryserver:4443 does not have trust data for sandboxregistry:5000/test/trusttest\n    ```\n\n    You see an error, because this content doesn’t exist on the `notaryserver` yet.\n\n6.  Push and sign the trusted image.\n\n    ``` \n     / # docker push sandboxregistry:5000/test/trusttest:latest\n     The push refers to a repository [sandboxregistry:5000/test/trusttest]\n     5f70bf18a086: Pushed\n     c22f7bc058a9: Pushed\n     latest: digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 size: 734\n     Signing and pushing trust metadata\n     You are about to create a new root signing key passphrase. This passphrase\n     will be used to protect the most sensitive key in your signing system. Please\n     choose a long, complex passphrase and be careful to keep the password and the\n     key file itself secure and backed up. It is highly recommended that you use a\n     password manager to generate the passphrase and keep it safe. There will be no\n     way to recover this key. You can find the key in your config directory.\n     Enter passphrase for new root key with ID 27ec255:\n     Repeat passphrase for new root key with ID 27ec255:\n     Enter passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\n     Repeat passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\n     Finished initializing \"sandboxregistry:5000/test/trusttest\"\n     Successfully signed \"sandboxregistry:5000/test/trusttest\":latest\n    ```\n\n    Because you are pushing this repository for the first time, Docker creates new root and repository keys and asks you for passphrases with which to encrypt them. If you push again after this, it only asks you for repository passphrase so it can decrypt the key and sign again.\n\n7.  Try pulling the image you just pushed:\n\n    ``` \n     / # docker pull sandboxregistry:5000/test/trusttest\n     Using default tag: latest\n     Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926: Pulling from test/trusttest\n     Digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     Status: Downloaded newer image for sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     Tagging sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 as sandboxregistry:5000/test/trusttest:latest\n    ```\n\n### Test with malicious images\n\nWhat happens when data is corrupted and you try to pull it when trust is enabled? In this section, you go into the `sandboxregistry` and tamper with some data. Then, you try and pull it.\n\n1.  Leave the `trustsandbox` shell and container running.\n\n2.  Open a new interactive terminal from your host, and obtain a shell into the `sandboxregistry` container.\n\n    ``` \n    $ docker container exec -it sandboxregistry bash\n    root@65084fc6f047:/#\n    ```\n\n3.  List the layers for the `test/trusttest` image you pushed:\n\n    ``` \n    root@65084fc6f047:/# ls -l /var/lib/registry/docker/registry/v2/repositories/test/trusttest/_layers/sha256\n    total 12\n    drwxr-xr-x 2 root root 4096 Jun 10 17:26 a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4\n    drwxr-xr-x 2 root root 4096 Jun 10 17:26 aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042\n    drwxr-xr-x 2 root root 4096 Jun 10 17:26 cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd\n    ```\n\n4.  Change into the registry storage for one of those layers (this is in a different directory):\n\n    ``` \n    root@65084fc6f047:/# cd /var/lib/registry/docker/registry/v2/blobs/sha256/aa/aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042\n    ```\n\n5.  Add malicious data to one of the `trusttest` layers:\n\n    ``` \n    root@65084fc6f047:/# echo \"Malicious data\" > data\n    ```\n\n6.  Go back to your `trustsandbox` terminal.\n\n7.  List the `trusttest` image.\n\n    ``` \n    / # docker image ls | grep trusttest\n    REPOSITORY                            TAG                 IMAGE ID            CREATED             SIZE\n    docker/trusttest                      latest              cc7629d1331a        11 months ago       5.025 MB\n    sandboxregistry:5000/test/trusttest   latest              cc7629d1331a        11 months ago       5.025 MB\n    sandboxregistry:5000/test/trusttest   <none>              cc7629d1331a        11 months ago       5.025 MB\n    ```\n\n8.  Remove the `trusttest:latest` image from our local cache.\n\n    ``` \n    / # docker image rm -f cc7629d1331a\n    Untagged: docker/trusttest:latest\n    Untagged: sandboxregistry:5000/test/trusttest:latest\n    Untagged: sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n    Deleted: sha256:cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd\n    Deleted: sha256:2a1f6535dc6816ffadcdbe20590045e6cbf048d63fd4cc753a684c9bc01abeea\n    Deleted: sha256:c22f7bc058a9a8ffeb32989b5d3338787e73855bf224af7aa162823da015d44c\n    ```\n\n    Docker does not re-download images that it already has cached, but we want Docker to attempt to download the tampered image from the registry and reject it because it is invalid.\n\n9.  Pull the image again. This downloads the image from the registry, because we don’t have it cached.\n\n    ``` \n    / # docker pull sandboxregistry:5000/test/trusttest\n    Using default tag: latest\n    Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest@sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e\n    sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e: Pulling from test/trusttest\n\n    aac0c133338d: Retrying in 5 seconds\n    a3ed95caeb02: Download complete\n    error pulling image configuration: unexpected EOF\n    ```\n\n    The pull did not complete because the trust system couldn’t verify the image.\n\n## More play in the sandbox\n\nNow, you have a full Docker content trust sandbox on your local system, feel free to play with it and see how it behaves. If you find any security issues with Docker, feel free to send us an email at <security@docker.com>.\n\n## Clean up your sandbox\n\nWhen you are done, and want to clean up all the services you’ve started and any anonymous volumes that have been created, just run the following command in the directory where you’ve created your Docker Compose file:\n\n``` \n    $ docker-compose down -v\n```\n\n[trust](https://docs.docker.com/search/?q=trust), [security](https://docs.docker.com/search/?q=security), [root](https://docs.docker.com/search/?q=root), [keys](https://docs.docker.com/search/?q=keys), [repository](https://docs.docker.com/search/?q=repository), [sandbox](https://docs.docker.com/search/?q=sandbox)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/trust/trust_sandbox/](https://docs.docker.com/engine/security/trust/trust_sandbox/)"
- name: Plugin Config Version 1 of Plugin V2
  id: engine/extend/config/index
  summary: This document outlines the format of the V0 plugin configuration
  description: "# Plugin Config Version 1 of Plugin V2\n\nThis document outlines the format of the V0 plugin configuration. The plugin config described herein was introduced in the Docker daemon in the [v1.12.0 release](https://github.com/docker/docker/commit/f37117045c5398fd3dca8016ea8ca0cb47e7312b).\n\nPlugin configs describe the various constituents of a docker plugin. Plugin configs can be serialized to JSON format with the following media types:\n\n| Config Type | Media Type                              |\n|-------------|-----------------------------------------|\n| config      | “application/vnd.docker.plugin.v1+json” |\n\n## *Config* Field Descriptions\n\nConfig provides the base accessible fields for working with V0 plugin format in the registry.\n\n- **`description`** *string*\n\n  description of the plugin\n\n- **`documentation`** *string*\n\n  link to the documentation about the plugin\n\n- **`interface`** *PluginInterface*\n\n  interface implemented by the plugins, struct consisting of the following fields\n\n  - **`types`** *string array*\n\n    types indicate what interface(s) the plugin currently implements.\n\n    currently supported:\n\n    - **docker.volumedriver/1.0**\n\n    - **docker.networkdriver/1.0**\n\n    - **docker.ipamdriver/1.0**\n\n    - **docker.authz/1.0**\n\n    - **docker.logdriver/1.0**\n\n    - **docker.metricscollector/1.0**\n\n  - **`socket`** *string*\n\n    socket is the name of the socket the engine should use to communicate with the plugins. the socket will be created in `/run/docker/plugins`.\n\n- **`entrypoint`** *string array*\n\n  entrypoint of the plugin, see [`ENTRYPOINT`](../../reference/builder/index#entrypoint)\n\n- **`workdir`** *string*\n\n  workdir of the plugin, see [`WORKDIR`](../../reference/builder/index#workdir)\n\n- **`network`** *PluginNetwork*\n\n  network of the plugin, struct consisting of the following fields\n\n  - **`type`** *string*\n\n    network type.\n\n    currently supported:\n\n    ``` \n    - **bridge**\n    - **host**\n    - **none**\n    ```\n\n- **`mounts`** *PluginMount array*\n\n  mount of the plugin, struct consisting of the following fields, see [`MOUNTS`](https://github.com/opencontainers/runtime-spec/blob/master/config/#mounts)\n\n  - **`name`** *string*\n\n    name of the mount.\n\n  - **`description`** *string*\n\n    description of the mount.\n\n  - **`source`** *string*\n\n    source of the mount.\n\n  - **`destination`** *string*\n\n    destination of the mount.\n\n  - **`type`** *string*\n\n    mount type.\n\n  - **`options`** *string array*\n\n    options of the mount.\n\n- **`ipchost`** *boolean* Access to host ipc namespace.\n\n- **`pidhost`** *boolean* Access to host pid namespace.\n\n- **`propagatedMount`** *string*\n\n  path to be mounted as rshared, so that mounts under that path are visible to docker. This is useful for volume plugins. This path will be bind-mounted outside of the plugin rootfs so it’s contents are preserved on upgrade.\n\n- **`env`** *PluginEnv array*\n\n  env of the plugin, struct consisting of the following fields\n\n  - **`name`** *string*\n\n    name of the env.\n\n  - **`description`** *string*\n\n    description of the env.\n\n  - **`value`** *string*\n\n    value of the env.\n\n- **`args`** *PluginArgs*\n\n  args of the plugin, struct consisting of the following fields\n\n  - **`name`** *string*\n\n    name of the args.\n\n  - **`description`** *string*\n\n    description of the args.\n\n  - **`value`** *string array*\n\n    values of the args.\n\n- **`linux`** *PluginLinux*\n\n  - **`capabilities`** *string array*\n\n    capabilities of the plugin (*Linux only*), see list [`here`](https://github.com/opencontainers/runc/blob/master/libcontainer/SPEC/#security)\n\n  - **`allowAllDevices`** *boolean*\n\n    If `/dev` is bind mounted from the host, and allowAllDevices is set to true, the plugin will have `rwm` access to all devices on the host.\n\n  - **`devices`** *PluginDevice array*\n\n    device of the plugin, (*Linux only*), struct consisting of the following fields, see [`DEVICES`](https://github.com/opencontainers/runtime-spec/blob/master/config-linux/#devices)\n\n    - **`name`** *string*\n\n      name of the device.\n\n    - **`description`** *string*\n\n      description of the device.\n\n    - **`path`** *string*\n\n      path of the device.\n\n## Example Config\n\n*Example showing the ‘tiborvass/sample-volume-plugin’ plugin config.*\n\n``` \n{\n  \"Args\": {\n    \"Description\": \"\",\n    \"Name\": \"\",\n    \"Settable\": null,\n    \"Value\": null\n  },\n  \"Description\": \"A sample volume plugin for Docker\",\n  \"Documentation\": \"https://docs.docker.com/engine/extend/plugins/\",\n  \"Entrypoint\": [\n    \"/usr/bin/sample-volume-plugin\",\n    \"/data\"\n  ],\n  \"Env\": [\n    {\n      \"Description\": \"\",\n      \"Name\": \"DEBUG\",\n      \"Settable\": [\n        \"value\"\n      ],\n      \"Value\": \"0\"\n    }\n  ],\n  \"Interface\": {\n    \"Socket\": \"plugin.sock\",\n    \"Types\": [\n      \"docker.volumedriver/1.0\"\n    ]\n  },\n  \"Linux\": {\n    \"Capabilities\": null,\n    \"AllowAllDevices\": false,\n    \"Devices\": null\n  },\n  \"Mounts\": null,\n  \"Network\": {\n    \"Type\": \"\"\n  },\n  \"PropagatedMount\": \"/data\",\n  \"User\": {},\n  \"Workdir\": \"\"\n}\n```\n\n[API](https://docs.docker.com/search/?q=API), [Usage](https://docs.docker.com/search/?q=Usage), [plugins](https://docs.docker.com/search/?q=plugins), [documentation](https://docs.docker.com/search/?q=documentation), [developer](https://docs.docker.com/search/?q=developer)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/config/](https://docs.docker.com/engine/extend/config/)"
- name: Post-installation steps for Linux
  id: engine/install/linux-postinstall/index
  summary: This section contains optional procedures for configuring Linux hosts to work better with Docker
  description: "# Post-installation steps for Linux\n\nThis section contains optional procedures for configuring Linux hosts to work better with Docker.\n\n## Manage Docker as a non-root user\n\nThe Docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user `root` and other users can only access it using `sudo`. The Docker daemon always runs as the `root` user.\n\nIf you don’t want to preface the `docker` command with `sudo`, create a Unix group called `docker` and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the `docker` group.\n\n> Warning\n>\n> The `docker` group grants privileges equivalent to the `root` user. For details on how this impacts security in your system, see [*Docker Daemon Attack Surface*](../../security/index#docker-daemon-attack-surface).\n\n> **Note**:\n>\n> To run Docker without root privileges, see [Run the Docker daemon as a non-root user (Rootless mode)](../../security/rootless/index).\n\nTo create the `docker` group and add your user:\n\n1.  Create the `docker` group.\n\n    ``` \n    $ sudo groupadd docker\n    ```\n\n2.  Add your user to the `docker` group.\n\n    ``` \n    $ sudo usermod -aG docker $USER\n    ```\n\n3.  Log out and log back in so that your group membership is re-evaluated.\n\n    If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect.\n\n    On a desktop Linux environment such as X Windows, log out of your session completely and then log back in.\n\n    On Linux, you can also run the following command to activate the changes to groups:\n\n    ``` \n    $ newgrp docker \n    ```\n\n4.  Verify that you can run `docker` commands without `sudo`.\n\n    ``` \n    $ docker run hello-world\n    ```\n\n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n\n    If you initially ran Docker CLI commands using `sudo` before adding your user to the `docker` group, you may see the following error, which indicates that your `~/.docker/` directory was created with incorrect permissions due to the `sudo` commands.\n\n        WARNING: Error loading config file: /home/user/.docker/config.json -\n        stat /home/user/.docker/config.json: permission denied\n\n    To fix this problem, either remove the `~/.docker/` directory (it is recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:\n\n    ``` \n    $ sudo chown \"$USER\":\"$USER\" /home/\"$USER\"/.docker -R\n    $ sudo chmod g+rwx \"$HOME/.docker\" -R\n    ```\n\n## Configure Docker to start on boot\n\nMost current Linux distributions (RHEL, CentOS, Fedora, Debian, Ubuntu 16.04 and higher) use [`systemd`](https://docs.docker.com/config/daemon/systemd/) to manage which services start when the system boots. On Debian and Ubuntu, the Docker service is configured to start on boot by default. To automatically start Docker and Containerd on boot for other distros, use the commands below:\n\n``` \n$ sudo systemctl enable docker.service\n$ sudo systemctl enable containerd.service\n```\n\nTo disable this behavior, use `disable` instead.\n\n``` \n$ sudo systemctl disable docker.service\n$ sudo systemctl disable containerd.service\n```\n\nIf you need to add an HTTP Proxy, set a different directory or partition for the Docker runtime files, or make other customizations, see [customize your systemd Docker daemon options](https://docs.docker.com/config/daemon/systemd/).\n\n## Use a different storage engine\n\nFor information about the different storage engines, see [Storage drivers](https://docs.docker.com/storage/storagedriver/). The default storage engine and the list of supported storage engines depend on your host’s Linux distribution and available kernel drivers.\n\n## Configure default logging driver\n\nDocker provides the [capability](https://docs.docker.com/config/containers/logging/) to collect and view log data from all containers running on a host via a series of logging drivers. The default logging driver, `json-file`, writes log data to JSON-formatted files on the host filesystem. Over time, these log files expand in size, leading to potential exhaustion of disk resources.\n\nTo alleviate such issues, either configure the `json-file` logging driver to enable [log rotation](https://docs.docker.com/config/containers/logging/json-file/), use an [alternative logging driver](https://docs.docker.com/config/containers/logging/configure/#configure-the-default-logging-driver) such as the [“local” logging driver](https://docs.docker.com/config/containers/logging/local/) that performs log rotation by default, or use a logging driver that sends logs to a remote logging aggregator.\n\n## Configure where the Docker daemon listens for connections\n\nBy default, the Docker daemon listens for connections on a UNIX socket to accept requests from local clients. It is possible to allow Docker to accept requests from remote hosts by configuring it to listen on an IP address and port as well as the UNIX socket. For more detailed information on this configuration option take a look at “Bind Docker to another host/port or a unix socket” section of the [Docker CLI Reference](../../reference/commandline/dockerd/index) article.\n\n> Secure your connection\n>\n> Before configuring Docker to accept connections from remote hosts it is critically important that you understand the security implications of opening docker to the network. If steps are not taken to secure the connection, it is possible for remote non-root users to gain root access on the host. For more information on how to use TLS certificates to secure this connection, check this article on [how to protect the Docker daemon socket](../../security/protect-access/index).\n\nConfiguring Docker to accept remote connections can be done with the `docker.service` systemd unit file for Linux distributions using systemd, such as recent versions of RedHat, CentOS, Ubuntu and SLES, or with the `daemon.json` file which is recommended for Linux distributions that do not use systemd.\n\n> systemd vs daemon.json\n>\n> Configuring Docker to listen for connections using both the `systemd` unit file and the `daemon.json` file causes a conflict that prevents Docker from starting.\n\n### Configuring remote access with `systemd` unit file\n\n1.  Use the command `sudo systemctl edit docker.service` to open an override file for `docker.service` in a text editor.\n\n2.  Add or modify the following lines, substituting your own values.\n\n    ``` \n    [Service]\n    ExecStart=\n    ExecStart=/usr/bin/dockerd -H fd:// -H tcp://127.0.0.1:2375\n    ```\n\n3.  Save the file.\n\n4.  Reload the `systemctl` configuration.\n\n    ``` \n     $ sudo systemctl daemon-reload\n    ```\n\n5.  Restart Docker.\n\n    ``` \n    $ sudo systemctl restart docker.service\n    ```\n\n6.  Check to see whether the change was honored by reviewing the output of `netstat` to confirm `dockerd` is listening on the configured port.\n\n    ``` \n    $ sudo netstat -lntp | grep dockerd\n    tcp        0      0 127.0.0.1:2375          0.0.0.0:*               LISTEN      3758/dockerd\n    ```\n\n### Configuring remote access with `daemon.json`\n\n1.  Set the `hosts` array in the `/etc/docker/daemon.json` to connect to the UNIX socket and an IP address, as follows:\n\n    ``` \n    {\n      \"hosts\": [\"unix:///var/run/docker.sock\", \"tcp://127.0.0.1:2375\"]\n    }\n    ```\n\n2.  Restart Docker.\n\n3.  Check to see whether the change was honored by reviewing the output of `netstat` to confirm `dockerd` is listening on the configured port.\n\n    ``` \n    $ sudo netstat -lntp | grep dockerd\n    tcp        0      0 127.0.0.1:2375          0.0.0.0:*               LISTEN      3758/dockerd\n    ```\n\n## Enable IPv6 on the Docker daemon\n\nTo enable IPv6 on the Docker daemon, see [Enable IPv6 support](https://docs.docker.com/config/daemon/ipv6/).\n\n## Troubleshooting\n\n### Kernel compatibility\n\nDocker cannot run correctly if your kernel is older than version 3.10 or if it is missing some modules. To check kernel compatibility, you can download and run the [`check-config.sh`](https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh) script.\n\n``` \n$ curl https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh > check-config.sh\n\n$ bash ./check-config.sh\n```\n\nThe script only works on Linux, not macOS.\n\n### `Cannot connect to the Docker daemon`\n\nIf you see an error such as the following, your Docker client may be configured to connect to a Docker daemon on a different host, and that host may not be reachable.\n\n``` \nCannot connect to the Docker daemon. Is 'docker daemon' running on this host?\n```\n\nTo see which host your client is configured to connect to, check the value of the `DOCKER_HOST` variable in your environment.\n\n``` \n$ env | grep DOCKER_HOST\n```\n\nIf this command returns a value, the Docker client is set to connect to a Docker daemon running on that host. If it is unset, the Docker client is set to connect to the Docker daemon running on the local host. If it is set in error, use the following command to unset it:\n\n``` \n$ unset DOCKER_HOST\n```\n\nYou may need to edit your environment in files such as `~/.bashrc` or `~/.profile` to prevent the `DOCKER_HOST` variable from being set erroneously.\n\nIf `DOCKER_HOST` is set as intended, verify that the Docker daemon is running on the remote host and that a firewall or network outage is not preventing you from connecting.\n\n### IP forwarding problems\n\nIf you manually configure your network using `systemd-network` with `systemd` version 219 or higher, Docker containers may not be able to access your network. Beginning with `systemd` version 220, the forwarding setting for a given network (`net.ipv4.conf.<interface>.forwarding`) defaults to *off*. This setting prevents IP forwarding. It also conflicts with Docker’s behavior of enabling the `net.ipv4.conf.all.forwarding` setting within containers.\n\nTo work around this on RHEL, CentOS, or Fedora, edit the `<interface>.network` file in `/usr/lib/systemd/network/` on your Docker host (ex: `/usr/lib/systemd/network/80-container-host0.network`) and add the following block within the `[Network]` section.\n\n``` \n[Network]\n...\nIPForward=kernel\n# OR\nIPForward=true\n```\n\nThis configuration allows IP forwarding from the container as expected.\n\n### `DNS resolver found in resolv.conf and containers can't use it`\n\nLinux systems which use a GUI often have a network manager running, which uses a `dnsmasq` instance running on a loopback address such as `127.0.0.1` or `127.0.1.1` to cache DNS requests, and adds this entry to `/etc/resolv.conf`. The `dnsmasq` service speeds up DNS look-ups and also provides DHCP services. This configuration does not work within a Docker container which has its own network namespace, because the Docker container resolves loopback addresses such as `127.0.0.1` to **itself**, and it is very unlikely to be running a DNS server on its own loopback address.\n\nIf Docker detects that no DNS server referenced in `/etc/resolv.conf` is a fully functional DNS server, the following warning occurs and Docker uses the public DNS servers provided by Google at `8.8.8.8` and `8.8.4.4` for DNS resolution.\n\n``` \nWARNING: Local (127.0.0.1) DNS resolver found in resolv.conf and containers\ncan't use it. Using default external servers : [8.8.8.8 8.8.4.4]\n```\n\nIf you see this warning, first check to see if you use `dnsmasq`:\n\n``` \n$ ps aux |grep dnsmasq\n```\n\nIf your container needs to resolve hosts which are internal to your network, the public nameservers are not adequate. You have two choices:\n\n- You can specify a DNS server for Docker to use, **or**\n- You can disable `dnsmasq` in NetworkManager. If you do this, NetworkManager adds your true DNS nameserver to `/etc/resolv.conf`, but you lose the possible benefits of `dnsmasq`.\n\n**You only need to use one of these methods.**\n\n### Specify DNS servers for Docker\n\nThe default location of the configuration file is `/etc/docker/daemon.json`. You can change the location of the configuration file using the `--config-file` daemon flag. The documentation below assumes the configuration file is located at `/etc/docker/daemon.json`.\n\n1.  Create or edit the Docker daemon configuration file, which defaults to `/etc/docker/daemon.json` file, which controls the Docker daemon configuration.\n\n    ``` \n    $ sudo nano /etc/docker/daemon.json\n    ```\n\n2.  Add a `dns` key with one or more IP addresses as values. If the file has existing contents, you only need to add or edit the `dns` line.\n\n    ``` \n    {\n      \"dns\": [\"8.8.8.8\", \"8.8.4.4\"]\n    }\n    ```\n\n    If your internal DNS server cannot resolve public IP addresses, include at least one DNS server which can, so that you can connect to Docker Hub and so that your containers can resolve internet domain names.\n\n    Save and close the file.\n\n3.  Restart the Docker daemon.\n\n    ``` \n    $ sudo service docker restart\n    ```\n\n4.  Verify that Docker can resolve external IP addresses by trying to pull an image:\n\n    ``` \n    $ docker pull hello-world\n    ```\n\n5.  If necessary, verify that Docker containers can resolve an internal hostname by pinging it.\n\n    ``` \n    $ docker run --rm -it alpine ping -c4 <my_internal_host>\n\n    PING google.com (192.168.1.2): 56 data bytes\n    64 bytes from 192.168.1.2: seq=0 ttl=41 time=7.597 ms\n    64 bytes from 192.168.1.2: seq=1 ttl=41 time=7.635 ms\n    64 bytes from 192.168.1.2: seq=2 ttl=41 time=7.660 ms\n    64 bytes from 192.168.1.2: seq=3 ttl=41 time=7.677 ms\n    ```\n\n#### Disable `dnsmasq`\n\n##### Ubuntu\n\nIf you prefer not to change the Docker daemon’s configuration to use a specific IP address, follow these instructions to disable `dnsmasq` in NetworkManager.\n\n1.  Edit the `/etc/NetworkManager/NetworkManager.conf` file.\n\n2.  Comment out the `dns=dnsmasq` line by adding a `#` character to the beginning of the line.\n\n        # dns=dnsmasq\n\n    Save and close the file.\n\n3.  Restart both NetworkManager and Docker. As an alternative, you can reboot your system.\n\n    ``` \n    $ sudo systemctl restart network-manager\n    $ sudo systemctl restart docker\n    ```\n\n##### RHEL, CentOS, or Fedora\n\nTo disable `dnsmasq` on RHEL, CentOS, or Fedora:\n\n1.  Disable the `dnsmasq` service:\n\n    ``` \n    $ sudo systemctl stop dnsmasq\n    $ sudo systemctl disable dnsmasq\n    ```\n\n2.  Configure the DNS servers manually using the [Red Hat documentation](https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/s1-networkscripts-interfaces.html).\n\n### Allow access to the remote API through a firewall\n\nIf you run a firewall on the same host as you run Docker and you want to access the Docker Remote API from another host and remote access is enabled, you need to configure your firewall to allow incoming connections on the Docker port, which defaults to `2376` if TLS encrypted transport is enabled or `2375` otherwise.\n\nTwo common firewall daemons are [UFW (Uncomplicated Firewall)](https://help.ubuntu.com/community/UFW) (often used for Ubuntu systems) and [firewalld](https://firewalld.org) (often used for RPM-based systems). Consult the documentation for your OS and firewall, but the following information might help you get started. These options are fairly permissive and you may want to use a different configuration that locks your system down more.\n\n- **UFW**: Set `DEFAULT_FORWARD_POLICY=\"ACCEPT\"` in your configuration.\n\n- **firewalld**: Add rules similar to the following to your policy (one for incoming requests and one for outgoing requests). Be sure the interface names and chain names are correct.\n\n  ``` \n  <direct>\n    [ <rule ipv=\"ipv6\" table=\"filter\" chain=\"FORWARD_direct\" priority=\"0\"> -i zt0 -j ACCEPT </rule> ]\n    [ <rule ipv=\"ipv6\" table=\"filter\" chain=\"FORWARD_direct\" priority=\"0\"> -o zt0 -j ACCEPT </rule> ]\n  </direct>\n  ```\n\n### `Your kernel does not support cgroup swap limit capabilities`\n\nOn Ubuntu or Debian hosts, You may see messages similar to the following when working with an image.\n\n``` \nWARNING: Your kernel does not support swap limit capabilities. Limitation discarded.\n```\n\nThis warning does not occur on RPM-based systems, which enable these capabilities by default.\n\nIf you don’t need these capabilities, you can ignore the warning. You can enable these capabilities on Ubuntu or Debian by following these instructions. Memory and swap accounting incur an overhead of about 1% of the total available memory and a 10% overall performance degradation, even if Docker is not running.\n\n1.  Log into the Ubuntu or Debian host as a user with `sudo` privileges.\n\n2.  Edit the `/etc/default/grub` file. Add or edit the `GRUB_CMDLINE_LINUX` line to add the following two key-value pairs:\n\n        GRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\"\n\n    Save and close the file.\n\n3.  Update GRUB.\n\n    ``` \n    $ sudo update-grub\n    ```\n\n    If your GRUB configuration file has incorrect syntax, an error occurs. In this case, repeat steps 2 and 3.\n\n    The changes take effect when the system is rebooted.\n\n## Next steps\n\n- Take a look at the [Get started](../../../get-started/index) training modules to learn how to build an image and run it as a containerized application.\n- Review the topics in [Develop with Docker](https://docs.docker.com/develop/) to learn how to build new applications using Docker.\n\n[Docker](https://docs.docker.com/search/?q=Docker), [Docker documentation](https://docs.docker.com/search/?q=Docker%20documentation), [requirements](https://docs.docker.com/search/?q=requirements), [apt](https://docs.docker.com/search/?q=apt), [installation](https://docs.docker.com/search/?q=installation), [ubuntu](https://docs.docker.com/search/?q=ubuntu), [install](https://docs.docker.com/search/?q=install), [uninstall](https://docs.docker.com/search/?q=uninstall), [upgrade](https://docs.docker.com/search/?q=upgrade), [update](https://docs.docker.com/search/?q=update)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/install/linux-postinstall/](https://docs.docker.com/engine/install/linux-postinstall/)"
- name: Protect the Docker daemon socket
  id: engine/security/protect-access/index
  summary: By default, Docker runs through a non-networked UNIX socket
  description: "# Protect the Docker daemon socket\n\nBy default, Docker runs through a non-networked UNIX socket. It can also optionally communicate using SSH or a TLS (HTTPS) socket.\n\n## Use SSH to protect the Docker daemon socket\n\n> **Note**\n>\n> The given `USERNAME` must have permissions to access the docker socket on the remote machine. Refer to [manage Docker as a non-root user](../../install/linux-postinstall/index#manage-docker-as-a-non-root-user) to learn how to give a non-root user access to the docker socket.\n\nThe following example creates a [`docker context`](../../context/working-with-contexts/index) to connect with a remote `dockerd` daemon on `host1.example.com` using SSH, and as the `docker-user` user on the remote machine:\n\n``` \n$ docker context create \\\n    --docker host=ssh://docker-user@host1.example.com \\\n    --description=\"Remote engine\" \\\n    my-remote-engine\n\nmy-remote-engine\nSuccessfully created context \"my-remote-engine\"\n```\n\nAfter creating the context, use `docker context use` to switch the `docker` CLI to use it, and to connect to the remote engine:\n\n``` \n$ docker context use my-remote-engine\nmy-remote-engine\nCurrent context is now \"my-remote-engine\"\n\n$ docker info\n<prints output of the remote engine>\n```\n\nUse the `default` context to switch back to the default (local) daemon:\n\n``` \n$ docker context use default\ndefault\nCurrent context is now \"default\"\n```\n\nAlternatively, use the `DOCKER_HOST` environment variable to temporarily switch the `docker` CLI to connect to the remote host using SSH. This does not require creating a context, and can be useful to create an ad-hoc connection with a different engine:\n\n``` \n$ export DOCKER_HOST=ssh://docker-user@host1.example.com\n$ docker info\n<prints output of the remote engine>\n```\n\n### SSH Tips\n\nFor the best user experience with SSH, configure `~/.ssh/config` as follows to allow reusing a SSH connection for multiple invocations of the `docker` CLI:\n\n``` \nControlMaster     auto\nControlPath       ~/.ssh/control-%C\nControlPersist    yes\n```\n\n## Use TLS (HTTPS) to protect the Docker daemon socket\n\nIf you need Docker to be reachable through HTTP rather than SSH in a safe manner, you can enable TLS (HTTPS) by specifying the `tlsverify` flag and pointing Docker’s `tlscacert` flag to a trusted CA certificate.\n\nIn the daemon mode, it only allows connections from clients authenticated by a certificate signed by that CA. In the client mode, it only connects to servers with a certificate signed by that CA.\n\n> Advanced topic\n>\n> Using TLS and managing a CA is an advanced topic. Please familiarize yourself with OpenSSL, x509, and TLS before using it in production.\n\n### Create a CA, server and client keys with OpenSSL\n\n> **Note**: Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon’s host.\n\nFirst, on the **Docker daemon’s host machine**, generate CA private and public keys:\n\n``` \n$ openssl genrsa -aes256 -out ca-key.pem 4096\nGenerating RSA private key, 4096 bit long modulus\n..............................................................................++\n........++\ne is 65537 (0x10001)\nEnter pass phrase for ca-key.pem:\nVerifying - Enter pass phrase for ca-key.pem:\n\n$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem\nEnter pass phrase for ca-key.pem:\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [AU]:\nState or Province Name (full name) [Some-State]:Queensland\nLocality Name (eg, city) []:Brisbane\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Docker Inc\nOrganizational Unit Name (eg, section) []:Sales\nCommon Name (e.g. server FQDN or YOUR name) []:$HOST\nEmail Address []:Sven@home.org.au\n```\n\nNow that you have a CA, you can create a server key and certificate signing request (CSR). Make sure that “Common Name” matches the hostname you use to connect to Docker:\n\n> **Note**: Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon’s host.\n\n``` \n$ openssl genrsa -out server-key.pem 4096\nGenerating RSA private key, 4096 bit long modulus\n.....................................................................++\n.................................................................................................++\ne is 65537 (0x10001)\n\n$ openssl req -subj \"/CN=$HOST\" -sha256 -new -key server-key.pem -out server.csr\n```\n\nNext, we’re going to sign the public key with our CA:\n\nSince TLS connections can be made through IP address as well as DNS name, the IP addresses need to be specified when creating the certificate. For example, to allow connections using `10.10.10.20` and `127.0.0.1`:\n\n``` \n$ echo subjectAltName = DNS:$HOST,IP:10.10.10.20,IP:127.0.0.1 >> extfile.cnf\n```\n\nSet the Docker daemon key’s extended usage attributes to be used only for server authentication:\n\n``` \n$ echo extendedKeyUsage = serverAuth >> extfile.cnf\n```\n\nNow, generate the signed certificate:\n\n``` \n$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\\n  -CAcreateserial -out server-cert.pem -extfile extfile.cnf\nSignature ok\nsubject=/CN=your.host.com\nGetting CA Private Key\nEnter pass phrase for ca-key.pem:\n```\n\n[Authorization plugins](../../extend/plugins_authorization/index) offer more fine-grained control to supplement authentication from mutual TLS. In addition to other information described in the above document, authorization plugins running on a Docker daemon receive the certificate information for connecting Docker clients.\n\nFor client authentication, create a client key and certificate signing request:\n\n> **Note**: For simplicity of the next couple of steps, you may perform this step on the Docker daemon’s host machine as well.\n\n``` \n$ openssl genrsa -out key.pem 4096\nGenerating RSA private key, 4096 bit long modulus\n.........................................................++\n................++\ne is 65537 (0x10001)\n\n$ openssl req -subj '/CN=client' -new -key key.pem -out client.csr\n```\n\nTo make the key suitable for client authentication, create a new extensions config file:\n\n``` \n$ echo extendedKeyUsage = clientAuth > extfile-client.cnf\n```\n\nNow, generate the signed certificate:\n\n``` \n$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\\n  -CAcreateserial -out cert.pem -extfile extfile-client.cnf\nSignature ok\nsubject=/CN=client\nGetting CA Private Key\nEnter pass phrase for ca-key.pem:\n```\n\nAfter generating `cert.pem` and `server-cert.pem` you can safely remove the two certificate signing requests and extensions config files:\n\n``` \n$ rm -v client.csr server.csr extfile.cnf extfile-client.cnf\n```\n\nWith a default `umask` of 022, your secret keys are *world-readable* and writable for you and your group.\n\nTo protect your keys from accidental damage, remove their write permissions. To make them only readable by you, change file modes as follows:\n\n``` \n$ chmod -v 0400 ca-key.pem key.pem server-key.pem\n```\n\nCertificates can be world-readable, but you might want to remove write access to prevent accidental damage:\n\n``` \n$ chmod -v 0444 ca.pem server-cert.pem cert.pem\n```\n\nNow you can make the Docker daemon only accept connections from clients providing a certificate trusted by your CA:\n\n``` \n$ dockerd \\\n    --tlsverify \\\n    --tlscacert=ca.pem \\\n    --tlscert=server-cert.pem \\\n    --tlskey=server-key.pem \\\n    -H=0.0.0.0:2376\n```\n\nTo connect to Docker and validate its certificate, provide your client keys, certificates and trusted CA:\n\n> Run it on the client machine\n>\n> This step should be run on your Docker client machine. As such, you need to copy your CA certificate, your server certificate, and your client certificate to that machine.\n\n> **Note**: Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon’s host.\n\n``` \n$ docker --tlsverify \\\n    --tlscacert=ca.pem \\\n    --tlscert=cert.pem \\\n    --tlskey=key.pem \\\n    -H=$HOST:2376 version\n```\n\n> **Note**: Docker over TLS should run on TCP port 2376.\n\n> **Warning**: As shown in the example above, you don’t need to run the `docker` client with `sudo` or the `docker` group when you use certificate authentication. That means anyone with the keys can give any instructions to your Docker daemon, giving them root access to the machine hosting the daemon. Guard these keys as you would a root password!\n\n### Secure by default\n\nIf you want to secure your Docker client connections by default, you can move the files to the `.docker` directory in your home directory --- and set the `DOCKER_HOST` and `DOCKER_TLS_VERIFY` variables as well (instead of passing `-H=tcp://$HOST:2376` and `--tlsverify` on every call).\n\n``` \n$ mkdir -pv ~/.docker\n$ cp -v {ca,cert,key}.pem ~/.docker\n\n$ export DOCKER_HOST=tcp://$HOST:2376 DOCKER_TLS_VERIFY=1\n```\n\nDocker now connects securely by default:\n\n``` \n$ docker ps\n```\n\n### Other modes\n\nIf you don’t want to have complete two-way authentication, you can run Docker in various other modes by mixing the flags.\n\n#### Daemon modes\n\n- `tlsverify`, `tlscacert`, `tlscert`, `tlskey` set: Authenticate clients\n- `tls`, `tlscert`, `tlskey`: Do not authenticate clients\n\n#### Client modes\n\n- `tls`: Authenticate server based on public/default CA pool\n- `tlsverify`, `tlscacert`: Authenticate server based on given CA\n- `tls`, `tlscert`, `tlskey`: Authenticate with client certificate, do not authenticate server based on given CA\n- `tlsverify`, `tlscacert`, `tlscert`, `tlskey`: Authenticate with client certificate and authenticate server based on given CA\n\nIf found, the client sends its client certificate, so you just need to drop your keys into `~/.docker/{ca,cert,key}.pem`. Alternatively, if you want to store your keys in another location, you can specify that location using the environment variable `DOCKER_CERT_PATH`.\n\n``` \n$ export DOCKER_CERT_PATH=~/.docker/zone1/\n$ docker --tlsverify ps\n```\n\n#### Connecting to the secure Docker port using `curl`\n\nTo use `curl` to make test API requests, you need to use three extra command line flags:\n\n``` \n$ curl https://$HOST:2376/images/json \\\n  --cert ~/.docker/cert.pem \\\n  --key ~/.docker/key.pem \\\n  --cacert ~/.docker/ca.pem\n```\n\n## Related information\n\n- [Using certificates for repository client verification](../certificates/index)\n- [Use trusted images](../trust/index)\n\n[docker](https://docs.docker.com/search/?q=docker), [docs](https://docs.docker.com/search/?q=docs), [article](https://docs.docker.com/search/?q=article), [example](https://docs.docker.com/search/?q=example), [ssh](https://docs.docker.com/search/?q=ssh), [https](https://docs.docker.com/search/?q=https), [daemon](https://docs.docker.com/search/?q=daemon), [tls](https://docs.docker.com/search/?q=tls), [ca](https://docs.docker.com/search/?q=ca), [certificate](https://docs.docker.com/search/?q=certificate)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/protect-access/](https://docs.docker.com/engine/security/protect-access/)"
- name: Raft consensus in swarm mode
  id: engine/swarm/raft/index
  summary: When the Docker Engine runs in swarm mode, manager nodes implement the Raft Consensus Algorithm to manage the global cluster state
  description: "# Raft consensus in swarm mode\n\nWhen the Docker Engine runs in swarm mode, manager nodes implement the [Raft Consensus Algorithm](http://thesecretlivesofdata.com/raft/) to manage the global cluster state.\n\nThe reason why *Docker swarm mode* is using a consensus algorithm is to make sure that all the manager nodes that are in charge of managing and scheduling tasks in the cluster, are storing the same consistent state.\n\nHaving the same consistent state across the cluster means that in case of a failure, any Manager node can pick up the tasks and restore the services to a stable state. For example, if the *Leader Manager* which is responsible for scheduling tasks in the cluster dies unexpectedly, any other Manager can pick up the task of scheduling and re-balance tasks to match the desired state.\n\nSystems using consensus algorithms to replicate logs in a distributed systems do require special care. They ensure that the cluster state stays consistent in the presence of failures by requiring a majority of nodes to agree on values.\n\nRaft tolerates up to `(N-1)/2` failures and requires a majority or quorum of `(N/2)+1` members to agree on values proposed to the cluster. This means that in a cluster of 5 Managers running Raft, if 3 nodes are unavailable, the system cannot process any more requests to schedule additional tasks. The existing tasks keep running but the scheduler cannot rebalance tasks to cope with failures if the manager set is not healthy.\n\nThe implementation of the consensus algorithm in swarm mode means it features the properties inherent to distributed systems:\n\n- *agreement on values* in a fault tolerant system. (Refer to [FLP impossibility theorem](https://www.the-paper-trail.org/post/2008-08-13-a-brief-tour-of-flp-impossibility/) and the [Raft Consensus Algorithm paper](https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf))\n- *mutual exclusion* through the leader election process\n- *cluster membership* management\n- *globally consistent object sequencing* and CAS (compare-and-swap) primitives\n\n[docker](https://docs.docker.com/search/?q=docker), [container](https://docs.docker.com/search/?q=container), [cluster](https://docs.docker.com/search/?q=cluster), [swarm](https://docs.docker.com/search/?q=swarm), [raft](https://docs.docker.com/search/?q=raft)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/raft/](https://docs.docker.com/engine/swarm/raft/)"
- name: Run Docker Engine in swarm mode
  id: engine/swarm/swarm-mode/index
  summary: When you first install and start working with Docker Engine, swarm mode is disabled by default
  description: "# Run Docker Engine in swarm mode\n\nWhen you first install and start working with Docker Engine, swarm mode is disabled by default. When you enable swarm mode, you work with the concept of services managed through the `docker service` command.\n\nThere are two ways to run the Engine in swarm mode:\n\n- Create a new swarm, covered in this article.\n- [Join an existing swarm](../join-nodes/index).\n\nWhen you run the Engine in swarm mode on your local machine, you can create and test services based upon images you’ve created or other available images. In your production environment, swarm mode provides a fault-tolerant platform with cluster management features to keep your services running and available.\n\nThese instructions assume you have installed the Docker Engine 1.12 or later on a machine to serve as a manager node in your swarm.\n\nIf you haven’t already, read through the [swarm mode key concepts](../key-concepts/index) and try the [swarm mode tutorial](../swarm-tutorial/index).\n\n## Create a swarm\n\nWhen you run the command to create a swarm, the Docker Engine starts running in swarm mode.\n\nRun [`docker swarm init`](../../reference/commandline/swarm_init/index) to create a single-node swarm on the current node. The Engine sets up the swarm as follows:\n\n- switches the current node into swarm mode.\n- creates a swarm named `default`.\n- designates the current node as a leader manager node for the swarm.\n- names the node with the machine hostname.\n- configures the manager to listen on an active network interface on port 2377.\n- sets the current node to `Active` availability, meaning it can receive tasks from the scheduler.\n- starts an internal distributed data store for Engines participating in the swarm to maintain a consistent view of the swarm and all services running on it.\n- by default, generates a self-signed root CA for the swarm.\n- by default, generates tokens for worker and manager nodes to join the swarm.\n- creates an overlay network named `ingress` for publishing service ports external to the swarm.\n- creates an overlay default IP addresses and subnet mask for your networks\n\nThe output for `docker swarm init` provides the connection command to use when you join new worker nodes to the swarm:\n\n``` \n$ docker swarm init\nSwarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n    192.168.99.100:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n```\n\n### Configuring default address pools\n\nBy default Docker Swarm uses a default address pool `10.0.0.0/8` for global scope (overlay) networks. Every network that does not have a subnet specified will have a subnet sequentially allocated from this pool. In some circumstances it may be desirable to use a different default IP address pool for networks.\n\nFor example, if the default `10.0.0.0/8` range conflicts with already allocated address space in your network, then it is desirable to ensure that networks use a different range without requiring Swarm users to specify each subnet with the `--subnet` command.\n\nTo configure custom default address pools, you must define pools at Swarm initialization using the `--default-addr-pool` command line option. This command line option uses CIDR notation for defining the subnet mask. To create the custom address pool for Swarm, you must define at least one default address pool, and an optional default address pool subnet mask. For example, for the `10.0.0.0/27`, use the value `27`.\n\nDocker allocates subnet addresses from the address ranges specified by the `--default-addr-pool` option. For example, a command line option `--default-addr-pool 10.10.0.0/16` indicates that Docker will allocate subnets from that `/16` address range. If `--default-addr-pool-mask-len` were unspecified or set explicitly to 24, this would result in 256 `/24` networks of the form `10.10.X.0/24`.\n\nThe subnet range comes from the `--default-addr-pool`, (such as `10.10.0.0/16`). The size of 16 there represents the number of networks one can create within that `default-addr-pool` range. The `--default-addr-pool` option may occur multiple times with each option providing additional addresses for docker to use for overlay subnets.\n\nThe format of the command is:\n\n``` \n$ docker swarm init --default-addr-pool <IP range in CIDR> [--default-addr-pool <IP range in CIDR> --default-addr-pool-mask-length <CIDR value>]\n```\n\nTo create a default IP address pool with a /16 (class B) for the 10.20.0.0 network looks like this:\n\n``` \n$ docker swarm init --default-addr-pool 10.20.0.0/16\n```\n\nTo create a default IP address pool with a `/16` (class B) for the `10.20.0.0` and `10.30.0.0` networks, and to create a subnet mask of `/26` for each network looks like this:\n\n``` \n$ docker swarm init --default-addr-pool 10.20.0.0/16 --default-addr-pool 10.30.0.0/16 --default-addr-pool-mask-length 26\n```\n\nIn this example, `docker network create -d overlay net1` will result in `10.20.0.0/26` as the allocated subnet for `net1`, and `docker network create -d overlay net2` will result in `10.20.0.64/26` as the allocated subnet for `net2`. This continues until all the subnets are exhausted.\n\nRefer to the following pages for more information:\n\n- [Swarm networking](https://docs.docker.com/network/overlay) for more information about the default address pool usage\n- `docker swarm init` [CLI reference](../../reference/commandline/swarm_init/index) for more detail on the `--default-addr-pool` flag.\n\n### Configure the advertise address\n\nManager nodes use an advertise address to allow other nodes in the swarm access to the Swarmkit API and overlay networking. The other nodes on the swarm must be able to access the manager node on its advertise address.\n\nIf you don’t specify an advertise address, Docker checks if the system has a single IP address. If so, Docker uses the IP address with the listening port `2377` by default. If the system has multiple IP addresses, you must specify the correct `--advertise-addr` to enable inter-manager communication and overlay networking:\n\n``` \n$ docker swarm init --advertise-addr <MANAGER-IP>\n```\n\nYou must also specify the `--advertise-addr` if the address where other nodes reach the first manager node is not the same address the manager sees as its own. For instance, in a cloud setup that spans different regions, hosts have both internal addresses for access within the region and external addresses that you use for access from outside that region. In this case, specify the external address with `--advertise-addr` so that the node can propagate that information to other nodes that subsequently connect to it.\n\nRefer to the `docker swarm init` [CLI reference](../../reference/commandline/swarm_init/index) for more detail on the advertise address.\n\n### View the join command or update a swarm join token\n\nNodes require a secret token to join the swarm. The token for worker nodes is different from the token for manager nodes. Nodes only use the join-token at the moment they join the swarm. Rotating the join token after a node has already joined a swarm does not affect the node’s swarm membership. Token rotation ensures an old token cannot be used by any new nodes attempting to join the swarm.\n\nTo retrieve the join command including the join token for worker nodes, run:\n\n``` \n$ docker swarm join-token worker\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n    192.168.99.100:2377\n\nThis node joined a swarm as a worker.\n```\n\nTo view the join command and token for manager nodes, run:\n\n``` \n$ docker swarm join-token manager\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-59egwe8qangbzbqb3ryawxzk3jn97ifahlsrw01yar60pmkr90-bdjfnkcflhooyafetgjod97sz \\\n    192.168.99.100:2377\n```\n\nPass the `--quiet` flag to print only the token:\n\n``` \n$ docker swarm join-token --quiet worker\n\nSWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c\n```\n\nBe careful with the join tokens because they are the secrets necessary to join the swarm. In particular, checking a secret into version control is a bad practice because it would allow anyone with access to the application source code to add new nodes to the swarm. Manager tokens are especially sensitive because they allow a new manager node to join and gain control over the whole swarm.\n\nWe recommend that you rotate the join tokens in the following circumstances:\n\n- If a token was checked-in by accident into a version control system, group chat or accidentally printed to your logs.\n- If you suspect a node has been compromised.\n- If you wish to guarantee that no new nodes can join the swarm.\n\nAdditionally, it is a best practice to implement a regular rotation schedule for any secret including swarm join tokens. We recommend that you rotate your tokens at least every 6 months.\n\nRun `swarm join-token --rotate` to invalidate the old token and generate a new token. Specify whether you want to rotate the token for `worker` or `manager` nodes:\n\n``` \n$ docker swarm join-token  --rotate worker\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join \\\n    --token SWMTKN-1-2kscvs0zuymrsc9t0ocyy1rdns9dhaodvpl639j2bqx55uptag-ebmn5u927reawo27s3azntd44 \\\n    192.168.99.100:2377\n```\n\n## Learn more\n\n- [Join nodes to a swarm](../join-nodes/index)\n- `swarm init` [command line reference](../../reference/commandline/swarm_init/index)\n- [Swarm mode tutorial](../swarm-tutorial/index)\n\n[guide](https://docs.docker.com/search/?q=guide), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [node](https://docs.docker.com/search/?q=node)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-mode/](https://docs.docker.com/engine/swarm/swarm-mode/)"
- name: Run the Docker daemon as a non-root user (Rootless mode)
  id: engine/security/rootless/index
  summary: Rootless mode allows running the Docker daemon and containers as a non-root user to mitigate potential vulnerabilities in the daemon and the container runtime
  description: "# Run the Docker daemon as a non-root user (Rootless mode)\n\nRootless mode allows running the Docker daemon and containers as a non-root user to mitigate potential vulnerabilities in the daemon and the container runtime.\n\nRootless mode does not require root privileges even during the installation of the Docker daemon, as long as the [prerequisites](#prerequisites) are met.\n\nRootless mode was introduced in Docker Engine v19.03 as an experimental feature. Rootless mode graduated from experimental in Docker Engine v20.10.\n\n## How it works\n\nRootless mode executes the Docker daemon and containers inside a user namespace. This is very similar to [`userns-remap` mode](../userns-remap/index), except that with `userns-remap` mode, the daemon itself is running with root privileges, whereas in rootless mode, both the daemon and the container are running without root privileges.\n\nRootless mode does not use binaries with `SETUID` bits or file capabilities, except `newuidmap` and `newgidmap`, which are needed to allow multiple UIDs/GIDs to be used in the user namespace.\n\n## Prerequisites\n\n- You must install `newuidmap` and `newgidmap` on the host. These commands are provided by the `uidmap` package on most distros.\n\n- `/etc/subuid` and `/etc/subgid` should contain at least 65,536 subordinate UIDs/GIDs for the user. In the following example, the user `testuser` has 65,536 subordinate UIDs/GIDs (231072-296607).\n\n``` \n$ id -u\n1001\n$ whoami\ntestuser\n$ grep ^$(whoami): /etc/subuid\ntestuser:231072:65536\n$ grep ^$(whoami): /etc/subgid\ntestuser:231072:65536\n```\n\n### Distribution-specific hint\n\n> Note: We recommend that you use the Ubuntu kernel.\n\n- Ubuntu\n- Debian GNU/Linux\n- Arch Linux\n- openSUSE and SLES\n- CentOS 8, RHEL 8 and Fedora\n- CentOS 7 and RHEL 7\n\n- Install `dbus-user-session` package if not installed. Run `sudo apt-get install -y dbus-user-session` and relogin.\n\n- `overlay2` storage driver is enabled by default ([Ubuntu-specific kernel patch](https://kernel.ubuntu.com/git/ubuntu/ubuntu-bionic.git/commit/fs/overlayfs?id=3b7da90f28fe1ed4b79ef2d994c81efbc58f1144)).\n\n- Known to work on Ubuntu 18.04, 20.04, and 21.04.\n\n- Install `dbus-user-session` package if not installed. Run `sudo apt-get install -y dbus-user-session` and relogin.\n\n- For Debian 10, add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`. This step is not required on Debian 11.\n\n- Installing `fuse-overlayfs` is recommended. Run `sudo apt-get install -y fuse-overlayfs`. Using `overlay2` storage driver with Debian-specific modprobe option `sudo modprobe overlay permit_mounts_in_userns=1` is also possible, however, highly discouraged due to [instability](https://github.com/moby/moby/issues/42302).\n\n- Rootless docker requires version of `slirp4netns` greater than `v0.4.0` (when `vpnkit` is not installed). Check you have this with\n\n  ``` \n  $ slirp4netns --version\n  ```\n\n  If you do not have this download and install with `sudo apt-get install -y slirp4netns` or download the latest [release](https://github.com/rootless-containers/slirp4netns/releases).\n\n- Installing `fuse-overlayfs` is recommended. Run `sudo pacman -S fuse-overlayfs`.\n\n- Add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`\n\n- Installing `fuse-overlayfs` is recommended. Run `sudo zypper install -y fuse-overlayfs`.\n\n- `sudo modprobe ip_tables iptable_mangle iptable_nat iptable_filter` is required. This might be required on other distros as well depending on the configuration.\n\n- Known to work on openSUSE 15 and SLES 15.\n\n- Installing `fuse-overlayfs` is recommended. Run `sudo dnf install -y fuse-overlayfs`.\n\n- You might need `sudo dnf install -y iptables`.\n\n- Known to work on CentOS 8, RHEL 8, and Fedora 34.\n\n- Add `user.max_user_namespaces=28633` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n- `systemctl --user` does not work by default. Run `dockerd-rootless.sh` directly without systemd.\n\n## Known limitations\n\n- Only the following storage drivers are supported:\n  - `overlay2` (only if running with kernel 5.11 or later, or Ubuntu-flavored kernel)\n  - `fuse-overlayfs` (only if running with kernel 4.18 or later, and `fuse-overlayfs` is installed)\n  - `btrfs` (only if running with kernel 4.18 or later, or `~/.local/share/docker` is mounted with `user_subvol_rm_allowed` mount option)\n  - `vfs`\n- Cgroup is supported only when running with cgroup v2 and systemd. See [Limiting resources](#limiting-resources).\n- Following features are not supported:\n  - AppArmor\n  - Checkpoint\n  - Overlay network\n  - Exposing SCTP ports\n- To use the `ping` command, see [Routing ping packets](#routing-ping-packets).\n- To expose privileged TCP/UDP ports (\\< 1024), see [Exposing privileged ports](#exposing-privileged-ports).\n- `IPAddress` shown in `docker inspect` and is namespaced inside RootlessKit’s network namespace. This means the IP address is not reachable from the host without `nsenter`-ing into the network namespace.\n- Host network (`docker run --net=host`) is also namespaced inside RootlessKit.\n- NFS mounts as the docker “data-root” is not supported. This limitation is not specific to rootless mode.\n\n## Install\n\n> **Note**\n>\n> If the system-wide Docker daemon is already running, consider disabling it: `$ sudo systemctl disable --now docker.service docker.socket`\n\n- With packages (RPM/DEB)\n- Without packages\n\nIf you installed Docker 20.10 or later with [RPM/DEB packages](../../install/index), you should have `dockerd-rootless-setuptool.sh` in `/usr/bin`.\n\nRun `dockerd-rootless-setuptool.sh install` as a non-root user to set up the daemon:\n\n``` \n$ dockerd-rootless-setuptool.sh install\n[INFO] Creating /home/testuser/.config/systemd/user/docker.service\n...\n[INFO] Installed docker.service successfully.\n[INFO] To control docker.service, run: `systemctl --user (start|stop|restart) docker.service`\n[INFO] To run docker.service on system startup, run: `sudo loginctl enable-linger testuser`\n\n[INFO] Make sure the following environment variables are set (or add them to ~/.bashrc):\n\nexport PATH=/usr/bin:$PATH\nexport DOCKER_HOST=unix:///run/user/1000/docker.sock\n```\n\nIf `dockerd-rootless-setuptool.sh` is not present, you may need to install the `docker-ce-rootless-extras` package manually, e.g.,\n\n``` \n$ sudo apt-get install -y docker-ce-rootless-extras\n```\n\nIf you do not have permission to run package managers like `apt-get` and `dnf`, consider using the installation script available at [https://get.docker.com/rootless](https://get.docker.com/rootless). Since static packages are not available for `s390x`, hence it is not supported for `s390x`.\n\n``` \n$ curl -fsSL https://get.docker.com/rootless | sh\n...\n[INFO] Creating /home/testuser/.config/systemd/user/docker.service\n...\n[INFO] Installed docker.service successfully.\n[INFO] To control docker.service, run: `systemctl --user (start|stop|restart) docker.service`\n[INFO] To run docker.service on system startup, run: `sudo loginctl enable-linger testuser`\n\n[INFO] Make sure the following environment variables are set (or add them to ~/.bashrc):\n\nexport PATH=/home/testuser/bin:$PATH\nexport DOCKER_HOST=unix:///run/user/1000/docker.sock\n```\n\nThe binaries will be installed at `~/bin`.\n\nSee [Troubleshooting](#troubleshooting) if you faced an error.\n\n## Uninstall\n\nTo remove the systemd service of the Docker daemon, run `dockerd-rootless-setuptool.sh uninstall`:\n\n``` \n$ dockerd-rootless-setuptool.sh uninstall\n+ systemctl --user stop docker.service\n+ systemctl --user disable docker.service\nRemoved /home/testuser/.config/systemd/user/default.target.wants/docker.service.\n[INFO] Uninstalled docker.service\n[INFO] This uninstallation tool does NOT remove Docker binaries and data.\n[INFO] To remove data, run: `/usr/bin/rootlesskit rm -rf /home/testuser/.local/share/docker`\n```\n\nUnset environment variables PATH and DOCKER_HOST if you have added them to `~/.bashrc`.\n\nTo remove the data directory, run `rootlesskit rm -rf ~/.local/share/docker`.\n\nTo remove the binaries, remove `docker-ce-rootless-extras` package if you installed Docker with package managers. If you installed Docker with https://get.docker.com/rootless ([Install without packages](#install)), remove the binary files under `~/bin`:\n\n``` \n$ cd ~/bin\n$ rm -f containerd containerd-shim containerd-shim-runc-v2 ctr docker docker-init docker-proxy dockerd dockerd-rootless-setuptool.sh dockerd-rootless.sh rootlesskit rootlesskit-docker-proxy runc vpnkit\n```\n\n## Usage\n\n### Daemon\n\n- With systemd (Highly recommended)\n- Without systemd\n\nThe systemd unit file is installed as `~/.config/systemd/user/docker.service`.\n\nUse `systemctl --user` to manage the lifecycle of the daemon:\n\n``` \n$ systemctl --user start docker\n```\n\nTo launch the daemon on system startup, enable the systemd service and lingering:\n\n``` \n$ systemctl --user enable docker\n$ sudo loginctl enable-linger $(whoami)\n```\n\nStarting Rootless Docker as a systemd-wide service (`/etc/systemd/system/docker.service`) is not supported, even with the `User=` directive.\n\nTo run the daemon directly without systemd, you need to run `dockerd-rootless.sh` instead of `dockerd`.\n\nThe following environment variables must be set:\n\n- `$HOME`: the home directory\n- `$XDG_RUNTIME_DIR`: an ephemeral directory that is only accessible by the expected user, e,g, `~/.docker/run`. The directory should be removed on every host shutdown. The directory can be on tmpfs, however, should not be under `/tmp`. Locating this directory under `/tmp` might be vulnerable to TOCTOU attack.\n\nRemarks about directory paths:\n\n- The socket path is set to `$XDG_RUNTIME_DIR/docker.sock` by default. `$XDG_RUNTIME_DIR` is typically set to `/run/user/$UID`.\n- The data dir is set to `~/.local/share/docker` by default. The data dir should not be on NFS.\n- The daemon config dir is set to `~/.config/docker` by default. This directory is different from `~/.docker` that is used by the client.\n\n### Client\n\nYou need to specify either the socket path or the CLI context explicitly.\n\nTo specify the socket path using `$DOCKER_HOST`:\n\n``` \n$ export DOCKER_HOST=unix://$XDG_RUNTIME_DIR/docker.sock\n$ docker run -d -p 8080:80 nginx\n```\n\nTo specify the CLI context using `docker context`:\n\n``` \n$ docker context use rootless\nrootless\nCurrent context is now \"rootless\"\n$ docker run -d -p 8080:80 nginx\n```\n\n## Best practices\n\n### Rootless Docker in Docker\n\nTo run Rootless Docker inside “rootful” Docker, use the `docker:<version>-dind-rootless` image instead of `docker:<version>-dind`.\n\n``` \n$ docker run -d --name dind-rootless --privileged docker:20.10-dind-rootless\n```\n\nThe `docker:<version>-dind-rootless` image runs as a non-root user (UID 1000). However, `--privileged` is required for disabling seccomp, AppArmor, and mount masks.\n\n### Expose Docker API socket through TCP\n\nTo expose the Docker API socket through TCP, you need to launch `dockerd-rootless.sh` with `DOCKERD_ROOTLESS_ROOTLESSKIT_FLAGS=\"-p 0.0.0.0:2376:2376/tcp\"`.\n\n``` \n$ DOCKERD_ROOTLESS_ROOTLESSKIT_FLAGS=\"-p 0.0.0.0:2376:2376/tcp\" \\\n  dockerd-rootless.sh \\\n  -H tcp://0.0.0.0:2376 \\\n  --tlsverify --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem\n```\n\n### Expose Docker API socket through SSH\n\nTo expose the Docker API socket through SSH, you need to make sure `$DOCKER_HOST` is set on the remote host.\n\n``` \n$ ssh -l <REMOTEUSER> <REMOTEHOST> 'echo $DOCKER_HOST'\nunix:///run/user/1001/docker.sock\n$ docker -H ssh://<REMOTEUSER>@<REMOTEHOST> run ...\n```\n\n### Routing ping packets\n\nOn some distributions, `ping` does not work by default.\n\nAdd `net.ipv4.ping_group_range = 0 2147483647` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system` to allow using `ping`.\n\n### Exposing privileged ports\n\nTo expose privileged ports (\\< 1024), set `CAP_NET_BIND_SERVICE` on `rootlesskit` binary and restart the daemon.\n\n``` \n$ sudo setcap cap_net_bind_service=ep $(which rootlesskit)\n$ systemctl --user restart docker\n```\n\nOr add `net.ipv4.ip_unprivileged_port_start=0` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n### Limiting resources\n\nLimiting resources with cgroup-related `docker run` flags such as `--cpus`, `--memory`, `--pids-limit` is supported only when running with cgroup v2 and systemd. See [Changing cgroup version](https://docs.docker.com/config/containers/runmetrics/) to enable cgroup v2.\n\nIf `docker info` shows `none` as `Cgroup Driver`, the conditions are not satisfied. When these conditions are not satisfied, rootless mode ignores the cgroup-related `docker run` flags. See [Limiting resources without cgroup](#limiting-resources-without-cgroup) for workarounds.\n\nIf `docker info` shows `systemd` as `Cgroup Driver`, the conditions are satisfied. However, typically, only `memory` and `pids` controllers are delegated to non-root users by default.\n\n``` \n$ cat /sys/fs/cgroup/user.slice/user-$(id -u).slice/user@$(id -u).service/cgroup.controllers\nmemory pids\n```\n\nTo allow delegation of all controllers, you need to change the systemd configuration as follows:\n\n``` \n# mkdir -p /etc/systemd/system/user@.service.d\n# cat > /etc/systemd/system/user@.service.d/delegate.conf << EOF\n[Service]\nDelegate=cpu cpuset io memory pids\nEOF\n# systemctl daemon-reload\n```\n\n> **Note**\n>\n> Delegating `cpuset` requires systemd 244 or later.\n\n#### Limiting resources without cgroup\n\nEven when cgroup is not available, you can still use the traditional `ulimit` and [`cpulimit`](https://github.com/opsengine/cpulimit), though they work in process-granularity rather than in container-granularity, and can be arbitrarily disabled by the container process.\n\nFor example:\n\n- To limit CPU usage to 0.5 cores (similar to `docker run --cpus 0.5`): `docker run <IMAGE> cpulimit --limit=50 --include-children <COMMAND>`\n\n- To limit max VSZ to 64MiB (similar to `docker run --memory 64m`): `docker run <IMAGE> sh -c \"ulimit -v 65536; <COMMAND>\"`\n\n- To limit max number of processes to 100 per namespaced UID 2000 (similar to `docker run --pids-limit=100`): `docker run --user 2000 --ulimit nproc=100 <IMAGE> <COMMAND>`\n\n## Troubleshooting\n\n### Errors when starting the Docker daemon\n\n**\\[rootlesskit:parent\\] error: failed to start the child: fork/exec /proc/self/exe: operation not permitted**\n\nThis error occurs mostly when the value of `/proc/sys/kernel/unprivileged_userns_clone` is set to 0:\n\n``` \n$ cat /proc/sys/kernel/unprivileged_userns_clone\n0\n```\n\nTo fix this issue, add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n**\\[rootlesskit:parent\\] error: failed to start the child: fork/exec /proc/self/exe: no space left on device**\n\nThis error occurs mostly when the value of `/proc/sys/user/max_user_namespaces` is too small:\n\n``` \n$ cat /proc/sys/user/max_user_namespaces\n0\n```\n\nTo fix this issue, add `user.max_user_namespaces=28633` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n**\\[rootlesskit:parent\\] error: failed to setup UID/GID map: failed to compute uid/gid map: No subuid ranges found for user 1001 (“testuser”)**\n\nThis error occurs when `/etc/subuid` and `/etc/subgid` are not configured. See [Prerequisites](#prerequisites).\n\n**could not get XDG_RUNTIME_DIR**\n\nThis error occurs when `$XDG_RUNTIME_DIR` is not set.\n\nOn a non-systemd host, you need to create a directory and then set the path:\n\n``` \n$ export XDG_RUNTIME_DIR=$HOME/.docker/xrd\n$ rm -rf $XDG_RUNTIME_DIR\n$ mkdir -p $XDG_RUNTIME_DIR\n$ dockerd-rootless.sh\n```\n\n> **Note**: You must remove the directory every time you log out.\n\nOn a systemd host, log into the host using `pam_systemd` (see below). The value is automatically set to `/run/user/$UID` and cleaned up on every logout.\n\n**`systemctl --user` fails with “Failed to connect to bus: No such file or directory”**\n\nThis error occurs mostly when you switch from the root user to an non-root user with `sudo`:\n\n``` \n# sudo -iu testuser\n$ systemctl --user start docker\nFailed to connect to bus: No such file or directory\n```\n\nInstead of `sudo -iu <USERNAME>`, you need to log in using `pam_systemd`. For example:\n\n- Log in through the graphic console\n- `ssh <USERNAME>@localhost`\n- `machinectl shell <USERNAME>@`\n\n**The daemon does not start up automatically**\n\nYou need `sudo loginctl enable-linger $(whoami)` to enable the daemon to start up automatically. See [Usage](#usage).\n\n**iptables failed: iptables -t nat -N DOCKER: Fatal: can’t open lock file /run/xtables.lock: Permission denied**\n\nThis error may happen with an older version of Docker when SELinux is enabled on the host.\n\nThe issue has been fixed in Docker 20.10.8. A known workaround for older version of Docker is to run the following commands to disable SELinux for `iptables`:\n\n``` \n$ sudo dnf install -y policycoreutils-python-utils && sudo semanage permissive -a iptables_t\n```\n\n### `docker pull` errors\n\n**docker: failed to register layer: Error processing tar file(exit status 1): lchown \\<FILE\\>: invalid argument**\n\nThis error occurs when the number of available entries in `/etc/subuid` or `/etc/subgid` is not sufficient. The number of entries required vary across images. However, 65,536 entries are sufficient for most images. See [Prerequisites](#prerequisites).\n\n**docker: failed to register layer: ApplyLayer exit status 1 stdout: stderr: lchown \\<FILE\\>: operation not permitted**\n\nThis error occurs mostly when `~/.local/share/docker` is located on NFS.\n\nA workaround is to specify non-NFS `data-root` directory in `~/.config/docker/daemon.json` as follows:\n\n``` \n{\"data-root\":\"/somewhere-out-of-nfs\"}\n```\n\n### `docker run` errors\n\n**docker: Error response from daemon: OCI runtime create failed: ...: read unix @-\\>/run/systemd/private: read: connection reset by peer: unknown.**\n\nThis error occurs on cgroup v2 hosts mostly when the dbus daemon is not running for the user.\n\n``` \n$ systemctl --user is-active dbus\ninactive\n\n$ docker run hello-world\ndocker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:385: applying cgroup configuration for process caused: error while starting unit \"docker\n-931c15729b5a968ce803784d04c7421f791d87e5ca1891f34387bb9f694c488e.scope\" with properties [{Name:Description Value:\"libcontainer container 931c15729b5a968ce803784d04c7421f791d87e5ca1891f34387bb9f694c488e\"} {Name:Slice Value:\"use\nr.slice\"} {Name:PIDs Value:@au [4529]} {Name:Delegate Value:true} {Name:MemoryAccounting Value:true} {Name:CPUAccounting Value:true} {Name:IOAccounting Value:true} {Name:TasksAccounting Value:true} {Name:DefaultDependencies Val\nue:false}]: read unix @->/run/systemd/private: read: connection reset by peer: unknown.\n```\n\nTo fix the issue, run `sudo apt-get install -y dbus-user-session` or `sudo dnf install -y dbus-daemon`, and then relogin.\n\nIf the error still occurs, try running `systemctl --user enable --now dbus` (without sudo).\n\n**`--cpus`, `--memory`, and `--pids-limit` are ignored**\n\nThis is an expected behavior on cgroup v1 mode. To use these flags, the host needs to be configured for enabling cgroup v2. For more information, see [Limiting resources](#limiting-resources).\n\n### Networking errors\n\n**`docker run -p` fails with `cannot expose privileged port`**\n\n`docker run -p` fails with this error when a privileged port (\\< 1024) is specified as the host port.\n\n``` \n$ docker run -p 80:80 nginx:alpine\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint focused_swanson (9e2e139a9d8fc92b37c36edfa6214a6e986fa2028c0cc359812f685173fa6df7): Error starting userland proxy: error while calling PortManager.AddPort(): cannot expose privileged port 80, you might need to add \"net.ipv4.ip_unprivileged_port_start=0\" (currently 1024) to /etc/sysctl.conf, or set CAP_NET_BIND_SERVICE on rootlesskit binary, or choose a larger port number (>= 1024): listen tcp 0.0.0.0:80: bind: permission denied.\n```\n\nWhen you experience this error, consider using an unprivileged port instead. For example, 8080 instead of 80.\n\n``` \n$ docker run -p 8080:80 nginx:alpine\n```\n\nTo allow exposing privileged ports, see [Exposing privileged ports](#exposing-privileged-ports).\n\n**ping doesn’t work**\n\nPing does not work when `/proc/sys/net/ipv4/ping_group_range` is set to `1 0`:\n\n``` \n$ cat /proc/sys/net/ipv4/ping_group_range\n1       0\n```\n\nFor details, see [Routing ping packets](#routing-ping-packets).\n\n**`IPAddress` shown in `docker inspect` is unreachable**\n\nThis is an expected behavior, as the daemon is namespaced inside RootlessKit’s network namespace. Use `docker run -p` instead.\n\n**`--net=host` doesn’t listen ports on the host network namespace**\n\nThis is an expected behavior, as the daemon is namespaced inside RootlessKit’s network namespace. Use `docker run -p` instead.\n\n**Network is slow**\n\nDocker with rootless mode uses [slirp4netns](https://github.com/rootless-containers/slirp4netns) as the default network stack if slirp4netns v0.4.0 or later is installed. If slirp4netns is not installed, Docker falls back to [VPNKit](https://github.com/moby/vpnkit).\n\nInstalling slirp4netns may improve the network throughput. See [RootlessKit documentation](https://github.com/rootless-containers/rootlesskit/tree/v0.13.0#network-drivers) for the benchmark result.\n\nAlso, changing MTU value may improve the throughput. The MTU value can be specified by creating `~/.config/systemd/user/docker.service.d/override.conf` with the following content:\n\n``` \n[Service]\nEnvironment=\"DOCKERD_ROOTLESS_ROOTLESSKIT_MTU=<INTEGER>\"\n```\n\nAnd then restart the daemon:\n\n``` \n$ systemctl --user daemon-reload\n$ systemctl --user restart docker\n```\n\n**`docker run -p` does not propagate source IP addresses**\n\nThis is because Docker with rootless mode uses RootlessKit’s builtin port driver by default.\n\nThe source IP addresses can be propagated by creating `~/.config/systemd/user/docker.service.d/override.conf` with the following content:\n\n``` \n[Service]\nEnvironment=\"DOCKERD_ROOTLESS_ROOTLESSKIT_PORT_DRIVER=slirp4netns\"\n```\n\nAnd then restart the daemon:\n\n``` \n$ systemctl --user daemon-reload\n$ systemctl --user restart docker\n```\n\nNote that this configuration decreases throughput. See [RootlessKit documentation](https://github.com/rootless-containers/rootlesskit/tree/v0.13.0#port-drivers) for the benchmark result.\n\n### Tips for debugging\n\n**Entering into `dockerd` namespaces**\n\nThe `dockerd-rootless.sh` script executes `dockerd` in its own user, mount, and network namespaces.\n\nFor debugging, you can enter the namespaces by running `nsenter -U --preserve-credentials -n -m -t $(cat $XDG_RUNTIME_DIR/docker.pid)`.\n\n[security](https://docs.docker.com/search/?q=security), [namespaces](https://docs.docker.com/search/?q=namespaces), [rootless](https://docs.docker.com/search/?q=rootless)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/rootless/](https://docs.docker.com/engine/security/rootless/)"
- name: Sample application
  id: get-started/02_our_app/index
  summary: For the rest of this tutorial, we will be working with a simple todo list manager that is running in Node.js
  description: "# Sample application\n\nFor the rest of this tutorial, we will be working with a simple todo list manager that is running in Node.js. If you’re not familiar with Node.js, don’t worry. No real JavaScript experience is needed.\n\nAt this point, your development team is quite small and you’re simply building an app to prove out your MVP (minimum viable product). You want to show how it works and what it’s capable of doing without needing to think about how it will work for a large team, multiple developers, etc.\n\n## Get the app\n\nBefore we can run the application, we need to get the application source code onto our machine. For real projects, you will typically clone the repo. But, for this tutorial, we have created a ZIP file containing the application.\n\n1.  [Download the App contents](https://github.com/docker/getting-started/tree/master/app). You can either pull the entire project or download it as a zip and extract the app folder out to get started with.\n\n2.  Once extracted, use your favorite code editor to open the project. If you’re in need of an editor, you can use [Visual Studio Code](https://code.visualstudio.com/). You should see the `package.json` and two subdirectories (`src` and `spec`).\n\n## Build the app’s container image\n\nIn order to build the application, we need to use a `Dockerfile`. A Dockerfile is simply a text-based script of instructions that is used to create a container image. If you’ve created Dockerfiles before, you might see a few flaws in the Dockerfile below. But, don’t worry. We’ll go over them.\n\n1.  Create a file named `Dockerfile` in the same folder as the file `package.json` with the following contents.\n\n    ``` \n    # syntax=docker/dockerfile:1\n    FROM node:12-alpine\n    RUN apk add --no-cache python2 g++ make\n    WORKDIR /app\n    COPY . .\n    RUN yarn install --production\n    CMD [\"node\", \"src/index.js\"]\n    EXPOSE 3000\n    ```\n\n    Please check that the file `Dockerfile` has no file extension like `.txt`. Some editors may append this file extension automatically and this would result in an error in the next step.\n\n2.  If you haven’t already done so, open a terminal and go to the `app` directory with the `Dockerfile`. Now build the container image using the `docker build` command.\n\n    ``` \n    $ docker build -t getting-started .\n    ```\n\n    This command used the Dockerfile to build a new container image. You might have noticed that a lot of “layers” were downloaded. This is because we instructed the builder that we wanted to start from the `node:12-alpine` image. But, since we didn’t have that on our machine, that image needed to be downloaded.\n\n    After the image was downloaded, we copied in our application and used `yarn` to install our application’s dependencies. The `CMD` directive specifies the default command to run when starting a container from this image.\n\n    Finally, the `-t` flag tags our image. Think of this simply as a human-readable name for the final image. Since we named the image `getting-started`, we can refer to that image when we run a container.\n\n    The `.` at the end of the `docker build` command tells Docker that it should look for the `Dockerfile` in the current directory.\n\n## Start an app container\n\nNow that we have an image, let’s run the application. To do so, we will use the `docker run` command (remember that from earlier?).\n\n1.  Start your container using the `docker run` command and specify the name of the image we just created:\n\n    ``` \n    $ docker run -dp 3000:3000 getting-started\n    ```\n\n    Remember the `-d` and `-p` flags? We’re running the new container in “detached” mode (in the background) and creating a mapping between the host’s port 3000 to the container’s port 3000. Without the port mapping, we wouldn’t be able to access the application.\n\n2.  After a few seconds, open your web browser to <http://localhost:3000>. You should see our app.\n\n3.  Go ahead and add an item or two and see that it works as you expect. You can mark items as complete and remove items. Your frontend is successfully storing items in the backend. Pretty quick and easy, huh?\n\nAt this point, you should have a running todo list manager with a few items, all built by you. Now, let’s make a few changes and learn about managing our containers.\n\nIf you take a quick look at the Docker Dashboard, you should see your two containers running now (this tutorial and your freshly launched app container).\n\n## Recap\n\nIn this short section, we learned the very basics about building a container image and created a Dockerfile to do so. Once we built an image, we started the container and saw the running app.\n\nNext, we’re going to make a modification to our app and learn how to update our running application with a new image. Along the way, we’ll learn a few other useful commands.\n\n[get started](https://docs.docker.com/search/?q=get%20started), [setup](https://docs.docker.com/search/?q=setup), [orientation](https://docs.docker.com/search/?q=orientation), [quickstart](https://docs.docker.com/search/?q=quickstart), [intro](https://docs.docker.com/search/?q=intro), [concepts](https://docs.docker.com/search/?q=concepts), [containers](https://docs.docker.com/search/?q=containers), [docker desktop](https://docs.docker.com/search/?q=docker%20desktop)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/02_our_app/](https://docs.docker.com/get-started/02_our_app/)"
- name: Sample apps with Compose
  id: compose/samples-for-compose/index
  summary: The following samples show the various aspects of how to work with Docker Compose
  description: "# Sample apps with Compose\n\nThe following samples show the various aspects of how to work with Docker Compose. As a prerequisite, be sure to [install Docker Compose](../install/index) if you have not already done so.\n\n## Key concepts these samples cover\n\nThe samples should help you to:\n\n- define services based on Docker images using [Compose files](../compose-file/index) `docker-compose.yml` and `docker-stack.yml` files\n- understand the relationship between `docker-compose.yml` and [Dockerfiles](../../engine/reference/builder/index)\n- learn how to make calls to your application services from Compose files\n- learn how to deploy applications and services to a [swarm](../../engine/swarm/index)\n\n## Samples tailored to demo Compose\n\nThese samples focus specifically on Docker Compose:\n\n- [Quickstart: Compose and Django](https://docs.docker.com/samples/django/) - Shows how to use Docker Compose to set up and run a simple Django/PostgreSQL app.\n\n- [Quickstart: Compose and Rails](https://docs.docker.com/samples/rails/) - Shows how to use Docker Compose to set up and run a Rails/PostgreSQL app.\n\n- [Quickstart: Compose and WordPress](https://docs.docker.com/samples/wordpress/) - Shows how to use Docker Compose to set up and run WordPress in an isolated environment with Docker containers.\n\n## Awesome Compose samples\n\nThe Awesome Compose samples provide a starting point on how to integrate different frameworks and technologies using Docker Compose. All samples are available in the [Awesome-compose GitHub repo](https://github.com/docker/awesome-compose).\n\n[documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs), [docker](https://docs.docker.com/search/?q=docker), [compose](https://docs.docker.com/search/?q=compose), [samples](https://docs.docker.com/search/?q=samples)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/samples-for-compose/](https://docs.docker.com/compose/samples-for-compose/)"
- name: Scale the service in the swarm
  id: engine/swarm/swarm-tutorial/scale-service/index
  summary: Once you have deployed a service to a swarm, you are ready to use the Docker CLI to scale the number of containers in the service
  description: "# Scale the service in the swarm\n\nOnce you have [deployed a service](../deploy-service/index) to a swarm, you are ready to use the Docker CLI to scale the number of containers in the service. Containers running in a service are called “tasks.”\n\n1.  If you haven’t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n\n2.  Run the following command to change the desired state of the service running in the swarm:\n\n    ``` \n    $ docker service scale <SERVICE-ID>=<NUMBER-OF-TASKS>\n    ```\n\n    For example:\n\n    ``` \n    $ docker service scale helloworld=5\n\n    helloworld scaled to 5\n    ```\n\n3.  Run `docker service ps <SERVICE-ID>` to see the updated task list:\n\n    ``` \n    $ docker service ps helloworld\n\n    NAME                                    IMAGE   NODE      DESIRED STATE  CURRENT STATE\n    helloworld.1.8p1vev3fq5zm0mi8g0as41w35  alpine  worker2   Running        Running 7 minutes\n    helloworld.2.c7a7tcdq5s0uk3qr88mf8xco6  alpine  worker1   Running        Running 24 seconds\n    helloworld.3.6crl09vdcalvtfehfh69ogfb1  alpine  worker1   Running        Running 24 seconds\n    helloworld.4.auky6trawmdlcne8ad8phb0f1  alpine  manager1  Running        Running 24 seconds\n    helloworld.5.ba19kca06l18zujfwxyc5lkyn  alpine  worker2   Running        Running 24 seconds\n    ```\n\n    You can see that swarm has created 4 new tasks to scale to a total of 5 running instances of Alpine Linux. The tasks are distributed between the three nodes of the swarm. One is running on `manager1`.\n\n4.  Run `docker ps` to see the containers running on the node where you’re connected. The following example shows the tasks running on `manager1`:\n\n    ``` \n    $ docker ps\n\n    CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n    528d68040f95        alpine:latest       \"ping docker.com\"   About a minute ago   Up About a minute                       helloworld.4.auky6trawmdlcne8ad8phb0f1\n    ```\n\n    If you want to see the containers running on other nodes, ssh into those nodes and run the `docker ps` command.\n\n## What’s next?\n\nAt this point in the tutorial, you’re finished with the `helloworld` service. The next step shows how to [delete the service](../delete-service/index).\n\n[tutorial](https://docs.docker.com/search/?q=tutorial), [cluster management](https://docs.docker.com/search/?q=cluster%20management), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [scale](https://docs.docker.com/search/?q=scale)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/](https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/)"
- name: Seccomp security profiles for Docker
  id: engine/security/seccomp/index
  summary: Secure computing mode (seccomp) is a Linux kernel feature
  description: "# Seccomp security profiles for Docker\n\nSecure computing mode (`seccomp`) is a Linux kernel feature. You can use it to restrict the actions available within the container. The `seccomp()` system call operates on the seccomp state of the calling process. You can use this feature to restrict your application’s access.\n\nThis feature is available only if Docker has been built with `seccomp` and the kernel is configured with `CONFIG_SECCOMP` enabled. To check if your kernel supports `seccomp`:\n\n``` \n$ grep CONFIG_SECCOMP= /boot/config-$(uname -r)\nCONFIG_SECCOMP=y\n```\n\n## Pass a profile for a container\n\nThe default `seccomp` profile provides a sane default for running containers with seccomp and disables around 44 system calls out of 300+. It is moderately protective while providing wide application compatibility. The default Docker profile can be found [here](https://github.com/moby/moby/blob/master/profiles/seccomp/default.json).\n\nIn effect, the profile is a allowlist which denies access to system calls by default, then allowlists specific system calls. The profile works by defining a `defaultAction` of `SCMP_ACT_ERRNO` and overriding that action only for specific system calls. The effect of `SCMP_ACT_ERRNO` is to cause a `Permission Denied` error. Next, the profile defines a specific list of system calls which are fully allowed, because their `action` is overridden to be `SCMP_ACT_ALLOW`. Finally, some specific rules are for individual system calls such as `personality`, and others, to allow variants of those system calls with specific arguments.\n\n`seccomp` is instrumental for running Docker containers with least privilege. It is not recommended to change the default `seccomp` profile.\n\nWhen you run a container, it uses the default profile unless you override it with the `--security-opt` option. For example, the following explicitly specifies a policy:\n\n``` \n$ docker run --rm \\\n             -it \\\n             --security-opt seccomp=/path/to/seccomp/profile.json \\\n             hello-world\n```\n\n### Significant syscalls blocked by the default profile\n\nDocker’s default seccomp profile is an allowlist which specifies the calls that are allowed. The table below lists the significant (but not all) syscalls that are effectively blocked because they are not on the Allowlist. The table includes the reason each syscall is blocked rather than white-listed.\n\n| Syscall             | Description                                                                                                                                                                                                                                    |\n|---------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `acct`              | Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_PACCT`.                                                                                                          |\n| `add_key`           | Prevent containers from using the kernel keyring, which is not namespaced.                                                                                                                                                                     |\n| `bpf`               | Deny loading potentially persistent bpf programs into kernel, already gated by `CAP_SYS_ADMIN`.                                                                                                                                                |\n| `clock_adjtime`     | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.                                                                                                                                                                                     |\n| `clock_settime`     | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.                                                                                                                                                                                     |\n| `clone`             | Deny cloning new namespaces. Also gated by `CAP_SYS_ADMIN` for CLONE\\_\\* flags, except `CLONE_NEWUSER`.                                                                                                                                        |\n| `create_module`     | Deny manipulation and functions on kernel modules. Obsolete. Also gated by `CAP_SYS_MODULE`.                                                                                                                                                   |\n| `delete_module`     | Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.                                                                                                                                                             |\n| `finit_module`      | Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.                                                                                                                                                             |\n| `get_kernel_syms`   | Deny retrieval of exported kernel and module symbols. Obsolete.                                                                                                                                                                                |\n| `get_mempolicy`     | Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.                                                                                                                                                        |\n| `init_module`       | Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.                                                                                                                                                             |\n| `ioperm`            | Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`.                                                                                                                                               |\n| `iopl`              | Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`.                                                                                                                                               |\n| `kcmp`              | Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.                                                                                                                                                        |\n| `kexec_file_load`   | Sister syscall of `kexec_load` that does the same thing, slightly different arguments. Also gated by `CAP_SYS_BOOT`.                                                                                                                           |\n| `kexec_load`        | Deny loading a new kernel for later execution. Also gated by `CAP_SYS_BOOT`.                                                                                                                                                                   |\n| `keyctl`            | Prevent containers from using the kernel keyring, which is not namespaced.                                                                                                                                                                     |\n| `lookup_dcookie`    | Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                   |\n| `mbind`             | Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.                                                                                                                                                        |\n| `mount`             | Deny mounting, already gated by `CAP_SYS_ADMIN`.                                                                                                                                                                                               |\n| `move_pages`        | Syscall that modifies kernel memory and NUMA settings.                                                                                                                                                                                         |\n| `name_to_handle_at` | Sister syscall to `open_by_handle_at`. Already gated by `CAP_DAC_READ_SEARCH`.                                                                                                                                                                 |\n| `nfsservctl`        | Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1.                                                                                                                                                                         |\n| `open_by_handle_at` | Cause of an old container breakout. Also gated by `CAP_DAC_READ_SEARCH`.                                                                                                                                                                       |\n| `perf_event_open`   | Tracing/profiling syscall, which could leak a lot of information on the host.                                                                                                                                                                  |\n| `personality`       | Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns.                                                                                                               |\n| `pivot_root`        | Deny `pivot_root`, should be privileged operation.                                                                                                                                                                                             |\n| `process_vm_readv`  | Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.                                                                                                                                                        |\n| `process_vm_writev` | Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.                                                                                                                                                        |\n| `ptrace`            | Tracing/profiling syscall. Blocked in Linux kernel versions before 4.8 to avoid seccomp bypass. Tracing/profiling arbitrary processes is already blocked by dropping `CAP_SYS_PTRACE`, because it could leak a lot of information on the host. |\n| `query_module`      | Deny manipulation and functions on kernel modules. Obsolete.                                                                                                                                                                                   |\n| `quotactl`          | Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_ADMIN`.                                                                                                               |\n| `reboot`            | Don’t let containers reboot the host. Also gated by `CAP_SYS_BOOT`.                                                                                                                                                                            |\n| `request_key`       | Prevent containers from using the kernel keyring, which is not namespaced.                                                                                                                                                                     |\n| `set_mempolicy`     | Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.                                                                                                                                                        |\n| `setns`             | Deny associating a thread with a namespace. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                     |\n| `settimeofday`      | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.                                                                                                                                                                                     |\n| `stime`             | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.                                                                                                                                                                                     |\n| `swapon`            | Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                        |\n| `swapoff`           | Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                        |\n| `sysfs`             | Obsolete syscall.                                                                                                                                                                                                                              |\n| `_sysctl`           | Obsolete, replaced by /proc/sys.                                                                                                                                                                                                               |\n| `umount`            | Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                               |\n| `umount2`           | Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                               |\n| `unshare`           | Deny cloning new namespaces for processes. Also gated by `CAP_SYS_ADMIN`, with the exception of `unshare --user`.                                                                                                                              |\n| `uselib`            | Older syscall related to shared libraries, unused for a long time.                                                                                                                                                                             |\n| `userfaultfd`       | Userspace page fault handling, largely needed for process migration.                                                                                                                                                                           |\n| `ustat`             | Obsolete syscall.                                                                                                                                                                                                                              |\n| `vm86`              | In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                        |\n| `vm86old`           | In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`.                                                                                                                                                                        |\n\n## Run without the default seccomp profile\n\nYou can pass `unconfined` to run a container without the default seccomp profile.\n\n``` \n$ docker run --rm -it --security-opt seccomp=unconfined debian:jessie \\\n    unshare --map-root-user --user sh -c whoami\n```\n\n[seccomp](https://docs.docker.com/search/?q=seccomp), [security](https://docs.docker.com/search/?q=security), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/seccomp/](https://docs.docker.com/engine/security/seccomp/)"
- name: Share Compose configurations between files and projects
  id: compose/extends/index
  summary: Using multiple Compose files enables you to customize a Compose application for different environments or different workflows
  description: "# Share Compose configurations between files and projects\n\nCompose supports two methods of sharing common configuration:\n\n1.  Extending an entire Compose file by [using multiple Compose files](index#multiple-compose-files)\n2.  Extending individual services with [the `extends` field](index#extending-services) (for Compose file versions up to 2.1)\n\n## Multiple Compose files\n\nUsing multiple Compose files enables you to customize a Compose application for different environments or different workflows.\n\n### Understanding multiple Compose files\n\nBy default, Compose reads two files, a `docker-compose.yml` and an optional `docker-compose.override.yml` file. By convention, the `docker-compose.yml` contains your base configuration. The override file, as its name implies, can contain configuration overrides for existing services or entirely new services.\n\nIf a service is defined in both files, Compose merges the configurations using the rules described in [Adding and overriding configuration](index#adding-and-overriding-configuration).\n\nTo use multiple override files, or an override file with a different name, you can use the `-f` option to specify the list of files. Compose merges files in the order they’re specified on the command line. See the [`docker-compose` command reference](../reference/index) for more information about using `-f`.\n\nWhen you use multiple configuration files, you must make sure all paths in the files are relative to the base Compose file (the first Compose file specified with `-f`). This is required because override files need not be valid Compose files. Override files can contain small fragments of configuration. Tracking which fragment of a service is relative to which path is difficult and confusing, so to keep paths easier to understand, all paths must be defined relative to the base file.\n\n### Example use case\n\nIn this section, there are two common use cases for multiple Compose files: changing a Compose app for different environments, and running administrative tasks against a Compose app.\n\n#### Different environments\n\nA common use case for multiple files is changing a development Compose app for a production-like environment (which may be production, staging or CI). To support these differences, you can split your Compose configuration into a few different files:\n\nStart with a base file that defines the canonical configuration for the services.\n\n**docker-compose.yml**\n\n``` \nweb:\n  image: example/my_web_app:latest\n  depends_on:\n    - db\n    - cache\n\ndb:\n  image: postgres:latest\n\ncache:\n  image: redis:latest\n```\n\nIn this example the development configuration exposes some ports to the host, mounts our code as a volume, and builds the web image.\n\n**docker-compose.override.yml**\n\n``` \nweb:\n  build: .\n  volumes:\n    - '.:/code'\n  ports:\n    - 8883:80\n  environment:\n    DEBUG: 'true'\n\ndb:\n  command: '-d'\n  ports:\n    - 5432:5432\n\ncache:\n  ports:\n    - 6379:6379\n```\n\nWhen you run `docker-compose up` it reads the overrides automatically.\n\nNow, it would be nice to use this Compose app in a production environment. So, create another override file (which might be stored in a different git repo or managed by a different team).\n\n**docker-compose.prod.yml**\n\n``` \nweb:\n  ports:\n    - 80:80\n  environment:\n    PRODUCTION: 'true'\n\ncache:\n  environment:\n    TTL: '500'\n```\n\nTo deploy with this production Compose file you can run\n\n``` \n$ docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n```\n\nThis deploys all three services using the configuration in `docker-compose.yml` and `docker-compose.prod.yml` (but not the dev configuration in `docker-compose.override.yml`).\n\nSee [production](../production/index) for more information about Compose in production.\n\n#### Administrative tasks\n\nAnother common use case is running adhoc or administrative tasks against one or more services in a Compose app. This example demonstrates running a database backup.\n\nStart with a **docker-compose.yml**.\n\n``` \nweb:\n  image: example/my_web_app:latest\n  depends_on:\n    - db\n\ndb:\n  image: postgres:latest\n```\n\nIn a **docker-compose.admin.yml** add a new service to run the database export or backup.\n\n``` \n    dbadmin:\n      build: database_admin/\n      depends_on:\n        - db\n```\n\nTo start a normal environment run `docker-compose up -d`. To run a database backup, include the `docker-compose.admin.yml` as well.\n\n``` \n$ docker-compose -f docker-compose.yml -f docker-compose.admin.yml \\\n  run dbadmin db-backup\n```\n\n## Extending services\n\n> **Note**\n>\n> The `extends` keyword is supported in earlier Compose file formats up to Compose file version 2.1 (see [extends in v2](../compose-file/compose-file-v2/index#extends)), but is not supported in Compose version 3.x. See the [Version 3 summary](../compose-file/compose-versioning/index#version-3) of keys added and removed, along with information on [how to upgrade](../compose-file/compose-versioning/index#upgrading). See [moby/moby#31101](https://github.com/moby/moby/issues/31101) to follow the discussion thread on the possibility of adding support for `extends` in some form in future versions. The `extends` keyword has been included in docker-compose versions 1.27 and higher.\n\nDocker Compose’s `extends` keyword enables the sharing of common configurations among different files, or even different projects entirely. Extending services is useful if you have several services that reuse a common set of configuration options. Using `extends` you can define a common set of service options in one place and refer to it from anywhere.\n\nKeep in mind that `volumes_from` and `depends_on` are never shared between services using `extends`. These exceptions exist to avoid implicit dependencies; you always define `volumes_from` locally. This ensures dependencies between services are clearly visible when reading the current file. Defining these locally also ensures that changes to the referenced file don’t break anything.\n\n### Understand the extends configuration\n\nWhen defining any service in `docker-compose.yml`, you can declare that you are extending another service like this:\n\n``` \nservices:\n  web:\n    extends:\n      file: common-services.yml\n      service: webapp\n```\n\nThis instructs Compose to re-use the configuration for the `webapp` service defined in the `common-services.yml` file. Suppose that `common-services.yml` looks like this:\n\n``` \nservices:\n  webapp:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - \"/data\"\n```\n\nIn this case, you get exactly the same result as if you wrote `docker-compose.yml` with the same `build`, `ports` and `volumes` configuration values defined directly under `web`.\n\nYou can go further and define (or re-define) configuration locally in `docker-compose.yml`:\n\n``` \nservices:\n  web:\n    extends:\n      file: common-services.yml\n      service: webapp\n    environment:\n      - DEBUG=1\n    cpu_shares: 5\n\n  important_web:\n    extends: web\n    cpu_shares: 10\n```\n\nYou can also write other services and link your `web` service to them:\n\n``` \nservices:\n  web:\n    extends:\n      file: common-services.yml\n      service: webapp\n    environment:\n      - DEBUG=1\n    cpu_shares: 5\n    depends_on:\n      - db\n  db:\n    image: postgres\n```\n\n### Example use case\n\nExtending an individual service is useful when you have multiple services that have a common configuration. The example below is a Compose app with two services: a web application and a queue worker. Both services use the same codebase and share many configuration options.\n\nIn a **common.yml** we define the common configuration:\n\n``` \nservices:\n  app:\n    build: .\n    environment:\n      CONFIG_FILE_PATH: /code/config\n      API_KEY: xxxyyy\n    cpu_shares: 5\n```\n\nIn a **docker-compose.yml** we define the concrete services which use the common configuration:\n\n``` \nservices:\n  webapp:\n    extends:\n      file: common.yml\n      service: app\n    command: /code/run_web_app\n    ports:\n      - 8080:8080\n    depends_on:\n      - queue\n      - db\n\n  queue_worker:\n    extends:\n      file: common.yml\n      service: app\n    command: /code/run_worker\n    depends_on:\n      - queue\n```\n\n## Adding and overriding configuration\n\nCompose copies configurations from the original service over to the local one. If a configuration option is defined in both the original service and the local service, the local value *replaces* or *extends* the original value.\n\nFor single-value options like `image`, `command` or `mem_limit`, the new value replaces the old value.\n\noriginal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    command: python app.py\n```\n\nlocal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    command: python otherapp.py\n```\n\nresult:\n\n``` \nservices:\n  myservice:\n    # ...\n    command: python otherapp.py\n```\n\nFor the **multi-value options** `ports`, `expose`, `external_links`, `dns`, `dns_search`, and `tmpfs`, Compose concatenates both sets of values:\n\noriginal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    expose:\n      - \"3000\"\n```\n\nlocal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    expose:\n      - \"4000\"\n      - \"5000\"\n```\n\nresult:\n\n``` \nservices:\n  myservice:\n    # ...\n    expose:\n      - \"3000\"\n      - \"4000\"\n      - \"5000\"\n```\n\nIn the case of `environment`, `labels`, `volumes`, and `devices`, Compose “merges” entries together with locally-defined values taking precedence. For `environment` and `labels`, the environment variable or label name determines which value is used:\n\noriginal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    environment:\n      - FOO=original\n      - BAR=original\n```\n\nlocal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    environment:\n      - BAR=local\n      - BAZ=local\n```\n\nresult\n\n``` \nservices:\n  myservice:\n    # ...\n    environment:\n      - FOO=original\n      - BAR=local\n      - BAZ=local\n```\n\nEntries for `volumes` and `devices` are merged using the mount path in the container:\n\noriginal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    volumes:\n      - ./original:/foo\n      - ./original:/bar\n```\n\nlocal service:\n\n``` \nservices:\n  myservice:\n    # ...\n    volumes:\n      - ./local:/bar\n      - ./local:/baz\n```\n\nresult:\n\n``` \nservices:\n  myservice:\n    # ...\n    volumes:\n      - ./original:/foo\n      - ./local:/bar\n      - ./local:/baz\n```\n\n## Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[fig](https://docs.docker.com/search/?q=fig), [composition](https://docs.docker.com/search/?q=composition), [compose](https://docs.docker.com/search/?q=compose), [docker](https://docs.docker.com/search/?q=docker), [orchestration](https://docs.docker.com/search/?q=orchestration), [documentation](https://docs.docker.com/search/?q=documentation), [docs](https://docs.docker.com/search/?q=docs)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/extends/](https://docs.docker.com/compose/extends/)"
- name: Share the application
  id: get-started/04_sharing_app/index
  summary: Now that we’ve built an image, let’s share it! To share Docker images, you have to use a Docker registry
  description: "# Share the application\n\nNow that we’ve built an image, let’s share it! To share Docker images, you have to use a Docker registry. The default registry is Docker Hub and is where all of the images we’ve used have come from.\n\n> **Docker ID**\n>\n> A Docker ID allows you to access Docker Hub which is the world’s largest library and community for container images. Create a [Docker ID](https://hub.docker.com/signup) for free if you don’t have one.\n\n## Create a repo\n\nTo push an image, we first need to create a repository on Docker Hub.\n\n1.  [Sign up](https://www.docker.com/pricing?utm_source=docker&utm_medium=webreferral&utm_campaign=docs_driven_upgrade) or Sign in to [Docker Hub](https://hub.docker.com).\n\n2.  Click the **Create Repository** button.\n\n3.  For the repo name, use `getting-started`. Make sure the Visibility is `Public`.\n\n    > **Private repositories**\n    >\n    > Did you know that Docker offers private repositories which allows you to restrict content to specific users or teams? Check out the details on the [Docker pricing](https://www.docker.com/pricing?utm_source=docker&utm_medium=webreferral&utm_campaign=docs_driven_upgrade) page.\n\n4.  Click the **Create** button!\n\nIf you look at the image below an example **Docker command** can be seen. This command will push to this repo.\n\n## Push the image\n\n1.  In the command line, try running the push command you see on Docker Hub. Note that your command will be using your namespace, not “docker”.\n\n    ``` \n     $ docker push docker/getting-started\n     The push refers to repository [docker.io/docker/getting-started]\n     An image does not exist locally with the tag: docker/getting-started\n    ```\n\n    Why did it fail? The push command was looking for an image named docker/getting-started, but didn’t find one. If you run `docker image ls`, you won’t see one either.\n\n    To fix this, we need to “tag” our existing image we’ve built to give it another name.\n\n2.  Login to the Docker Hub using the command `docker login -u YOUR-USER-NAME`.\n\n3.  Use the `docker tag` command to give the `getting-started` image a new name. Be sure to swap out `YOUR-USER-NAME` with your Docker ID.\n\n    ``` \n     $ docker tag getting-started YOUR-USER-NAME/getting-started\n    ```\n\n4.  Now try your push command again. If you’re copying the value from Docker Hub, you can drop the `tagname` portion, as we didn’t add a tag to the image name. If you don’t specify a tag, Docker will use a tag called `latest`.\n\n    ``` \n     $ docker push YOUR-USER-NAME/getting-started\n    ```\n\n## Run the image on a new instance\n\nNow that our image has been built and pushed into a registry, let’s try running our app on a brand new instance that has never seen this container image! To do this, we will use Play with Docker.\n\n1.  Open your browser to [Play with Docker](https://labs.play-with-docker.com/).\n\n2.  Click **Login** and then select **docker** from the drop-down list.\n\n3.  Connect with your Docker Hub account.\n\n4.  Once you’re logged in, click on the **ADD NEW INSTANCE** option on the left side bar. If you don’t see it, make your browser a little wider. After a few seconds, a terminal window opens in your browser.\n\n5.  In the terminal, start your freshly pushed app.\n\n    ``` \n     $ docker run -dp 3000:3000 YOUR-USER-NAME/getting-started\n    ```\n\n    You should see the image get pulled down and eventually start up!\n\n6.  Click on the 3000 badge when it comes up and you should see the app with your modifications! Hooray! If the 3000 badge doesn’t show up, you can click on the “Open Port” button and type in 3000.\n\n## Recap\n\nIn this section, we learned how to share our images by pushing them to a registry. We then went to a brand new instance and were able to run the freshly pushed image. This is quite common in CI pipelines, where the pipeline will create the image and push it to a registry and then the production environment can use the latest version of the image.\n\nNow that we have that figured out, let’s circle back around to what we noticed at the end of the last section. As a reminder, we noticed that when we restarted the app, we lost all of our todo list items. That’s obviously not a great user experience, so let’s learn how we can persist the data across restarts!\n\n[get started](https://docs.docker.com/search/?q=get%20started), [setup](https://docs.docker.com/search/?q=setup), [orientation](https://docs.docker.com/search/?q=orientation), [quickstart](https://docs.docker.com/search/?q=quickstart), [intro](https://docs.docker.com/search/?q=intro), [concepts](https://docs.docker.com/search/?q=concepts), [containers](https://docs.docker.com/search/?q=containers), [docker desktop](https://docs.docker.com/search/?q=docker%20desktop), [docker hub](https://docs.docker.com/search/?q=docker%20hub), [sharing](https://docs.docker.com/search/?q=sharing)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/get-started/04_sharing_app/](https://docs.docker.com/get-started/04_sharing_app/)"
- name: Store configuration data using Docker Configs
  id: engine/swarm/configs/index
  summary: Docker swarm service configs allow you to store non-sensitive information, such as configuration files, outside a service’s image or running containers
  description: "# Store configuration data using Docker Configs\n\n## About configs\n\nDocker swarm service configs allow you to store non-sensitive information, such as configuration files, outside a service’s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables.\n\nConfigs operate in a similar way to [secrets](../secrets/index), except that they are not encrypted at rest and are mounted directly into the container’s filesystem without the use of RAM disks. Configs can be added or removed from a service at any time, and services can share a config. You can even use configs in conjunction with environment variables or labels, for maximum flexibility. Config values can be generic strings or binary content (up to 500 kb in size).\n\n> **Note**: Docker configs are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service with a scale of 1.\n\nConfigs are supported on both Linux and Windows services.\n\n### Windows support\n\nDocker includes support for configs on Windows containers, but there are differences in the implementations, which are called out in the examples below. Keep the following notable differences in mind:\n\n- Config files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, configs for a container are all mounted in `C:\\ProgramData\\Docker\\internal\\configs` (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the config within the container. The default target is `C:\\ProgramData\\Docker\\configs`.\n\n- When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for configs. Configs are currently only accessible by administrators and users with `system` access within the container.\n\n- On Windows, create or update a service using `--credential-spec` with the `config://<config-name>` format. This passes the gMSA credentials file directly to nodes before a container starts. No gMSA credentials are written to disk on worker nodes. For more information, refer to [Deploy services to a swarm](../services/index#gmsa-for-swarm).\n\n## How Docker manages configs\n\nWhen you add a config to the swarm, Docker sends the config to the swarm manager over a mutual TLS connection. The config is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for configs as for the rest of the swarm management data.\n\nWhen you grant a newly-created or running service access to a config, the config is mounted as a file in the container. The location of the mount point within the container defaults to `/<config-name>` in Linux containers. In Windows containers, configs are all mounted into `C:\\ProgramData\\Docker\\configs` and symbolic links are created to the desired location, which defaults to `C:\\<config-name>`.\n\nYou can set the ownership (`uid` and `gid`) for the config, using either the numerical ID or the name of the user or group. You can also specify the file permissions (`mode`). These settings are ignored for Windows containers.\n\n- If not set, the config is owned by the user running the container command (often `root`) and that user’s default group (also often `root`).\n- If not set, the config has world-readable permissions (mode `0444`), unless a `umask` is set within the container, in which case the mode is impacted by that `umask` value.\n\nYou can update a service to grant it access to additional configs or revoke its access to a given config at any time.\n\nA node only has access to configs if the node is a swarm manager or if it is running service tasks which have been granted access to the config. When a container task stops running, the configs shared to it are unmounted from the in-memory filesystem for that container and flushed from the node’s memory.\n\nIf a node loses connectivity to the swarm while it is running a task container with access to a config, the task container still has access to its configs, but cannot receive updates until the node reconnects to the swarm.\n\nYou can add or inspect an individual config at any time, or list all configs. You cannot remove a config that a running service is using. See [Rotate a config](index#example-rotate-a-config) for a way to remove a config without disrupting running services.\n\nTo update or roll back configs more easily, consider adding a version number or date to the config name. This is made easier by the ability to control the mount point of the config within a given container.\n\nTo update a stack, make changes to your Compose file, then re-run `docker stack deploy -c <new-compose-file> <stack-name>`. If you use a new config in that file, your services start using them. Keep in mind that configurations are immutable, so you can’t change the file for an existing service. Instead, you create a new config to use a different file\n\nYou can run `docker stack rm` to stop the app and take down the stack. This removes any config that was created by `docker stack deploy` with the same stack name. This removes *all* configs, including those not referenced by services and those remaining after a `docker service update --config-rm`.\n\n## Read more about `docker config` commands\n\nUse these links to read about specific commands, or continue to the [example about using configs with a service](#advanced-example-use-configs-with-a-nginx-service).\n\n- [`docker config create`](../../reference/commandline/config_create/index)\n- [`docker config inspect`](../../reference/commandline/config_inspect/index)\n- [`docker config ls`](../../reference/commandline/config_ls/index)\n- [`docker config rm`](../../reference/commandline/config_rm/index)\n\n## Examples\n\nThis section includes graduated examples which illustrate how to use Docker configs.\n\n> **Note**: These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support configs.\n\n### Defining and using configs in compose files\n\nThe `docker stack` command supports defining configs in a Compose file. However, the `configs` key is not supported for `docker compose`. See [the Compose file reference](../../../compose/compose-file/compose-file-v3/index#configs) for details.\n\n### Simple example: Get started with configs\n\nThis simple example shows how configs work in just a few commands. For a real-world example, continue to [Advanced example: Use configs with a Nginx service](#advanced-example-use-configs-with-a-nginx-service).\n\n1.  Add a config to Docker. The `docker config create` command reads standard input because the last argument, which represents the file to read the config from, is set to `-`.\n\n    ``` \n    $ echo \"This is a config\" | docker config create my-config -\n    ```\n\n2.  Create a `redis` service and grant it access to the config. By default, the container can access the config at `/my-config`, but you can customize the file name on the container using the `target` option.\n\n    ``` \n    $ docker service create --name redis --config my-config redis:alpine\n    ```\n\n3.  Verify that the task is running without issues using `docker service ps`. If everything is working, the output looks similar to this:\n\n    ``` \n    $ docker service ps redis\n\n    ID            NAME     IMAGE         NODE              DESIRED STATE  CURRENT STATE          ERROR  PORTS\n    bkna6bpn8r1a  redis.1  redis:alpine  ip-172-31-46-109  Running        Running 8 seconds ago\n    ```\n\n4.  Get the ID of the `redis` service task container using `docker ps`, so that you can use `docker container exec` to connect to the container and read the contents of the config data file, which defaults to being readable by all and has the same name as the name of the config. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\n\n    ``` \n    $ docker ps --filter name=redis -q\n\n    5cb1c2348a59\n\n    $ docker container exec $(docker ps --filter name=redis -q) ls -l /my-config\n\n    -r--r--r--    1 root     root            12 Jun  5 20:49 my-config\n\n    $ docker container exec $(docker ps --filter name=redis -q) cat /my-config\n\n    This is a config\n    ```\n\n5.  Try removing the config. The removal fails because the `redis` service is running and has access to the config.\n\n    ``` \n    $ docker config ls\n\n    ID                          NAME                CREATED             UPDATED\n    fzwcfuqjkvo5foqu7ts7ls578   hello               31 minutes ago      31 minutes ago\n\n\n    $ docker config rm my-config\n\n    Error response from daemon: rpc error: code = 3 desc = config 'my-config' is\n    in use by the following service: redis\n    ```\n\n6.  Remove access to the config from the running `redis` service by updating the service.\n\n    ``` \n    $ docker service update --config-rm my-config redis\n    ```\n\n7.  Repeat steps 3 and 4 again, verifying that the service no longer has access to the config. The container ID is different, because the `service update` command redeploys the service.\n\n        $ docker container exec -it $(docker ps --filter name=redis -q) cat /my-config\n\n        cat: can't open '/my-config': No such file or directory\n\n8.  Stop and remove the service, and remove the config from Docker.\n\n    ``` \n    $ docker service rm redis\n\n    $ docker config rm my-config\n    ```\n\n### Simple example: Use configs in a Windows service\n\nThis is a very simple example which shows how to use configs with a Microsoft IIS service running on Docker for Windows running Windows containers on Microsoft Windows 10. It is a naive example that stores the webpage in a config.\n\nThis example assumes that you have PowerShell installed.\n\n1.  Save the following into a new file `index.html`.\n\n    ``` \n    <html lang=\"en\">\n      <head><title>Hello Docker</title></head>\n      <body>\n        <p>Hello Docker! You have deployed a HTML page.</p>\n      </body>\n    </html>\n    ```\n\n2.  If you have not already done so, initialize or join the swarm.\n\n    ``` \n    docker swarm init\n    ```\n\n3.  Save the `index.html` file as a swarm config named `homepage`.\n\n    ``` \n    docker config create homepage index.html\n    ```\n\n4.  Create an IIS service and grant it access to the `homepage` config.\n\n    ``` \n    docker service create\n        --name my-iis\n        --publish published=8000,target=8000\n        --config src=homepage,target=\"\\inetpub\\wwwroot\\index.html\"\n        microsoft/iis:nanoserver\n    ```\n\n5.  Access the IIS service at `http://localhost:8000/`. It should serve the HTML content from the first step.\n\n6.  Remove the service and the config.\n\n    ``` \n    docker service rm my-iis\n\n    docker config rm homepage\n    ```\n\n### Example: Use a templated config\n\nTo create a configuration in which the content will be generated using a template engine, use the `--template-driver` parameter and specify the engine name as its argument. The template will be rendered when container is created.\n\n1.  Save the following into a new file `index.html.tmpl`.\n\n    ``` \n    <html lang=\"en\">\n      <head><title>Hello Docker</title></head>\n      <body>\n        <p>Hello {{ env \"HELLO\" }}! I'm service {{ .Service.Name }}.</p>\n      </body>\n    </html>\n    ```\n\n2.  Save the `index.html.tmpl` file as a swarm config named `homepage`. Provide parameter `--template-driver` and specify `golang` as template engine.\n\n    ``` \n    $ docker config create --template-driver golang homepage index.html.tmpl\n    ```\n\n3.  Create a service that runs Nginx and has access to the environment variable HELLO and to the config.\n\n    ``` \n    $ docker service create \\\n         --name hello-template \\\n         --env HELLO=\"Docker\" \\\n         --config source=homepage,target=/usr/share/nginx/html/index.html \\\n         --publish published=3000,target=80 \\\n         nginx:alpine\n    ```\n\n4.  Verify that the service is operational: you can reach the Nginx server, and that the correct output is being served.\n\n    ``` \n    $ curl http://0.0.0.0:3000\n\n    <html lang=\"en\">\n      <head><title>Hello Docker</title></head>\n      <body>\n        <p>Hello Docker! I'm service hello-template.</p>\n      </body>\n    </html>\n    ```\n\n### Advanced example: Use configs with a Nginx service\n\nThis example is divided into two parts. [The first part](#generate-the-site-certificate) is all about generating the site certificate and does not directly involve Docker configs at all, but it sets up [the second part](#configure-the-nginx-container), where you store and use the site certificate as a series of secrets and the Nginx configuration as a config. The example shows how to set options on the config, such as the target location within the container and the file permissions (`mode`).\n\n#### Generate the site certificate\n\nGenerate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as `Let’s Encrypt` to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can [use Let’s Encrypt](https://letsencrypt.org/getting-started/) to generate the site key and certificate, name the files `site.key` and `site.crt`, and skip to [Configure the Nginx container](#configure-the-nginx-container).\n\n1.  Generate a root key.\n\n    ``` \n    $ openssl genrsa -out \"root-ca.key\" 4096\n    ```\n\n2.  Generate a CSR using the root key.\n\n    ``` \n    $ openssl req \\\n              -new -key \"root-ca.key\" \\\n              -out \"root-ca.csr\" -sha256 \\\n              -subj '/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA'\n    ```\n\n3.  Configure the root CA. Edit a new file called `root-ca.cnf` and paste the following contents into it. This constrains the root CA to only sign leaf certificates and not intermediate CAs.\n\n        [root_ca]\n        basicConstraints = critical,CA:TRUE,pathlen:1\n        keyUsage = critical, nonRepudiation, cRLSign, keyCertSign\n        subjectKeyIdentifier=hash\n\n4.  Sign the certificate.\n\n    ``` \n    $ openssl x509 -req -days 3650 -in \"root-ca.csr\" \\\n                   -signkey \"root-ca.key\" -sha256 -out \"root-ca.crt\" \\\n                   -extfile \"root-ca.cnf\" -extensions \\\n                   root_ca\n    ```\n\n5.  Generate the site key.\n\n    ``` \n    $ openssl genrsa -out \"site.key\" 4096\n    ```\n\n6.  Generate the site certificate and sign it with the site key.\n\n    ``` \n    $ openssl req -new -key \"site.key\" -out \"site.csr\" -sha256 \\\n              -subj '/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost'\n    ```\n\n7.  Configure the site certificate. Edit a new file called `site.cnf` and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can’t be used to sign certificates.\n\n        [server]\n        authorityKeyIdentifier=keyid,issuer\n        basicConstraints = critical,CA:FALSE\n        extendedKeyUsage=serverAuth\n        keyUsage = critical, digitalSignature, keyEncipherment\n        subjectAltName = DNS:localhost, IP:127.0.0.1\n        subjectKeyIdentifier=hash\n\n8.  Sign the site certificate.\n\n    ``` \n    $ openssl x509 -req -days 750 -in \"site.csr\" -sha256 \\\n        -CA \"root-ca.crt\" -CAkey \"root-ca.key\" -CAcreateserial \\\n        -out \"site.crt\" -extfile \"site.cnf\" -extensions server\n    ```\n\n9.  The `site.csr` and `site.cnf` files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the `root-ca.key` file.\n\n#### Configure the Nginx container\n\n1.  Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\n\n    In the current directory, create a new file called `site.conf` with the following contents:\n\n        server {\n            listen                443 ssl;\n            server_name           localhost;\n            ssl_certificate       /run/secrets/site.crt;\n            ssl_certificate_key   /run/secrets/site.key;\n\n            location / {\n                root   /usr/share/nginx/html;\n                index  index.html index.htm;\n            }\n        }\n\n2.  Create two secrets, representing the key and the certificate. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key and certificate from the services that use them. In these examples, the secret name and the file name are the same.\n\n    ``` \n    $ docker secret create site.key site.key\n\n    $ docker secret create site.crt site.crt\n    ```\n\n3.  Save the `site.conf` file in a Docker config. The first parameter is the name of the config, and the second parameter is the file to read it from.\n\n    ``` \n    $ docker config create site.conf site.conf\n    ```\n\n    List the configs:\n\n    ``` \n    $ docker config ls\n\n    ID                          NAME                CREATED             UPDATED\n    4ory233120ccg7biwvy11gl5z   site.conf           4 seconds ago       4 seconds ago\n    ```\n\n4.  Create a service that runs Nginx and has access to the two secrets and the config. Set the mode to `0440` so that the file is only readable by its owner and that owner’s group, not the world.\n\n    ``` \n    $ docker service create \\\n         --name nginx \\\n         --secret site.key \\\n         --secret site.crt \\\n         --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\n         --publish published=3000,target=443 \\\n         nginx:latest \\\n         sh -c \"exec nginx -g 'daemon off;'\"\n    ```\n\n    Within the running containers, the following three files now exist:\n\n    - `/run/secrets/site.key`\n    - `/run/secrets/site.crt`\n    - `/etc/nginx/conf.d/site.conf`\n\n5.  Verify that the Nginx service is running.\n\n    ``` \n    $ docker service ls\n\n    ID            NAME   MODE        REPLICAS  IMAGE\n    zeskcec62q24  nginx  replicated  1/1       nginx:latest\n\n    $ docker service ps nginx\n\n    NAME                  IMAGE         NODE  DESIRED STATE  CURRENT STATE          ERROR  PORTS\n    nginx.1.9ls3yo9ugcls  nginx:latest  moby  Running        Running 3 minutes ago\n    ```\n\n6.  Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\n\n    ``` \n    $ curl --cacert root-ca.crt https://0.0.0.0:3000\n\n    <!DOCTYPE html>\n    <html>\n    <head>\n    <title>Welcome to nginx!</title>\n    <style>\n        body {\n            width: 35em;\n            margin: 0 auto;\n            font-family: Tahoma, Verdana, Arial, sans-serif;\n        }\n    </style>\n    </head>\n    <body>\n    <h1>Welcome to nginx!</h1>\n    <p>If you see this page, the nginx web server is successfully installed and\n    working. Further configuration is required.</p>\n\n    <p>For online documentation and support, refer to\n    <a href=\"https://nginx.org\">nginx.org</a>.<br/>\n    Commercial support is available at\n    <a href=\"https://www.nginx.com\">www.nginx.com</a>.</p>\n\n    <p><em>Thank you for using nginx.</em></p>\n    </body>\n    </html>\n    ```\n\n    ``` \n    $ openssl s_client -connect 0.0.0.0:3000 -CAfile root-ca.crt\n\n    CONNECTED(00000003)\n    depth=1 /C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\n    verify return:1\n    depth=0 /C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\n    verify return:1\n    ---\n    Certificate chain\n     0 s:/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\n       i:/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\n    ---\n    Server certificate\n    -----BEGIN CERTIFICATE-----\n    …\n    -----END CERTIFICATE-----\n    subject=/C=US/ST=CA/L=San Francisco/O=Docker/CN=localhost\n    issuer=/C=US/ST=CA/L=San Francisco/O=Docker/CN=Swarm Secret Example CA\n    ---\n    No client certificate CA names sent\n    ---\n    SSL handshake has read 1663 bytes and written 712 bytes\n    ---\n    New, TLSv1/SSLv3, Cipher is AES256-SHA\n    Server public key is 4096 bit\n    Secure Renegotiation IS supported\n    Compression: NONE\n    Expansion: NONE\n    SSL-Session:\n        Protocol  : TLSv1\n        Cipher    : AES256-SHA\n        Session-ID: A1A8BF35549C5715648A12FD7B7E3D861539316B03440187D9DA6C2E48822853\n        Session-ID-ctx:\n        Master-Key: F39D1B12274BA16D3A906F390A61438221E381952E9E1E05D3DD784F0135FB81353DA38C6D5C021CB926E844DFC49FC4\n        Key-Arg   : None\n        Start Time: 1481685096\n        Timeout   : 300 (sec)\n        Verify return code: 0 (ok)\n    ```\n\n7.  Unless you are going to continue to the next example, clean up after running this example by removing the `nginx` service and the stored secrets and config.\n\n    ``` \n    $ docker service rm nginx\n\n    $ docker secret rm site.crt site.key\n\n    $ docker config rm site.conf\n    ```\n\nYou have now configured a Nginx service with its configuration decoupled from its image. You could run multiple sites with exactly the same image but separate configurations, without the need to build a custom image at all.\n\n### Example: Rotate a config\n\nTo rotate a config, you first save a new config with a different name than the one that is currently in use. You then redeploy the service, removing the old config and adding the new config at the same mount point within the container. This example builds upon the previous one by rotating the `site.conf` configuration file.\n\n1.  Edit the `site.conf` file locally. Add `index.php` to the `index` line, and save the file.\n\n        server {\n            listen                443 ssl;\n            server_name           localhost;\n            ssl_certificate       /run/secrets/site.crt;\n            ssl_certificate_key   /run/secrets/site.key;\n\n            location / {\n                root   /usr/share/nginx/html;\n                index  index.html index.htm index.php;\n            }\n        }\n\n2.  Create a new Docker config using the new `site.conf`, called `site-v2.conf`.\n\n        $ docker config create site-v2.conf site.conf\n\n3.  Update the `nginx` service to use the new config instead of the old one.\n\n    ``` \n    $ docker service update \\\n      --config-rm site.conf \\\n      --config-add source=site-v2.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\n      nginx\n    ```\n\n4.  Verify that the `nginx` service is fully re-deployed, using `docker service ps nginx`. When it is, you can remove the old `site.conf` config.\n\n    ``` \n    $ docker config rm site.conf\n    ```\n\n5.  To clean up, you can remove the `nginx` service, as well as the secrets and configs.\n\n    ``` \n    $ docker service rm nginx\n\n    $ docker secret rm site.crt site.key\n\n    $ docker config rm site-v2.conf\n    ```\n\nYou have now updated your `nginx` service’s configuration without the need to rebuild its image.\n\n[swarm](https://docs.docker.com/search/?q=swarm), [configuration](https://docs.docker.com/search/?q=configuration), [configs](https://docs.docker.com/search/?q=configs)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/configs/](https://docs.docker.com/engine/swarm/configs/)"
- name: Swarm mode key concepts
  id: engine/swarm/key-concepts/index
  summary: This topic introduces some of the concepts unique to the cluster management and orchestration features of Docker Engine 1.12
  description: "# Swarm mode key concepts\n\nThis topic introduces some of the concepts unique to the cluster management and orchestration features of Docker Engine 1.12.\n\n## What is a swarm?\n\nThe cluster management and orchestration features embedded in the Docker Engine are built using [swarmkit](https://github.com/docker/swarmkit/). Swarmkit is a separate project which implements Docker’s orchestration layer and is used directly within Docker.\n\nA swarm consists of multiple Docker hosts which run in **swarm mode** and act as managers (to manage membership and delegation) and workers (which run [swarm services](#services-and-tasks)). A given Docker host can be a manager, a worker, or perform both roles. When you create a service, you define its optimal state (number of replicas, network and storage resources available to it, ports the service exposes to the outside world, and more). Docker works to maintain that desired state. For instance, if a worker node becomes unavailable, Docker schedules that node’s tasks on other nodes. A *task* is a running container which is part of a swarm service and managed by a swarm manager, as opposed to a standalone container.\n\nOne of the key advantages of swarm services over standalone containers is that you can modify a service’s configuration, including the networks and volumes it is connected to, without the need to manually restart the service. Docker will update the configuration, stop the service tasks with the out of date configuration, and create new ones matching the desired configuration.\n\nWhen Docker is running in swarm mode, you can still run standalone containers on any of the Docker hosts participating in the swarm, as well as swarm services. A key difference between standalone containers and swarm services is that only swarm managers can manage a swarm, while standalone containers can be started on any daemon. Docker daemons can participate in a swarm as managers, workers, or both.\n\nIn the same way that you can use [Docker Compose](../../../compose/index) to define and run containers, you can define and run [Swarm service](../services/index) stacks.\n\nKeep reading for details about concepts relating to Docker swarm services, including nodes, services, tasks, and load balancing.\n\n## Nodes\n\nA **node** is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.\n\nTo deploy your application to a swarm, you submit a service definition to a **manager node**. The manager node dispatches units of work called [tasks](#services-and-tasks) to worker nodes.\n\nManager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.\n\n**Worker nodes** receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.\n\n## Services and tasks\n\nA **service** is the definition of the tasks to execute on the manager or worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.\n\nWhen you create a service, you specify which container image to use and which commands to execute inside running containers.\n\nIn the **replicated services** model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.\n\nFor **global services**, the swarm runs one task for the service on every available node in the cluster.\n\nA **task** carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.\n\n## Load balancing\n\nThe swarm manager uses **ingress load balancing** to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a **PublishedPort** or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.\n\nExternal components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.\n\nSwarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses **internal load balancing** to distribute requests among services within the cluster based upon the DNS name of the service.\n\n## What’s next?\n\n- Read the [Swarm mode overview](../index).\n- Get started with the [Swarm mode tutorial](../swarm-tutorial/index).\n\n[docker](https://docs.docker.com/search/?q=docker), [container](https://docs.docker.com/search/?q=container), [cluster](https://docs.docker.com/search/?q=cluster), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/key-concepts/](https://docs.docker.com/engine/swarm/key-concepts/)"
- name: Swarm mode overview
  id: engine/swarm/index
  summary: To use Docker in swarm mode, install Docker
  description: "# Swarm mode overview\n\nTo use Docker in swarm mode, install Docker. See [installation instructions](https://docs.docker.com/get-docker/) for all operating systems and platforms.\n\nCurrent versions of Docker include *swarm mode* for natively managing a cluster of Docker Engines called a *swarm*. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.\n\nDocker Swarm mode is built into the Docker Engine. Do not confuse Docker Swarm mode with [Docker Classic Swarm](https://github.com/docker/classicswarm) which is no longer actively developed.\n\n## Feature highlights\n\n- **Cluster management integrated with Docker Engine:** Use the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You don’t need additional orchestration software to create or manage a swarm.\n\n- **Decentralized design:** Instead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n- **Declarative service model:** Docker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n- **Scaling:** For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n- **Desired state reconciliation:** The swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager creates two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n- **Multi-host networking:** You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n- **Service discovery:** Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n- **Load balancing:** You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n- **Secure by default:** Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n- **Rolling updates:** At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll back to a previous version of the service.\n\n## What’s next?\n\n### Swarm mode key concepts and tutorial\n\n- Learn swarm mode [key concepts](key-concepts/index).\n\n- Get started with the [Swarm mode tutorial](swarm-tutorial/index).\n\n### Swarm mode CLI commands\n\nExplore swarm mode CLI commands\n\n- [swarm init](../reference/commandline/swarm_init/index)\n- [swarm join](../reference/commandline/swarm_join/index)\n- [service create](../reference/commandline/service_create/index)\n- [service inspect](../reference/commandline/service_inspect/index)\n- [service ls](../reference/commandline/service_ls/index)\n- [service rm](../reference/commandline/service_rm/index)\n- [service scale](../reference/commandline/service_scale/index)\n- [service ps](../reference/commandline/service_ps/index)\n- [service update](../reference/commandline/service_update/index)\n\n[docker](https://docs.docker.com/search/?q=docker), [container](https://docs.docker.com/search/?q=container), [cluster](https://docs.docker.com/search/?q=cluster), [swarm](https://docs.docker.com/search/?q=swarm)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)"
- name: Use Compose in production
  id: compose/production/index
  summary: When you define your app with Compose in development, you can use this definition to run your application in different environments such as CI, staging, and production
  description: "# Use Compose in production\n\nWhen you define your app with Compose in development, you can use this definition to run your application in different environments such as CI, staging, and production.\n\nThe easiest way to deploy an application is to run it on a single server, similar to how you would run your development environment. If you want to scale up your application, you can run Compose apps on a Swarm cluster.\n\n### Modify your Compose file for production\n\nYou probably need to make changes to your app configuration to make it ready for production. These changes may include:\n\n- Removing any volume bindings for application code, so that code stays inside the container and can’t be changed from outside\n- Binding to different ports on the host\n- Setting environment variables differently, such as reducing the verbosity of logging, or to specify settings for external services such as an email server\n- Specifying a restart policy like `restart: always` to avoid downtime\n- Adding extra services such as a log aggregator\n\nFor this reason, consider defining an additional Compose file, say `production.yml`, which specifies production-appropriate configuration. This configuration file only needs to include the changes you’d like to make from the original Compose file. The additional Compose file can be applied over the original `docker-compose.yml` to create a new configuration.\n\nOnce you’ve got a second configuration file, tell Compose to use it with the `-f` option:\n\n``` \n$ docker-compose -f docker-compose.yml -f production.yml up -d\n```\n\nSee [Using multiple compose files](../extends/index#different-environments) for a more complete example.\n\n### Deploying changes\n\nWhen you make changes to your app code, remember to rebuild your image and recreate your app’s containers. To redeploy a service called `web`, use:\n\n``` \n$ docker-compose build web\n$ docker-compose up --no-deps -d web\n```\n\nThis first rebuilds the image for `web` and then stop, destroy, and recreate *just* the `web` service. The `--no-deps` flag prevents Compose from also recreating any services which `web` depends on.\n\n### Running Compose on a single server\n\nYou can use Compose to deploy an app to a remote Docker host by setting the `DOCKER_HOST`, `DOCKER_TLS_VERIFY`, and `DOCKER_CERT_PATH` environment variables appropriately.\n\nOnce you’ve set up your environment variables, all the normal `docker-compose` commands work with no further configuration.\n\n## Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[compose](https://docs.docker.com/search/?q=compose), [orchestration](https://docs.docker.com/search/?q=orchestration), [containers](https://docs.docker.com/search/?q=containers), [production](https://docs.docker.com/search/?q=production)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/production/](https://docs.docker.com/compose/production/)"
- name: Use Docker Engine plugins
  id: engine/extend/legacy_plugins/index
  summary: This document describes the Docker Engine plugins generally available in Docker Engine
  description: "# Use Docker Engine plugins\n\nThis document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker, refer to [Docker Engine plugin system](../index).\n\nYou can extend the capabilities of the Docker Engine by loading third-party plugins. This page explains the types of plugins and provides links to several volume and network plugins for Docker.\n\n## Types of plugins\n\nPlugins extend Docker’s functionality. They come in specific types. For example, a [volume plugin](../plugins_volume/index) might enable Docker volumes to persist across multiple Docker hosts and a [network plugin](../plugins_network/index) might provide network plumbing.\n\nCurrently Docker supports authorization, volume and network driver plugins. In the future it will support additional plugin types.\n\n## Installing a plugin\n\nFollow the instructions in the plugin’s documentation.\n\n## Finding a plugin\n\nThe sections below provide an inexhaustive overview of available plugins.\n\n### Network plugins\n\n| Plugin                                                                             | Description                                                                                                                                                                                                                                                                                                                                            |\n|:-----------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Contiv Networking](https://github.com/contiv/netplugin)                           | An open source network plugin to provide infrastructure and security policies for a multi-tenant micro services deployment, while providing an integration to physical network for non-container workload. Contiv Networking implements the remote driver and IPAM APIs available in Docker 1.9 onwards.                                               |\n| [Kuryr Network Plugin](https://github.com/openstack/kuryr)                         | A network plugin is developed as part of the OpenStack Kuryr project and implements the Docker networking (libnetwork) remote driver API by utilizing Neutron, the OpenStack networking service. It includes an IPAM driver as well.                                                                                                                   |\n| [Weave Network Plugin](https://www.weave.works/docs/net/latest/introducing-weave/) | A network plugin that creates a virtual network that connects your Docker containers - across multiple hosts or clouds and enables automatic discovery of applications. Weave networks are resilient, partition tolerant, secure and work in partially connected networks, and other adverse environments - all configured with delightful simplicity. |\n\n### Volume plugins\n\n| Plugin                                                                                             | Description                                                                                                                                                                                                                                                                                                   |\n|:---------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Azure File Storage plugin](https://github.com/Azure/azurefile-dockervolumedriver)                 | Lets you mount Microsoft [Azure File Storage](https://azure.microsoft.com/blog/azure-file-storage-now-generally-available/) shares to Docker containers as volumes using the SMB 3.0 protocol. [Learn more](https://azure.microsoft.com/blog/persistent-docker-volumes-with-azure-file-storage/).             |\n| [BeeGFS Volume Plugin](https://github.com/RedCoolBeans/docker-volume-beegfs)                       | An open source volume plugin to create persistent volumes in a BeeGFS parallel file system.                                                                                                                                                                                                                   |\n| [Blockbridge plugin](https://github.com/blockbridge/blockbridge-docker-volume)                     | A volume plugin that provides access to an extensible set of container-based persistent storage options. It supports single and multi-host Docker environments with features that include tenant isolation, automated provisioning, encryption, secure deletion, snapshots and QoS.                           |\n| [Contiv Volume Plugin](https://github.com/contiv/volplugin)                                        | An open source volume plugin that provides multi-tenant, persistent, distributed storage with intent based consumption. It has support for Ceph and NFS.                                                                                                                                                      |\n| [Convoy plugin](https://github.com/rancher/convoy)                                                 | A volume plugin for a variety of storage back-ends including device mapper and NFS. It’s a simple standalone executable written in Go and provides the framework to support vendor-specific extensions such as snapshots, backups and restore.                                                                |\n| [DigitalOcean Block Storage plugin](https://github.com/omallo/docker-volume-plugin-dostorage)      | Integrates DigitalOcean’s [block storage solution](https://www.digitalocean.com/products/storage/) into the Docker ecosystem by automatically attaching a given block storage volume to a DigitalOcean droplet and making the contents of the volume available to Docker containers running on that droplet.  |\n| [DRBD plugin](https://www.drbd.org/en/supported-projects/docker)                                   | A volume plugin that provides highly available storage replicated by [DRBD](https://www.drbd.org). Data written to the docker volume is replicated in a cluster of DRBD nodes.                                                                                                                                |\n| [Flocker plugin](https://github.com/ScatterHQ/flocker)                                             | A volume plugin that provides multi-host portable volumes for Docker, enabling you to run databases and other stateful containers and move them around across a cluster of machines.                                                                                                                          |\n| [Fuxi Volume Plugin](https://github.com/openstack/fuxi)                                            | A volume plugin that is developed as part of the OpenStack Kuryr project and implements the Docker volume plugin API by utilizing Cinder, the OpenStack block storage service.                                                                                                                                |\n| [gce-docker plugin](https://github.com/mcuadros/gce-docker)                                        | A volume plugin able to attach, format and mount Google Compute [persistent-disks](https://cloud.google.com/compute/docs/disks/persistent-disks).                                                                                                                                                             |\n| [GlusterFS plugin](https://github.com/calavera/docker-volume-glusterfs)                            | A volume plugin that provides multi-host volumes management for Docker using GlusterFS.                                                                                                                                                                                                                       |\n| [Horcrux Volume Plugin](https://github.com/muthu-r/horcrux)                                        | A volume plugin that allows on-demand, version controlled access to your data. Horcrux is an open-source plugin, written in Go, and supports SCP, [Minio](https://www.minio.io) and Amazon S3.                                                                                                                |\n| [HPE 3Par Volume Plugin](https://github.com/hpe-storage/python-hpedockerplugin/)                   | A volume plugin that supports HPE 3Par and StoreVirtual iSCSI storage arrays.                                                                                                                                                                                                                                 |\n| [Infinit volume plugin](https://infinit.sh/documentation/docker/volume-plugin)                     | A volume plugin that makes it easy to mount and manage Infinit volumes using Docker.                                                                                                                                                                                                                          |\n| [IPFS Volume Plugin](https://github.com/vdemeester/docker-volume-ipfs)                             | An open source volume plugin that allows using an [ipfs](https://ipfs.io/) filesystem as a volume.                                                                                                                                                                                                            |\n| [Keywhiz plugin](https://github.com/calavera/docker-volume-keywhiz)                                | A plugin that provides credentials and secret management using Keywhiz as a central repository.                                                                                                                                                                                                               |\n| [Local Persist Plugin](https://github.com/CWSpear/local-persist)                                   | A volume plugin that extends the default `local` driver’s functionality by allowing you specify a mountpoint anywhere on the host, which enables the files to *always persist*, even if the volume is removed via `docker volume rm`.                                                                         |\n| [NetApp Plugin](https://github.com/NetApp/netappdvp) (nDVP)                                        | A volume plugin that provides direct integration with the Docker ecosystem for the NetApp storage portfolio. The nDVP package supports the provisioning and management of storage resources from the storage platform to Docker hosts, with a robust framework for adding additional platforms in the future. |\n| [Netshare plugin](https://github.com/ContainX/docker-volume-netshare)                              | A volume plugin that provides volume management for NFS 3/4, AWS EFS and CIFS file systems.                                                                                                                                                                                                                   |\n| [Nimble Storage Volume Plugin](https://connect.nimblestorage.com/community/app-integration/docker) | A volume plug-in that integrates with Nimble Storage Unified Flash Fabric arrays. The plug-in abstracts array volume capabilities to the Docker administrator to allow self-provisioning of secure multi-tenant volumes and clones.                                                                           |\n| [OpenStorage Plugin](https://github.com/libopenstorage/openstorage)                                | A cluster-aware volume plugin that provides volume management for file and block storage solutions. It implements a vendor neutral specification for implementing extensions such as CoS, encryption, and snapshots. It has example drivers based on FUSE, NFS, NBD and EBS to name a few.                    |\n| [Portworx Volume Plugin](https://github.com/portworx/px-dev)                                       | A volume plugin that turns any server into a scale-out converged compute/storage node, providing container granular storage and highly available volumes across any node, using a shared-nothing storage backend that works with any docker scheduler.                                                        |\n| [Quobyte Volume Plugin](https://github.com/quobyte/docker-volume)                                  | A volume plugin that connects Docker to [Quobyte](https://www.quobyte.com/containers)’s data center file system, a general-purpose scalable and fault-tolerant storage platform.                                                                                                                              |\n| [REX-Ray plugin](https://github.com/emccode/rexray)                                                | A volume plugin which is written in Go and provides advanced storage functionality for many platforms including VirtualBox, EC2, Google Compute Engine, OpenStack, and EMC.                                                                                                                                   |\n| [Virtuozzo Storage and Ploop plugin](https://github.com/virtuozzo/docker-volume-ploop)             | A volume plugin with support for Virtuozzo Storage distributed cloud file system as well as ploop devices.                                                                                                                                                                                                    |\n| [VMware vSphere Storage Plugin](https://github.com/vmware/docker-volume-vsphere)                   | Docker Volume Driver for vSphere enables customers to address persistent storage requirements for Docker containers in vSphere environments.                                                                                                                                                                  |\n\n### Authorization plugins\n\n| Plugin                                                               | Description                                                                                                                                                                                                                                                                                                                          |\n|:---------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Casbin AuthZ Plugin](https://github.com/casbin/casbin-authz-plugin) | An authorization plugin based on [Casbin](https://github.com/casbin/casbin), which supports access control models like ACL, RBAC, ABAC. The access control model can be customized. The policy can be persisted into file or DB.                                                                                                     |\n| [HBM plugin](https://github.com/kassisol/hbm)                        | An authorization plugin that prevents from executing commands with certains parameters.                                                                                                                                                                                                                                              |\n| [Twistlock AuthZ Broker](https://github.com/twistlock/authz)         | A basic extendable authorization plugin that runs directly on the host or inside a container. This plugin allows you to define user policies that it evaluates during authorization. Basic authorization is provided if Docker daemon is started with the --tlsverify flag (username is extracted from the certificate common name). |\n\n## Troubleshooting a plugin\n\nIf you are having problems with Docker after loading a plugin, ask the authors of the plugin for help. The Docker team may not be able to assist you.\n\n## Writing a plugin\n\nIf you are interested in writing a plugin for Docker, or seeing how they work under the hood, see the [docker plugins reference](../plugin_api/index).\n\n[Examples](https://docs.docker.com/search/?q=Examples), [Usage](https://docs.docker.com/search/?q=Usage), [plugins](https://docs.docker.com/search/?q=plugins), [docker](https://docs.docker.com/search/?q=docker), [documentation](https://docs.docker.com/search/?q=documentation), [user guide](https://docs.docker.com/search/?q=user%20guide)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/extend/legacy_plugins/](https://docs.docker.com/engine/extend/legacy_plugins/)"
- name: Use swarm mode routing mesh
  id: engine/swarm/ingress/index
  summary: Docker Engine swarm mode makes it easy to publish ports for services to make them available to resources outside the swarm
  description: "# Use swarm mode routing mesh\n\nDocker Engine swarm mode makes it easy to publish ports for services to make them available to resources outside the swarm. All nodes participate in an ingress **routing mesh**. The routing mesh enables each node in the swarm to accept connections on published ports for any service running in the swarm, even if there’s no task running on the node. The routing mesh routes all incoming requests to published ports on available nodes to an active container.\n\nTo use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable swarm mode:\n\n- Port `7946` TCP/UDP for container network discovery.\n- Port `4789` UDP for the container ingress network.\n\nYou must also open the published port between the swarm nodes and any external resources, such as an external load balancer, that require access to the port.\n\nYou can also [bypass the routing mesh](#bypass-the-routing-mesh) for a given service.\n\n## Publish a port for a service\n\nUse the `--publish` flag to publish a port when you create a service. `target` is used to specify the port inside the container, and `published` is used to specify the port to bind on the routing mesh. If you leave off the `published` port, a random high-numbered port is bound for each service task. You need to inspect the task to determine the port.\n\n``` \n$ docker service create \\\n  --name <SERVICE-NAME> \\\n  --publish published=<PUBLISHED-PORT>,target=<CONTAINER-PORT> \\\n  <IMAGE>\n```\n\n> **Note**: The older form of this syntax is a colon-separated string, where the published port is first and the target port is second, such as `-p 8080:80`. The new syntax is preferred because it is easier to read and allows more flexibility.\n\nThe `<PUBLISHED-PORT>` is the port where the swarm makes the service available. If you omit it, a random high-numbered port is bound. The `<CONTAINER-PORT>` is the port where the container listens. This parameter is required.\n\nFor example, the following command publishes port 80 in the nginx container to port 8080 for any node in the swarm:\n\n``` \n$ docker service create \\\n  --name my-web \\\n  --publish published=8080,target=80 \\\n  --replicas 2 \\\n  nginx\n```\n\nWhen you access port 8080 on any node, Docker routes your request to an active container. On the swarm nodes themselves, port 8080 may not actually be bound, but the routing mesh knows how to route the traffic and prevents any port conflicts from happening.\n\nThe routing mesh listens on the published port for any IP address assigned to the node. For externally routable IP addresses, the port is available from outside the host. For all other IP addresses the access is only available from within the host.\n\nYou can publish a port for an existing service using the following command:\n\n``` \n$ docker service update \\\n  --publish-add published=<PUBLISHED-PORT>,target=<CONTAINER-PORT> \\\n  <SERVICE>\n```\n\nYou can use `docker service inspect` to view the service’s published port. For instance:\n\n``` \n$ docker service inspect --format=\"{{json .Endpoint.Spec.Ports}}\" my-web\n\n[{\"Protocol\":\"tcp\",\"TargetPort\":80,\"PublishedPort\":8080}]\n```\n\nThe output shows the `<CONTAINER-PORT>` (labeled `TargetPort`) from the containers and the `<PUBLISHED-PORT>` (labeled `PublishedPort`) where nodes listen for requests for the service.\n\n### Publish a port for TCP only or UDP only\n\nBy default, when you publish a port, it is a TCP port. You can specifically publish a UDP port instead of or in addition to a TCP port. When you publish both TCP and UDP ports, If you omit the protocol specifier, the port is published as a TCP port. If you use the longer syntax (recommended), set the `protocol` key to either `tcp` or `udp`.\n\n#### TCP only\n\n**Long syntax:**\n\n``` \n$ docker service create --name dns-cache \\\n  --publish published=53,target=53 \\\n  dns-cache\n```\n\n**Short syntax:**\n\n``` \n$ docker service create --name dns-cache \\\n  -p 53:53 \\\n  dns-cache\n```\n\n#### TCP and UDP\n\n**Long syntax:**\n\n``` \n$ docker service create --name dns-cache \\\n  --publish published=53,target=53 \\\n  --publish published=53,target=53,protocol=udp \\\n  dns-cache\n```\n\n**Short syntax:**\n\n``` \n$ docker service create --name dns-cache \\\n  -p 53:53 \\\n  -p 53:53/udp \\\n  dns-cache\n```\n\n#### UDP only\n\n**Long syntax:**\n\n``` \n$ docker service create --name dns-cache \\\n  --publish published=53,target=53,protocol=udp \\\n  dns-cache\n```\n\n**Short syntax:**\n\n``` \n$ docker service create --name dns-cache \\\n  -p 53:53/udp \\\n  dns-cache\n```\n\n## Bypass the routing mesh\n\nYou can bypass the routing mesh, so that when you access the bound port on a given node, you are always accessing the instance of the service running on that node. This is referred to as `host` mode. There are a few things to keep in mind.\n\n- If you access a node which is not running a service task, the service does not listen on that port. It is possible that nothing is listening, or that a completely different application is listening.\n\n- If you expect to run multiple service tasks on each node (such as when you have 5 nodes but run 10 replicas), you cannot specify a static target port. Either allow Docker to assign a random high-numbered port (by leaving off the `published`), or ensure that only a single instance of the service runs on a given node, by using a global service rather than a replicated one, or by using placement constraints.\n\nTo bypass the routing mesh, you must use the long `--publish` service and set `mode` to `host`. If you omit the `mode` key or set it to `ingress`, the routing mesh is used. The following command creates a global service using `host` mode and bypassing the routing mesh.\n\n``` \n$ docker service create --name dns-cache \\\n  --publish published=53,target=53,protocol=udp,mode=host \\\n  --mode global \\\n  dns-cache\n```\n\n## Configure an external load balancer\n\nYou can configure an external load balancer for swarm services, either in combination with the routing mesh or without using the routing mesh at all.\n\n### Using the routing mesh\n\nYou can configure an external load balancer to route requests to a swarm service. For example, you could configure [HAProxy](https://www.haproxy.org) to balance requests to an nginx service published to port 8080.\n\nIn this case, port 8080 must be open between the load balancer and the nodes in the swarm. The swarm nodes can reside on a private network that is accessible to the proxy server, but that is not publicly accessible.\n\nYou can configure the load balancer to balance requests between every node in the swarm even if there are no tasks scheduled on the node. For example, you could have the following HAProxy configuration in `/etc/haproxy/haproxy.cfg`:\n\n``` \nglobal\n        log /dev/log    local0\n        log /dev/log    local1 notice\n...snip...\n\n# Configure HAProxy to listen on port 80\nfrontend http_front\n   bind *:80\n   stats uri /haproxy?stats\n   default_backend http_back\n\n# Configure HAProxy to route requests to swarm nodes on port 8080\nbackend http_back\n   balance roundrobin\n   server node1 192.168.99.100:8080 check\n   server node2 192.168.99.101:8080 check\n   server node3 192.168.99.102:8080 check\n```\n\nWhen you access the HAProxy load balancer on port 80, it forwards requests to nodes in the swarm. The swarm routing mesh routes the request to an active task. If, for any reason the swarm scheduler dispatches tasks to different nodes, you don’t need to reconfigure the load balancer.\n\nYou can configure any type of load balancer to route requests to swarm nodes. To learn more about HAProxy, see the [HAProxy documentation](https://cbonte.github.io/haproxy-dconv/).\n\n### Without the routing mesh\n\nTo use an external load balancer without the routing mesh, set `--endpoint-mode` to `dnsrr` instead of the default value of `vip`. In this case, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these. You are responsible for providing the list of IP addresses and ports to your load balancer. See [Configure service discovery](https://docs.docker.com/network/overlay#configure-service-discovery).\n\n## Learn more\n\n- [Deploy services to a swarm](../services/index)\n\n[guide](https://docs.docker.com/search/?q=guide), [swarm mode](https://docs.docker.com/search/?q=swarm%20mode), [swarm](https://docs.docker.com/search/?q=swarm), [network](https://docs.docker.com/search/?q=network), [ingress](https://docs.docker.com/search/?q=ingress), [routing mesh](https://docs.docker.com/search/?q=routing%20mesh)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/swarm/ingress/](https://docs.docker.com/engine/swarm/ingress/)"
- name: Use the Docker command line
  id: engine/reference/commandline/cli/index
  summary: Depending on your Docker system configuration, you may be required to preface each docker command with sudo
  description: "# Use the Docker command line\n\n## docker\n\nTo list available commands, either run `docker` with no parameters or execute `docker help`:\n\n``` \n$ docker\nUsage: docker [OPTIONS] COMMAND [ARG...]\n       docker [ --help | -v | --version ]\n\nA self-sufficient runtime for containers.\n\nOptions:\n      --config string      Location of client config files (default \"/root/.docker\")\n  -c, --context string     Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with \"docker context use\")\n  -D, --debug              Enable debug mode\n      --help               Print usage\n  -H, --host value         Daemon socket(s) to connect to (default [])\n  -l, --log-level string   Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\")\n      --tls                Use TLS; implied by --tlsverify\n      --tlscacert string   Trust certs signed only by this CA (default \"/root/.docker/ca.pem\")\n      --tlscert string     Path to TLS certificate file (default \"/root/.docker/cert.pem\")\n      --tlskey string      Path to TLS key file (default \"/root/.docker/key.pem\")\n      --tlsverify          Use TLS and verify the remote\n  -v, --version            Print version information and quit\n\nCommands:\n    attach    Attach to a running container\n    # […]\n```\n\n## Description\n\nDepending on your Docker system configuration, you may be required to preface each `docker` command with `sudo`. To avoid having to use `sudo` with the `docker` command, your system administrator can create a Unix group called `docker` and add users to it.\n\nFor more information about installing Docker or `sudo` configuration, refer to the [installation](https://docs.docker.com/install/) instructions for your operating system.\n\n## Environment variables\n\nThe following list of environment variables are supported by the `docker` command line:\n\n| Variable                      | Description                                                                                                                                                                                                                                                                                                       |\n|:------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `DOCKER_API_VERSION`          | Override the negotiated API version to use for debugging (e.g. `1.19`)                                                                                                                                                                                                                                            |\n| `DOCKER_CERT_PATH`            | Location of your authentication keys. This variable is used both by the `docker` CLI and the [`dockerd` daemon](../dockerd/index)                                                                                                                                                                                 |\n| `DOCKER_CONFIG`               | The location of your client configuration files.                                                                                                                                                                                                                                                                  |\n| `DOCKER_CONTENT_TRUST_SERVER` | The URL of the Notary server to use. Defaults to the same URL as the registry.                                                                                                                                                                                                                                    |\n| `DOCKER_CONTENT_TRUST`        | When set Docker uses notary to sign and verify images. Equates to `--disable-content-trust=false` for build, create, pull, push, run.                                                                                                                                                                             |\n| `DOCKER_CONTEXT`              | Name of the `docker context` to use (overrides `DOCKER_HOST` env var and default context set with `docker context use`)                                                                                                                                                                                           |\n| `DOCKER_DEFAULT_PLATFORM`     | Default platform for commands that take the `--platform` flag.                                                                                                                                                                                                                                                    |\n| `DOCKER_HIDE_LEGACY_COMMANDS` | When set, Docker hides “legacy” top-level commands (such as `docker rm`, and `docker pull`) in `docker help` output, and only `Management commands` per object-type (e.g., `docker container`) are printed. This may become the default in a future release, at which point this environment-variable is removed. |\n| `DOCKER_HOST`                 | Daemon socket to connect to.                                                                                                                                                                                                                                                                                      |\n| `DOCKER_STACK_ORCHESTRATOR`   | Configure the default orchestrator to use when using `docker stack` management commands.                                                                                                                                                                                                                          |\n| `DOCKER_TLS_VERIFY`           | When set Docker uses TLS and verifies the remote. This variable is used both by the `docker` CLI and the [`dockerd` daemon](../dockerd/index)                                                                                                                                                                     |\n| `BUILDKIT_PROGRESS`           | Set type of progress output (`auto`, `plain`, `tty`) when [building](../build/index) with [BuildKit backend](../../builder/index#buildkit). Use plain to show container output (default `auto`).                                                                                                                  |\n\nBecause Docker is developed using Go, you can also use any environment variables used by the Go runtime. In particular, you may find these useful:\n\n- `HTTP_PROXY`\n- `HTTPS_PROXY`\n- `NO_PROXY`\n\nThese Go environment variables are case-insensitive. See the [Go specification](https://golang.org/pkg/net/http/) for details on these variables.\n\n## Configuration files\n\nBy default, the Docker command line stores its configuration files in a directory called `.docker` within your `$HOME` directory.\n\nDocker manages most of the files in the configuration directory and you should not modify them. However, you *can* modify the `config.json` file to control certain aspects of how the `docker` command behaves.\n\nYou can modify the `docker` command behavior using environment variables or command-line options. You can also use options within `config.json` to modify some of the same behavior. If an environment variable and the `--config` flag are set, the flag takes precedent over the environment variable. Command line options override environment variables and environment variables override properties you specify in a `config.json` file.\n\n### Change the `.docker` directory\n\nTo specify a different directory, use the `DOCKER_CONFIG` environment variable or the `--config` command line option. If both are specified, then the `--config` option overrides the `DOCKER_CONFIG` environment variable. The example below overrides the `docker ps` command using a `config.json` file located in the `~/testconfigs/` directory.\n\n``` \n$ docker --config ~/testconfigs/ ps\n```\n\nThis flag only applies to whatever command is being ran. For persistent configuration, you can set the `DOCKER_CONFIG` environment variable in your shell (e.g. `~/.profile` or `~/.bashrc`). The example below sets the new directory to be `HOME/newdir/.docker`.\n\n``` \n$ echo export DOCKER_CONFIG=$HOME/newdir/.docker > ~/.profile\n```\n\n## Docker CLI configuration file (`config.json`) properties\n\nUse the Docker CLI configuration to customize settings for the `docker` CLI. The configuration file uses JSON formatting, and properties:\n\nBy default, configuration file is stored in `~/.docker/config.json`. Refer to the [change the `.docker` directory](#change-the-docker-directory) section to use a different location.\n\n> **Warning**\n>\n> The configuration file and other files inside the `~/.docker` configuration directory may contain sensitive information, such as authentication information for proxies or, depending on your credential store, credentials for your image registries. Review your configuration file’s content before sharing with others, and prevent committing the file to version control.\n\n### Customize the default output format for commands\n\nThese fields allow you to customize the default output format for some commands if no `--format` flag is provided.\n\n| Property               | Description                                                                                                                                                                                                                               |\n|:-----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `configFormat`         | Custom default format for `docker config ls` output. Refer to the [**format the output** section in the `docker config ls` documentation](../config_ls/index#format-the-output) for a list of supported formatting directives.            |\n| `imagesFormat`         | Custom default format for `docker images` / `docker image ls` output. Refer to the [**format the output** section in the `docker images` documentation](../images/index#format-the-output) for a list of supported formatting directives. |\n| `nodesFormat`          | Custom default format for `docker node ls` output. Refer to the [**formatting** section in the `docker node ls` documentation](../node_ls/index#formatting) for a list of supported formatting directives.                                |\n| `pluginsFormat`        | Custom default format for `docker plugin ls` output. Refer to the [**formatting** section in the `docker plugin ls` documentation](../plugin_ls/index#formatting) for a list of supported formatting directives.                          |\n| `psFormat`             | Custom default format for `docker ps` / `docker container ps` output. Refer to the [**formatting** section in the `docker ps` documentation](../ps/index#formatting) for a list of supported formatting directives.                       |\n| `secretFormat`         | Custom default format for `docker secret ls` output. Refer to the [**format the output** section in the `docker secret ls` documentation](../secret_ls/index#format-the-output) for a list of supported formatting directives.            |\n| `serviceInspectFormat` | Custom default format for `docker service inspect` output. Refer to the [**formatting** section in the `docker service inspect` documentation](../service_inspect/index#formatting) for a list of supported formatting directives.        |\n| `servicesFormat`       | Custom default format for `docker service ls` output. Refer to the [**formatting** section in the `docker service ls` documentation](../service_ls/index#formatting) for a list of supported formatting directives.                       |\n| `statsFormat`          | Custom default format for `docker stats` output. Refer to the [**formatting** section in the `docker stats` documentation](../stats/index#formatting) for a list of supported formatting directives.                                      |\n\n### Custom HTTP headers\n\nThe property `HttpHeaders` specifies a set of headers to include in all messages sent from the Docker client to the daemon. Docker does not try to interpret or understand these headers; it simply puts them into the messages. Docker does not allow these headers to change any headers it sets for itself.\n\n### Credential store options\n\nThe property `credsStore` specifies an external binary to serve as the default credential store. When this property is set, `docker login` will attempt to store credentials in the binary specified by `docker-credential-<value>` which is visible on `$PATH`. If this property is not set, credentials will be stored in the `auths` property of the config. For more information, see the [**Credentials store** section in the `docker login` documentation](../login/index#credentials-store)\n\nThe property `credHelpers` specifies a set of credential helpers to use preferentially over `credsStore` or `auths` when storing and retrieving credentials for specific registries. If this property is set, the binary `docker-credential-<value>` will be used when storing or retrieving credentials for a specific registry. For more information, see the [**Credential helpers** section in the `docker login` documentation](../login/index#credential-helpers)\n\n### Orchestrator options for docker stacks\n\nThe property `stackOrchestrator` specifies the default orchestrator to use when running `docker stack` management commands. Valid values are `\"swarm\"`, `\"kubernetes\"`, and `\"all\"`. This property can be overridden with the `DOCKER_STACK_ORCHESTRATOR` environment variable, or the `--orchestrator` flag.\n\n### Automatic proxy configuration for containers\n\nThe property `proxies` specifies proxy environment variables to be automatically set on containers, and set as `--build-arg` on containers used during `docker build`. A `\"default\"` set of proxies can be configured, and will be used for any docker daemon that the client connects to, or a configuration per host (docker daemon), for example, “https://docker-daemon1.example.com”. The following properties can be set for each environment:\n\n| Property     | Description                                                                                             |\n|:-------------|:--------------------------------------------------------------------------------------------------------|\n| `httpProxy`  | Default value of `HTTP_PROXY` and `http_proxy` for containers, and as `--build-arg` on `docker build`   |\n| `httpsProxy` | Default value of `HTTPS_PROXY` and `https_proxy` for containers, and as `--build-arg` on `docker build` |\n| `ftpProxy`   | Default value of `FTP_PROXY` and `ftp_proxy` for containers, and as `--build-arg` on `docker build`     |\n| `noProxy`    | Default value of `NO_PROXY` and `no_proxy` for containers, and as `--build-arg` on `docker build`       |\n\nThese settings are used to configure proxy settings for containers only, and not used as proxy settings for the `docker` CLI or the `dockerd` daemon. Refer to the [environment variables](#environment-variables) and [HTTP/HTTPS proxy](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) sections for configuring proxy settings for the cli and daemon.\n\n> **Warning**\n>\n> Proxy settings may contain sensitive information (for example, if the proxy requires authentication). Environment variables are stored as plain text in the container’s configuration, and as such can be inspected through the remote API or committed to an image when using `docker commit`.\n\n### Default key-sequence to detach from containers\n\nOnce attached to a container, users detach from it and leave it running using the using `CTRL-p CTRL-q` key sequence. This detach key sequence is customizable using the `detachKeys` property. Specify a `<sequence>` value for the property. The format of the `<sequence>` is a comma-separated list of either a letter \\[a-Z\\], or the `ctrl-` combined with any of the following:\n\n- `a-z` (a single lowercase alpha character )\n- `@` (at sign)\n- `[` (left bracket)\n- `\\\\` (two backward slashes)\n- `_` (underscore)\n- `^` (caret)\n\nYour customization applies to all containers started in with your Docker client. Users can override your custom or the default key sequence on a per-container basis. To do this, the user specifies the `--detach-keys` flag with the `docker attach`, `docker exec`, `docker run` or `docker start` command.\n\n### CLI Plugin options\n\nThe property `plugins` contains settings specific to CLI plugins. The key is the plugin name, while the value is a further map of options, which are specific to that plugin.\n\n### Sample configuration file\n\nFollowing is a sample `config.json` file to illustrate the format used for various fields:\n\n``` \n{\n  \"HttpHeaders\": {\n    \"MyHeader\": \"MyValue\"\n  },\n  \"psFormat\": \"table {{.ID}}\\\\t{{.Image}}\\\\t{{.Command}}\\\\t{{.Labels}}\",\n  \"imagesFormat\": \"table {{.ID}}\\\\t{{.Repository}}\\\\t{{.Tag}}\\\\t{{.CreatedAt}}\",\n  \"pluginsFormat\": \"table {{.ID}}\\t{{.Name}}\\t{{.Enabled}}\",\n  \"statsFormat\": \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\",\n  \"servicesFormat\": \"table {{.ID}}\\t{{.Name}}\\t{{.Mode}}\",\n  \"secretFormat\": \"table {{.ID}}\\t{{.Name}}\\t{{.CreatedAt}}\\t{{.UpdatedAt}}\",\n  \"configFormat\": \"table {{.ID}}\\t{{.Name}}\\t{{.CreatedAt}}\\t{{.UpdatedAt}}\",\n  \"serviceInspectFormat\": \"pretty\",\n  \"nodesFormat\": \"table {{.ID}}\\t{{.Hostname}}\\t{{.Availability}}\",\n  \"detachKeys\": \"ctrl-e,e\",\n  \"credsStore\": \"secretservice\",\n  \"credHelpers\": {\n    \"awesomereg.example.org\": \"hip-star\",\n    \"unicorn.example.com\": \"vcbait\"\n  },\n  \"stackOrchestrator\": \"kubernetes\",\n  \"plugins\": {\n    \"plugin1\": {\n      \"option\": \"value\"\n    },\n    \"plugin2\": {\n      \"anotheroption\": \"anothervalue\",\n      \"athirdoption\": \"athirdvalue\"\n    }\n  },\n  \"proxies\": {\n    \"default\": {\n      \"httpProxy\":  \"http://user:pass@example.com:3128\",\n      \"httpsProxy\": \"https://my-proxy.example.com:3129\",\n      \"noProxy\":    \"intra.mycorp.example.com\",\n      \"ftpProxy\":   \"http://user:pass@example.com:3128\"\n    },\n    \"https://manager1.mycorp.example.com:2377\": {\n      \"httpProxy\":  \"http://user:pass@example.com:3128\",\n      \"httpsProxy\": \"https://my-proxy.example.com:3129\"\n    }\n  }\n}\n```\n\n### Experimental features\n\nExperimental features provide early access to future product functionality. These features are intended for testing and feedback, and they may change between releases without warning or can be removed from a future release.\n\nStarting with Docker 20.10, experimental CLI features are enabled by default, and require no configuration to enable them.\n\n### Notary\n\nIf using your own notary server and a self-signed certificate or an internal Certificate Authority, you need to place the certificate at `tls/<registry_url>/ca.crt` in your docker config directory.\n\nAlternatively you can trust the certificate globally by adding it to your system’s list of root Certificate Authorities.\n\n## Examples\n\n### Display help text\n\nTo list the help on any command just execute the command, followed by the `--help` option.\n\n``` \n$ docker run --help\n\nUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n\nRun a command in a new container\n\nOptions:\n      --add-host value             Add a custom host-to-IP mapping (host:ip) (default [])\n  -a, --attach value               Attach to STDIN, STDOUT or STDERR (default [])\n<...>\n```\n\n### Option types\n\nSingle character command line options can be combined, so rather than typing `docker run -i -t --name test busybox sh`, you can write `docker run -it --name test busybox sh`.\n\n#### Boolean\n\nBoolean options take the form `-d=false`. The value you see in the help text is the default value which is set if you do **not** specify that flag. If you specify a Boolean flag without a value, this will set the flag to `true`, irrespective of the default value.\n\nFor example, running `docker run -d` will set the value to `true`, so your container **will** run in “detached” mode, in the background.\n\nOptions which default to `true` (e.g., `docker build --rm=true`) can only be set to the non-default value by explicitly setting them to `false`:\n\n``` \n$ docker build --rm=false .\n```\n\n#### Multi\n\nYou can specify options like `-a=[]` multiple times in a single command line, for example in these commands:\n\n``` \n$ docker run -a stdin -a stdout -i -t ubuntu /bin/bash\n\n$ docker run -a stdin -a stdout -a stderr ubuntu /bin/ls\n```\n\nSometimes, multiple options can call for a more complex value string as for `-v`:\n\n``` \n$ docker run -v /host:/container example/mysql\n```\n\n> **Note**\n>\n> Do not use the `-t` and `-a stderr` options together due to limitations in the `pty` implementation. All `stderr` in `pty` mode simply goes to `stdout`.\n\n#### Strings and Integers\n\nOptions like `--name=\"\"` expect a string, and they can only be specified once. Options like `-c=0` expect an integer, and they can only be specified once.\n\n[Docker](https://docs.docker.com/search/?q=Docker), [Docker documentation](https://docs.docker.com/search/?q=Docker%20documentation), [CLI](https://docs.docker.com/search/?q=CLI), [command line](https://docs.docker.com/search/?q=command%20line), [config.json](https://docs.docker.com/search/?q=config.json), [CLI configuration file](https://docs.docker.com/search/?q=CLI%20configuration%20file)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/reference/commandline/cli/](https://docs.docker.com/engine/reference/commandline/cli/)"
- name: Using profiles with Compose
  id: compose/profiles/index
  summary: Profiles allow adjusting the Compose application model for various usages and environments by selectively enabling services
  description: "# Using profiles with Compose\n\nProfiles allow adjusting the Compose application model for various usages and environments by selectively enabling services. This is achieved by assigning each service to zero or more profiles. If unassigned, the service is *always* started but if assigned, it is only started if the profile is activated.\n\nThis allows one to define additional services in a single `docker-compose.yml` file that should only be started in specific scenarios, e.g. for debugging or development tasks.\n\n## Assigning profiles to services\n\nServices are associated with profiles through the [`profiles` attribute](../compose-file/compose-file-v3/index#profiles) which takes an array of profile names:\n\n``` \nversion: \"3.9\"\nservices:\n  frontend:\n    image: frontend\n    profiles: [\"frontend\"]\n\n  phpmyadmin:\n    image: phpmyadmin\n    depends_on:\n      - db\n    profiles:\n      - debug\n\n  backend:\n    image: backend\n\n  db:\n    image: mysql\n```\n\nHere the services `frontend` and `phpmyadmin` are assigned to the profiles `frontend` and `debug` respectively and as such are only started when their respective profiles are enabled.\n\nServices without a `profiles` attribute will *always* be enabled, i.e. in this case running `docker-compose up` would only start `backend` and `db`.\n\nValid profile names follow the regex format of `[a-zA-Z0-9][a-zA-Z0-9_.-]+`.\n\n> **Note**\n>\n> The core services of your application should not be assigned `profiles` so they will always be enabled and automatically started.\n\n## Enabling profiles\n\nTo enable a profile supply the `--profile` [command-line option](../reference/index) or use the [`COMPOSE_PROFILES` environment variable](../reference/envvars/index#compose_profiles):\n\n``` \n$ docker-compose --profile debug up\n$ COMPOSE_PROFILES=debug docker-compose up\n```\n\nThe above command would both start your application with the `debug` profile enabled. Using the `docker-compose.yml` file above, this would start the services `backend`, `db` and `phpmyadmin`.\n\nMultiple profiles can be specified by passing multiple `--profile` flags or a comma-separated list for the `COMPOSE_PROFILES` environment variable:\n\n``` \n$ docker-compose --profile frontend --profile debug up\n$ COMPOSE_PROFILES=frontend,debug docker-compose up\n```\n\n## Auto-enabling profiles and dependency resolution\n\nWhen a service with assigned `profiles` is explicitly targeted on the command line its profiles will be enabled automatically so you don’t need to enable them manually. This can be used for one-off services and debugging tools. As an example consider this configuration:\n\n``` \nversion: \"3.9\"\nservices:\n  backend:\n    image: backend\n\n  db:\n    image: mysql\n\n  db-migrations:\n    image: backend\n    command: myapp migrate\n    depends_on:\n      - db\n    profiles:\n      - tools\n```\n\n``` \n# will only start backend and db\n$ docker-compose up -d\n\n# this will run db-migrations (and - if necessary - start db)\n# by implicitly enabling profile `tools`\n$ docker-compose run db-migrations\n```\n\nBut keep in mind that `docker-compose` will only automatically enable the profiles of the services on the command line and not of any dependencies. This means that all services the targeted service `depends_on` must have a common profile with it, be always enabled (by omitting `profiles`) or have a matching profile enabled explicitly:\n\n``` \nversion: \"3.9\"\nservices:\n  web:\n    image: web\n\n  mock-backend:\n    image: backend\n    profiles: [\"dev\"]\n    depends_on:\n      - db\n\n  db:\n    image: mysql\n    profiles: [\"dev\"]\n\n  phpmyadmin:\n    image: phpmyadmin\n    profiles: [\"debug\"]\n    depends_on:\n      - db\n```\n\n``` \n# will only start \"web\"\n$ docker-compose up -d\n\n# this will start mock-backend (and - if necessary - db)\n# by implicitly enabling profile `dev`\n$ docker-compose up -d mock-backend\n\n# this will fail because profile \"dev\" is disabled\n$ docker-compose up phpmyadmin\n```\n\nAlthough targeting `phpmyadmin` will automatically enable its profiles - i.e. `debug` - it will not automatically enable the profile(s) required by `db` - i.e. `dev`. To fix this you either have to add the `debug` profile to the `db` service:\n\n``` \ndb:\n  image: mysql\n  profiles: [\"debug\", \"dev\"]\n```\n\nor enable a profile of `db` explicitly:\n\n``` \n# profile \"debug\" is enabled automatically by targeting phpmyadmin\n$ docker-compose --profile dev up phpmyadmin\n$ COMPOSE_PROFILES=dev docker-compose up phpmyadmin\n```\n\n## Compose documentation\n\n- [User guide](../index)\n- [Installing Compose](../install/index)\n- [Getting Started](../gettingstarted/index)\n- [Command line reference](../reference/index)\n- [Compose file reference](../compose-file/index)\n- [Sample apps with Compose](../samples-for-compose/index)\n\n[cli](https://docs.docker.com/search/?q=cli), [compose](https://docs.docker.com/search/?q=compose), [profile](https://docs.docker.com/search/?q=profile), [profiles reference](https://docs.docker.com/search/?q=profiles%20reference)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/compose/profiles/](https://docs.docker.com/compose/profiles/)"
- name: Verify repository client with certificates
  id: engine/security/certificates/index
  summary: In Running Docker with HTTPS, you learned that, by default, Docker runs via a non-networked Unix socket and TLS must be enabled in order to have the Docker client and the daemon communicate securely over HTTPS
  description: "# Verify repository client with certificates\n\nIn [Running Docker with HTTPS](../protect-access/index), you learned that, by default, Docker runs via a non-networked Unix socket and TLS must be enabled in order to have the Docker client and the daemon communicate securely over HTTPS. TLS ensures authenticity of the registry endpoint and that traffic to/from registry is encrypted.\n\nThis article demonstrates how to ensure the traffic between the Docker registry server and the Docker daemon (a client of the registry server) is encrypted and properly authenticated using *certificate-based client-server authentication*.\n\nWe show you how to install a Certificate Authority (CA) root certificate for the registry and how to set the client TLS certificate for verification.\n\n## Understand the configuration\n\nA custom certificate is configured by creating a directory under `/etc/docker/certs.d` using the same name as the registry’s hostname, such as `localhost`. All `*.crt` files are added to this directory as CA roots.\n\n> **Note**\n>\n> On Linux any root certificates authorities are merged with the system defaults, including the host’s root CA set. If you are running Docker on Windows Server, or Docker Desktop for Windows with Windows containers, the system default certificates are only used when no custom root certificates are configured.\n\nThe presence of one or more `<filename>.key/cert` pairs indicates to Docker that there are custom certificates required for access to the desired repository.\n\n> **Note**: If multiple certificates exist, each is tried in alphabetical order. If there is a 4xx-level or 5xx-level authentication error, Docker continues to try with the next certificate.\n\nThe following illustrates a configuration with custom certificates:\n\n``` \n    /etc/docker/certs.d/        <-- Certificate directory\n    └── localhost:5000          <-- Hostname:port\n       ├── client.cert          <-- Client certificate\n       ├── client.key           <-- Client key\n       └── ca.crt               <-- Certificate authority that signed\n                                    the registry certificate\n```\n\nThe preceding example is operating-system specific and is for illustrative purposes only. You should consult your operating system documentation for creating an os-provided bundled certificate chain.\n\n## Create the client certificates\n\nUse OpenSSL’s `genrsa` and `req` commands to first generate an RSA key and then use the key to create the certificate.\n\n``` \n$ openssl genrsa -out client.key 4096\n$ openssl req -new -x509 -text -key client.key -out client.cert\n```\n\n> **Note**: These TLS commands only generate a working set of certificates on Linux. The version of OpenSSL in macOS is incompatible with the type of certificate Docker requires.\n\n## Troubleshooting tips\n\nThe Docker daemon interprets `.crt` files as CA certificates and `.cert` files as client certificates. If a CA certificate is accidentally given the extension `.cert` instead of the correct `.crt` extension, the Docker daemon logs the following error message:\n\n``` \nMissing key KEY_NAME for client certificate CERT_NAME. CA certificates should use the extension .crt.\n```\n\nIf the Docker registry is accessed without a port number, do not add the port to the directory name. The following shows the configuration for a registry on default port 443 which is accessed with `docker login my-https.registry.example.com`:\n\n``` \n    /etc/docker/certs.d/\n    └── my-https.registry.example.com          <-- Hostname without port\n       ├── client.cert\n       ├── client.key\n       └── ca.crt\n```\n\n## Related information\n\n- [Use trusted images](../trust/index)\n- [Protect the Docker daemon socket](../protect-access/index)\n\n[Usage](https://docs.docker.com/search/?q=Usage), [registry](https://docs.docker.com/search/?q=registry), [repository](https://docs.docker.com/search/?q=repository), [client](https://docs.docker.com/search/?q=client), [root](https://docs.docker.com/search/?q=root), [certificate](https://docs.docker.com/search/?q=certificate), [docker](https://docs.docker.com/search/?q=docker), [apache](https://docs.docker.com/search/?q=apache), [ssl](https://docs.docker.com/search/?q=ssl), [tls](https://docs.docker.com/search/?q=tls), [documentation](https://docs.docker.com/search/?q=documentation), [examples](https://docs.docker.com/search/?q=examples), [articles](https://docs.docker.com/search/?q=articles), [tutorials](https://docs.docker.com/search/?q=tutorials)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/security/certificates/](https://docs.docker.com/engine/security/certificates/)"
- name: Vulnerability scanning for Docker local images
  id: engine/scan/index
  summary: Did you know that you can now get 10 free scans per month? Sign in to Docker to start scanning your images for vulnerabilities
  description: "# Vulnerability scanning for Docker local images\n\nScan your images for free\n\nDid you know that you can now get 10 free scans per month? Sign in to Docker to start scanning your images for vulnerabilities.\n\n[Sign in](https://www.docker.com/pricing?utm_source=docker&utm_medium=webreferral&utm_campaign=docs_driven_upgrade_scan)\n\nLooking to speed up your development cycles? Quickly detect and learn how to remediate CVEs in your images by running `docker scan IMAGE_NAME`. Check out [How to scan images](#how-to-scan-images) for details.\n\nVulnerability scanning for Docker local images allows developers and development teams to review the security state of the container images and take actions to fix issues identified during the scan, resulting in more secure deployments. Docker Scan runs on Snyk engine, providing users with visibility into the security posture of their local Dockerfiles and local images.\n\nUsers trigger vulnerability scans through the CLI, and use the CLI to view the scan results. The scan results contain a list of Common Vulnerabilities and Exposures (CVEs), the sources, such as OS packages and libraries, versions in which they were introduced, and a recommended fixed version (if available) to remediate the CVEs discovered.\n\n> **Log4j 2 CVE-2021-44228**\n>\n> Versions of `docker Scan` earlier than `v0.11.0` are not able to detect [Log4j 2 CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228). You must update your Docker Desktop installation to 4.3.1 or higher to fix this issue. For more information, see [Scan images for Log4j 2 CVE](#scan-images-for-log4j-2-cve).\n\nFor information about the system requirements to run vulnerability scanning, see [Prerequisites](#prerequisites).\n\nThis page contains information about the `docker scan` CLI command. For information about automatically scanning Docker images through Docker Hub, see [Hub Vulnerability Scanning](https://docs.docker.com/docker-hub/vulnerability-scanning/).\n\n## Scan images for Log4j 2 CVE\n\nDocker Scan versions earlier than `v0.11.0` do not detect [Log4j 2 CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228) when you scan your images for vulnerabilities. You must update your Docker installation to the latest version to fix this issue.\n\nIf you are using the `docker scan` plugin shipped with Docker Desktop, update Docker Desktop to version 4.3.1 or higher. See the release notes for [Mac](https://docs.docker.com/desktop/mac/release-notes/) and [Windows](https://docs.docker.com/desktop/windows/release-notes/) for download information.\n\nIf you are using Linux, run the following command to manually install the latest version of `docker scan`:\n\nOn `.deb` based distros, such as Ubuntu and Debian:\n\n``` \n$ apt-get update && apt-get install docker-scan-plugin\n```\n\nOn rpm-based distros, such as CentOS or Fedora:\n\n``` \n$ yum install docker-scan-plugin\n```\n\nAlternatively, you can manually download the `docker scan` binaries from the [Docker Scan](https://github.com/docker/scan-cli-plugin/releases/tag/v0.11.0) GitHub repository and [install](https://github.com/docker/scan-cli-plugin) in the plugins directory.\n\n### Verify the `docker scan` version\n\nAfter upgrading `docker scan`, verify you are running the latest version by running the following command:\n\n``` \n$ docker scan --accept-license --version\nVersion:    v0.12.0\nGit commit: 1074dd0\nProvider:   Snyk (1.790.0 (standalone))\n```\n\nIf your code output contains `ORGAPACHELOGGINGLOG4J`, it is likely that your code is affected by the Log4j 2 CVE-2021-44228 vulnerability. When you run the updated version of `docker scan`, you should also see a message in the output log similar to:\n\n``` \nUpgrade org.apache.logging.log4j:log4j-core@2.14.0 to org.apache.logging.log4j:log4j-core@2.15.0 to fix\n✗ Arbitrary Code Execution (new) [Critical Severity][https://snyk.io/vuln/SNYK-JAVA-ORGAPACHELOGGINGLOG4J-2314720] in org.apache.logging.log4j:log4j-core@2.14.0\nintroduced by org.apache.logging.log4j:log4j-core@2.14.0\n```\n\nFor more information, read our blog post [Apache Log4j 2 CVE-2021-44228](https://www.docker.com/blog/apache-log4j-2-cve-2021-44228/).\n\n## How to scan images\n\nThe `docker scan` command allows you to scan existing Docker images using the image name or ID. For example, run the following command to scan the hello-world image:\n\n``` \n$ docker scan hello-world\n\nTesting hello-world...\n\nOrganization:      docker-desktop-test\nPackage manager:   linux\nProject name:      docker-image|hello-world\nDocker image:      hello-world\nLicenses:          enabled\n\n✓ Tested 0 dependencies for known issues, no vulnerable paths found.\n\nNote that we do not currently have vulnerability data for your image.\n```\n\n### Get a detailed scan report\n\nYou can get a detailed scan report about a Docker image by providing the Dockerfile used to create the image. The syntax is `docker scan --file PATH_TO_DOCKERFILE DOCKER_IMAGE`.\n\nFor example, if you apply the option to the `docker-scan` test image, it displays the following result:\n\n``` \n$ docker scan --file Dockerfile docker-scan:e2e\nTesting docker-scan:e2e\n...\n✗ High severity vulnerability found in perl\n  Description: Integer Overflow or Wraparound\n  Info: https://snyk.io/vuln/SNYK-DEBIAN10-PERL-570802\n  Introduced through: git@1:2.20.1-2+deb10u3, meta-common-packages@meta\n  From: git@1:2.20.1-2+deb10u3 > perl@5.28.1-6\n  From: git@1:2.20.1-2+deb10u3 > liberror-perl@0.17027-2 > perl@5.28.1-6\n  From: git@1:2.20.1-2+deb10u3 > perl@5.28.1-6 > perl/perl-modules-5.28@5.28.1-6\n  and 3 more...\n  Introduced by your base image (golang:1.14.6)\n\nOrganization:      docker-desktop-test\nPackage manager:   deb\nTarget file:       Dockerfile\nProject name:      docker-image|99138c65ebc7\nDocker image:      99138c65ebc7\nBase image:        golang:1.14.6\nLicenses:          enabled\n\nTested 200 dependencies for known issues, found 157 issues.\n\nAccording to our scan, you are currently using the most secure version of the selected base image\n```\n\n### Excluding the base image\n\nWhen using docker scan with the `--file` flag, you can also add the `--exclude-base` tag. This excludes the base image (specified in the Dockerfile using the `FROM` directive) vulnerabilities from your report. For example:\n\n``` \n$ docker scan --file Dockerfile --exclude-base docker-scan:e2e\nTesting docker-scan:e2e\n...\n✗ Medium severity vulnerability found in libidn2/libidn2-0\n  Description: Improper Input Validation\n  Info: https://snyk.io/vuln/SNYK-DEBIAN10-LIBIDN2-474100\n  Introduced through: iputils/iputils-ping@3:20180629-2+deb10u1, wget@1.20.1-1.1, curl@7.64.0-4+deb10u1, git@1:2.20.1-2+deb10u3\n  From: iputils/iputils-ping@3:20180629-2+deb10u1 > libidn2/libidn2-0@2.0.5-1+deb10u1\n  From: wget@1.20.1-1.1 > libidn2/libidn2-0@2.0.5-1+deb10u1\n  From: curl@7.64.0-4+deb10u1 > curl/libcurl4@7.64.0-4+deb10u1 > libidn2/libidn2-0@2.0.5-1+deb10u1\n  and 3 more...\n  Introduced in your Dockerfile by 'RUN apk add -U --no-cache wget tar'\n\n\n\nOrganization:      docker-desktop-test\nPackage manager:   deb\nTarget file:       Dockerfile\nProject name:      docker-image|99138c65ebc7\nDocker image:      99138c65ebc7\nBase image:        golang:1.14.6\nLicenses:          enabled\n\nTested 200 dependencies for known issues, found 16 issues.\n```\n\n### Viewing the JSON output\n\nYou can also display the scan result as a JSON output by adding the `--json` flag to the command. For example:\n\n``` \n$ docker scan --json hello-world\n{\n  \"vulnerabilities\": [],\n  \"ok\": true,\n  \"dependencyCount\": 0,\n  \"org\": \"docker-desktop-test\",\n  \"policy\": \"# Snyk (https://snyk.io) policy file, patches or ignores known vulnerabilities.\\nversion: v1.19.0\\nignore: {}\\npatch: {}\\n\",\n  \"isPrivate\": true,\n  \"licensesPolicy\": {\n    \"severities\": {},\n    \"orgLicenseRules\": {\n      \"AGPL-1.0\": {\n        \"licenseType\": \"AGPL-1.0\",\n        \"severity\": \"high\",\n        \"instructions\": \"\"\n      },\n      ...\n      \"SimPL-2.0\": {\n        \"licenseType\": \"SimPL-2.0\",\n        \"severity\": \"high\",\n        \"instructions\": \"\"\n      }\n    }\n  },\n  \"packageManager\": \"linux\",\n  \"ignoreSettings\": null,\n  \"docker\": {\n    \"baseImageRemediation\": {\n      \"code\": \"SCRATCH_BASE_IMAGE\",\n      \"advice\": [\n        {\n          \"message\": \"Note that we do not currently have vulnerability data for your image.\",\n          \"bold\": true,\n          \"color\": \"yellow\"\n        }\n      ]\n    },\n    \"binariesVulns\": {\n      \"issuesData\": {},\n      \"affectedPkgs\": {}\n    }\n  },\n  \"summary\": \"No known vulnerabilities\",\n  \"filesystemPolicy\": false,\n  \"uniqueCount\": 0,\n  \"projectName\": \"docker-image|hello-world\",\n  \"path\": \"hello-world\"\n}\n```\n\nIn addition to the `--json` flag, you can also use the `--group-issues` flag to display a vulnerability only once in the scan report:\n\n``` \n$ docker scan --json --group-issues docker-scan:e2e\n{\n    {\n      \"title\": \"Improper Check for Dropped Privileges\",\n      ...\n      \"packageName\": \"bash\",\n      \"language\": \"linux\",\n      \"packageManager\": \"debian:10\",\n      \"description\": \"## Overview\\nAn issue was discovered in disable_priv_mode in shell.c in GNU Bash through 5.0 patch 11. By default, if Bash is run with its effective UID not equal to its real UID, it will drop privileges by setting its effective UID to its real UID. However, it does so incorrectly. On Linux and other systems that support \\\"saved UID\\\" functionality, the saved UID is not dropped. An attacker with command execution in the shell can use \\\"enable -f\\\" for runtime loading of a new builtin, which can be a shared object that calls setuid() and therefore regains privileges. However, binaries running with an effective UID of 0 are unaffected.\\n\\n## References\\n- [CONFIRM](https://security.netapp.com/advisory/ntap-20200430-0003/)\\n- [Debian Security Tracker](https://security-tracker.debian.org/tracker/CVE-2019-18276)\\n- [GitHub Commit](https://github.com/bminor/bash/commit/951bdaad7a18cc0dc1036bba86b18b90874d39ff)\\n- [MISC](http://packetstormsecurity.com/files/155498/Bash-5.0-Patch-11-Privilege-Escalation.html)\\n- [MISC](https://www.youtube.com/watch?v=-wGtxJ8opa8)\\n- [Ubuntu CVE Tracker](http://people.ubuntu.com/~ubuntu-security/cve/CVE-2019-18276)\\n\",\n      \"identifiers\": {\n        \"ALTERNATIVE\": [],\n        \"CVE\": [\n          \"CVE-2019-18276\"\n        ],\n        \"CWE\": [\n          \"CWE-273\"\n        ]\n      },\n      \"severity\": \"low\",\n      \"severityWithCritical\": \"low\",\n      \"cvssScore\": 7.8,\n      \"CVSSv3\": \"CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H/E:F\",\n      ...\n      \"from\": [\n        \"docker-image|docker-scan@e2e\",\n        \"bash@5.0-4\"\n      ],\n      \"upgradePath\": [],\n      \"isUpgradable\": false,\n      \"isPatchable\": false,\n      \"name\": \"bash\",\n      \"version\": \"5.0-4\"\n    },\n    ...\n    \"summary\": \"880 vulnerable dependency paths\",\n      \"filesystemPolicy\": false,\n      \"filtered\": {\n        \"ignore\": [],\n        \"patch\": []\n      },\n      \"uniqueCount\": 158,\n      \"projectName\": \"docker-image|docker-scan\",\n      \"platform\": \"linux/amd64\",\n      \"path\": \"docker-scan:e2e\"\n}\n```\n\nYou can find all the sources of the vulnerability in the `from` section.\n\n### Checking the dependency tree\n\nTo view the dependency tree of your image, use the --dependency-tree flag. This displays all the dependencies before the scan result. For example:\n\n``` \n$ docker scan --dependency-tree debian:buster\n\n$ docker-image|99138c65ebc7 @ latest\n     ├─ ca-certificates @ 20200601~deb10u1\n     │  └─ openssl @ 1.1.1d-0+deb10u3\n     │     └─ openssl/libssl1.1 @ 1.1.1d-0+deb10u3\n     ├─ curl @ 7.64.0-4+deb10u1\n     │  └─ curl/libcurl4 @ 7.64.0-4+deb10u1\n     │     ├─ e2fsprogs/libcom-err2 @ 1.44.5-1+deb10u3\n     │     ├─ krb5/libgssapi-krb5-2 @ 1.17-3\n     │     │  ├─ e2fsprogs/libcom-err2 @ 1.44.5-1+deb10u3\n     │     │  ├─ krb5/libk5crypto3 @ 1.17-3\n     │     │  │  └─ krb5/libkrb5support0 @ 1.17-3\n     │     │  ├─ krb5/libkrb5-3 @ 1.17-3\n     │     │  │  ├─ e2fsprogs/libcom-err2 @ 1.44.5-1+deb10u3\n     │     │  │  ├─ krb5/libk5crypto3 @ 1.17-3\n     │     │  │  ├─ krb5/libkrb5support0 @ 1.17-3\n     │     │  │  └─ openssl/libssl1.1 @ 1.1.1d-0+deb10u3\n     │     │  └─ krb5/libkrb5support0 @ 1.17-3\n     │     ├─ libidn2/libidn2-0 @ 2.0.5-1+deb10u1\n     │     │  └─ libunistring/libunistring2 @ 0.9.10-1\n     │     ├─ krb5/libk5crypto3 @ 1.17-3\n     │     ├─ krb5/libkrb5-3 @ 1.17-3\n     │     ├─ openldap/libldap-2.4-2 @ 2.4.47+dfsg-3+deb10u2\n     │     │  ├─ gnutls28/libgnutls30 @ 3.6.7-4+deb10u4\n     │     │  │  ├─ nettle/libhogweed4 @ 3.4.1-1\n     │     │  │  │  └─ nettle/libnettle6 @ 3.4.1-1\n     │     │  │  ├─ libidn2/libidn2-0 @ 2.0.5-1+deb10u1\n     │     │  │  ├─ nettle/libnettle6 @ 3.4.1-1\n     │     │  │  ├─ p11-kit/libp11-kit0 @ 0.23.15-2\n     │     │  │  │  └─ libffi/libffi6 @ 3.2.1-9\n     │     │  │  ├─ libtasn1-6 @ 4.13-3\n     │     │  │  └─ libunistring/libunistring2 @ 0.9.10-1\n     │     │  ├─ cyrus-sasl2/libsasl2-2 @ 2.1.27+dfsg-1+deb10u1\n     │     │  │  └─ cyrus-sasl2/libsasl2-modules-db @ 2.1.27+dfsg-1+deb10u1\n     │     │  │     └─ db5.3/libdb5.3 @ 5.3.28+dfsg1-0.5\n     │     │  └─ openldap/libldap-common @ 2.4.47+dfsg-3+deb10u2\n     │     ├─ nghttp2/libnghttp2-14 @ 1.36.0-2+deb10u1\n     │     ├─ libpsl/libpsl5 @ 0.20.2-2\n     │     │  ├─ libidn2/libidn2-0 @ 2.0.5-1+deb10u1\n     │     │  └─ libunistring/libunistring2 @ 0.9.10-1\n     │     ├─ rtmpdump/librtmp1 @ 2.4+20151223.gitfa8646d.1-2\n     │     │  ├─ gnutls28/libgnutls30 @ 3.6.7-4+deb10u4\n     │     │  ├─ nettle/libhogweed4 @ 3.4.1-1\n     │     │  └─ nettle/libnettle6 @ 3.4.1-1\n     │     ├─ libssh2/libssh2-1 @ 1.8.0-2.1\n     │     │  └─ libgcrypt20 @ 1.8.4-5\n     │     └─ openssl/libssl1.1 @ 1.1.1d-0+deb10u3\n     ├─ gnupg2/dirmngr @ 2.2.12-1+deb10u1\n    ...\n\nOrganization:      docker-desktop-test\nPackage manager:   deb\nProject name:      docker-image|99138c65ebc7\nDocker image:      99138c65ebc7\nLicenses:          enabled\n\nTested 200 dependencies for known issues, found 157 issues.\n\nFor more free scans that keep your images secure, sign up to Snyk at https://dockr.ly/3ePqVcp.\n```\n\nFor more information about the vulnerability data, see [Docker Vulnerability Scanning CLI Cheat Sheet](https://goto.docker.com/rs/929-FJL-178/images/cheat-sheet-docker-desktop-vulnerability-scanning-CLI.pdf).\n\n### Limiting the level of vulnerabilities displayed\n\nDocker scan allows you to choose the level of vulnerabilities displayed in your scan report using the `--severity` flag. You can set the severity flag to `low`, `medium`, or`high` depending on the level of vulnerabilities you’d like to see in your report.  \nFor example, if you set the severity level as `medium`, the scan report displays all vulnerabilities that are classified as medium and high.\n\n``` \n$ docker scan --severity=medium docker-scan:e2e \n./bin/docker-scan_darwin_amd64 scan --severity=medium docker-scan:e2e\n\nTesting docker-scan:e2e...\n\n✗ Medium severity vulnerability found in sqlite3/libsqlite3-0\n  Description: Divide By Zero\n  Info: https://snyk.io/vuln/SNYK-DEBIAN10-SQLITE3-466337\n  Introduced through: gnupg2/gnupg@2.2.12-1+deb10u1, subversion@1.10.4-1+deb10u1, mercurial@4.8.2-1+deb10u1\n  From: gnupg2/gnupg@2.2.12-1+deb10u1 > gnupg2/gpg@2.2.12-1+deb10u1 > sqlite3/libsqlite3-0@3.27.2-3\n  From: subversion@1.10.4-1+deb10u1 > subversion/libsvn1@1.10.4-1+deb10u1 > sqlite3/libsqlite3-0@3.27.2-3\n  From: mercurial@4.8.2-1+deb10u1 > python-defaults/python@2.7.16-1 > python2.7@2.7.16-2+deb10u1 > python2.7/libpython2.7-stdlib@2.7.16-2+deb10u1 > sqlite3/libsqlite3-0@3.27.2-3\n\n✗ Medium severity vulnerability found in sqlite3/libsqlite3-0\n  Description: Uncontrolled Recursion\n...\n✗ High severity vulnerability found in binutils/binutils-common\n  Description: Missing Release of Resource after Effective Lifetime\n  Info: https://snyk.io/vuln/SNYK-DEBIAN10-BINUTILS-403318\n  Introduced through: gcc-defaults/g++@4:8.3.0-1\n  From: gcc-defaults/g++@4:8.3.0-1 > gcc-defaults/gcc@4:8.3.0-1 > gcc-8@8.3.0-6 > binutils@2.31.1-16 > binutils/binutils-common@2.31.1-16\n  From: gcc-defaults/g++@4:8.3.0-1 > gcc-defaults/gcc@4:8.3.0-1 > gcc-8@8.3.0-6 > binutils@2.31.1-16 > binutils/libbinutils@2.31.1-16 > binutils/binutils-common@2.31.1-16\n  From: gcc-defaults/g++@4:8.3.0-1 > gcc-defaults/gcc@4:8.3.0-1 > gcc-8@8.3.0-6 > binutils@2.31.1-16 > binutils/binutils-x86-64-linux-gnu@2.31.1-16 > binutils/binutils-common@2.31.1-16\n  and 4 more...\n\nOrganization:      docker-desktop-test\nPackage manager:   deb\nProject name:      docker-image|docker-scan\nDocker image:      docker-scan:e2e\nPlatform:          linux/amd64\nLicenses:          enabled\n\nTested 200 dependencies for known issues, found 37 issues.\n```\n\n## Provider authentication\n\nIf you have an existing Snyk account, you can directly use your Snyk [API token](https://app.snyk.io/account):\n\n``` \n$ docker scan --login --token SNYK_AUTH_TOKEN\n\nYour account has been authenticated. Snyk is now ready to be used.\n```\n\nIf you use the `--login` flag without any token, you will be redirected to the Snyk website to login.\n\n## Prerequisites\n\nTo run vulnerability scanning on your Docker images, you must meet the following requirements:\n\n1.  Download and install the latest version of Docker Desktop.\n\n    - [Download for Mac with Intel chip](https://desktop.docker.com/mac/main/amd64/Docker.dmg?utm_source=docker&utm_medium=webreferral&utm_campaign=docs-driven-download-mac-amd64)\n    - [Download for Mac with Apple chip](https://desktop.docker.com/mac/main/arm64/Docker.dmg?utm_source=docker&utm_medium=webreferral&utm_campaign=docs-driven-download-mac-arm64)\n    - [Download for Windows](https://desktop.docker.com/win/main/amd64/Docker%20Desktop%20Installer.exe)\n\n2.  Sign into [Docker Hub](https://hub.docker.com).\n\n3.  From the Docker Desktop menu, select **Sign in/ Create Docker ID**. Alternatively, open a terminal and run the command `docker login`.\n\n4.  (Optional) You can create a [Snyk account](https://dockr.ly/3ePqVcp) for scans, or use the additional monthly free scans provided by Snyk with your Docker Hub account.\n\nCheck your installation by running `docker scan --version`, it should print the current version of docker scan and the Snyk engine version. For example:\n\n``` \n$ docker scan --version\nVersion:    v0.5.0\nGit commit: 5a09266\nProvider:   Snyk (1.432.0)\n```\n\n> **Note:**\n>\n> Docker Scan uses the Snyk binary installed in your environment by default. If this is not available, it uses the Snyk binary embedded in Docker Desktop. The minimum version required for Snyk is `1.385.0`.\n\n## Supported options\n\nThe high-level `docker scan` command scans local images using the image name or the image ID. It supports the following options:\n\n| Option                | Description                                                                                                   |\n|:----------------------|:--------------------------------------------------------------------------------------------------------------|\n| `--accept-license`    | Accept the license agreement of the third-party scanning provider                                             |\n| `--dependency-tree`   | Display the dependency tree of the image along with scan results                                              |\n| `--exclude-base`      | Exclude the base image during scanning. This option requires the --file option to be set                      |\n| `-f`, `--file string` | Specify the location of the Dockerfile associated with the image. This option displays a detailed scan result |\n| `--json`              | Display the result of the scan in JSON format                                                                 |\n| `--login`             | Log into Snyk using an optional token (using the flag --token), or by using a web-based token                 |\n| `--reject-license`    | Reject the license agreement of the third-party scanning provider                                             |\n| `--severity string`   | Only report vulnerabilities of provided level or higher (low, medium, high)                                   |\n| `--token string`      | Use the authentication token to log into the third-party scanning provider                                    |\n| `--version`           | Display the Docker Scan plugin version                                                                        |\n\n## Known issues\n\n**WSL 2**\n\n- The Vulnerability scanning feature doesn’t work with Alpine distributions.\n- If you are using Debian and OpenSUSE distributions, the login process only works with the `--token` flag, you won’t be redirected to the Snyk website for authentication.\n\n## Feedback\n\nYour feedback is very important to us. Let us know your feedback by creating an issue in the [scan-cli-plugin](https://github.com/docker/scan-cli-plugin/issues/new) GitHub repository.\n\n[Docker](https://docs.docker.com/search/?q=Docker), [scan](https://docs.docker.com/search/?q=scan), [Snyk](https://docs.docker.com/search/?q=Snyk), [images](https://docs.docker.com/search/?q=images), [local](https://docs.docker.com/search/?q=local), [CVE](https://docs.docker.com/search/?q=CVE), [vulnerability](https://docs.docker.com/search/?q=vulnerability), [security](https://docs.docker.com/search/?q=security)\n\n© 2019 Docker, Inc.  \nLicensed under the Apache License, Version 2.0.  \nDocker and the Docker logo are trademarks or registered trademarks of Docker, Inc. in the United States and/or other countries.  \nDocker, Inc. and other parties may also have trademark rights in other terms used herein.  \n[https://docs.docker.com/engine/scan/](https://docs.docker.com/engine/scan/)"
