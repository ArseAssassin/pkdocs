---
name: Graphite
slug: graphite
text_format: markdown
generator: src:devdocs
generator_command: src:devdocs
version: null
copyright: |-
  © 2008–2012 Chris Davis
  © 2011–2016 The Graphite Project
  Licensed under the Apache License, Version 2.0.
  https://graphite.readthedocs.io/en/latest/
homepage: null

---
- name: About the project
  id: overview#about-the-project
  summary: Graphite is an enterprise-scale monitoring tool that runs well on cheap hardware
  belongs_to: Overview
  description: |-
    ## About the project

    Graphite is an enterprise-scale monitoring tool that runs well on cheap hardware. It was originally designed and written by [Chris Davis](mailto:chrismd%40gmail.com) at [Orbitz](http://www.orbitz.com/) in 2006 as side project that ultimately grew to be a foundational monitoring tool. In 2008, Orbitz allowed Graphite to be released under the open source Apache 2.0 license. Since then Chris has continued to work on Graphite and has deployed it at other companies including [Sears](http://www.sears.com/), where it serves as a pillar of the e-commerce monitoring system. Today many large [companies](https://graphite.readthedocs.io/en/latest/who-is-using.html) use it.
- name: absolute()
  id: functions#graphite.render.functions.absolute
  summary: Takes one metric or a wildcard seriesList and applies the mathematical abs function to each datapoint transforming it to its absolute value
  belongs_to: Functions
  description: |-
    absolute(seriesList)

    Takes one metric or a wildcard seriesList and applies the mathematical abs function to each datapoint transforming it to its absolute value.

    Example:

    ``` none
    &target=absolute(Server.instance01.threads.busy)
    &target=absolute(Server.instance*.threads.busy)
    ```
- name: Adding a Graph
  id: dashboard#adding-a-graph
  summary: To add a new graph directly, you select a metric series in the completer or browser tree, and a graph for that value is added to the end of the dashboard
  belongs_to: The Dashboard User Interface
  description: |-
    ### Adding a Graph

    To add a new graph directly, you select a metric series in the completer or browser tree, and a graph for that value is added to the end of the dashboard. Alternatively, if a graph for that metric series already exists on the dashboard, it will be removed.

    See later for ways of customizing the graph, including adding multiple metric series, changing axes, adding titles and legends etc.
- name: Adding Events
  id: events#adding-events
  summary: Events can be submitted via HTTP POST using command-line tools such as curl or with a variety of HTTP programming libraries
  belongs_to: Graphite Events
  description: |-
    ## Adding Events

    Events can be submitted via HTTP POST using command-line tools such as `curl` or with a variety of HTTP programming libraries. The JSON format is simple and predictable.

    ``` none
    $ curl -X POST "http://graphite/events/"
        -d '{ "what": "Event - deploy", "tags": ["deploy"], "when": 1467844481,
        "data": "deploy of master branch happened at Wed Jul  6 22:34:41 UTC 2016" }'
    ```

    `when` is an optional key which is set to the current Unix timestamp if `when` is not set.

    *Note*: Prior to 0.10.0, the value of `tags` is a string, with multiple tags being separated by a space.
- name: Adding Series to the TagDB
  id: tags#adding-series-to-the-tagdb
  summary: Normally carbon will take care of this, it submits all new series to the TagDB, and periodically re-submits all series to ensure that the TagDB is kept up to date
  belongs_to: Graphite Tag Support
  description: |-
    ## Adding Series to the TagDB

    Normally carbon will take care of this, it submits all new series to the TagDB, and periodically re-submits all series to ensure that the TagDB is kept up to date. There are 2 carbon configuration settings related to tagging; the GRAPHITE_URL setting specifies the url of your graphite-web installation (default http://127.0.0.1:8000), and the TAG_UPDATE_INTERVAL setting specifies how often each series should be re-submitted to the TagDB (default is every 100th update).

    Series can be submitted via HTTP POST using command-line tools such as `curl` or with a variety of HTTP programming libraries.

    ``` none
    $ curl -X POST "http://graphite/tags/tagSeries" \
      --data-urlencode 'path=disk.used;rack=a1;datacenter=dc1;server=web01'

    "disk.used;datacenter=dc1;rack=a1;server=web01"
    ```

    This endpoint returns the canonicalized version of the path, with the tags sorted in alphabetical order.

    To add multiple series with a single HTTP request, use the `/tags/tagMultiSeries` endpoint, which support multiple `path` parameters:

    ``` none
    $ curl -X POST "http://graphite/tags/tagMultiSeries" \
      --data-urlencode 'path=disk.used;rack=a1;datacenter=dc1;server=web01' \
      --data-urlencode 'path=disk.used;rack=a1;datacenter=dc1;server=web02' \
      --data-urlencode 'pretty=1'

    [
      "disk.used;datacenter=dc1;rack=a1;server=web01",
      "disk.used;datacenter=dc1;rack=a1;server=web02"
    ]
    ```

    This endpoint returns a list of the canonicalized paths, in the same order they are specified.
- name: Additional Django Settings
  id: config-local-settings#additional-django-settings
  summary: The local_settings.py.example shipped with Graphite-web imports app_settings.py into the namespace to allow further customization of Django
  belongs_to: Graphite-web’s local_settings.py
  description: "## Additional Django Settings\n\nThe `local_settings.py.example` shipped with Graphite-web imports `app_settings.py` into the namespace to allow further customization of Django. This allows the setting or customization of standard [Django settings](https://docs.djangoproject.com/en/dev/ref/settings/) and the installation and configuration of additional [middleware](https://docs.djangoproject.com/en/dev/topics/http/middleware/).\n\nTo manipulate these settings, ensure `app_settings.py` is imported as such:\n\n``` python\nfrom graphite.app_settings import *\n```\n\nThe most common settings to manipulate are `INSTALLED_APPS`, `MIDDLEWARE`, and `AUTHENTICATION_BACKENDS`.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-local-settings.html](https://graphite.readthedocs.io/en/latest/config-local-settings.html)"
- name: Administering Carbon
  id: admin-carbon
  summary: This starts the main Carbon daemon in the background
  description: "# Administering Carbon\n\n## Starting Carbon\n\nCarbon can be started with the `carbon-cache.py` script:\n\n``` default\n/opt/graphite/bin/carbon-cache.py start\n```\n\nThis starts the main Carbon daemon in the background. Now is a good time to check the logs, located in `/opt/graphite/storage/log/carbon-cache/` for any errors.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/admin-carbon.html](https://graphite.readthedocs.io/en/latest/admin-carbon.html)"
- name: Administering The Webapp
  id: admin-webapp
  summary: Depending on the stack you choose to expose the Graphite webapp, its usage varies slightly
  description: "# Administering The Webapp\n\nDepending on the stack you choose to expose the Graphite webapp, its usage varies slightly.\n\n## nginx + gunicorn\n\nAs nginx is already ready to proxy requests, we just need to start Gunicorn.\n\nThe following will do:\n\n``` none\nPYTHONPATH=/opt/graphite/webapp gunicorn wsgi --workers=4 --bind=127.0.0.1:8080 --log-file=/var/log/gunicorn.log --preload --pythonpath=/opt/graphite/webapp/graphite &\n```\n\nIt will start Gunicorn and listen on `localhost:8080`, log to `/var/log/gunicorn.log` and use `/opt/graphite/webapp/graphite` as the webapp path.\n\nNaturally, you can change these settings so that it fits your setup.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/admin-webapp.html](https://graphite.readthedocs.io/en/latest/admin-webapp.html)"
- name: Advanced finders
  id: storage-backends#advanced-finders
  summary: This class method is responsible for initializing and returning the finder object(s) as a list
  belongs_to: Alternative storage finders
  description: |-
    ## Advanced finders

    Custom finders may also implement the following methods:

    ` ``factory(cls)`` `

    This class method is responsible for initializing and returning the finder object(s) as a list.

    It may return a list of 1 or more instances of the finder, if multiple instances are returned they will be called concurrently in multiple threads. This is used by `RemoteFinder` to dispatch requests to multiple remote hosts in parallel.

    If not defined, a single instance of the finder will be initialized with no parameters.

    ` ``get_index(self,`` ``requestContext)`` `

    This method should return all node paths that the finder is aware of as a list of strings.

    `requestContext` is a dict which may contain `localOnly` and `forwardHeaders` keys.

    If not implemented, `find_nodes()` will be called with a query for `**` and a list of the returned nodes’ paths will be returned.

    ` ``find_multi(self,`` ``queries)`` `

    This method follows the same semantics as `find_node()` but accepts a list of queries.

    If not implemented, `find_nodes()` will be called for each query specified.

    ` ``fetch(self,`` ``patterns,`` ``start_time,`` ``end_time,`` ``now=None,`` ``requestContext=None)`` `

    This method is responsible for loading data for render requests.

    It should return a list of result dicts, each of which contains:

    ``` python
    {
      'pathExpression': '<the pattern that this path matched>',
      'path': 'the.metric.path',
      'name': 'the.metric.path',
      'time_info': (_from_, _to_, _step_),
      'values': [list of values],
    }
    ```

    If not implemented, `find_multi()` will be called with a list of queries and `node.fetch()` will be called on every result.

    ` ``auto_complete_tags(self,`` ``exprs,`` ``tagPrefix=None,`` ``limit=None,`` ``requestContext=None)`` `

    This method is only used when `tags``=``True` is specified in the class definition.

    If defined it should return an auto-complete list of tags for series that match the specified expressions.

    ` ``auto_complete_values(self,`` ``exprs,`` ``tag,`` ``valuePrefix=None,`` ``limit=None,`` ``requestContext=None)`` `

    This method is only used when `tags``=``True` is specified in the class definition.

    If defined it should return an auto-complete list of values for the specified tag on series that match the specified expressions.
- name: aggregate()
  id: functions#graphite.render.functions.aggregate
  summary: Aggregate series using the specified function
  belongs_to: Functions
  description: |-
    aggregate(seriesList, func, xFilesFactor=None)

    Aggregate series using the specified function.

    Example:

    ``` none
    &target=aggregate(host.cpu-[0-7].cpu-{user,system}.value, "sum")
    ```

    This would be the equivalent of

    ``` none
    &target=sumSeries(host.cpu-[0-7].cpu-{user,system}.value)
    ```

    This function can be used with aggregation functions `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `count`, `range`, `multiply` & `last`.
- name: aggregateLine()
  id: functions#graphite.render.functions.aggregateLine
  summary: Takes a metric or wildcard seriesList and draws a horizontal line based on the function applied to each series
  belongs_to: Functions
  description: |-
    aggregateLine(seriesList, func='average', keepStep=False)

    Takes a metric or wildcard seriesList and draws a horizontal line based on the function applied to each series.

    If the optional keepStep parameter is set to True, the result will have the same time period and step as the source series.

    Note: By default, the graphite renderer consolidates data points by averaging data points over time. If you are using the ‘min’ or ‘max’ function for aggregateLine, this can cause an unusual gap in the line drawn by this function and the data itself. To fix this, you should use the consolidateBy() function with the same function argument you are using for aggregateLine. This will ensure that the proper data points are retained and the graph should line up correctly.

    Example:

    ``` none
    &target=aggregateLine(server01.connections.total, 'avg')
    &target=aggregateLine(server*.connections.total, 'avg')
    ```
- name: aggregateWithWildcards()
  id: functions#graphite.render.functions.aggregateWithWildcards
  summary: Call aggregator after inserting wildcards at the given position(s)
  belongs_to: Functions
  description: |-
    aggregateWithWildcards(seriesList, func, \*positions)

    Call aggregator after inserting wildcards at the given position(s).

    Example:

    ``` none
    &target=aggregateWithWildcards(host.cpu-[0-7].cpu-{user,system}.value, "sum", 1)
    ```

    This would be the equivalent of

    ``` none
    &target=sumSeries(host.cpu-[0-7].cpu-user.value)&target=sumSeries(host.cpu-[0-7].cpu-system.value)
    # or
    &target=aggregate(host.cpu-[0-7].cpu-user.value,"sum")&target=aggregate(host.cpu-[0-7].cpu-system.value,"sum")
    ```

    This function can be used with all aggregation functions supported by [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate"): `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range` & `multiply`.

    This complements [`groupByNodes`](#graphite.render.functions.groupByNodes "graphite.render.functions.groupByNodes") which takes a list of nodes that must match in each group.
- name: aggregation-rules.conf
  id: config-carbon#aggregation-rules-conf
  summary: Aggregation rules allow you to add several metrics together as they come in, reducing the need to sum() many metrics in every URL
  belongs_to: Configuring Carbon
  description: |-
    ## aggregation-rules.conf

    Aggregation rules allow you to add several metrics together as they come in, reducing the need to sum() many metrics in every URL. Note that unlike some other config files, any time this file is modified it will take effect automatically. This requires the carbon-aggregator service to be running.

    The form of each line in this file should be as follows:

    ``` none
    output_template (frequency) = method input_pattern
    ```

    This will capture any received metrics that match `input_pattern` for calculating an aggregate metric. The calculation will occur every `frequency` seconds using a valid `method`. The name of the aggregate metric will be derived from `output_template` filling in any captured fields from `input_pattern`. Any metric that will arrive to `carbon-aggregator` will proceed to its output untouched unless it is overridden by some rule.

    Available aggregation methods are: `sum`, `avg`, `min`, `max`, `p50`, `p75`, `p80`, `p90`, `p95`, `p99`, `p999`, and `count` - where `p50` means 50th percentile and `p999` means 99.9th percentile, etc.

    Care should be taken when using percentile aggregation methods because re-aggregation does not work the way you [might](https://www.vividcortex.com/blog/why-percentiles-dont-work-the-way-you-think) [expect](https://grafana.com/blog/2016/03/03/25-graphite-grafana-and-statsd-gotchas/#aggregating.percentiles). The utility of percentile aggregation however means they are provided if you wish to use them.

    For example, if your metric naming scheme is:

    ``` none
    <env>.applications.<app>.<server>.<metric>
    ```

    You could configure some aggregations like so:

    ``` none
    <env>.applications.<app>.all.requests (60) = sum <env>.applications.<app>.*.requests
    <env>.applications.<app>.all.latency (60) = avg <env>.applications.<app>.*.latency
    ```

    As an example, if the following metrics are received:

    ``` none
    prod.applications.apache.www01.requests
    prod.applications.apache.www02.requests
    prod.applications.apache.www03.requests
    prod.applications.apache.www04.requests
    prod.applications.apache.www05.requests
    ```

    They would all go into the same aggregation buffer and after 60 seconds the aggregate metric `prod.applications.apache.all.requests` would be calculated by summing their values.

    Template components such as \<env\> will match everything up to the next dot. To match metric multiple components including the dots, use \<\<metric\>\> in the input template:

    ``` none
    <env>.applications.<app>.all.<app_metric> (60) = sum <env>.applications.<app>.*.<<app_metric>>
    ```

    It is also possible to use regular expressions. Following the example above when using:

    ``` none
    <env>.applications.<app>.<domain>.requests (60) = sum <env>.applications.<app>.<domain>\d{2}.requests
    ```

    You will end up with `prod.applications.apache.www.requests` instead of `prod.applications.apache.all.requests`.

    Another common use pattern of `carbon-aggregator` is to aggregate several data points of the *same metric*. This could come in handy when you have got the same metric coming from several hosts, or when you are bound to send data more frequently than your shortest retention.
- name: alias()
  id: functions#graphite.render.functions.alias
  summary: Takes one metric or a wildcard seriesList and a string in quotes
  belongs_to: Functions
  description: |-
    alias(seriesList, newName)

    Takes one metric or a wildcard seriesList and a string in quotes. Prints the string instead of the metric name in the legend.

    ``` none
    &target=alias(Sales.widgets.largeBlue,"Large Blue Widgets")
    ```
- name: aliasByMetric()
  id: functions#graphite.render.functions.aliasByMetric
  summary: Takes a seriesList and applies an alias derived from the base metric name
  belongs_to: Functions
  description: |-
    aliasByMetric(seriesList)

    Takes a seriesList and applies an alias derived from the base metric name.

    ``` none
    &target=aliasByMetric(carbon.agents.graphite.creates)
    ```
- name: aliasByNode()
  id: functions#graphite.render.functions.aliasByNode
  summary: Takes a seriesList and applies an alias derived from one or more “node” portion/s of the target name or tags
  belongs_to: Functions
  description: |-
    aliasByNode(seriesList, \*nodes)

    Takes a seriesList and applies an alias derived from one or more “node” portion/s of the target name or tags. Node indices are 0 indexed.

    ``` none
    &target=aliasByNode(ganglia.*.cpu.load5,1)
    ```

    Each node may be an integer referencing a node in the series name or a string identifying a tag.

    ``` none
    &target=seriesByTag("name=~cpu.load.*", "server=~server[1-9]+", "datacenter=dc1")|aliasByNode("datacenter", "server", 1)

    # will produce output series like
    # dc1.server1.load5, dc1.server2.load5, dc1.server1.load10, dc1.server2.load10
    ```
- name: aliasByTags()
  id: functions#graphite.render.functions.aliasByTags
  summary: This is an alias for aliasByNode
  belongs_to: Functions
  description: |-
    aliasByTags(seriesList, \*tags)

    Takes a seriesList and applies an alias derived from one or more tags and/or nodes

    ``` none
    &target=seriesByTag("name=cpu")|aliasByTags("server","name")
    ```

    This is an alias for [`aliasByNode`](#graphite.render.functions.aliasByNode "graphite.render.functions.aliasByNode").
- name: aliasQuery()
  id: functions#graphite.render.functions.aliasQuery
  summary: Performs a query to alias the metrics in seriesList
  belongs_to: Functions
  description: |-
    aliasQuery(seriesList, search, replace, newName)

    Performs a query to alias the metrics in seriesList.

    ``` none
    &target=aliasQuery(channel.power.*,"channel\.power\.([0-9]+)","channel.frequency.\1", "Channel %d MHz")
    ```

    The series in seriesList will be aliased by first translating the series names using the search & replace parameters, then using the last value of the resulting series to construct the alias using sprintf-style syntax.
- name: aliasSub()
  id: functions#graphite.render.functions.aliasSub
  summary: Runs series names through a regex search/replace
  belongs_to: Functions
  description: |-
    aliasSub(seriesList, search, replace)

    Runs series names through a regex search/replace.

    ``` none
    &target=aliasSub(ip.*TCP*,"^.*TCP(\d+)","\1")
    ```
- name: alpha()
  id: functions#graphite.render.functions.alpha
  summary: Assigns the given alpha transparency setting to the series
  belongs_to: Functions
  description: |-
    alpha(seriesList, alpha)

    Assigns the given alpha transparency setting to the series. Takes a float value between 0 and 1.
- name: Alternative storage finders
  id: storage-backends
  summary: It is possible to use an alternate storage layer than the default, Whisper, in order to accommodate specific needs
  description: "# Alternative storage finders\n\n## Built-in finders\n\nThe default graphite setup consists of:\n\n- A Whisper database\n- A carbon daemon writing data to the database\n- Graphite-web reading and graphing data from the database\n\nIt is possible to use an alternate storage layer than the default, Whisper, in order to accommodate specific needs. The setup above would become:\n\n- An alternative database\n- A carbon daemon or alternative daemon for writing to the database\n- A custom *storage finder* for reading the data in graphite-web\n\nThis section aims at documenting the last item: configuring graphite-web to read data from a custom storage layer.\n\nThis can be done via the `STORAGE_FINDERS` setting. This setting is a list of paths to finder implementations. Its default value is:\n\n``` python\nSTORAGE_FINDERS = (\n    'graphite.finders.remote.RemoteFinder',\n    'graphite.finders.standard.StandardFinder',\n)\n```\n\nThe default finder reads data from a Whisper database.\n\nAn alternative finder for the experimental Ceres database is available:\n\n``` python\nSTORAGE_FINDERS = (\n    'graphite.finders.ceres.CeresFinder',\n)\n```\n\nThe setting supports multiple values, meaning you can read data from both a Whisper database and a Ceres database:\n\n``` python\nSTORAGE_FINDERS = (\n    'graphite.finders.remote.RemoteFinder',\n    'graphite.finders.standard.StandardFinder',\n    'graphite.finders.ceres.CeresFinder',\n)\n```\n\n## Custom finders\n\n`STORAGE_FINDERS` being a list of arbitrary python paths, it is relatively easy to write a custom finder if you want to read data from other places than Whisper and Ceres. A finder is a python class with a `find_nodes()` method:\n\n``` python\nclass CustomFinder(object):\n    def find_nodes(self, query):\n        # ...\n```\n\n`query` is a `FindQuery` object. `find_nodes()` is the entry point when browsing the metrics tree. It must yield leaf or branch nodes matching the query:\n\n``` python\nfrom graphite.node import LeafNode, BranchNode\nfrom graphite.finders.utils import BaseFinder\n\nclass CustomFinder(BaseFinder):\n    def find_nodes(self, query):\n        # find some paths matching the query, then yield them\n        for path in matches:\n            if is_branch(path):\n                yield BranchNode(path)\n            if is_leaf(path):\n                yield LeafNode(path, CustomReader(path))\n```\n\n`LeafNode` is created with a *reader*, which is the class responsible for fetching the datapoints for the given path. It is a simple class with 2 methods: `fetch()` and `get_intervals()`:\n\n``` python\nfrom graphite.intervals import IntervalSet, Interval\nfrom graphite.readers.utils import BaseReader\n\nclass CustomReader(BaseReader):\n    __slots__ = ('path',)  # __slots__ is recommended to save memory on readers\n\n    def __init__(self, path):\n        self.path = path\n\n    def fetch(self, start_time, end_time):\n        # fetch data\n        time_info = _from_, _to_, _step_\n        return time_info, series\n\n    def get_intervals(self):\n        return IntervalSet([Interval(start, end)])\n```\n\n`fetch()` must return a list of 2 elements: the time info for the data and the datapoints themselves. The time info is a list of 3 items: the start time of the datapoints (in unix time), the end time and the time step (in seconds) between the datapoints.\n\nThe datapoints is a list of points found in the database for the required interval. There must be `(end`` ``-`` ``start)`` ``/`` ``step` points in the dataset even if the database has gaps: gaps can be filled with `None` values.\n\n`get_intervals()` is a method that hints graphite-web about the time range available for this given metric in the database. It must return an `IntervalSet` of one or more `Interval` objects.\n\n## Advanced finders\n\nCustom finders may also implement the following methods:\n\n`factory(cls)`  \nThis class method is responsible for initializing and returning the finder object(s) as a list.\n\nIt may return a list of 1 or more instances of the finder, if multiple instances are returned they will be called concurrently in multiple threads. This is used by `RemoteFinder` to dispatch requests to multiple remote hosts in parallel.\n\nIf not defined, a single instance of the finder will be initialized with no parameters.\n\n`get_index(self,`` ``requestContext)`  \nThis method should return all node paths that the finder is aware of as a list of strings.\n\n`requestContext` is a dict which may contain `localOnly` and `forwardHeaders` keys.\n\nIf not implemented, `find_nodes()` will be called with a query for `**` and a list of the returned nodes’ paths will be returned.\n\n`find_multi(self,`` ``queries)`  \nThis method follows the same semantics as `find_node()` but accepts a list of queries.\n\nIf not implemented, `find_nodes()` will be called for each query specified.\n\n`fetch(self,`` ``patterns,`` ``start_time,`` ``end_time,`` ``now=None,`` ``requestContext=None)`  \nThis method is responsible for loading data for render requests.\n\nIt should return a list of result dicts, each of which contains:\n\n``` python\n{\n  'pathExpression': '<the pattern that this path matched>',\n  'path': 'the.metric.path',\n  'name': 'the.metric.path',\n  'time_info': (_from_, _to_, _step_),\n  'values': [list of values],\n}\n```\n\nIf not implemented, `find_multi()` will be called with a list of queries and `node.fetch()` will be called on every result.\n\n`auto_complete_tags(self,`` ``exprs,`` ``tagPrefix=None,`` ``limit=None,`` ``requestContext=None)`  \nThis method is only used when `tags`` ``=`` ``True` is specified in the class definition.\n\nIf defined it should return an auto-complete list of tags for series that match the specified expressions.\n\n`auto_complete_values(self,`` ``exprs,`` ``tag,`` ``valuePrefix=None,`` ``limit=None,`` ``requestContext=None)`  \nThis method is only used when `tags`` ``=`` ``True` is specified in the class definition.\n\nIf defined it should return an auto-complete list of values for the specified tag on series that match the specified expressions.\n\n## Installing custom finders\n\nIn order for your custom finder to be importable, you need to package it under a namespace of your choice. Python packaging won’t be covered here but you can look at third-party finders to get some inspiration:\n\n- [Cyanite finder](https://github.com/brutasse/graphite-cyanite)\n- [BigGraphite finder](https://github.com/criteo/biggraphite/blob/master/biggraphite/plugins/graphite.py)\n- KairosDB finder\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/storage-backends.html](https://graphite.readthedocs.io/en/latest/storage-backends.html)"
- name: Apache + mod_wsgi
  id: config-webapp#apache-mod-wsgi
  summary: First, you need to install mod_wsgi
  belongs_to: Configuring The Webapp
  description: |-
    ## Apache + mod_wsgi

    First, you need to install mod_wsgi.

    See the [mod_wsgi InstallationInstructions](https://code.google.com/p/modwsgi/wiki/InstallationInstructions) for installation instructions.

    Then create the graphite.wsgi. (You can find example of graphite.wsgi file on the [conf](https://github.com/graphite-project/graphite-web/blob/master/conf/graphite.wsgi.example) directory of source ditribution):

    ``` bash
    # /opt/graphite/conf/graphite.wsgi

    import sys
    sys.path.append('/opt/graphite/webapp')
    from graphite.wsgi import application
    ```

    Finally, configure the apache vhost. (You can find example of Graphite vhost configuration in the [contrib](https://github.com/graphite-project/graphite-web/blob/master/examples/example-graphite-vhost.conf) directory of source ditribution):

    ``` apache
    # /etc/httpd/conf.d/graphite-vhost.conf

    LoadModule wsgi_module modules/mod_wsgi.so

    WSGISocketPrefix /var/run/wsgi

    Listen 80
    <VirtualHost *:80>

        ServerName graphite
        DocumentRoot "/opt/graphite/webapp"
        ErrorLog /opt/graphite/storage/log/webapp/error.log
        CustomLog /opt/graphite/storage/log/webapp/access.log common

        WSGIDaemonProcess graphite-web processes=5 threads=5 display-name='%{GROUP}' inactivity-timeout=120
        WSGIProcessGroup graphite-web
        WSGIApplicationGroup %{GLOBAL}
        WSGIImportScript /opt/graphite/conf/graphite.wsgi process-group=graphite-web application-group=%{GLOBAL}

        WSGIScriptAlias / /opt/graphite/conf/graphite.wsgi

        Alias /static/ /opt/graphite/static/

        <Directory /opt/graphite/static/>
                <IfVersion < 2.4>
                        Order deny,allow
                        Allow from all
                </IfVersion>
                <IfVersion >= 2.4>
                        Require all granted
                </IfVersion>
        </Directory>

        <Directory /opt/graphite/conf/>
                <IfVersion < 2.4>
                        Order deny,allow
                        Allow from all
                </IfVersion>
                <IfVersion >= 2.4>
                        Require all granted
                </IfVersion>
        </Directory>
    </VirtualHost>
    ```

    Adapt the mod_wsgi configuration to your requirements.

    See the [mod_wsgi QuickConfigurationGuide](https://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) for an overview of configurations and [mod_wsgi ConfigurationDirectives](https://code.google.com/p/modwsgi/wiki/ConfigurationDirectives) to see all configuration directives

    Restart apache:

    ``` default
    $ service httpd restart
    ```
- name: Apache mod_wsgi
  id: install-virtualenv#apache-mod-wsgi
  summary: See the mod_wsgi documentation on Virtual Environments <http://code.google.com/p/modwsgi/wiki/VirtualEnvironments\> for more details
  belongs_to: Installing in Virtualenv
  description: |-
    ### Apache mod_wsgi

    Note

    The version Python used to compile mod_wsgi must match the Python installed in the virtualenv (generally the system Python)

    To the Apache [mod_wsgi](http://code.google.com/p/modwsgi/) config, add the root of the virtualenv as `WSGIPythonHome`, `/opt/graphite` in this example:

    ``` none
    WSGIPythonHome /opt/graphite
    ```

    and add the virtualenv’s python site-packages to the `graphite.wsgi` file, python 2.6 in `/opt/graphite` in this example:

    ``` none
    site.addsitedir('/opt/graphite/lib/python2.6/site-packages')
    ```

    See the mod_wsgi documentation on Virtual Environments \<http://code.google.com/p/modwsgi/wiki/VirtualEnvironments\> for more details.
- name: applyByNode()
  id: functions#graphite.render.functions.applyByNode
  summary: Takes a seriesList and applies some complicated function (described by a string), replacing templates with unique prefixes of keys from the seriesList (the key is all nodes up to the index given as nodeNum)
  belongs_to: Functions
  description: |-
    applyByNode(seriesList, nodeNum, templateFunction, newName=None)

    Takes a seriesList and applies some complicated function (described by a string), replacing templates with unique prefixes of keys from the seriesList (the key is all nodes up to the index given as nodeNum).

    If the newName parameter is provided, the name of the resulting series will be given by that parameter, with any “%” characters replaced by the unique prefix.

    Example:

    ``` none
    &target=applyByNode(servers.*.disk.bytes_free,1,"divideSeries(%.disk.bytes_free,sumSeries(%.disk.bytes_*))")
    ```

    Would find all series which match servers.\*.disk.bytes_free, then trim them down to unique series up to the node given by nodeNum, then fill them into the template function provided (replacing % by the prefixes).

    Additional Examples:

    Given keys of

    - stats.counts.haproxy.web.2XX
    - stats.counts.haproxy.web.3XX
    - stats.counts.haproxy.web.5XX
    - stats.counts.haproxy.microservice.2XX
    - stats.counts.haproxy.microservice.3XX
    - stats.counts.haproxy.microservice.5XX

    The following will return the rate of 5XX’s per service:

    ``` none
    applyByNode(stats.counts.haproxy.*.*XX, 3, "asPercent(%.5XX, sumSeries(%.*XX))", "%.pct_5XX")
    ```

    The output series would have keys stats.counts.haproxy.web.pct_5XX and stats.counts.haproxy.microservice.pct_5XX.
- name: 'Archives: Retention and Precision'
  id: whisper#archives-retention-and-precision
  summary: Whisper databases contain one or more archives, each with a specific data resolution and retention (defined in number of points or max timestamp age)
  belongs_to: The Whisper Database
  description: |-
    ## Archives: Retention and Precision

    Whisper databases contain one or more archives, each with a specific data resolution and retention (defined in number of points or max timestamp age). Archives are ordered from the highest-resolution and shortest retention archive to the lowest-resolution and longest retention period archive.

    To support accurate aggregation from higher to lower resolution archives, the precision of a longer retention archive must be divisible by precision of next lower retention archive. For example, an archive with 1 data point every 60 seconds can have a lower-resolution archive following it with a resolution of 1 data point every 300 seconds because 60 cleanly divides 300. In contrast, a 180 second precision (3 minutes) could not be followed by a 600 second precision (10 minutes) because the ratio of points to be propagated from the first archive to the next would be 3 1/3 and Whisper will not do partial point interpolation.

    The total retention time of the database is determined by the archive with the highest retention as the time period covered by each archive is overlapping (see [Multi-Archive Storage and Retrieval Behavior](#multi-archive-storage-and-retrieval-behavior)). That is, a pair of archives with retentions of 1 month and 1 year will not provide 13 months of data storage as may be guessed. Instead, it will provide 1 year of storage - the length of its longest archive.
- name: areaAlpha
  id: render_api#areaalpha
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### areaAlpha

    *Default: 1.0*

    Takes a floating point number between 0.0 and 1.0

    Sets the alpha (transparency) value of filled areas when using an [areaMode](#areamode)
- name: areaBetween()
  id: functions#graphite.render.functions.areaBetween
  summary: Draws the vertical area in between the two series in seriesList
  belongs_to: Functions
  description: |-
    areaBetween(seriesList)

    Draws the vertical area in between the two series in seriesList. Useful for visualizing a range such as the minimum and maximum latency for a service.

    areaBetween expects **exactly one argument** that results in exactly two series (see example below). The order of the lower and higher values series does not matter. The visualization only works when used in conjunction with `areaMode=stacked`.

    Most likely use case is to provide a band within which another metric should move. In such case applying an `alpha()`, as in the second example, gives best visual results.

    Example:

    ``` none
    &target=areaBetween(service.latency.{min,max})&areaMode=stacked

    &target=alpha(areaBetween(service.latency.{min,max}),0.3)&areaMode=stacked
    ```

    If for instance, you need to build a seriesList, you should use the `group` function, like so:

    ``` none
    &target=areaBetween(group(minSeries(a.*.min),maxSeries(a.*.max)))
    ```
- name: areaMode
  id: render_api#areamode
  summary: Enables filling of the area below the graphed lines
  belongs_to: The Render URL API
  description: |-
    ### areaMode

    *Default: none*

    Enables filling of the area below the graphed lines. Fill area is the same color as the line color associated with it. See [areaAlpha](#areaalpha) to make this area transparent. Takes one of the following parameters which determines the fill mode to use:

    ` ``none`` `

    Disables areaMode

    ` ``first`` `

    Fills the area under the first target and no other

    ` ``all`` `

    Fills the areas under each target

    ` ``stacked`` `

    Creates a graph where the filled area of each target is stacked on one another. Each target line is displayed as the sum of all previous lines plus the value of the current line.
- name: asPercent()
  id: functions#graphite.render.functions.asPercent
  summary: Calculates a percentage of the total of a wildcard series
  belongs_to: Functions
  description: |-
    asPercent(seriesList, total=None, \*nodes)

    Calculates a percentage of the total of a wildcard series. If total is specified, each series will be calculated as a percentage of that total. If total is not specified, the sum of all points in the wildcard series will be used instead.

    A list of nodes can optionally be provided, if so they will be used to match series with their corresponding totals following the same logic as [`groupByNodes`](#graphite.render.functions.groupByNodes "graphite.render.functions.groupByNodes").

    When passing nodes the total parameter may be a series list or None. If it is None then for each series in seriesList the percentage of the sum of series in that group will be returned.

    When not passing nodes, the total parameter may be a single series, reference the same number of series as seriesList or be a numeric value.

    Example:

    ``` none
    # Server01 connections failed and succeeded as a percentage of Server01 connections attempted
    &target=asPercent(Server01.connections.{failed,succeeded}, Server01.connections.attempted)

    # For each server, its connections failed as a percentage of its connections attempted
    &target=asPercent(Server*.connections.failed, Server*.connections.attempted)

    # For each server, its connections failed and succeeded as a percentage of its connections attemped
    &target=asPercent(Server*.connections.{failed,succeeded}, Server*.connections.attempted, 0)

    # apache01.threads.busy as a percentage of 1500
    &target=asPercent(apache01.threads.busy,1500)

    # Server01 cpu stats as a percentage of its total
    &target=asPercent(Server01.cpu.*.jiffies)

    # cpu stats for each server as a percentage of its total
    &target=asPercent(Server*.cpu.*.jiffies, None, 0)
    ```

    When using nodes, any series or totals that can’t be matched will create output series with names like `asPercent(someSeries,MISSING)` or `asPercent(MISSING,someTotalSeries)` and all values set to None. If desired these series can be filtered out by piping the result through `|exclude("MISSING")` as shown below:

    ``` none
    &target=asPercent(Server{1,2}.memory.used,Server{1,3}.memory.total,0)

    # will produce 3 output series:
    # asPercent(Server1.memory.used,Server1.memory.total) [values will be as expected]
    # asPercent(Server2.memory.used,MISSING) [all values will be None]
    # asPercent(MISSING,Server3.memory.total) [all values will be None]

    &target=asPercent(Server{1,2}.memory.used,Server{1,3}.memory.total,0)|exclude("MISSING")

    # will produce 1 output series:
    # asPercent(Server1.memory.used,Server1.memory.total) [values will be as expected]
    ```

    Each node may be an integer referencing a node in the series name or a string identifying a tag.

    Note

    When total is a seriesList, specifying nodes to match series with the corresponding total series will increase reliability.
- name: Authentication Configuration
  id: config-local-settings#authentication-configuration
  summary: These settings insert additional backends to the AUTHENTICATION_BACKENDS and MIDDLEWARE settings
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Authentication Configuration

    These settings insert additional backends to the [AUTHENTICATION_BACKENDS](https://docs.djangoproject.com/en/dev/ref/settings/#authentication-backends) and [MIDDLEWARE settings](https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-MIDDLEWARE). Additional authentication schemes are possible by manipulating these lists directly.
- name: Auto-complete Support
  id: tags#auto-complete-support
  summary: The HTTP api provides 2 endpoints to support auto-completion of tags and values based on the series which match a provided set of tag expressions
  belongs_to: Graphite Tag Support
  description: |-
    ## Auto-complete Support

    The HTTP api provides 2 endpoints to support auto-completion of tags and values based on the series which match a provided set of tag expressions.

    Each of these endpoints accepts an optional list of tag expressions using the same syntax as the /tags/findSeries endpoint.

    The provided expressions are used to filter the results, so that the suggested list of tags will only include tags that occur in series matching the expressions.

    Results are limited to 100 by default, this can be overridden by passing limit=X in the request parameters. The returned JSON is a compact representation by default, if pretty=1 is passed in the request parameters the returned JSON will be formatted with newlines and indentation.

    To get an auto-complete list of tags:

    ``` none
    $ curl -s "http://graphite/tags/autoComplete/tags?pretty=1&limit=100"

    [
      "datacenter",
      "name",
      "rack",
      "server"
    ]
    ```

    To filter by prefix:

    ``` none
    $ curl -s "http://graphite/tags/autoComplete/tags?pretty=1&tagPrefix=d"

    [
      "datacenter"
    ]
    ```

    If you provide a list of tag expressions, the specified tags are excluded and the result is filtered to only tags that occur in series matching those expressions:

    ``` none
    $ curl -s "http://graphite/tags/autoComplete/tags?pretty=1&expr=datacenter=dc1&expr=server=web01"

    [
      "name",
      "rack"
    ]
    ```

    To get an auto-complete list of values for a specified tag:

    ``` none
    $ curl -s "http://graphite/tags/autoComplete/values?pretty=1&tag=rack"

    [
      "a1",
      "a2",
      "b1",
      "b2"
    ]
    ```

    To filter by prefix:

    ``` none
    $ curl -s "http://graphite/tags/autoComplete/values?pretty=1&tag=rack&valuePrefix=a"

    [
      "a1",
      "a2"
    ]
    ```

    If you provide a list of tag expressions, the result is filtered to only values that occur for the specified tag in series matching those expressions:

    ``` none
    $ curl -s "http://graphite/tags/autoComplete/values?pretty=1&tag=rack&expr=datacenter=dc1&expr=server=web01"

    [
      "a1"
    ]
    ```
- name: averageAbove()
  id: functions#graphite.render.functions.averageAbove
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    averageAbove(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics with an average value above N for the time period specified.

    Example:

    ``` none
    &target=averageAbove(server*.instance*.threads.busy,25)
    ```

    Draws the servers with average values above 25.
- name: averageBelow()
  id: functions#graphite.render.functions.averageBelow
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    averageBelow(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics with an average value below N for the time period specified.

    Example:

    ``` none
    &target=averageBelow(server*.instance*.threads.busy,25)
    ```

    Draws the servers with average values below 25.
- name: averageOutsidePercentile()
  id: functions#graphite.render.functions.averageOutsidePercentile
  summary: null
  belongs_to: Functions
  description: |-
    averageOutsidePercentile(seriesList, n)

    Removes series lying inside an average percentile interval
- name: averageSeries()
  id: functions#graphite.render.functions.averageSeries
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    averageSeries(\*seriesLists)

    Short Alias: avg()

    Takes one metric or a wildcard seriesList. Draws the average value of all metrics passed at each time.

    Example:

    ``` none
    &target=averageSeries(company.server.*.threads.busy)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `average`.
- name: averageSeriesWithWildcards()
  id: functions#graphite.render.functions.averageSeriesWithWildcards
  summary: Call averageSeries after inserting wildcards at the given position(s)
  belongs_to: Functions
  description: |-
    averageSeriesWithWildcards(seriesList, \*position)

    Call averageSeries after inserting wildcards at the given position(s).

    Example:

    ``` none
    &target=averageSeriesWithWildcards(host.cpu-[0-7].cpu-{user,system}.value, 1)
    ```

    This would be the equivalent of

    ``` none
    &target=averageSeries(host.*.cpu-user.value)&target=averageSeries(host.*.cpu-system.value)
    ```

    This is an alias for [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards "graphite.render.functions.aggregateWithWildcards") with aggregation `average`.
- name: bgcolor
  id: render_api#bgcolor
  summary: Sets the background color of the graph
  belongs_to: The Render URL API
  description: |-
    ### bgcolor

    *Default: value from the \[default\] template in graphTemplates.conf*

    Sets the background color of the graph.

    | Color Names | RGB Value   |
    |-------------|-------------|
    | black       | 0,0,0       |
    | white       | 255,255,255 |
    | blue        | 100,100,255 |
    | green       | 0,200,0     |
    | red         | 200,0,50    |
    | yellow      | 255,255,0   |
    | orange      | 255, 165, 0 |
    | purple      | 200,100,255 |
    | brown       | 150,100,50  |
    | aqua        | 0,150,150   |
    | gray        | 175,175,175 |
    | grey        | 175,175,175 |
    | magenta     | 255,0,255   |
    | pink        | 255,100,100 |
    | gold        | 200,200,0   |
    | rose        | 200,150,200 |
    | darkblue    | 0,0,255     |
    | darkgreen   | 0,255,0     |
    | darkred     | 255,0,0     |
    | darkgray    | 111,111,111 |
    | darkgrey    | 111,111,111 |

    RGB can be passed directly in the format \#RRGGBB\[AA\] where RR, GG, and BB are 2-digit hex vaules for red, green and blue, respectively. AA is an optional addition describing the opacity (“alpha”). Where FF is fully opaque, 00 fully transparent.

    Examples:

    ``` none
    &bgcolor=blue
    &bgcolor=2222FF
    &bgcolor=5522FF60
    ```
- name: Built-in finders
  id: storage-backends#built-in-finders
  summary: It is possible to use an alternate storage layer than the default, Whisper, in order to accommodate specific needs
  belongs_to: Alternative storage finders
  description: |-
    ## Built-in finders

    The default graphite setup consists of:

    - A Whisper database
    - A carbon daemon writing data to the database
    - Graphite-web reading and graphing data from the database

    It is possible to use an alternate storage layer than the default, Whisper, in order to accommodate specific needs. The setup above would become:

    - An alternative database
    - A carbon daemon or alternative daemon for writing to the database
    - A custom *storage finder* for reading the data in graphite-web

    This section aims at documenting the last item: configuring graphite-web to read data from a custom storage layer.

    This can be done via the `STORAGE_FINDERS` setting. This setting is a list of paths to finder implementations. Its default value is:

    ``` python
    STORAGE_FINDERS = (
        'graphite.finders.remote.RemoteFinder',
        'graphite.finders.standard.StandardFinder',
    )
    ```

    The default finder reads data from a Whisper database.

    An alternative finder for the experimental Ceres database is available:

    ``` python
    STORAGE_FINDERS = (
        'graphite.finders.ceres.CeresFinder',
    )
    ```

    The setting supports multiple values, meaning you can read data from both a Whisper database and a Ceres database:

    ``` python
    STORAGE_FINDERS = (
        'graphite.finders.remote.RemoteFinder',
        'graphite.finders.standard.StandardFinder',
        'graphite.finders.ceres.CeresFinder',
    )
    ```
- name: cacheTimeout
  id: render_api#cachetimeout
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### cacheTimeout

    *Default: The value of DEFAULT_CACHE_DURATION from local_settings.py*

    The time in seconds for the rendered graph to be cached (only relevant if memcached is configured)
- name: cactiStyle()
  id: functions#graphite.render.functions.cactiStyle
  summary: Takes a series list and modifies the aliases to provide column aligned output with Current, Max, and Min values in the style of cacti
  belongs_to: Functions
  description: |-
    cactiStyle(seriesList, system=None, units=None)

    Takes a series list and modifies the aliases to provide column aligned output with Current, Max, and Min values in the style of cacti. Optionally takes a “system” value to apply unit formatting in the same style as the Y-axis, or a “unit” string to append an arbitrary unit suffix.

    ``` none
    &target=cactiStyle(ganglia.*.net.bytes_out,"si")
    &target=cactiStyle(ganglia.*.net.bytes_out,"si","b")
    ```

    A possible value for `system` is `si`, which would express your values in multiples of a thousand. A second option is to use `binary` which will instead express your values in multiples of 1024 (useful for network devices).

    Column alignment of the Current, Max, Min values works under two conditions: you use a monospace font such as terminus and use a single cactiStyle call, as separate cactiStyle calls are not aware of each other. In case you have different targets for which you would like to have cactiStyle to line up, you can use `group()` to combine them before applying cactiStyle, such as:

    ``` none
    &target=cactiStyle(group(metricA,metricB))
    ```
- name: Carbon
  id: tags#carbon
  summary: Carbon will automatically decode the tags, normalize the tag order, and register the series in the tag database
  belongs_to: Graphite Tag Support
  description: |-
    ## Carbon

    To enter tagged series into Graphite, they should be passed to Carbon by appending the tags to the series name:

    ``` none
    my.series;tag1=value1;tag2=value2
    ```

    Carbon will automatically decode the tags, normalize the tag order, and register the series in the tag database.
- name: Carbon and Graphite-web
  id: install#carbon-and-graphite-web
  summary: null
  belongs_to: Installing Graphite
  description: |-
    ### Carbon and Graphite-web

    Carbon and Graphite-web are installed in `/opt/graphite/` with the following layout:

    - ` ``bin/`` `

    - ` ``conf/`` `

    - ` ``lib/`` `

      Carbon `PYTHONPATH`

    - ` ``storage/`` `

      - ` ``log`` `

        Log directory for Carbon and Graphite-web

      - ` ``rrd`` `

        Location for RRD files to be read

      - ` ``whisper`` `

        Location for Whisper data files to be stored and read

      - ` ``ceres`` `

        Location for Ceres data files to be stored and read

    - ` ``webapp/`` `

      Graphite-web `PYTHONPATH`

      - ` ``graphite/`` `

        Location of `local_settings.py`

      - ` ``content/`` `

        Graphite-web static content directory
- name: carbon-aggregator-cache.py
  id: carbon-daemons#carbon-aggregator-cache-py
  summary: carbon-aggregator-cache.py combines both carbon-aggregator.py and carbon-cache.py
  belongs_to: The Carbon Daemons
  description: "## carbon-aggregator-cache.py\n\n`carbon-aggregator-cache.py` combines both `carbon-aggregator.py` and `carbon-cache.py`. This is useful to reduce the resource and administration overhead of running both daemons.\n\n`carbon-aggregator-cache.py` is configured via:\n\n[carbon.conf](config-carbon)\n\nThe `[aggregator-cache]` section defines listener and destination host/ports.\n\n[relay-rules.conf](config-carbon)\n\nSee carbon-relay.py section.\n\n[aggregation-rules.conf](config-carbon)\n\nSee carbon-aggregator.py section.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/carbon-daemons.html](https://graphite.readthedocs.io/en/latest/carbon-daemons.html)"
- name: carbon-aggregator.py
  id: carbon-daemons#carbon-aggregator-py
  summary: carbon-aggregator.py can be run in front of carbon-cache.py to buffer metrics over time before reporting them into whisper
  belongs_to: The Carbon Daemons
  description: |-
    ## carbon-aggregator.py

    `carbon-aggregator.py` can be run in front of `carbon-cache.py` to buffer metrics over time before reporting them into whisper. This is useful when granular reporting is not required, and can help reduce I/O load and whisper file sizes due to lower retention policies.

    `carbon-aggregator.py` is configured via:

    [carbon.conf](config-carbon)

    The `[aggregator]` section defines listener and destination host/ports.

    [aggregation-rules.conf](config-carbon)

    Defines a time interval (in seconds) and aggregation function (sum or average) for incoming metrics matching a certain pattern. At the end of each interval, the values received are aggregated and published to `carbon-cache.py` as a single metric.
- name: carbon-cache.py
  id: carbon-daemons#carbon-cache-py
  summary: carbon-cache.py accepts metrics over various protocols and writes them to disk as efficiently as possible
  belongs_to: The Carbon Daemons
  description: |-
    ## carbon-cache.py

    `carbon-cache.py` accepts metrics over various protocols and writes them to disk as efficiently as possible. This requires caching metric values in RAM as they are received, and flushing them to disk on an interval using the underlying whisper library. It also provides a query service for in-memory metric datapoints, used by the Graphite webapp to retrieve “hot data”.

    `carbon-cache.py` requires some basic configuration files to run:

    [carbon.conf](config-carbon)

    The `[cache]` section tells `carbon-cache.py` what ports (2003/2004/7002), protocols (newline delimited, pickle) and transports (TCP/UDP) to listen on.

    [storage-schemas.conf](config-carbon)

    Defines a retention policy for incoming metrics based on regex patterns. This policy is passed to whisper when the `.wsp` file is pre-allocated, and dictates how long data is stored for.

    As the number of incoming metrics increases, one `carbon-cache.py` instance may not be enough to handle the I/O load. To scale out, simply run multiple `carbon-cache.py` instances (on one or more machines) behind a `carbon-aggregator.py` or `carbon-relay.py`.

    Warning

    If clients connecting to the `carbon-cache.py` are experiencing errors such as connection refused by the daemon, a common reason is a shortage of file descriptors.

    In the `console.log` file, if you find presence of:

    ` ``Could`` ``not`` ``accept`` ``new`` ``connection`` ``(EMFILE)`` `

    or

    ` ``exceptions.IOError:`` ``[Errno`` ``24]`` ``Too`` ``many`` ``open`` ``files:`` ``'/var/lib/graphite/whisper/systems/somehost/something.wsp'`` `

    the number of files `carbon-cache.py` can open will need to be increased. Many systems default to a max of 1024 file descriptors. A value of 8192 or more may be necessary depending on how many clients are simultaneously connecting to the `carbon-cache.py` daemon.

    In Linux, the system-global file descriptor max can be set via sysctl. Per-process limits are set via ulimit. See documentation for your operating system distribution for details on how to set these values.
- name: carbon-relay.py
  id: carbon-daemons#carbon-relay-py
  summary: 'carbon-relay.py serves two distinct purposes: replication and sharding'
  belongs_to: The Carbon Daemons
  description: |-
    ## carbon-relay.py

    `carbon-relay.py` serves two distinct purposes: replication and sharding.

    When running with `RELAY_METHOD``=``rules`, a `carbon-relay.py` instance can run in place of a `carbon-cache.py` server and relay all incoming metrics to multiple backend `carbon-cache.py`’s running on different ports or hosts.

    In `RELAY_METHOD``=``consistent-hashing` mode, a `DESTINATIONS` setting defines a sharding strategy across multiple `carbon-cache.py` backends. The same consistent hashing list can be provided to the graphite webapp via `CARBONLINK_HOSTS` to spread reads across the multiple backends.

    `carbon-relay.py` is configured via:

    [carbon.conf](config-carbon)

    The `[relay]` section defines listener host/ports and a `RELAY_METHOD`

    [relay-rules.conf](config-carbon)

    With `RELAY_METHOD``=``rules` set, pattern/servers tuples in this file define which metrics matching certain regex rules are forwarded to which hosts.
- name: carbon.conf
  id: config-carbon#carbon-conf
  summary: This is the main config file, and defines the settings for each Carbon daemon
  belongs_to: Configuring Carbon
  description: |-
    ## carbon.conf

    This is the main config file, and defines the settings for each Carbon daemon.

    **Each setting within this file is documented via comments in the config file itself.** The settings are broken down into sections for each daemon - carbon-cache is controlled by the `[cache]` section, carbon-relay is controlled by `[relay]` and carbon-aggregator by `[aggregator]`. However, if this is your first time using Graphite, don’t worry about anything but the `[cache]` section for now.

    Tip

    Carbon-cache and carbon-relay can run on the same host! Try swapping the default ports listed for `LINE_RECEIVER_PORT` and `PICKLE_RECEIVER_PORT` between the `[cache]` and `[relay]` sections to prevent having to reconfigure your deployed metric senders. When setting `DESTINATIONS` in the `[relay]` section, keep in mind your newly-set `PICKLE_RECEIVER_PORT` in the `[cache]` section.
- name: changed()
  id: functions#graphite.render.functions.changed
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    changed(seriesList)

    Takes one metric or a wildcard seriesList. Output 1 when the value changed, 0 when null or the same

    Example:

    ``` none
    &target=changed(Server01.connections.handled)
    ```
- name: Changing Default Graph Parameters
  id: dashboard#changing-default-graph-parameters
  summary: By default, graphs are generated with a standard render template
  belongs_to: The Dashboard User Interface
  description: "### Changing Default Graph Parameters\n\nBy default, graphs are generated with a standard render template. If you find yourself applying *Render Options* to each and every graph you create, then you can select *Edit Default Parameters* in the *Graphs* menu to automatically handle that. These parameters are saved with the dashboard and persisted in a cookie.\n\nThe format is as a set of key-value pairs separated by ampersands, like a query string. The keys and values come from [The Render URL API](render_api) and they’re all available. For example:\n\n` ``drawNullAsZero=true&graphOnly=true`` `\n\nAny new graphs created after saving that as the default graph parameters would have unreported metrics graphed as zeroes and omit the grid lines.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/dashboard.html](https://graphite.readthedocs.io/en/latest/dashboard.html)"
- name: Changing Graph Sizes
  id: dashboard#changing-graph-sizes
  summary: The Graphs | Resize menu item and the Gear menu button allow all graphs on the dashboard to be set to a specified size
  belongs_to: The Dashboard User Interface
  description: |-
    ### Changing Graph Sizes

    The *Graphs \| Resize* menu item and the Gear menu button allow all graphs on the dashboard to be set to a specified size. You can either choose one of the preset sizes, or select *Custom* and enter your own width and height (in pixels).
- name: Client APIs
  id: client-apis
  summary: Cubism.js is a D3 plugin for visualizing time series data in real time, and can pull data from Graphite
  description: "# Client APIs\n\n## Cubism.js\n\n[Cubism.js](http://square.github.io/cubism/) is a D3 plugin for visualizing time series data in real time, and can pull data from Graphite.\n\n## Graphitejs\n\n[Graphitejs](https://github.com/prestontimmons/graphitejs) is a jQuery plugin for easily making and displaying graphs and updating them on the fly using the Graphite URL api.\n\n## Scales\n\n[Scales](https://github.com/Cue/scales) is a Python server state and statistics library that can output its data to Graphite.\n\n## Structured Metrics\n\n[structured_metrics](https://github.com/vimeo/graph-explorer/tree/master/structured_metrics) is a lightweight python library that uses plugins to read in Graphite’s list of metric names and convert it into a multi-dimensional tag space of clear, sanitized targets.\n\n## txCarbonClient\n\n[txCarbonClient](https://github.com/fdChasm/txCarbonClient) is a simple Twisted API for reporting metrics to Carbon.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/client-apis.html](https://graphite.readthedocs.io/en/latest/client-apis.html)"
- name: Cluster Configuration
  id: config-local-settings#cluster-configuration
  summary: These settings configure the Graphite webapp for clustered use
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Cluster Configuration

    These settings configure the Graphite webapp for clustered use. When `CLUSTER_SERVERS` is set, metric browse and render requests will cause the webapp to query other webapps in CLUSTER_SERVERS for matching metrics. Graphite can either merge responses or choose the best response if more than one cluster server returns the same series.

    CLUSTER_SERVERS

    Default: \[\]

    The list of IP addresses and ports of remote Graphite webapps in a cluster. Each of these servers should have local access to metric data to serve. Ex: \[“10.0.2.2:80”, “[http://10.0.2.3:80?format=pickle&local=1](http://10.0.2.3:80?format=pickle&local=1)”\]

    Cluster server definitions can optionally include a protocol ([http://](#) or [https://](#)) and/or additional config parameters.

    The format parameter can be set to pickle (the default) or msgpack to control the encoding used for intra-cluster find and render requests.

    The local parameter can be set to 1 (the default) or 0 to control whether cluster servers should only return results from local finders, or fan the request out to their remote finders.

    USE_WORKER_POOL

    Default: True

    Creates a pool of worker threads to which tasks can be dispatched. This makes sense if there are multiple CLUSTER_SERVERS and/or STORAGE_FINDERS because then the communication with them can be parallelized. The number of threads is equal to: min(number of finders, POOL_MAX_WORKERS)

    Be careful when increasing the number of threads, in particular if your start multiple graphite-web processes (with uwsgi or similar) as this will increase memory consumption (and number of connections to memcached).

    POOL_MAX_WORKERS

    Default: 10

    > The maximum number of worker threads that should be created.

    REMOTE_RETRY_DELAY

    Default: 60

    Time in seconds to blacklist a webapp after a timed-out request.

    FIND_CACHE_DURATION

    Default: 300

    Time to cache remote metric find results in seconds.

    MAX_FETCH_RETRIES

    Default: 2

    Number of retries for a specific remote data fetch.

    FIND_TOLERANCE

    Default: FIND_TOLERANCE = 2 \* FIND_CACHE_DURATION

    If the query doesn’t fall entirely within the FIND_TOLERANCE window we disregard the window. This prevents unnecessary remote fetches caused when carbon’s cache skews node.intervals, giving the appearance remote systems have data we don’t have locally, which we probably do.

    REMOTE_STORE_MERGE_RESULTS

    Default: True

    During a rebalance of a consistent hash cluster, after a partition event on a replication \> 1 cluster or in other cases we might receive multiple TimeSeries data for a metric key. Merge them together rather than choosing the “most complete” one (pre-0.9.14 behaviour).

    REMOTE_STORE_USE_POST

    Default: False

    This setting enables POST queries instead of GET for remote requests.

    REMOTE_STORE_FORWARD_HEADERS

    Default: \[\]

    Provide a list of HTTP headers that you want forwarded on from this host when making a request to a remote webapp server in CLUSTER_SERVERS.

    REMOTE_EXCLUDE_LOCAL

    Default: False

    Try to detect when a cluster server is localhost and don’t forward queries

    REMOTE_RENDERING

    Default: False

    Enable remote rendering of images and data (JSON, et al.) on remote Graphite webapps. If this is enabled, `RENDERING_HOSTS` must also be enabled and configured accordingly.

    RENDERING_HOSTS

    Default: \[\]

    List of IP addresses and ports of remote Graphite webapps used to perform rendering. Each webapp must have access to the same data as the Graphite webapp which uses this setting either through shared local storage or via `CLUSTER_SERVERS`. Ex: \[“10.0.2.4:80”, “10.0.2.5:80”\]

    REMOTE_RENDER_CONNECT_TIMEOUT

    Default: 1.0

    Connection timeout for remote rendering requests in seconds.

    CARBONLINK_HOSTS

    Default: \[127.0.0.1:7002\]

    If multiple carbon-caches are running on this machine, each should be listed here so that the Graphite webapp may query the caches for data that has not yet been persisted. Remote carbon-cache instances in a multi-host clustered setup should *not* be listed here. Instance names should be listed as applicable. Ex: \[‘127.0.0.1:7002:a’,‘127.0.0.1:7102:b’, ‘127.0.0.1:7202:c’\]

    CARBONLINK_TIMEOUT

    Default: 1.0

    Timeout for carbon-cache cache queries in seconds.

    CARBONLINK_HASHING_TYPE

    Default: carbon_ch

    Possible values: carbon_ch, fnv1a_ch

    The default carbon_ch is Graphite’s traditional consistent-hashing implementation. Alternatively, you can use fnv1a_ch, which supports the Fowler–Noll–Vo hash function (FNV-1a) hash implementation offered by the [carbon-c-relay relay](https://github.com/grobian/carbon-c-relay) project.

    CARBON_METRIC_PREFIX:

    Default: carbon

    Prefix for internal carbon statistics.

    INTRACLUSTER_HTTPS

    Default: False

    This setting controls whether https is used to communicate between cluster members that don’t have an explicit protocol specified.
- name: Collection
  id: tools#collection
  summary: A statsd-compatible stats aggregator written in C
  belongs_to: Tools That Work With Graphite
  description: |-
    ## Collection

    [Brubeck](https://github.com/github/brubeck)

    A statsd-compatible stats aggregator written in C.

    [Bucky](http://pypi.python.org/pypi/bucky)

    A small service implemented in Python for collecting and translating metrics for Graphite. It can currently collect metric data from CollectD daemons and from StatsD clients.

    [Carbonator Windows Service](https://github.com/CryptonZylog/carbonator)

    Simple lightweight Windows Service that collects Performance Counter metrics and sends them over to the Graphite server. Configured via .NET xml application configuration.

    [collectd](http://collectd.org)

    A daemon which collects system performance statistics periodically and provides mechanisms to store the values in a variety of ways, including RRD. To send collectd metrics into carbon/graphite, use collectd’s [write-graphite](http://collectd.org/wiki/index.php/Plugin:Write_Graphite) plugin (available as of 5.1). Other options include:

    - Jordan Sissel’s node [collectd-to-graphite](https://github.com/loggly/collectd-to-graphite) proxy
    - Joe Miller’s perl [collectd-graphite](https://github.com/joemiller/collectd-graphite) plugin
    - Gregory Szorc’s python [collectd-carbon](https://github.com/indygreg/collectd-carbon) plugin
    - Paul J. Davis’s [Bucky](http://pypi.python.org/pypi/bucky) service

    Graphite can also read directly from [collectd](http://collectd.org)’s RRD files. RRD files can simply be added to `STORAGE_DIR/rrd` (as long as directory names and files do not contain any `.` characters). For example, collectd’s `host.name/load/load.rrd` can be symlinked to `rrd/collectd/host_name/load/load.rrd` to graph `collectd.host_name.load.load.{short,mid,long}term`.

    [Collectl](http://collectl.sourceforge.net)

    A collection tool for system metrics that can be run both interactively and as a daemon and has support for collecting from a broad set of subsystems. Collectl includes a Graphite interface which allows data to easily be fed to Graphite for storage.

    [Diamond](https://diamond.readthedocs.io/en/latest/)

    a Python daemon that collects system metrics and publishes them to Graphite. It is capable of collecting cpu, memory, network, I/O, load and disk metrics. Additionally, it features an API for implementing custom collectors for gathering metrics from almost any source.

    [Ganglia](http://ganglia.info)

    A scalable distributed monitoring system for high-performance computing systems such as clusters and Grids. It collects system performance metrics and stores them in RRD, but now there is an [add-on](https://github.com/ganglia/ganglia_contrib/tree/master/graphite_integration/) that allows Ganglia to send metrics directly to Graphite. Further integration work is underway.

    [graphite-pollers](https://github.com/phreakocious/graphite-pollers)

    A collection of scripts that shovel data into Graphite including a multi-threaded SNMP poller for network interface IF-MIB statistics and another which pulls linux network stack data from files in /proc/net. Add to cron and go.

    [Graphite PowerShell Functions](https://github.com/MattHodge/Graphite-PowerShell-Functions)

    A group of functions that can be used to collect Windows Performance Counters and send them over to the Graphite server. The main function can be run as a Windows service, and everything is configurable via an XML file.

    [HoardD](https://github.com/coredump/hoardd)

    A Node.js app written in CoffeeScript to send data from servers to Graphite, much like collectd does, but aimed at being easier to expand and with less footprint. It comes by default with basic collectors plus Redis and MySQL metrics, and can be expanded with Javascript or CoffeeScript.

    [Host sFlow](http://host-sflow.sourceforge.net)

    An open source implementation of the sFlow protocol ([http://www.sflow.org](http://www.sflow.org)), exporting a standard set of host cpu, memory, disk and network I/O metrics. The sflow2graphite utility converts sFlow to Graphite’s plaintext protocol, allowing Graphite to receive sFlow metrics.

    [jmx2graphite](https://github.com/logzio/jmx2graphite)

    The easiest way to poll JMX metrics and write them to Graphite. This tool runs as a Docker container, polling your JMX every X seconds and writing the metrics to Graphite. Requires a minimum of configuration to get started.

    [jmxtrans](https://github.com/jmxtrans/jmxtrans)

    A powerful tool that performs JMX queries to collect metrics from Java applications. It is requires very little configuration and is capable of sending metric data to several backend applications, including Graphite.

    [Logster](https://github.com/etsy/logster)

    A utility for reading log files and generating metrics in Graphite or Ganglia. It is ideal for visualizing trends of events that are occurring in your application/system/error logs. For example, you might use logster to graph the number of occurrences of HTTP response code that appears in your web server logs.

    [metrics-sampler](https://github.com/dimovelev/metrics-sampler)

    A java program which regularly queries metrics from a configured set of inputs, selects and renames them using regular expressions and sends them to a configured set of outputs. It supports JMX and JDBC as inputs and Graphite as output out of the box.

    [Sensu](http://sensuapp.org)

    A monitoring framework that can route metrics to Graphite. Servers subscribe to sets of checks, so getting metrics from a new server to Graphite is as simple as installing the Sensu client and subscribing.

    [snort2graphite](https://github.com/gregvolk/snort2graphite)

    Snort IDS/IPS can be configured to generate a rich set of metrics about network traffic. Presently there are more than 130 metrics available. Snort2graphite will pick up the most recent data from your snort.stats file and send all the metrics into Graphite.

    [SqlToGraphite](https://github.com/perryofpeek/SqlToGraphite)

    An agent for windows written in .net to collect metrics using plugins (WMI, SQL Server, Oracle) by polling an endpoint with a SQL query and pushing the results into graphite. It uses either a local or a centralised configuration over HTTP.

    [SSC Serv](https://ssc-serv.com)

    A Windows service (agent) which periodically publishes system metrics, for example CPU, memory and disk usage. It can store data in Graphite using a naming schema that’s identical to that used by collectd.

    [telegraf](https://github.com/influxdata/telegraf)

    Telegraf is an agent written in Go for collecting, processing, aggregating, and writing metrics. It also supports metric output to Graphite.
- name: color()
  id: functions#graphite.render.functions.color
  summary: null
  belongs_to: Functions
  description: |-
    color(seriesList, theColor)

    Assigns the given color to the seriesList

    Example:

    ``` none
    &target=color(collectd.hostname.cpu.0.user, 'green')
    &target=color(collectd.hostname.cpu.0.system, 'ff0000')
    &target=color(collectd.hostname.cpu.0.idle, 'gray')
    &target=color(collectd.hostname.cpu.0.idle, '6464ffaa')
    ```
- name: colorList
  id: render_api#colorlist
  summary: Takes one or more comma-separated color names or RGB values (see bgcolor for a list of color names) and uses that list in order as the colors of the lines
  belongs_to: The Render URL API
  description: |-
    ### colorList

    *Default: value from the \[default\] template in graphTemplates.conf*

    Takes one or more comma-separated color names or RGB values (see bgcolor for a list of color names) and uses that list in order as the colors of the lines. If more lines / metrics are drawn than colors passed, the list is reused in order. Any RGB value can also have an optional transparency (00 being fully transparent, FF being opaque), as shown in the second example.

    Example:

    ``` none
    &colorList=green,yellow,orange,red,purple,DECAFF
    &colorList=FF000055,00FF00AA,DECAFFEF
    ```
- name: Completer or browser tree?
  id: dashboard#completer-or-browser-tree
  summary: When you open the Dashboard interface, you’ll see the top of the page taken up by a completer
  belongs_to: The Dashboard User Interface
  description: |-
    ### Completer or browser tree?

    When you open the Dashboard interface, you’ll see the top of the page taken up by a completer. This allows you to select a metric series to show on a graph in the dashboard.

    If you’re only viewing a dashboard rather than modifying one, the completer just gets in the way. You can either resize it by dragging the splitter bar (between the completer and graph panels), or hide it by clicking on the little triangular icon in the splitter bar. Once hidden, the same triangular icon serves to display the panel again.

    An alternative to the completer is a browser tree, which shows to the left of the graph panel. To change to this mode, use the *Dashboard \| Configure UI* menu item, and choose *Tree (left nav)*. You’ll have to refresh the page to get this to show. The completer and browser tree do the same job, so the choice is down to your personal preference. Your choice is recorded in a persistent browser cookie, so it should be preserved across sessions.
- name: Config File Location
  id: config-local-settings#config-file-location
  summary: By default settings module is local_settings.py and it is generally located within the main graphite module where the webapp’s code lives
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Config File Location

    By default settings module is `local_settings.py` and it is generally located within the main `graphite` module where the webapp’s code lives. In the [default installation layout](install#default-installation-layout) this is `/opt/graphite/webapp/graphite/local_settings.py`. Alternative locations can be used by symlinking to this path or by ensuring the module can be found within the Python module search path.

    This can be change by setting `GRAPHITE_SETTINGS_MODULE` environment variable. For example in a wsgi file.
- name: Configure nginx
  id: config-webapp#configure-nginx
  summary: Don’t forget to change the server_name to match your actual hostname
  belongs_to: Configuring The Webapp
  description: |-
    ### Configure nginx

    We will use dedicated log files for nginx when serving Graphite:

    ``` none
    sudo touch /var/log/nginx/graphite.access.log
    sudo touch /var/log/nginx/graphite.error.log
    sudo chmod 640 /var/log/nginx/graphite.*
    sudo chown www-data:www-data /var/log/nginx/graphite.*
    ```

    Write the following configuration in `/etc/nginx/sites-available/graphite`:

    ``` none
    upstream graphite {
        server 127.0.0.1:8080 fail_timeout=0;
    }

    server {
        listen 80 default_server;

        server_name HOSTNAME;

        root /opt/graphite/webapp;

        access_log /var/log/nginx/graphite.access.log;
        error_log  /var/log/nginx/graphite.error.log;

        location = /favicon.ico {
            return 204;
        }

        # serve static content from the "content" directory
        location /static {
            alias /opt/graphite/webapp/content;
            expires max;
        }

        location / {
            try_files $uri @graphite;
        }

        location @graphite {
            proxy_pass_header Server;
            proxy_set_header Host $http_host;
            proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Scheme $scheme;
            proxy_connect_timeout 10;
            proxy_read_timeout 10;
            proxy_pass http://graphite;
        }
    }
    ```

    Note

    Don’t forget to change the `server_name` to match your actual hostname. You may also adapt other settings to your use case, such as `root`.

    Enable this configuration for nginx:

    ``` none
    sudo ln -s /etc/nginx/sites-available/graphite /etc/nginx/sites-enabled
    sudo rm -f /etc/nginx/sites-enabled/default
    ```

    Reload nginx to use the new configuration:

    ``` none
    sudo service nginx reload
    ```
- name: Configure Webserver (Apache)
  id: config-local-settings#configure-webserver-apache
  summary: There is an example example-graphite-vhost.conf file in the examples directory of the graphite web source code
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Configure Webserver (Apache)

    There is an example `example-graphite-vhost.conf` file in the examples directory of the graphite web source code. You can use this to configure apache. Different distributions have different ways of configuring Apache. Please refer to your distribution’s documentation on the subject.

    For example, Ubuntu uses `/etc/apache2/sites-available` and `sites-enabled/` to handle this (A symlink from `sites-enabled/` to `sites-available/` would be used after placing the file in sites-available/).

    Others use an Include directive in the `httpd.conf` file like this:

    ``` none
    # This goes in httpd.conf
    Include /usr/local/apache2/conf/vhosts.d/*.conf
    ```

    The configuration files must then all be added to `/usr/local/apache2/conf/vhosts.d/`. Still others may not help handle this at all and you must add the configuration to your http.conf file directly.

    Graphite will be in the DocumentRoot of your webserver, and will not allow you to access plain-HTML in subdirectories without addition configuration. You may want to edit the `example-graphite-vhost.conf` file to change port numbers or use additional `"SetHandler``None"` directives to allow access to other directories.

    Be sure to reload your Apache configuration by running `sudo``/etc/init.d/apache2``reload` or `sudo``/etc/init.d/httpd``reload`.
- name: Configuring Carbon
  id: config-carbon
  summary: Carbon’s config files all live in /opt/graphite/conf/. If you’ve just installed Graphite, none of the .conf files will exist yet, but there will be a .conf.example file for each one
  description: "# Configuring Carbon\n\nCarbon’s config files all live in `/opt/graphite/conf/`. If you’ve just installed Graphite, none of the `.conf` files will exist yet, but there will be a `.conf.example` file for each one. Simply copy the example files, removing the .example extension, and customize your settings.\n\n``` default\npushd /opt/graphite/conf\ncp carbon.conf.example carbon.conf\ncp storage-schemas.conf.example storage-schemas.conf\n```\n\nThe example defaults are sane, but they may not meet your information resolution needs or storage limitations.\n\n## carbon.conf\n\nThis is the main config file, and defines the settings for each Carbon daemon.\n\n**Each setting within this file is documented via comments in the config file itself.** The settings are broken down into sections for each daemon - carbon-cache is controlled by the `[cache]` section, carbon-relay is controlled by `[relay]` and carbon-aggregator by `[aggregator]`. However, if this is your first time using Graphite, don’t worry about anything but the `[cache]` section for now.\n\nTip\n\nCarbon-cache and carbon-relay can run on the same host! Try swapping the default ports listed for `LINE_RECEIVER_PORT` and `PICKLE_RECEIVER_PORT` between the `[cache]` and `[relay]` sections to prevent having to reconfigure your deployed metric senders. When setting `DESTINATIONS` in the `[relay]` section, keep in mind your newly-set `PICKLE_RECEIVER_PORT` in the `[cache]` section.\n\n## storage-schemas.conf\n\nThis configuration file details retention rates for storing metrics. It matches metric paths to patterns, and tells whisper what frequency and history of datapoints to store.\n\nImportant notes before continuing:\n\n- There can be many sections in this file.\n- The sections are applied in order from the top (first) and bottom (last).\n- The patterns are regular expressions, as opposed to the wildcards used in the URL API.\n- The first pattern that matches the metric name is used.\n- This retention is set at the time the first metric is sent.\n- Changing this file will not affect already-created .wsp files. Use whisper-resize.py to change those.\n\nA given rule is made up of 3 lines:\n\n- A name, specified inside square brackets.\n- A regex, specified after “pattern=”\n- A retention rate line, specified after “retentions=”\n\nThe retentions line can specify multiple retentions. Each retention of `frequency:history` is separated by a comma.\n\nFrequencies and histories are specified using the following suffixes:\n\n- s - second\n- m - minute\n- h - hour\n- d - day\n- w - week\n- y - year\n\nHere’s a simple, single retention example:\n\n``` none\n[garbage_collection]\npattern = garbageCollections$\nretentions = 10s:14d\n```\n\nThe name `[garbage_collection]` is mainly for documentation purposes, and will show up in `creates.log` when metrics matching this section are created.\n\nThe regular expression pattern will match any metric that ends with `garbageCollections`. For example, `com.acmeCorp.instance01.jvm.memory.garbageCollections` would match, but `com.acmeCorp.instance01.jvm.memory.garbageCollections.full` would not.\n\nThe `retentions` line is saying that each datapoint represents 10 seconds, and we want to keep enough datapoints so that they add up to 14 days of data.\n\nHere’s a more complicated example with multiple retention rates:\n\n``` none\n[apache_busyWorkers]\npattern = ^servers\\.www.*\\.workers\\.busyWorkers$\nretentions = 15s:7d,1m:21d,15m:5y\n```\n\nIn this example, imagine that your metric scheme is `servers.<servername>.<metrics>`. The pattern would match server names that start with ‘www’, followed by anything, that are sending metrics that end in ‘.workers.busyWorkers’ (note the escaped ‘.’ characters).\n\nAdditionally, this example uses multiple retentions. The general rule is to specify retentions from most-precise:least-history to least-precise:most-history – whisper will properly downsample metrics (averaging by default) as thresholds for retention are crossed.\n\nBy using multiple retentions, you can store long histories of metrics while saving on disk space and I/O. Because whisper averages (by default) as it downsamples, one is able to determine totals of metrics by reversing the averaging process later on down the road.\n\nExample: You store the number of sales per minute for 1 year, and the sales per hour for 5 years after that. You need to know the total sales for January 1st of the year before. You can query whisper for the raw data, and you’ll get 24 datapoints, one for each hour. They will most likely be floating point numbers. You can take each datapoint, multiply by 60 (the ratio of high-precision to low-precision datapoints) and still get the total sales per hour.\n\nAdditionally, whisper supports a legacy retention specification for backwards compatibility reasons - `seconds-per-datapoint:count-of-datapoints`\n\n``` none\nretentions = 60:1440\n```\n\n60 represents the number of seconds per datapoint, and 1440 represents the number of datapoints to store. This required some unnecessarily complicated math, so although it’s valid, it’s not recommended.\n\n## storage-aggregation.conf\n\nThis file defines how to aggregate data to lower-precision retentions. The format is similar to `storage-schemas.conf`. Important notes before continuing:\n\n- This file is optional. If it is not present, defaults will be used.\n- The sections are applied in order from the top (first) and bottom (last), similar to `storage-schemas.conf`.\n- The first pattern that matches the metric name is used, similar to `storage-schemas.conf`.\n- There is no `retentions` line. Instead, there are `xFilesFactor` and/or `aggregationMethod` lines.\n- `xFilesFactor` should be a floating point number between 0 and 1, and specifies what fraction of the previous retention level’s slots must have non-null values in order to aggregate to a non-null value. The default is 0.5.\n- `aggregationMethod` specifies the function used to aggregate values for the next retention level. Legal methods are `average`, `sum`, `min`, `max`, and `last`. The default is `average`.\n- These are set at the time the first metric is sent.\n- Changing this file will not affect .wsp files already created on disk. Use whisper-set-aggregation-method.py to change those.\n\nHere’s an example:\n\n``` none\n[all_min]\npattern = \\.min$\nxFilesFactor = 0.1\naggregationMethod = min\n```\n\nThe pattern above will match any metric that ends with `.min`.\n\nThe `xFilesFactor` line is saying that a minimum of 10% of the slots in the previous retention level must have values for next retention level to contain an aggregate. The `aggregationMethod` line is saying that the aggregate function to use is `min`.\n\nIf either `xFilesFactor` or `aggregationMethod` is left out, the default value will be used.\n\nThe aggregation parameters are kept separate from the retention parameters because the former depends on the type of data being collected and the latter depends on volume and importance.\n\nIf you want to change aggregation methods for existing data, be sure that you update the whisper files as well.\n\nExample:\n\n``` none\n/opt/graphite/bin/whisper-set-aggregation-method.py /opt/graphite/storage/whisper/test.wsp max\n```\n\nThis example sets the aggregation for the test.wsp to max. (The location of the python script depends on your installation)\n\n## relay-rules.conf\n\nRelay rules are used to send certain metrics to a certain backend. This is handled by the carbon-relay system. It must be running for relaying to work. You can use a regular expression to select the metrics and define the servers to which they should go with the servers line.\n\nExample:\n\n``` none\n[example]\npattern = ^mydata\\.foo\\..+\nservers = 10.1.2.3, 10.1.2.4:2004, myserver.mydomain.com\n```\n\nYou must define at least one section as the default.\n\n## aggregation-rules.conf\n\nAggregation rules allow you to add several metrics together as they come in, reducing the need to sum() many metrics in every URL. Note that unlike some other config files, any time this file is modified it will take effect automatically. This requires the carbon-aggregator service to be running.\n\nThe form of each line in this file should be as follows:\n\n``` none\noutput_template (frequency) = method input_pattern\n```\n\nThis will capture any received metrics that match `input_pattern` for calculating an aggregate metric. The calculation will occur every `frequency` seconds using a valid `method`. The name of the aggregate metric will be derived from `output_template` filling in any captured fields from `input_pattern`. Any metric that will arrive to `carbon-aggregator` will proceed to its output untouched unless it is overridden by some rule.\n\nAvailable aggregation methods are: `sum`, `avg`, `min`, `max`, `p50`, `p75`, `p80`, `p90`, `p95`, `p99`, `p999`, and `count` - where `p50` means 50th percentile and `p999` means 99.9th percentile, etc.\n\nCare should be taken when using percentile aggregation methods because re-aggregation does not work the way you [might](https://www.vividcortex.com/blog/why-percentiles-dont-work-the-way-you-think) [expect](https://grafana.com/blog/2016/03/03/25-graphite-grafana-and-statsd-gotchas/#aggregating.percentiles). The utility of percentile aggregation however means they are provided if you wish to use them.\n\nFor example, if your metric naming scheme is:\n\n``` none\n<env>.applications.<app>.<server>.<metric>\n```\n\nYou could configure some aggregations like so:\n\n``` none\n<env>.applications.<app>.all.requests (60) = sum <env>.applications.<app>.*.requests\n<env>.applications.<app>.all.latency (60) = avg <env>.applications.<app>.*.latency\n```\n\nAs an example, if the following metrics are received:\n\n``` none\nprod.applications.apache.www01.requests\nprod.applications.apache.www02.requests\nprod.applications.apache.www03.requests\nprod.applications.apache.www04.requests\nprod.applications.apache.www05.requests\n```\n\nThey would all go into the same aggregation buffer and after 60 seconds the aggregate metric `prod.applications.apache.all.requests` would be calculated by summing their values.\n\nTemplate components such as \\<env\\> will match everything up to the next dot. To match metric multiple components including the dots, use \\<\\<metric\\>\\> in the input template:\n\n``` none\n<env>.applications.<app>.all.<app_metric> (60) = sum <env>.applications.<app>.*.<<app_metric>>\n```\n\nIt is also possible to use regular expressions. Following the example above when using:\n\n``` none\n<env>.applications.<app>.<domain>.requests (60) = sum <env>.applications.<app>.<domain>\\d{2}.requests\n```\n\nYou will end up with `prod.applications.apache.www.requests` instead of `prod.applications.apache.all.requests`.\n\nAnother common use pattern of `carbon-aggregator` is to aggregate several data points of the *same metric*. This could come in handy when you have got the same metric coming from several hosts, or when you are bound to send data more frequently than your shortest retention.\n\n## rewrite-rules.conf\n\nRewrite rules allow you to rewrite metric names using Python regular expressions. Note that unlike some other config files, any time this file is modified it will take effect automatically. This requires the carbon-aggregator service to be running.\n\nThe form of each line in this file should be as follows:\n\n``` none\nregex-pattern = replacement-text\n```\n\nThis will capture any received metrics that match ‘regex-pattern’ and rewrite the matched portion of the text with ‘replacement-text’. The ‘regex-pattern’ must be a valid Python regular expression, and the ‘replacement-text’ can be any value. You may also use capture groups:\n\n``` none\n^collectd\\.([a-z0-9]+)\\. = \\1.system.\n```\n\nWhich would result in:\n\n``` none\ncollectd.prod.cpu-0.idle-time => prod.system.cpu-0.idle-item\n```\n\nrewrite-rules.conf consists of two sections, \\[pre\\] and \\[post\\]. The rules in the pre section are applied to metric names as soon as they are received. The post rules are applied after aggregation has taken place.\n\nFor example:\n\n``` none\n[post]\n_sum$ =\n_avg$ =\n```\n\nThese rules would strip off a suffix of \\_sum or \\_avg from any metric names after aggregation.\n\n**Note:** if you plan to use the `=` sign in your rewrite rules. Use its octal value: `\\075`. For example `foo=bar`` ``=`` ``foo.bar` would be `foo\\075bar`` ``=`` ``foo.bar`\n\n## whitelist and blacklist\n\nThe whitelist functionality allows any of the carbon daemons to only accept metrics that are explicitly whitelisted and/or to reject blacklisted metrics. The functionality can be enabled in carbon.conf with the `USE_WHITELIST` flag. This can be useful when too many metrics are being sent to a Graphite instance or when there are metric senders sending useless or invalid metrics.\n\n`GRAPHITE_CONF_DIR` is searched for `whitelist.conf` and `blacklist.conf`. Each file contains one regular expressions per line to match against metric values. If the whitelist configuration is missing or empty, all metrics will be passed through by default.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-carbon.html](https://graphite.readthedocs.io/en/latest/config-carbon.html)"
- name: Configuring The Webapp
  id: config-webapp
  summary: There are multiple ways to expose the Graphite webapp
  description: "# Configuring The Webapp\n\nThere are multiple ways to expose the Graphite webapp. The following stack configurations exist:\n\n- nginx + gunicorn\n- Apache + mod_wsgi\n- nginx + uWSGI\n\nDepending on the configuration you choose, the webapp configuration is slightly different.\n\n## nginx + gunicorn\n\nIn this setup, nginx will proxy requests for Gunicorn, which will itself listen locally on port 8080 and serve the webapp (Django application).\n\n### Install Gunicorn\n\nIf you use a virtualenv, you can use `pip`:\n\n``` none\npip install gunicorn\n```\n\nOtherwise, you can use packages for your distribution.\n\nOn Debian-based systems, run:\n\n``` none\nsudo apt install gunicorn\n```\n\n### Install nginx\n\nOn Debian-based systems, run:\n\n``` none\nsudo apt install nginx\n```\n\n### Configure nginx\n\nWe will use dedicated log files for nginx when serving Graphite:\n\n``` none\nsudo touch /var/log/nginx/graphite.access.log\nsudo touch /var/log/nginx/graphite.error.log\nsudo chmod 640 /var/log/nginx/graphite.*\nsudo chown www-data:www-data /var/log/nginx/graphite.*\n```\n\nWrite the following configuration in `/etc/nginx/sites-available/graphite`:\n\n``` none\nupstream graphite {\n    server 127.0.0.1:8080 fail_timeout=0;\n}\n\nserver {\n    listen 80 default_server;\n\n    server_name HOSTNAME;\n\n    root /opt/graphite/webapp;\n\n    access_log /var/log/nginx/graphite.access.log;\n    error_log  /var/log/nginx/graphite.error.log;\n\n    location = /favicon.ico {\n        return 204;\n    }\n\n    # serve static content from the \"content\" directory\n    location /static {\n        alias /opt/graphite/webapp/content;\n        expires max;\n    }\n\n    location / {\n        try_files $uri @graphite;\n    }\n\n    location @graphite {\n        proxy_pass_header Server;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Scheme $scheme;\n        proxy_connect_timeout 10;\n        proxy_read_timeout 10;\n        proxy_pass http://graphite;\n    }\n}\n```\n\nNote\n\nDon’t forget to change the `server_name` to match your actual hostname. You may also adapt other settings to your use case, such as `root`.\n\nEnable this configuration for nginx:\n\n``` none\nsudo ln -s /etc/nginx/sites-available/graphite /etc/nginx/sites-enabled\nsudo rm -f /etc/nginx/sites-enabled/default\n```\n\nReload nginx to use the new configuration:\n\n``` none\nsudo service nginx reload\n```\n\n## Apache + mod_wsgi\n\nFirst, you need to install mod_wsgi.\n\nSee the [mod_wsgi InstallationInstructions](https://code.google.com/p/modwsgi/wiki/InstallationInstructions) for installation instructions.\n\nThen create the graphite.wsgi. (You can find example of graphite.wsgi file on the [conf](https://github.com/graphite-project/graphite-web/blob/master/conf/graphite.wsgi.example) directory of source ditribution):\n\n``` bash\n# /opt/graphite/conf/graphite.wsgi\n\nimport sys\nsys.path.append('/opt/graphite/webapp')\nfrom graphite.wsgi import application\n```\n\nFinally, configure the apache vhost. (You can find example of Graphite vhost configuration in the [contrib](https://github.com/graphite-project/graphite-web/blob/master/examples/example-graphite-vhost.conf) directory of source ditribution):\n\n``` apache\n# /etc/httpd/conf.d/graphite-vhost.conf\n\nLoadModule wsgi_module modules/mod_wsgi.so\n\nWSGISocketPrefix /var/run/wsgi\n\nListen 80\n<VirtualHost *:80>\n\n    ServerName graphite\n    DocumentRoot \"/opt/graphite/webapp\"\n    ErrorLog /opt/graphite/storage/log/webapp/error.log\n    CustomLog /opt/graphite/storage/log/webapp/access.log common\n\n    WSGIDaemonProcess graphite-web processes=5 threads=5 display-name='%{GROUP}' inactivity-timeout=120\n    WSGIProcessGroup graphite-web\n    WSGIApplicationGroup %{GLOBAL}\n    WSGIImportScript /opt/graphite/conf/graphite.wsgi process-group=graphite-web application-group=%{GLOBAL}\n\n    WSGIScriptAlias / /opt/graphite/conf/graphite.wsgi\n\n    Alias /static/ /opt/graphite/static/\n\n    <Directory /opt/graphite/static/>\n            <IfVersion < 2.4>\n                    Order deny,allow\n                    Allow from all\n            </IfVersion>\n            <IfVersion >= 2.4>\n                    Require all granted\n            </IfVersion>\n    </Directory>\n\n    <Directory /opt/graphite/conf/>\n            <IfVersion < 2.4>\n                    Order deny,allow\n                    Allow from all\n            </IfVersion>\n            <IfVersion >= 2.4>\n                    Require all granted\n            </IfVersion>\n    </Directory>\n</VirtualHost>\n```\n\nAdapt the mod_wsgi configuration to your requirements.\n\nSee the [mod_wsgi QuickConfigurationGuide](https://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) for an overview of configurations and [mod_wsgi ConfigurationDirectives](https://code.google.com/p/modwsgi/wiki/ConfigurationDirectives) to see all configuration directives\n\nRestart apache:\n\n``` default\n$ service httpd restart\n```\n\n### Running the webapp with mod_wsgi as URL-prefixed application (Apache)\n\nWhen using the new `URL_PREFIX` parameter in `local_settings.py` the `WSGIScriptAlias` setting must look like the following (e.g. URL_PREFIX=”/graphite”):\n\n``` default\nWSGIScriptAlias /graphite /opt/graphite/conf/graphite.wsgi/graphite\n```\n\nThe /graphite is needed for Django to create the correct URLs\n\n## Nginx + uWSGI\n\nFirst, you need to install uWSGI with Python support. On Debian, install `uwsgi-plugin-python`.\n\nThen create the uWSGI file for Graphite-web in `/etc/uwsgi/apps-available/graphite.ini`:\n\n``` ini\n[uwsgi]\nprocesses = 2\nsocket = localhost:8080\ngid = www-data\nuid = www-data\nvirtualenv = /opt/graphite\nchdir = /opt/graphite/conf\nmodule = wsgi:application\n```\n\nThen create the file `wsgi.py`:\n\n``` bash\n# /opt/graphite/conf/wsgi.py\n\nimport sys\nsys.path.append('/opt/graphite/webapp')\nfrom graphite.wsgi import application\n```\n\nEnable `graphite.ini` and restart uWSGI:\n\n``` bash\n$ ln -s /etc/uwsgi/apps-available/graphite.ini /etc/uwsgi/apps-enabled\n$ service uwsgi restart\n```\n\nFinally, configure the nginx vhost:\n\n``` nginx\n# /etc/nginx/sites-available/graphite.conf\n\nserver {\n    listen 80;\n\n    location /static/ {\n        alias /opt/graphite/webapp/content/;\n    }\n\n    location / {\n        include uwsgi_params;\n        uwsgi_pass localhost:8080;\n    }\n}\n```\n\nEnable the vhost and restart nginx:\n\n``` bash\n$ ln -s /etc/nginx/sites-available/graphite.conf /etc/nginx/sites-enabled\n$ service nginx restart\n```\n\nAcnowlegments ————\\_\n\nPortions of that manual are based on [Graphite-API deployment manual](https://github.com/brutasse/graphite-api/blob/master/docs/deployment.rst).\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-webapp.html](https://graphite.readthedocs.io/en/latest/config-webapp.html)"
- name: consolidateBy()
  id: functions#graphite.render.functions.consolidateBy
  summary: Takes one metric or a wildcard seriesList and a consolidation function name
  belongs_to: Functions
  description: |-
    consolidateBy(seriesList, consolidationFunc)

    Takes one metric or a wildcard seriesList and a consolidation function name.

    Valid function names are ‘sum’, ‘average’, ‘min’, ‘max’, ‘first’ & ‘last’.

    When a graph is drawn where width of the graph size in pixels is smaller than the number of datapoints to be graphed, Graphite consolidates the values to to prevent line overlap. The consolidateBy() function changes the consolidation function from the default of ‘average’ to one of ‘sum’, ‘max’, ‘min’, ‘first’, or ‘last’. This is especially useful in sales graphs, where fractional values make no sense and a ‘sum’ of consolidated values is appropriate.

    ``` none
    &target=consolidateBy(Sales.widgets.largeBlue, 'sum')
    &target=consolidateBy(Servers.web01.sda1.free_space, 'max')
    ```
- name: constantLine()
  id: functions#graphite.render.functions.constantLine
  summary: Takes a float F
  belongs_to: Functions
  description: |-
    constantLine(value)

    Takes a float F.

    Draws a horizontal line at value F across the graph.

    Example:

    ``` none
    &target=constantLine(123.456)
    ```
- name: countSeries()
  id: functions#graphite.render.functions.countSeries
  summary: Draws a horizontal line representing the number of nodes found in the seriesList
  belongs_to: Functions
  description: |-
    countSeries(\*seriesLists)

    Draws a horizontal line representing the number of nodes found in the seriesList.

    ``` none
    &target=countSeries(carbon.agents.*.*)
    ```
- name: Creating or Modifying a Dashboard
  id: dashboard#creating-or-modifying-a-dashboard
  summary: When you open the Dashboard interface, no dashboard is open
  belongs_to: The Dashboard User Interface
  description: |-
    ## Creating or Modifying a Dashboard

    When you open the Dashboard interface, no dashboard is open. You can either start building a new dashboard, or you can open an existing one (see [Opening a Dashboard](#opening-a-dashboard)) and modify that. If you’re working on a previously-saved dashboard, its name will show at the top of the completer and browser tree panels.

    **Note for Power Users:** Any action that can be performed via the UI, as explained in this section, can also be performed using the Edit Dashboard function (as JSON text). See [Editing, Importing and Exporting via JSON](#editing-importing-and-exporting-via-json).
- name: Cubism.js
  id: client-apis#cubism-js
  summary: Cubism.js is a D3 plugin for visualizing time series data in real time, and can pull data from Graphite
  belongs_to: Client APIs
  description: |-
    ## Cubism.js

    [Cubism.js](http://square.github.io/cubism/) is a D3 plugin for visualizing time series data in real time, and can pull data from Graphite.
- name: cumulative()
  id: functions#graphite.render.functions.cumulative
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    cumulative(seriesList)

    Takes one metric or a wildcard seriesList.

    When a graph is drawn where width of the graph size in pixels is smaller than the number of datapoints to be graphed, Graphite consolidates the values to to prevent line overlap. The cumulative() function changes the consolidation function from the default of ‘average’ to ‘sum’. This is especially useful in sales graphs, where fractional values make no sense and a ‘sum’ of consolidated values is appropriate.

    Alias for [`consolidateBy(series,``'sum')`](#graphite.render.functions.consolidateBy "graphite.render.functions.consolidateBy")

    ``` none
    &target=cumulative(Sales.widgets.largeBlue)
    ```
- name: currentAbove()
  id: functions#graphite.render.functions.currentAbove
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    currentAbove(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics whose value is above N at the end of the time period specified.

    Example:

    ``` none
    &target=currentAbove(server*.instance*.threads.busy,50)
    ```

    Draws the servers with more than 50 busy threads.
- name: currentBelow()
  id: functions#graphite.render.functions.currentBelow
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    currentBelow(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics whose value is below N at the end of the time period specified.

    Example:

    ``` none
    &target=currentBelow(server*.instance*.threads.busy,3)
    ```

    Draws the servers with less than 3 busy threads.
- name: Custom finders
  id: storage-backends#custom-finders
  summary: STORAGE_FINDERS being a list of arbitrary python paths, it is relatively easy to write a custom finder if you want to read data from other places than Whisper and Ceres
  belongs_to: Alternative storage finders
  description: |-
    ## Custom finders

    `STORAGE_FINDERS` being a list of arbitrary python paths, it is relatively easy to write a custom finder if you want to read data from other places than Whisper and Ceres. A finder is a python class with a `find_nodes()` method:

    ``` python
    class CustomFinder(object):
        def find_nodes(self, query):
            # ...
    ```

    `query` is a `FindQuery` object. `find_nodes()` is the entry point when browsing the metrics tree. It must yield leaf or branch nodes matching the query:

    ``` python
    from graphite.node import LeafNode, BranchNode
    from graphite.finders.utils import BaseFinder

    class CustomFinder(BaseFinder):
        def find_nodes(self, query):
            # find some paths matching the query, then yield them
            for path in matches:
                if is_branch(path):
                    yield BranchNode(path)
                if is_leaf(path):
                    yield LeafNode(path, CustomReader(path))
    ```

    `LeafNode` is created with a *reader*, which is the class responsible for fetching the datapoints for the given path. It is a simple class with 2 methods: `fetch()` and `get_intervals()`:

    ``` python
    from graphite.intervals import IntervalSet, Interval
    from graphite.readers.utils import BaseReader

    class CustomReader(BaseReader):
        __slots__ = ('path',)  # __slots__ is recommended to save memory on readers

        def __init__(self, path):
            self.path = path

        def fetch(self, start_time, end_time):
            # fetch data
            time_info = _from_, _to_, _step_
            return time_info, series

        def get_intervals(self):
            return IntervalSet([Interval(start, end)])
    ```

    `fetch()` must return a list of 2 elements: the time info for the data and the datapoints themselves. The time info is a list of 3 items: the start time of the datapoints (in unix time), the end time and the time step (in seconds) between the datapoints.

    The datapoints is a list of points found in the database for the required interval. There must be `(end``-``start)``/``step` points in the dataset even if the database has gaps: gaps can be filled with `None` values.

    `get_intervals()` is a method that hints graphite-web about the time range available for this given metric in the database. It must return an `IntervalSet` of one or more `Interval` objects.
- name: Customizing a Single Metric Element
  id: dashboard#customizing-a-single-metric-element
  summary: To customize a single metric element, you select the element in the metric list, then use the menu items on the Apply Function menu button to apply functions to the metric element
  belongs_to: The Dashboard User Interface
  description: |-
    ### Customizing a Single Metric Element

    To customize a single metric element, you select the element in the metric list, then use the menu items on the *Apply Function* menu button to apply functions to the metric element. Note that each metric element in the list may include multiple metric series, e.g. if the path includes wildcards.

    Note

    All these actions use functions documented on [the functions page](functions#list-of-functions). For further information, read the documentation for the appropriate function on that page. Function names are included in brackets in the list below.

    The functions are grouped in the menu, as follows:

    *Combine*

    Functions that combine a group of metric series (returned by a path containing wildcards) into a single series (and therefore a single line). Includes sum, average, product, minimum, maximum.

    *Transform*

    Functions that transform the values in a metric series, against either the Y-axis or (less commonly) the X-axis. Includes scale, scale to seconds, offset, derivative, integral, time-shift, log.

    *Calculate*

    Functions that calculate a new metric series based on an existing metric series. Includes moving average, percentage, Holt-Winters forecast, ratio and difference (of 2 metrics)

    *Filter*

    Functions that filter metric series from a group. Includes highest current value, current value above limit, most deviant, remove below percentile.

    *Special*

    Functions that control how the metric series are drawn on the graph. Includes line colors/widths/styles, drawing stacked, drawing on the second Y-axis, and setting the legend name either directly or from the path.

    The last menu item is *Remove Outer Call*, which removes the outer-most function on the current metric.
- name: Customizing Graphs
  id: dashboard#customizing-graphs
  summary: To change a graph on the dashboard, click on it
  belongs_to: The Dashboard User Interface
  description: |-
    ## Customizing Graphs

    To change a graph on the dashboard, click on it. This will display a pop-up containing the following sections:

    - A list of all metric elements, i.e. the path and functions for each of the data elements displayed on the graph
    - An *Apply Function* menu button, which allows functions to be applied to the currently-selected item in the metrics list
    - A *Render Operations* menu button, which allows customization of the graph as a whole
    - A *Graph Operations* menu button, providing menu items for miscellaneous actions to take on the graph.

    Note

    The items in the list of metrics can be edited in place. Double-click the item, edit as required, then hit Enter to complete.
- name: Customizing the Whole Graph
  id: dashboard#customizing-the-whole-graph
  summary: The Render Options menu button is used to set options that apply to the whole graph, rather than just the selected metric
  belongs_to: The Dashboard User Interface
  description: |-
    ### Customizing the Whole Graph

    The *Render Options* menu button is used to set options that apply to the whole graph, rather than just the selected metric.

    Note

    Each of the items in this menu matches a graph parameter in the [The Render URL API](render_api). For further information, read the documentation for the appropriate parameter on that page.

    The functions are grouped as follows:

    *Graph Title*

    Unsurprisingly, this sets the title for the graph. See [title](render_api#param-title).

    *Display*

    Provides options for:

    - fonts (see [fontName](render_api#param-fontname), [fontBold](render_api#param-fontbold), [fontItalic](render_api#param-fontitalic), [fontSize](render_api#param-fontsize) and [fgcolor](render_api#param-fgcolor))
    - colors (see [colorList](render_api#param-colorlist), [bgcolor](render_api#param-bgcolor), [majorGridLineColor](render_api#param-majorgridlinecolor), [minorGridLineColor](render_api#param-minorgridlinecolor) and [areaAlpha](render_api#param-areaalpha))
    - legends (see [hideLegend](render_api#param-hidelegend) and [uniqueLegend](render_api#param-uniquelegend))
    - line thickness (see [lineWidth](render_api#param-linewidth))
    - hiding of graph elements (see [graphOnly](render_api#param-graphonly), [hideAxes](render_api#param-hideaxes), [hideYAxis](render_api#param-hideyaxis) and [hideGrid](render_api#param-hidegrid))
    - apply a template (see [template](render_api#param-template)).

    *Line Mode*

    Sets the way lines are rendered, e.g. sloped, staircase, connected, and how the value `None` is rendered. See [lineMode](render_api#param-linemode) and [drawNullAsZero](render_api#param-drawnullaszero).

    *Area Mode*

    Determines whether the area below lines is filled, and whether the lines are stacked. See [areaMode](render_api#param-areamode).

    *X-Axis*

    Allows setting the time format for dates/times on the axis (see [xFormat](render_api#param-xformat)), the timezone for interpretation of timestamps (see [tz](render_api#param-tz)), and the threshold for point consolidation (the closest number of pixels between points before they are consolidated, see [minXStep](render_api#param-minxstep)).

    *Y-Axis*

    Determines how the Y-axis or axes are rendered. This includes:

    - label (see [vtitle](render_api#param-vtitle))
    - minimum/maximum values on the axis (see [yMin](render_api#param-ymin) and [yMax](render_api#param-ymax))
    - the number of minor lines to draw (see [minorY](render_api#param-minory))
    - drawing on a logarithmic scale of the specified base (see [logBase](render_api#param-logbase))
    - step between the Y-axis labels and gridlines (see [yStep](render_api#param-ystep))
    - divisor for the axis (see [yDivisors](render_api#param-ydivisors))
    - unit system (SI, binary, or none - see [yUnitSystem](render_api#param-yunitsystem))
    - side the axis appears (see [yAxisSide](render_api#param-yaxisside)).

    When you have more than one Y-axis (because you selected *Apply Function \| Special \| Draw in second Y axis* for at least one metric series), use the *Dual Y-Axis Options* item on this menu. This provides individual control of both the left and right Y-axes, with the same settings as listed above.
- name: Dashboard Authorization Configuration
  id: config-local-settings#dashboard-authorization-configuration
  summary: These settings control who is allowed to save and delete dashboards
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Dashboard Authorization Configuration

    These settings control who is allowed to save and delete dashboards. By default anyone can perform these actions, but by setting DASHBOARD_REQUIRE_AUTHENTICATION, users must at least be logged in to do so. The other two settings allow further restriction of who is able to perform these actions. Users who are not suitably authorized will still be able to use and change dashboards, but will not be able to save changes or delete dashboards.

    DASHBOARD_REQUIRE_AUTHENTICATION

    Default: False

    If set to True, dashboards can only be saved and deleted by logged in users.

    DASHBOARD_REQUIRE_EDIT_GROUP

    Default: None

    If set to the name of a user group, dashboards can only be saved and deleted by logged-in users who are members of this group. Groups can be set in the Django Admin app, or in LDAP.

    Note that DASHBOARD_REQUIRE_AUTHENTICATION must be set to true - if not, this setting is ignored.

    DASHBOARD_REQUIRE_PERMISSIONS

    Default: False

    If set to True, dashboards can only be saved or deleted by users having the appropriate (change or delete) permission (as set in the Django Admin app). These permissions can be set at the user or group level. Note that Django’s ‘add’ permission is not used.

    Note that DASHBOARD_REQUIRE_AUTHENTICATION must be set to true - if not, this setting is ignored.
- name: dashed()
  id: functions#graphite.render.functions.dashed
  summary: Takes one metric or a wildcard seriesList, followed by a float F
  belongs_to: Functions
  description: |-
    dashed(seriesList, dashLength=5)

    Takes one metric or a wildcard seriesList, followed by a float F.

    Draw the selected metrics with a dotted line with segments of length F If omitted, the default length of the segments is 5.0

    Example:

    ``` none
    &target=dashed(server01.instance01.memory.free,2.5)
    ```
- name: Data Display Formats
  id: render_api#data-display-formats
  summary: Along with rendering an image, the api can also generate SVG with embedded metadata, PDF, or return the raw data in various formats for external graphing, analysis or monitoring
  belongs_to: The Render URL API
  description: |-
    ## Data Display Formats

    Along with rendering an image, the api can also generate [SVG](http://www.w3.org/Graphics/SVG/) with embedded metadata, PDF, or return the raw data in various formats for external graphing, analysis or monitoring.
- name: Data Points
  id: whisper#data-points
  summary: Data points in Whisper are stored on-disk as big-endian double-precision floats
  belongs_to: The Whisper Database
  description: |-
    ## Data Points

    Data points in Whisper are stored on-disk as big-endian double-precision floats. Each value is paired with a timestamp in seconds since the UNIX Epoch (01-01-1970). The data value is parsed by the Python [float()](http://docs.python.org/library/functions.html#float) function and as such behaves in the same way for special strings such as `'inf'`. Maximum and minimum values are determined by the Python interpreter’s allowable range for float values which can be found by executing:

    ``` default
    python -c 'import sys; print sys.float_info'
    ```
- name: Database Configuration
  id: config-local-settings#database-configuration
  summary: The following configures the Django database settings
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Database Configuration

    The following configures the Django database settings. Graphite uses the database for storing user profiles, dashboards, and for the Events functionality. Graphite uses an SQLite database file located at `STORAGE_DIR/graphite.db` by default. If running multiple Graphite-web instances, a database such as PostgreSQL or MySQL is required so that all instances may share the same data source.

    Note

    As of Django 1.2, the database configuration is specified by the DATABASES dictionary instead of the old `DATABASE_*` format. Users must use the new specification to have a working database.

    See the [Django documentation](https://docs.djangoproject.com/en/dev/ref/settings/#databases) for full documentation of the DATABASES setting.

    Note

    Remember, setting up a new database requires running `PYTHONPATH=$GRAPHITE_ROOT/webapp``django-admin.py``migrate``--settings=graphite.settings``--run-syncdb` to create the initial schema.

    Note

    If you are using a custom database backend (other than SQLite) you must first create a $GRAPHITE_ROOT/webapp/graphite/local_settings.py file that overrides the database related settings from settings.py. Use $GRAPHITE_ROOT/webapp/graphite/local_settings.py.example as a template.

    If you are experiencing problems, uncomment the following line in /opt/graphite/webapp/graphite/local_settings.py:

    ``` none
    # DEBUG = True
    ```

    and review your webapp logs. If you’re using the default graphite-example-vhost.conf, your logs will be found in /opt/graphite/storage/log/webapp/.

    If you’re using the default SQLite database, your webserver will need permissions to read and write to the database file. So, for example, if your webapp is running in Apache as the ‘nobody’ user, you will need to fix the permissions like this:

    ``` none
    sudo chown nobody:nobody /opt/graphite/storage/graphite.db
    ```
- name: Database Format
  id: whisper#database-format
  summary: © 2008–2012 Chris Davis © 2011–2016 The Graphite Project Licensed under the Apache License, Version 2.0
  belongs_to: The Whisper Database
  description: "## Database Format\n\n|             |               |                         |                                                        |                 |\n|-------------|---------------|-------------------------|--------------------------------------------------------|-----------------|\n| WhisperFile | *Header,Data* |                         |                                                        |                 |\n|             | Header        | *Metadata,ArchiveInfo+* |                                                        |                 |\n|             |               | Metadata                | aggregationType,maxRetention,xFilesFactor,archiveCount |                 |\n|             |               | ArchiveInfo             | Offset,SecondsPerPoint,Points                          |                 |\n|             | Data          | *Archive+*              |                                                        |                 |\n|             |               | Archive                 | *Point+*                                               |                 |\n|             |               |                         | Point                                                  | timestamp,value |\n\nData types in Python’s [struct format](http://docs.python.org/library/struct.html#format-strings):\n\n|             |               |\n|-------------|---------------|\n| Metadata    | ` ``!2LfL`` ` |\n| ArchiveInfo | ` ``!3L`` `   |\n| Point       | ` ``!Ld`` `   |\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/whisper.html](https://graphite.readthedocs.io/en/latest/whisper.html)"
- name: Database Format
  id: ceres#database-format
  summary: © 2008–2012 Chris Davis © 2011–2016 The Graphite Project Licensed under the Apache License, Version 2.0
  belongs_to: The Ceres Database
  description: "## Database Format\n\n|            |        |          |\n|------------|--------|----------|\n| CeresSlice | *Data* |          |\n|            | Data   | *Point+* |\n\nData types in Python’s [struct format](http://docs.python.org/library/struct.html#format-strings):\n\n|       |            |\n|-------|------------|\n| Point | ` ``!d`` ` |\n\nMetadata for Ceres is stored in [JSON format](https://docs.python.org/3/library/json.html):\n\n> {“retentions”: \\[\\[30, 1440\\]\\], “timeStep”: 30, “xFilesFactor”: 0.5, “aggregationMethod”: “average”}\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/ceres.html](https://graphite.readthedocs.io/en/latest/ceres.html)"
- name: Database Storage
  id: events#database-storage
  summary: As Whisper was designed to hold simple time-series data (metric key, value, and timestamp), it’s altogether unsuitable for storing rich metric data such as events
  belongs_to: Graphite Events
  description: |-
    ## Database Storage

    As Whisper was designed to hold simple time-series data (metric key, value, and timestamp), it’s altogether unsuitable for storing rich metric data such as events. Many users continue to store simple event-type data (e.g. releases, state changes, etc) in Whisper by encoding its meaning within the metric namespace and rendering them as a vertical line with Graphite’s [drawAsInfinite](functions#graphite.render.functions.drawAsInfinite) function.

    However, taking advantage of this pattern typically requires the use of wildcards across a significant number of these singleton metric files and directories, which can cause a significant performance hit on the server and result in a poor experience for users. To accommodate this more sophisticated use case, Graphite’s webapp database was extended to support this new metric type.

    Note

    Events require Graphite webapp version 0.9.9 or newer.
- name: Database Storage
  id: tags#database-storage
  summary: As Whisper and other storage backends are designed to hold simple time-series data (metric key, value, and timestamp), Graphite stores tag information in a separate tag database (TagDB)
  belongs_to: Graphite Tag Support
  description: |-
    ## Database Storage

    As Whisper and other storage backends are designed to hold simple time-series data (metric key, value, and timestamp), Graphite stores tag information in a separate tag database (TagDB). The TagDB is a pluggable store, by default it uses the Graphite SQLite, MySQL or PostgreSQL database, but it can also be configured to use an external Redis server or a custom plugin.

    Note

    Tag support requires Graphite webapp & carbon version 1.1.1 or newer.
- name: Default Installation Layout
  id: install#default-installation-layout
  summary: null
  belongs_to: Installing Graphite
  description: |-
    ## Default Installation Layout

    Graphite defaults to an installation layout that puts the entire install in its own directory: `/opt/graphite`
- name: delay()
  id: functions#graphite.render.functions.delay
  summary: This shifts all samples later by an integer number of steps
  belongs_to: Functions
  description: |-
    delay(seriesList, steps)

    This shifts all samples later by an integer number of steps. This can be used for custom derivative calculations, among other things. Note: this will pad the early end of the data with None for every step shifted.

    This complements other time-displacement functions such as timeShift and timeSlice, in that this function is indifferent about the step intervals being shifted.

    Example:

    ``` none
    &target=divideSeries(server.FreeSpace,delay(server.FreeSpace,1))
    ```

    This computes the change in server free space as a percentage of the previous free space.
- name: Deleting a Dashboard
  id: dashboard#deleting-a-dashboard
  summary: To delete a dashboard, open the Finder (using the Dashboard | Finder menu item), select the dashboard to delete in the list, and click Delete
  belongs_to: The Dashboard User Interface
  description: |-
    ### Deleting a Dashboard

    To delete a dashboard, open the Finder (using the *Dashboard \| Finder* menu item), select the dashboard to delete in the list, and click *Delete*. Note that you may need to be logged in as a user with appropriate permissions to do this, depending on the configuration of Graphite.
- name: Deleting a Graph
  id: dashboard#deleting-a-graph
  summary: When you hover the mouse over a graph, a red cross icon appears at the top right
  belongs_to: The Dashboard User Interface
  description: |-
    ### Deleting a Graph

    When you hover the mouse over a graph, a red cross icon appears at the top right. Click this to delete the graph from the dashboard.
- name: Dependencies
  id: install#dependencies
  summary: Graphite renders graphs using the Cairo graphics library
  belongs_to: Installing Graphite
  description: |-
    ## Dependencies

    Graphite renders graphs using the Cairo graphics library. This adds dependencies on several graphics-related libraries not typically found on a server. If you’re installing from source you can use the `check-dependencies.py` script to see if the dependencies have been met or not.

    Basic Graphite requirements:

    - a UNIX-like Operating System
    - Python 2.7 or greater (including experimental Python3 support)
    - [cairocffi](https://pythonhosted.org/cairocffi/)
    - [Django](http://www.djangoproject.com/) 1.8 - 1.11 (for Python3 - 1.11 only)
    - [django-tagging](http://django-tagging.readthedocs.io/) 0.4.6 (not django-taggit yet)
    - [pytz](https://pypi.python.org/pypi/pytz/)
    - [scandir](https://pypi.python.org/pypi/scandir)
    - [fontconfig](http://www.freedesktop.org/wiki/Software/fontconfig/) and at least one font package (a system package usually)
    - A WSGI server and web server. Popular choices are:
      - [Apache](https://projects.apache.org/project.html?httpd-http_server) with [mod_wsgi](https://modwsgi.readthedocs.io/)
      - [gunicorn](http://gunicorn.org/) with [nginx](http://nginx.org/)
      - [uWSGI](http://uwsgi-docs.readthedocs.io/) with [nginx](http://nginx.org/)

    Additionally, the Graphite webapp and Carbon require the Whisper database library which is part of the Graphite project.

    There are also several other dependencies required for additional features:

    - Render caching: [memcached](http://memcached.org/) and [python-memcache](https://www.tummy.com/software/python-memcached/)
    - LDAP authentication: [python-ldap](https://www.python-ldap.org/) (for LDAP authentication support in the webapp)
    - AMQP support: [txamqp](https://launchpad.net/txamqp/) (version 0.8 is required)
    - RRD support: [python-rrdtool](http://oss.oetiker.ch/rrdtool/prog/rrdpython.en.html)
    - Dependent modules for additional database support (MySQL, PostgreSQL, etc). See [Django database install](https://docs.djangoproject.com/en/dev/topics/install/#get-your-database-running) instructions and the [Django database](https://docs.djangoproject.com/en/dev/ref/databases/) documentation for details

    See also

    On some systems it is necessary to install fonts for Cairo to use. If the webapp is running but all graphs return as broken images, this may be why.

    - [https://answers.launchpad.net/graphite/+question/38833](https://answers.launchpad.net/graphite/+question/38833)
    - [https://answers.launchpad.net/graphite/+question/133390](https://answers.launchpad.net/graphite/+question/133390)
    - [https://answers.launchpad.net/graphite/+question/127623](https://answers.launchpad.net/graphite/+question/127623)
- name: derivative()
  id: functions#graphite.render.functions.derivative
  summary: This is the opposite of the integral function
  belongs_to: Functions
  description: |-
    derivative(seriesList)

    This is the opposite of the integral function. This is useful for taking a running total metric and calculating the delta between subsequent data points.

    This function does not normalize for periods of time, as a true derivative would. Instead see the perSecond() function to calculate a rate of change over time.

    Example:

    ``` none
    &target=derivative(company.server.application01.ifconfig.TXPackets)
    ```

    Each time you run ifconfig, the RX and TXPackets are higher (assuming there is network traffic.) By applying the derivative function, you can get an idea of the packets per minute sent or received, even though you’re only recording the total.
- name: Differences Between Whisper and RRD
  id: whisper#differences-between-whisper-and-rrd
  summary: This means that there is no way to back-fill data in an RRD series
  belongs_to: The Whisper Database
  description: |-
    ## Differences Between Whisper and RRD

    *RRD can not take updates to a time-slot prior to its most recent update*

    This means that there is no way to back-fill data in an RRD series. Whisper does not have this limitation, and this makes importing historical data into Graphite much more simple and easy

    *RRD was not designed with irregular updates in mind*

    In many cases (depending on configuration) if an update is made to an RRD series but is not followed up by another update soon, the original update will be lost. This makes it less suitable for recording data such as operational metrics (e.g. code pushes)

    *Whisper requires that metric updates occur at the same interval as the finest resolution storage archive*

    This pushes the onus of aggregating values to fit into the finest precision archive to the user rather than the database. It also means that updates are written immediately into the finest precision archive rather than being staged first for aggregation and written later (during a subsequent write operation) as they are in RRD.
- name: diffSeries()
  id: functions#graphite.render.functions.diffSeries
  summary: Subtracts series 2 through n from series 1
  belongs_to: Functions
  description: |-
    diffSeries(\*seriesLists)

    Subtracts series 2 through n from series 1.

    Example:

    ``` none
    &target=diffSeries(service.connections.total,service.connections.failed)
    ```

    To diff a series and a constant, one should use offset instead of (or in addition to) diffSeries

    Example:

    ``` none
    &target=offset(service.connections.total,-5)

    &target=offset(diffSeries(service.connections.total,service.connections.failed),-4)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `diff`.
- name: Disk Space Efficiency
  id: whisper#disk-space-efficiency
  summary: Rather than a timestamp being inferred from its position in the archive, timestamps are stored with each point
  belongs_to: The Whisper Database
  description: |-
    ## Disk Space Efficiency

    Whisper is somewhat inefficient in its usage of disk space because of certain design choices:

    *Each data point is stored with its timestamp*

    Rather than a timestamp being inferred from its position in the archive, timestamps are stored with each point. The timestamps are used during data retrieval to check the validity of the data point. If a timestamp does not match the expected value for its position relative to the beginning of the requested series, it is known to be out of date and a null value is returned

    *Archives overlap time periods*

    During the write of a data point, Whisper stores the same data in all archives at once (see [Multi-Archive Storage and Retrieval Behavior](#multi-archive-storage-and-retrieval-behavior)). Implied by this behavior is that all archives store from now until each of their retention times. Because of this, lower-resolution archives should be configured to significantly lower resolution and higher retentions than their higher-resolution counterparts so as to reduce the overlap.

    *All time-slots within an archive take up space whether or not a value is stored*

    While Whisper allows for reliable storage of irregular updates, it is most space efficient when data points are stored at every update interval. This behavior is a consequence of the fixed-size design of the database and allows the reading and writing of series data to be performed in a single contiguous disk operation (for each archive in a database).
- name: divideSeries()
  id: functions#graphite.render.functions.divideSeries
  summary: Takes a dividend metric and a divisor metric and draws the division result
  belongs_to: Functions
  description: |-
    divideSeries(dividendSeriesList, divisorSeries)

    Takes a dividend metric and a divisor metric and draws the division result. A constant may *not* be passed. To divide by a constant, use the scale() function (which is essentially a multiplication operation) and use the inverse of the dividend. (Division by 8 = multiplication by 1/8 or 0.125)

    Example:

    ``` none
    &target=divideSeries(Series.dividends,Series.divisors)
    ```
- name: divideSeriesLists()
  id: functions#graphite.render.functions.divideSeriesLists
  summary: Iterates over a two lists and divides list1[0] by list2[0], list1[1] by list2[1] and so on
  belongs_to: Functions
  description: |-
    divideSeriesLists(dividendSeriesList, divisorSeriesList)

    Iterates over a two lists and divides list1\[0\] by list2\[0\], list1\[1\] by list2\[1\] and so on. The lists need to be the same length
- name: Docker
  id: install#docker
  summary: Check docker repo for details
  belongs_to: Installing Graphite
  description: |-
    ## Docker

    Try Graphite in Docker and have it running in seconds:

    ``` none
    docker run -d\
     --name graphite\
     --restart=always\
     -p 80:80\
     -p 2003-2004:2003-2004\
     -p 2023-2024:2023-2024\
     -p 8125:8125/udp\
     -p 8126:8126\
     graphiteapp/graphite-statsd
    ```

    Check [docker repo](https://github.com/graphite-project/docker-graphite-statsd) for details.

    This is portable, fast and easy to use. Or use instructions below for installation.
- name: Does Graphite use RRDtool?
  id: faq#does-graphite-use-rrdtool
  summary: No, not since Graphite was first written in 2006 at least
  belongs_to: FAQ
  description: |-
    ## Does Graphite use RRDtool?

    No, not since Graphite was first written in 2006 at least. Graphite has its own specialized database library called [whisper](whisper), which is very similar in design to RRD, but has a subtle yet fundamentally important difference that Graphite requires. There are two reasons whisper was created. The first reason is that RRD is designed under the assumption that data will always be inserted into the database on a regular basis, and this assumption causes RRD behave undesirably when given irregularly occurring data. Graphite was built to facilitate visualization of various application metrics that do not always occur regularly, like when an uncommon request is handled and the latency is measured and sent to Graphite. Using RRD, the data gets put into a temporary area inside the database where it is not accessible until the current time interval has passed *and* another value is inserted into the database for the following interval. If that does not happen within an allotted period of time, the original data point will get overwritten and is lost. Now for some metrics, the lack of a value can be correctly interpreted as a value of zero, however this is not the case for metrics like latency because a zero indicates that work was done in zero time, which is different than saying no work was done. Assuming a zero value for latency also screws up analysis like calculating the average latency, etc.

    The second reason whisper was written is performance. RRDtool is very fast; in fact it is much faster than whisper. But the problem with RRD (at the time whisper was written) was that RRD only allowed you to insert a single value into a database at a time, while whisper was written to allow the insertion of multiple data points at once, compacting them into a single write operation. This improves performance drastically under high load because Graphite operates on many many files, and with such small operations being done (write a few bytes here, a few over there, etc) the bottleneck is caused by the *number of I/O operations*. Consider the scenario where Graphite is receiving 100,000 distinct metric values each minute; in order to sustain that load Graphite must be able to write that many data points to disk each minute. But assume that your underlying storage can only handle 20,000 I/O operations per minute. With RRD (at the time whisper was written), there was no chance of keeping up. But with whisper, we can keep caching the incoming data until we accumulate say 10 minutes worth of data for a given metric, then instead of doing 10 I/O operations to write those 10 data points, whisper can do it in one operation. The reason I have kept mentioning “at the time whisper was written” is that RRD now supports this behavior. However Graphite will continue to use whisper as long as the first issue still exists.
- name: drawAsInfinite()
  id: functions#graphite.render.functions.drawAsInfinite
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    drawAsInfinite(seriesList)

    Takes one metric or a wildcard seriesList. If the value is zero, draw the line at 0. If the value is above zero, draw the line at infinity. If the value is null or less than zero, do not draw the line.

    Useful for displaying on/off metrics, such as exit codes. (0 = success, anything else = failure.)

    Example:

    ``` none
    drawAsInfinite(Testing.script.exitCode)
    ```
- name: drawNullAsZero
  id: render_api#drawnullaszero
  summary: Converts any None (null) values in the displayed metrics to zero at render time
  belongs_to: The Render URL API
  description: |-
    ### drawNullAsZero

    *Default: false*

    Converts any None (null) values in the displayed metrics to zero at render time.
- name: Editing, Importing and Exporting via JSON
  id: dashboard#editing-importing-and-exporting-via-json
  summary: The Dashboard | Edit Dashboard menu item shows a JSON (JavaScript Object Notation) representation of the current dashboard and all its graphs in an editor dialog
  belongs_to: The Dashboard User Interface
  description: |-
    ### Editing, Importing and Exporting via JSON

    The *Dashboard \| Edit Dashboard* menu item shows a JSON (JavaScript Object Notation) representation of the current dashboard and all its graphs in an editor dialog.

    If you’re a power user, you can edit the dashboard configuration directly. When you click the *Update* button, the changes are applied to the dashboard on screen only. This function also provides a convenient mechanism for importing and exporting dashboards, for instance to promote dashboards from development to production systems.

    Note

    The Update button does not save your changes - you’ll need to use *Save* or *Save As* to do this.
- name: Email Configuration
  id: config-local-settings#email-configuration
  summary: These settings configure Django’s email functionality which is used for emailing rendered graphs
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Email Configuration

    These settings configure Django’s email functionality which is used for emailing rendered graphs. See the [Django documentation](https://docs.djangoproject.com/en/dev/topics/email/) for further detail on these settings.

    EMAIL_BACKEND

    Default: django.core.mail.backends.smtp.EmailBackend Set to `django.core.mail.backends.dummy.EmailBackend` to drop emails on the floor and effectively disable email features.

    EMAIL_HOST

    Default: localhost

    EMAIL_PORT

    Default: 25

    EMAIL_HOST_USER

    Default: ‘’

    EMAIL_HOST_PASSWORD

    Default: ‘’

    EMAIL_USE_TLS

    Default: False
- name: events()
  id: functions#graphite.render.functions.events
  summary: Returns the number of events at this point in time
  belongs_to: Functions
  description: |-
    events(\*tags)

    Returns the number of events at this point in time. Usable with drawAsInfinite.

    Example:

    ``` none
    &target=events("tag-one", "tag-two")
    &target=events("*")
    ```

    Returns all events tagged as “tag-one” and “tag-two” and the second one returns all events.
- name: exclude()
  id: functions#graphite.render.functions.exclude
  summary: Takes a metric or a wildcard seriesList, followed by a regular expression in double quotes
  belongs_to: Functions
  description: |-
    exclude(seriesList, pattern)

    Takes a metric or a wildcard seriesList, followed by a regular expression in double quotes. Excludes metrics that match the regular expression.

    Example:

    ``` none
    &target=exclude(servers*.instance*.threads.busy,"server02")
    ```
- name: Existing tools and APIs
  id: feeding-carbon#existing-tools-and-apis
  summary: null
  belongs_to: Feeding In Your Data
  description: |-
    ## Existing tools and APIs

    - [client daemons and tools](tools)
    - [client APIs](client-apis)

    &nbsp;
- name: Exploring Tags
  id: tags#exploring-tags
  summary: You can use the HTTP api to get lists of defined tags, values for each tag, and to find series using the same logic as the seriesByTag function
  belongs_to: Graphite Tag Support
  description: |-
    ## Exploring Tags

    You can use the HTTP api to get lists of defined tags, values for each tag, and to find series using the same logic as the [seriesByTag](functions#graphite.render.functions.seriesByTag) function.

    To get a list of defined tags:

    ``` none
    $ curl -s "http://graphite/tags?pretty=1"

    [
      {
        "tag": "datacenter"
      },
      {
        "tag": "name"
      },
      {
        "tag": "rack"
      },
      {
        "tag": "server"
      }
    ]
    ```

    You can filter the returned list by providing a regular expression in the filter parameter:

    ``` none
    $ curl -s "http://graphite/tags?pretty=1&filter=data"

    [
      {
        "tag": "datacenter"
      }
    ]
    ```

    To get a list of values for a specific tag:

    ``` none
    $ curl -s "http://graphite/tags/datacenter?pretty=1"

    {
      "tag": "datacenter",
      "values": [
        {
          "count": 2,
          "value": "dc1"
        },
        {
          "count": 2,
          "value": "dc2"
        }
      ]
    }
    ```

    You can filter the returned list of values using the filter parameter:

    ``` none
    $ curl -s "http://graphite/tags/datacenter?pretty=1&filter=dc1"

    {
      "tag": "datacenter",
      "values": [
        {
          "count": 2,
          "value": "dc1"
        }
      ]
    }
    ```

    Finally, to search for series matching a set of tag expressions:

    ``` none
    $ curl -s "http://graphite/tags/findSeries?pretty=1&expr=datacenter=dc1&expr=server=web01"

    [
      "disk.used;datacenter=dc1;rack=a1;server=web01"
    ]
    ```
- name: exponentialMovingAverage()
  id: functions#graphite.render.functions.exponentialMovingAverage
  summary: The first period EMA uses a simple moving average for its value
  belongs_to: Functions
  description: |-
    exponentialMovingAverage(seriesList, windowSize)

    Takes a series of values and a window size and produces an exponential moving average utilizing the following formula:

    ``` none
    ema(current) = constant * (Current Value) + (1 - constant) * ema(previous)
    ```

    The Constant is calculated as:

    ``` none
    constant = 2 / (windowSize + 1)
    ```

    The first period EMA uses a simple moving average for its value.

    Example:

    ``` none
    &target=exponentialMovingAverage(*.transactions.count, 10)
    &target=exponentialMovingAverage(*.transactions.count, '-10s')
    ```
- name: fallbackSeries()
  id: functions#graphite.render.functions.fallbackSeries
  summary: Takes a wildcard seriesList, and a second fallback metric
  belongs_to: Functions
  description: |-
    fallbackSeries(seriesList, fallback)

    Takes a wildcard seriesList, and a second fallback metric. If the wildcard does not match any series, draws the fallback metric.

    Example:

    ``` none
    &target=fallbackSeries(server*.requests_per_second, constantLine(0))
    ```

    Draws a 0 line when server metric does not exist.
- name: FAQ
  id: faq
  summary: Graphite is a highly scalable real-time graphing system
  description: "# FAQ\n\n## What is Graphite?\n\nGraphite is a highly scalable real-time graphing system. As a user, you write an application that collects numeric time-series data that you are interested in graphing, and send it to Graphite’s processing backend, [carbon](carbon-daemons), which stores the data in Graphite’s specialized database. The data can then be visualized through graphite’s web interfaces.\n\n## Who should use Graphite?\n\nAnybody who would want to track values of anything over time. If you have a number that could potentially change over time, and you might want to represent the value over time on a graph, then Graphite can probably meet your needs.\n\nSpecifically, Graphite is designed to handle numeric time-series data. For example, Graphite would be good at graphing stock prices because they are numbers that change over time. Whether it’s a few data points, or dozens of performance metrics from thousands of servers, then Graphite is for you. As a bonus, you don’t necessarily know the names of those things in advance (who wants to maintain such huge configuration?); you simply send a metric name, a timestamp, and a value, and Graphite takes care of the rest!\n\n## How scalable is Graphite?\n\nFrom a CPU perspective, Graphite scales horizontally on both the frontend and the backend, meaning you can simply add more machines to the mix to get more throughput. It is also fault tolerant in the sense that losing a backend machine will cause a minimal amount of data loss (whatever that machine had cached in memory) and will not disrupt the system if you have sufficient capacity remaining to handle the load.\n\nFrom an I/O perspective, under load Graphite performs lots of tiny I/O operations on lots of different files very rapidly. This is because each distinct metric sent to Graphite is stored in its own database file, similar to how many tools (drraw, Cacti, Centreon, etc) built on top of RRD work. In fact, Graphite originally did use RRD for storage until fundamental limitations arose that required a new storage engine.\n\nHigh volume (a few thousand distinct metrics updating every minute) pretty much requires a good RAID array and/or SSDs. Graphite’s backend caches incoming data if the disks cannot keep up with the large number of small write operations that occur (each data point is only a few bytes, but most standard disks cannot do more than a few thousand I/O operations per second, even if they are tiny). When this occurs, Graphite’s database engine, whisper, allows carbon to write multiple data points at once, thus increasing overall throughput only at the cost of keeping excess data cached in memory until it can be written.\n\nGraphite also supports [alternative storage backends](storage-backends) which can greatly change these characteristics.\n\n## How real-time are the graphs?\n\nVery. Even under heavy load, where the number of metrics coming in each time interval is much greater than the rate at which your storage system can perform I/O operations and lots of data points are being cached in the storage pipeline (see previous question for explanation), Graphite still draws real-time graphs. The trick is that when the Graphite webapp receives a request to draw a graph, it simultaneously retrieves data off the disk as well as from the pre-storage cache (which may be distributed if you have multiple backend servers) and combines the two sources of data to create a real-time graph.\n\n## Who already uses Graphite?\n\nGraphite was internally developed by [Orbitz](http://www.orbitz.com/) where it is used to visualize a variety of operations-critical data including application metrics, database metrics, sales, etc. At the time of this writing, the production system at Orbitz can handle approximately 160,000 distinct metrics per minute running on two niagra-2 Sun servers on a very fast SAN.\n\n## What is Graphite written in?\n\nPython2. The Graphite webapp is built on the [Django](http://www.djangoproject.com/) web framework and uses the ExtJS javascript GUI toolkit. The graph rendering is done using the Cairo graphics library. The backend and database are written in pure Python.\n\n## Who writes and maintains Graphite?\n\nGraphite was initially developed by [Chris Davis](mailto:chrismd%40gmail.com) at [Orbitz](http://www.orbitz.com/). Orbitz has long been a part of the open source community and has published several other internally developed products.\n\nGraphite is currently developed by a team of volunteers under the [Graphite-Project](https://github.com/graphite-project/) GitHub Organization.\n\n## What license is Graphite released under?\n\nThe [Apache 2.0 License](http://www.apache.org/licenses/LICENSE-2.0.html).\n\n## Does Graphite use RRDtool?\n\nNo, not since Graphite was first written in 2006 at least. Graphite has its own specialized database library called [whisper](whisper), which is very similar in design to RRD, but has a subtle yet fundamentally important difference that Graphite requires. There are two reasons whisper was created. The first reason is that RRD is designed under the assumption that data will always be inserted into the database on a regular basis, and this assumption causes RRD behave undesirably when given irregularly occurring data. Graphite was built to facilitate visualization of various application metrics that do not always occur regularly, like when an uncommon request is handled and the latency is measured and sent to Graphite. Using RRD, the data gets put into a temporary area inside the database where it is not accessible until the current time interval has passed *and* another value is inserted into the database for the following interval. If that does not happen within an allotted period of time, the original data point will get overwritten and is lost. Now for some metrics, the lack of a value can be correctly interpreted as a value of zero, however this is not the case for metrics like latency because a zero indicates that work was done in zero time, which is different than saying no work was done. Assuming a zero value for latency also screws up analysis like calculating the average latency, etc.\n\nThe second reason whisper was written is performance. RRDtool is very fast; in fact it is much faster than whisper. But the problem with RRD (at the time whisper was written) was that RRD only allowed you to insert a single value into a database at a time, while whisper was written to allow the insertion of multiple data points at once, compacting them into a single write operation. This improves performance drastically under high load because Graphite operates on many many files, and with such small operations being done (write a few bytes here, a few over there, etc) the bottleneck is caused by the *number of I/O operations*. Consider the scenario where Graphite is receiving 100,000 distinct metric values each minute; in order to sustain that load Graphite must be able to write that many data points to disk each minute. But assume that your underlying storage can only handle 20,000 I/O operations per minute. With RRD (at the time whisper was written), there was no chance of keeping up. But with whisper, we can keep caching the incoming data until we accumulate say 10 minutes worth of data for a given metric, then instead of doing 10 I/O operations to write those 10 data points, whisper can do it in one operation. The reason I have kept mentioning “at the time whisper was written” is that RRD now supports this behavior. However Graphite will continue to use whisper as long as the first issue still exists.\n\n## How do I report problems or request features for Graphite?\n\nPlease post any feature requests or bug reports to the [GitHub Issues](https://github.com/graphite-project/graphite-web/issues) page.\n\n## Is this Graphite related to the SIL font rendering graphite?\n\nNo. SIL Graphite is completely unrelated to this Graphite.\n\n## Is this Graphite related to the sourceforge project called graphite?\n\nNo. The sourceforge project called graphite is completely unrelated to this Graphite.\n\n## Is there a diagram of Graphite’s architecture?\n\nThere sure is! Here it is:\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/faq.html](https://graphite.readthedocs.io/en/latest/faq.html)"
- name: Feeding In Your Data
  id: feeding-carbon
  summary: Getting your data into Graphite is very flexible
  description: "# Feeding In Your Data\n\nGetting your data into Graphite is very flexible. There are three main methods for sending data to Graphite: Plaintext, Pickle, and AMQP.\n\nIt’s worth noting that data sent to Graphite is actually sent to the [Carbon and Carbon-Relay](carbon-daemons), which then manage the data. The Graphite web interface reads this data back out, either from cache or straight off disk.\n\nChoosing the right transfer method for you is dependent on how you want to build your application or script to send data:\n\n- There are some tools and APIs which can help you get your data into Carbon.\n- For a singular script, or for test data, the plaintext protocol is the most straightforward method.\n- For sending large amounts of data, you’ll want to batch this data up and send it to Carbon’s pickle receiver.\n- Finally, Carbon can listen to a message bus, via AMQP.\n\n## Existing tools and APIs\n\n- [client daemons and tools](tools)\n- [client APIs](client-apis)\n\n## The plaintext protocol\n\nThe plaintext protocol is the most straightforward protocol supported by Carbon.\n\nThe data sent must be in the following format: `<metric`` ``path>`` ``<metric`` ``value>`` ``<metric`` ``timestamp>`. Carbon will then help translate this line of text into a metric that the web interface and Whisper understand.\n\nOn Unix, the `nc` program (`netcat`) can be used to create a socket and send data to Carbon (by default, ‘plaintext’ runs on port 2003):\n\n> ``` none\n> PORT=2003\n> SERVER=graphite.your.org\n> echo \"local.random.diceroll 4 `date +%s`\" | nc ${SERVER} ${PORT}\n> ```\n>\n> As many `netcat` implementations exist, a parameter may be needed to instruct `nc` to close the socket once data is sent. Such param will usually be `-q0`, `-c` or `-N`. Refer to your `nc` implementation man page to determine it.\n>\n> Note that if your Carbon instance is listening using the UDP protocol, you also need the `-u` parameter.\n\n## The pickle protocol\n\nThe pickle protocol is a much more efficient take on the plaintext protocol, and supports sending batches of metrics to Carbon in one go.\n\nThe general idea is that the pickled data forms a list of multi-level tuples:\n\n``` none\n[(path, (timestamp, value)), ...]\n```\n\nOnce you’ve formed a list of sufficient size (don’t go too big!), and pickled it (if your client is running a more recent version of python than your server, you may need to specify the protocol) send the data over a socket to Carbon’s pickle receiver (by default, port 2004). You’ll need to pack your pickled data into a packet containing a simple header:\n\n``` python\npayload = pickle.dumps(listOfMetricTuples, protocol=2)\nheader = struct.pack(\"!L\", len(payload))\nmessage = header + payload\n```\n\nYou would then send the `message` object through a network socket.\n\n## Using AMQP\n\nWhen AMQP_METRIC_NAME_IN_BODY is set to True in your carbon.conf file, the data should be of the same format as the plaintext protocol, e.g. echo “local.random.diceroll 4 date +%s”. When AMQP_METRIC_NAME_IN_BODY is set to False, you should omit ‘local.random.diceroll’.\n\n# Getting Your Data Into Graphite\n\n## The Basic Idea\n\nGraphite is useful if you have some numeric values that change over time and you want to graph them. Basically you write a program to collect these numeric values which then sends them to graphite’s backend, Carbon.\n\n## Step 1 - Plan a Naming Hierarchy\n\nEvery series stored in Graphite has a unique identifier, which is composed of a metric name and optionally a set of tags.\n\nIn a traditional hierarchy, website.orbitz.bookings.air or something like that would represent the number of air bookings on orbitz. Before producing your data you need to decide what your naming scheme will be. In a path such as “foo.bar.baz”, each thing surrounded by dots is called a path component. So “foo” is a path component, as well as “bar”, etc.\n\nEach path component should have a clear and well-defined purpose. Volatile path components should be kept as deep into the hierarchy as possible.\n\nMatt \\_Aimonetti has a reasonably sane [post describing the organization of your namespace](http://matt.aimonetti.net/posts/2013/06/26/practical-guide-to-graphite-monitoring/).\n\nThe disadvantage of a purely hierarchical system is that it is very difficult to make changes to the hierarchy, since anything querying Graphite will also need to be updated. Additionally, there is no built-in description of the meaning of any particular element in the hierarchy.\n\nTo address these issues, Graphite also supports using tags to describe your metrics, which makes it much simpler to design the initial structure and to evolve it over time. A tagged series is made up of a name and a set of tags, like “disk.used;datacenter=dc1;rack=a1;server=web01”. In that example, the series name is “disk.used” and the tags are “datacenter” = “dc1”, “rack” = “a1”, and “server” = “web01”. When series are named this way they can be selected using the [seriesByTag](functions#graphite.render.functions.seriesByTag) function as described in [Graphite Tag Support](tags).\n\nWhen using a tagged naming scheme it is much easier to add or alter individual tags as needed. It is important however to be aware that changing the number of tags reported for a given metric or the value of a tag will create a new database file on disk, so tags should not be used for data that changes over the lifetime of a particular metric.\n\n## Step 2 - Configure your Data Retention\n\nGraphite is built on fixed-size databases (see [Whisper.](whisper)) so we have to configure in advance how much data we intend to store and at what level of precision. For instance you could store your data with 1-minute precision (meaning you will have one data point for each minute) for say 2 hours. Additionally you could store your data with 10-minute precision for 2 weeks, etc. The idea is that the storage cost is determined by the number of data points you want to store, the less fine your precision, the more time you can cover with fewer points. To determine the best retention configuration, you must answer all of the following questions.\n\n1.  How often can you produce your data?\n2.  What is the finest precision you will require?\n3.  How far back will you need to look at that level of precision?\n4.  What is the coarsest precision you can use?\n5.  How far back would you ever need to see data? (yes it has to be finite, and determined ahead of time)\n\nOnce you have picked your naming scheme and answered all of the retention questions, you need to create a schema by creating/editing the `/opt/graphite/conf/storage-schemas.conf` file.\n\nThe format of the schemas file is easiest to demonstrate with an example. Let’s say we’ve written a script to collect system load data from various servers, the naming scheme will be like so:\n\n`servers.HOSTNAME.METRIC`\n\nWhere HOSTNAME will be the server’s hostname and METRIC will be something like cpu_load, mem_usage, open_files, etc. Also let’s say we want to store this data with minutely precision for 30 days, then at 15 minute precision for 10 years.\n\nFor details of implementing your schema, see the [Configuring Carbon](config-carbon) document.\n\nBasically, when carbon receives a metric, it determines where on the filesystem the whisper data file should be for that metric. If the data file does not exist, carbon knows it has to create it, but since whisper is a fixed size database, some parameters must be determined at the time of file creation (this is the reason we’re making a schema). Carbon looks at the schemas file, and in order of priority (highest to lowest) looks for the first schema whose pattern matches the metric name. If no schema matches the default schema (2 hours of minutely data) is used. Once the appropriate schema is determined, carbon uses the retention configuration for the schema to create the whisper data file appropriately.\n\n## Step 3 - Understanding the Graphite Message Format\n\nGraphite understands messages with this format:\n\n``` none\nmetric_path value timestamp\\n\n```\n\n`metric_path` is the metric namespace that you want to populate.\n\n`value` is the value that you want to assign to the metric at this time.\n\n`timestamp` is the number of seconds since unix epoch time. Carbon-cache will use the time of arrival if the `timestamp` is set to `-1`.\n\nA simple example of doing this from the unix terminal would look like this:\n\n``` none\necho \"test.bash.stats 42 `date +%s`\" | nc graphite.example.com 2003\n```\n\nThere are many tools that interact with Graphite. See the [Tools](tools) page for some choices of tools that may be used to feed Graphite.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/feeding-carbon.html](https://graphite.readthedocs.io/en/latest/feeding-carbon.html)"
- name: fgcolor
  id: render_api#fgcolor
  summary: Sets the foreground color
  belongs_to: The Render URL API
  description: |-
    ### fgcolor

    *Default: value from the \[default\] template in graphTemplates.conf*

    Sets the foreground color. This only affects the title, legend text, and axis labels.

    See [majorGridLineColor](#majorgridlinecolor), and [minorGridLineColor](#minorgridlinecolor) for further control of colors.

    See [bgcolor](#bgcolor) for a list of color names and details on formatting this parameter.
- name: Filesystem Paths
  id: config-local-settings#filesystem-paths
  summary: These settings configure the location of Graphite-web’s additional configuration files, static content, and data
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## Filesystem Paths

    These settings configure the location of Graphite-web’s additional configuration files, static content, and data. These need to be adjusted if Graphite-web is installed outside of the [default installation layout](install#default-installation-layout).

    GRAPHITE_ROOT

    Default: /opt/graphite The base directory for the Graphite install. This setting is used to shift the Graphite install from the default base directory which keeping the [default layout](install#default-installation-layout). The paths derived from this setting can be individually overridden as well.

    CONF_DIR

    Default: GRAPHITE_ROOT/conf The location of additional Graphite-web configuration files.

    STORAGE_DIR

    Default: GRAPHITE_ROOT/storage The base directory from which WHISPER_DIR, RRD_DIR, CERES_DIR, LOG_DIR, and INDEX_FILE default paths are referenced.

    STATIC_ROOT

    Default: See below The location of Graphite-web’s static content. This defaults to `static/` three parent directories up from `settings.py`. In the [default layout](install#default-installation-layout) this is `/opt/graphite/static`.

    This directory doesn’t even exist once you’ve installed graphite. It needs to be populated with the following command:

    ``` default
    PYTHONPATH=$GRAPHITE_ROOT/webapp django-admin.py collectstatic --noinput --settings=graphite.settings
    ```

    This collects static files for graphite-web and external apps (namely, the Django admin app) and puts them in a directory that needs to be available under the `/static/` URL of your web server. To configure Apache:

    ``` default
    Alias /static/ "/opt/graphite/static"
    ```

    For Nginx:

    ``` default
    location /static/ {
        alias /opt/graphite/static/;
    }
    ```

    Alternatively, static files can be served directly by the Graphite webapp if you install the `whitenoise` Python package.

    DASHBOARD_CONF

    Default: CONF_DIR/dashboard.conf The location of the Graphite-web Dashboard configuration.

    GRAPHTEMPLATES_CONF

    Default: CONF_DIR/graphTemplates.conf The location of the Graphite-web Graph Template configuration.

    WHISPER_DIR

    Default: /opt/graphite/storage/whisper The location of Whisper data files.

    CERES_DIR

    Default: /opt/graphite/storage/ceres The location of Ceres data files.

    RRD_DIR

    Default: /opt/graphite/storage/rrd The location of RRD data files.

    STANDARD_DIRS

    Default: \[WHISPER_DIR, RRD_DIR\] The list of directories searched for data files. By default, this is the value of WHISPER_DIR and RRD_DIR (if rrd support is detected). If this setting is defined, the WHISPER_DIR, CERES_DIR, and RRD_DIR settings have no effect.

    LOG_DIR

    Default: STORAGE_DIR/log/webapp The directory to write Graphite-web’s log files. This directory must be writable by the user running the Graphite-web webapp.

    INDEX_FILE

    Default: /opt/graphite/storage/index The location of the search index file. This file is generated by the build-index.sh script and must be writable by the user running the Graphite-web webapp.

    STORAGE_FINDERS

    Default: () It is possible to use an alternate storage layer than the default, Whisper, in order to accommodate specific needs. See: [http://graphite.readthedocs.io/en/latest/storage-backends.html](http://graphite.readthedocs.io/en/latest/storage-backends.html)

    FETCH_TIMEOUT

    Default: 6

    Timeout for data fetches in seconds.

    FIND_TIMEOUT

    Default: 3

    Timeout for find requests (metric browsing) in seconds.

    TAGDB

    Default: ‘graphite.tags.localdatabase.LocalDatabaseTagDB’ Tag database driver to use, other options include graphite.tags.redis.RedisTagDB

    TAGDB_REDIS_HOST

    Default: ‘localhost’ Redis host to use with TAGDB = ‘graphite.tags.redis.RedisTagDB’

    TAGDB_REDIS_PORT

    Default: 6379 Redis port to use with TAGDB = ‘graphite.tags.redis.RedisTagDB’

    TAGDB_REDIS_DB

    Default: 0 Redis database to use with TAGDB = ‘graphite.tags.redis.RedisTagDB’
- name: filterSeries()
  id: functions#graphite.render.functions.filterSeries
  summary: Takes one metric or a wildcard seriesList followed by a consolidation function, an operator and a threshold
  belongs_to: Functions
  description: |-
    filterSeries(seriesList, func, operator, threshold)

    Takes one metric or a wildcard seriesList followed by a consolidation function, an operator and a threshold. Draws only the metrics which match the filter expression.

    Example:

    ``` none
    &target=filterSeries(system.interface.eth*.packetsSent, 'max', '>', 1000)
    ```

    This would only display interfaces which has a peak throughput higher than 1000 packets/min.

    Supported aggregation functions: `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range`, `multiply` & `last`.

    Supported operators: `=`, `!=`, `>`, `>=`, `<` & `<=`.
- name: fontBold
  id: render_api#fontbold
  summary: If set to true, makes the font bold
  belongs_to: The Render URL API
  description: |-
    ### fontBold

    *Default: value from the \[default\] template in graphTemplates.conf*

    If set to true, makes the font bold.

    Example:

    ``` none
    &fontBold=true
    ```
- name: fontItalic
  id: render_api#fontitalic
  summary: If set to true, makes the font italic / oblique
  belongs_to: The Render URL API
  description: |-
    ### fontItalic

    *Default: value from the \[default\] template in graphTemplates.conf*

    If set to true, makes the font italic / oblique. Default is false.

    Example:

    ``` none
    &fontItalic=true
    ```
- name: fontName
  id: render_api#fontname
  summary: Change the font used to render text on the graph
  belongs_to: The Render URL API
  description: |-
    ### fontName

    *Default: value from the \[default\] template in graphTemplates.conf*

    Change the font used to render text on the graph. The font must be installed on the Graphite Server.

    Example:

    ``` none
    &fontName=FreeMono
    ```
- name: fontSize
  id: render_api#fontsize
  summary: Changes the font size
  belongs_to: The Render URL API
  description: |-
    ### fontSize

    *Default: value from the \[default\] template in graphTemplates.conf*

    Changes the font size. Must be passed a positive floating point number or integer equal to or greater than 1. Default is 10

    Example:

    ``` none
    &fontSize=8
    ```
- name: format
  id: render_api#format
  summary: Controls the format of data returned
  belongs_to: The Render URL API
  description: |-
    ### format

    Controls the format of data returned. Affects all `&targets` passed in the URL.

    Examples:

    ``` none
    &format=png
    &format=raw
    &format=csv
    &format=json
    &format=svg
    &format=pdf
    &format=dygraph
    &format=rickshaw
    ```

    #### png

    Renders the graph as a PNG image of size determined by [width](#width) and [height](#height)

    #### raw

    Renders the data in a custom line-delimited format. Targets are output one per line and are of the format `<target``name>,<start``timestamp>,<end``timestamp>,<series``step>|[data]*`

    ``` none
    entries,1311836008,1311836013,1|1.0,2.0,3.0,5.0,6.0
    ```

    #### csv

    Renders the data in a CSV format suitable for import into a spreadsheet or for processing in a script

    ``` none
    entries,2011-07-28 01:53:28,1.0
    entries,2011-07-28 01:53:29,2.0
    entries,2011-07-28 01:53:30,3.0
    entries,2011-07-28 01:53:31,5.0
    entries,2011-07-28 01:53:32,6.0
    ```

    #### json

    Renders the data as a json object. The [jsonp](#jsonp) option can be used to wrap this data in a named call for cross-domain access

    ``` none
    [{
      "target": "entries",
      "datapoints": [
        [1.0, 1311836008],
        [2.0, 1311836009],
        [3.0, 1311836010],
        [5.0, 1311836011],
        [6.0, 1311836012]
      ]
    }]
    ```

    #### svg

    Renders the graph as SVG markup of size determined by [width](#width) and [height](#height). Metadata about the drawn graph is saved as an embedded script with the variable `metadata` being set to an object describing the graph

    ``` none
    <script>
      <![CDATA[
        metadata = {
          "area": {
            "xmin": 39.195507812499997,
            "ymin": 33.96875,
            "ymax": 623.794921875,
            "xmax": 1122
          },
          "series": [
            {
              "start": 1335398400,
              "step": 1800,
              "end": 1335425400,
              "name": "summarize(test.data, \"30min\", \"sum\")",
              "color": "#859900",
              "data": [null, null, 1.0, null, 1.0, null, 1.0, null, 1.0, null, 1.0, null, null, null, null],
              "options": {},
              "valuesPerPoint": 1
            }
          ],
          "y": {
            "labelValues": [0, 0.25, 0.5, 0.75, 1.0],
            "top": 1.0,
            "labels": ["0 ", "0.25 ", "0.50 ", "0.75 ", "1.00  "],
            "step": 0.25,
            "bottom": 0
          },
          "x": {
            "start": 1335398400,
            "end": 1335423600
          },
          "font": {
            "bold": false,
            "name": "Sans",
            "italic": false,
            "size": 10
          },
          "options": {
            "lineWidth": 1.2
          }
        }
      ]]>
    </script>
    ```

    #### pdf

    Renders the graph as a PDF of size determined by [width](#width) and [height](#height).

    #### dygraph

    Renders the data as a json object suitable for passing to a [Dygraph](http://dygraphs.com/data.html) object.

    ``` none
    {
      "labels" : [
        "Time",
        "entries"
      ],
      "data" : [
        [1468791890000, 0.0],
        [1468791900000, 0.0]
      ]
    }
    ```

    #### rickshaw

    Renders the data as a json object suitable for passing to a [Rickshaw](http://code.shutterstock.com/rickshaw/tutorial/introduction.html) object.

    ``` none
    [{
      "target": "entries",
      "datapoints": [{
        "y": 0.0,
        "x": 1468791890
      }, {
        "y": 0.0,
        "x": 1468791900
      }]
    }]
    ```

    #### pickle

    Returns a Python [pickle](http://docs.python.org/library/pickle.html) (serialized Python object). The response will have the MIME type ‘application/pickle’. The pickled object is a list of dictionaries with the keys: `name`, `start`, `end`, `step`, and `values` as below:

    ``` python
    [
      {
        'name' : 'summarize(test.data, "30min", "sum")',
        'start': 1335398400,
        'end'  : 1335425400,
        'step' : 1800,
        'values' : [None, None, 1.0, None, 1.0, None, 1.0, None, 1.0, None, 1.0, None, None, None, None],
      }
    ]
    ```
- name: format
  id: render_api#param-format
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### format

    See: [Data Display Formats](#data-display-formats)
- name: Forwarding
  id: tools#forwarding
  summary: A simple endpoint for submitting metrics to Graphite
  belongs_to: Tools That Work With Graphite
  description: |-
    ## Forwarding

    [Backstop](https://github.com/obfuscurity/backstop)

    A simple endpoint for submitting metrics to Graphite. It accepts JSON data via HTTP POST and proxies the data to one or more Carbon/Graphite listeners.

    [carbon-c-relay](https://github.com/grobian/carbon-c-relay)

    Enhanced C implementation of Carbon relay, aggregator and rewriter.

    [carbon-relay-ng](https://github.com/graphite-ng/carbon-relay-ng)

    Fast carbon relay+aggregator with admin interfaces for making changes online - production ready.

    [Evenflow](https://github.com/github/evenflow)

    A simple service for submitting sFlow datagrams to Graphite. It accepts sFlow datagrams from multiple network devices and proxies the data to a Carbon listener. Currently only Generic Interface Counters are supported. All other message types are discarded.

    [Grafsy](https://github.com/leoleovich/grafsy)

    Very light caching proxy for graphite metrics with additional features:

    - Caching metrics in case of outage and sending them later
    - Validation of metrics
    - Aggregating of metrics, including SUM and AVG functions
    - Much more

    [Graphite-Newrelic](https://github.com/gingerlime/graphite-newrelic)

    Get your graphite data into [New Relic](https://newrelic.com/platform) via a New Relic Platform plugin.

    [Graphite-relay](https://github.com/markchadwick/graphite-relay)

    A fast Graphite relay written in Scala with the Netty framework.

    [Graphios](https://github.com/shawn-sterling/graphios)

    A small Python daemon to send Nagios performance data (perfdata) to Graphite.

    [Graphout](http://shamil.github.io/graphout)

    A Node.js application that lets you forward Graphite based queries (using the render API) out to different external services. There are built in modules for Zabbix and CloudWatch. Custom modules are very easy to write.

    [Grockets](https://github.com/disqus/grockets)

    A node.js application which provides streaming JSON data over HTTP from Graphite.

    [Gruffalo](https://github.com/outbrain/gruffalo)

    An asynchronous Netty based graphite proxy, for large scale installations. It protects Graphite from the herds of clients by minimizing context switches and interrupts; by batching and aggregating metrics. Gruffalo also allows you to replicate metrics between Graphite installations for DR scenarios, for example.

    [Ledbetter](https://github.com/github/ledbetter)

    A simple script for gathering Nagios problem statistics and submitting them to Graphite. It focuses on summary (overall, servicegroup and hostgroup) statistics and writes them to the nagios.problems metrics namespace within Graphite.

    [pipe-to-graphite](https://github.com/iFixit/pipe-to-graphite)

    A small shell script that makes it easy to report the output of any other cli program to Graphite.

    [Polymur](https://github.com/jamiealquiza/polymur)

    A fast relay and HTTPS forwarder toolset written in Go.

    [statsd](https://github.com/etsy/statsd)

    A simple daemon for easy stats aggregation, developed by the folks at Etsy. A list of forks and alternative implementations can be found at \<[http://joemiller.me/2011/09/21/list-of-statsd-server-implementations/](http://joemiller.me/2011/09/21/list-of-statsd-server-implementations/)\>
- name: from
  id: render_api#from
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### from

    See: [from / until](#from-until)
- name: from / until
  id: render_api#from-until
  summary: These are optional parameters that specify the relative or absolute time period to graph
  belongs_to: The Render URL API
  description: |-
    ### from / until

    These are optional parameters that specify the relative or absolute time period to graph. `from` specifies the beginning, `until` specifies the end. If `from` is omitted, it defaults to 24 hours ago. If `until` is omitted, it defaults to the current time (now).

    There are multiple formats for these functions:

    ``` none
    &from=-RELATIVE_TIME
    &from=ABSOLUTE_TIME
    ```

    RELATIVE_TIME is a length of time since the current time. It is always preceded by a minus sign ( - ) and followed by a unit of time. Valid units of time:

    | Abbreviation | Unit            |
    |--------------|-----------------|
    | s            | Seconds         |
    | min          | Minutes         |
    | h            | Hours           |
    | d            | Days            |
    | w            | Weeks           |
    | mon          | 30 Days (month) |
    | y            | 365 Days (year) |

    ABSOLUTE_TIME is in the format HH:MM_YYYYMMDD, YYYYMMDD, MM/DD/YY, or any other `at(1)`-compatible time format.

    | Abbreviation | Meaning                                                                    |
    |--------------|----------------------------------------------------------------------------|
    | HH           | Hours, in 24h clock format. Times before 12PM must include leading zeroes. |
    | MM           | Minutes                                                                    |
    | YYYY         | 4 Digit Year.                                                              |
    | MM           | Numeric month representation with leading zero                             |
    | DD           | Day of month with leading zero                                             |

    `&from` and `&until` can mix absolute and relative time if desired.

    Examples:

    ``` none
    &from=-8d&until=-7d
    (shows same day last week)

    &from=04:00_20110501&until=16:00_20110501
    (shows 4AM-4PM on May 1st, 2011)

    &from=20091201&until=20091231
    (shows December 2009)

    &from=noon+yesterday
    (shows data since 12:00pm on the previous day)

    &from=6pm+today
    (shows data since 6:00pm on the same day)

    &from=january+1
    (shows data since the beginning of the current year)

    &from=monday
    (show data since the previous monday)
    ```
- name: Fulfilling Dependencies
  id: install#fulfilling-dependencies
  summary: Most current Linux distributions have all of the requirements available in the base packages
  belongs_to: Installing Graphite
  description: |-
    ## Fulfilling Dependencies

    Most current Linux distributions have all of the requirements available in the base packages. RHEL based distributions may require the [EPEL](http://fedoraproject.org/wiki/EPEL) repository for requirements. Python module dependencies can be install with [pip](https://pip.pypa.io/) rather than system packages if desired or if using a Python version that differs from the system default. Some modules (such as Cairo) may require library development headers to be available.
- name: Function API
  id: functions#function-api
  summary: You can use the HTTP api to get a list of available functions, or the details of a specific function
  belongs_to: Functions
  description: "## Function API\n\nYou can use the HTTP api to get a list of available functions, or the details of a specific function.\n\nTo get a list of available functions:\n\n``` none\n$ curl -s \"http://graphite/functions?pretty=1\"\n\n{\n  \"absolute\": {\n    \"description\": \"<function description>\",\n    \"function\": \"absolute(seriesList)\",\n    \"group\": \"Transform\",\n    \"module\": \"graphite.render.functions\",\n    \"name\": \"absolute\",\n    \"params\": [\n      {\n        \"name\": \"seriesList\",\n        \"required\": true,\n        \"type\": \"seriesList\"\n      }\n    ]\n  },\n  <more functions...>\n}\n```\n\nIf the parameter `grouped=1` is passed, the returned list will be organized by group:\n\n``` none\n$ curl -s \"http://graphite/functions?pretty=1&grouped=1\"\n\n{\n  \"Alias\": {\n    <alias functions...>\n  },\n  <more groups...>\n}\n```\n\nTo get the definition of a specific function:\n\n``` none\n$ curl -s \"http://graphite/functions/absolute?pretty=1\"\n\n{\n  \"description\": \"<function description>\",\n  \"function\": \"absolute(seriesList)\",\n  \"group\": \"Transform\",\n  \"module\": \"graphite.render.functions\",\n  \"name\": \"absolute\",\n  \"params\": [\n    {\n      \"name\": \"seriesList\",\n      \"required\": true,\n      \"type\": \"seriesList\"\n    }\n  ]\n}\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/functions.html](https://graphite.readthedocs.io/en/latest/functions.html)"
- name: Function Plugins
  id: functions#function-plugins
  summary: Function plugins can define additional functions for use in render calls
  belongs_to: Functions
  description: |-
    ## Function Plugins

    Function plugins can define additional functions for use in render calls.

    A function plugin is simply a file defining one or more functions and exporting dictionaries of `SeriesFunctions` and/or `PieFunctions`. When Graphite loads the plugin it will add functions in `SeriesFunctions` and/or `PieFunctions` to the list of available functions.

    Each exposed function must accept at least a `requestContext` and `seriesList` parameter, and may accept additional parameters as needed.

    `requestContext` will be a dictionary as defined in `graphite.render.views.renderView()`, `seriesList` will be a list of `TimeSeries` objects.

    ``` python
    from graphite.functions.params import Param, ParamTypes

    def toUpperCase(requestContext, seriesList):
      """Custom function that changes series names to UPPERCASE"""
      for series in seriesList:
        series.name = series.name.upper()
      return seriesList

    # optionally set the group attribute
    toUpperCase.group = 'Custom'
    toUpperCase.params = [
      Param('seriesList', ParamTypes.seriesList, required=True),
    ]

    SeriesFunctions = {
      'upper': toUpperCase,
    }
    ```

    Each function can have a docstring, `.group`, and `.params` attributes defined, these are used in the function API output as hints for query builders.

    The `.group` attribute is the group name as a string, the `.params` attribute is a list of parameter definitions.

    Each parameter definition is `Param` object, the `Param` constructor accepts the following arguments (note that requestContext is not included in the list of parameters):

    - **name**: The name of the parameter
    - **paramtype**: The parameter type, one of:
      - **ParamTypes.aggFunc**: An aggregation function name
      - **ParamTypes.boolean**: True/False
      - **ParamTypes.date**: A date specification
      - **ParamTypes.float**: A float value
      - **ParamTypes.integer**: An integer value
      - **ParamTypes.interval**: An interval specifier like `1h`, `1d`, etc
      - **ParamTypes.intOrInterval**: An integer or interval specifier
      - **ParamTypes.node**: A node number
      - **ParamTypes.nodeOrTag**: A node number or tag name
      - **ParamTypes.series**: A single series
      - **ParamTypes.seriesList**: A list of series
      - **ParamTypes.seriesLists**: A list of seriesLists
      - **ParamTypes.string**: A string value
      - **ParamTypes.tag**: A tag name
    - **required**: Set to `True` for required parameters
    - **default**: Default value for optional parameters
    - **multiple**: Set to `True` for parameters that accept multiple instances (defined with `*` in Python)
    - **options**: A list of available values for parameters that accept only a defined list
    - **suggestions**: A list of suggested values for parameters that accept free-form values

    Custom plugin files may be placed in the `/opt/graphite/webapp/graphite/functions/custom` folder and will be loaded automatically when graphite starts.

    To load a packaged function plugin module, add it to the `FUNCTION_PLUGINS` setting:

    ``` python
    FUNCTION_PLUGINS = [
      'some.function_plugin',
    ]
    ```
- name: Functions
  id: functions
  summary: Functions are used to transform, combine, and perform computations on series data
  description: "# Functions\n\nFunctions are used to transform, combine, and perform computations on [series](terminology#term-series) data. Functions are applied using the Composer interface or by manipulating the `target` parameters in the [Render API](render_api).\n\n## Usage\n\nMost functions are applied to one [series list](terminology#term-series-list). Functions with the parameter `*seriesLists` can take an arbitrary number of series lists. To pass multiple series lists to a function which only takes one, use the `group()` function.\n\n## List of functions\n\nabsolute(seriesList)  \nTakes one metric or a wildcard seriesList and applies the mathematical abs function to each datapoint transforming it to its absolute value.\n\nExample:\n\n``` none\n&target=absolute(Server.instance01.threads.busy)\n&target=absolute(Server.instance*.threads.busy)\n```\n\naggregate(seriesList, func, xFilesFactor=None)  \nAggregate series using the specified function.\n\nExample:\n\n``` none\n&target=aggregate(host.cpu-[0-7].cpu-{user,system}.value, \"sum\")\n```\n\nThis would be the equivalent of\n\n``` none\n&target=sumSeries(host.cpu-[0-7].cpu-{user,system}.value)\n```\n\nThis function can be used with aggregation functions `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `count`, `range`, `multiply` & `last`.\n\n&nbsp;\n\naggregateLine(seriesList, func='average', keepStep=False)  \nTakes a metric or wildcard seriesList and draws a horizontal line based on the function applied to each series.\n\nIf the optional keepStep parameter is set to True, the result will have the same time period and step as the source series.\n\nNote: By default, the graphite renderer consolidates data points by averaging data points over time. If you are using the ‘min’ or ‘max’ function for aggregateLine, this can cause an unusual gap in the line drawn by this function and the data itself. To fix this, you should use the consolidateBy() function with the same function argument you are using for aggregateLine. This will ensure that the proper data points are retained and the graph should line up correctly.\n\nExample:\n\n``` none\n&target=aggregateLine(server01.connections.total, 'avg')\n&target=aggregateLine(server*.connections.total, 'avg')\n```\n\n&nbsp;\n\naggregateWithWildcards(seriesList, func, \\*positions)  \nCall aggregator after inserting wildcards at the given position(s).\n\nExample:\n\n``` none\n&target=aggregateWithWildcards(host.cpu-[0-7].cpu-{user,system}.value, \"sum\", 1)\n```\n\nThis would be the equivalent of\n\n``` none\n&target=sumSeries(host.cpu-[0-7].cpu-user.value)&target=sumSeries(host.cpu-[0-7].cpu-system.value)\n# or\n&target=aggregate(host.cpu-[0-7].cpu-user.value,\"sum\")&target=aggregate(host.cpu-[0-7].cpu-system.value,\"sum\")\n```\n\nThis function can be used with all aggregation functions supported by [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\"): `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range` & `multiply`.\n\nThis complements [`groupByNodes`](#graphite.render.functions.groupByNodes \"graphite.render.functions.groupByNodes\") which takes a list of nodes that must match in each group.\n\n&nbsp;\n\nalias(seriesList, newName)  \nTakes one metric or a wildcard seriesList and a string in quotes. Prints the string instead of the metric name in the legend.\n\n``` none\n&target=alias(Sales.widgets.largeBlue,\"Large Blue Widgets\")\n```\n\n&nbsp;\n\naliasByMetric(seriesList)  \nTakes a seriesList and applies an alias derived from the base metric name.\n\n``` none\n&target=aliasByMetric(carbon.agents.graphite.creates)\n```\n\n&nbsp;\n\naliasByNode(seriesList, \\*nodes)  \nTakes a seriesList and applies an alias derived from one or more “node” portion/s of the target name or tags. Node indices are 0 indexed.\n\n``` none\n&target=aliasByNode(ganglia.*.cpu.load5,1)\n```\n\nEach node may be an integer referencing a node in the series name or a string identifying a tag.\n\n``` none\n&target=seriesByTag(\"name=~cpu.load.*\", \"server=~server[1-9]+\", \"datacenter=dc1\")|aliasByNode(\"datacenter\", \"server\", 1)\n\n# will produce output series like\n# dc1.server1.load5, dc1.server2.load5, dc1.server1.load10, dc1.server2.load10\n```\n\n&nbsp;\n\naliasByTags(seriesList, \\*tags)  \nTakes a seriesList and applies an alias derived from one or more tags and/or nodes\n\n``` none\n&target=seriesByTag(\"name=cpu\")|aliasByTags(\"server\",\"name\")\n```\n\nThis is an alias for [`aliasByNode`](#graphite.render.functions.aliasByNode \"graphite.render.functions.aliasByNode\").\n\n&nbsp;\n\naliasQuery(seriesList, search, replace, newName)  \nPerforms a query to alias the metrics in seriesList.\n\n``` none\n&target=aliasQuery(channel.power.*,\"channel\\.power\\.([0-9]+)\",\"channel.frequency.\\1\", \"Channel %d MHz\")\n```\n\nThe series in seriesList will be aliased by first translating the series names using the search & replace parameters, then using the last value of the resulting series to construct the alias using sprintf-style syntax.\n\n&nbsp;\n\naliasSub(seriesList, search, replace)  \nRuns series names through a regex search/replace.\n\n``` none\n&target=aliasSub(ip.*TCP*,\"^.*TCP(\\d+)\",\"\\1\")\n```\n\n&nbsp;\n\nalpha(seriesList, alpha)  \nAssigns the given alpha transparency setting to the series. Takes a float value between 0 and 1.\n\n&nbsp;\n\napplyByNode(seriesList, nodeNum, templateFunction, newName=None)  \nTakes a seriesList and applies some complicated function (described by a string), replacing templates with unique prefixes of keys from the seriesList (the key is all nodes up to the index given as nodeNum).\n\nIf the newName parameter is provided, the name of the resulting series will be given by that parameter, with any “%” characters replaced by the unique prefix.\n\nExample:\n\n``` none\n&target=applyByNode(servers.*.disk.bytes_free,1,\"divideSeries(%.disk.bytes_free,sumSeries(%.disk.bytes_*))\")\n```\n\nWould find all series which match servers.\\*.disk.bytes_free, then trim them down to unique series up to the node given by nodeNum, then fill them into the template function provided (replacing % by the prefixes).\n\nAdditional Examples:\n\nGiven keys of\n\n- stats.counts.haproxy.web.2XX\n- stats.counts.haproxy.web.3XX\n- stats.counts.haproxy.web.5XX\n- stats.counts.haproxy.microservice.2XX\n- stats.counts.haproxy.microservice.3XX\n- stats.counts.haproxy.microservice.5XX\n\nThe following will return the rate of 5XX’s per service:\n\n``` none\napplyByNode(stats.counts.haproxy.*.*XX, 3, \"asPercent(%.5XX, sumSeries(%.*XX))\", \"%.pct_5XX\")\n```\n\nThe output series would have keys stats.counts.haproxy.web.pct_5XX and stats.counts.haproxy.microservice.pct_5XX.\n\n&nbsp;\n\nareaBetween(seriesList)  \nDraws the vertical area in between the two series in seriesList. Useful for visualizing a range such as the minimum and maximum latency for a service.\n\nareaBetween expects **exactly one argument** that results in exactly two series (see example below). The order of the lower and higher values series does not matter. The visualization only works when used in conjunction with `areaMode=stacked`.\n\nMost likely use case is to provide a band within which another metric should move. In such case applying an `alpha()`, as in the second example, gives best visual results.\n\nExample:\n\n``` none\n&target=areaBetween(service.latency.{min,max})&areaMode=stacked\n\n&target=alpha(areaBetween(service.latency.{min,max}),0.3)&areaMode=stacked\n```\n\nIf for instance, you need to build a seriesList, you should use the `group` function, like so:\n\n``` none\n&target=areaBetween(group(minSeries(a.*.min),maxSeries(a.*.max)))\n```\n\n&nbsp;\n\nasPercent(seriesList, total=None, \\*nodes)  \nCalculates a percentage of the total of a wildcard series. If total is specified, each series will be calculated as a percentage of that total. If total is not specified, the sum of all points in the wildcard series will be used instead.\n\nA list of nodes can optionally be provided, if so they will be used to match series with their corresponding totals following the same logic as [`groupByNodes`](#graphite.render.functions.groupByNodes \"graphite.render.functions.groupByNodes\").\n\nWhen passing nodes the total parameter may be a series list or None. If it is None then for each series in seriesList the percentage of the sum of series in that group will be returned.\n\nWhen not passing nodes, the total parameter may be a single series, reference the same number of series as seriesList or be a numeric value.\n\nExample:\n\n``` none\n# Server01 connections failed and succeeded as a percentage of Server01 connections attempted\n&target=asPercent(Server01.connections.{failed,succeeded}, Server01.connections.attempted)\n\n# For each server, its connections failed as a percentage of its connections attempted\n&target=asPercent(Server*.connections.failed, Server*.connections.attempted)\n\n# For each server, its connections failed and succeeded as a percentage of its connections attemped\n&target=asPercent(Server*.connections.{failed,succeeded}, Server*.connections.attempted, 0)\n\n# apache01.threads.busy as a percentage of 1500\n&target=asPercent(apache01.threads.busy,1500)\n\n# Server01 cpu stats as a percentage of its total\n&target=asPercent(Server01.cpu.*.jiffies)\n\n# cpu stats for each server as a percentage of its total\n&target=asPercent(Server*.cpu.*.jiffies, None, 0)\n```\n\nWhen using nodes, any series or totals that can’t be matched will create output series with names like `asPercent(someSeries,MISSING)` or `asPercent(MISSING,someTotalSeries)` and all values set to None. If desired these series can be filtered out by piping the result through `|exclude(\"MISSING\")` as shown below:\n\n``` none\n&target=asPercent(Server{1,2}.memory.used,Server{1,3}.memory.total,0)\n\n# will produce 3 output series:\n# asPercent(Server1.memory.used,Server1.memory.total) [values will be as expected]\n# asPercent(Server2.memory.used,MISSING) [all values will be None]\n# asPercent(MISSING,Server3.memory.total) [all values will be None]\n\n&target=asPercent(Server{1,2}.memory.used,Server{1,3}.memory.total,0)|exclude(\"MISSING\")\n\n# will produce 1 output series:\n# asPercent(Server1.memory.used,Server1.memory.total) [values will be as expected]\n```\n\nEach node may be an integer referencing a node in the series name or a string identifying a tag.\n\nNote\n\nWhen total is a seriesList, specifying nodes to match series with the corresponding total series will increase reliability.\n\n&nbsp;\n\naverageAbove(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics with an average value above N for the time period specified.\n\nExample:\n\n``` none\n&target=averageAbove(server*.instance*.threads.busy,25)\n```\n\nDraws the servers with average values above 25.\n\n&nbsp;\n\naverageBelow(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics with an average value below N for the time period specified.\n\nExample:\n\n``` none\n&target=averageBelow(server*.instance*.threads.busy,25)\n```\n\nDraws the servers with average values below 25.\n\n&nbsp;\n\naverageOutsidePercentile(seriesList, n)  \nRemoves series lying inside an average percentile interval\n\n&nbsp;\n\naverageSeries(\\*seriesLists)  \nShort Alias: avg()\n\nTakes one metric or a wildcard seriesList. Draws the average value of all metrics passed at each time.\n\nExample:\n\n``` none\n&target=averageSeries(company.server.*.threads.busy)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `average`.\n\n&nbsp;\n\naverageSeriesWithWildcards(seriesList, \\*position)  \nCall averageSeries after inserting wildcards at the given position(s).\n\nExample:\n\n``` none\n&target=averageSeriesWithWildcards(host.cpu-[0-7].cpu-{user,system}.value, 1)\n```\n\nThis would be the equivalent of\n\n``` none\n&target=averageSeries(host.*.cpu-user.value)&target=averageSeries(host.*.cpu-system.value)\n```\n\nThis is an alias for [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards \"graphite.render.functions.aggregateWithWildcards\") with aggregation `average`.\n\n&nbsp;\n\ncactiStyle(seriesList, system=None, units=None)  \nTakes a series list and modifies the aliases to provide column aligned output with Current, Max, and Min values in the style of cacti. Optionally takes a “system” value to apply unit formatting in the same style as the Y-axis, or a “unit” string to append an arbitrary unit suffix.\n\n``` none\n&target=cactiStyle(ganglia.*.net.bytes_out,\"si\")\n&target=cactiStyle(ganglia.*.net.bytes_out,\"si\",\"b\")\n```\n\nA possible value for `system` is `si`, which would express your values in multiples of a thousand. A second option is to use `binary` which will instead express your values in multiples of 1024 (useful for network devices).\n\nColumn alignment of the Current, Max, Min values works under two conditions: you use a monospace font such as terminus and use a single cactiStyle call, as separate cactiStyle calls are not aware of each other. In case you have different targets for which you would like to have cactiStyle to line up, you can use `group()` to combine them before applying cactiStyle, such as:\n\n``` none\n&target=cactiStyle(group(metricA,metricB))\n```\n\n&nbsp;\n\nchanged(seriesList)  \nTakes one metric or a wildcard seriesList. Output 1 when the value changed, 0 when null or the same\n\nExample:\n\n``` none\n&target=changed(Server01.connections.handled)\n```\n\n&nbsp;\n\ncolor(seriesList, theColor)  \nAssigns the given color to the seriesList\n\nExample:\n\n``` none\n&target=color(collectd.hostname.cpu.0.user, 'green')\n&target=color(collectd.hostname.cpu.0.system, 'ff0000')\n&target=color(collectd.hostname.cpu.0.idle, 'gray')\n&target=color(collectd.hostname.cpu.0.idle, '6464ffaa')\n```\n\n&nbsp;\n\nconsolidateBy(seriesList, consolidationFunc)  \nTakes one metric or a wildcard seriesList and a consolidation function name.\n\nValid function names are ‘sum’, ‘average’, ‘min’, ‘max’, ‘first’ & ‘last’.\n\nWhen a graph is drawn where width of the graph size in pixels is smaller than the number of datapoints to be graphed, Graphite consolidates the values to to prevent line overlap. The consolidateBy() function changes the consolidation function from the default of ‘average’ to one of ‘sum’, ‘max’, ‘min’, ‘first’, or ‘last’. This is especially useful in sales graphs, where fractional values make no sense and a ‘sum’ of consolidated values is appropriate.\n\n``` none\n&target=consolidateBy(Sales.widgets.largeBlue, 'sum')\n&target=consolidateBy(Servers.web01.sda1.free_space, 'max')\n```\n\n&nbsp;\n\nconstantLine(value)  \nTakes a float F.\n\nDraws a horizontal line at value F across the graph.\n\nExample:\n\n``` none\n&target=constantLine(123.456)\n```\n\n&nbsp;\n\ncountSeries(\\*seriesLists)  \nDraws a horizontal line representing the number of nodes found in the seriesList.\n\n``` none\n&target=countSeries(carbon.agents.*.*)\n```\n\n&nbsp;\n\ncumulative(seriesList)  \nTakes one metric or a wildcard seriesList.\n\nWhen a graph is drawn where width of the graph size in pixels is smaller than the number of datapoints to be graphed, Graphite consolidates the values to to prevent line overlap. The cumulative() function changes the consolidation function from the default of ‘average’ to ‘sum’. This is especially useful in sales graphs, where fractional values make no sense and a ‘sum’ of consolidated values is appropriate.\n\nAlias for [`consolidateBy(series,`` ``'sum')`](#graphite.render.functions.consolidateBy \"graphite.render.functions.consolidateBy\")\n\n``` none\n&target=cumulative(Sales.widgets.largeBlue)\n```\n\n&nbsp;\n\ncurrentAbove(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics whose value is above N at the end of the time period specified.\n\nExample:\n\n``` none\n&target=currentAbove(server*.instance*.threads.busy,50)\n```\n\nDraws the servers with more than 50 busy threads.\n\n&nbsp;\n\ncurrentBelow(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the metrics whose value is below N at the end of the time period specified.\n\nExample:\n\n``` none\n&target=currentBelow(server*.instance*.threads.busy,3)\n```\n\nDraws the servers with less than 3 busy threads.\n\n&nbsp;\n\ndashed(seriesList, dashLength=5)  \nTakes one metric or a wildcard seriesList, followed by a float F.\n\nDraw the selected metrics with a dotted line with segments of length F If omitted, the default length of the segments is 5.0\n\nExample:\n\n``` none\n&target=dashed(server01.instance01.memory.free,2.5)\n```\n\n&nbsp;\n\ndelay(seriesList, steps)  \nThis shifts all samples later by an integer number of steps. This can be used for custom derivative calculations, among other things. Note: this will pad the early end of the data with None for every step shifted.\n\nThis complements other time-displacement functions such as timeShift and timeSlice, in that this function is indifferent about the step intervals being shifted.\n\nExample:\n\n``` none\n&target=divideSeries(server.FreeSpace,delay(server.FreeSpace,1))\n```\n\nThis computes the change in server free space as a percentage of the previous free space.\n\n&nbsp;\n\nderivative(seriesList)  \nThis is the opposite of the integral function. This is useful for taking a running total metric and calculating the delta between subsequent data points.\n\nThis function does not normalize for periods of time, as a true derivative would. Instead see the perSecond() function to calculate a rate of change over time.\n\nExample:\n\n``` none\n&target=derivative(company.server.application01.ifconfig.TXPackets)\n```\n\nEach time you run ifconfig, the RX and TXPackets are higher (assuming there is network traffic.) By applying the derivative function, you can get an idea of the packets per minute sent or received, even though you’re only recording the total.\n\n&nbsp;\n\ndiffSeries(\\*seriesLists)  \nSubtracts series 2 through n from series 1.\n\nExample:\n\n``` none\n&target=diffSeries(service.connections.total,service.connections.failed)\n```\n\nTo diff a series and a constant, one should use offset instead of (or in addition to) diffSeries\n\nExample:\n\n``` none\n&target=offset(service.connections.total,-5)\n\n&target=offset(diffSeries(service.connections.total,service.connections.failed),-4)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `diff`.\n\n&nbsp;\n\ndivideSeries(dividendSeriesList, divisorSeries)  \nTakes a dividend metric and a divisor metric and draws the division result. A constant may *not* be passed. To divide by a constant, use the scale() function (which is essentially a multiplication operation) and use the inverse of the dividend. (Division by 8 = multiplication by 1/8 or 0.125)\n\nExample:\n\n``` none\n&target=divideSeries(Series.dividends,Series.divisors)\n```\n\n&nbsp;\n\ndivideSeriesLists(dividendSeriesList, divisorSeriesList)  \nIterates over a two lists and divides list1\\[0\\] by list2\\[0\\], list1\\[1\\] by list2\\[1\\] and so on. The lists need to be the same length\n\n&nbsp;\n\ndrawAsInfinite(seriesList)  \nTakes one metric or a wildcard seriesList. If the value is zero, draw the line at 0. If the value is above zero, draw the line at infinity. If the value is null or less than zero, do not draw the line.\n\nUseful for displaying on/off metrics, such as exit codes. (0 = success, anything else = failure.)\n\nExample:\n\n``` none\ndrawAsInfinite(Testing.script.exitCode)\n```\n\n&nbsp;\n\nevents(\\*tags)  \nReturns the number of events at this point in time. Usable with drawAsInfinite.\n\nExample:\n\n``` none\n&target=events(\"tag-one\", \"tag-two\")\n&target=events(\"*\")\n```\n\nReturns all events tagged as “tag-one” and “tag-two” and the second one returns all events.\n\n&nbsp;\n\nexclude(seriesList, pattern)  \nTakes a metric or a wildcard seriesList, followed by a regular expression in double quotes. Excludes metrics that match the regular expression.\n\nExample:\n\n``` none\n&target=exclude(servers*.instance*.threads.busy,\"server02\")\n```\n\n&nbsp;\n\nexponentialMovingAverage(seriesList, windowSize)  \nTakes a series of values and a window size and produces an exponential moving average utilizing the following formula:\n\n``` none\nema(current) = constant * (Current Value) + (1 - constant) * ema(previous)\n```\n\nThe Constant is calculated as:\n\n``` none\nconstant = 2 / (windowSize + 1)\n```\n\nThe first period EMA uses a simple moving average for its value.\n\nExample:\n\n``` none\n&target=exponentialMovingAverage(*.transactions.count, 10)\n&target=exponentialMovingAverage(*.transactions.count, '-10s')\n```\n\n&nbsp;\n\nfallbackSeries(seriesList, fallback)  \nTakes a wildcard seriesList, and a second fallback metric. If the wildcard does not match any series, draws the fallback metric.\n\nExample:\n\n``` none\n&target=fallbackSeries(server*.requests_per_second, constantLine(0))\n```\n\nDraws a 0 line when server metric does not exist.\n\n&nbsp;\n\nfilterSeries(seriesList, func, operator, threshold)  \nTakes one metric or a wildcard seriesList followed by a consolidation function, an operator and a threshold. Draws only the metrics which match the filter expression.\n\nExample:\n\n``` none\n&target=filterSeries(system.interface.eth*.packetsSent, 'max', '>', 1000)\n```\n\nThis would only display interfaces which has a peak throughput higher than 1000 packets/min.\n\nSupported aggregation functions: `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range`, `multiply` & `last`.\n\nSupported operators: `=`, `!=`, `>`, `>=`, `<` & `<=`.\n\n&nbsp;\n\ngrep(seriesList, pattern)  \nTakes a metric or a wildcard seriesList, followed by a regular expression in double quotes. Excludes metrics that don’t match the regular expression.\n\nExample:\n\n``` none\n&target=grep(servers*.instance*.threads.busy,\"server02\")\n```\n\n&nbsp;\n\ngroup(\\*seriesLists)  \nTakes an arbitrary number of seriesLists and adds them to a single seriesList. This is used to pass multiple seriesLists to a function which only takes one\n\n&nbsp;\n\ngroupByNode(seriesList, nodeNum, callback='average')  \nTakes a serieslist and maps a callback to subgroups within as defined by a common node\n\n``` none\n&target=groupByNode(ganglia.by-function.*.*.cpu.load5,2,\"sumSeries\")\n```\n\nWould return multiple series which are each the result of applying the “sumSeries” function to groups joined on the second node (0 indexed) resulting in a list of targets like\n\n``` none\nsumSeries(ganglia.by-function.server1.*.cpu.load5),sumSeries(ganglia.by-function.server2.*.cpu.load5),...\n```\n\nNode may be an integer referencing a node in the series name or a string identifying a tag.\n\nThis is an alias for using [`groupByNodes`](#graphite.render.functions.groupByNodes \"graphite.render.functions.groupByNodes\") with a single node.\n\n&nbsp;\n\ngroupByNodes(seriesList, callback, \\*nodes)  \nTakes a serieslist and maps a callback to subgroups within as defined by multiple nodes\n\n``` none\n&target=groupByNodes(ganglia.server*.*.cpu.load*,\"sum\",1,4)\n```\n\nWould return multiple series which are each the result of applying the “sum” aggregation to groups joined on the nodes’ list (0 indexed) resulting in a list of targets like\n\n``` none\nsumSeries(ganglia.server1.*.cpu.load5),sumSeries(ganglia.server1.*.cpu.load10),sumSeries(ganglia.server1.*.cpu.load15),sumSeries(ganglia.server2.*.cpu.load5),sumSeries(ganglia.server2.*.cpu.load10),sumSeries(ganglia.server2.*.cpu.load15),...\n```\n\nThis function can be used with all aggregation functions supported by [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\"): `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range` & `multiply`.\n\nEach node may be an integer referencing a node in the series name or a string identifying a tag.\n\n``` none\n&target=seriesByTag(\"name=~cpu.load.*\", \"server=~server[1-9]+\", \"datacenter=~dc[1-9]+\")|groupByNodes(\"average\", \"datacenter\", 1)\n\n# will produce output series like\n# dc1.load5, dc2.load5, dc1.load10, dc2.load10\n```\n\nThis complements [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards \"graphite.render.functions.aggregateWithWildcards\") which takes a list of wildcard nodes.\n\n&nbsp;\n\ngroupByTags(seriesList, callback, \\*tags)  \nTakes a serieslist and maps a callback to subgroups within as defined by multiple tags\n\n``` none\n&target=seriesByTag(\"name=cpu\")|groupByTags(\"average\",\"dc\")\n```\n\nWould return multiple series which are each the result of applying the “averageSeries” function to groups joined on the specified tags resulting in a list of targets like\n\n``` none\naverageSeries(seriesByTag(\"name=cpu\",\"dc=dc1\")),averageSeries(seriesByTag(\"name=cpu\",\"dc=dc2\")),...\n```\n\nThis function can be used with all aggregation functions supported by [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\"): `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range` & `multiply`.\n\n&nbsp;\n\nhighest(seriesList, n=1, func='average')  \nTakes one metric or a wildcard seriesList followed by an integer N and an aggregation function. Out of all metrics passed, draws only the N metrics with the highest aggregated value over the time period specified.\n\nExample:\n\n``` none\n&target=highest(server*.instance*.threads.busy,5,'max')\n```\n\nDraws the 5 servers with the highest number of busy threads.\n\n&nbsp;\n\nhighestAverage(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the top N metrics with the highest average value for the time period specified.\n\nExample:\n\n``` none\n&target=highestAverage(server*.instance*.threads.busy,5)\n```\n\nDraws the top 5 servers with the highest average value.\n\nThis is an alias for [`highest`](#graphite.render.functions.highest \"graphite.render.functions.highest\") with aggregation `average`.\n\n&nbsp;\n\nhighestCurrent(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the N metrics with the highest value at the end of the time period specified.\n\nExample:\n\n``` none\n&target=highestCurrent(server*.instance*.threads.busy,5)\n```\n\nDraws the 5 servers with the highest busy threads.\n\nThis is an alias for [`highest`](#graphite.render.functions.highest \"graphite.render.functions.highest\") with aggregation `current`.\n\n&nbsp;\n\nhighestMax(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N.\n\nOut of all metrics passed, draws only the N metrics with the highest maximum value in the time period specified.\n\nExample:\n\n``` none\n&target=highestMax(server*.instance*.threads.busy,5)\n```\n\nDraws the top 5 servers who have had the most busy threads during the time period specified.\n\nThis is an alias for [`highest`](#graphite.render.functions.highest \"graphite.render.functions.highest\") with aggregation `max`.\n\n&nbsp;\n\nhitcount(seriesList, intervalString, alignToInterval=False)  \nEstimate hit counts from a list of time series.\n\nThis function assumes the values in each time series represent hits per second. It calculates hits per some larger interval such as per day or per hour. This function is like summarize(), except that it compensates automatically for different time scales (so that a similar graph results from using either fine-grained or coarse-grained records) and handles rarely-occurring events gracefully.\n\n&nbsp;\n\nholtWintersAberration(seriesList, delta=3, bootstrapInterval='7d', seasonality='1d')  \nPerforms a Holt-Winters forecast using the series as input data and plots the positive or negative deviation of the series data from the forecast.\n\n&nbsp;\n\nholtWintersConfidenceArea(seriesList, delta=3, bootstrapInterval='7d', seasonality='1d')  \nPerforms a Holt-Winters forecast using the series as input data and plots the area between the upper and lower bands of the predicted forecast deviations.\n\n&nbsp;\n\nholtWintersConfidenceBands(seriesList, delta=3, bootstrapInterval='7d', seasonality='1d')  \nPerforms a Holt-Winters forecast using the series as input data and plots upper and lower bands with the predicted forecast deviations.\n\n&nbsp;\n\nholtWintersForecast(seriesList, bootstrapInterval='7d', seasonality='1d')  \nPerforms a Holt-Winters forecast using the series as input data. Data from bootstrapInterval (one week by default) previous to the series is used to bootstrap the initial forecast.\n\n&nbsp;\n\nidentity(name)  \nIdentity function: Returns datapoints where the value equals the timestamp of the datapoint. Useful when you have another series where the value is a timestamp, and you want to compare it to the time of the datapoint, to render an age\n\nExample:\n\n``` none\n&target=identity(\"The.time.series\")\n```\n\nThis would create a series named “The.time.series” that contains points where x(t) == t.\n\n&nbsp;\n\nintegral(seriesList)  \nThis will show the sum over time, sort of like a continuous addition function. Useful for finding totals or trends in metrics that are collected per minute.\n\nExample:\n\n``` none\n&target=integral(company.sales.perMinute)\n```\n\nThis would start at zero on the left side of the graph, adding the sales each minute, and show the total sales for the time period selected at the right side, (time now, or the time specified by ‘&until=’).\n\n&nbsp;\n\nintegralByInterval(seriesList, intervalUnit)  \nThis will do the same as integral() funcion, except resetting the total to 0 at the given time in the parameter “from” Useful for finding totals per hour/day/week/..\n\nExample:\n\n``` none\n&target=integralByInterval(company.sales.perMinute, \"1d\")&from=midnight-10days\n```\n\nThis would start at zero on the left side of the graph, adding the sales each minute, and show the evolution of sales per day during the last 10 days.\n\n&nbsp;\n\ninterpolate(seriesList, limit=inf)  \nTakes one metric or a wildcard seriesList, and optionally a limit to the number of ‘None’ values to skip over. Continues the line with the last received value when gaps (‘None’ values) appear in your data, rather than breaking your line.\n\nExample:\n\n``` none\n&target=interpolate(Server01.connections.handled)\n&target=interpolate(Server01.connections.handled, 10)\n```\n\n&nbsp;\n\ninvert(seriesList)  \nTakes one metric or a wildcard seriesList, and inverts each datapoint (i.e. 1/x).\n\nExample:\n\n``` none\n&target=invert(Server.instance01.threads.busy)\n```\n\n&nbsp;\n\nisNonNull(seriesList)  \nTakes a metric or wildcard seriesList and counts up the number of non-null values. This is useful for understanding the number of metrics that have data at a given point in time (i.e. to count which servers are alive).\n\nExample:\n\n``` none\n&target=isNonNull(webapp.pages.*.views)\n```\n\nReturns a seriesList where 1 is specified for non-null values, and 0 is specified for null values.\n\n&nbsp;\n\nkeepLastValue(seriesList, limit=inf)  \nTakes one metric or a wildcard seriesList, and optionally a limit to the number of ‘None’ values to skip over. Continues the line with the last received value when gaps (‘None’ values) appear in your data, rather than breaking your line.\n\nExample:\n\n``` none\n&target=keepLastValue(Server01.connections.handled)\n&target=keepLastValue(Server01.connections.handled, 10)\n```\n\n&nbsp;\n\nlegendValue(seriesList, \\*valueTypes)  \nTakes one metric or a wildcard seriesList and a string in quotes. Appends a value to the metric name in the legend. Currently one or several of: last, avg, total, min, max. The last argument can be si (default) or binary, in that case values will be formatted in the corresponding system.\n\n``` none\n&target=legendValue(Sales.widgets.largeBlue, 'avg', 'max', 'si')\n```\n\n&nbsp;\n\nlimit(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N.\n\nOnly draw the first N metrics. Useful when testing a wildcard in a metric.\n\nExample:\n\n``` none\n&target=limit(server*.instance*.memory.free,5)\n```\n\nDraws only the first 5 instance’s memory free.\n\n&nbsp;\n\nlineWidth(seriesList, width)  \nTakes one metric or a wildcard seriesList, followed by a float F.\n\nDraw the selected metrics with a line width of F, overriding the default value of 1, or the &lineWidth=X.X parameter.\n\nUseful for highlighting a single metric out of many, or having multiple line widths in one graph.\n\nExample:\n\n``` none\n&target=lineWidth(server01.instance01.memory.free,5)\n```\n\n&nbsp;\n\nlinearRegression(seriesList, startSourceAt=None, endSourceAt=None)  \nGraphs the linear regression function by least squares method.\n\nTakes one metric or a wildcard seriesList, followed by a quoted string with the time to start the line and another quoted string with the time to end the line. The start and end times are inclusive (default range is from to until). See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats. Datapoints in the range is used to regression.\n\nExample:\n\n``` none\n&target=linearRegression(Server.instance01.threads.busy, '-1d')\n&target=linearRegression(Server.instance*.threads.busy, \"00:00 20140101\",\"11:59 20140630\")\n```\n\n&nbsp;\n\nlinearRegressionAnalysis(series)  \nReturns factor and offset of linear regression function by least squares method.\n\n&nbsp;\n\nlogarithm(seriesList, base=10)  \nTakes one metric or a wildcard seriesList, a base, and draws the y-axis in logarithmic format. If base is omitted, the function defaults to base 10.\n\nExample:\n\n``` none\n&target=log(carbon.agents.hostname.avgUpdateTime,2)\n```\n\n&nbsp;\n\nlowest(seriesList, n=1, func='average')  \nTakes one metric or a wildcard seriesList followed by an integer N and an aggregation function. Out of all metrics passed, draws only the N metrics with the lowest aggregated value over the time period specified.\n\nExample:\n\n``` none\n&target=lowest(server*.instance*.threads.busy,5,'min')\n```\n\nDraws the 5 servers with the lowest number of busy threads.\n\n&nbsp;\n\nlowestAverage(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the bottom N metrics with the lowest average value for the time period specified.\n\nExample:\n\n``` none\n&target=lowestAverage(server*.instance*.threads.busy,5)\n```\n\nDraws the bottom 5 servers with the lowest average value.\n\nThis is an alias for [`lowest`](#graphite.render.functions.lowest \"graphite.render.functions.lowest\") with aggregation `average`.\n\n&nbsp;\n\nlowestCurrent(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the N metrics with the lowest value at the end of the time period specified.\n\nExample:\n\n``` none\n&target=lowestCurrent(server*.instance*.threads.busy,5)\n```\n\nDraws the 5 servers with the least busy threads right now.\n\nThis is an alias for [`lowest`](#graphite.render.functions.lowest \"graphite.render.functions.lowest\") with aggregation `current`.\n\n&nbsp;\n\nmapSeries(seriesList, \\*mapNodes)  \nShort form: `map()`\n\nTakes a seriesList and maps it to a list of seriesList. Each seriesList has the given mapNodes in common.\n\nNote\n\nThis function is not very useful alone. It should be used with [`reduceSeries()`](#graphite.render.functions.reduceSeries \"graphite.render.functions.reduceSeries\")\n\n``` none\nmapSeries(servers.*.cpu.*,1) =>\n\n  [\n    servers.server1.cpu.*,\n    servers.server2.cpu.*,\n    ...\n    servers.serverN.cpu.*\n  ]\n```\n\nEach node may be an integer referencing a node in the series name or a string identifying a tag.\n\n&nbsp;\n\nmaxSeries(\\*seriesLists)  \nTakes one metric or a wildcard seriesList. For each datapoint from each metric passed in, pick the maximum value and graph it.\n\nExample:\n\n``` none\n&target=maxSeries(Server*.connections.total)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `max`.\n\n&nbsp;\n\nmaximumAbove(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a maximum value above n.\n\nExample:\n\n``` none\n&target=maximumAbove(system.interface.eth*.packetsSent,1000)\n```\n\nThis would only display interfaces which sent more than 1000 packets/min.\n\n&nbsp;\n\nmaximumBelow(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a maximum value below n.\n\nExample:\n\n``` none\n&target=maximumBelow(system.interface.eth*.packetsSent,1000)\n```\n\nThis would only display interfaces which sent less than 1000 packets/min.\n\n&nbsp;\n\nminMax(seriesList)  \nApplies the popular min max normalization technique, which takes each point and applies the following normalization transformation to it: normalized = (point - min) / (max - min).\n\nExample:\n\n``` none\n&target=minMax(Server.instance01.threads.busy)\n```\n\n&nbsp;\n\nminSeries(\\*seriesLists)  \nTakes one metric or a wildcard seriesList. For each datapoint from each metric passed in, pick the minimum value and graph it.\n\nExample:\n\n``` none\n&target=minSeries(Server*.connections.total)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `min`.\n\n&nbsp;\n\nminimumAbove(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a minimum value above n.\n\nExample:\n\n``` none\n&target=minimumAbove(system.interface.eth*.packetsSent,1000)\n```\n\nThis would only display interfaces which sent more than 1000 packets/min.\n\n&nbsp;\n\nminimumBelow(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a minimum value below n.\n\nExample:\n\n``` none\n&target=minimumBelow(system.interface.eth*.packetsSent,1000)\n```\n\nThis would only display interfaces which at one point sent less than 1000 packets/min.\n\n&nbsp;\n\nmostDeviant(seriesList, n)  \nTakes one metric or a wildcard seriesList followed by an integer N. Draws the N most deviant metrics. To find the deviants, the standard deviation (sigma) of each series is taken and ranked. The top N standard deviations are returned.\n\n> Example:\n\n``` none\n&target=mostDeviant(server*.instance*.memory.free, 5)\n```\n\nDraws the 5 instances furthest from the average memory free.\n\n&nbsp;\n\nmovingAverage(seriesList, windowSize, xFilesFactor=None)  \nGraphs the moving average of a metric (or metrics) over a fixed number of past points, or a time interval.\n\nTakes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the average of the preceeding datapoints for each point on the graph.\n\nExample:\n\n``` none\n&target=movingAverage(Server.instance01.threads.busy,10)\n&target=movingAverage(Server.instance*.threads.idle,'5min')\n```\n\n&nbsp;\n\nmovingMax(seriesList, windowSize, xFilesFactor=None)  \nGraphs the moving maximum of a metric (or metrics) over a fixed number of past points, or a time interval.\n\nTakes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the maximum of the preceeding datapoints for each point on the graph.\n\nExample:\n\n``` none\n&target=movingMax(Server.instance01.requests,10)\n&target=movingMax(Server.instance*.errors,'5min')\n```\n\n&nbsp;\n\nmovingMedian(seriesList, windowSize, xFilesFactor=None)  \nGraphs the moving median of a metric (or metrics) over a fixed number of past points, or a time interval.\n\nTakes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the median of the preceeding datapoints for each point on the graph.\n\nExample:\n\n``` none\n&target=movingMedian(Server.instance01.threads.busy,10)\n&target=movingMedian(Server.instance*.threads.idle,'5min')\n```\n\n&nbsp;\n\nmovingMin(seriesList, windowSize, xFilesFactor=None)  \nGraphs the moving minimum of a metric (or metrics) over a fixed number of past points, or a time interval.\n\nTakes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the minimum of the preceeding datapoints for each point on the graph.\n\nExample:\n\n``` none\n&target=movingMin(Server.instance01.requests,10)\n&target=movingMin(Server.instance*.errors,'5min')\n```\n\n&nbsp;\n\nmovingSum(seriesList, windowSize, xFilesFactor=None)  \nGraphs the moving sum of a metric (or metrics) over a fixed number of past points, or a time interval.\n\nTakes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the sum of the preceeding datapoints for each point on the graph.\n\nExample:\n\n``` none\n&target=movingSum(Server.instance01.requests,10)\n&target=movingSum(Server.instance*.errors,'5min')\n```\n\n&nbsp;\n\nmovingWindow(seriesList, windowSize, func='average', xFilesFactor=None)  \nGraphs a moving window function of a metric (or metrics) over a fixed number of past points, or a time interval.\n\nTakes one metric or a wildcard seriesList, a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats), a function to apply to the points in the window to produce the output, and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the output of the function for the preceeding datapoints for each point on the graph.\n\nExample:\n\n``` none\n&target=movingWindow(Server.instance01.threads.busy,10)\n&target=movingWindow(Server.instance*.threads.idle,'5min','median',0.5)\n```\n\nNote\n\nxFilesFactor follows the same semantics as in Whisper storage schemas. Setting it to 0 (the default) means that only a single value in a given interval needs to be non-null, setting it to 1 means that all values in the interval must be non-null. A setting of 0.5 means that at least half the values in the interval must be non-null.\n\n&nbsp;\n\nmultiplySeries(\\*seriesLists)  \nTakes two or more series and multiplies their points. A constant may not be used. To multiply by a constant, use the scale() function.\n\nExample:\n\n``` none\n&target=multiplySeries(Series.dividends,Series.divisors)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `multiply`.\n\n&nbsp;\n\nmultiplySeriesWithWildcards(seriesList, \\*position)  \nCall multiplySeries after inserting wildcards at the given position(s).\n\nExample:\n\n``` none\n&target=multiplySeriesWithWildcards(web.host-[0-7].{avg-response,total-request}.value, 2)\n```\n\nThis would be the equivalent of\n\n``` none\n&target=multiplySeries(web.host-0.{avg-response,total-request}.value)&target=multiplySeries(web.host-1.{avg-response,total-request}.value)...\n```\n\nThis is an alias for [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards \"graphite.render.functions.aggregateWithWildcards\") with aggregation `multiply`.\n\n&nbsp;\n\nnPercentile(seriesList, n)  \nReturns n-percent of each series in the seriesList.\n\n&nbsp;\n\nnonNegativeDerivative(seriesList, maxValue=None)  \nSame as the derivative function above, but ignores datapoints that trend down. Useful for counters that increase for a long time, then wrap or reset. (Such as if a network interface is destroyed and recreated by unloading and re-loading a kernel module, common with USB / WiFi cards.\n\nExample:\n\n``` none\n&target=nonNegativederivative(company.server.application01.ifconfig.TXPackets)\n```\n\n&nbsp;\n\noffset(seriesList, factor)  \nTakes one metric or a wildcard seriesList followed by a constant, and adds the constant to each datapoint.\n\nExample:\n\n``` none\n&target=offset(Server.instance01.threads.busy,10)\n```\n\n&nbsp;\n\noffsetToZero(seriesList)  \nOffsets a metric or wildcard seriesList by subtracting the minimum value in the series from each datapoint.\n\nUseful to compare different series where the values in each series may be higher or lower on average but you’re only interested in the relative difference.\n\nAn example use case is for comparing different round trip time results. When measuring RTT (like pinging a server), different devices may come back with consistently different results due to network latency which will be different depending on how many network hops between the probe and the device. To compare different devices in the same graph, the network latency to each has to be factored out of the results. This is a shortcut that takes the fastest response (lowest number in the series) and sets that to zero and then offsets all of the other datapoints in that series by that amount. This makes the assumption that the lowest response is the fastest the device can respond, of course the more datapoints that are in the series the more accurate this assumption is.\n\nExample:\n\n``` none\n&target=offsetToZero(Server.instance01.responseTime)\n&target=offsetToZero(Server.instance*.responseTime)\n```\n\n&nbsp;\n\nperSecond(seriesList, maxValue=None)  \nNonNegativeDerivative adjusted for the series time interval This is useful for taking a running total metric and showing how many requests per second were handled.\n\nExample:\n\n``` none\n&target=perSecond(company.server.application01.ifconfig.TXPackets)\n```\n\nEach time you run ifconfig, the RX and TXPackets are higher (assuming there is network traffic.) By applying the perSecond function, you can get an idea of the packets per second sent or received, even though you’re only recording the total.\n\n&nbsp;\n\npercentileOfSeries(seriesList, n, interpolate=False)  \npercentileOfSeries returns a single series which is composed of the n-percentile values taken across a wildcard series at each point. Unless interpolate is set to True, percentile values are actual values contained in one of the supplied series.\n\n&nbsp;\n\npieAverage(series)  \nReturn the average\n\n&nbsp;\n\npieMaximum(series)  \nReturn the maximum\n\n&nbsp;\n\npieMinimum(series)  \nReturn the minimum\n\n&nbsp;\n\npow(seriesList, factor)  \nTakes one metric or a wildcard seriesList followed by a constant, and raises the datapoint by the power of the constant provided at each point.\n\nExample:\n\n``` none\n&target=pow(Server.instance01.threads.busy,10)\n&target=pow(Server.instance*.threads.busy,10)\n```\n\n&nbsp;\n\npowSeries(\\*seriesLists)  \nTakes two or more series and pows their points. A constant line may be used.\n\nExample:\n\n``` none\n&target=powSeries(Server.instance01.app.requests, Server.instance01.app.replies)\n```\n\n&nbsp;\n\nrandomWalkFunction(name, step=60)  \nShort Alias: randomWalk()\n\nReturns a random walk starting at 0. This is great for testing when there is no real data in whisper.\n\nExample:\n\n``` none\n&target=randomWalk(\"The.time.series\")\n```\n\nThis would create a series named “The.time.series” that contains points where x(t) == x(t-1)+random()-0.5, and x(0) == 0. Accepts optional second argument as ‘step’ parameter (default step is 60 sec)\n\n&nbsp;\n\nrangeOfSeries(\\*seriesLists)  \nTakes a wildcard seriesList. Distills down a set of inputs into the range of the series\n\nExample:\n\n``` none\n&target=rangeOfSeries(Server*.connections.total)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `rangeOf`.\n\n&nbsp;\n\nreduceSeries(seriesLists, reduceFunction, reduceNode, \\*reduceMatchers)  \nShort form: `reduce()`\n\nTakes a list of seriesLists and reduces it to a list of series by means of the reduceFunction.\n\nReduction is performed by matching the reduceNode in each series against the list of reduceMatchers. Then each series is passed to the reduceFunction as arguments in the order given by reduceMatchers. The reduceFunction should yield a single series.\n\nThe resulting list of series are aliased so that they can easily be nested in other functions.\n\n**Example**: Map/Reduce asPercent(bytes_used,total_bytes) for each server\n\nAssume that metrics in the form below exist:\n\n``` none\nservers.server1.disk.bytes_used\nservers.server1.disk.total_bytes\nservers.server2.disk.bytes_used\nservers.server2.disk.total_bytes\nservers.server3.disk.bytes_used\nservers.server3.disk.total_bytes\n...\nservers.serverN.disk.bytes_used\nservers.serverN.disk.total_bytes\n```\n\nTo get the percentage of disk used for each server:\n\n``` none\nreduceSeries(mapSeries(servers.*.disk.*,1),\"asPercent\",3,\"bytes_used\",\"total_bytes\") =>\n\n  alias(asPercent(servers.server1.disk.bytes_used,servers.server1.disk.total_bytes),\"servers.server1.disk.reduce.asPercent\"),\n  alias(asPercent(servers.server2.disk.bytes_used,servers.server2.disk.total_bytes),\"servers.server2.disk.reduce.asPercent\"),\n  alias(asPercent(servers.server3.disk.bytes_used,servers.server3.disk.total_bytes),\"servers.server3.disk.reduce.asPercent\"),\n  ...\n  alias(asPercent(servers.serverN.disk.bytes_used,servers.serverN.disk.total_bytes),\"servers.serverN.disk.reduce.asPercent\")\n```\n\nIn other words, we will get back the following metrics:\n\n``` default\nservers.server1.disk.reduce.asPercent\nservers.server2.disk.reduce.asPercent\nservers.server3.disk.reduce.asPercent\n...\nservers.serverN.disk.reduce.asPercent\n```\n\nSee also\n\n[`mapSeries()`](#graphite.render.functions.mapSeries \"graphite.render.functions.mapSeries\")\n\n&nbsp;\n\nremoveAbovePercentile(seriesList, n)  \nRemoves data above the nth percentile from the series or list of series provided. Values above this percentile are assigned a value of None.\n\n&nbsp;\n\nremoveAboveValue(seriesList, n)  \nRemoves data above the given threshold from the series or list of series provided. Values above this threshold are assigned a value of None.\n\n&nbsp;\n\nremoveBelowPercentile(seriesList, n)  \nRemoves data below the nth percentile from the series or list of series provided. Values below this percentile are assigned a value of None.\n\n&nbsp;\n\nremoveBelowValue(seriesList, n)  \nRemoves data below the given threshold from the series or list of series provided. Values below this threshold are assigned a value of None.\n\n&nbsp;\n\nremoveBetweenPercentile(seriesList, n)  \nRemoves series that do not have an value lying in the x-percentile of all the values at a moment\n\n&nbsp;\n\nremoveEmptySeries(seriesList, xFilesFactor=None)  \nTakes one metric or a wildcard seriesList. Out of all metrics passed, draws only the metrics with not empty data\n\nExample:\n\n``` none\n&target=removeEmptySeries(server*.instance*.threads.busy)\n```\n\nDraws only live servers with not empty data.\n\nxFilesFactor follows the same semantics as in Whisper storage schemas. Setting it to 0 (the default) means that only a single value in the series needs to be non-null for it to be considered non-empty, setting it to 1 means that all values in the series must be non-null. A setting of 0.5 means that at least half the values in the series must be non-null.\n\n&nbsp;\n\nroundFunction(seriesList, precision=None)  \nTakes one metric or a wildcard seriesList optionally followed by a precision, and rounds each datapoint to the specified precision.\n\nExample:\n\n``` none\n&target=round(Server.instance01.threads.busy)\n&target=round(Server.instance01.threads.busy,2)\n```\n\n&nbsp;\n\nscale(seriesList, factor)  \nTakes one metric or a wildcard seriesList followed by a constant, and multiplies the datapoint by the constant provided at each point.\n\nExample:\n\n``` none\n&target=scale(Server.instance01.threads.busy,10)\n&target=scale(Server.instance*.threads.busy,10)\n```\n\n&nbsp;\n\nscaleToSeconds(seriesList, seconds)  \nTakes one metric or a wildcard seriesList and returns “value per seconds” where seconds is a last argument to this functions.\n\nUseful in conjunction with derivative or integral function if you want to normalize its result to a known resolution for arbitrary retentions\n\n&nbsp;\n\nsecondYAxis(seriesList)  \nGraph the series on the secondary Y axis.\n\n&nbsp;\n\nseriesByTag(\\*tagExpressions)  \nReturns a SeriesList of series matching all the specified tag expressions.\n\nExample:\n\n``` none\n&target=seriesByTag(\"tag1=value1\",\"tag2!=value2\")\n```\n\nReturns a seriesList of all series that have tag1 set to value1, AND do not have tag2 set to value2.\n\nTags specifiers are strings, and may have the following formats:\n\n``` none\ntag=spec    tag value exactly matches spec\ntag!=spec   tag value does not exactly match spec\ntag=~value  tag value matches the regular expression spec\ntag!=~spec  tag value does not match the regular expression spec\n```\n\nAny tag spec that matches an empty value is considered to match series that don’t have that tag.\n\nAt least one tag spec must require a non-empty value.\n\nRegular expression conditions are treated as being anchored at the start of the value.\n\nSee [querying tagged series](tags#querying-tagged-series) for more detail.\n\n&nbsp;\n\nsetXFilesFactor(seriesList, xFilesFactor)  \nShort form: xFilesFactor()\n\nTakes one metric or a wildcard seriesList and an xFilesFactor value between 0 and 1\n\nWhen a series needs to be consolidated, this sets the fraction of values in an interval that must not be null for the consolidation to be considered valid. If there are not enough values then None will be returned for that interval.\n\n``` none\n&target=xFilesFactor(Sales.widgets.largeBlue, 0.5)\n&target=Servers.web01.sda1.free_space|consolidateBy('max')|xFilesFactor(0.5)\n```\n\nThe xFilesFactor set via this function is used as the default for all functions that accept an xFilesFactor parameter, all functions that aggregate data across multiple series and/or intervals, and [maxDataPoints](render_api#maxdatapoints) consolidation.\n\nA default for the entire render request can also be set using the [xFilesFactor](render_api#xfilesfactor) query parameter.\n\nNote\n\nxFilesFactor follows the same semantics as in Whisper storage schemas. Setting it to 0 (the default) means that only a single value in a given interval needs to be non-null, setting it to 1 means that all values in the interval must be non-null. A setting of 0.5 means that at least half the values in the interval must be non-null.\n\n&nbsp;\n\nsinFunction(name, amplitude=1, step=60)  \nShort Alias: sin()\n\nJust returns the sine of the current time. The optional amplitude parameter changes the amplitude of the wave.\n\nExample:\n\n``` none\n&target=sin(\"The.time.series\", 2)\n```\n\nThis would create a series named “The.time.series” that contains sin(x)\\*2. Accepts optional second argument as ‘amplitude’ parameter (default amplitude is 1) Accepts optional third argument as ‘step’ parameter (default step is 60 sec)\n\n&nbsp;\n\nsmartSummarize(seriesList, intervalString, func='sum', alignTo=None)  \nSmarter version of summarize.\n\nThe alignToFrom boolean parameter has been replaced by alignTo and no longer has any effect. Alignment can be to years, months, weeks, days, hours, and minutes.\n\nThis function can be used with aggregation functions `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `count`, `range`, `multiply` & `last`.\n\n&nbsp;\n\nsortBy(seriesList, func='average', reverse=False)  \nTakes one metric or a wildcard seriesList followed by an aggregation function and an optional `reverse` parameter.\n\nReturns the metrics sorted according to the specified function.\n\nExample:\n\n``` none\n&target=sortBy(server*.instance*.threads.busy,'max')\n```\n\nDraws the servers in ascending order by maximum.\n\n&nbsp;\n\nsortByMaxima(seriesList)  \nTakes one metric or a wildcard seriesList.\n\nSorts the list of metrics in descending order by the maximum value across the time period specified. Useful with the &areaMode=all parameter, to keep the lowest value lines visible.\n\nExample:\n\n``` none\n&target=sortByMaxima(server*.instance*.memory.free)\n```\n\n&nbsp;\n\nsortByMinima(seriesList)  \nTakes one metric or a wildcard seriesList.\n\nSorts the list of metrics by the lowest value across the time period specified, including only series that have a maximum value greater than 0.\n\nExample:\n\n``` none\n&target=sortByMinima(server*.instance*.memory.free)\n```\n\n&nbsp;\n\nsortByName(seriesList, natural=False, reverse=False)  \nTakes one metric or a wildcard seriesList. Sorts the list of metrics by the metric name using either alphabetical order or natural sorting. Natural sorting allows names containing numbers to be sorted more naturally, e.g: - Alphabetical sorting: server1, server11, server12, server2 - Natural sorting: server1, server2, server11, server12\n\n&nbsp;\n\nsortByTotal(seriesList)  \nTakes one metric or a wildcard seriesList.\n\nSorts the list of metrics in descending order by the sum of values across the time period specified.\n\n&nbsp;\n\nsquareRoot(seriesList)  \nTakes one metric or a wildcard seriesList, and computes the square root of each datapoint.\n\nExample:\n\n``` none\n&target=squareRoot(Server.instance01.threads.busy)\n```\n\n&nbsp;\n\nstacked(seriesLists, stackName='\\_\\_DEFAULT\\_\\_')  \nTakes one metric or a wildcard seriesList and change them so they are stacked. This is a way of stacking just a couple of metrics without having to use the stacked area mode (that stacks everything). By means of this a mixed stacked and non stacked graph can be made\n\nIt can also take an optional argument with a name of the stack, in case there is more than one, e.g. for input and output metrics.\n\nExample:\n\n``` none\n&target=stacked(company.server.application01.ifconfig.TXPackets, 'tx')\n```\n\n&nbsp;\n\nstddevSeries(\\*seriesLists)  \nTakes one metric or a wildcard seriesList. Draws the standard deviation of all metrics passed at each time.\n\nExample:\n\n``` none\n&target=stddevSeries(company.server.*.threads.busy)\n```\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `stddev`.\n\n&nbsp;\n\nstdev(seriesList, points, windowTolerance=0.1)  \nTakes one metric or a wildcard seriesList followed by an integer N. Draw the Standard Deviation of all metrics passed for the past N datapoints. If the ratio of null points in the window is greater than windowTolerance, skip the calculation. The default for windowTolerance is 0.1 (up to 10% of points in the window can be missing). Note that if this is set to 0.0, it will cause large gaps in the output anywhere a single point is missing.\n\nExample:\n\n``` none\n&target=stdev(server*.instance*.threads.busy,30)\n&target=stdev(server*.instance*.cpu.system,30,0.0)\n```\n\n&nbsp;\n\nsubstr(seriesList, start=0, stop=0)  \nTakes one metric or a wildcard seriesList followed by 1 or 2 integers. Assume that the metric name is a list or array, with each element separated by dots. Prints n - length elements of the array (if only one integer n is passed) or n - m elements of the array (if two integers n and m are passed). The list starts with element 0 and ends with element (length - 1).\n\nExample:\n\n``` none\n&target=substr(carbon.agents.hostname.avgUpdateTime,2,4)\n```\n\nThe label would be printed as “hostname.avgUpdateTime”.\n\n&nbsp;\n\nsumSeries(\\*seriesLists)  \nShort form: sum()\n\nThis will add metrics together and return the sum at each datapoint. (See integral for a sum over time)\n\nExample:\n\n``` none\n&target=sum(company.server.application*.requestsHandled)\n```\n\nThis would show the sum of all requests handled per minute (provided requestsHandled are collected once a minute). If metrics with different retention rates are combined, the coarsest metric is graphed, and the sum of the other metrics is averaged for the metrics with finer retention rates.\n\nThis is an alias for [`aggregate`](#graphite.render.functions.aggregate \"graphite.render.functions.aggregate\") with aggregation `sum`.\n\n&nbsp;\n\nsumSeriesWithWildcards(seriesList, \\*position)  \nCall sumSeries after inserting wildcards at the given position(s).\n\nExample:\n\n``` none\n&target=sumSeriesWithWildcards(host.cpu-[0-7].cpu-{user,system}.value, 1)\n```\n\nThis would be the equivalent of\n\n``` none\n&target=sumSeries(host.cpu-[0-7].cpu-user.value)&target=sumSeries(host.cpu-[0-7].cpu-system.value)\n```\n\nThis is an alias for [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards \"graphite.render.functions.aggregateWithWildcards\") with aggregation `sum`.\n\n&nbsp;\n\nsummarize(seriesList, intervalString, func='sum', alignToFrom=False)  \nSummarize the data into interval buckets of a certain size.\n\nBy default, the contents of each interval bucket are summed together. This is useful for counters where each increment represents a discrete event and retrieving a “per X” value requires summing all the events in that interval.\n\nSpecifying ‘average’ instead will return the mean for each bucket, which can be more useful when the value is a gauge that represents a certain value in time.\n\nThis function can be used with aggregation functions `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `count`, `range`, `multiply` & `last`.\n\nBy default, buckets are calculated by rounding to the nearest interval. This works well for intervals smaller than a day. For example, 22:32 will end up in the bucket 22:00-23:00 when the interval=1hour.\n\nPassing alignToFrom=true will instead create buckets starting at the from time. In this case, the bucket for 22:32 depends on the from time. If from=6:30 then the 1hour bucket for 22:32 is 22:30-23:30.\n\nExample:\n\n``` none\n&target=summarize(counter.errors, \"1hour\") # total errors per hour\n&target=summarize(nonNegativeDerivative(gauge.num_users), \"1week\") # new users per week\n&target=summarize(queue.size, \"1hour\", \"avg\") # average queue size per hour\n&target=summarize(queue.size, \"1hour\", \"max\") # maximum queue size during each hour\n&target=summarize(metric, \"13week\", \"avg\", true)&from=midnight+20100101 # 2010 Q1-4\n```\n\n&nbsp;\n\nthreshold(value, label=None, color=None)  \nTakes a float F, followed by a label (in double quotes) and a color. (See `bgcolor` in the [Render API](render_api) for valid color names & formats.)\n\nDraws a horizontal line at value F across the graph.\n\nExample:\n\n``` none\n&target=threshold(123.456, \"omgwtfbbq\", \"red\")\n```\n\n&nbsp;\n\ntimeFunction(name, step=60)  \nShort Alias: time()\n\nJust returns the timestamp for each X value. T\n\nExample:\n\n``` none\n&target=time(\"The.time.series\")\n```\n\nThis would create a series named “The.time.series” that contains in Y the same value (in seconds) as X. Accepts optional second argument as ‘step’ parameter (default step is 60 sec)\n\n&nbsp;\n\ntimeShift(seriesList, timeShift, resetEnd=True, alignDST=False)  \nTakes one metric or a wildcard seriesList, followed by a quoted string with the length of time (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats).\n\nDraws the selected metrics shifted in time. If no sign is given, a minus sign ( - ) is implied which will shift the metric back in time. If a plus sign ( + ) is given, the metric will be shifted forward in time.\n\nWill reset the end date range automatically to the end of the base stat unless resetEnd is False. Example case is when you timeshift to last week and have the graph date range set to include a time in the future, will limit this timeshift to pretend ending at the current time. If resetEnd is False, will instead draw full range including future time.\n\nBecause time is shifted by a fixed number of seconds, comparing a time period with DST to a time period without DST, and vice-versa, will result in an apparent misalignment. For example, 8am might be overlaid with 7am. To compensate for this, use the alignDST option.\n\nUseful for comparing a metric against itself at a past periods or correcting data stored at an offset.\n\nExample:\n\n``` none\n&target=timeShift(Sales.widgets.largeBlue,\"7d\")\n&target=timeShift(Sales.widgets.largeBlue,\"-7d\")\n&target=timeShift(Sales.widgets.largeBlue,\"+1h\")\n```\n\n&nbsp;\n\ntimeSlice(seriesList, startSliceAt, endSliceAt='now')  \nTakes one metric or a wildcard metric, followed by a quoted string with the time to start the line and another quoted string with the time to end the line. The start and end times are inclusive. See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats.\n\nUseful for filtering out a part of a series of data from a wider range of data.\n\nExample:\n\n``` none\n&target=timeSlice(network.core.port1,\"00:00 20140101\",\"11:59 20140630\")\n&target=timeSlice(network.core.port1,\"12:00 20140630\",\"now\")\n```\n\n&nbsp;\n\ntimeStack(seriesList, timeShiftUnit='1d', timeShiftStart=0, timeShiftEnd=7)  \nTakes one metric or a wildcard seriesList, followed by a quoted string with the length of time (See `from`` ``/`` ``until` in the [Render API](render_api) for examples of time formats). Also takes a start multiplier and end multiplier for the length of time\n\ncreate a seriesList which is composed the original metric series stacked with time shifts starting time shifts from the start multiplier through the end multiplier\n\nUseful for looking at history, or feeding into averageSeries or stddevSeries.\n\nExample:\n\n``` none\n&target=timeStack(Sales.widgets.largeBlue,\"1d\",0,7)    # create a series for today and each of the previous 7 days\n```\n\n&nbsp;\n\ntransformNull(seriesList, default=0, referenceSeries=None)  \nTakes a metric or wildcard seriesList and replaces null values with the value specified by default. The value 0 used if not specified. The optional referenceSeries, if specified, is a metric or wildcard series list that governs which time intervals nulls should be replaced. If specified, nulls are replaced only in intervals where a non-null is found for the same interval in any of referenceSeries. This method compliments the drawNullAsZero function in graphical mode, but also works in text-only mode.\n\nExample:\n\n``` none\n&target=transformNull(webapp.pages.*.views,-1)\n```\n\nThis would take any page that didn’t have values and supply negative 1 as a default. Any other numeric value may be used as well.\n\n&nbsp;\n\nunique(\\*seriesLists)  \nTakes an arbitrary number of seriesLists and returns unique series, filtered by name.\n\nExample:\n\n``` none\n&target=unique(mostDeviant(server.*.disk_free,5),lowestCurrent(server.*.disk_free,5))\n```\n\nDraws servers with low disk space, and servers with highly deviant disk space, but never the same series twice.\n\n&nbsp;\n\nuseSeriesAbove(seriesList, value, search, replace)  \nCompares the maximum of each series against the given value. If the series maximum is greater than value, the regular expression search and replace is applied against the series name to plot a related metric\n\ne.g. given useSeriesAbove(ganglia.metric1.reqs,10,’reqs’,’time’), the response time metric will be plotted only when the maximum value of the corresponding request/s metric is \\> 10\n\n``` none\n&target=useSeriesAbove(ganglia.metric1.reqs,10,\"reqs\",\"time\")\n```\n\n&nbsp;\n\nverticalLine(ts, label=None, color=None)  \nTakes a timestamp string ts.\n\nDraws a vertical line at the designated timestamp with optional ‘label’ and ‘color’. Supported timestamp formats include both relative (e.g. -3h) and absolute (e.g. 16:00_20110501) strings, such as those used with `from` and `until` parameters. When set, the ‘label’ will appear in the graph legend.\n\nNote: Any timestamps defined outside the requested range will raise a ‘ValueError’ exception.\n\nExample:\n\n``` none\n&target=verticalLine(\"12:3420131108\",\"event\",\"blue\")\n&target=verticalLine(\"16:00_20110501\",\"event\")\n&target=verticalLine(\"-5mins\")\n```\n\n&nbsp;\n\nweightedAverage(seriesListAvg, seriesListWeight, \\*nodes)  \nTakes a series of average values and a series of weights and produces a weighted average for all values. The corresponding values should share one or more zero-indexed nodes and/or tags.\n\nExample:\n\n``` none\n&target=weightedAverage(*.transactions.mean,*.transactions.count,0)\n```\n\nEach node may be an integer referencing a node in the series name or a string identifying a tag.\n\n## Function Plugins\n\nFunction plugins can define additional functions for use in render calls.\n\nA function plugin is simply a file defining one or more functions and exporting dictionaries of `SeriesFunctions` and/or `PieFunctions`. When Graphite loads the plugin it will add functions in `SeriesFunctions` and/or `PieFunctions` to the list of available functions.\n\nEach exposed function must accept at least a `requestContext` and `seriesList` parameter, and may accept additional parameters as needed.\n\n`requestContext` will be a dictionary as defined in `graphite.render.views.renderView()`, `seriesList` will be a list of `TimeSeries` objects.\n\n``` python\nfrom graphite.functions.params import Param, ParamTypes\n\ndef toUpperCase(requestContext, seriesList):\n  \"\"\"Custom function that changes series names to UPPERCASE\"\"\"\n  for series in seriesList:\n    series.name = series.name.upper()\n  return seriesList\n\n# optionally set the group attribute\ntoUpperCase.group = 'Custom'\ntoUpperCase.params = [\n  Param('seriesList', ParamTypes.seriesList, required=True),\n]\n\nSeriesFunctions = {\n  'upper': toUpperCase,\n}\n```\n\nEach function can have a docstring, `.group`, and `.params` attributes defined, these are used in the function API output as hints for query builders.\n\nThe `.group` attribute is the group name as a string, the `.params` attribute is a list of parameter definitions.\n\nEach parameter definition is `Param` object, the `Param` constructor accepts the following arguments (note that requestContext is not included in the list of parameters):\n\n- **name**: The name of the parameter\n- **paramtype**: The parameter type, one of:\n  - **ParamTypes.aggFunc**: An aggregation function name\n  - **ParamTypes.boolean**: True/False\n  - **ParamTypes.date**: A date specification\n  - **ParamTypes.float**: A float value\n  - **ParamTypes.integer**: An integer value\n  - **ParamTypes.interval**: An interval specifier like `1h`, `1d`, etc\n  - **ParamTypes.intOrInterval**: An integer or interval specifier\n  - **ParamTypes.node**: A node number\n  - **ParamTypes.nodeOrTag**: A node number or tag name\n  - **ParamTypes.series**: A single series\n  - **ParamTypes.seriesList**: A list of series\n  - **ParamTypes.seriesLists**: A list of seriesLists\n  - **ParamTypes.string**: A string value\n  - **ParamTypes.tag**: A tag name\n- **required**: Set to `True` for required parameters\n- **default**: Default value for optional parameters\n- **multiple**: Set to `True` for parameters that accept multiple instances (defined with `*` in Python)\n- **options**: A list of available values for parameters that accept only a defined list\n- **suggestions**: A list of suggested values for parameters that accept free-form values\n\nCustom plugin files may be placed in the `/opt/graphite/webapp/graphite/functions/custom` folder and will be loaded automatically when graphite starts.\n\nTo load a packaged function plugin module, add it to the `FUNCTION_PLUGINS` setting:\n\n``` python\nFUNCTION_PLUGINS = [\n  'some.function_plugin',\n]\n```\n\n## Function API\n\nYou can use the HTTP api to get a list of available functions, or the details of a specific function.\n\nTo get a list of available functions:\n\n``` none\n$ curl -s \"http://graphite/functions?pretty=1\"\n\n{\n  \"absolute\": {\n    \"description\": \"<function description>\",\n    \"function\": \"absolute(seriesList)\",\n    \"group\": \"Transform\",\n    \"module\": \"graphite.render.functions\",\n    \"name\": \"absolute\",\n    \"params\": [\n      {\n        \"name\": \"seriesList\",\n        \"required\": true,\n        \"type\": \"seriesList\"\n      }\n    ]\n  },\n  <more functions...>\n}\n```\n\nIf the parameter `grouped=1` is passed, the returned list will be organized by group:\n\n``` none\n$ curl -s \"http://graphite/functions?pretty=1&grouped=1\"\n\n{\n  \"Alias\": {\n    <alias functions...>\n  },\n  <more groups...>\n}\n```\n\nTo get the definition of a specific function:\n\n``` none\n$ curl -s \"http://graphite/functions/absolute?pretty=1\"\n\n{\n  \"description\": \"<function description>\",\n  \"function\": \"absolute(seriesList)\",\n  \"group\": \"Transform\",\n  \"module\": \"graphite.render.functions\",\n  \"name\": \"absolute\",\n  \"params\": [\n    {\n      \"name\": \"seriesList\",\n      \"required\": true,\n      \"type\": \"seriesList\"\n    }\n  ]\n}\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/functions.html](https://graphite.readthedocs.io/en/latest/functions.html)"
- name: General Settings
  id: config-local-settings#general-settings
  summary: Set the URL_PREFIX when deploying graphite-web to a non-root location
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ## General Settings

    URL_PREFIX

    Default: /

    Set the URL_PREFIX when deploying graphite-web to a non-root location.

    SECRET_KEY

    Default: UNSAFE_DEFAULT

    This key is used for salting of hashes used in auth tokens, CRSF middleware, cookie storage, etc. This should be set identically among all nodes if used behind a load balancer.

    ALLOWED_HOSTS

    Default: \*

    In Django 1.5+ set the list of hosts from where your graphite instances is accessible. See: [https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-ALLOWED_HOSTS](https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-ALLOWED_HOSTS)

    TIME_ZONE

    Default: America/Chicago

    Set your local timezone. Timezone is specified using [zoneinfo names](http://en.wikipedia.org/wiki/Zoneinfo#Names_of_time_zones).

    DATE_FORMAT

    Default: %m/%d

    Set the default short date format. See strftime(3) for supported sequences.

    DOCUMENTATION_URL

    Default: http://graphite.readthedocs.io/

    Overrides the Documentation link used in the header of the Graphite Composer.

    LOG_RENDERING_PERFORMANCE

    Default: False

    Triggers the creation of `rendering.log` which logs timings for calls to the [The Render URL API](render_api).

    LOG_CACHE_PERFORMANCE

    Default: False

    Triggers the creation of `cache.log` which logs timings for remote calls to carbon-cache as well as Request Cache (memcached) hits and misses.

    DEBUG = True

    Default: False

    Enables generation of detailed Django error pages. See [Django’s documentation](https://docs.djangoproject.com/en/dev/ref/settings/#debug) for details.

    FLUSHRRDCACHED

    Default: \<unset\>

    If set, executes `rrdtool``flushcached` before fetching data from RRD files. Set to the address or socket of the rrdcached daemon. Ex: `unix:/var/run/rrdcached.sock`

    MEMCACHE_HOSTS

    Default: \[\]

    If set, enables the caching of calculated targets (including applied functions) and rendered images. If running a cluster of Graphite webapps, each webapp should have the exact same values for this setting to prevent unneeded cache misses.

    Set this to the list of memcached hosts. Ex: `['10.10.10.10:11211',``'10.10.10.11:11211',``'10.10.10.12:11211']`

    MEMCACHE_KEY_PREFIX

    Default: graphite

    Memcached prefix for graphite keys.

    MEMCACHE_OPTIONS

    Default: {}

    Accepted options depend on the Memcached implementation and the Django version. Until Django 1.10, options are used only for pylibmc. Starting from 1.11, options are used for both python-memcached and pylibmc.

    DEFAULT_CACHE_DURATION

    Default: 60

    Default expiration of cached data and images.

    DEFAULT_CACHE_POLICY

    Default: \[\]

    Metric data and graphs are cached for one minute by default. If defined, DEFAULT_CACHE_POLICY is a list of tuples of minimum query time ranges mapped to the cache duration for the results. This allows for larger queries to be cached for longer periods of times. All times are in seconds. An example configuration:

    ``` default
    DEFAULT_CACHE_POLICY = [(0, 60), # default is 60 seconds
                            (7200, 120), # >= 2 hour queries are cached 2 minutes
                            (21600, 180)] # >= 6 hour queries are cached 3 minutes
    ```

    This will cache any queries between 0 seconds and 2 hours for 1 minute, any queries between 2 and 6 hours for 2 minutes, and anything greater than 6 hours for 3 minutes. If the policy is empty or undefined, everything will be cached for DEFAULT_CACHE_DURATION.

    AUTO_REFRESH_INTERVAL

    Default: 60

    Interval for the Auto-Refresh feature in the Composer, measured in seconds.

    MAX_TAG_LENGTH

    Default: 50

    Graphite uses Django Tagging to support tags in Events. By default each tag is limited to 50 characters.
- name: Getting Started with the Dashboard Interface
  id: dashboard#getting-started-with-the-dashboard-interface
  summary: You can access the Dashboard interface directly at http://my.graphite.host/dashboard, or via the link at the top of the Composer interface
  belongs_to: The Dashboard User Interface
  description: |-
    ## Getting Started with the Dashboard Interface

    You can access the Dashboard interface directly at `http://my.graphite.host/dashboard`, or via the link at the top of the Composer interface.
- name: Graph Parameters
  id: render_api#graph-parameters
  summary: null
  belongs_to: The Render URL API
  description: '## Graph Parameters'
- name: Graphing Metrics
  id: render_api#graphing-metrics
  summary: To begin graphing specific metrics, pass one or more target parameters and specify a time window for the graph via from / until
  belongs_to: The Render URL API
  description: |-
    ## Graphing Metrics

    To begin graphing specific metrics, pass one or more [target](#target) parameters and specify a time window for the graph via [from / until](#from-until).
- name: Graphite Events
  id: events
  summary: Graphite is well known for storing simple key/value metrics using the Whisper time-series database on-disk format
  description: "# Graphite Events\n\nGraphite is well known for storing simple key/value metrics using the Whisper time-series database on-disk format. What is not well known about Graphite is that it also ships with a feature known as **Events** that supports a richer form of metrics storage suitable for irregular events often associated with metadata.\n\nExamples of data appropriate for this storage format include releases, commits, application exceptions, and state changes where you may wish to track or correlate the event with traditional time-series activity.\n\n## Database Storage\n\nAs Whisper was designed to hold simple time-series data (metric key, value, and timestamp), it’s altogether unsuitable for storing rich metric data such as events. Many users continue to store simple event-type data (e.g. releases, state changes, etc) in Whisper by encoding its meaning within the metric namespace and rendering them as a vertical line with Graphite’s [drawAsInfinite](functions#graphite.render.functions.drawAsInfinite) function.\n\nHowever, taking advantage of this pattern typically requires the use of wildcards across a significant number of these singleton metric files and directories, which can cause a significant performance hit on the server and result in a poor experience for users. To accommodate this more sophisticated use case, Graphite’s webapp database was extended to support this new metric type.\n\nNote\n\nEvents require Graphite webapp version 0.9.9 or newer.\n\n## Adding Events\n\nEvents can be submitted via HTTP POST using command-line tools such as `curl` or with a variety of HTTP programming libraries. The JSON format is simple and predictable.\n\n``` none\n$ curl -X POST \"http://graphite/events/\"\n    -d '{ \"what\": \"Event - deploy\", \"tags\": [\"deploy\"], \"when\": 1467844481,\n    \"data\": \"deploy of master branch happened at Wed Jul  6 22:34:41 UTC 2016\" }'\n```\n\n`when` is an optional key which is set to the current Unix timestamp if `when` is not set.\n\n*Note*: Prior to 0.10.0, the value of `tags` is a string, with multiple tags being separated by a space.\n\n## Querying Events\n\nGraphite allows you to query for tags associated with events. You can search for a single tag string, a combination of space-delimited tags, or a simple `*` wildcard using the [events](functions#graphite.render.functions.events) function.\n\n``` none\n$ curl -s \"http://graphite/render/?target=events('exception')&format=json\" | json_pp\n\n[\n   {\n      \"target\" : \"events(exception)\",\n      \"datapoints\" : [\n         [\n            1,\n            1388966651\n         ],\n         [\n            3,\n            1388966652\n         ]\n      ]\n   }\n]\n```\n\nIt’s also possible to dump the raw events using the API.\n\n``` none\n$ curl -s \"http://graphite/events/get_data?tags=deploy&from=-3hours&until=now\" | json_pp\n\n[\n   {\n      \"when\" : 1392046352,\n      \"tags\" : [\"deploy\"],\n      \"data\" : \"deploy of master branch happened at Fri Jan 3 22:34:41 UTC 2014\",\n      \"id\" : 2,\n      \"what\" : \"Event - deploy\"\n   },\n   {\n      \"id\" : 3,\n      \"what\" : \"Event - deploy\",\n      \"when\" : 1392046661,\n      \"tags\" : [\"deploy\"],\n      \"data\" : \"deploy of master branch happened at Fri Jan 3 22:34:41 UTC 2014\"\n   }\n]\n```\n\nThe `set` parameter accepts an optional `union` or `intersection` argument to determine the behavior for filtering sets of tags (i.e. inclusive or exclusive). By default, Graphite uses a “lazy union” that will return any matching events for a given tag in a list of tags. This behavior is not intuitive and will therefore be deprecated in a future release.\n\n## Managing Events in the Admin UI\n\nEvents can be managed using the Graphite [administration module](admin-webapp). This is particularly handy for deleting a large number of events at once, although it also supports adding and editing individual events.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/events.html](https://graphite.readthedocs.io/en/latest/events.html)"
- name: Graphite Tag Support
  id: tags
  summary: From the release of the 1.1.x series, Graphite supports storing data using tags to identify each series
  description: "# Graphite Tag Support\n\nFrom the release of the 1.1.x series, Graphite supports storing data using tags to identify each series. This allows for much more flexibility than the traditional hierarchical layout. When using tag support, each series is uniquely identified by its name and set of tag/value pairs.\n\n## Carbon\n\nTo enter tagged series into Graphite, they should be passed to Carbon by appending the tags to the series name:\n\n``` none\nmy.series;tag1=value1;tag2=value2\n```\n\nCarbon will automatically decode the tags, normalize the tag order, and register the series in the tag database.\n\n## Querying\n\nWhen querying tagged series, we start with the [seriesByTag](functions#graphite.render.functions.seriesByTag) function:\n\n``` none\n# find all series that have tag1 set to value1\nseriesByTag('tag1=value1')\n```\n\nThis function returns a seriesList that can then be used by any other Graphite functions:\n\n``` none\n# find all series that have tag1 set to value1, sorted by total\nseriesByTag('tag1=value1') | sortByTotal()\n```\n\nThe [seriesByTag](functions#graphite.render.functions.seriesByTag) function supports specifying any number of tag expressions to refine the list of matches. When multiple tag expressions are specified, only series that match all the expressions will be returned.\n\nTags expressions are strings, and may have the following formats:\n\n``` none\ntag=spec    tag value exactly matches spec\ntag!=spec   tag value does not exactly match spec\ntag=~value  tag value matches the regular expression spec\ntag!=~spec  tag value does not match the regular expression spec\n```\n\nAny tag spec that matches an empty value is considered to match series that don’t have that tag, and at least one tag spec must require a non-empty value.\n\nRegular expression conditions are treated as being anchored at the start of the value.\n\nA more complex example:\n\n``` none\n# find all series where name matches the regular expression cpu\\..*, AND tag1 is not value1\nseriesByTag('name=~cpu\\..*', 'tag1!=value1')\n```\n\nOnce you have selected a seriesList, it is possible to group series together using the [groupByTags](functions#graphite.render.functions.groupByTags) function, which operates on tags in the same way that [groupByNodes](functions#graphite.render.functions.groupByNodes) works on nodes within a traditional naming hierarchy.\n\n``` none\n# get a list of disk space used per datacenter for all webheads\nseriesByTag('name=disk.used', 'server=~web.*') | groupByTags('sumSeries', 'datacenter')\n\n# given series like:\n# disk.used;datacenter=dc1;rack=a1;server=web01\n# disk.used;datacenter=dc1;rack=b2;server=web02\n# disk.used;datacenter=dc2;rack=c3;server=web01\n# disk.used;datacenter=dc2;rack=d4;server=web02\n\n# will return the following new series, each containing the sum of the values for that datacenter:\n# disk.used;datacenter=dc1\n# disk.used;datacenter=dc2\n```\n\nFinally, the [aliasByTags](functions#graphite.render.functions.aliasByTags) function is used to help format series names for display. It is the tag-based equivalent of the [aliasByNode](functions#graphite.render.functions.aliasByNode) function.\n\n``` none\n# given series like:\n# disk.used;datacenter=dc1;rack=a1;server=web01\n# disk.used;datacenter=dc1;rack=b2;server=web02\n\n# format series name using datacenter tag:\nseriesByTag('name=disk.used','datacenter=dc1') | aliasByTags('server', 'name')\n\n# will return\n# web01.disk.used\n# web02.disk.used\n```\n\n## Database Storage\n\nAs Whisper and other storage backends are designed to hold simple time-series data (metric key, value, and timestamp), Graphite stores tag information in a separate tag database (TagDB). The TagDB is a pluggable store, by default it uses the Graphite SQLite, MySQL or PostgreSQL database, but it can also be configured to use an external Redis server or a custom plugin.\n\nNote\n\nTag support requires Graphite webapp & carbon version 1.1.1 or newer.\n\n### Local Database TagDB\n\nThe Local TagDB stores tag information in tables inside the graphite-web database. It supports SQLite, MySQL and Postgres, and is enabled by default.\n\n### Redis TagDB\n\nThe Redis TagDB will store the tag information on a Redis server, and is selected by setting `TAGDB='graphite.tags.redis.RedisTagDB'` in local_settings.py. There are 3 additional config settings for the Redis TagDB:\n\n``` default\nTAGDB_REDIS_HOST = 'localhost'\nTAGDB_REDIS_PORT = 6379\nTAGDB_REDIS_DB = 0\n```\n\nThe default settings (above) will connect to a local Redis server on the default port, and use the default database.\n\n### HTTP(S) TagDB\n\nThe HTTP(S) TagDB is used to delegate all tag operations to an external server that implements the Graphite tagging HTTP API. It can be used in clustered graphite scenarios, or with custom data stores. It is selected by setting `TAGDB='graphite.tags.http.HttpTagDB'` in local_settings.py. There are 4 additional config settings for the HTTP(S) TagDB:\n\n``` default\nTAGDB_HTTP_URL = 'https://another.server'\nTAGDB_HTTP_USER = ''\nTAGDB_HTTP_PASSWORD = ''\nTAGDB_HTTP_AUTOCOMPLETE = False\n```\n\nThe `TAGDB_HTTP_URL` is required. `TAGDB_HTTP_USER` and `TAGDB_HTTP_PASSWORD` are optional and if specified will be used to send a Basic Authorization header in all requests.\n\n`TAGDB_HTTP_AUTOCOMPLETE` is also optional, if set to `True` auto-complete requests will be forwarded to the remote TagDB, otherwise calls to /tags/findSeries, /tags & /tags/\\<tag\\> will be used to provide auto-complete functionality.\n\nIf `REMOTE_STORE_FORWARD_HEADERS` is defined, those headers will also be forwarded to the remote TagDB.\n\n## Adding Series to the TagDB\n\nNormally carbon will take care of this, it submits all new series to the TagDB, and periodically re-submits all series to ensure that the TagDB is kept up to date. There are 2 carbon configuration settings related to tagging; the GRAPHITE_URL setting specifies the url of your graphite-web installation (default http://127.0.0.1:8000), and the TAG_UPDATE_INTERVAL setting specifies how often each series should be re-submitted to the TagDB (default is every 100th update).\n\nSeries can be submitted via HTTP POST using command-line tools such as `curl` or with a variety of HTTP programming libraries.\n\n``` none\n$ curl -X POST \"http://graphite/tags/tagSeries\" \\\n  --data-urlencode 'path=disk.used;rack=a1;datacenter=dc1;server=web01'\n\n\"disk.used;datacenter=dc1;rack=a1;server=web01\"\n```\n\nThis endpoint returns the canonicalized version of the path, with the tags sorted in alphabetical order.\n\nTo add multiple series with a single HTTP request, use the `/tags/tagMultiSeries` endpoint, which support multiple `path` parameters:\n\n``` none\n$ curl -X POST \"http://graphite/tags/tagMultiSeries\" \\\n  --data-urlencode 'path=disk.used;rack=a1;datacenter=dc1;server=web01' \\\n  --data-urlencode 'path=disk.used;rack=a1;datacenter=dc1;server=web02' \\\n  --data-urlencode 'pretty=1'\n\n[\n  \"disk.used;datacenter=dc1;rack=a1;server=web01\",\n  \"disk.used;datacenter=dc1;rack=a1;server=web02\"\n]\n```\n\nThis endpoint returns a list of the canonicalized paths, in the same order they are specified.\n\n## Exploring Tags\n\nYou can use the HTTP api to get lists of defined tags, values for each tag, and to find series using the same logic as the [seriesByTag](functions#graphite.render.functions.seriesByTag) function.\n\nTo get a list of defined tags:\n\n``` none\n$ curl -s \"http://graphite/tags?pretty=1\"\n\n[\n  {\n    \"tag\": \"datacenter\"\n  },\n  {\n    \"tag\": \"name\"\n  },\n  {\n    \"tag\": \"rack\"\n  },\n  {\n    \"tag\": \"server\"\n  }\n]\n```\n\nYou can filter the returned list by providing a regular expression in the filter parameter:\n\n``` none\n$ curl -s \"http://graphite/tags?pretty=1&filter=data\"\n\n[\n  {\n    \"tag\": \"datacenter\"\n  }\n]\n```\n\nTo get a list of values for a specific tag:\n\n``` none\n$ curl -s \"http://graphite/tags/datacenter?pretty=1\"\n\n{\n  \"tag\": \"datacenter\",\n  \"values\": [\n    {\n      \"count\": 2,\n      \"value\": \"dc1\"\n    },\n    {\n      \"count\": 2,\n      \"value\": \"dc2\"\n    }\n  ]\n}\n```\n\nYou can filter the returned list of values using the filter parameter:\n\n``` none\n$ curl -s \"http://graphite/tags/datacenter?pretty=1&filter=dc1\"\n\n{\n  \"tag\": \"datacenter\",\n  \"values\": [\n    {\n      \"count\": 2,\n      \"value\": \"dc1\"\n    }\n  ]\n}\n```\n\nFinally, to search for series matching a set of tag expressions:\n\n``` none\n$ curl -s \"http://graphite/tags/findSeries?pretty=1&expr=datacenter=dc1&expr=server=web01\"\n\n[\n  \"disk.used;datacenter=dc1;rack=a1;server=web01\"\n]\n```\n\n## Auto-complete Support\n\nThe HTTP api provides 2 endpoints to support auto-completion of tags and values based on the series which match a provided set of tag expressions.\n\nEach of these endpoints accepts an optional list of tag expressions using the same syntax as the /tags/findSeries endpoint.\n\nThe provided expressions are used to filter the results, so that the suggested list of tags will only include tags that occur in series matching the expressions.\n\nResults are limited to 100 by default, this can be overridden by passing limit=X in the request parameters. The returned JSON is a compact representation by default, if pretty=1 is passed in the request parameters the returned JSON will be formatted with newlines and indentation.\n\nTo get an auto-complete list of tags:\n\n``` none\n$ curl -s \"http://graphite/tags/autoComplete/tags?pretty=1&limit=100\"\n\n[\n  \"datacenter\",\n  \"name\",\n  \"rack\",\n  \"server\"\n]\n```\n\nTo filter by prefix:\n\n``` none\n$ curl -s \"http://graphite/tags/autoComplete/tags?pretty=1&tagPrefix=d\"\n\n[\n  \"datacenter\"\n]\n```\n\nIf you provide a list of tag expressions, the specified tags are excluded and the result is filtered to only tags that occur in series matching those expressions:\n\n``` none\n$ curl -s \"http://graphite/tags/autoComplete/tags?pretty=1&expr=datacenter=dc1&expr=server=web01\"\n\n[\n  \"name\",\n  \"rack\"\n]\n```\n\nTo get an auto-complete list of values for a specified tag:\n\n``` none\n$ curl -s \"http://graphite/tags/autoComplete/values?pretty=1&tag=rack\"\n\n[\n  \"a1\",\n  \"a2\",\n  \"b1\",\n  \"b2\"\n]\n```\n\nTo filter by prefix:\n\n``` none\n$ curl -s \"http://graphite/tags/autoComplete/values?pretty=1&tag=rack&valuePrefix=a\"\n\n[\n  \"a1\",\n  \"a2\"\n]\n```\n\nIf you provide a list of tag expressions, the result is filtered to only values that occur for the specified tag in series matching those expressions:\n\n``` none\n$ curl -s \"http://graphite/tags/autoComplete/values?pretty=1&tag=rack&expr=datacenter=dc1&expr=server=web01\"\n\n[\n  \"a1\"\n]\n```\n\n## Removing Series from the TagDB\n\nWhen a series is deleted from the data store (for example, by deleting .wsp files from the whisper storage folders), it should also be removed from the tag database. Having series in the tag database that don’t exist in the data store won’t cause any problems with graphing, but will cause the system to do work that isn’t needed during the graph rendering, so it is recommended that the tag database be cleaned up when series are removed from the data store.\n\nSeries can be deleted via HTTP POST to the /tags/delSeries endpoint:\n\n``` none\n$ curl -X POST \"http://graphite/tags/delSeries\" \\\n  --data-urlencode 'path=disk.used;datacenter=dc1;rack=a1;server=web01'\n\ntrue\n```\n\nTo delete multiple series at once pass multiple `path` parameters:\n\n``` none\n$ curl -X POST \"http://graphite/tags/delSeries\" \\\n  --data-urlencode 'path=disk.used;datacenter=dc1;rack=a1;server=web01' \\\n  --data-urlencode 'path=disk.used;datacenter=dc1;rack=a1;server=web02'\n\ntrue\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/tags.html](https://graphite.readthedocs.io/en/latest/tags.html)"
- name: Graphite Terminology
  id: terminology
  summary: Graphite uses many terms that can have ambiguous meaning
  description: "# Graphite Terminology\n\nGraphite uses many terms that can have ambiguous meaning. The following definitions are what these terms mean in the context of Graphite.\n\ndatapoint  \nA [value](#term-value) stored at a [timestamp bucket](#term-timestamp-bucket). If no value is recorded at a particular timestamp bucket in a [series](#term-series), the value will be None (null).\n\nfunction  \nA time-series function which transforms, combines, or performs computations on one or more [series](#term-series). See [Functions](functions)\n\nmetric  \nSee [series](#term-series)\n\nmetric series  \nSee [series](#term-series)\n\nprecision  \nSee [resolution](#term-resolution)\n\nresolution  \nThe number of seconds per datapoint in a [series](#term-series). Series are created with a resolution which determines how often a [datapoint](#term-datapoint) may be stored. This resolution is represented as the number of seconds in time that each datapoint covers. A series which stores one datapoint per minute has a resolution of 60 seconds. Similarly, a series which stores one datapoint per second has a resolution of 1 second.\n\nretention  \nThe number of datapoints retained in a [series](#term-series). Alternatively: The length of time datapoints are stored in a series.\n\nseries  \nA named set of datapoints. A series is identified by a unique name, which is composed of elements separated by periods (`.`) which are used to display the collection of series into a hierarchical tree. A series storing system load average on a server called `apache02` in datacenter `metro_east` might be named as `metro_east.servers.apache02.system.load_average`\n\nseries list  \nA series name or wildcard which matches one or more [series](#term-series). Series lists are received by [functions](#term-function) as a list of matching series. From a user perspective, a series list is merely the name of a metric. For example, each of these would be considered a single series list:\n\n- `metro_east.servers.apache02.system.load_average.1_min`,\n- `metro_east.servers.apache0{1,2,3}.system.load_average.1_min`\n- `metro_east.servers.apache01.system.load_average.*`\n\ntarget  \nA source of data used as input for a Graph. A target can be a single metric name, a metric wildcard, or either of these enclosed within one or more [functions](#term-function)\n\ntimestamp  \nA point in time in which [values](#term-value) can be associated. Time in Graphite is represented as [epoch time](http://en.wikipedia.org/wiki/Epoch_time) with a maximum resolution of 1-second.\n\ntimestamp bucket  \nA [timestamp](#term-timestamp) after rounding down to the nearest multiple of a [series’s](#term-series) [resolution](#term-resolution).\n\nvalue  \nA numeric or null value. Values are stored as double-precision floats. Values are parsed using the python `float()` constructor and can also be None (null). The range and precision of values is system dependent and can be found by executing (with Python 2.6 or later):: python -c ‘import sys; print sys.float_info’\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/terminology.html](https://graphite.readthedocs.io/en/latest/terminology.html)"
- name: Graphite-web’s local_settings.py
  id: config-local-settings
  summary: Graphite-web uses the convention of importing a local_settings.py file from the webapp settings.py module
  description: "# Graphite-web’s local_settings.py\n\nGraphite-web uses the convention of importing a `local_settings.py` file from the webapp `settings.py` module. This is where Graphite-web’s runtime configuration is loaded from. Also alternate local settings module can be set (see below). This may be usable for multi-instance deployments.\n\n## Config File Location\n\nBy default settings module is `local_settings.py` and it is generally located within the main `graphite` module where the webapp’s code lives. In the [default installation layout](install#default-installation-layout) this is `/opt/graphite/webapp/graphite/local_settings.py`. Alternative locations can be used by symlinking to this path or by ensuring the module can be found within the Python module search path.\n\nThis can be change by setting `GRAPHITE_SETTINGS_MODULE` environment variable. For example in a wsgi file.\n\n## General Settings\n\nURL_PREFIX  \nDefault: /\n\nSet the URL_PREFIX when deploying graphite-web to a non-root location.\n\nSECRET_KEY  \nDefault: UNSAFE_DEFAULT\n\nThis key is used for salting of hashes used in auth tokens, CRSF middleware, cookie storage, etc. This should be set identically among all nodes if used behind a load balancer.\n\nALLOWED_HOSTS  \nDefault: \\*\n\nIn Django 1.5+ set the list of hosts from where your graphite instances is accessible. See: [https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-ALLOWED_HOSTS](https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-ALLOWED_HOSTS)\n\nTIME_ZONE  \nDefault: America/Chicago\n\nSet your local timezone. Timezone is specified using [zoneinfo names](http://en.wikipedia.org/wiki/Zoneinfo#Names_of_time_zones).\n\nDATE_FORMAT  \nDefault: %m/%d\n\nSet the default short date format. See strftime(3) for supported sequences.\n\nDOCUMENTATION_URL  \nDefault: http://graphite.readthedocs.io/\n\nOverrides the Documentation link used in the header of the Graphite Composer.\n\nLOG_RENDERING_PERFORMANCE  \nDefault: False\n\nTriggers the creation of `rendering.log` which logs timings for calls to the [The Render URL API](render_api).\n\nLOG_CACHE_PERFORMANCE  \nDefault: False\n\nTriggers the creation of `cache.log` which logs timings for remote calls to carbon-cache as well as Request Cache (memcached) hits and misses.\n\nDEBUG = True  \nDefault: False\n\nEnables generation of detailed Django error pages. See [Django’s documentation](https://docs.djangoproject.com/en/dev/ref/settings/#debug) for details.\n\nFLUSHRRDCACHED  \nDefault: \\<unset\\>\n\nIf set, executes `rrdtool`` ``flushcached` before fetching data from RRD files. Set to the address or socket of the rrdcached daemon. Ex: `unix:/var/run/rrdcached.sock`\n\nMEMCACHE_HOSTS  \nDefault: \\[\\]\n\nIf set, enables the caching of calculated targets (including applied functions) and rendered images. If running a cluster of Graphite webapps, each webapp should have the exact same values for this setting to prevent unneeded cache misses.\n\nSet this to the list of memcached hosts. Ex: `['10.10.10.10:11211',`` ``'10.10.10.11:11211',`` ``'10.10.10.12:11211']`\n\nMEMCACHE_KEY_PREFIX  \nDefault: graphite\n\nMemcached prefix for graphite keys.\n\nMEMCACHE_OPTIONS  \nDefault: {}\n\nAccepted options depend on the Memcached implementation and the Django version. Until Django 1.10, options are used only for pylibmc. Starting from 1.11, options are used for both python-memcached and pylibmc.\n\nDEFAULT_CACHE_DURATION  \nDefault: 60\n\nDefault expiration of cached data and images.\n\nDEFAULT_CACHE_POLICY  \nDefault: \\[\\]\n\nMetric data and graphs are cached for one minute by default. If defined, DEFAULT_CACHE_POLICY is a list of tuples of minimum query time ranges mapped to the cache duration for the results. This allows for larger queries to be cached for longer periods of times. All times are in seconds. An example configuration:\n\n``` default\nDEFAULT_CACHE_POLICY = [(0, 60), # default is 60 seconds\n                        (7200, 120), # >= 2 hour queries are cached 2 minutes\n                        (21600, 180)] # >= 6 hour queries are cached 3 minutes\n```\n\nThis will cache any queries between 0 seconds and 2 hours for 1 minute, any queries between 2 and 6 hours for 2 minutes, and anything greater than 6 hours for 3 minutes. If the policy is empty or undefined, everything will be cached for DEFAULT_CACHE_DURATION.\n\nAUTO_REFRESH_INTERVAL  \nDefault: 60\n\nInterval for the Auto-Refresh feature in the Composer, measured in seconds.\n\nMAX_TAG_LENGTH  \nDefault: 50\n\nGraphite uses Django Tagging to support tags in Events. By default each tag is limited to 50 characters.\n\n## Filesystem Paths\n\nThese settings configure the location of Graphite-web’s additional configuration files, static content, and data. These need to be adjusted if Graphite-web is installed outside of the [default installation layout](install#default-installation-layout).\n\nGRAPHITE_ROOT  \nDefault: /opt/graphite The base directory for the Graphite install. This setting is used to shift the Graphite install from the default base directory which keeping the [default layout](install#default-installation-layout). The paths derived from this setting can be individually overridden as well.\n\nCONF_DIR  \nDefault: GRAPHITE_ROOT/conf The location of additional Graphite-web configuration files.\n\nSTORAGE_DIR  \nDefault: GRAPHITE_ROOT/storage The base directory from which WHISPER_DIR, RRD_DIR, CERES_DIR, LOG_DIR, and INDEX_FILE default paths are referenced.\n\nSTATIC_ROOT  \nDefault: See below The location of Graphite-web’s static content. This defaults to `static/` three parent directories up from `settings.py`. In the [default layout](install#default-installation-layout) this is `/opt/graphite/static`.\n\nThis directory doesn’t even exist once you’ve installed graphite. It needs to be populated with the following command:\n\n``` default\nPYTHONPATH=$GRAPHITE_ROOT/webapp django-admin.py collectstatic --noinput --settings=graphite.settings\n```\n\nThis collects static files for graphite-web and external apps (namely, the Django admin app) and puts them in a directory that needs to be available under the `/static/` URL of your web server. To configure Apache:\n\n``` default\nAlias /static/ \"/opt/graphite/static\"\n```\n\nFor Nginx:\n\n``` default\nlocation /static/ {\n    alias /opt/graphite/static/;\n}\n```\n\nAlternatively, static files can be served directly by the Graphite webapp if you install the `whitenoise` Python package.\n\nDASHBOARD_CONF  \nDefault: CONF_DIR/dashboard.conf The location of the Graphite-web Dashboard configuration.\n\nGRAPHTEMPLATES_CONF  \nDefault: CONF_DIR/graphTemplates.conf The location of the Graphite-web Graph Template configuration.\n\nWHISPER_DIR  \nDefault: /opt/graphite/storage/whisper The location of Whisper data files.\n\nCERES_DIR  \nDefault: /opt/graphite/storage/ceres The location of Ceres data files.\n\nRRD_DIR  \nDefault: /opt/graphite/storage/rrd The location of RRD data files.\n\nSTANDARD_DIRS  \nDefault: \\[WHISPER_DIR, RRD_DIR\\] The list of directories searched for data files. By default, this is the value of WHISPER_DIR and RRD_DIR (if rrd support is detected). If this setting is defined, the WHISPER_DIR, CERES_DIR, and RRD_DIR settings have no effect.\n\nLOG_DIR  \nDefault: STORAGE_DIR/log/webapp The directory to write Graphite-web’s log files. This directory must be writable by the user running the Graphite-web webapp.\n\nINDEX_FILE  \nDefault: /opt/graphite/storage/index The location of the search index file. This file is generated by the build-index.sh script and must be writable by the user running the Graphite-web webapp.\n\nSTORAGE_FINDERS  \nDefault: () It is possible to use an alternate storage layer than the default, Whisper, in order to accommodate specific needs. See: [http://graphite.readthedocs.io/en/latest/storage-backends.html](http://graphite.readthedocs.io/en/latest/storage-backends.html)\n\nFETCH_TIMEOUT  \nDefault: 6\n\nTimeout for data fetches in seconds.\n\nFIND_TIMEOUT  \nDefault: 3\n\nTimeout for find requests (metric browsing) in seconds.\n\nTAGDB  \nDefault: ‘graphite.tags.localdatabase.LocalDatabaseTagDB’ Tag database driver to use, other options include graphite.tags.redis.RedisTagDB\n\nTAGDB_REDIS_HOST  \nDefault: ‘localhost’ Redis host to use with TAGDB = ‘graphite.tags.redis.RedisTagDB’\n\nTAGDB_REDIS_PORT  \nDefault: 6379 Redis port to use with TAGDB = ‘graphite.tags.redis.RedisTagDB’\n\nTAGDB_REDIS_DB  \nDefault: 0 Redis database to use with TAGDB = ‘graphite.tags.redis.RedisTagDB’\n\n## Configure Webserver (Apache)\n\nThere is an example `example-graphite-vhost.conf` file in the examples directory of the graphite web source code. You can use this to configure apache. Different distributions have different ways of configuring Apache. Please refer to your distribution’s documentation on the subject.\n\nFor example, Ubuntu uses `/etc/apache2/sites-available` and `sites-enabled/` to handle this (A symlink from `sites-enabled/` to `sites-available/` would be used after placing the file in sites-available/).\n\nOthers use an Include directive in the `httpd.conf` file like this:\n\n``` none\n# This goes in httpd.conf\nInclude /usr/local/apache2/conf/vhosts.d/*.conf\n```\n\nThe configuration files must then all be added to `/usr/local/apache2/conf/vhosts.d/`. Still others may not help handle this at all and you must add the configuration to your http.conf file directly.\n\nGraphite will be in the DocumentRoot of your webserver, and will not allow you to access plain-HTML in subdirectories without addition configuration. You may want to edit the `example-graphite-vhost.conf` file to change port numbers or use additional `\"SetHandler`` ``None\"` directives to allow access to other directories.\n\nBe sure to reload your Apache configuration by running `sudo`` ``/etc/init.d/apache2`` ``reload` or `sudo`` ``/etc/init.d/httpd`` ``reload`.\n\n## Email Configuration\n\nThese settings configure Django’s email functionality which is used for emailing rendered graphs. See the [Django documentation](https://docs.djangoproject.com/en/dev/topics/email/) for further detail on these settings.\n\nEMAIL_BACKEND  \nDefault: django.core.mail.backends.smtp.EmailBackend Set to `django.core.mail.backends.dummy.EmailBackend` to drop emails on the floor and effectively disable email features.\n\nEMAIL_HOST  \nDefault: localhost\n\nEMAIL_PORT  \nDefault: 25\n\nEMAIL_HOST_USER  \nDefault: ‘’\n\nEMAIL_HOST_PASSWORD  \nDefault: ‘’\n\nEMAIL_USE_TLS  \nDefault: False\n\n## Authentication Configuration\n\nThese settings insert additional backends to the [AUTHENTICATION_BACKENDS](https://docs.djangoproject.com/en/dev/ref/settings/#authentication-backends) and [MIDDLEWARE settings](https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-MIDDLEWARE). Additional authentication schemes are possible by manipulating these lists directly.\n\n### LDAP\n\nThese settings configure a custom LDAP authentication backend provided by Graphite. Additional settings to the ones below are configurable setting the LDAP module’s global options using `ldap.set_option`. See the [module documentation](http://python-ldap.org/) for more details.\n\n``` none\n# SSL Example\nimport ldap\nldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_ALLOW)\nldap.set_option(ldap.OPT_X_TLS_CACERTDIR, \"/etc/ssl/ca\")\nldap.set_option(ldap.OPT_X_TLS_CERTFILE, \"/etc/ssl/mycert.pem\")\nldap.set_option(ldap.OPT_X_TLS_KEYFILE, \"/etc/ssl/mykey.pem\")\n```\n\nUSE_LDAP_AUTH  \nDefault: False\n\nLDAP_SERVER  \nDefault: ‘’\n\nSet the LDAP server here or alternately in `LDAP_URI`.\n\nLDAP_PORT  \nDefault: 389\n\nSet the LDAP server port here or alternately in `LDAP_URI`.\n\nLDAP_URI  \nDefault: None\n\nSets the LDAP server URI. E.g. `ldaps://ldap.mycompany.com:636`\n\nLDAP_SEARCH_BASE  \nDefault: ‘’\n\nSets the LDAP search base. E.g. `OU=users,DC=mycompany,DC=com`\n\nLDAP_BASE_USER  \nDefault: ‘’\n\nSets the base LDAP user to bind to the server with. E.g. `CN=some_readonly_account,DC=mycompany,DC=com`\n\nLDAP_BASE_PASS  \nDefault: ‘’\n\nSets the password of the base LDAP user to bind to the server with.\n\nLDAP_USER_QUERY  \nDefault: ‘’\n\nSets the LDAP query to return a user object where `%s` substituted with the user id. E.g. `(username=%s)` or `(sAMAccountName=%s)` (Active Directory).\n\nLDAP_USER_DN_TEMPLATE:  \nDefault: ‘’\n\nInstead of using a hardcoded username and password for the account that binds to the LDAP server you could use the credentials of the user that tries to log in to Graphite. This is the template that creates the full DN to bind with.\n\n### Other Authentications\n\nUSE_REMOTE_USER_AUTHENTICATION  \nDefault: False\n\nEnables the use of the Django RemoteUserBackend authentication backend. See the [Django documentation](https://docs.djangoproject.com/en/dev/howto/auth-remote-user/) for further details.\n\nREMOTE_USER_BACKEND  \nDefault: “django.contrib.auth.middleware.RemoteUserBackend”\n\nEnables the use of an alternative remote authentication backend.\n\nREMOTE_USER_MIDDLEWARE  \nDefault: “django.contrib.auth.middleware.RemoteUserMiddleware”\n\nEnables the use of an alternative remote authentication middleware.\n\nLOGIN_URL  \nDefault: /account/login\n\nModifies the URL linked in the Login link in the Composer interface. This is useful for directing users to an external authentication link such as for Remote User authentication or a backend such as [django_openid_auth](https://launchpad.net/django-openid-auth).\n\n## Dashboard Authorization Configuration\n\nThese settings control who is allowed to save and delete dashboards. By default anyone can perform these actions, but by setting DASHBOARD_REQUIRE_AUTHENTICATION, users must at least be logged in to do so. The other two settings allow further restriction of who is able to perform these actions. Users who are not suitably authorized will still be able to use and change dashboards, but will not be able to save changes or delete dashboards.\n\nDASHBOARD_REQUIRE_AUTHENTICATION  \nDefault: False\n\nIf set to True, dashboards can only be saved and deleted by logged in users.\n\nDASHBOARD_REQUIRE_EDIT_GROUP  \nDefault: None\n\nIf set to the name of a user group, dashboards can only be saved and deleted by logged-in users who are members of this group. Groups can be set in the Django Admin app, or in LDAP.\n\nNote that DASHBOARD_REQUIRE_AUTHENTICATION must be set to true - if not, this setting is ignored.\n\nDASHBOARD_REQUIRE_PERMISSIONS  \nDefault: False\n\nIf set to True, dashboards can only be saved or deleted by users having the appropriate (change or delete) permission (as set in the Django Admin app). These permissions can be set at the user or group level. Note that Django’s ‘add’ permission is not used.\n\nNote that DASHBOARD_REQUIRE_AUTHENTICATION must be set to true - if not, this setting is ignored.\n\n## Database Configuration\n\nThe following configures the Django database settings. Graphite uses the database for storing user profiles, dashboards, and for the Events functionality. Graphite uses an SQLite database file located at `STORAGE_DIR/graphite.db` by default. If running multiple Graphite-web instances, a database such as PostgreSQL or MySQL is required so that all instances may share the same data source.\n\nNote\n\nAs of Django 1.2, the database configuration is specified by the DATABASES dictionary instead of the old `DATABASE_*` format. Users must use the new specification to have a working database.\n\nSee the [Django documentation](https://docs.djangoproject.com/en/dev/ref/settings/#databases) for full documentation of the DATABASES setting.\n\nNote\n\nRemember, setting up a new database requires running `PYTHONPATH=$GRAPHITE_ROOT/webapp`` ``django-admin.py`` ``migrate`` ``--settings=graphite.settings`` ``--run-syncdb` to create the initial schema.\n\nNote\n\nIf you are using a custom database backend (other than SQLite) you must first create a $GRAPHITE_ROOT/webapp/graphite/local_settings.py file that overrides the database related settings from settings.py. Use $GRAPHITE_ROOT/webapp/graphite/local_settings.py.example as a template.\n\nIf you are experiencing problems, uncomment the following line in /opt/graphite/webapp/graphite/local_settings.py:\n\n``` none\n# DEBUG = True\n```\n\nand review your webapp logs. If you’re using the default graphite-example-vhost.conf, your logs will be found in /opt/graphite/storage/log/webapp/.\n\nIf you’re using the default SQLite database, your webserver will need permissions to read and write to the database file. So, for example, if your webapp is running in Apache as the ‘nobody’ user, you will need to fix the permissions like this:\n\n``` none\nsudo chown nobody:nobody /opt/graphite/storage/graphite.db\n```\n\n## Cluster Configuration\n\nThese settings configure the Graphite webapp for clustered use. When `CLUSTER_SERVERS` is set, metric browse and render requests will cause the webapp to query other webapps in CLUSTER_SERVERS for matching metrics. Graphite can either merge responses or choose the best response if more than one cluster server returns the same series.\n\nCLUSTER_SERVERS  \nDefault: \\[\\]\n\nThe list of IP addresses and ports of remote Graphite webapps in a cluster. Each of these servers should have local access to metric data to serve. Ex: \\[“10.0.2.2:80”, “[http://10.0.2.3:80?format=pickle&local=1](http://10.0.2.3:80?format=pickle&local=1)”\\]\n\nCluster server definitions can optionally include a protocol ([http://](#) or [https://](#)) and/or additional config parameters.\n\nThe format parameter can be set to pickle (the default) or msgpack to control the encoding used for intra-cluster find and render requests.\n\nThe local parameter can be set to 1 (the default) or 0 to control whether cluster servers should only return results from local finders, or fan the request out to their remote finders.\n\nUSE_WORKER_POOL  \nDefault: True\n\nCreates a pool of worker threads to which tasks can be dispatched. This makes sense if there are multiple CLUSTER_SERVERS and/or STORAGE_FINDERS because then the communication with them can be parallelized. The number of threads is equal to: min(number of finders, POOL_MAX_WORKERS)\n\nBe careful when increasing the number of threads, in particular if your start multiple graphite-web processes (with uwsgi or similar) as this will increase memory consumption (and number of connections to memcached).\n\nPOOL_MAX_WORKERS  \nDefault: 10\n\n> The maximum number of worker threads that should be created.\n\nREMOTE_RETRY_DELAY  \nDefault: 60\n\nTime in seconds to blacklist a webapp after a timed-out request.\n\nFIND_CACHE_DURATION  \nDefault: 300\n\nTime to cache remote metric find results in seconds.\n\nMAX_FETCH_RETRIES  \nDefault: 2\n\nNumber of retries for a specific remote data fetch.\n\nFIND_TOLERANCE  \nDefault: FIND_TOLERANCE = 2 \\* FIND_CACHE_DURATION\n\nIf the query doesn’t fall entirely within the FIND_TOLERANCE window we disregard the window. This prevents unnecessary remote fetches caused when carbon’s cache skews node.intervals, giving the appearance remote systems have data we don’t have locally, which we probably do.\n\nREMOTE_STORE_MERGE_RESULTS  \nDefault: True\n\nDuring a rebalance of a consistent hash cluster, after a partition event on a replication \\> 1 cluster or in other cases we might receive multiple TimeSeries data for a metric key. Merge them together rather than choosing the “most complete” one (pre-0.9.14 behaviour).\n\nREMOTE_STORE_USE_POST  \nDefault: False\n\nThis setting enables POST queries instead of GET for remote requests.\n\nREMOTE_STORE_FORWARD_HEADERS  \nDefault: \\[\\]\n\nProvide a list of HTTP headers that you want forwarded on from this host when making a request to a remote webapp server in CLUSTER_SERVERS.\n\nREMOTE_EXCLUDE_LOCAL  \nDefault: False\n\nTry to detect when a cluster server is localhost and don’t forward queries\n\nREMOTE_RENDERING  \nDefault: False\n\nEnable remote rendering of images and data (JSON, et al.) on remote Graphite webapps. If this is enabled, `RENDERING_HOSTS` must also be enabled and configured accordingly.\n\nRENDERING_HOSTS  \nDefault: \\[\\]\n\nList of IP addresses and ports of remote Graphite webapps used to perform rendering. Each webapp must have access to the same data as the Graphite webapp which uses this setting either through shared local storage or via `CLUSTER_SERVERS`. Ex: \\[“10.0.2.4:80”, “10.0.2.5:80”\\]\n\nREMOTE_RENDER_CONNECT_TIMEOUT  \nDefault: 1.0\n\nConnection timeout for remote rendering requests in seconds.\n\nCARBONLINK_HOSTS  \nDefault: \\[127.0.0.1:7002\\]\n\nIf multiple carbon-caches are running on this machine, each should be listed here so that the Graphite webapp may query the caches for data that has not yet been persisted. Remote carbon-cache instances in a multi-host clustered setup should *not* be listed here. Instance names should be listed as applicable. Ex: \\[‘127.0.0.1:7002:a’,‘127.0.0.1:7102:b’, ‘127.0.0.1:7202:c’\\]\n\nCARBONLINK_TIMEOUT  \nDefault: 1.0\n\nTimeout for carbon-cache cache queries in seconds.\n\nCARBONLINK_HASHING_TYPE  \nDefault: carbon_ch\n\nPossible values: carbon_ch, fnv1a_ch\n\nThe default carbon_ch is Graphite’s traditional consistent-hashing implementation. Alternatively, you can use fnv1a_ch, which supports the Fowler–Noll–Vo hash function (FNV-1a) hash implementation offered by the [carbon-c-relay relay](https://github.com/grobian/carbon-c-relay) project.\n\nCARBON_METRIC_PREFIX:  \nDefault: carbon\n\nPrefix for internal carbon statistics.\n\nINTRACLUSTER_HTTPS  \nDefault: False\n\nThis setting controls whether https is used to communicate between cluster members that don’t have an explicit protocol specified.\n\n## Additional Django Settings\n\nThe `local_settings.py.example` shipped with Graphite-web imports `app_settings.py` into the namespace to allow further customization of Django. This allows the setting or customization of standard [Django settings](https://docs.djangoproject.com/en/dev/ref/settings/) and the installation and configuration of additional [middleware](https://docs.djangoproject.com/en/dev/topics/http/middleware/).\n\nTo manipulate these settings, ensure `app_settings.py` is imported as such:\n\n``` python\nfrom graphite.app_settings import *\n```\n\nThe most common settings to manipulate are `INSTALLED_APPS`, `MIDDLEWARE`, and `AUTHENTICATION_BACKENDS`.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-local-settings.html](https://graphite.readthedocs.io/en/latest/config-local-settings.html)"
- name: Graphitejs
  id: client-apis#graphitejs
  summary: Graphitejs is a jQuery plugin for easily making and displaying graphs and updating them on the fly using the Graphite URL api
  belongs_to: Client APIs
  description: |-
    ## Graphitejs

    [Graphitejs](https://github.com/prestontimmons/graphitejs) is a jQuery plugin for easily making and displaying graphs and updating them on the fly using the Graphite URL api.
- name: graphOnly
  id: render_api#graphonly
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### graphOnly

    *Default: False*

    Display only the graph area with no grid lines, axes, or legend
- name: graphType
  id: render_api#graphtype
  summary: Sets the type of graph to be rendered
  belongs_to: The Render URL API
  description: |-
    ### graphType

    *Default: line*

    Sets the type of graph to be rendered. Currently there are only two graph types:

    ` ``line`` `

    A line graph displaying metrics as lines over time

    ` ``pie`` `

    A pie graph with each slice displaying an aggregate of each metric calculated using the function specified by [pieMode](#piemode)
- name: grep()
  id: functions#graphite.render.functions.grep
  summary: Takes a metric or a wildcard seriesList, followed by a regular expression in double quotes
  belongs_to: Functions
  description: |-
    grep(seriesList, pattern)

    Takes a metric or a wildcard seriesList, followed by a regular expression in double quotes. Excludes metrics that don’t match the regular expression.

    Example:

    ``` none
    &target=grep(servers*.instance*.threads.busy,"server02")
    ```
- name: group()
  id: functions#graphite.render.functions.group
  summary: Takes an arbitrary number of seriesLists and adds them to a single seriesList
  belongs_to: Functions
  description: |-
    group(\*seriesLists)

    Takes an arbitrary number of seriesLists and adds them to a single seriesList. This is used to pass multiple seriesLists to a function which only takes one
- name: groupByNode()
  id: functions#graphite.render.functions.groupByNode
  summary: Node may be an integer referencing a node in the series name or a string identifying a tag
  belongs_to: Functions
  description: |-
    groupByNode(seriesList, nodeNum, callback='average')

    Takes a serieslist and maps a callback to subgroups within as defined by a common node

    ``` none
    &target=groupByNode(ganglia.by-function.*.*.cpu.load5,2,"sumSeries")
    ```

    Would return multiple series which are each the result of applying the “sumSeries” function to groups joined on the second node (0 indexed) resulting in a list of targets like

    ``` none
    sumSeries(ganglia.by-function.server1.*.cpu.load5),sumSeries(ganglia.by-function.server2.*.cpu.load5),...
    ```

    Node may be an integer referencing a node in the series name or a string identifying a tag.

    This is an alias for using [`groupByNodes`](#graphite.render.functions.groupByNodes "graphite.render.functions.groupByNodes") with a single node.
- name: groupByNodes()
  id: functions#graphite.render.functions.groupByNodes
  summary: 'This function can be used with all aggregation functions supported by aggregate: average, median, sum, min, max, diff, stddev, range & multiply'
  belongs_to: Functions
  description: |-
    groupByNodes(seriesList, callback, \*nodes)

    Takes a serieslist and maps a callback to subgroups within as defined by multiple nodes

    ``` none
    &target=groupByNodes(ganglia.server*.*.cpu.load*,"sum",1,4)
    ```

    Would return multiple series which are each the result of applying the “sum” aggregation to groups joined on the nodes’ list (0 indexed) resulting in a list of targets like

    ``` none
    sumSeries(ganglia.server1.*.cpu.load5),sumSeries(ganglia.server1.*.cpu.load10),sumSeries(ganglia.server1.*.cpu.load15),sumSeries(ganglia.server2.*.cpu.load5),sumSeries(ganglia.server2.*.cpu.load10),sumSeries(ganglia.server2.*.cpu.load15),...
    ```

    This function can be used with all aggregation functions supported by [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate"): `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range` & `multiply`.

    Each node may be an integer referencing a node in the series name or a string identifying a tag.

    ``` none
    &target=seriesByTag("name=~cpu.load.*", "server=~server[1-9]+", "datacenter=~dc[1-9]+")|groupByNodes("average", "datacenter", 1)

    # will produce output series like
    # dc1.load5, dc2.load5, dc1.load10, dc2.load10
    ```

    This complements [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards "graphite.render.functions.aggregateWithWildcards") which takes a list of wildcard nodes.
- name: groupByTags()
  id: functions#graphite.render.functions.groupByTags
  summary: 'This function can be used with all aggregation functions supported by aggregate: average, median, sum, min, max, diff, stddev, range & multiply'
  belongs_to: Functions
  description: |-
    groupByTags(seriesList, callback, \*tags)

    Takes a serieslist and maps a callback to subgroups within as defined by multiple tags

    ``` none
    &target=seriesByTag("name=cpu")|groupByTags("average","dc")
    ```

    Would return multiple series which are each the result of applying the “averageSeries” function to groups joined on the specified tags resulting in a list of targets like

    ``` none
    averageSeries(seriesByTag("name=cpu","dc=dc1")),averageSeries(seriesByTag("name=cpu","dc=dc2")),...
    ```

    This function can be used with all aggregation functions supported by [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate"): `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `range` & `multiply`.
- name: Gunicorn
  id: install-virtualenv#gunicorn
  summary: Ensure Gunicorn is installed in the activated virtualenv and execute as normal
  belongs_to: Installing in Virtualenv
  description: |-
    ### Gunicorn

    Ensure [Gunicorn](http://gunicorn.org/) is installed in the activated virtualenv and execute as normal. If gunicorn is installed system-wide, it may be necessary to execute it from the virtualenv’s bin path
- name: height
  id: render_api#height
  summary: Sets the height of the generated graph image in pixels
  belongs_to: The Render URL API
  description: |-
    ### height

    *Default: 250*

    Sets the height of the generated graph image in pixels.

    See also: [width](#width)

    Example:

    ``` none
    &width=650&height=250
    ```
- name: Help! It didn’t work!
  id: install#help-it-didn-t-work
  summary: 'If you run into any issues with Graphite, please to post a question to our Questions forum on Launchpad or join us on IRC in #graphite on FreeNode'
  belongs_to: Installing Graphite
  description: |-
    ## Help! It didn’t work!

    If you run into any issues with Graphite, please to post a question to our [Questions forum on Launchpad](https://answers.launchpad.net/graphite) or join us on IRC in \#graphite on FreeNode.
- name: hideAxes
  id: render_api#hideaxes
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### hideAxes

    *Default: False*

    If set to `true` the X and Y axes will not be rendered

    Example:

    ``` none
    &hideAxes=true
    ```
- name: hideGrid
  id: render_api#hidegrid
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### hideGrid

    *Default: False*

    If set to `true` the grid lines will not be rendered

    Example:

    ``` none
    &hideGrid=true
    ```
- name: hideLegend
  id: render_api#hidelegend
  summary: If set to true, the legend is not drawn
  belongs_to: The Render URL API
  description: |-
    ### hideLegend

    *Default: \<unset\>*

    If set to `true`, the legend is not drawn. If set to `false`, the legend is drawn. If unset, the `LEGEND_MAX_ITEMS` settings in `local_settings.py` is used to determine whether or not to display the legend.

    Hint: If set to `false` the `&height` parameter may need to be increased to accommodate the additional text.

    Example:

    ``` none
    &hideLegend=false
    ```
- name: hideNullFromLegend
  id: render_api#hidenullfromlegend
  summary: If set to true, series with all null values will not be reported in the legend
  belongs_to: The Render URL API
  description: |-
    ### hideNullFromLegend

    *Default: False*

    If set to `true`, series with all null values will not be reported in the legend.

    Example:

    ``` none
    &hideNullFromLegend=true
    ```
- name: hideXAxis
  id: render_api#hidexaxis
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### hideXAxis

    *Default: False*

    If set to `true` the X Axis will not be rendered
- name: hideYAxis
  id: render_api#hideyaxis
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### hideYAxis

    *Default: False*

    If set to `true` the Y Axis will not be rendered
- name: highest()
  id: functions#graphite.render.functions.highest
  summary: Takes one metric or a wildcard seriesList followed by an integer N and an aggregation function
  belongs_to: Functions
  description: |-
    highest(seriesList, n=1, func='average')

    Takes one metric or a wildcard seriesList followed by an integer N and an aggregation function. Out of all metrics passed, draws only the N metrics with the highest aggregated value over the time period specified.

    Example:

    ``` none
    &target=highest(server*.instance*.threads.busy,5,'max')
    ```

    Draws the 5 servers with the highest number of busy threads.
- name: highestAverage()
  id: functions#graphite.render.functions.highestAverage
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    highestAverage(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the top N metrics with the highest average value for the time period specified.

    Example:

    ``` none
    &target=highestAverage(server*.instance*.threads.busy,5)
    ```

    Draws the top 5 servers with the highest average value.

    This is an alias for [`highest`](#graphite.render.functions.highest "graphite.render.functions.highest") with aggregation `average`.
- name: highestCurrent()
  id: functions#graphite.render.functions.highestCurrent
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    highestCurrent(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the N metrics with the highest value at the end of the time period specified.

    Example:

    ``` none
    &target=highestCurrent(server*.instance*.threads.busy,5)
    ```

    Draws the 5 servers with the highest busy threads.

    This is an alias for [`highest`](#graphite.render.functions.highest "graphite.render.functions.highest") with aggregation `current`.
- name: highestMax()
  id: functions#graphite.render.functions.highestMax
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    highestMax(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N.

    Out of all metrics passed, draws only the N metrics with the highest maximum value in the time period specified.

    Example:

    ``` none
    &target=highestMax(server*.instance*.threads.busy,5)
    ```

    Draws the top 5 servers who have had the most busy threads during the time period specified.

    This is an alias for [`highest`](#graphite.render.functions.highest "graphite.render.functions.highest") with aggregation `max`.
- name: hitcount()
  id: functions#graphite.render.functions.hitcount
  summary: Estimate hit counts from a list of time series
  belongs_to: Functions
  description: |-
    hitcount(seriesList, intervalString, alignToInterval=False)

    Estimate hit counts from a list of time series.

    This function assumes the values in each time series represent hits per second. It calculates hits per some larger interval such as per day or per hour. This function is like summarize(), except that it compensates automatically for different time scales (so that a similar graph results from using either fine-grained or coarse-grained records) and handles rarely-occurring events gracefully.
- name: holtWintersAberration()
  id: functions#graphite.render.functions.holtWintersAberration
  summary: Performs a Holt-Winters forecast using the series as input data and plots the positive or negative deviation of the series data from the forecast
  belongs_to: Functions
  description: |-
    holtWintersAberration(seriesList, delta=3, bootstrapInterval='7d', seasonality='1d')

    Performs a Holt-Winters forecast using the series as input data and plots the positive or negative deviation of the series data from the forecast.
- name: holtWintersConfidenceArea()
  id: functions#graphite.render.functions.holtWintersConfidenceArea
  summary: Performs a Holt-Winters forecast using the series as input data and plots the area between the upper and lower bands of the predicted forecast deviations
  belongs_to: Functions
  description: |-
    holtWintersConfidenceArea(seriesList, delta=3, bootstrapInterval='7d', seasonality='1d')

    Performs a Holt-Winters forecast using the series as input data and plots the area between the upper and lower bands of the predicted forecast deviations.
- name: holtWintersConfidenceBands()
  id: functions#graphite.render.functions.holtWintersConfidenceBands
  summary: Performs a Holt-Winters forecast using the series as input data and plots upper and lower bands with the predicted forecast deviations
  belongs_to: Functions
  description: |-
    holtWintersConfidenceBands(seriesList, delta=3, bootstrapInterval='7d', seasonality='1d')

    Performs a Holt-Winters forecast using the series as input data and plots upper and lower bands with the predicted forecast deviations.
- name: holtWintersForecast()
  id: functions#graphite.render.functions.holtWintersForecast
  summary: Performs a Holt-Winters forecast using the series as input data
  belongs_to: Functions
  description: |-
    holtWintersForecast(seriesList, bootstrapInterval='7d', seasonality='1d')

    Performs a Holt-Winters forecast using the series as input data. Data from bootstrapInterval (one week by default) previous to the series is used to bootstrap the initial forecast.
- name: How do I report problems or request features for Graphite?
  id: faq#how-do-i-report-problems-or-request-features-for-graphite
  summary: Please post any feature requests or bug reports to the GitHub Issues page
  belongs_to: FAQ
  description: |-
    ## How do I report problems or request features for Graphite?

    Please post any feature requests or bug reports to the [GitHub Issues](https://github.com/graphite-project/graphite-web/issues) page.
- name: How real-time are the graphs?
  id: faq#how-real-time-are-the-graphs
  summary: Very
  belongs_to: FAQ
  description: |-
    ## How real-time are the graphs?

    Very. Even under heavy load, where the number of metrics coming in each time interval is much greater than the rate at which your storage system can perform I/O operations and lots of data points are being cached in the storage pipeline (see previous question for explanation), Graphite still draws real-time graphs. The trick is that when the Graphite webapp receives a request to draw a graph, it simultaneously retrieves data off the disk as well as from the pre-storage cache (which may be distributed if you have multiple backend servers) and combines the two sources of data to create a real-time graph.
- name: How scalable is Graphite?
  id: faq#how-scalable-is-graphite
  summary: From a CPU perspective, Graphite scales horizontally on both the frontend and the backend, meaning you can simply add more machines to the mix to get more throughput
  belongs_to: FAQ
  description: |-
    ## How scalable is Graphite?

    From a CPU perspective, Graphite scales horizontally on both the frontend and the backend, meaning you can simply add more machines to the mix to get more throughput. It is also fault tolerant in the sense that losing a backend machine will cause a minimal amount of data loss (whatever that machine had cached in memory) and will not disrupt the system if you have sufficient capacity remaining to handle the load.

    From an I/O perspective, under load Graphite performs lots of tiny I/O operations on lots of different files very rapidly. This is because each distinct metric sent to Graphite is stored in its own database file, similar to how many tools (drraw, Cacti, Centreon, etc) built on top of RRD work. In fact, Graphite originally did use RRD for storage until fundamental limitations arose that required a new storage engine.

    High volume (a few thousand distinct metrics updating every minute) pretty much requires a good RAID array and/or SSDs. Graphite’s backend caches incoming data if the disks cannot keep up with the large number of small write operations that occur (each data point is only a few bytes, but most standard disks cannot do more than a few thousand I/O operations per second, even if they are tiny). When this occurs, Graphite’s database engine, whisper, allows carbon to write multiple data points at once, thus increasing overall throughput only at the cost of keeping excess data cached in memory until it can be written.

    Graphite also supports [alternative storage backends](storage-backends) which can greatly change these characteristics.
- name: HTTP(S) TagDB
  id: tags#http-s-tagdb
  summary: The HTTP(S) TagDB is used to delegate all tag operations to an external server that implements the Graphite tagging HTTP API
  belongs_to: Graphite Tag Support
  description: |-
    ### HTTP(S) TagDB

    The HTTP(S) TagDB is used to delegate all tag operations to an external server that implements the Graphite tagging HTTP API. It can be used in clustered graphite scenarios, or with custom data stores. It is selected by setting `TAGDB='graphite.tags.http.HttpTagDB'` in local_settings.py. There are 4 additional config settings for the HTTP(S) TagDB:

    ``` default
    TAGDB_HTTP_URL = 'https://another.server'
    TAGDB_HTTP_USER = ''
    TAGDB_HTTP_PASSWORD = ''
    TAGDB_HTTP_AUTOCOMPLETE = False
    ```

    The `TAGDB_HTTP_URL` is required. `TAGDB_HTTP_USER` and `TAGDB_HTTP_PASSWORD` are optional and if specified will be used to send a Basic Authorization header in all requests.

    `TAGDB_HTTP_AUTOCOMPLETE` is also optional, if set to `True` auto-complete requests will be forwarded to the remote TagDB, otherwise calls to /tags/findSeries, /tags & /tags/\<tag\> will be used to provide auto-complete functionality.

    If `REMOTE_STORE_FORWARD_HEADERS` is defined, those headers will also be forwarded to the remote TagDB.
- name: identity()
  id: functions#graphite.render.functions.identity
  summary: 'Identity function: Returns datapoints where the value equals the timestamp of the datapoint'
  belongs_to: Functions
  description: |-
    identity(name)

    Identity function: Returns datapoints where the value equals the timestamp of the datapoint. Useful when you have another series where the value is a timestamp, and you want to compare it to the time of the datapoint, to render an age

    Example:

    ``` none
    &target=identity("The.time.series")
    ```

    This would create a series named “The.time.series” that contains points where x(t) == t.
- name: Importing a Graph
  id: dashboard#importing-a-graph
  summary: Existing graphs can be imported into your dashboard, either from URLs or from saved graphs
  belongs_to: The Dashboard User Interface
  description: |-
    ### Importing a Graph

    Existing graphs can be imported into your dashboard, either from URLs or from saved graphs.

    Import a graph from a URL when you already have the graph you want displaying elsewhere (maybe you built it in the Completer, or you want to copy it from another dashboard). Use the *Graphs \| New Graph \| From URL* menu item and enter the URL, which you probably copied from another browser window.

    Alternatively, if you’ve saved a graph in the Composer, you can import it. Use the *Graphs \| New Graph \| From Saved Graph* menu item, and select the graph to import.
- name: Initial Configuration
  id: install#initial-configuration
  summary: null
  belongs_to: Installing Graphite
  description: |-
    ## Initial Configuration

    - [Webapp Database Setup](config-database-setup)
    - [Configuring The Webapp](config-webapp)
      - [nginx + gunicorn](config-webapp#nginx-gunicorn)
      - [Apache + mod_wsgi](config-webapp#apache-mod-wsgi)
      - [Nginx + uWSGI](config-webapp#nginx-uwsgi)
    - [Graphite-web’s local_settings.py](config-local-settings)
      - [Config File Location](config-local-settings#config-file-location)
      - [General Settings](config-local-settings#general-settings)
      - [Filesystem Paths](config-local-settings#filesystem-paths)
      - [Configure Webserver (Apache)](config-local-settings#configure-webserver-apache)
      - [Email Configuration](config-local-settings#email-configuration)
      - [Authentication Configuration](config-local-settings#authentication-configuration)
      - [Dashboard Authorization Configuration](config-local-settings#dashboard-authorization-configuration)
      - [Database Configuration](config-local-settings#database-configuration)
      - [Cluster Configuration](config-local-settings#cluster-configuration)
      - [Additional Django Settings](config-local-settings#additional-django-settings)
    - [Configuring Carbon](config-carbon)
      - [carbon.conf](config-carbon#carbon-conf)
      - [storage-schemas.conf](config-carbon#storage-schemas-conf)
      - [storage-aggregation.conf](config-carbon#storage-aggregation-conf)
      - [relay-rules.conf](config-carbon#relay-rules-conf)
      - [aggregation-rules.conf](config-carbon#aggregation-rules-conf)
      - [rewrite-rules.conf](config-carbon#rewrite-rules-conf)
      - [whitelist and blacklist](config-carbon#whitelist-and-blacklist)
- name: Install Gunicorn
  id: config-webapp#install-gunicorn
  summary: Otherwise, you can use packages for your distribution
  belongs_to: Configuring The Webapp
  description: |-
    ### Install Gunicorn

    If you use a virtualenv, you can use `pip`:

    ``` none
    pip install gunicorn
    ```

    Otherwise, you can use packages for your distribution.

    On Debian-based systems, run:

    ``` none
    sudo apt install gunicorn
    ```
- name: Install nginx
  id: config-webapp#install-nginx
  summary: null
  belongs_to: Configuring The Webapp
  description: |-
    ### Install nginx

    On Debian-based systems, run:

    ``` none
    sudo apt install nginx
    ```
- name: Installing Carbon in a Custom Location
  id: install-source#installing-carbon-in-a-custom-location
  summary: Carbon’s setup.py installer is configured to use a prefix of /opt/graphite and an install-lib of /opt/graphite/lib
  belongs_to: Installing From Source
  description: |-
    ## Installing Carbon in a Custom Location

    Carbon’s `setup.py` installer is configured to use a `prefix` of `/opt/graphite` and an `install-lib` of `/opt/graphite/lib`. Carbon’s lifecycle wrapper scripts and utilities are installed in `bin`, configuration within `conf`, and stored data in `storage` all within `prefix`. These may be overridden by passing parameters to the `setup.py``install` command.

    The following parameters influence the install location:

    - ` ``--prefix`` `

      Location to place the `bin/` and `storage/` and `conf/` directories (defaults to `/opt/graphite/`)

    - ` ``--install-lib`` `

      Location to install Python modules (default: `/opt/graphite/lib`)

    - ` ``--install-data`` `

      Location to place the `storage` and `conf` directories (default: value of `prefix`)

    - ` ``--install-scripts`` `

      Location to place the scripts (default: `bin/` inside of `prefix`)

    For example, to install everything in `/srv/graphite/`:

    ``` none
    python setup.py install --prefix=/srv/graphite --install-lib=/srv/graphite/lib
    ```

    To install Carbon into the system-wide site-packages directory with scripts in `/usr/bin` and storage and configuration in `/usr/share/graphite`:

    ``` none
    python setup.py install --install-scripts=/usr/bin --install-lib=/usr/lib/python2.6/site-packages --install-data=/var/lib/graphite
    ```
- name: Installing Carbon in a Custom Location
  id: install-pip#installing-carbon-in-a-custom-location
  summary: Installation of Carbon in a custom location with pip is similar to doing so from a source install
  belongs_to: Installing From Pip
  description: |-
    ## Installing Carbon in a Custom Location

    Installation of Carbon in a custom location with pip is similar to doing so from a source install. Arguments to the underlying `setup.py` controlling installation location can be passed through pip with the `--install-option` option.

    See [Installing Carbon in a Custom Location](install-source#carbon-custom-location-source) for details of locations and available arguments

    For example, to install everything in `/srv/graphite/`:

    ``` none
    pip install https://github.com/graphite-project/carbon/tarball/master --install-option="--prefix=/srv/graphite" --install-option="--install-lib=/srv/graphite/lib"
    ```

    To install Carbon into the system-wide site-packages directory with scripts in `/usr/bin` and storage and configuration in `/usr/share/graphite`:

    ``` none
    pip install https://github.com/graphite-project/carbon/tarball/master --install-option="--install-scripts=/usr/bin" --install-option="--install-lib=/usr/lib/python2.6/site-packages" --install-option="--install-data=/var/lib/graphite"
    ```
- name: Installing Ceres
  id: install-pip#installing-ceres
  summary: Ceres is an alternative storage backend that some choose to use in place of the default Whisper backend
  belongs_to: Installing From Pip
  description: "## Installing Ceres\n\nCeres is an alternative storage backend that some choose to use in place of the default Whisper backend.\n\n``` none\npip install https://github.com/graphite-project/ceres/tarball/master\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-pip.html](https://graphite.readthedocs.io/en/latest/install-pip.html)"
- name: Installing custom finders
  id: storage-backends#installing-custom-finders
  summary: In order for your custom finder to be importable, you need to package it under a namespace of your choice
  belongs_to: Alternative storage finders
  description: "## Installing custom finders\n\nIn order for your custom finder to be importable, you need to package it under a namespace of your choice. Python packaging won’t be covered here but you can look at third-party finders to get some inspiration:\n\n- [Cyanite finder](https://github.com/brutasse/graphite-cyanite)\n- [BigGraphite finder](https://github.com/criteo/biggraphite/blob/master/biggraphite/plugins/graphite.py)\n- KairosDB finder\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/storage-backends.html](https://graphite.readthedocs.io/en/latest/storage-backends.html)"
- name: Installing From Pip
  id: install-pip
  summary: Versioned Graphite releases can be installed via pip
  description: "# Installing From Pip\n\nVersioned Graphite releases can be installed via [pip](http://pypi.python.org/pypi/pip). When installing with pip, installation of Python package dependencies will automatically be attempted.\n\nNote\n\nIn order to install Graphite-Web and Carbon, you must first install some development headers. In Debian-based distributions, this will require `apt-get`` ``install`` ``python-dev`` ``libcairo2-dev`` ``libffi-dev`` ``build-essential`, and in Red Hat-based distributions you will run `yum`` ``install`` ``python-devel`` ``cairo-devel`` ``libffi-devel`.\n\n## Installing in the Default Location\n\nTo install Graphite in the [default location](install#default-installation-layout), `/opt/graphite/`, simply execute as root:\n\n``` none\nexport PYTHONPATH=\"/opt/graphite/lib/:/opt/graphite/webapp/\"\npip install --no-binary=:all: https://github.com/graphite-project/whisper/tarball/master\npip install --no-binary=:all: https://github.com/graphite-project/carbon/tarball/master\npip install --no-binary=:all: https://github.com/graphite-project/graphite-web/tarball/master\n```\n\nNote\n\nIf your version of `pip` is \\< 7.0.0 then no need to use `--no-binary=:all:` parameter\n\nNote\n\nOn RedHat-based systems using the `python-pip` package, the pip executable is named `pip-python`\n\n## Installing Carbon in a Custom Location\n\nInstallation of Carbon in a custom location with pip is similar to doing so from a source install. Arguments to the underlying `setup.py` controlling installation location can be passed through pip with the `--install-option` option.\n\nSee [Installing Carbon in a Custom Location](install-source#carbon-custom-location-source) for details of locations and available arguments\n\nFor example, to install everything in `/srv/graphite/`:\n\n``` none\npip install https://github.com/graphite-project/carbon/tarball/master --install-option=\"--prefix=/srv/graphite\" --install-option=\"--install-lib=/srv/graphite/lib\"\n```\n\nTo install Carbon into the system-wide site-packages directory with scripts in `/usr/bin` and storage and configuration in `/usr/share/graphite`:\n\n``` none\npip install https://github.com/graphite-project/carbon/tarball/master --install-option=\"--install-scripts=/usr/bin\" --install-option=\"--install-lib=/usr/lib/python2.6/site-packages\" --install-option=\"--install-data=/var/lib/graphite\"\n```\n\n## Installing Graphite-web in a Custom Location\n\nInstallation of Graphite-web in a custom location with pip is similar to doing so from a source install. Arguments to the underlying `setup.py` controlling installation location can be passed through pip with the `--install-option` option.\n\nSee [Installing Graphite-web in a Custom Location](install-source#graphite-web-custom-location-source) for details on default locations and available arguments\n\nFor example, to install everything in `/srv/graphite/`:\n\n``` none\npip install https://github.com/graphite-project/graphite-web/tarball/master --install-option=\"--prefix=/srv/graphite\" --install-option=\"--install-lib=/srv/graphite/webapp\"\n```\n\nTo install the Graphite-web code into the system-wide site-packages directory with scripts in `/usr/bin` and storage configuration, and content in `/usr/share/graphite`:\n\n``` none\npip install https://github.com/graphite-project/graphite-web/tarball/master --install-option=\"--install-scripts=/usr/bin\" --install-option=\"--install-lib=/usr/lib/python2.6/site-packages\" --install-option=\"--install-data=/var/lib/graphite\"\n```\n\n## Installing Ceres\n\nCeres is an alternative storage backend that some choose to use in place of the default Whisper backend.\n\n``` none\npip install https://github.com/graphite-project/ceres/tarball/master\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-pip.html](https://graphite.readthedocs.io/en/latest/install-pip.html)"
- name: Installing From Source
  id: install-source
  summary: To install Graphite in the default location, /opt/graphite/, simply execute python`` ``setup.py`` ``install as root in each of the project directories for Graphite-web, Carbon, Whisper, and Ceres
  description: "# Installing From Source\n\nThe latest source tarballs for Graphite-web, Carbon, and Whisper may be fetched from the Graphite project [download page](https://launchpad.net/graphite/+download) or the latest development branches may be cloned from the [Github project page](http://github.com/graphite-project):\n\n- Graphite-web: `git`` ``clone`` ``https://github.com/graphite-project/graphite-web.git`\n- Carbon: `git`` ``clone`` ``https://github.com/graphite-project/carbon.git`\n- Whisper: `git`` ``clone`` ``https://github.com/graphite-project/whisper.git`\n- Ceres: `git`` ``clone`` ``https://github.com/graphite-project/ceres.git`\n\nNote\n\nThere currently is no tarball available for Ceres, it must be cloned from the [Github project page](http://github.com/graphite-project)\n\n## Installing in the Default Location\n\nTo install Graphite in the [default location](install#default-installation-layout), `/opt/graphite/`, simply execute `python`` ``setup.py`` ``install` as root in each of the project directories for Graphite-web, Carbon, Whisper, and Ceres.\n\n## Installing Carbon in a Custom Location\n\nCarbon’s `setup.py` installer is configured to use a `prefix` of `/opt/graphite` and an `install-lib` of `/opt/graphite/lib`. Carbon’s lifecycle wrapper scripts and utilities are installed in `bin`, configuration within `conf`, and stored data in `storage` all within `prefix`. These may be overridden by passing parameters to the `setup.py`` ``install` command.\n\nThe following parameters influence the install location:\n\n- `--prefix`\n\n  Location to place the `bin/` and `storage/` and `conf/` directories (defaults to `/opt/graphite/`)\n\n- `--install-lib`\n\n  Location to install Python modules (default: `/opt/graphite/lib`)\n\n- `--install-data`\n\n  Location to place the `storage` and `conf` directories (default: value of `prefix`)\n\n- `--install-scripts`\n\n  Location to place the scripts (default: `bin/` inside of `prefix`)\n\nFor example, to install everything in `/srv/graphite/`:\n\n``` none\npython setup.py install --prefix=/srv/graphite --install-lib=/srv/graphite/lib\n```\n\nTo install Carbon into the system-wide site-packages directory with scripts in `/usr/bin` and storage and configuration in `/usr/share/graphite`:\n\n``` none\npython setup.py install --install-scripts=/usr/bin --install-lib=/usr/lib/python2.6/site-packages --install-data=/var/lib/graphite\n```\n\n## Installing Graphite-web in a Custom Location\n\nGraphite-web’s `setup.py` installer is configured to use a `prefix` of `/opt/graphite` and an `install-lib` of `/opt/graphite/webapp`. Utilities are installed in `bin`, and configuration in `conf` within the `prefix`. These may be overridden by passing parameters to `setup.py`` ``install`\n\nThe following parameters influence the install location:\n\n- `--prefix`\n\n  Location to place the `bin/` and `conf/` directories (defaults to `/opt/graphite/`)\n\n- `--install-lib`\n\n  Location to install Python modules (default: `/opt/graphite/webapp`)\n\n- `--install-data`\n\n  Location to place the `webapp/content` and `conf` directories (default: value of `prefix`)\n\n- `--install-scripts`\n\n  Location to place scripts (default: `bin/` inside of `prefix`)\n\nFor example, to install everything in `/srv/graphite/`:\n\n``` none\npython setup.py install --prefix=/srv/graphite --install-lib=/srv/graphite/webapp\n```\n\nTo install the Graphite-web code into the system-wide site-packages directory with scripts in `/usr/bin` and storage configuration, and content in `/usr/share/graphite`:\n\n``` none\npython setup.py install --install-scripts=/usr/bin --install-lib=/usr/lib/python2.6/site-packages --install-data=/var/lib/graphite\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-source.html](https://graphite.readthedocs.io/en/latest/install-source.html)"
- name: Installing From Synthesize
  id: install-synthesize
  summary: Synthesize is a script dedicated to making Graphite easy to install
  description: "# Installing From Synthesize\n\n[Synthesize](https://github.com/obfuscurity/synthesize/) is a script dedicated to making Graphite easy to install. As of this writing, the default installation provides Graphite 0.9.15 for Ubuntu Linux 14.04 LTS with an experimental release candidate for tracking Graphite `HEAD`. Users may run the installation script manually, or they can choose to use the provided Vagrantfile.\n\nFor detailed instructions, please refer to the official project documentation on the [Synthesize](https://github.com/obfuscurity/synthesize/) website.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-synthesize.html](https://graphite.readthedocs.io/en/latest/install-synthesize.html)"
- name: Installing Graphite
  id: install
  summary: Check docker repo for details
  description: "# Installing Graphite\n\n## Docker\n\nTry Graphite in Docker and have it running in seconds:\n\n``` none\ndocker run -d\\\n --name graphite\\\n --restart=always\\\n -p 80:80\\\n -p 2003-2004:2003-2004\\\n -p 2023-2024:2023-2024\\\n -p 8125:8125/udp\\\n -p 8126:8126\\\n graphiteapp/graphite-statsd\n```\n\nCheck [docker repo](https://github.com/graphite-project/docker-graphite-statsd) for details.\n\nThis is portable, fast and easy to use. Or use instructions below for installation.\n\n## Dependencies\n\nGraphite renders graphs using the Cairo graphics library. This adds dependencies on several graphics-related libraries not typically found on a server. If you’re installing from source you can use the `check-dependencies.py` script to see if the dependencies have been met or not.\n\nBasic Graphite requirements:\n\n- a UNIX-like Operating System\n- Python 2.7 or greater (including experimental Python3 support)\n- [cairocffi](https://pythonhosted.org/cairocffi/)\n- [Django](http://www.djangoproject.com/) 1.8 - 1.11 (for Python3 - 1.11 only)\n- [django-tagging](http://django-tagging.readthedocs.io/) 0.4.6 (not django-taggit yet)\n- [pytz](https://pypi.python.org/pypi/pytz/)\n- [scandir](https://pypi.python.org/pypi/scandir)\n- [fontconfig](http://www.freedesktop.org/wiki/Software/fontconfig/) and at least one font package (a system package usually)\n- A WSGI server and web server. Popular choices are:\n  - [Apache](https://projects.apache.org/project.html?httpd-http_server) with [mod_wsgi](https://modwsgi.readthedocs.io/)\n  - [gunicorn](http://gunicorn.org/) with [nginx](http://nginx.org/)\n  - [uWSGI](http://uwsgi-docs.readthedocs.io/) with [nginx](http://nginx.org/)\n\nAdditionally, the Graphite webapp and Carbon require the Whisper database library which is part of the Graphite project.\n\nThere are also several other dependencies required for additional features:\n\n- Render caching: [memcached](http://memcached.org/) and [python-memcache](https://www.tummy.com/software/python-memcached/)\n- LDAP authentication: [python-ldap](https://www.python-ldap.org/) (for LDAP authentication support in the webapp)\n- AMQP support: [txamqp](https://launchpad.net/txamqp/) (version 0.8 is required)\n- RRD support: [python-rrdtool](http://oss.oetiker.ch/rrdtool/prog/rrdpython.en.html)\n- Dependent modules for additional database support (MySQL, PostgreSQL, etc). See [Django database install](https://docs.djangoproject.com/en/dev/topics/install/#get-your-database-running) instructions and the [Django database](https://docs.djangoproject.com/en/dev/ref/databases/) documentation for details\n\nSee also\n\nOn some systems it is necessary to install fonts for Cairo to use. If the webapp is running but all graphs return as broken images, this may be why.\n\n- [https://answers.launchpad.net/graphite/+question/38833](https://answers.launchpad.net/graphite/+question/38833)\n- [https://answers.launchpad.net/graphite/+question/133390](https://answers.launchpad.net/graphite/+question/133390)\n- [https://answers.launchpad.net/graphite/+question/127623](https://answers.launchpad.net/graphite/+question/127623)\n\n## Fulfilling Dependencies\n\nMost current Linux distributions have all of the requirements available in the base packages. RHEL based distributions may require the [EPEL](http://fedoraproject.org/wiki/EPEL) repository for requirements. Python module dependencies can be install with [pip](https://pip.pypa.io/) rather than system packages if desired or if using a Python version that differs from the system default. Some modules (such as Cairo) may require library development headers to be available.\n\n## Default Installation Layout\n\nGraphite defaults to an installation layout that puts the entire install in its own directory: `/opt/graphite`\n\n### Whisper\n\nWhisper is installed Python’s system-wide site-packages directory with Whisper’s utilities installed in the bin dir of the system’s default prefix (generally `/usr/bin/`).\n\n### Carbon and Graphite-web\n\nCarbon and Graphite-web are installed in `/opt/graphite/` with the following layout:\n\n- `bin/`\n\n- `conf/`\n\n- `lib/`\n\n  Carbon `PYTHONPATH`\n\n- `storage/`\n\n  - `log`\n\n    Log directory for Carbon and Graphite-web\n\n  - `rrd`\n\n    Location for RRD files to be read\n\n  - `whisper`\n\n    Location for Whisper data files to be stored and read\n\n  - `ceres`\n\n    Location for Ceres data files to be stored and read\n\n- `webapp/`\n\n  Graphite-web `PYTHONPATH`\n\n  - `graphite/`\n\n    Location of `local_settings.py`\n\n  - `content/`\n\n    Graphite-web static content directory\n\n## Installing Graphite\n\nSeveral installation options exist:\n\n- [Installing From Source](install-source)\n  - [Installing in the Default Location](install-source#installing-in-the-default-location)\n  - [Installing Carbon in a Custom Location](install-source#installing-carbon-in-a-custom-location)\n  - [Installing Graphite-web in a Custom Location](install-source#installing-graphite-web-in-a-custom-location)\n- [Installing From Pip](install-pip)\n  - [Installing in the Default Location](install-pip#installing-in-the-default-location)\n  - [Installing Carbon in a Custom Location](install-pip#installing-carbon-in-a-custom-location)\n  - [Installing Graphite-web in a Custom Location](install-pip#installing-graphite-web-in-a-custom-location)\n  - [Installing Ceres](install-pip#installing-ceres)\n- [Installing in Virtualenv](install-virtualenv)\n  - [Installing in the Default Location](install-virtualenv#installing-in-the-default-location)\n  - [Installing in a Custom Location](install-virtualenv#installing-in-a-custom-location)\n  - [Running Carbon Within Virtualenv](install-virtualenv#running-carbon-within-virtualenv)\n  - [Running Graphite-web Within Virtualenv](install-virtualenv#running-graphite-web-within-virtualenv)\n- [Installing From Synthesize](install-synthesize)\n\n## Initial Configuration\n\n- [Webapp Database Setup](config-database-setup)\n- [Configuring The Webapp](config-webapp)\n  - [nginx + gunicorn](config-webapp#nginx-gunicorn)\n  - [Apache + mod_wsgi](config-webapp#apache-mod-wsgi)\n  - [Nginx + uWSGI](config-webapp#nginx-uwsgi)\n- [Graphite-web’s local_settings.py](config-local-settings)\n  - [Config File Location](config-local-settings#config-file-location)\n  - [General Settings](config-local-settings#general-settings)\n  - [Filesystem Paths](config-local-settings#filesystem-paths)\n  - [Configure Webserver (Apache)](config-local-settings#configure-webserver-apache)\n  - [Email Configuration](config-local-settings#email-configuration)\n  - [Authentication Configuration](config-local-settings#authentication-configuration)\n  - [Dashboard Authorization Configuration](config-local-settings#dashboard-authorization-configuration)\n  - [Database Configuration](config-local-settings#database-configuration)\n  - [Cluster Configuration](config-local-settings#cluster-configuration)\n  - [Additional Django Settings](config-local-settings#additional-django-settings)\n- [Configuring Carbon](config-carbon)\n  - [carbon.conf](config-carbon#carbon-conf)\n  - [storage-schemas.conf](config-carbon#storage-schemas-conf)\n  - [storage-aggregation.conf](config-carbon#storage-aggregation-conf)\n  - [relay-rules.conf](config-carbon#relay-rules-conf)\n  - [aggregation-rules.conf](config-carbon#aggregation-rules-conf)\n  - [rewrite-rules.conf](config-carbon#rewrite-rules-conf)\n  - [whitelist and blacklist](config-carbon#whitelist-and-blacklist)\n\n## Help! It didn’t work!\n\nIf you run into any issues with Graphite, please to post a question to our [Questions forum on Launchpad](https://answers.launchpad.net/graphite) or join us on IRC in \\#graphite on FreeNode.\n\n## Post-Install Tasks\n\n[Configuring Carbon](config-carbon)  \nOnce you’ve installed everything you will need to create some basic configuration. Initially none of the config files are created by the installer but example files are provided. Simply copy the `.example` files and customize.\n\n[Administering Carbon](admin-carbon)  \nOnce Carbon is configured, you need to start it up.\n\n[Feeding In Your Data](feeding-carbon)  \nOnce it’s up and running, you need to feed it some data.\n\n[Configuring The Webapp](config-webapp)  \nWith data getting into carbon, you probably want to look at graphs of it. So now we turn our attention to the webapp.\n\n[Administering The Webapp](admin-webapp)  \nOnce its configured you’ll need to get it running.\n\n[Using the Composer](https://graphite.readthedocs.io/en/latest/composer.html)  \nNow that the webapp is running, you probably want to learn how to use it.\n\n## Windows Users\n\nUnfortunately, native Graphite on Windows is completely unsupported, but you can run Graphite on Windows in [Docker](https://www.docker.com/) or the [Installing via Synthesize](install-synthesize) article will help you set up a Vagrant VM that will run Graphite. In order to leverage this, you will need to install [Vagrant](https://www.vagrantup.com/).\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install.html](https://graphite.readthedocs.io/en/latest/install.html)"
- name: Installing Graphite
  id: install#id2
  summary: null
  belongs_to: Installing Graphite
  description: |-
    ## Installing Graphite

    Several installation options exist:

    - [Installing From Source](install-source)
      - [Installing in the Default Location](install-source#installing-in-the-default-location)
      - [Installing Carbon in a Custom Location](install-source#installing-carbon-in-a-custom-location)
      - [Installing Graphite-web in a Custom Location](install-source#installing-graphite-web-in-a-custom-location)
    - [Installing From Pip](install-pip)
      - [Installing in the Default Location](install-pip#installing-in-the-default-location)
      - [Installing Carbon in a Custom Location](install-pip#installing-carbon-in-a-custom-location)
      - [Installing Graphite-web in a Custom Location](install-pip#installing-graphite-web-in-a-custom-location)
      - [Installing Ceres](install-pip#installing-ceres)
    - [Installing in Virtualenv](install-virtualenv)
      - [Installing in the Default Location](install-virtualenv#installing-in-the-default-location)
      - [Installing in a Custom Location](install-virtualenv#installing-in-a-custom-location)
      - [Running Carbon Within Virtualenv](install-virtualenv#running-carbon-within-virtualenv)
      - [Running Graphite-web Within Virtualenv](install-virtualenv#running-graphite-web-within-virtualenv)
    - [Installing From Synthesize](install-synthesize)
- name: Installing Graphite-web in a Custom Location
  id: install-pip#installing-graphite-web-in-a-custom-location
  summary: Installation of Graphite-web in a custom location with pip is similar to doing so from a source install
  belongs_to: Installing From Pip
  description: |-
    ## Installing Graphite-web in a Custom Location

    Installation of Graphite-web in a custom location with pip is similar to doing so from a source install. Arguments to the underlying `setup.py` controlling installation location can be passed through pip with the `--install-option` option.

    See [Installing Graphite-web in a Custom Location](install-source#graphite-web-custom-location-source) for details on default locations and available arguments

    For example, to install everything in `/srv/graphite/`:

    ``` none
    pip install https://github.com/graphite-project/graphite-web/tarball/master --install-option="--prefix=/srv/graphite" --install-option="--install-lib=/srv/graphite/webapp"
    ```

    To install the Graphite-web code into the system-wide site-packages directory with scripts in `/usr/bin` and storage configuration, and content in `/usr/share/graphite`:

    ``` none
    pip install https://github.com/graphite-project/graphite-web/tarball/master --install-option="--install-scripts=/usr/bin" --install-option="--install-lib=/usr/lib/python2.6/site-packages" --install-option="--install-data=/var/lib/graphite"
    ```
- name: Installing Graphite-web in a Custom Location
  id: install-source#installing-graphite-web-in-a-custom-location
  summary: Graphite-web’s setup.py installer is configured to use a prefix of /opt/graphite and an install-lib of /opt/graphite/webapp
  belongs_to: Installing From Source
  description: "## Installing Graphite-web in a Custom Location\n\nGraphite-web’s `setup.py` installer is configured to use a `prefix` of `/opt/graphite` and an `install-lib` of `/opt/graphite/webapp`. Utilities are installed in `bin`, and configuration in `conf` within the `prefix`. These may be overridden by passing parameters to `setup.py``install`\n\nThe following parameters influence the install location:\n\n- ` ``--prefix`` `\n\n  Location to place the `bin/` and `conf/` directories (defaults to `/opt/graphite/`)\n\n- ` ``--install-lib`` `\n\n  Location to install Python modules (default: `/opt/graphite/webapp`)\n\n- ` ``--install-data`` `\n\n  Location to place the `webapp/content` and `conf` directories (default: value of `prefix`)\n\n- ` ``--install-scripts`` `\n\n  Location to place scripts (default: `bin/` inside of `prefix`)\n\nFor example, to install everything in `/srv/graphite/`:\n\n``` none\npython setup.py install --prefix=/srv/graphite --install-lib=/srv/graphite/webapp\n```\n\nTo install the Graphite-web code into the system-wide site-packages directory with scripts in `/usr/bin` and storage configuration, and content in `/usr/share/graphite`:\n\n``` none\npython setup.py install --install-scripts=/usr/bin --install-lib=/usr/lib/python2.6/site-packages --install-data=/var/lib/graphite\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-source.html](https://graphite.readthedocs.io/en/latest/install-source.html)"
- name: Installing in a Custom Location
  id: install-virtualenv#installing-in-a-custom-location
  summary: null
  belongs_to: Installing in Virtualenv
  description: |-
    ## Installing in a Custom Location

    To install from source activate the virtualenv and see the instructions for [graphite-web](install-source#graphite-web-custom-location-source) and [carbon](install-source#carbon-custom-location-source)
- name: Installing in the Default Location
  id: install-pip#installing-in-the-default-location
  summary: null
  belongs_to: Installing From Pip
  description: |-
    ## Installing in the Default Location

    To install Graphite in the [default location](install#default-installation-layout), `/opt/graphite/`, simply execute as root:

    ``` none
    export PYTHONPATH="/opt/graphite/lib/:/opt/graphite/webapp/"
    pip install --no-binary=:all: https://github.com/graphite-project/whisper/tarball/master
    pip install --no-binary=:all: https://github.com/graphite-project/carbon/tarball/master
    pip install --no-binary=:all: https://github.com/graphite-project/graphite-web/tarball/master
    ```

    Note

    If your version of `pip` is \< 7.0.0 then no need to use `--no-binary=:all:` parameter

    Note

    On RedHat-based systems using the `python-pip` package, the pip executable is named `pip-python`
- name: Installing in the Default Location
  id: install-virtualenv#installing-in-the-default-location
  summary: Once the virtualenv is activated, Graphite and Carbon can be installed from source or via pip
  belongs_to: Installing in Virtualenv
  description: |-
    ## Installing in the Default Location

    To install Graphite in the [default location](install#default-installation-layout), `/opt/graphite/`, create a virtualenv in `/opt/graphite` and activate it:

    ``` none
    virtualenv /opt/graphite
    source /opt/graphite/bin/activate
    ```

    Once the virtualenv is activated, Graphite and Carbon can be installed [from source](install-source) or [via pip](install-pip). Note that dependencies will need to be installed while the virtualenv is activated unless [–system-site-packages](http://www.virtualenv.org/en/latest/index.html#the-system-site-packages-option) is specified at virtualenv creation time.
- name: Installing in the Default Location
  id: install-source#installing-in-the-default-location
  summary: To install Graphite in the default location, /opt/graphite/, simply execute python``setup.py``install as root in each of the project directories for Graphite-web, Carbon, Whisper, and Ceres
  belongs_to: Installing From Source
  description: |-
    ## Installing in the Default Location

    To install Graphite in the [default location](install#default-installation-layout), `/opt/graphite/`, simply execute `python``setup.py``install` as root in each of the project directories for Graphite-web, Carbon, Whisper, and Ceres.
- name: Installing in Virtualenv
  id: install-virtualenv
  summary: Virtualenv provides an isolated Python environment to run Graphite in
  description: "# Installing in Virtualenv\n\n[Virtualenv](http://virtualenv.org/) provides an isolated Python environment to run Graphite in.\n\n## Installing in the Default Location\n\nTo install Graphite in the [default location](install#default-installation-layout), `/opt/graphite/`, create a virtualenv in `/opt/graphite` and activate it:\n\n``` none\nvirtualenv /opt/graphite\nsource /opt/graphite/bin/activate\n```\n\nOnce the virtualenv is activated, Graphite and Carbon can be installed [from source](install-source) or [via pip](install-pip). Note that dependencies will need to be installed while the virtualenv is activated unless [–system-site-packages](http://www.virtualenv.org/en/latest/index.html#the-system-site-packages-option) is specified at virtualenv creation time.\n\n## Installing in a Custom Location\n\nTo install from source activate the virtualenv and see the instructions for [graphite-web](install-source#graphite-web-custom-location-source) and [carbon](install-source#carbon-custom-location-source)\n\n## Running Carbon Within Virtualenv\n\nCarbon may be run within Virtualenv by [activating virtualenv](http://www.virtualenv.org/en/latest/index.html#activate-script) before Carbon is started\n\n## Running Graphite-web Within Virtualenv\n\nRunning Django’s `django-admin.py` within a virtualenv requires using the full path of the virtualenv:\n\n``` default\n/path/to/env/bin/django-admin.py <command> --settings=graphite.settings\n```\n\nThe method of running Graphite-web within Virtualenv depends on the WSGI server used:\n\n### Apache mod_wsgi\n\nNote\n\nThe version Python used to compile mod_wsgi must match the Python installed in the virtualenv (generally the system Python)\n\nTo the Apache [mod_wsgi](http://code.google.com/p/modwsgi/) config, add the root of the virtualenv as `WSGIPythonHome`, `/opt/graphite` in this example:\n\n``` none\nWSGIPythonHome /opt/graphite\n```\n\nand add the virtualenv’s python site-packages to the `graphite.wsgi` file, python 2.6 in `/opt/graphite` in this example:\n\n``` none\nsite.addsitedir('/opt/graphite/lib/python2.6/site-packages')\n```\n\nSee the mod_wsgi documentation on Virtual Environments \\<http://code.google.com/p/modwsgi/wiki/VirtualEnvironments\\> for more details.\n\n### Gunicorn\n\nEnsure [Gunicorn](http://gunicorn.org/) is installed in the activated virtualenv and execute as normal. If gunicorn is installed system-wide, it may be necessary to execute it from the virtualenv’s bin path\n\n### uWSGI\n\nExecute [uWSGI](http://projects.unbit.it/uwsgi) using the `-H` option to specify the virtualenv root. See the [uWSGI documentation on virtualenv](http://projects.unbit.it/uwsgi/wiki/VirtualEnv) for more details.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-virtualenv.html](https://graphite.readthedocs.io/en/latest/install-virtualenv.html)"
- name: integral()
  id: functions#graphite.render.functions.integral
  summary: This will show the sum over time, sort of like a continuous addition function
  belongs_to: Functions
  description: |-
    integral(seriesList)

    This will show the sum over time, sort of like a continuous addition function. Useful for finding totals or trends in metrics that are collected per minute.

    Example:

    ``` none
    &target=integral(company.sales.perMinute)
    ```

    This would start at zero on the left side of the graph, adding the sales each minute, and show the total sales for the time period selected at the right side, (time now, or the time specified by ‘&until=’).
- name: integralByInterval()
  id: functions#graphite.render.functions.integralByInterval
  summary: This would start at zero on the left side of the graph, adding the sales each minute, and show the evolution of sales per day during the last 10 days
  belongs_to: Functions
  description: |-
    integralByInterval(seriesList, intervalUnit)

    This will do the same as integral() funcion, except resetting the total to 0 at the given time in the parameter “from” Useful for finding totals per hour/day/week/..

    Example:

    ``` none
    &target=integralByInterval(company.sales.perMinute, "1d")&from=midnight-10days
    ```

    This would start at zero on the left side of the graph, adding the sales each minute, and show the evolution of sales per day during the last 10 days.
- name: interpolate()
  id: functions#graphite.render.functions.interpolate
  summary: Takes one metric or a wildcard seriesList, and optionally a limit to the number of ‘None’ values to skip over
  belongs_to: Functions
  description: |-
    interpolate(seriesList, limit=inf)

    Takes one metric or a wildcard seriesList, and optionally a limit to the number of ‘None’ values to skip over. Continues the line with the last received value when gaps (‘None’ values) appear in your data, rather than breaking your line.

    Example:

    ``` none
    &target=interpolate(Server01.connections.handled)
    &target=interpolate(Server01.connections.handled, 10)
    ```
- name: invert()
  id: functions#graphite.render.functions.invert
  summary: Takes one metric or a wildcard seriesList, and inverts each datapoint (i.e
  belongs_to: Functions
  description: |-
    invert(seriesList)

    Takes one metric or a wildcard seriesList, and inverts each datapoint (i.e. 1/x).

    Example:

    ``` none
    &target=invert(Server.instance01.threads.busy)
    ```
- name: Is there a diagram of Graphite’s architecture?
  id: faq#is-there-a-diagram-of-graphite-s-architecture
  summary: © 2008–2012 Chris Davis © 2011–2016 The Graphite Project Licensed under the Apache License, Version 2.0
  belongs_to: FAQ
  description: "## Is there a diagram of Graphite’s architecture?\n\nThere sure is! Here it is:\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/faq.html](https://graphite.readthedocs.io/en/latest/faq.html)"
- name: Is this Graphite related to the SIL font rendering graphite?
  id: faq#is-this-graphite-related-to-the-sil-font-rendering-graphite
  summary: No
  belongs_to: FAQ
  description: |-
    ## Is this Graphite related to the SIL font rendering graphite?

    No. SIL Graphite is completely unrelated to this Graphite.
- name: Is this Graphite related to the sourceforge project called graphite?
  id: faq#is-this-graphite-related-to-the-sourceforge-project-called-graphite
  summary: No
  belongs_to: FAQ
  description: |-
    ## Is this Graphite related to the sourceforge project called graphite?

    No. The sourceforge project called graphite is completely unrelated to this Graphite.
- name: isNonNull()
  id: functions#graphite.render.functions.isNonNull
  summary: Takes a metric or wildcard seriesList and counts up the number of non-null values
  belongs_to: Functions
  description: |-
    isNonNull(seriesList)

    Takes a metric or wildcard seriesList and counts up the number of non-null values. This is useful for understanding the number of metrics that have data at a given point in time (i.e. to count which servers are alive).

    Example:

    ``` none
    &target=isNonNull(webapp.pages.*.views)
    ```

    Returns a seriesList where 1 is specified for non-null values, and 0 is specified for null values.
- name: jsonp
  id: render_api#jsonp
  summary: If set and combined with format=json, wraps the JSON response in a function call named by the parameter specified
  belongs_to: The Render URL API
  description: |-
    ### jsonp

    *Default: \<unset\>*

    If set and combined with `format=json`, wraps the JSON response in a function call named by the parameter specified.
- name: keepLastValue()
  id: functions#graphite.render.functions.keepLastValue
  summary: Takes one metric or a wildcard seriesList, and optionally a limit to the number of ‘None’ values to skip over
  belongs_to: Functions
  description: |-
    keepLastValue(seriesList, limit=inf)

    Takes one metric or a wildcard seriesList, and optionally a limit to the number of ‘None’ values to skip over. Continues the line with the last received value when gaps (‘None’ values) appear in your data, rather than breaking your line.

    Example:

    ``` none
    &target=keepLastValue(Server01.connections.handled)
    &target=keepLastValue(Server01.connections.handled, 10)
    ```
- name: LDAP
  id: config-local-settings#ldap
  summary: These settings configure a custom LDAP authentication backend provided by Graphite
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ### LDAP

    These settings configure a custom LDAP authentication backend provided by Graphite. Additional settings to the ones below are configurable setting the LDAP module’s global options using `ldap.set_option`. See the [module documentation](http://python-ldap.org/) for more details.

    ``` none
    # SSL Example
    import ldap
    ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_ALLOW)
    ldap.set_option(ldap.OPT_X_TLS_CACERTDIR, "/etc/ssl/ca")
    ldap.set_option(ldap.OPT_X_TLS_CERTFILE, "/etc/ssl/mycert.pem")
    ldap.set_option(ldap.OPT_X_TLS_KEYFILE, "/etc/ssl/mykey.pem")
    ```

    USE_LDAP_AUTH

    Default: False

    LDAP_SERVER

    Default: ‘’

    Set the LDAP server here or alternately in `LDAP_URI`.

    LDAP_PORT

    Default: 389

    Set the LDAP server port here or alternately in `LDAP_URI`.

    LDAP_URI

    Default: None

    Sets the LDAP server URI. E.g. `ldaps://ldap.mycompany.com:636`

    LDAP_SEARCH_BASE

    Default: ‘’

    Sets the LDAP search base. E.g. `OU=users,DC=mycompany,DC=com`

    LDAP_BASE_USER

    Default: ‘’

    Sets the base LDAP user to bind to the server with. E.g. `CN=some_readonly_account,DC=mycompany,DC=com`

    LDAP_BASE_PASS

    Default: ‘’

    Sets the password of the base LDAP user to bind to the server with.

    LDAP_USER_QUERY

    Default: ‘’

    Sets the LDAP query to return a user object where `%s` substituted with the user id. E.g. `(username=%s)` or `(sAMAccountName=%s)` (Active Directory).

    LDAP_USER_DN_TEMPLATE:

    Default: ‘’

    Instead of using a hardcoded username and password for the account that binds to the LDAP server you could use the credentials of the user that tries to log in to Graphite. This is the template that creates the full DN to bind with.
- name: leftColor
  id: render_api#leftcolor
  summary: In dual Y-axis mode, sets the color of all metrics associated with the left Y-axis
  belongs_to: The Render URL API
  description: |-
    ### leftColor

    *Default: color chosen from* [colorList](#colorlist)

    In dual Y-axis mode, sets the color of all metrics associated with the left Y-axis.
- name: leftDashed
  id: render_api#leftdashed
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### leftDashed

    *Default: False*

    In dual Y-axis mode, draws all metrics associated with the left Y-axis using dashed lines
- name: leftWidth
  id: render_api#leftwidth
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### leftWidth

    *Default: value of the parameter* [lineWidth](#linewidth)

    In dual Y-axis mode, sets the line width of all metrics associated with the left Y-axis
- name: legendValue()
  id: functions#graphite.render.functions.legendValue
  summary: Takes one metric or a wildcard seriesList and a string in quotes
  belongs_to: Functions
  description: |-
    legendValue(seriesList, \*valueTypes)

    Takes one metric or a wildcard seriesList and a string in quotes. Appends a value to the metric name in the legend. Currently one or several of: last, avg, total, min, max. The last argument can be si (default) or binary, in that case values will be formatted in the corresponding system.

    ``` none
    &target=legendValue(Sales.widgets.largeBlue, 'avg', 'max', 'si')
    ```
- name: limit()
  id: functions#graphite.render.functions.limit
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    limit(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N.

    Only draw the first N metrics. Useful when testing a wildcard in a metric.

    Example:

    ``` none
    &target=limit(server*.instance*.memory.free,5)
    ```

    Draws only the first 5 instance’s memory free.
- name: linearRegression()
  id: functions#graphite.render.functions.linearRegression
  summary: Graphs the linear regression function by least squares method
  belongs_to: Functions
  description: |-
    linearRegression(seriesList, startSourceAt=None, endSourceAt=None)

    Graphs the linear regression function by least squares method.

    Takes one metric or a wildcard seriesList, followed by a quoted string with the time to start the line and another quoted string with the time to end the line. The start and end times are inclusive (default range is from to until). See `from``/``until` in the [Render API](render_api) for examples of time formats. Datapoints in the range is used to regression.

    Example:

    ``` none
    &target=linearRegression(Server.instance01.threads.busy, '-1d')
    &target=linearRegression(Server.instance*.threads.busy, "00:00 20140101","11:59 20140630")
    ```
- name: linearRegressionAnalysis()
  id: functions#graphite.render.functions.linearRegressionAnalysis
  summary: Returns factor and offset of linear regression function by least squares method
  belongs_to: Functions
  description: |-
    linearRegressionAnalysis(series)

    Returns factor and offset of linear regression function by least squares method.
- name: lineMode
  id: render_api#linemode
  summary: Sets the line drawing behavior
  belongs_to: The Render URL API
  description: |-
    ### lineMode

    *Default: slope*

    Sets the line drawing behavior. Takes one of the following parameters:

    ` ``slope`` `

    Slope line mode draws a line from each point to the next. Periods with Null values will not be drawn

    ` ``staircase`` `

    Staircase draws a flat line for the duration of a time period and then a vertical line up or down to the next value

    ` ``connected`` `

    Like a slope line, but values are always connected with a slope line, regardless of whether or not there are Null values between them

    Example:

    ``` none
    &lineMode=staircase
    ```
- name: lineWidth
  id: render_api#linewidth
  summary: Takes any floating point or integer (negative numbers do not error but will cause no line to be drawn)
  belongs_to: The Render URL API
  description: |-
    ### lineWidth

    *Default: 1.2*

    Takes any floating point or integer (negative numbers do not error but will cause no line to be drawn). Changes the width of the line in pixels.

    Example:

    ``` none
    &lineWidth=2
    ```
- name: lineWidth()
  id: functions#graphite.render.functions.lineWidth
  summary: Takes one metric or a wildcard seriesList, followed by a float F
  belongs_to: Functions
  description: |-
    lineWidth(seriesList, width)

    Takes one metric or a wildcard seriesList, followed by a float F.

    Draw the selected metrics with a line width of F, overriding the default value of 1, or the &lineWidth=X.X parameter.

    Useful for highlighting a single metric out of many, or having multiple line widths in one graph.

    Example:

    ``` none
    &target=lineWidth(server01.instance01.memory.free,5)
    ```
- name: List of functions
  id: functions#module-graphite.render.functions
  summary: null
  belongs_to: Functions
  description: '## List of functions'
- name: Local Database TagDB
  id: tags#local-database-tagdb
  summary: The Local TagDB stores tag information in tables inside the graphite-web database
  belongs_to: Graphite Tag Support
  description: |-
    ### Local Database TagDB

    The Local TagDB stores tag information in tables inside the graphite-web database. It supports SQLite, MySQL and Postgres, and is enabled by default.
- name: localOnly
  id: render_api#localonly
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### localOnly

    *Default: False*

    Set to prevent fetching from remote Graphite servers, only returning metrics which are accessible locally
- name: logarithm()
  id: functions#graphite.render.functions.logarithm
  summary: Takes one metric or a wildcard seriesList, a base, and draws the y-axis in logarithmic format
  belongs_to: Functions
  description: |-
    logarithm(seriesList, base=10)

    Takes one metric or a wildcard seriesList, a base, and draws the y-axis in logarithmic format. If base is omitted, the function defaults to base 10.

    Example:

    ``` none
    &target=log(carbon.agents.hostname.avgUpdateTime,2)
    ```
- name: logBase
  id: render_api#logbase
  summary: If set, draws the graph with a logarithmic scale of the specified base (e.g
  belongs_to: The Render URL API
  description: |-
    ### logBase

    *Default: \<unset\>*

    If set, draws the graph with a logarithmic scale of the specified base (e.g. 10 for common logarithm)
- name: Login/logout
  id: dashboard#login-logout
  summary: By default, it’s not necessary to be logged in to use or change dashboards
  belongs_to: The Dashboard User Interface
  description: |-
    ### Login/logout

    By default, it’s not necessary to be logged in to use or change dashboards. However, your system may be configured to require users to be logged in to change or delete dashboards, and may also require appropriate permissions to do so.

    Log into Graphite using the *Dashboard \| Log in* menu item, which shows a standard login dialog. Once you’re logged in, the menu item changes to *Log out from “username”* - click this to log out again. Note that logins are recorded by a persistent browser cookie, so you don’t have to log in again each time you connect to Graphite.
- name: lowest()
  id: functions#graphite.render.functions.lowest
  summary: Takes one metric or a wildcard seriesList followed by an integer N and an aggregation function
  belongs_to: Functions
  description: |-
    lowest(seriesList, n=1, func='average')

    Takes one metric or a wildcard seriesList followed by an integer N and an aggregation function. Out of all metrics passed, draws only the N metrics with the lowest aggregated value over the time period specified.

    Example:

    ``` none
    &target=lowest(server*.instance*.threads.busy,5,'min')
    ```

    Draws the 5 servers with the lowest number of busy threads.
- name: lowestAverage()
  id: functions#graphite.render.functions.lowestAverage
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    lowestAverage(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the bottom N metrics with the lowest average value for the time period specified.

    Example:

    ``` none
    &target=lowestAverage(server*.instance*.threads.busy,5)
    ```

    Draws the bottom 5 servers with the lowest average value.

    This is an alias for [`lowest`](#graphite.render.functions.lowest "graphite.render.functions.lowest") with aggregation `average`.
- name: lowestCurrent()
  id: functions#graphite.render.functions.lowestCurrent
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    lowestCurrent(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Out of all metrics passed, draws only the N metrics with the lowest value at the end of the time period specified.

    Example:

    ``` none
    &target=lowestCurrent(server*.instance*.threads.busy,5)
    ```

    Draws the 5 servers with the least busy threads right now.

    This is an alias for [`lowest`](#graphite.render.functions.lowest "graphite.render.functions.lowest") with aggregation `current`.
- name: majorGridLineColor
  id: render_api#majorgridlinecolor
  summary: Sets the color of the major grid lines
  belongs_to: The Render URL API
  description: |-
    ### majorGridLineColor

    *Default: value from the \[default\] template in graphTemplates.conf*

    Sets the color of the major grid lines.

    See [bgcolor](#bgcolor) for valid color names and formats.

    Example:

    ``` none
    &majorGridLineColor=FF22FF
    ```
- name: Managing Events in the Admin UI
  id: events#managing-events-in-the-admin-ui
  summary: Events can be managed using the Graphite administration module
  belongs_to: Graphite Events
  description: "## Managing Events in the Admin UI\n\nEvents can be managed using the Graphite [administration module](admin-webapp). This is particularly handy for deleting a large number of events at once, although it also supports adding and editing individual events.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/events.html](https://graphite.readthedocs.io/en/latest/events.html)"
- name: Manual and Auto Refresh
  id: dashboard#manual-and-auto-refresh
  summary: By default, dashboards are set to manually refresh
  belongs_to: The Dashboard User Interface
  description: |-
    ### Manual and Auto Refresh

    By default, dashboards are set to manually refresh. Click the green refresh menu button to the left of the *Auto-Refresh* button to refresh the dashboard. The time of the last refresh is shown at the right of the menu bar.

    Alternatively, set the dashboard to auto-refresh by ensuring that the *Auto-Refresh* menu button is pressed in. The refresh defaults to 60 seconds, but you can change this in the edit field to the right of the *Auto-Refresh* button.

    Note that refresh options are saved with the dashboard.
- name: mapSeries()
  id: functions#graphite.render.functions.mapSeries
  summary: Takes a seriesList and maps it to a list of seriesList
  belongs_to: Functions
  description: |-
    mapSeries(seriesList, \*mapNodes)

    Short form: `map()`

    Takes a seriesList and maps it to a list of seriesList. Each seriesList has the given mapNodes in common.

    Note

    This function is not very useful alone. It should be used with [`reduceSeries()`](#graphite.render.functions.reduceSeries "graphite.render.functions.reduceSeries")

    ``` none
    mapSeries(servers.*.cpu.*,1) =>

      [
        servers.server1.cpu.*,
        servers.server2.cpu.*,
        ...
        servers.serverN.cpu.*
      ]
    ```

    Each node may be an integer referencing a node in the series name or a string identifying a tag.
- name: margin
  id: render_api#margin
  summary: 'Default: 10 Sets the margin around a graph image in pixels on all sides'
  belongs_to: The Render URL API
  description: |-
    ### margin

    *Default: 10* Sets the margin around a graph image in pixels on all sides.

    Example:

    ``` none
    &margin=20
    ```
- name: max
  id: render_api#max
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### max

    Deprecated since version 0.9.0: See [yMax](#ymax)
- name: maxDataPoints
  id: render_api#maxdatapoints
  summary: Set the maximum numbers of datapoints for each series returned when using json content
  belongs_to: The Render URL API
  description: |-
    ### maxDataPoints

    Set the maximum numbers of datapoints for each series returned when using json content.

    If for any output series the number of datapoints in a selected range exceeds the maxDataPoints value then the datapoints over the whole period are consolidated.

    The function used to consolidate points can be set using the [consolidateBy](functions#graphite.render.functions.consolidateBy) function.
- name: maximumAbove()
  id: functions#graphite.render.functions.maximumAbove
  summary: Takes one metric or a wildcard seriesList followed by a constant n
  belongs_to: Functions
  description: |-
    maximumAbove(seriesList, n)

    Takes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a maximum value above n.

    Example:

    ``` none
    &target=maximumAbove(system.interface.eth*.packetsSent,1000)
    ```

    This would only display interfaces which sent more than 1000 packets/min.
- name: maximumBelow()
  id: functions#graphite.render.functions.maximumBelow
  summary: Takes one metric or a wildcard seriesList followed by a constant n
  belongs_to: Functions
  description: |-
    maximumBelow(seriesList, n)

    Takes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a maximum value below n.

    Example:

    ``` none
    &target=maximumBelow(system.interface.eth*.packetsSent,1000)
    ```

    This would only display interfaces which sent less than 1000 packets/min.
- name: maxSeries()
  id: functions#graphite.render.functions.maxSeries
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    maxSeries(\*seriesLists)

    Takes one metric or a wildcard seriesList. For each datapoint from each metric passed in, pick the maximum value and graph it.

    Example:

    ``` none
    &target=maxSeries(Server*.connections.total)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `max`.
- name: min
  id: render_api#min
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### min

    Deprecated since version 0.9.0: See [yMin](#ymin)
- name: minimumAbove()
  id: functions#graphite.render.functions.minimumAbove
  summary: Takes one metric or a wildcard seriesList followed by a constant n
  belongs_to: Functions
  description: |-
    minimumAbove(seriesList, n)

    Takes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a minimum value above n.

    Example:

    ``` none
    &target=minimumAbove(system.interface.eth*.packetsSent,1000)
    ```

    This would only display interfaces which sent more than 1000 packets/min.
- name: minimumBelow()
  id: functions#graphite.render.functions.minimumBelow
  summary: Takes one metric or a wildcard seriesList followed by a constant n
  belongs_to: Functions
  description: |-
    minimumBelow(seriesList, n)

    Takes one metric or a wildcard seriesList followed by a constant n. Draws only the metrics with a minimum value below n.

    Example:

    ``` none
    &target=minimumBelow(system.interface.eth*.packetsSent,1000)
    ```

    This would only display interfaces which at one point sent less than 1000 packets/min.
- name: minMax()
  id: functions#graphite.render.functions.minMax
  summary: 'Applies the popular min max normalization technique, which takes each point and applies the following normalization transformation to it: normalized = (point - min) / (max - min)'
  belongs_to: Functions
  description: |-
    minMax(seriesList)

    Applies the popular min max normalization technique, which takes each point and applies the following normalization transformation to it: normalized = (point - min) / (max - min).

    Example:

    ``` none
    &target=minMax(Server.instance01.threads.busy)
    ```
- name: minorGridLineColor
  id: render_api#minorgridlinecolor
  summary: Sets the color of the minor grid lines
  belongs_to: The Render URL API
  description: |-
    ### minorGridLineColor

    *Default: value from the \[default\] template in graphTemplates.conf*

    Sets the color of the minor grid lines.

    See [bgcolor](#bgcolor) for valid color names and formats.

    Example:

    ``` none
    &minorGridLineColor=darkgrey
    ```
- name: minorY
  id: render_api#minory
  summary: Sets the number of minor grid lines per major line on the y-axis
  belongs_to: The Render URL API
  description: |-
    ### minorY

    Sets the number of minor grid lines per major line on the y-axis.

    Example:

    ``` none
    &minorY=3
    ```
- name: minSeries()
  id: functions#graphite.render.functions.minSeries
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    minSeries(\*seriesLists)

    Takes one metric or a wildcard seriesList. For each datapoint from each metric passed in, pick the minimum value and graph it.

    Example:

    ``` none
    &target=minSeries(Server*.connections.total)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `min`.
- name: minXStep
  id: render_api#minxstep
  summary: Sets the minimum pixel-step to use between datapoints drawn
  belongs_to: The Render URL API
  description: |-
    ### minXStep

    *Default: 1*

    Sets the minimum pixel-step to use between datapoints drawn. Any value below this will trigger a point consolidation of the series at render time. The default value of `1` combined with the default lineWidth of `1.2` will cause a minimal amount of line overlap between close-together points. To disable render-time point consolidation entirely, set this to `0` though note that series with more points than there are pixels in the graph area (e.g. a few month’s worth of per-minute data) will look very ‘smooshed’ as there will be a good deal of line overlap. In response, one may use [lineWidth](#linewidth) to compensate for this.
- name: Monitoring
  id: tools#monitoring
  summary: A self-hosted monitoring and alerting server that watches Graphite metrics and can alert on them by phone, SMS, Hipchat or email
  belongs_to: Tools That Work With Graphite
  description: |-
    ## Monitoring

    [Cabot](https://github.com/arachnys/cabot)

    A self-hosted monitoring and alerting server that watches Graphite metrics and can alert on them by phone, SMS, Hipchat or email. It is designed to be deployed to cloud or physical hardware in minutes and configured via web interface.

    [graphite-beacon](https://github.com/klen/graphite-beacon)

    A simple alerting application for Graphite. It asynchronous and sends notification alerts based on Graphite metrics. It hasn’t any dependencies except Tornado package. Very light and really very easy deployed.

    [graphite-to-zabbix](https://github.com/blacked/graphite-to-zabbix)

    A tool to make zabbix alerts based on Graphite data.

    [Icinga](http://docs.icinga.org/icinga2/latest/doc/module/icinga2/chapter/icinga2-features#graphite-carbon-cache-writer)

    Icinga 2 will directly write metrics to the defined Graphite Carbon daemon tcp socket if the graphite feature is enabled. This feature is a more simple integration compared to Icinga 1.x and Graphios.

    [Moira](http://moira.readthedocs.io)

    An alerting system based on Graphite data. Moira is a real-time alerting tool, independent from graphite storage, custom expressions and extendable notification channels.

    [rearview](http://github.com/livingsocial/rearview)

    A real-time monitoring framework that sits on top of Graphite’s time series data. This allows users to create monitors that both visualize and alert on data as it streams from Graphite. The monitors themselves are simple Ruby scripts which run in a sandbox to provide additional security. Monitors are also configured with a crontab compatible time specification used by the scheduler. Alerts can be sent via email, pagerduty, or campfire.

    [Rocksteady](http://code.google.com/p/rocksteady)

    A system that ties together Graphite, [RabbitMQ](http://www.rabbitmq.com), and [Esper](http://esper.codehaus.org). Developed by AdMob (who was then bought by Google), this was released by Google as open source ([http://google-opensource.blogspot.com/2010/09/get-ready-to-rocksteady.html](http://google-opensource.blogspot.com/2010/09/get-ready-to-rocksteady.html)).

    [Seyren](https://github.com/scobal/seyren)

    An alerting dashboard for Graphite.

    [Shinken](http://www.shinken-monitoring.org)

    A system monitoring solution compatible with Nagios which emphasizes scalability, flexibility, and ease of setup. Shinken provides complete integration with Graphite for processing and display of performance data.

    [Skyline](https://github.com/earthgecko/skyline)

    An anomaly detection/deflection system that receives all Graphite metrics data in real time via a carbon-relay pickle and analyses each time series to detect anomalies, drops off cliffs, user defined thresholds, handles multiple seasonality, records all anomalies and cross correlates all metrics to anomalies for the purpose of root cause analysis. Skyline can also be trained on what is not anomalous and thereafter it can independently learn what is not anomalous using a time series similarities comparison method. It can alert via smtp, hipchat and pagerduty.
- name: mostDeviant()
  id: functions#graphite.render.functions.mostDeviant
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    mostDeviant(seriesList, n)

    Takes one metric or a wildcard seriesList followed by an integer N. Draws the N most deviant metrics. To find the deviants, the standard deviation (sigma) of each series is taken and ranked. The top N standard deviations are returned.

    > Example:

    ``` none
    &target=mostDeviant(server*.instance*.memory.free, 5)
    ```

    Draws the 5 instances furthest from the average memory free.
- name: movingAverage()
  id: functions#graphite.render.functions.movingAverage
  summary: Graphs the moving average of a metric (or metrics) over a fixed number of past points, or a time interval
  belongs_to: Functions
  description: |-
    movingAverage(seriesList, windowSize, xFilesFactor=None)

    Graphs the moving average of a metric (or metrics) over a fixed number of past points, or a time interval.

    Takes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from``/``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the average of the preceeding datapoints for each point on the graph.

    Example:

    ``` none
    &target=movingAverage(Server.instance01.threads.busy,10)
    &target=movingAverage(Server.instance*.threads.idle,'5min')
    ```
- name: movingMax()
  id: functions#graphite.render.functions.movingMax
  summary: Graphs the moving maximum of a metric (or metrics) over a fixed number of past points, or a time interval
  belongs_to: Functions
  description: |-
    movingMax(seriesList, windowSize, xFilesFactor=None)

    Graphs the moving maximum of a metric (or metrics) over a fixed number of past points, or a time interval.

    Takes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from``/``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the maximum of the preceeding datapoints for each point on the graph.

    Example:

    ``` none
    &target=movingMax(Server.instance01.requests,10)
    &target=movingMax(Server.instance*.errors,'5min')
    ```
- name: movingMedian()
  id: functions#graphite.render.functions.movingMedian
  summary: Graphs the moving median of a metric (or metrics) over a fixed number of past points, or a time interval
  belongs_to: Functions
  description: |-
    movingMedian(seriesList, windowSize, xFilesFactor=None)

    Graphs the moving median of a metric (or metrics) over a fixed number of past points, or a time interval.

    Takes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from``/``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the median of the preceeding datapoints for each point on the graph.

    Example:

    ``` none
    &target=movingMedian(Server.instance01.threads.busy,10)
    &target=movingMedian(Server.instance*.threads.idle,'5min')
    ```
- name: movingMin()
  id: functions#graphite.render.functions.movingMin
  summary: Graphs the moving minimum of a metric (or metrics) over a fixed number of past points, or a time interval
  belongs_to: Functions
  description: |-
    movingMin(seriesList, windowSize, xFilesFactor=None)

    Graphs the moving minimum of a metric (or metrics) over a fixed number of past points, or a time interval.

    Takes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from``/``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the minimum of the preceeding datapoints for each point on the graph.

    Example:

    ``` none
    &target=movingMin(Server.instance01.requests,10)
    &target=movingMin(Server.instance*.errors,'5min')
    ```
- name: movingSum()
  id: functions#graphite.render.functions.movingSum
  summary: Graphs the moving sum of a metric (or metrics) over a fixed number of past points, or a time interval
  belongs_to: Functions
  description: |-
    movingSum(seriesList, windowSize, xFilesFactor=None)

    Graphs the moving sum of a metric (or metrics) over a fixed number of past points, or a time interval.

    Takes one metric or a wildcard seriesList followed by a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from``/``until` in the [Render API](render_api) for examples of time formats), and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the sum of the preceeding datapoints for each point on the graph.

    Example:

    ``` none
    &target=movingSum(Server.instance01.requests,10)
    &target=movingSum(Server.instance*.errors,'5min')
    ```
- name: movingWindow()
  id: functions#graphite.render.functions.movingWindow
  summary: Graphs a moving window function of a metric (or metrics) over a fixed number of past points, or a time interval
  belongs_to: Functions
  description: |-
    movingWindow(seriesList, windowSize, func='average', xFilesFactor=None)

    Graphs a moving window function of a metric (or metrics) over a fixed number of past points, or a time interval.

    Takes one metric or a wildcard seriesList, a number N of datapoints or a quoted string with a length of time like ‘1hour’ or ‘5min’ (See `from``/``until` in the [Render API](render_api) for examples of time formats), a function to apply to the points in the window to produce the output, and an xFilesFactor value to specify how many points in the window must be non-null for the output to be considered valid. Graphs the output of the function for the preceeding datapoints for each point on the graph.

    Example:

    ``` none
    &target=movingWindow(Server.instance01.threads.busy,10)
    &target=movingWindow(Server.instance*.threads.idle,'5min','median',0.5)
    ```

    Note

    xFilesFactor follows the same semantics as in Whisper storage schemas. Setting it to 0 (the default) means that only a single value in a given interval needs to be non-null, setting it to 1 means that all values in the interval must be non-null. A setting of 0.5 means that at least half the values in the interval must be non-null.
- name: Multi-Archive Storage and Retrieval Behavior
  id: whisper#multi-archive-storage-and-retrieval-behavior
  summary: When Whisper writes to a database with multiple archives, the incoming data point is written to all archives at once
  belongs_to: The Whisper Database
  description: |-
    ## Multi-Archive Storage and Retrieval Behavior

    When Whisper writes to a database with multiple archives, the incoming data point is written to all archives at once. The data point will be written to the highest resolution archive as-is, and will be aggregated by the configured aggregation method (see [Rollup Aggregation](#rollup-aggregation)) and placed into each of the higher-retention archives. If you are in need for aggregation of the highest resolution points, please consider using [carbon-aggregator](carbon-daemons) for that purpose.

    When data is retrieved (scoped by a time range), the first archive which can satisfy the entire time period is used. If the time period overlaps an archive boundary, the lower-resolution archive will be used. This allows for a simpler behavior while retrieving data as the data’s resolution is consistent through an entire returned series.
- name: Multiple Metrics - Combining Graphs
  id: dashboard#multiple-metrics-combining-graphs
  summary: The simplest way to show more than one metric on a graph is to add each as a separate graph, and then combine the graphs
  belongs_to: The Dashboard User Interface
  description: |-
    ### Multiple Metrics - Combining Graphs

    The simplest way to show more than one metric on a graph is to add each as a separate graph, and then combine the graphs. To combine 2 graphs, drag one over the other and then wait until the target graph shows “Drop to Merge”. Drop the graph, and the target graph will now show all metrics from both graphs. Repeat for as many metrics as required.

    Note, however, that if you have multiple *related* metrics, it may be easier to use a single path containing wildcards - see [Paths and wildcards](#paths-and-wildcards).
- name: multiplySeries()
  id: functions#graphite.render.functions.multiplySeries
  summary: Takes two or more series and multiplies their points
  belongs_to: Functions
  description: |-
    multiplySeries(\*seriesLists)

    Takes two or more series and multiplies their points. A constant may not be used. To multiply by a constant, use the scale() function.

    Example:

    ``` none
    &target=multiplySeries(Series.dividends,Series.divisors)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `multiply`.
- name: multiplySeriesWithWildcards()
  id: functions#graphite.render.functions.multiplySeriesWithWildcards
  summary: Call multiplySeries after inserting wildcards at the given position(s)
  belongs_to: Functions
  description: |-
    multiplySeriesWithWildcards(seriesList, \*position)

    Call multiplySeries after inserting wildcards at the given position(s).

    Example:

    ``` none
    &target=multiplySeriesWithWildcards(web.host-[0-7].{avg-response,total-request}.value, 2)
    ```

    This would be the equivalent of

    ``` none
    &target=multiplySeries(web.host-0.{avg-response,total-request}.value)&target=multiplySeries(web.host-1.{avg-response,total-request}.value)...
    ```

    This is an alias for [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards "graphite.render.functions.aggregateWithWildcards") with aggregation `multiply`.
- name: New Dashboard
  id: dashboard#new-dashboard
  summary: Selecting the Dashboard | New menu item removes the association between the current dashboard on the screen and its saved version (if any), which means that you’ll need to use Dashboard | Save As to save it again
  belongs_to: The Dashboard User Interface
  description: |-
    ### New Dashboard

    Selecting the *Dashboard \| New* menu item removes the association between the current dashboard on the screen and its saved version (if any), which means that you’ll need to use *Dashboard \| Save As* to save it again. Note that it doesn’t clear the contents of the dashboard, i.e. the graphs - use *Remove All* to achieve this.
- name: nginx + gunicorn
  id: config-webapp#nginx-gunicorn
  summary: In this setup, nginx will proxy requests for Gunicorn, which will itself listen locally on port 8080 and serve the webapp (Django application)
  belongs_to: Configuring The Webapp
  description: |-
    ## nginx + gunicorn

    In this setup, nginx will proxy requests for Gunicorn, which will itself listen locally on port 8080 and serve the webapp (Django application).
- name: nginx + gunicorn
  id: admin-webapp#nginx-gunicorn
  summary: As nginx is already ready to proxy requests, we just need to start Gunicorn
  belongs_to: Administering The Webapp
  description: "## nginx + gunicorn\n\nAs nginx is already ready to proxy requests, we just need to start Gunicorn.\n\nThe following will do:\n\n``` none\nPYTHONPATH=/opt/graphite/webapp gunicorn wsgi --workers=4 --bind=127.0.0.1:8080 --log-file=/var/log/gunicorn.log --preload --pythonpath=/opt/graphite/webapp/graphite &\n```\n\nIt will start Gunicorn and listen on `localhost:8080`, log to `/var/log/gunicorn.log` and use `/opt/graphite/webapp/graphite` as the webapp path.\n\nNaturally, you can change these settings so that it fits your setup.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/admin-webapp.html](https://graphite.readthedocs.io/en/latest/admin-webapp.html)"
- name: Nginx + uWSGI
  id: config-webapp#nginx-uwsgi
  summary: First, you need to install uWSGI with Python support
  belongs_to: Configuring The Webapp
  description: "## Nginx + uWSGI\n\nFirst, you need to install uWSGI with Python support. On Debian, install `uwsgi-plugin-python`.\n\nThen create the uWSGI file for Graphite-web in `/etc/uwsgi/apps-available/graphite.ini`:\n\n``` ini\n[uwsgi]\nprocesses = 2\nsocket = localhost:8080\ngid = www-data\nuid = www-data\nvirtualenv = /opt/graphite\nchdir = /opt/graphite/conf\nmodule = wsgi:application\n```\n\nThen create the file `wsgi.py`:\n\n``` bash\n# /opt/graphite/conf/wsgi.py\n\nimport sys\nsys.path.append('/opt/graphite/webapp')\nfrom graphite.wsgi import application\n```\n\nEnable `graphite.ini` and restart uWSGI:\n\n``` bash\n$ ln -s /etc/uwsgi/apps-available/graphite.ini /etc/uwsgi/apps-enabled\n$ service uwsgi restart\n```\n\nFinally, configure the nginx vhost:\n\n``` nginx\n# /etc/nginx/sites-available/graphite.conf\n\nserver {\n    listen 80;\n\n    location /static/ {\n        alias /opt/graphite/webapp/content/;\n    }\n\n    location / {\n        include uwsgi_params;\n        uwsgi_pass localhost:8080;\n    }\n}\n```\n\nEnable the vhost and restart nginx:\n\n``` bash\n$ ln -s /etc/nginx/sites-available/graphite.conf /etc/nginx/sites-enabled\n$ service nginx restart\n```\n\nAcnowlegments ————\\_\n\nPortions of that manual are based on [Graphite-API deployment manual](https://github.com/brutasse/graphite-api/blob/master/docs/deployment.rst).\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-webapp.html](https://graphite.readthedocs.io/en/latest/config-webapp.html)"
- name: noCache
  id: render_api#nocache
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### noCache

    *Default: False*

    Set to disable caching of rendered images
- name: nonNegativeDerivative()
  id: functions#graphite.render.functions.nonNegativeDerivative
  summary: Same as the derivative function above, but ignores datapoints that trend down
  belongs_to: Functions
  description: |-
    nonNegativeDerivative(seriesList, maxValue=None)

    Same as the derivative function above, but ignores datapoints that trend down. Useful for counters that increase for a long time, then wrap or reset. (Such as if a network interface is destroyed and recreated by unloading and re-loading a kernel module, common with USB / WiFi cards.

    Example:

    ``` none
    &target=nonNegativederivative(company.server.application01.ifconfig.TXPackets)
    ```
- name: noNullPoints
  id: render_api#nonullpoints
  summary: If set and combined with format=json, removes all null datapoints from the series returned
  belongs_to: The Render URL API
  description: |-
    ### noNullPoints

    *Default: False*

    If set and combined with `format=json`, removes all null datapoints from the series returned.
- name: nPercentile()
  id: functions#graphite.render.functions.nPercentile
  summary: Returns n-percent of each series in the seriesList
  belongs_to: Functions
  description: |-
    nPercentile(seriesList, n)

    Returns n-percent of each series in the seriesList.
- name: offset()
  id: functions#graphite.render.functions.offset
  summary: Takes one metric or a wildcard seriesList followed by a constant, and adds the constant to each datapoint
  belongs_to: Functions
  description: |-
    offset(seriesList, factor)

    Takes one metric or a wildcard seriesList followed by a constant, and adds the constant to each datapoint.

    Example:

    ``` none
    &target=offset(Server.instance01.threads.busy,10)
    ```
- name: offsetToZero()
  id: functions#graphite.render.functions.offsetToZero
  summary: Offsets a metric or wildcard seriesList by subtracting the minimum value in the series from each datapoint
  belongs_to: Functions
  description: |-
    offsetToZero(seriesList)

    Offsets a metric or wildcard seriesList by subtracting the minimum value in the series from each datapoint.

    Useful to compare different series where the values in each series may be higher or lower on average but you’re only interested in the relative difference.

    An example use case is for comparing different round trip time results. When measuring RTT (like pinging a server), different devices may come back with consistently different results due to network latency which will be different depending on how many network hops between the probe and the device. To compare different devices in the same graph, the network latency to each has to be factored out of the results. This is a shortcut that takes the fastest response (lowest number in the series) and sets that to zero and then offsets all of the other datapoints in that series by that amount. This makes the assumption that the lowest response is the fastest the device can respond, of course the more datapoints that are in the series the more accurate this assumption is.

    Example:

    ``` none
    &target=offsetToZero(Server.instance01.responseTime)
    &target=offsetToZero(Server.instance*.responseTime)
    ```
- name: Opening a Dashboard
  id: dashboard#opening-a-dashboard
  summary: Use the Dashboard | Finder menu item to select the dashboard to open
  belongs_to: The Dashboard User Interface
  description: |-
    ### Opening a Dashboard

    Use the *Dashboard \| Finder* menu item to select the dashboard to open.
- name: Other
  id: tools#other
  summary: Time Series Alerting Framework
  belongs_to: Tools That Work With Graphite
  description: "## Other\n\n[bosun](http://bosun.org)\n\nTime Series Alerting Framework. Can use Graphite as time series source.\n\n[carbonapi](https://github.com/go-graphite/carbonapi)\n\n3rd party reimplementation of graphite-web in Go, which supports a significant subset of graphite functions. In some testing it has shown to be 5x-10x faster than requesting data from graphite-web.\n\n[Bryans-Graphite-Tools](https://github.com/linkslice/graphite-tools)\n\nA collection of miscellaneous scripts for pulling data from various devices, F5, Infoblox, Nutanix, etc.\n\n[buckytools](https://github.com/jjneely/buckytools)\n\nGo implementation of useful tools for dealing with Graphite’s Whisper DBs and Carbon hashing.\n\n[carbonate](https://github.com/graphite-project/carbonate)\n\nUtilities for managing graphite clusters.\n\n[graphite-remote-adapter](https://github.com/criteo/graphite-remote-adapter)\n\nFully featured graphite remote adapter for [Prometheus](https://github.com/prometheus/prometheus).\n\n[riemann](http://riemann.io)\n\nA network event stream processing system, in Clojure. Can use Graphite as source of event stream.\n\n[Therry](https://github.com/obfuscurity/therry)\n\nA simple web service that caches Graphite metrics and exposes an endpoint for dumping or searching against them by substring.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/tools.html](https://graphite.readthedocs.io/en/latest/tools.html)"
- name: Other Authentications
  id: config-local-settings#other-authentications
  summary: Enables the use of the Django RemoteUserBackend authentication backend
  belongs_to: Graphite-web’s local_settings.py
  description: |-
    ### Other Authentications

    USE_REMOTE_USER_AUTHENTICATION

    Default: False

    Enables the use of the Django RemoteUserBackend authentication backend. See the [Django documentation](https://docs.djangoproject.com/en/dev/howto/auth-remote-user/) for further details.

    REMOTE_USER_BACKEND

    Default: “django.contrib.auth.middleware.RemoteUserBackend”

    Enables the use of an alternative remote authentication backend.

    REMOTE_USER_MIDDLEWARE

    Default: “django.contrib.auth.middleware.RemoteUserMiddleware”

    Enables the use of an alternative remote authentication middleware.

    LOGIN_URL

    Default: /account/login

    Modifies the URL linked in the Login link in the Composer interface. This is useful for directing users to an external authentication link such as for Remote User authentication or a backend such as [django_openid_auth](https://launchpad.net/django-openid-auth).
- name: Other Global Menu Options
  id: dashboard#other-global-menu-options
  summary: null
  belongs_to: The Dashboard User Interface
  description: '## Other Global Menu Options'
- name: Other Operations on the Graph
  id: dashboard#other-operations-on-the-graph
  summary: The Graph Operations menu button is used to perform miscellaneous actions on the graph
  belongs_to: The Dashboard User Interface
  description: |-
    ### Other Operations on the Graph

    The *Graph Operations* menu button is used to perform miscellaneous actions on the graph.

    *Breakout*

    Creates new graphs for each of the metrics in the graph, adds them to the dashboard, and removes the original.

    *Clone*

    Creates a copy of the graph, and adds it to the dashboard.

    *Email*

    Allows you to send a copy of the graph to someone via email.

    *Direct URL*

    Provides the URL for rendering this graph, suitable for copying and pasting. Note that changing this URL does not affect the chart it came from, i.e. this is not a mechanism for editing the chart.
- name: Overview
  id: overview
  summary: What Graphite does not do is collect data for you, however there are some tools out there that know how to send data to graphite
  description: "# Overview\n\n## What Graphite is and is not\n\nGraphite does two things:\n\n1.  Store numeric time-series data\n2.  Render graphs of this data on demand\n\nWhat Graphite does not do is collect data for you, however there are some [tools](tools) out there that know how to send data to graphite. Even though it often requires a little code, [sending data](feeding-carbon) to Graphite is very simple.\n\n## About the project\n\nGraphite is an enterprise-scale monitoring tool that runs well on cheap hardware. It was originally designed and written by [Chris Davis](mailto:chrismd%40gmail.com) at [Orbitz](http://www.orbitz.com/) in 2006 as side project that ultimately grew to be a foundational monitoring tool. In 2008, Orbitz allowed Graphite to be released under the open source Apache 2.0 license. Since then Chris has continued to work on Graphite and has deployed it at other companies including [Sears](http://www.sears.com/), where it serves as a pillar of the e-commerce monitoring system. Today many large [companies](https://graphite.readthedocs.io/en/latest/who-is-using.html) use it.\n\n## The architecture in a nutshell\n\nGraphite consists of 3 software components:\n\n1.  **carbon** - a [Twisted](http://www.twistedmatrix.com/) daemon that listens for time-series data\n2.  **whisper** - a simple database library for storing time-series data (similar in design to [RRD](http://oss.oetiker.ch/rrdtool/))\n3.  **graphite webapp** - A [Django](http://www.djangoproject.com/) webapp that renders graphs on-demand using [Cairo](http://www.cairographics.org/)\n\n[Feeding in your data](feeding-carbon) is pretty easy, typically most of the effort is in collecting the data to begin with. As you send datapoints to Carbon, they become immediately available for graphing in the webapp. The webapp offers several ways to create and display graphs including a simple [URL API](render_api) for rendering that makes it easy to embed graphs in other webpages.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/overview.html](https://graphite.readthedocs.io/en/latest/overview.html)"
- name: Paths and Wildcards
  id: dashboard#paths-and-wildcards
  summary: In any reasonably-sized environment, you’ll have the same or similar metrics being collected from a number of points
  belongs_to: The Dashboard User Interface
  description: |-
    ### Paths and Wildcards

    In any reasonably-sized environment, you’ll have the same or similar metrics being collected from a number of points. Rather than requiring you to add each one to the graph individually, Graphite provides a powerful wildcard mechanism - for example, the metric path `servers.*ehssvc*.cpu.total.{user,system,iowait}` will include a line on the graph for the user, system and I/O wait CPU usage for every server whose name contains `ehssvc`. Each of these is referred to as a metric series. Graphite also provides a large number of functions for working on groups of metric series, e.g. showing only the top 5 metric series from a group.

    See [Paths and Wildcards](render_api#paths-and-wildcards) for further information.
- name: percentileOfSeries()
  id: functions#graphite.render.functions.percentileOfSeries
  summary: percentileOfSeries returns a single series which is composed of the n-percentile values taken across a wildcard series at each point
  belongs_to: Functions
  description: |-
    percentileOfSeries(seriesList, n, interpolate=False)

    percentileOfSeries returns a single series which is composed of the n-percentile values taken across a wildcard series at each point. Unless interpolate is set to True, percentile values are actual values contained in one of the supplied series.
- name: Performance
  id: whisper#performance
  summary: Whisper is fast enough for most purposes
  belongs_to: The Whisper Database
  description: |-
    ## Performance

    Whisper is fast enough for most purposes. It is slower than RRDtool primarily as a consequence of Whisper being written in Python, while RRDtool is written in C. The speed difference between the two in practice is quite small as much effort was spent to optimize Whisper to be as close to RRDtool’s speed as possible. Testing has shown that update operations take anywhere from 2 to 3 times as long as RRDtool, and fetch operations take anywhere from 2 to 5 times as long. In practice the actual difference is measured in hundreds of microseconds (10^-4) which means less than a millisecond difference for simple cases.
- name: perSecond()
  id: functions#graphite.render.functions.perSecond
  summary: NonNegativeDerivative adjusted for the series time interval This is useful for taking a running total metric and showing how many requests per second were handled
  belongs_to: Functions
  description: |-
    perSecond(seriesList, maxValue=None)

    NonNegativeDerivative adjusted for the series time interval This is useful for taking a running total metric and showing how many requests per second were handled.

    Example:

    ``` none
    &target=perSecond(company.server.application01.ifconfig.TXPackets)
    ```

    Each time you run ifconfig, the RX and TXPackets are higher (assuming there is network traffic.) By applying the perSecond function, you can get an idea of the packets per second sent or received, even though you’re only recording the total.
- name: pickle
  id: render_api#param-pickle
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### pickle

    Deprecated since version 0.9.10: See [Data Display Formats](#data-display-formats)
- name: pieAverage()
  id: functions#graphite.render.functions.pieAverage
  summary: null
  belongs_to: Functions
  description: |-
    pieAverage(series)

    Return the average
- name: pieLabels
  id: render_api#pielabels
  summary: Orientation to use for slice labels inside of a pie chart
  belongs_to: The Render URL API
  description: |-
    ### pieLabels

    *Default: horizontal*

    Orientation to use for slice labels inside of a pie chart.

    ` ``horizontal`` `

    Labels are oriented horizontally within each slice

    ` ``rotated`` `

    Labels are oriented radially within each slice
- name: pieMaximum()
  id: functions#graphite.render.functions.pieMaximum
  summary: null
  belongs_to: Functions
  description: |-
    pieMaximum(series)

    Return the maximum
- name: pieMinimum()
  id: functions#graphite.render.functions.pieMinimum
  summary: null
  belongs_to: Functions
  description: |-
    pieMinimum(series)

    Return the minimum
- name: pieMode
  id: render_api#piemode
  summary: The type of aggregation to use to calculate slices of a pie when graphType=pie
  belongs_to: The Render URL API
  description: |-
    ### pieMode

    *Default: average*

    The type of aggregation to use to calculate slices of a pie when `graphType=pie`. One of:

    ` ``average`` `

    The average of non-null points in the series

    ` ``maximum`` `

    The maximum of non-null points in the series

    ` ``minimum`` `

    THe minimum of non-null points in the series
- name: Post-Install Tasks
  id: install#post-install-tasks
  summary: Once you’ve installed everything you will need to create some basic configuration
  belongs_to: Installing Graphite
  description: |-
    ## Post-Install Tasks

    [Configuring Carbon](config-carbon)

    Once you’ve installed everything you will need to create some basic configuration. Initially none of the config files are created by the installer but example files are provided. Simply copy the `.example` files and customize.

    [Administering Carbon](admin-carbon)

    Once Carbon is configured, you need to start it up.

    [Feeding In Your Data](feeding-carbon)

    Once it’s up and running, you need to feed it some data.

    [Configuring The Webapp](config-webapp)

    With data getting into carbon, you probably want to look at graphs of it. So now we turn our attention to the webapp.

    [Administering The Webapp](admin-webapp)

    Once its configured you’ll need to get it running.

    [Using the Composer](https://graphite.readthedocs.io/en/latest/composer.html)

    Now that the webapp is running, you probably want to learn how to use it.
- name: pow()
  id: functions#graphite.render.functions.pow
  summary: Takes one metric or a wildcard seriesList followed by a constant, and raises the datapoint by the power of the constant provided at each point
  belongs_to: Functions
  description: |-
    pow(seriesList, factor)

    Takes one metric or a wildcard seriesList followed by a constant, and raises the datapoint by the power of the constant provided at each point.

    Example:

    ``` none
    &target=pow(Server.instance01.threads.busy,10)
    &target=pow(Server.instance*.threads.busy,10)
    ```
- name: powSeries()
  id: functions#graphite.render.functions.powSeries
  summary: Takes two or more series and pows their points
  belongs_to: Functions
  description: |-
    powSeries(\*seriesLists)

    Takes two or more series and pows their points. A constant line may be used.

    Example:

    ``` none
    &target=powSeries(Server.instance01.app.requests, Server.instance01.app.replies)
    ```
- name: pretty
  id: render_api#pretty
  summary: If set to 1 and combined with format=json, outputs human-friendly json
  belongs_to: The Render URL API
  description: |-
    ### pretty

    *Default: \<unset\>*

    If set to 1 and combined with `format=json`, outputs human-friendly json.
- name: Querying
  id: tags#querying
  summary: The seriesByTag function supports specifying any number of tag expressions to refine the list of matches
  belongs_to: Graphite Tag Support
  description: |-
    ## Querying

    When querying tagged series, we start with the [seriesByTag](functions#graphite.render.functions.seriesByTag) function:

    ``` none
    # find all series that have tag1 set to value1
    seriesByTag('tag1=value1')
    ```

    This function returns a seriesList that can then be used by any other Graphite functions:

    ``` none
    # find all series that have tag1 set to value1, sorted by total
    seriesByTag('tag1=value1') | sortByTotal()
    ```

    The [seriesByTag](functions#graphite.render.functions.seriesByTag) function supports specifying any number of tag expressions to refine the list of matches. When multiple tag expressions are specified, only series that match all the expressions will be returned.

    Tags expressions are strings, and may have the following formats:

    ``` none
    tag=spec    tag value exactly matches spec
    tag!=spec   tag value does not exactly match spec
    tag=~value  tag value matches the regular expression spec
    tag!=~spec  tag value does not match the regular expression spec
    ```

    Any tag spec that matches an empty value is considered to match series that don’t have that tag, and at least one tag spec must require a non-empty value.

    Regular expression conditions are treated as being anchored at the start of the value.

    A more complex example:

    ``` none
    # find all series where name matches the regular expression cpu\..*, AND tag1 is not value1
    seriesByTag('name=~cpu\..*', 'tag1!=value1')
    ```

    Once you have selected a seriesList, it is possible to group series together using the [groupByTags](functions#graphite.render.functions.groupByTags) function, which operates on tags in the same way that [groupByNodes](functions#graphite.render.functions.groupByNodes) works on nodes within a traditional naming hierarchy.

    ``` none
    # get a list of disk space used per datacenter for all webheads
    seriesByTag('name=disk.used', 'server=~web.*') | groupByTags('sumSeries', 'datacenter')

    # given series like:
    # disk.used;datacenter=dc1;rack=a1;server=web01
    # disk.used;datacenter=dc1;rack=b2;server=web02
    # disk.used;datacenter=dc2;rack=c3;server=web01
    # disk.used;datacenter=dc2;rack=d4;server=web02

    # will return the following new series, each containing the sum of the values for that datacenter:
    # disk.used;datacenter=dc1
    # disk.used;datacenter=dc2
    ```

    Finally, the [aliasByTags](functions#graphite.render.functions.aliasByTags) function is used to help format series names for display. It is the tag-based equivalent of the [aliasByNode](functions#graphite.render.functions.aliasByNode) function.

    ``` none
    # given series like:
    # disk.used;datacenter=dc1;rack=a1;server=web01
    # disk.used;datacenter=dc1;rack=b2;server=web02

    # format series name using datacenter tag:
    seriesByTag('name=disk.used','datacenter=dc1') | aliasByTags('server', 'name')

    # will return
    # web01.disk.used
    # web02.disk.used
    ```
- name: Querying Events
  id: events#querying-events
  summary: Graphite allows you to query for tags associated with events
  belongs_to: Graphite Events
  description: |-
    ## Querying Events

    Graphite allows you to query for tags associated with events. You can search for a single tag string, a combination of space-delimited tags, or a simple `*` wildcard using the [events](functions#graphite.render.functions.events) function.

    ``` none
    $ curl -s "http://graphite/render/?target=events('exception')&format=json" | json_pp

    [
       {
          "target" : "events(exception)",
          "datapoints" : [
             [
                1,
                1388966651
             ],
             [
                3,
                1388966652
             ]
          ]
       }
    ]
    ```

    It’s also possible to dump the raw events using the API.

    ``` none
    $ curl -s "http://graphite/events/get_data?tags=deploy&from=-3hours&until=now" | json_pp

    [
       {
          "when" : 1392046352,
          "tags" : ["deploy"],
          "data" : "deploy of master branch happened at Fri Jan 3 22:34:41 UTC 2014",
          "id" : 2,
          "what" : "Event - deploy"
       },
       {
          "id" : 3,
          "what" : "Event - deploy",
          "when" : 1392046661,
          "tags" : ["deploy"],
          "data" : "deploy of master branch happened at Fri Jan 3 22:34:41 UTC 2014"
       }
    ]
    ```

    The `set` parameter accepts an optional `union` or `intersection` argument to determine the behavior for filtering sets of tags (i.e. inclusive or exclusive). By default, Graphite uses a “lazy union” that will return any matching events for a given tag in a list of tags. This behavior is not intuitive and will therefore be deprecated in a future release.
- name: randomWalkFunction()
  id: functions#graphite.render.functions.randomWalkFunction
  summary: Returns a random walk starting at 0
  belongs_to: Functions
  description: |-
    randomWalkFunction(name, step=60)

    Short Alias: randomWalk()

    Returns a random walk starting at 0. This is great for testing when there is no real data in whisper.

    Example:

    ``` none
    &target=randomWalk("The.time.series")
    ```

    This would create a series named “The.time.series” that contains points where x(t) == x(t-1)+random()-0.5, and x(0) == 0. Accepts optional second argument as ‘step’ parameter (default step is 60 sec)
- name: rangeOfSeries()
  id: functions#graphite.render.functions.rangeOfSeries
  summary: Takes a wildcard seriesList
  belongs_to: Functions
  description: |-
    rangeOfSeries(\*seriesLists)

    Takes a wildcard seriesList. Distills down a set of inputs into the range of the series

    Example:

    ``` none
    &target=rangeOfSeries(Server*.connections.total)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `rangeOf`.
- name: rawData
  id: render_api#rawdata
  summary: Used to get numerical data out of the webapp instead of an image
  belongs_to: The Render URL API
  description: |-
    ### rawData

    Deprecated since version 0.9.9: This option is deprecated in favor of format

    Used to get numerical data out of the webapp instead of an image. Can be set to true, false, csv. Affects all `&targets` passed in the URL.

    Example:

    ``` none
    &target=carbon.agents.graphiteServer01.cpuUsage&from=-5min&rawData=true
    ```

    Returns the following text:

    ``` none
    carbon.agents.graphiteServer01.cpuUsage,1306217160,1306217460,60|0.0,0.00666666520965,0.00666666624282,0.0,0.0133345399694
    ```
- name: Re-ordering Graphs
  id: dashboard#re-ordering-graphs
  summary: Drag a graph to the position you want, and drop it before the “Drop to Merge” message shows
  belongs_to: The Dashboard User Interface
  description: |-
    ### Re-ordering Graphs

    Drag a graph to the position you want, and drop it *before the “Drop to Merge” message shows.*

    For power users wanting to perform a large scale re-ordering of graphs in a dashboard, consider using [Editing, Importing and Exporting via JSON](#editing-importing-and-exporting-via-json).
- name: Redis TagDB
  id: tags#redis-tagdb
  summary: The Redis TagDB will store the tag information on a Redis server, and is selected by setting TAGDB='graphite.tags.redis.RedisTagDB' in local_settings.py
  belongs_to: Graphite Tag Support
  description: |-
    ### Redis TagDB

    The Redis TagDB will store the tag information on a Redis server, and is selected by setting `TAGDB='graphite.tags.redis.RedisTagDB'` in local_settings.py. There are 3 additional config settings for the Redis TagDB:

    ``` default
    TAGDB_REDIS_HOST = 'localhost'
    TAGDB_REDIS_PORT = 6379
    TAGDB_REDIS_DB = 0
    ```

    The default settings (above) will connect to a local Redis server on the default port, and use the default database.
- name: reduceSeries()
  id: functions#graphite.render.functions.reduceSeries
  summary: Takes a list of seriesLists and reduces it to a list of series by means of the reduceFunction
  belongs_to: Functions
  description: |-
    reduceSeries(seriesLists, reduceFunction, reduceNode, \*reduceMatchers)

    Short form: `reduce()`

    Takes a list of seriesLists and reduces it to a list of series by means of the reduceFunction.

    Reduction is performed by matching the reduceNode in each series against the list of reduceMatchers. Then each series is passed to the reduceFunction as arguments in the order given by reduceMatchers. The reduceFunction should yield a single series.

    The resulting list of series are aliased so that they can easily be nested in other functions.

    **Example**: Map/Reduce asPercent(bytes_used,total_bytes) for each server

    Assume that metrics in the form below exist:

    ``` none
    servers.server1.disk.bytes_used
    servers.server1.disk.total_bytes
    servers.server2.disk.bytes_used
    servers.server2.disk.total_bytes
    servers.server3.disk.bytes_used
    servers.server3.disk.total_bytes
    ...
    servers.serverN.disk.bytes_used
    servers.serverN.disk.total_bytes
    ```

    To get the percentage of disk used for each server:

    ``` none
    reduceSeries(mapSeries(servers.*.disk.*,1),"asPercent",3,"bytes_used","total_bytes") =>

      alias(asPercent(servers.server1.disk.bytes_used,servers.server1.disk.total_bytes),"servers.server1.disk.reduce.asPercent"),
      alias(asPercent(servers.server2.disk.bytes_used,servers.server2.disk.total_bytes),"servers.server2.disk.reduce.asPercent"),
      alias(asPercent(servers.server3.disk.bytes_used,servers.server3.disk.total_bytes),"servers.server3.disk.reduce.asPercent"),
      ...
      alias(asPercent(servers.serverN.disk.bytes_used,servers.serverN.disk.total_bytes),"servers.serverN.disk.reduce.asPercent")
    ```

    In other words, we will get back the following metrics:

    ``` default
    servers.server1.disk.reduce.asPercent
    servers.server2.disk.reduce.asPercent
    servers.server3.disk.reduce.asPercent
    ...
    servers.serverN.disk.reduce.asPercent
    ```

    See also

    [` ``mapSeries()`` `](#graphite.render.functions.mapSeries "graphite.render.functions.mapSeries")
- name: relay-rules.conf
  id: config-carbon#relay-rules-conf
  summary: Relay rules are used to send certain metrics to a certain backend
  belongs_to: Configuring Carbon
  description: |-
    ## relay-rules.conf

    Relay rules are used to send certain metrics to a certain backend. This is handled by the carbon-relay system. It must be running for relaying to work. You can use a regular expression to select the metrics and define the servers to which they should go with the servers line.

    Example:

    ``` none
    [example]
    pattern = ^mydata\.foo\..+
    servers = 10.1.2.3, 10.1.2.4:2004, myserver.mydomain.com
    ```

    You must define at least one section as the default.
- name: removeAbovePercentile()
  id: functions#graphite.render.functions.removeAbovePercentile
  summary: Removes data above the nth percentile from the series or list of series provided
  belongs_to: Functions
  description: |-
    removeAbovePercentile(seriesList, n)

    Removes data above the nth percentile from the series or list of series provided. Values above this percentile are assigned a value of None.
- name: removeAboveValue()
  id: functions#graphite.render.functions.removeAboveValue
  summary: Removes data above the given threshold from the series or list of series provided
  belongs_to: Functions
  description: |-
    removeAboveValue(seriesList, n)

    Removes data above the given threshold from the series or list of series provided. Values above this threshold are assigned a value of None.
- name: removeBelowPercentile()
  id: functions#graphite.render.functions.removeBelowPercentile
  summary: Removes data below the nth percentile from the series or list of series provided
  belongs_to: Functions
  description: |-
    removeBelowPercentile(seriesList, n)

    Removes data below the nth percentile from the series or list of series provided. Values below this percentile are assigned a value of None.
- name: removeBelowValue()
  id: functions#graphite.render.functions.removeBelowValue
  summary: Removes data below the given threshold from the series or list of series provided
  belongs_to: Functions
  description: |-
    removeBelowValue(seriesList, n)

    Removes data below the given threshold from the series or list of series provided. Values below this threshold are assigned a value of None.
- name: removeBetweenPercentile()
  id: functions#graphite.render.functions.removeBetweenPercentile
  summary: null
  belongs_to: Functions
  description: |-
    removeBetweenPercentile(seriesList, n)

    Removes series that do not have an value lying in the x-percentile of all the values at a moment
- name: removeEmptySeries()
  id: functions#graphite.render.functions.removeEmptySeries
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    removeEmptySeries(seriesList, xFilesFactor=None)

    Takes one metric or a wildcard seriesList. Out of all metrics passed, draws only the metrics with not empty data

    Example:

    ``` none
    &target=removeEmptySeries(server*.instance*.threads.busy)
    ```

    Draws only live servers with not empty data.

    xFilesFactor follows the same semantics as in Whisper storage schemas. Setting it to 0 (the default) means that only a single value in the series needs to be non-null for it to be considered non-empty, setting it to 1 means that all values in the series must be non-null. A setting of 0.5 means that at least half the values in the series must be non-null.
- name: Removing All Graphs
  id: dashboard#removing-all-graphs
  summary: To remove all graphs on the current dashboard, use the Graphs | Remove All menu item or the red cross menu button
  belongs_to: The Dashboard User Interface
  description: |-
    ### Removing All Graphs

    To remove all graphs on the current dashboard, use the *Graphs \| Remove All* menu item or the red cross menu button. This asks for confirmation, and also gives you the option to skip confirmation in future.
- name: Removing Series from the TagDB
  id: tags#removing-series-from-the-tagdb
  summary: When a series is deleted from the data store (for example, by deleting .wsp files from the whisper storage folders), it should also be removed from the tag database
  belongs_to: Graphite Tag Support
  description: "## Removing Series from the TagDB\n\nWhen a series is deleted from the data store (for example, by deleting .wsp files from the whisper storage folders), it should also be removed from the tag database. Having series in the tag database that don’t exist in the data store won’t cause any problems with graphing, but will cause the system to do work that isn’t needed during the graph rendering, so it is recommended that the tag database be cleaned up when series are removed from the data store.\n\nSeries can be deleted via HTTP POST to the /tags/delSeries endpoint:\n\n``` none\n$ curl -X POST \"http://graphite/tags/delSeries\" \\\n  --data-urlencode 'path=disk.used;datacenter=dc1;rack=a1;server=web01'\n\ntrue\n```\n\nTo delete multiple series at once pass multiple `path` parameters:\n\n``` none\n$ curl -X POST \"http://graphite/tags/delSeries\" \\\n  --data-urlencode 'path=disk.used;datacenter=dc1;rack=a1;server=web01' \\\n  --data-urlencode 'path=disk.used;datacenter=dc1;rack=a1;server=web02'\n\ntrue\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/tags.html](https://graphite.readthedocs.io/en/latest/tags.html)"
- name: Retrieval Behavior
  id: ceres#retrieval-behavior
  summary: When data is retrieved (scoped by a time range), the first slice which has data within the requested interval is used
  belongs_to: The Ceres Database
  description: |-
    ## Retrieval Behavior

    When data is retrieved (scoped by a time range), the first slice which has data within the requested interval is used. If the time period overlaps a slice boundary, then both slices are read, with their values joined together. Any missing data between them are filled with null data points.

    There is currently no support in Ceres for handling slices with mixed resolutions in the same way that is done with Whisper archives.
- name: rewrite-rules.conf
  id: config-carbon#rewrite-rules-conf
  summary: Rewrite rules allow you to rewrite metric names using Python regular expressions
  belongs_to: Configuring Carbon
  description: |-
    ## rewrite-rules.conf

    Rewrite rules allow you to rewrite metric names using Python regular expressions. Note that unlike some other config files, any time this file is modified it will take effect automatically. This requires the carbon-aggregator service to be running.

    The form of each line in this file should be as follows:

    ``` none
    regex-pattern = replacement-text
    ```

    This will capture any received metrics that match ‘regex-pattern’ and rewrite the matched portion of the text with ‘replacement-text’. The ‘regex-pattern’ must be a valid Python regular expression, and the ‘replacement-text’ can be any value. You may also use capture groups:

    ``` none
    ^collectd\.([a-z0-9]+)\. = \1.system.
    ```

    Which would result in:

    ``` none
    collectd.prod.cpu-0.idle-time => prod.system.cpu-0.idle-item
    ```

    rewrite-rules.conf consists of two sections, \[pre\] and \[post\]. The rules in the pre section are applied to metric names as soon as they are received. The post rules are applied after aggregation has taken place.

    For example:

    ``` none
    [post]
    _sum$ =
    _avg$ =
    ```

    These rules would strip off a suffix of \_sum or \_avg from any metric names after aggregation.

    **Note:** if you plan to use the `=` sign in your rewrite rules. Use its octal value: `\075`. For example `foo=bar``=``foo.bar` would be `foo\075bar``=``foo.bar`
- name: rightColor
  id: render_api#rightcolor
  summary: In dual Y-axis mode, sets the color of all metrics associated with the right Y-axis
  belongs_to: The Render URL API
  description: |-
    ### rightColor

    *Default: color chosen from* [colorList](#colorlist)

    In dual Y-axis mode, sets the color of all metrics associated with the right Y-axis.
- name: rightDashed
  id: render_api#rightdashed
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### rightDashed

    *Default: False*

    In dual Y-axis mode, draws all metrics associated with the right Y-axis using dashed lines
- name: rightWidth
  id: render_api#rightwidth
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### rightWidth

    *Default: value of the parameter* [lineWidth](#linewidth)

    In dual Y-axis mode, sets the line width of all metrics associated with the right Y-axis
- name: Rollup Aggregation
  id: ceres#rollup-aggregation
  summary: Expected features such as roll-up aggregation and data expiration are not provided by Ceres itself, but instead are implemented as maintenance plugins
  belongs_to: The Ceres Database
  description: |-
    ## Rollup Aggregation

    Expected features such as roll-up aggregation and data expiration are not provided by Ceres itself, but instead are implemented as maintenance plugins.

    Such a rollup plugin exists in Ceres that aggregates data points in a way that is similar behavior of Whisper archives. Where multiple data points are collapsed and written to a lower precision slice, and data points outside of the set slice retentions are trimmed. By default, an average function is used, however alternative methods can be chosen by changing the metadata.
- name: Rollup Aggregation
  id: whisper#rollup-aggregation
  summary: Whisper databases with more than a single archive need a strategy to collapse multiple data points for when the data rolls up a lower precision archive
  belongs_to: The Whisper Database
  description: |-
    ## Rollup Aggregation

    Whisper databases with more than a single archive need a strategy to collapse multiple data points for when the data rolls up a lower precision archive. By default, an average function is used. Available aggregation methods are:

    - average
    - sum
    - last
    - max
    - min
- name: roundFunction()
  id: functions#graphite.render.functions.roundFunction
  summary: Takes one metric or a wildcard seriesList optionally followed by a precision, and rounds each datapoint to the specified precision
  belongs_to: Functions
  description: |-
    roundFunction(seriesList, precision=None)

    Takes one metric or a wildcard seriesList optionally followed by a precision, and rounds each datapoint to the specified precision.

    Example:

    ``` none
    &target=round(Server.instance01.threads.busy)
    &target=round(Server.instance01.threads.busy,2)
    ```
- name: Running Carbon Within Virtualenv
  id: install-virtualenv#running-carbon-within-virtualenv
  summary: null
  belongs_to: Installing in Virtualenv
  description: |-
    ## Running Carbon Within Virtualenv

    Carbon may be run within Virtualenv by [activating virtualenv](http://www.virtualenv.org/en/latest/index.html#activate-script) before Carbon is started
- name: Running Graphite-web Within Virtualenv
  id: install-virtualenv#running-graphite-web-within-virtualenv
  summary: null
  belongs_to: Installing in Virtualenv
  description: |-
    ## Running Graphite-web Within Virtualenv

    Running Django’s `django-admin.py` within a virtualenv requires using the full path of the virtualenv:

    ``` default
    /path/to/env/bin/django-admin.py <command> --settings=graphite.settings
    ```

    The method of running Graphite-web within Virtualenv depends on the WSGI server used:
- name: Running the tests
  id: development#running-the-tests
  summary: If you want to run the tests for all combinations of Python and Django versions, you can use the tox tool
  belongs_to: Working on Graphite-web
  description: |-
    ## Running the tests

    To run the tests for the Python and Django versions of your virtualenv:

    ``` default
    cd webapp
    ./manage.py test --settings=tests.settings
    ```

    If you want to run the tests for all combinations of Python and Django versions, you can use the [tox](http://tox.readthedocs.io/) tool.

    ``` default
    pip install tox
    tox
    ```

    This will run the tests for all configurations declared in the `tox.ini` file at the root of the repository.

    You can see all the configurations available by running:

    ``` default
    tox -l
    ```

    You can run a single configuration with:

    ``` default
    tox -e <configuration>
    ```

    Note that you need the corresponding python version on your system. Most systems only provide one or two different python versions, it is up to you to install other versions.
- name: Running the webapp with mod_wsgi as URL-prefixed application (Apache)
  id: config-webapp#running-the-webapp-with-mod-wsgi-as-url-prefixed-application-apache
  summary: When using the new URL_PREFIX parameter in local_settings.py the WSGIScriptAlias setting must look like the following (e.g
  belongs_to: Configuring The Webapp
  description: |-
    ### Running the webapp with mod_wsgi as URL-prefixed application (Apache)

    When using the new `URL_PREFIX` parameter in `local_settings.py` the `WSGIScriptAlias` setting must look like the following (e.g. URL_PREFIX=”/graphite”):

    ``` default
    WSGIScriptAlias /graphite /opt/graphite/conf/graphite.wsgi/graphite
    ```

    The /graphite is needed for Django to create the correct URLs
- name: Saving the Dashboard
  id: dashboard#saving-the-dashboard
  summary: If the dashboard has previously been saved, and assuming you have any required permissions (see later), you can use the Dashboard | Save menu item to save your changes
  belongs_to: The Dashboard User Interface
  description: |-
    ### Saving the Dashboard

    If the dashboard has previously been saved, and assuming you have any required permissions (see later), you can use the *Dashboard \| Save* menu item to save your changes. Note that your dashboard will be visible to all users, whether logged in or not, and can be edited and/or deleted by any user with the required permissions.

    You can use the *Dashboard \| Save As* menu item to save your dashboard for the first time, or to save it with a different name.
- name: scale()
  id: functions#graphite.render.functions.scale
  summary: Takes one metric or a wildcard seriesList followed by a constant, and multiplies the datapoint by the constant provided at each point
  belongs_to: Functions
  description: |-
    scale(seriesList, factor)

    Takes one metric or a wildcard seriesList followed by a constant, and multiplies the datapoint by the constant provided at each point.

    Example:

    ``` none
    &target=scale(Server.instance01.threads.busy,10)
    &target=scale(Server.instance*.threads.busy,10)
    ```
- name: Scales
  id: client-apis#scales
  summary: Scales is a Python server state and statistics library that can output its data to Graphite
  belongs_to: Client APIs
  description: |-
    ## Scales

    [Scales](https://github.com/Cue/scales) is a Python server state and statistics library that can output its data to Graphite.
- name: scaleToSeconds()
  id: functions#graphite.render.functions.scaleToSeconds
  summary: Takes one metric or a wildcard seriesList and returns “value per seconds” where seconds is a last argument to this functions
  belongs_to: Functions
  description: |-
    scaleToSeconds(seriesList, seconds)

    Takes one metric or a wildcard seriesList and returns “value per seconds” where seconds is a last argument to this functions.

    Useful in conjunction with derivative or integral function if you want to normalize its result to a known resolution for arbitrary retentions
- name: secondYAxis()
  id: functions#graphite.render.functions.secondYAxis
  summary: Graph the series on the secondary Y axis
  belongs_to: Functions
  description: |-
    secondYAxis(seriesList)

    Graph the series on the secondary Y axis.
- name: seriesByTag()
  id: functions#graphite.render.functions.seriesByTag
  summary: Returns a SeriesList of series matching all the specified tag expressions
  belongs_to: Functions
  description: |-
    seriesByTag(\*tagExpressions)

    Returns a SeriesList of series matching all the specified tag expressions.

    Example:

    ``` none
    &target=seriesByTag("tag1=value1","tag2!=value2")
    ```

    Returns a seriesList of all series that have tag1 set to value1, AND do not have tag2 set to value2.

    Tags specifiers are strings, and may have the following formats:

    ``` none
    tag=spec    tag value exactly matches spec
    tag!=spec   tag value does not exactly match spec
    tag=~value  tag value matches the regular expression spec
    tag!=~spec  tag value does not match the regular expression spec
    ```

    Any tag spec that matches an empty value is considered to match series that don’t have that tag.

    At least one tag spec must require a non-empty value.

    Regular expression conditions are treated as being anchored at the start of the value.

    See [querying tagged series](tags#querying-tagged-series) for more detail.
- name: Setting the Time Range
  id: dashboard#setting-the-time-range
  summary: Graphite allows you to set a time range as relative or absolute
  belongs_to: The Dashboard User Interface
  description: |-
    ### Setting the Time Range

    Graphite allows you to set a time range as relative or absolute. Relative time ranges are most commonly used. The same time range is applied to every graph on the dashboard, and the current time range is shown in the center of the menu bar.

    To set a relative time range, click the *Relative Time Range* menu button, and enter the time range to display (value and units, e.g. “6 hours”). By default, this time range ends at the current time, as shown by “Now” in the “Until” units field. However, you can move the time range back by entering your own value and units in the “Until” fields.

    To set an absolute time range, click the *Absolute Time range* menu button, and set the start and end dates and times (all are required). Dates can be selected using the calendar picker or entered directly in US format (mm/dd/yyyy), while times can be selected from the dropdown or entered in 12 or 24 hour format (e.g. “5:00 PM”, “17:00”).
- name: Setting up a development environment
  id: development#setting-up-a-development-environment
  summary: The recommended workflow is to use virtualenv / virtualenvwrapper to isolate projects between each other
  belongs_to: Working on Graphite-web
  description: |-
    ## Setting up a development environment

    The recommended workflow is to use [virtualenv](http://www.virtualenv.org/) / [virtualenvwrapper](http://virtualenvwrapper.readthedocs.io/) to isolate projects between each other. This document uses virtualenv as the lowest common denominator.

    Create a virtualenv at the root of your graphite-web repository:

    ``` default
    virtualenv env
    source env/bin/activate
    ```

    Install the required dependencies:

    ``` default
    pip install -r requirements.txt
    ```

    Create the default storage directories:

    ``` default
    mkdir -p storage/{ceres,whisper,log/webapp}
    ```

    Then you should be able to run the graphite development server:

    ``` default
    cd webapp
    ./manage.py runserver
    ```
- name: setXFilesFactor()
  id: functions#graphite.render.functions.setXFilesFactor
  summary: When a series needs to be consolidated, this sets the fraction of values in an interval that must not be null for the consolidation to be considered valid
  belongs_to: Functions
  description: |-
    setXFilesFactor(seriesList, xFilesFactor)

    Short form: xFilesFactor()

    Takes one metric or a wildcard seriesList and an xFilesFactor value between 0 and 1

    When a series needs to be consolidated, this sets the fraction of values in an interval that must not be null for the consolidation to be considered valid. If there are not enough values then None will be returned for that interval.

    ``` none
    &target=xFilesFactor(Sales.widgets.largeBlue, 0.5)
    &target=Servers.web01.sda1.free_space|consolidateBy('max')|xFilesFactor(0.5)
    ```

    The xFilesFactor set via this function is used as the default for all functions that accept an xFilesFactor parameter, all functions that aggregate data across multiple series and/or intervals, and [maxDataPoints](render_api#maxdatapoints) consolidation.

    A default for the entire render request can also be set using the [xFilesFactor](render_api#xfilesfactor) query parameter.

    Note

    xFilesFactor follows the same semantics as in Whisper storage schemas. Setting it to 0 (the default) means that only a single value in a given interval needs to be non-null, setting it to 1 means that all values in the interval must be non-null. A setting of 0.5 means that at least half the values in the interval must be non-null.
- name: Sharing a Dashboard
  id: dashboard#sharing-a-dashboard
  summary: The Share menu button shows a URL for the dashboard, allowing others to access it directly
  belongs_to: The Dashboard User Interface
  description: |-
    ### Sharing a Dashboard

    The *Share* menu button shows a URL for the dashboard, allowing others to access it directly. This first warns you that your dashboard must be saved, then presents the URL.

    Note

    If you haven’t yet saved your dashboard (ever), it will be given a name like “temporary-0”, so you probably want to save it first. It’s important to note that temporary dashboards are never shown in the Finder, and so the only way to delete them is via the Admin webapp or the database. You probably don’t want that…
- name: sinFunction()
  id: functions#graphite.render.functions.sinFunction
  summary: Just returns the sine of the current time
  belongs_to: Functions
  description: |-
    sinFunction(name, amplitude=1, step=60)

    Short Alias: sin()

    Just returns the sine of the current time. The optional amplitude parameter changes the amplitude of the wave.

    Example:

    ``` none
    &target=sin("The.time.series", 2)
    ```

    This would create a series named “The.time.series” that contains sin(x)\*2. Accepts optional second argument as ‘amplitude’ parameter (default amplitude is 1) Accepts optional third argument as ‘step’ parameter (default step is 60 sec)
- name: 'Slices: Precision and Fragmentation'
  id: ceres#slices-precision-and-fragmentation
  summary: Ceres databases contain one or more slices, each with a specific data resolution and a timestamp to mark the beginning of the slice
  belongs_to: The Ceres Database
  description: |-
    ## Slices: Precision and Fragmentation

    Ceres databases contain one or more slices, each with a specific data resolution and a timestamp to mark the beginning of the slice. Slices are ordered from the most recent timestamp to the oldest timestamp. Resolution of data is not considered when reading from a slice, only that when writing a slice with the finest precision configured for the node exists.

    Gaps in data are handled in Ceres by padding slices with null datapoints. If the slice gap however is too big, then a new slice is instead created. If a Ceres node accumulates too many slices, read performance can suffer. This can be caused by intermittently reported data. To mitigate slice fragmentation there is a tolerance for how much space can be wasted within a slice file to avoid creating a new one. That tolerance level is determined by `'MAX_SLICE_GAP'`, which is the number of consecutive null datapoints allowed in a slice file.

    If set very low, Ceres will waste less of the tiny bit disk space that this feature wastes, but then will be prone to performance problems caused by slice fragmentation, which can be pretty severe.

    If set really high, Ceres will waste a bit more disk space. Although each null datapoint wastes 8 bytes, you must keep in mind your filesystem’s block size. If you suffer slice fragmentation issues, you should increase this or defrag the data more often. However you should not set it to be huge because then if a large but allowed gap occurs it has to get filled in, which means instead of a simple 8-byte write to a new file we could end up doing an `(8``*``MAX_SLICE_GAP)`-byte write to the latest slice.
- name: smartSummarize()
  id: functions#graphite.render.functions.smartSummarize
  summary: Smarter version of summarize
  belongs_to: Functions
  description: |-
    smartSummarize(seriesList, intervalString, func='sum', alignTo=None)

    Smarter version of summarize.

    The alignToFrom boolean parameter has been replaced by alignTo and no longer has any effect. Alignment can be to years, months, weeks, days, hours, and minutes.

    This function can be used with aggregation functions `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `count`, `range`, `multiply` & `last`.
- name: sortBy()
  id: functions#graphite.render.functions.sortBy
  summary: Takes one metric or a wildcard seriesList followed by an aggregation function and an optional reverse parameter
  belongs_to: Functions
  description: |-
    sortBy(seriesList, func='average', reverse=False)

    Takes one metric or a wildcard seriesList followed by an aggregation function and an optional `reverse` parameter.

    Returns the metrics sorted according to the specified function.

    Example:

    ``` none
    &target=sortBy(server*.instance*.threads.busy,'max')
    ```

    Draws the servers in ascending order by maximum.
- name: sortByMaxima()
  id: functions#graphite.render.functions.sortByMaxima
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    sortByMaxima(seriesList)

    Takes one metric or a wildcard seriesList.

    Sorts the list of metrics in descending order by the maximum value across the time period specified. Useful with the &areaMode=all parameter, to keep the lowest value lines visible.

    Example:

    ``` none
    &target=sortByMaxima(server*.instance*.memory.free)
    ```
- name: sortByMinima()
  id: functions#graphite.render.functions.sortByMinima
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    sortByMinima(seriesList)

    Takes one metric or a wildcard seriesList.

    Sorts the list of metrics by the lowest value across the time period specified, including only series that have a maximum value greater than 0.

    Example:

    ``` none
    &target=sortByMinima(server*.instance*.memory.free)
    ```
- name: sortByName()
  id: functions#graphite.render.functions.sortByName
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    sortByName(seriesList, natural=False, reverse=False)

    Takes one metric or a wildcard seriesList. Sorts the list of metrics by the metric name using either alphabetical order or natural sorting. Natural sorting allows names containing numbers to be sorted more naturally, e.g: - Alphabetical sorting: server1, server11, server12, server2 - Natural sorting: server1, server2, server11, server12
- name: sortByTotal()
  id: functions#graphite.render.functions.sortByTotal
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    sortByTotal(seriesList)

    Takes one metric or a wildcard seriesList.

    Sorts the list of metrics in descending order by the sum of values across the time period specified.
- name: squareRoot()
  id: functions#graphite.render.functions.squareRoot
  summary: Takes one metric or a wildcard seriesList, and computes the square root of each datapoint
  belongs_to: Functions
  description: |-
    squareRoot(seriesList)

    Takes one metric or a wildcard seriesList, and computes the square root of each datapoint.

    Example:

    ``` none
    &target=squareRoot(Server.instance01.threads.busy)
    ```
- name: stacked()
  id: functions#graphite.render.functions.stacked
  summary: Takes one metric or a wildcard seriesList and change them so they are stacked
  belongs_to: Functions
  description: |-
    stacked(seriesLists, stackName='\_\_DEFAULT\_\_')

    Takes one metric or a wildcard seriesList and change them so they are stacked. This is a way of stacking just a couple of metrics without having to use the stacked area mode (that stacks everything). By means of this a mixed stacked and non stacked graph can be made

    It can also take an optional argument with a name of the stack, in case there is more than one, e.g. for input and output metrics.

    Example:

    ``` none
    &target=stacked(company.server.application01.ifconfig.TXPackets, 'tx')
    ```
- name: Starting Carbon
  id: admin-carbon#starting-carbon
  summary: This starts the main Carbon daemon in the background
  belongs_to: Administering Carbon
  description: "## Starting Carbon\n\nCarbon can be started with the `carbon-cache.py` script:\n\n``` default\n/opt/graphite/bin/carbon-cache.py start\n```\n\nThis starts the main Carbon daemon in the background. Now is a good time to check the logs, located in `/opt/graphite/storage/log/carbon-cache/` for any errors.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/admin-carbon.html](https://graphite.readthedocs.io/en/latest/admin-carbon.html)"
- name: stddevSeries()
  id: functions#graphite.render.functions.stddevSeries
  summary: Takes one metric or a wildcard seriesList
  belongs_to: Functions
  description: |-
    stddevSeries(\*seriesLists)

    Takes one metric or a wildcard seriesList. Draws the standard deviation of all metrics passed at each time.

    Example:

    ``` none
    &target=stddevSeries(company.server.*.threads.busy)
    ```

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `stddev`.
- name: stdev()
  id: functions#graphite.render.functions.stdev
  summary: Takes one metric or a wildcard seriesList followed by an integer N
  belongs_to: Functions
  description: |-
    stdev(seriesList, points, windowTolerance=0.1)

    Takes one metric or a wildcard seriesList followed by an integer N. Draw the Standard Deviation of all metrics passed for the past N datapoints. If the ratio of null points in the window is greater than windowTolerance, skip the calculation. The default for windowTolerance is 0.1 (up to 10% of points in the window can be missing). Note that if this is set to 0.0, it will cause large gaps in the output anywhere a single point is missing.

    Example:

    ``` none
    &target=stdev(server*.instance*.threads.busy,30)
    &target=stdev(server*.instance*.cpu.system,30,0.0)
    ```
- name: Step 1 - Plan a Naming Hierarchy
  id: feeding-carbon#step-1-plan-a-naming-hierarchy
  summary: Every series stored in Graphite has a unique identifier, which is composed of a metric name and optionally a set of tags
  belongs_to: Feeding In Your Data
  description: |-
    ## Step 1 - Plan a Naming Hierarchy

    Every series stored in Graphite has a unique identifier, which is composed of a metric name and optionally a set of tags.

    In a traditional hierarchy, website.orbitz.bookings.air or something like that would represent the number of air bookings on orbitz. Before producing your data you need to decide what your naming scheme will be. In a path such as “foo.bar.baz”, each thing surrounded by dots is called a path component. So “foo” is a path component, as well as “bar”, etc.

    Each path component should have a clear and well-defined purpose. Volatile path components should be kept as deep into the hierarchy as possible.

    Matt \_Aimonetti has a reasonably sane [post describing the organization of your namespace](http://matt.aimonetti.net/posts/2013/06/26/practical-guide-to-graphite-monitoring/).

    The disadvantage of a purely hierarchical system is that it is very difficult to make changes to the hierarchy, since anything querying Graphite will also need to be updated. Additionally, there is no built-in description of the meaning of any particular element in the hierarchy.

    To address these issues, Graphite also supports using tags to describe your metrics, which makes it much simpler to design the initial structure and to evolve it over time. A tagged series is made up of a name and a set of tags, like “disk.used;datacenter=dc1;rack=a1;server=web01”. In that example, the series name is “disk.used” and the tags are “datacenter” = “dc1”, “rack” = “a1”, and “server” = “web01”. When series are named this way they can be selected using the [seriesByTag](functions#graphite.render.functions.seriesByTag) function as described in [Graphite Tag Support](tags).

    When using a tagged naming scheme it is much easier to add or alter individual tags as needed. It is important however to be aware that changing the number of tags reported for a given metric or the value of a tag will create a new database file on disk, so tags should not be used for data that changes over the lifetime of a particular metric.
- name: Step 2 - Configure your Data Retention
  id: feeding-carbon#step-2-configure-your-data-retention
  summary: Graphite is built on fixed-size databases (see Whisper.) so we have to configure in advance how much data we intend to store and at what level of precision
  belongs_to: Feeding In Your Data
  description: |-
    ## Step 2 - Configure your Data Retention

    Graphite is built on fixed-size databases (see [Whisper.](whisper)) so we have to configure in advance how much data we intend to store and at what level of precision. For instance you could store your data with 1-minute precision (meaning you will have one data point for each minute) for say 2 hours. Additionally you could store your data with 10-minute precision for 2 weeks, etc. The idea is that the storage cost is determined by the number of data points you want to store, the less fine your precision, the more time you can cover with fewer points. To determine the best retention configuration, you must answer all of the following questions.

    1.  How often can you produce your data?
    2.  What is the finest precision you will require?
    3.  How far back will you need to look at that level of precision?
    4.  What is the coarsest precision you can use?
    5.  How far back would you ever need to see data? (yes it has to be finite, and determined ahead of time)

    Once you have picked your naming scheme and answered all of the retention questions, you need to create a schema by creating/editing the `/opt/graphite/conf/storage-schemas.conf` file.

    The format of the schemas file is easiest to demonstrate with an example. Let’s say we’ve written a script to collect system load data from various servers, the naming scheme will be like so:

    ` ``servers.HOSTNAME.METRIC`` `

    Where HOSTNAME will be the server’s hostname and METRIC will be something like cpu_load, mem_usage, open_files, etc. Also let’s say we want to store this data with minutely precision for 30 days, then at 15 minute precision for 10 years.

    For details of implementing your schema, see the [Configuring Carbon](config-carbon) document.

    Basically, when carbon receives a metric, it determines where on the filesystem the whisper data file should be for that metric. If the data file does not exist, carbon knows it has to create it, but since whisper is a fixed size database, some parameters must be determined at the time of file creation (this is the reason we’re making a schema). Carbon looks at the schemas file, and in order of priority (highest to lowest) looks for the first schema whose pattern matches the metric name. If no schema matches the default schema (2 hours of minutely data) is used. Once the appropriate schema is determined, carbon uses the retention configuration for the schema to create the whisper data file appropriately.
- name: Step 3 - Understanding the Graphite Message Format
  id: feeding-carbon#step-3-understanding-the-graphite-message-format
  summary: metric_path is the metric namespace that you want to populate
  belongs_to: Feeding In Your Data
  description: "## Step 3 - Understanding the Graphite Message Format\n\nGraphite understands messages with this format:\n\n``` none\nmetric_path value timestamp\\n\n```\n\n`metric_path` is the metric namespace that you want to populate.\n\n`value` is the value that you want to assign to the metric at this time.\n\n`timestamp` is the number of seconds since unix epoch time. Carbon-cache will use the time of arrival if the `timestamp` is set to `-1`.\n\nA simple example of doing this from the unix terminal would look like this:\n\n``` none\necho \"test.bash.stats 42 `date +%s`\" | nc graphite.example.com 2003\n```\n\nThere are many tools that interact with Graphite. See the [Tools](tools) page for some choices of tools that may be used to feed Graphite.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/feeding-carbon.html](https://graphite.readthedocs.io/en/latest/feeding-carbon.html)"
- name: Storage Backend Alternates
  id: tools#storage-backend-alternates
  summary: If you wish to use a backend to graphite other than Whisper, there are some options available to you
  belongs_to: Tools That Work With Graphite
  description: |-
    ## Storage Backend Alternates

    If you wish to use a backend to graphite other than Whisper, there are some options available to you.

    [BigGraphite](https://github.com/criteo/biggraphite)

    A time-series database written in Python on top of Cassandra. It integrates with Graphite as a plugin.

    [carbon-clickhouse](https://github.com/lomik/carbon-clickhouse)

    Graphite metrics receiver with [ClickHouse](https://clickhouse.yandex) as storage. You will also need [graphite-clickhouse](https://github.com/lomik/graphite-clickhouse) as backend for Graphite-web.

    [cassabon](https://github.com/jeffpierce/cassabon)

    Carbon daemon using Cassandra as the backend, implemented in Go. It also acts as an API for Graphite (using the [Cyanite](http://cyanite.io/) reader) to retrieve the stats to display.

    [Ceres](https://github.com/graphite-project/ceres)

    An alternate storage backend provided by the Graphite Project. It it intended to be a distributable time-series database. It is currently in a pre-release status.

    [Cyanite](http://cyanite.io/)

    A highly available, elastic, and low-latency time-series storage wirtten on top of Cassandra

    [graphite-clickhouse](https://github.com/lomik/graphite-clickhouse)

    Graphite-web backend with [ClickHouse](https://clickhouse.yandex) support. Please also see [carbon-clickhouse](https://github.com/lomik/carbon-clickhouse).

    [Graphouse](https://github.com/yandex/graphouse)

    Graphouse allows you to use [ClickHouse](https://clickhouse.yandex) as a Graphite storage.

    [go-carbon](https://github.com/lomik/go-carbon)

    Golang implementation of Graphite/Carbon server with classic architecture: Agent -\> Cache -\> Persister.

    [influxgraph](https://github.com/InfluxGraph/influxgraph)

    Graphite [InfluxDB](https://influxdb.com/) backend. [InfluxDB](https://influxdb.com/) storage finder / plugin for Graphite API.

    [Kenshin](https://github.com/douban/Kenshin)

    A time-series database alternative to Graphite Whisper with 40x improvement in IOPS. It integrates with Graphite as a plugin.

    [metrictank](https://github.com/grafana/metrictank)

    Cassandra-backed, metrics2.0 based, multi-tenant timeseries database for Graphite and friends.
- name: Storage Overview
  id: ceres#storage-overview
  summary: Ceres databases are comprised of a single tree contained within a single path on disk that stores all metrics in nesting directories as nodes
  belongs_to: The Ceres Database
  description: |-
    ## Storage Overview

    Ceres databases are comprised of a single tree contained within a single path on disk that stores all metrics in nesting directories as nodes.

    A Ceres node represents a single time-series metric, and is composed of at least two data files. A slice to store all data points, and an arbitrary key-value metadata file. The minimum required metadata a node needs is a `'timeStep'`. This setting is the finest resolution that can be used for writing. A Ceres node however can contain and read data with other, less-precise values in its underlying slice data.

    Other metadata keys that may be set for compatibility with Graphite are `'retentions'` , `'xFilesFacter'`, and `'aggregationMethod'`.

    A Ceres slice contains the actual data points in a file. The only other information a slice holds is the timestamp of the oldest data point, and the resolution. Both of which are encoded as part of its filename in the format `timestamp@resolution`.

    Data points in Ceres are stored on-disk as a contiguous list of big-endian double-precision floats. The timestamp of a datapoint is not stored with the value, rather it is calculated by using the timestamp of the slice plus the index offset of the value multiplied by the resolution.

    The timestamp is the number of seconds since the UNIX Epoch (01-01-1970). The data value is parsed by the Python [float()](http://docs.python.org/library/functions.html#float) function and as such behaves in the same way for special strings such as `'inf'`. Maximum and minimum values are determined by the Python interpreter’s allowable range for float values which can be found by executing:

    ``` default
    python -c 'import sys; print sys.float_info'
    ```
- name: storage-aggregation.conf
  id: config-carbon#storage-aggregation-conf
  summary: This file defines how to aggregate data to lower-precision retentions
  belongs_to: Configuring Carbon
  description: |-
    ## storage-aggregation.conf

    This file defines how to aggregate data to lower-precision retentions. The format is similar to `storage-schemas.conf`. Important notes before continuing:

    - This file is optional. If it is not present, defaults will be used.
    - The sections are applied in order from the top (first) and bottom (last), similar to `storage-schemas.conf`.
    - The first pattern that matches the metric name is used, similar to `storage-schemas.conf`.
    - There is no `retentions` line. Instead, there are `xFilesFactor` and/or `aggregationMethod` lines.
    - `xFilesFactor` should be a floating point number between 0 and 1, and specifies what fraction of the previous retention level’s slots must have non-null values in order to aggregate to a non-null value. The default is 0.5.
    - `aggregationMethod` specifies the function used to aggregate values for the next retention level. Legal methods are `average`, `sum`, `min`, `max`, and `last`. The default is `average`.
    - These are set at the time the first metric is sent.
    - Changing this file will not affect .wsp files already created on disk. Use whisper-set-aggregation-method.py to change those.

    Here’s an example:

    ``` none
    [all_min]
    pattern = \.min$
    xFilesFactor = 0.1
    aggregationMethod = min
    ```

    The pattern above will match any metric that ends with `.min`.

    The `xFilesFactor` line is saying that a minimum of 10% of the slots in the previous retention level must have values for next retention level to contain an aggregate. The `aggregationMethod` line is saying that the aggregate function to use is `min`.

    If either `xFilesFactor` or `aggregationMethod` is left out, the default value will be used.

    The aggregation parameters are kept separate from the retention parameters because the former depends on the type of data being collected and the latter depends on volume and importance.

    If you want to change aggregation methods for existing data, be sure that you update the whisper files as well.

    Example:

    ``` none
    /opt/graphite/bin/whisper-set-aggregation-method.py /opt/graphite/storage/whisper/test.wsp max
    ```

    This example sets the aggregation for the test.wsp to max. (The location of the python script depends on your installation)
- name: storage-schemas.conf
  id: config-carbon#storage-schemas-conf
  summary: This configuration file details retention rates for storing metrics
  belongs_to: Configuring Carbon
  description: |-
    ## storage-schemas.conf

    This configuration file details retention rates for storing metrics. It matches metric paths to patterns, and tells whisper what frequency and history of datapoints to store.

    Important notes before continuing:

    - There can be many sections in this file.
    - The sections are applied in order from the top (first) and bottom (last).
    - The patterns are regular expressions, as opposed to the wildcards used in the URL API.
    - The first pattern that matches the metric name is used.
    - This retention is set at the time the first metric is sent.
    - Changing this file will not affect already-created .wsp files. Use whisper-resize.py to change those.

    A given rule is made up of 3 lines:

    - A name, specified inside square brackets.
    - A regex, specified after “pattern=”
    - A retention rate line, specified after “retentions=”

    The retentions line can specify multiple retentions. Each retention of `frequency:history` is separated by a comma.

    Frequencies and histories are specified using the following suffixes:

    - s - second
    - m - minute
    - h - hour
    - d - day
    - w - week
    - y - year

    Here’s a simple, single retention example:

    ``` none
    [garbage_collection]
    pattern = garbageCollections$
    retentions = 10s:14d
    ```

    The name `[garbage_collection]` is mainly for documentation purposes, and will show up in `creates.log` when metrics matching this section are created.

    The regular expression pattern will match any metric that ends with `garbageCollections`. For example, `com.acmeCorp.instance01.jvm.memory.garbageCollections` would match, but `com.acmeCorp.instance01.jvm.memory.garbageCollections.full` would not.

    The `retentions` line is saying that each datapoint represents 10 seconds, and we want to keep enough datapoints so that they add up to 14 days of data.

    Here’s a more complicated example with multiple retention rates:

    ``` none
    [apache_busyWorkers]
    pattern = ^servers\.www.*\.workers\.busyWorkers$
    retentions = 15s:7d,1m:21d,15m:5y
    ```

    In this example, imagine that your metric scheme is `servers.<servername>.<metrics>`. The pattern would match server names that start with ‘www’, followed by anything, that are sending metrics that end in ‘.workers.busyWorkers’ (note the escaped ‘.’ characters).

    Additionally, this example uses multiple retentions. The general rule is to specify retentions from most-precise:least-history to least-precise:most-history – whisper will properly downsample metrics (averaging by default) as thresholds for retention are crossed.

    By using multiple retentions, you can store long histories of metrics while saving on disk space and I/O. Because whisper averages (by default) as it downsamples, one is able to determine totals of metrics by reversing the averaging process later on down the road.

    Example: You store the number of sales per minute for 1 year, and the sales per hour for 5 years after that. You need to know the total sales for January 1st of the year before. You can query whisper for the raw data, and you’ll get 24 datapoints, one for each hour. They will most likely be floating point numbers. You can take each datapoint, multiply by 60 (the ratio of high-precision to low-precision datapoints) and still get the total sales per hour.

    Additionally, whisper supports a legacy retention specification for backwards compatibility reasons - `seconds-per-datapoint:count-of-datapoints`

    ``` none
    retentions = 60:1440
    ```

    60 represents the number of seconds per datapoint, and 1440 represents the number of datapoints to store. This required some unnecessarily complicated math, so although it’s valid, it’s not recommended.
- name: Structured Metrics
  id: client-apis#structured-metrics
  summary: structured_metrics is a lightweight python library that uses plugins to read in Graphite’s list of metric names and convert it into a multi-dimensional tag space of clear, sanitized targets
  belongs_to: Client APIs
  description: |-
    ## Structured Metrics

    [structured_metrics](https://github.com/vimeo/graph-explorer/tree/master/structured_metrics) is a lightweight python library that uses plugins to read in Graphite’s list of metric names and convert it into a multi-dimensional tag space of clear, sanitized targets.
- name: substr()
  id: functions#graphite.render.functions.substr
  summary: Takes one metric or a wildcard seriesList followed by 1 or 2 integers
  belongs_to: Functions
  description: |-
    substr(seriesList, start=0, stop=0)

    Takes one metric or a wildcard seriesList followed by 1 or 2 integers. Assume that the metric name is a list or array, with each element separated by dots. Prints n - length elements of the array (if only one integer n is passed) or n - m elements of the array (if two integers n and m are passed). The list starts with element 0 and ends with element (length - 1).

    Example:

    ``` none
    &target=substr(carbon.agents.hostname.avgUpdateTime,2,4)
    ```

    The label would be printed as “hostname.avgUpdateTime”.
- name: summarize()
  id: functions#graphite.render.functions.summarize
  summary: Summarize the data into interval buckets of a certain size
  belongs_to: Functions
  description: |-
    summarize(seriesList, intervalString, func='sum', alignToFrom=False)

    Summarize the data into interval buckets of a certain size.

    By default, the contents of each interval bucket are summed together. This is useful for counters where each increment represents a discrete event and retrieving a “per X” value requires summing all the events in that interval.

    Specifying ‘average’ instead will return the mean for each bucket, which can be more useful when the value is a gauge that represents a certain value in time.

    This function can be used with aggregation functions `average`, `median`, `sum`, `min`, `max`, `diff`, `stddev`, `count`, `range`, `multiply` & `last`.

    By default, buckets are calculated by rounding to the nearest interval. This works well for intervals smaller than a day. For example, 22:32 will end up in the bucket 22:00-23:00 when the interval=1hour.

    Passing alignToFrom=true will instead create buckets starting at the from time. In this case, the bucket for 22:32 depends on the from time. If from=6:30 then the 1hour bucket for 22:32 is 22:30-23:30.

    Example:

    ``` none
    &target=summarize(counter.errors, "1hour") # total errors per hour
    &target=summarize(nonNegativeDerivative(gauge.num_users), "1week") # new users per week
    &target=summarize(queue.size, "1hour", "avg") # average queue size per hour
    &target=summarize(queue.size, "1hour", "max") # maximum queue size during each hour
    &target=summarize(metric, "13week", "avg", true)&from=midnight+20100101 # 2010 Q1-4
    ```
- name: sumSeries()
  id: functions#graphite.render.functions.sumSeries
  summary: This will add metrics together and return the sum at each datapoint
  belongs_to: Functions
  description: |-
    sumSeries(\*seriesLists)

    Short form: sum()

    This will add metrics together and return the sum at each datapoint. (See integral for a sum over time)

    Example:

    ``` none
    &target=sum(company.server.application*.requestsHandled)
    ```

    This would show the sum of all requests handled per minute (provided requestsHandled are collected once a minute). If metrics with different retention rates are combined, the coarsest metric is graphed, and the sum of the other metrics is averaged for the metrics with finer retention rates.

    This is an alias for [`aggregate`](#graphite.render.functions.aggregate "graphite.render.functions.aggregate") with aggregation `sum`.
- name: sumSeriesWithWildcards()
  id: functions#graphite.render.functions.sumSeriesWithWildcards
  summary: Call sumSeries after inserting wildcards at the given position(s)
  belongs_to: Functions
  description: |-
    sumSeriesWithWildcards(seriesList, \*position)

    Call sumSeries after inserting wildcards at the given position(s).

    Example:

    ``` none
    &target=sumSeriesWithWildcards(host.cpu-[0-7].cpu-{user,system}.value, 1)
    ```

    This would be the equivalent of

    ``` none
    &target=sumSeries(host.cpu-[0-7].cpu-user.value)&target=sumSeries(host.cpu-[0-7].cpu-system.value)
    ```

    This is an alias for [`aggregateWithWildcards`](#graphite.render.functions.aggregateWithWildcards "graphite.render.functions.aggregateWithWildcards") with aggregation `sum`.
- name: target
  id: render_api#target
  summary: The target parameter specifies a path identifying one or several metrics, optionally with functions acting on those metrics
  belongs_to: The Render URL API
  description: |-
    ### target

    The `target` parameter specifies a path identifying one or several metrics, optionally with functions acting on those metrics. Paths are documented below, while functions are listed on the [Functions](functions) page.

    #### Paths and Wildcards

    Metric paths show the “.” separated path from the root of the metrics tree (often starting with `servers`) to a metric, for example `servers.ix02ehssvc04v.cpu.total.user`.

    Paths also support the following wildcards, which allows you to identify more than one metric in a single path.

    *Asterisk*

    The asterisk (`*`) matches zero or more characters. It is non-greedy, so you can have more than one within a single path element.

    Example: `servers.ix*ehssvc*v.cpu.total.*` will return all total CPU metrics for all servers matching the given name pattern.

    *Character list or range*

    Characters in square brackets (`[...]`) specify a single character position in the path string, and match if the character in that position matches one of the characters in the list or range.

    A character range is indicated by 2 characters separated by a dash (`-`), and means that any character between those 2 characters (inclusive) will match. More than one range can be included within the square brackets, e.g. `foo[a-z0-9]bar` will match `foopbar`, `foo7bar` etc..

    If the characters cannot be read as a range, they are treated as a list - any character in the list will match, e.g. `foo[bc]ar` will match `foobar` and `foocar`. If you want to include a dash (`-`) in your list, put it at the beginning or end, so it’s not interpreted as a range.

    *Value list*

    Comma-separated values within curly braces (`{foo,bar,...}`) are treated as value lists, and match if any of the values matches the current point in the path. For example, `servers.ix01ehssvc04v.cpu.total.{user,system,iowait}` will match the user, system and I/O wait total CPU metrics for the specified server.

    Note

    All wildcards apply only within a single path element. In other words, they do not include or cross dots (`.`). Therefore, `servers.*` will not match `servers.ix02ehssvc04v.cpu.total.user`, while `servers.*.*.*.*` will.

    #### Tagged Series

    When querying tagged series, we start with the [seriesByTag](functions#graphite.render.functions.seriesByTag) function:

    ``` none
    # find all series that have tag1 set to value1
    seriesByTag('tag1=value1')
    ```

    See [querying tagged series](tags#querying-tagged-series) for more detail on using [seriesByTag](functions#graphite.render.functions.seriesByTag).

    #### Examples

    This will draw one or more metrics

    Example:

    ``` none
    &target=company.server05.applicationInstance04.requestsHandled
    (draws one metric)
    ```

    Let’s say there are 4 identical application instances running on each server.

    ``` none
    &target=company.server05.applicationInstance*.requestsHandled
    (draws 4 metrics / lines)
    ```

    Now let’s say you have 10 servers.

    ``` none
    &target=company.server*.applicationInstance*.requestsHandled
    (draws 40 metrics / lines)
    ```

    You can also run any number of [functions](functions) on the various metrics before graphing.

    ``` none
    &target=averageSeries(company.server*.applicationInstance.requestsHandled)
    (draws 1 aggregate line)
    ```

    Multiple function calls can be chained together either by nesting them or by piping the result into another function (it will be passed to the piped function as its first parameter):

    ``` none
    &target=movingAverage(aliasByNode(company.server*.applicationInstance.requestsHandled,1),"5min")
    &target=aliasByNode(company.server*.applicationInstance.requestsHandled,1)|movingAverage("5min")
    &target=company.server*.applicationInstance.requestsHandled|aliasByNode(1)|movingAverage("5min")
    &target=movingAverage(company.server*.applicationInstance.requestsHandled|aliasByNode(1),"5min")
    (these are all equivalent)
    ```

    The target param can also be repeated to graph multiple related metrics.

    ``` none
    &target=company.server1.loadAvg&target=company.server1.memUsage
    ```

    Note

    If more than 10 metrics are drawn the legend is no longer displayed. See the [hideLegend](#hidelegend) parameter for details.
- name: template
  id: render_api#template
  summary: The target metrics can use a special template function which allows the metric paths to contain variables
  belongs_to: The Render URL API
  description: |-
    ### template

    The `target` metrics can use a special `template` function which allows the metric paths to contain variables. Values for these variables can be provided via the `template` query parameter.

    #### Examples

    Example:

    ``` none
    &target=template(hosts.$hostname.cpu)&template[hostname]=worker1
    ```

    Default values for the template variables can also be provided:

    ``` none
    &target=template(hosts.$hostname.cpu, hostname="worker1")
    ```

    Positional arguments can be used instead of named ones:

    ``` none
    &target=template(hosts.$1.cpu, "worker1")
    &target=template(hosts.$1.cpu, "worker1")&template[1]=worker*
    ```

    In addition to path substitution, variables can be used for numeric and string literals:

    ``` none
    &target=template(constantLine($number))&template[number]=123
    &target=template(sinFunction($name))&template[name]=nameOfMySineWaveMetric
    ```
- name: template
  id: render_api#param-template
  summary: Used to specify a template from graphTemplates.conf to use for default colors and graph styles
  belongs_to: The Render URL API
  description: |-
    ### template

    *Default: default*

    Used to specify a template from `graphTemplates.conf` to use for default colors and graph styles.

    Example:

    ``` none
    &template=plain
    ```
- name: The architecture in a nutshell
  id: overview#the-architecture-in-a-nutshell
  summary: Feeding in your data is pretty easy, typically most of the effort is in collecting the data to begin with
  belongs_to: Overview
  description: "## The architecture in a nutshell\n\nGraphite consists of 3 software components:\n\n1.  **carbon** - a [Twisted](http://www.twistedmatrix.com/) daemon that listens for time-series data\n2.  **whisper** - a simple database library for storing time-series data (similar in design to [RRD](http://oss.oetiker.ch/rrdtool/))\n3.  **graphite webapp** - A [Django](http://www.djangoproject.com/) webapp that renders graphs on-demand using [Cairo](http://www.cairographics.org/)\n\n[Feeding in your data](feeding-carbon) is pretty easy, typically most of the effort is in collecting the data to begin with. As you send datapoints to Carbon, they become immediately available for graphing in the webapp. The webapp offers several ways to create and display graphs including a simple [URL API](render_api) for rendering that makes it easy to embed graphs in other webpages.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/overview.html](https://graphite.readthedocs.io/en/latest/overview.html)"
- name: The Basic Idea
  id: feeding-carbon#the-basic-idea
  summary: Graphite is useful if you have some numeric values that change over time and you want to graph them
  belongs_to: Feeding In Your Data
  description: |-
    ## The Basic Idea

    Graphite is useful if you have some numeric values that change over time and you want to graph them. Basically you write a program to collect these numeric values which then sends them to graphite’s backend, Carbon.
- name: The Carbon Daemons
  id: carbon-daemons
  summary: When we talk about “Carbon” we mean one or more of various daemons that make up the storage backend of a Graphite installation
  description: "# The Carbon Daemons\n\nWhen we talk about “Carbon” we mean one or more of various daemons that make up the storage backend of a Graphite installation. In simple installations, there is typically only one daemon, `carbon-cache.py`. As an installation grows, the `carbon-relay.py` and `carbon-aggregator.py` daemons can be introduced to distribute metrics load and perform custom aggregations, respectively.\n\nAll of the carbon daemons listen for time-series data and can accept it over a common set of [protocols](feeding-carbon). However, they differ in what they do with the data once they receive it. This document gives a brief overview of what each daemon does and how you can use them to build a more sophisticated storage backend.\n\n## carbon-cache.py\n\n`carbon-cache.py` accepts metrics over various protocols and writes them to disk as efficiently as possible. This requires caching metric values in RAM as they are received, and flushing them to disk on an interval using the underlying whisper library. It also provides a query service for in-memory metric datapoints, used by the Graphite webapp to retrieve “hot data”.\n\n`carbon-cache.py` requires some basic configuration files to run:\n\n[carbon.conf](config-carbon)  \nThe `[cache]` section tells `carbon-cache.py` what ports (2003/2004/7002), protocols (newline delimited, pickle) and transports (TCP/UDP) to listen on.\n\n[storage-schemas.conf](config-carbon)  \nDefines a retention policy for incoming metrics based on regex patterns. This policy is passed to whisper when the `.wsp` file is pre-allocated, and dictates how long data is stored for.\n\nAs the number of incoming metrics increases, one `carbon-cache.py` instance may not be enough to handle the I/O load. To scale out, simply run multiple `carbon-cache.py` instances (on one or more machines) behind a `carbon-aggregator.py` or `carbon-relay.py`.\n\nWarning\n\nIf clients connecting to the `carbon-cache.py` are experiencing errors such as connection refused by the daemon, a common reason is a shortage of file descriptors.\n\nIn the `console.log` file, if you find presence of:\n\n`Could`` ``not`` ``accept`` ``new`` ``connection`` ``(EMFILE)`\n\nor\n\n`exceptions.IOError:`` ``[Errno`` ``24]`` ``Too`` ``many`` ``open`` ``files:`` ``'/var/lib/graphite/whisper/systems/somehost/something.wsp'`\n\nthe number of files `carbon-cache.py` can open will need to be increased. Many systems default to a max of 1024 file descriptors. A value of 8192 or more may be necessary depending on how many clients are simultaneously connecting to the `carbon-cache.py` daemon.\n\nIn Linux, the system-global file descriptor max can be set via sysctl. Per-process limits are set via ulimit. See documentation for your operating system distribution for details on how to set these values.\n\n## carbon-relay.py\n\n`carbon-relay.py` serves two distinct purposes: replication and sharding.\n\nWhen running with `RELAY_METHOD`` ``=`` ``rules`, a `carbon-relay.py` instance can run in place of a `carbon-cache.py` server and relay all incoming metrics to multiple backend `carbon-cache.py`’s running on different ports or hosts.\n\nIn `RELAY_METHOD`` ``=`` ``consistent-hashing` mode, a `DESTINATIONS` setting defines a sharding strategy across multiple `carbon-cache.py` backends. The same consistent hashing list can be provided to the graphite webapp via `CARBONLINK_HOSTS` to spread reads across the multiple backends.\n\n`carbon-relay.py` is configured via:\n\n[carbon.conf](config-carbon)  \nThe `[relay]` section defines listener host/ports and a `RELAY_METHOD`\n\n[relay-rules.conf](config-carbon)  \nWith `RELAY_METHOD`` ``=`` ``rules` set, pattern/servers tuples in this file define which metrics matching certain regex rules are forwarded to which hosts.\n\n## carbon-aggregator.py\n\n`carbon-aggregator.py` can be run in front of `carbon-cache.py` to buffer metrics over time before reporting them into whisper. This is useful when granular reporting is not required, and can help reduce I/O load and whisper file sizes due to lower retention policies.\n\n`carbon-aggregator.py` is configured via:\n\n[carbon.conf](config-carbon)  \nThe `[aggregator]` section defines listener and destination host/ports.\n\n[aggregation-rules.conf](config-carbon)  \nDefines a time interval (in seconds) and aggregation function (sum or average) for incoming metrics matching a certain pattern. At the end of each interval, the values received are aggregated and published to `carbon-cache.py` as a single metric.\n\n## carbon-aggregator-cache.py\n\n`carbon-aggregator-cache.py` combines both `carbon-aggregator.py` and `carbon-cache.py`. This is useful to reduce the resource and administration overhead of running both daemons.\n\n`carbon-aggregator-cache.py` is configured via:\n\n[carbon.conf](config-carbon)  \nThe `[aggregator-cache]` section defines listener and destination host/ports.\n\n[relay-rules.conf](config-carbon)  \nSee carbon-relay.py section.\n\n[aggregation-rules.conf](config-carbon)  \nSee carbon-aggregator.py section.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/carbon-daemons.html](https://graphite.readthedocs.io/en/latest/carbon-daemons.html)"
- name: The Ceres Database
  id: ceres
  summary: Ceres is a time-series database format intended to replace Whisper as the default storage format for Graphite
  description: "# The Ceres Database\n\nCeres is a time-series database format intended to replace Whisper as the default storage format for Graphite. In contrast with Whisper, Ceres is not a fixed-size database and is designed to better support sparse data of arbitrary fixed-size resolutions. This allows Graphite to distribute individual time-series across multiple servers or mounts.\n\nCeres is not actively developped at the moment. For alternatives to whisper look at [alternative storage backends](tools).\n\n## Storage Overview\n\nCeres databases are comprised of a single tree contained within a single path on disk that stores all metrics in nesting directories as nodes.\n\nA Ceres node represents a single time-series metric, and is composed of at least two data files. A slice to store all data points, and an arbitrary key-value metadata file. The minimum required metadata a node needs is a `'timeStep'`. This setting is the finest resolution that can be used for writing. A Ceres node however can contain and read data with other, less-precise values in its underlying slice data.\n\nOther metadata keys that may be set for compatibility with Graphite are `'retentions'` , `'xFilesFacter'`, and `'aggregationMethod'`.\n\nA Ceres slice contains the actual data points in a file. The only other information a slice holds is the timestamp of the oldest data point, and the resolution. Both of which are encoded as part of its filename in the format `timestamp@resolution`.\n\nData points in Ceres are stored on-disk as a contiguous list of big-endian double-precision floats. The timestamp of a datapoint is not stored with the value, rather it is calculated by using the timestamp of the slice plus the index offset of the value multiplied by the resolution.\n\nThe timestamp is the number of seconds since the UNIX Epoch (01-01-1970). The data value is parsed by the Python [float()](http://docs.python.org/library/functions.html#float) function and as such behaves in the same way for special strings such as `'inf'`. Maximum and minimum values are determined by the Python interpreter’s allowable range for float values which can be found by executing:\n\n``` default\npython -c 'import sys; print sys.float_info'\n```\n\n## Slices: Precision and Fragmentation\n\nCeres databases contain one or more slices, each with a specific data resolution and a timestamp to mark the beginning of the slice. Slices are ordered from the most recent timestamp to the oldest timestamp. Resolution of data is not considered when reading from a slice, only that when writing a slice with the finest precision configured for the node exists.\n\nGaps in data are handled in Ceres by padding slices with null datapoints. If the slice gap however is too big, then a new slice is instead created. If a Ceres node accumulates too many slices, read performance can suffer. This can be caused by intermittently reported data. To mitigate slice fragmentation there is a tolerance for how much space can be wasted within a slice file to avoid creating a new one. That tolerance level is determined by `'MAX_SLICE_GAP'`, which is the number of consecutive null datapoints allowed in a slice file.\n\nIf set very low, Ceres will waste less of the tiny bit disk space that this feature wastes, but then will be prone to performance problems caused by slice fragmentation, which can be pretty severe.\n\nIf set really high, Ceres will waste a bit more disk space. Although each null datapoint wastes 8 bytes, you must keep in mind your filesystem’s block size. If you suffer slice fragmentation issues, you should increase this or defrag the data more often. However you should not set it to be huge because then if a large but allowed gap occurs it has to get filled in, which means instead of a simple 8-byte write to a new file we could end up doing an `(8`` ``*`` ``MAX_SLICE_GAP)`-byte write to the latest slice.\n\n## Rollup Aggregation\n\nExpected features such as roll-up aggregation and data expiration are not provided by Ceres itself, but instead are implemented as maintenance plugins.\n\nSuch a rollup plugin exists in Ceres that aggregates data points in a way that is similar behavior of Whisper archives. Where multiple data points are collapsed and written to a lower precision slice, and data points outside of the set slice retentions are trimmed. By default, an average function is used, however alternative methods can be chosen by changing the metadata.\n\n## Retrieval Behavior\n\nWhen data is retrieved (scoped by a time range), the first slice which has data within the requested interval is used. If the time period overlaps a slice boundary, then both slices are read, with their values joined together. Any missing data between them are filled with null data points.\n\nThere is currently no support in Ceres for handling slices with mixed resolutions in the same way that is done with Whisper archives.\n\n## Database Format\n\n|            |        |          |\n|------------|--------|----------|\n| CeresSlice | *Data* |          |\n|            | Data   | *Point+* |\n\nData types in Python’s [struct format](http://docs.python.org/library/struct.html#format-strings):\n\n|       |      |\n|-------|------|\n| Point | `!d` |\n\nMetadata for Ceres is stored in [JSON format](https://docs.python.org/3/library/json.html):\n\n> {“retentions”: \\[\\[30, 1440\\]\\], “timeStep”: 30, “xFilesFactor”: 0.5, “aggregationMethod”: “average”}\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/ceres.html](https://graphite.readthedocs.io/en/latest/ceres.html)"
- name: The Dashboard User Interface
  id: dashboard
  summary: The Dashboard interface is the tool of choice for displaying more than one graph at a time, with all graphs showing the same time range
  description: "# The Dashboard User Interface\n\nThe Dashboard interface is the tool of choice for displaying more than one graph at a time, with all graphs showing the same time range. Unless you’re using the HTTP interface to embed graphs in your own applications or web pages, this is the Graphite interface you’ll use most often. It’s certainly the interface that will be of most use to operations staff.\n\n## Getting Started with the Dashboard Interface\n\nYou can access the Dashboard interface directly at `http://my.graphite.host/dashboard`, or via the link at the top of the Composer interface.\n\n### Completer or browser tree?\n\nWhen you open the Dashboard interface, you’ll see the top of the page taken up by a completer. This allows you to select a metric series to show on a graph in the dashboard.\n\nIf you’re only viewing a dashboard rather than modifying one, the completer just gets in the way. You can either resize it by dragging the splitter bar (between the completer and graph panels), or hide it by clicking on the little triangular icon in the splitter bar. Once hidden, the same triangular icon serves to display the panel again.\n\nAn alternative to the completer is a browser tree, which shows to the left of the graph panel. To change to this mode, use the *Dashboard \\| Configure UI* menu item, and choose *Tree (left nav)*. You’ll have to refresh the page to get this to show. The completer and browser tree do the same job, so the choice is down to your personal preference. Your choice is recorded in a persistent browser cookie, so it should be preserved across sessions.\n\n## Creating or Modifying a Dashboard\n\nWhen you open the Dashboard interface, no dashboard is open. You can either start building a new dashboard, or you can open an existing one (see [Opening a Dashboard](#opening-a-dashboard)) and modify that. If you’re working on a previously-saved dashboard, its name will show at the top of the completer and browser tree panels.\n\n**Note for Power Users:** Any action that can be performed via the UI, as explained in this section, can also be performed using the Edit Dashboard function (as JSON text). See [Editing, Importing and Exporting via JSON](#editing-importing-and-exporting-via-json).\n\n### Adding a Graph\n\nTo add a new graph directly, you select a metric series in the completer or browser tree, and a graph for that value is added to the end of the dashboard. Alternatively, if a graph for that metric series already exists on the dashboard, it will be removed.\n\nSee later for ways of customizing the graph, including adding multiple metric series, changing axes, adding titles and legends etc.\n\n### Importing a Graph\n\nExisting graphs can be imported into your dashboard, either from URLs or from saved graphs.\n\nImport a graph from a URL when you already have the graph you want displaying elsewhere (maybe you built it in the Completer, or you want to copy it from another dashboard). Use the *Graphs \\| New Graph \\| From URL* menu item and enter the URL, which you probably copied from another browser window.\n\nAlternatively, if you’ve saved a graph in the Composer, you can import it. Use the *Graphs \\| New Graph \\| From Saved Graph* menu item, and select the graph to import.\n\n### Deleting a Graph\n\nWhen you hover the mouse over a graph, a red cross icon appears at the top right. Click this to delete the graph from the dashboard.\n\n### Multiple Metrics - Combining Graphs\n\nThe simplest way to show more than one metric on a graph is to add each as a separate graph, and then combine the graphs. To combine 2 graphs, drag one over the other and then wait until the target graph shows “Drop to Merge”. Drop the graph, and the target graph will now show all metrics from both graphs. Repeat for as many metrics as required.\n\nNote, however, that if you have multiple *related* metrics, it may be easier to use a single path containing wildcards - see [Paths and wildcards](#paths-and-wildcards).\n\n### Re-ordering Graphs\n\nDrag a graph to the position you want, and drop it *before the “Drop to Merge” message shows.*\n\nFor power users wanting to perform a large scale re-ordering of graphs in a dashboard, consider using [Editing, Importing and Exporting via JSON](#editing-importing-and-exporting-via-json).\n\n### Saving the Dashboard\n\nIf the dashboard has previously been saved, and assuming you have any required permissions (see later), you can use the *Dashboard \\| Save* menu item to save your changes. Note that your dashboard will be visible to all users, whether logged in or not, and can be edited and/or deleted by any user with the required permissions.\n\nYou can use the *Dashboard \\| Save As* menu item to save your dashboard for the first time, or to save it with a different name.\n\n## Viewing a Dashboard\n\nThis section explains the options available when viewing an existing dashboard. Once you’ve defined the dashboards you need, you’ll spend most of your time in this mode.\n\nNote that you’ll most likely want to hide the completer when working in this mode - see earlier.\n\n### Opening a Dashboard\n\nUse the *Dashboard \\| Finder* menu item to select the dashboard to open.\n\n### Setting the Time Range\n\nGraphite allows you to set a time range as relative or absolute. Relative time ranges are most commonly used. The same time range is applied to every graph on the dashboard, and the current time range is shown in the center of the menu bar.\n\nTo set a relative time range, click the *Relative Time Range* menu button, and enter the time range to display (value and units, e.g. “6 hours”). By default, this time range ends at the current time, as shown by “Now” in the “Until” units field. However, you can move the time range back by entering your own value and units in the “Until” fields.\n\nTo set an absolute time range, click the *Absolute Time range* menu button, and set the start and end dates and times (all are required). Dates can be selected using the calendar picker or entered directly in US format (mm/dd/yyyy), while times can be selected from the dropdown or entered in 12 or 24 hour format (e.g. “5:00 PM”, “17:00”).\n\n### Manual and Auto Refresh\n\nBy default, dashboards are set to manually refresh. Click the green refresh menu button to the left of the *Auto-Refresh* button to refresh the dashboard. The time of the last refresh is shown at the right of the menu bar.\n\nAlternatively, set the dashboard to auto-refresh by ensuring that the *Auto-Refresh* menu button is pressed in. The refresh defaults to 60 seconds, but you can change this in the edit field to the right of the *Auto-Refresh* button.\n\nNote that refresh options are saved with the dashboard.\n\n## Customizing Graphs\n\nTo change a graph on the dashboard, click on it. This will display a pop-up containing the following sections:\n\n- A list of all metric elements, i.e. the path and functions for each of the data elements displayed on the graph\n- An *Apply Function* menu button, which allows functions to be applied to the currently-selected item in the metrics list\n- A *Render Operations* menu button, which allows customization of the graph as a whole\n- A *Graph Operations* menu button, providing menu items for miscellaneous actions to take on the graph.\n\nNote\n\nThe items in the list of metrics can be edited in place. Double-click the item, edit as required, then hit Enter to complete.\n\n### Paths and Wildcards\n\nIn any reasonably-sized environment, you’ll have the same or similar metrics being collected from a number of points. Rather than requiring you to add each one to the graph individually, Graphite provides a powerful wildcard mechanism - for example, the metric path `servers.*ehssvc*.cpu.total.{user,system,iowait}` will include a line on the graph for the user, system and I/O wait CPU usage for every server whose name contains `ehssvc`. Each of these is referred to as a metric series. Graphite also provides a large number of functions for working on groups of metric series, e.g. showing only the top 5 metric series from a group.\n\nSee [Paths and Wildcards](render_api#paths-and-wildcards) for further information.\n\n### Customizing a Single Metric Element\n\nTo customize a single metric element, you select the element in the metric list, then use the menu items on the *Apply Function* menu button to apply functions to the metric element. Note that each metric element in the list may include multiple metric series, e.g. if the path includes wildcards.\n\nNote\n\nAll these actions use functions documented on [the functions page](functions#list-of-functions). For further information, read the documentation for the appropriate function on that page. Function names are included in brackets in the list below.\n\nThe functions are grouped in the menu, as follows:\n\n*Combine*  \nFunctions that combine a group of metric series (returned by a path containing wildcards) into a single series (and therefore a single line). Includes sum, average, product, minimum, maximum.\n\n*Transform*  \nFunctions that transform the values in a metric series, against either the Y-axis or (less commonly) the X-axis. Includes scale, scale to seconds, offset, derivative, integral, time-shift, log.\n\n*Calculate*  \nFunctions that calculate a new metric series based on an existing metric series. Includes moving average, percentage, Holt-Winters forecast, ratio and difference (of 2 metrics)\n\n*Filter*  \nFunctions that filter metric series from a group. Includes highest current value, current value above limit, most deviant, remove below percentile.\n\n*Special*  \nFunctions that control how the metric series are drawn on the graph. Includes line colors/widths/styles, drawing stacked, drawing on the second Y-axis, and setting the legend name either directly or from the path.\n\nThe last menu item is *Remove Outer Call*, which removes the outer-most function on the current metric.\n\n### Customizing the Whole Graph\n\nThe *Render Options* menu button is used to set options that apply to the whole graph, rather than just the selected metric.\n\nNote\n\nEach of the items in this menu matches a graph parameter in the [The Render URL API](render_api). For further information, read the documentation for the appropriate parameter on that page.\n\nThe functions are grouped as follows:\n\n*Graph Title*  \nUnsurprisingly, this sets the title for the graph. See [title](render_api#param-title).\n\n*Display*  \nProvides options for:\n\n- fonts (see [fontName](render_api#param-fontname), [fontBold](render_api#param-fontbold), [fontItalic](render_api#param-fontitalic), [fontSize](render_api#param-fontsize) and [fgcolor](render_api#param-fgcolor))\n- colors (see [colorList](render_api#param-colorlist), [bgcolor](render_api#param-bgcolor), [majorGridLineColor](render_api#param-majorgridlinecolor), [minorGridLineColor](render_api#param-minorgridlinecolor) and [areaAlpha](render_api#param-areaalpha))\n- legends (see [hideLegend](render_api#param-hidelegend) and [uniqueLegend](render_api#param-uniquelegend))\n- line thickness (see [lineWidth](render_api#param-linewidth))\n- hiding of graph elements (see [graphOnly](render_api#param-graphonly), [hideAxes](render_api#param-hideaxes), [hideYAxis](render_api#param-hideyaxis) and [hideGrid](render_api#param-hidegrid))\n- apply a template (see [template](render_api#param-template)).\n\n*Line Mode*  \nSets the way lines are rendered, e.g. sloped, staircase, connected, and how the value `None` is rendered. See [lineMode](render_api#param-linemode) and [drawNullAsZero](render_api#param-drawnullaszero).\n\n*Area Mode*  \nDetermines whether the area below lines is filled, and whether the lines are stacked. See [areaMode](render_api#param-areamode).\n\n*X-Axis*  \nAllows setting the time format for dates/times on the axis (see [xFormat](render_api#param-xformat)), the timezone for interpretation of timestamps (see [tz](render_api#param-tz)), and the threshold for point consolidation (the closest number of pixels between points before they are consolidated, see [minXStep](render_api#param-minxstep)).\n\n*Y-Axis*  \nDetermines how the Y-axis or axes are rendered. This includes:\n\n- label (see [vtitle](render_api#param-vtitle))\n- minimum/maximum values on the axis (see [yMin](render_api#param-ymin) and [yMax](render_api#param-ymax))\n- the number of minor lines to draw (see [minorY](render_api#param-minory))\n- drawing on a logarithmic scale of the specified base (see [logBase](render_api#param-logbase))\n- step between the Y-axis labels and gridlines (see [yStep](render_api#param-ystep))\n- divisor for the axis (see [yDivisors](render_api#param-ydivisors))\n- unit system (SI, binary, or none - see [yUnitSystem](render_api#param-yunitsystem))\n- side the axis appears (see [yAxisSide](render_api#param-yaxisside)).\n\nWhen you have more than one Y-axis (because you selected *Apply Function \\| Special \\| Draw in second Y axis* for at least one metric series), use the *Dual Y-Axis Options* item on this menu. This provides individual control of both the left and right Y-axes, with the same settings as listed above.\n\n### Other Operations on the Graph\n\nThe *Graph Operations* menu button is used to perform miscellaneous actions on the graph.\n\n*Breakout*  \nCreates new graphs for each of the metrics in the graph, adds them to the dashboard, and removes the original.\n\n*Clone*  \nCreates a copy of the graph, and adds it to the dashboard.\n\n*Email*  \nAllows you to send a copy of the graph to someone via email.\n\n*Direct URL*  \nProvides the URL for rendering this graph, suitable for copying and pasting. Note that changing this URL does not affect the chart it came from, i.e. this is not a mechanism for editing the chart.\n\n## Other Global Menu Options\n\n### Editing, Importing and Exporting via JSON\n\nThe *Dashboard \\| Edit Dashboard* menu item shows a JSON (JavaScript Object Notation) representation of the current dashboard and all its graphs in an editor dialog.\n\nIf you’re a power user, you can edit the dashboard configuration directly. When you click the *Update* button, the changes are applied to the dashboard on screen only. This function also provides a convenient mechanism for importing and exporting dashboards, for instance to promote dashboards from development to production systems.\n\nNote\n\nThe Update button does not save your changes - you’ll need to use *Save* or *Save As* to do this.\n\n### Sharing a Dashboard\n\nThe *Share* menu button shows a URL for the dashboard, allowing others to access it directly. This first warns you that your dashboard must be saved, then presents the URL.\n\nNote\n\nIf you haven’t yet saved your dashboard (ever), it will be given a name like “temporary-0”, so you probably want to save it first. It’s important to note that temporary dashboards are never shown in the Finder, and so the only way to delete them is via the Admin webapp or the database. You probably don’t want that…\n\n### Changing Graph Sizes\n\nThe *Graphs \\| Resize* menu item and the Gear menu button allow all graphs on the dashboard to be set to a specified size. You can either choose one of the preset sizes, or select *Custom* and enter your own width and height (in pixels).\n\n### New Dashboard\n\nSelecting the *Dashboard \\| New* menu item removes the association between the current dashboard on the screen and its saved version (if any), which means that you’ll need to use *Dashboard \\| Save As* to save it again. Note that it doesn’t clear the contents of the dashboard, i.e. the graphs - use *Remove All* to achieve this.\n\n### Removing All Graphs\n\nTo remove all graphs on the current dashboard, use the *Graphs \\| Remove All* menu item or the red cross menu button. This asks for confirmation, and also gives you the option to skip confirmation in future.\n\n### Deleting a Dashboard\n\nTo delete a dashboard, open the Finder (using the *Dashboard \\| Finder* menu item), select the dashboard to delete in the list, and click *Delete*. Note that you may need to be logged in as a user with appropriate permissions to do this, depending on the configuration of Graphite.\n\n### Login/logout\n\nBy default, it’s not necessary to be logged in to use or change dashboards. However, your system may be configured to require users to be logged in to change or delete dashboards, and may also require appropriate permissions to do so.\n\nLog into Graphite using the *Dashboard \\| Log in* menu item, which shows a standard login dialog. Once you’re logged in, the menu item changes to *Log out from “username”* - click this to log out again. Note that logins are recorded by a persistent browser cookie, so you don’t have to log in again each time you connect to Graphite.\n\n### Changing Default Graph Parameters\n\nBy default, graphs are generated with a standard render template. If you find yourself applying *Render Options* to each and every graph you create, then you can select *Edit Default Parameters* in the *Graphs* menu to automatically handle that. These parameters are saved with the dashboard and persisted in a cookie.\n\nThe format is as a set of key-value pairs separated by ampersands, like a query string. The keys and values come from [The Render URL API](render_api) and they’re all available. For example:\n\n`drawNullAsZero=true&graphOnly=true`\n\nAny new graphs created after saving that as the default graph parameters would have unreported metrics graphed as zeroes and omit the grid lines.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/dashboard.html](https://graphite.readthedocs.io/en/latest/dashboard.html)"
- name: The pickle protocol
  id: feeding-carbon#the-pickle-protocol
  summary: The pickle protocol is a much more efficient take on the plaintext protocol, and supports sending batches of metrics to Carbon in one go
  belongs_to: Feeding In Your Data
  description: |-
    ## The pickle protocol

    The pickle protocol is a much more efficient take on the plaintext protocol, and supports sending batches of metrics to Carbon in one go.

    The general idea is that the pickled data forms a list of multi-level tuples:

    ``` none
    [(path, (timestamp, value)), ...]
    ```

    Once you’ve formed a list of sufficient size (don’t go too big!), and pickled it (if your client is running a more recent version of python than your server, you may need to specify the protocol) send the data over a socket to Carbon’s pickle receiver (by default, port 2004). You’ll need to pack your pickled data into a packet containing a simple header:

    ``` python
    payload = pickle.dumps(listOfMetricTuples, protocol=2)
    header = struct.pack("!L", len(payload))
    message = header + payload
    ```

    You would then send the `message` object through a network socket.
- name: The plaintext protocol
  id: feeding-carbon#the-plaintext-protocol
  summary: The plaintext protocol is the most straightforward protocol supported by Carbon
  belongs_to: Feeding In Your Data
  description: |-
    ## The plaintext protocol

    The plaintext protocol is the most straightforward protocol supported by Carbon.

    The data sent must be in the following format: `<metric``path>``<metric``value>``<metric``timestamp>`. Carbon will then help translate this line of text into a metric that the web interface and Whisper understand.

    On Unix, the `nc` program (`netcat`) can be used to create a socket and send data to Carbon (by default, ‘plaintext’ runs on port 2003):

    > ``` none
    > PORT=2003
    > SERVER=graphite.your.org
    > echo "local.random.diceroll 4 `date +%s`" | nc ${SERVER} ${PORT}
    > ```
    >
    > As many `netcat` implementations exist, a parameter may be needed to instruct `nc` to close the socket once data is sent. Such param will usually be `-q0`, `-c` or `-N`. Refer to your `nc` implementation man page to determine it.
    >
    > Note that if your Carbon instance is listening using the UDP protocol, you also need the `-u` parameter.
- name: The Render URL API
  id: render_api
  summary: The graphite webapp provides a /render endpoint for generating graphs and retrieving raw data
  description: "# The Render URL API\n\nThe graphite webapp provides a `/render` endpoint for generating graphs and retrieving raw data. This endpoint accepts various arguments via query string parameters. These parameters are separated by an ampersand (`&`) and are supplied in the format:\n\n``` none\n&name=value\n```\n\nTo verify that the api is running and able to generate images, open `http://GRAPHITE_HOST:GRAPHITE_PORT/render` in a browser. The api should return a simple 330x250 image with the text “No Data”.\n\nOnce the api is running and you’ve begun [feeding data into carbon](feeding-carbon), use the parameters below to customize your graphs and pull out raw data. For example:\n\n``` none\n# single server load on large graph\nhttp://graphite/render?target=server.web1.load&height=800&width=600\n\n# average load across web machines over last 12 hours\nhttp://graphite/render?target=averageSeries(server.web*.load)&from=-12hours\n\n# number of registered users over past day as raw json data\nhttp://graphite/render?target=app.numUsers&format=json\n\n# rate of new signups per minute\nhttp://graphite/render?target=summarize(derivative(app.numUsers),\"1min\")&title=New_Users_Per_Minute\n```\n\nNote\n\nMost of the functions and parameters are case sensitive. For example `&linewidth=2` will fail silently. The correct parameter in this case is `&lineWidth=2`\n\n## Graphing Metrics\n\nTo begin graphing specific metrics, pass one or more [target](#target) parameters and specify a time window for the graph via [from / until](#from-until).\n\n### target\n\nThe `target` parameter specifies a path identifying one or several metrics, optionally with functions acting on those metrics. Paths are documented below, while functions are listed on the [Functions](functions) page.\n\n#### Paths and Wildcards\n\nMetric paths show the “.” separated path from the root of the metrics tree (often starting with `servers`) to a metric, for example `servers.ix02ehssvc04v.cpu.total.user`.\n\nPaths also support the following wildcards, which allows you to identify more than one metric in a single path.\n\n*Asterisk*  \nThe asterisk (`*`) matches zero or more characters. It is non-greedy, so you can have more than one within a single path element.\n\nExample: `servers.ix*ehssvc*v.cpu.total.*` will return all total CPU metrics for all servers matching the given name pattern.\n\n*Character list or range*  \nCharacters in square brackets (`[...]`) specify a single character position in the path string, and match if the character in that position matches one of the characters in the list or range.\n\nA character range is indicated by 2 characters separated by a dash (`-`), and means that any character between those 2 characters (inclusive) will match. More than one range can be included within the square brackets, e.g. `foo[a-z0-9]bar` will match `foopbar`, `foo7bar` etc..\n\nIf the characters cannot be read as a range, they are treated as a list - any character in the list will match, e.g. `foo[bc]ar` will match `foobar` and `foocar`. If you want to include a dash (`-`) in your list, put it at the beginning or end, so it’s not interpreted as a range.\n\n*Value list*  \nComma-separated values within curly braces (`{foo,bar,...}`) are treated as value lists, and match if any of the values matches the current point in the path. For example, `servers.ix01ehssvc04v.cpu.total.{user,system,iowait}` will match the user, system and I/O wait total CPU metrics for the specified server.\n\nNote\n\nAll wildcards apply only within a single path element. In other words, they do not include or cross dots (`.`). Therefore, `servers.*` will not match `servers.ix02ehssvc04v.cpu.total.user`, while `servers.*.*.*.*` will.\n\n#### Tagged Series\n\nWhen querying tagged series, we start with the [seriesByTag](functions#graphite.render.functions.seriesByTag) function:\n\n``` none\n# find all series that have tag1 set to value1\nseriesByTag('tag1=value1')\n```\n\nSee [querying tagged series](tags#querying-tagged-series) for more detail on using [seriesByTag](functions#graphite.render.functions.seriesByTag).\n\n#### Examples\n\nThis will draw one or more metrics\n\nExample:\n\n``` none\n&target=company.server05.applicationInstance04.requestsHandled\n(draws one metric)\n```\n\nLet’s say there are 4 identical application instances running on each server.\n\n``` none\n&target=company.server05.applicationInstance*.requestsHandled\n(draws 4 metrics / lines)\n```\n\nNow let’s say you have 10 servers.\n\n``` none\n&target=company.server*.applicationInstance*.requestsHandled\n(draws 40 metrics / lines)\n```\n\nYou can also run any number of [functions](functions) on the various metrics before graphing.\n\n``` none\n&target=averageSeries(company.server*.applicationInstance.requestsHandled)\n(draws 1 aggregate line)\n```\n\nMultiple function calls can be chained together either by nesting them or by piping the result into another function (it will be passed to the piped function as its first parameter):\n\n``` none\n&target=movingAverage(aliasByNode(company.server*.applicationInstance.requestsHandled,1),\"5min\")\n&target=aliasByNode(company.server*.applicationInstance.requestsHandled,1)|movingAverage(\"5min\")\n&target=company.server*.applicationInstance.requestsHandled|aliasByNode(1)|movingAverage(\"5min\")\n&target=movingAverage(company.server*.applicationInstance.requestsHandled|aliasByNode(1),\"5min\")\n(these are all equivalent)\n```\n\nThe target param can also be repeated to graph multiple related metrics.\n\n``` none\n&target=company.server1.loadAvg&target=company.server1.memUsage\n```\n\nNote\n\nIf more than 10 metrics are drawn the legend is no longer displayed. See the [hideLegend](#hidelegend) parameter for details.\n\n### from / until\n\nThese are optional parameters that specify the relative or absolute time period to graph. `from` specifies the beginning, `until` specifies the end. If `from` is omitted, it defaults to 24 hours ago. If `until` is omitted, it defaults to the current time (now).\n\nThere are multiple formats for these functions:\n\n``` none\n&from=-RELATIVE_TIME\n&from=ABSOLUTE_TIME\n```\n\nRELATIVE_TIME is a length of time since the current time. It is always preceded by a minus sign ( - ) and followed by a unit of time. Valid units of time:\n\n| Abbreviation | Unit            |\n|--------------|-----------------|\n| s            | Seconds         |\n| min          | Minutes         |\n| h            | Hours           |\n| d            | Days            |\n| w            | Weeks           |\n| mon          | 30 Days (month) |\n| y            | 365 Days (year) |\n\nABSOLUTE_TIME is in the format HH:MM_YYYYMMDD, YYYYMMDD, MM/DD/YY, or any other `at(1)`-compatible time format.\n\n| Abbreviation | Meaning                                                                    |\n|--------------|----------------------------------------------------------------------------|\n| HH           | Hours, in 24h clock format. Times before 12PM must include leading zeroes. |\n| MM           | Minutes                                                                    |\n| YYYY         | 4 Digit Year.                                                              |\n| MM           | Numeric month representation with leading zero                             |\n| DD           | Day of month with leading zero                                             |\n\n`&from` and `&until` can mix absolute and relative time if desired.\n\nExamples:\n\n``` none\n&from=-8d&until=-7d\n(shows same day last week)\n\n&from=04:00_20110501&until=16:00_20110501\n(shows 4AM-4PM on May 1st, 2011)\n\n&from=20091201&until=20091231\n(shows December 2009)\n\n&from=noon+yesterday\n(shows data since 12:00pm on the previous day)\n\n&from=6pm+today\n(shows data since 6:00pm on the same day)\n\n&from=january+1\n(shows data since the beginning of the current year)\n\n&from=monday\n(show data since the previous monday)\n```\n\n### template\n\nThe `target` metrics can use a special `template` function which allows the metric paths to contain variables. Values for these variables can be provided via the `template` query parameter.\n\n#### Examples\n\nExample:\n\n``` none\n&target=template(hosts.$hostname.cpu)&template[hostname]=worker1\n```\n\nDefault values for the template variables can also be provided:\n\n``` none\n&target=template(hosts.$hostname.cpu, hostname=\"worker1\")\n```\n\nPositional arguments can be used instead of named ones:\n\n``` none\n&target=template(hosts.$1.cpu, \"worker1\")\n&target=template(hosts.$1.cpu, \"worker1\")&template[1]=worker*\n```\n\nIn addition to path substitution, variables can be used for numeric and string literals:\n\n``` none\n&target=template(constantLine($number))&template[number]=123\n&target=template(sinFunction($name))&template[name]=nameOfMySineWaveMetric\n```\n\n## Data Display Formats\n\nAlong with rendering an image, the api can also generate [SVG](http://www.w3.org/Graphics/SVG/) with embedded metadata, PDF, or return the raw data in various formats for external graphing, analysis or monitoring.\n\n### format\n\nControls the format of data returned. Affects all `&targets` passed in the URL.\n\nExamples:\n\n``` none\n&format=png\n&format=raw\n&format=csv\n&format=json\n&format=svg\n&format=pdf\n&format=dygraph\n&format=rickshaw\n```\n\n#### png\n\nRenders the graph as a PNG image of size determined by [width](#width) and [height](#height)\n\n#### raw\n\nRenders the data in a custom line-delimited format. Targets are output one per line and are of the format `<target`` ``name>,<start`` ``timestamp>,<end`` ``timestamp>,<series`` ``step>|[data]*`\n\n``` none\nentries,1311836008,1311836013,1|1.0,2.0,3.0,5.0,6.0\n```\n\n#### csv\n\nRenders the data in a CSV format suitable for import into a spreadsheet or for processing in a script\n\n``` none\nentries,2011-07-28 01:53:28,1.0\nentries,2011-07-28 01:53:29,2.0\nentries,2011-07-28 01:53:30,3.0\nentries,2011-07-28 01:53:31,5.0\nentries,2011-07-28 01:53:32,6.0\n```\n\n#### json\n\nRenders the data as a json object. The [jsonp](#jsonp) option can be used to wrap this data in a named call for cross-domain access\n\n``` none\n[{\n  \"target\": \"entries\",\n  \"datapoints\": [\n    [1.0, 1311836008],\n    [2.0, 1311836009],\n    [3.0, 1311836010],\n    [5.0, 1311836011],\n    [6.0, 1311836012]\n  ]\n}]\n```\n\n#### svg\n\nRenders the graph as SVG markup of size determined by [width](#width) and [height](#height). Metadata about the drawn graph is saved as an embedded script with the variable `metadata` being set to an object describing the graph\n\n``` none\n<script>\n  <![CDATA[\n    metadata = {\n      \"area\": {\n        \"xmin\": 39.195507812499997,\n        \"ymin\": 33.96875,\n        \"ymax\": 623.794921875,\n        \"xmax\": 1122\n      },\n      \"series\": [\n        {\n          \"start\": 1335398400,\n          \"step\": 1800,\n          \"end\": 1335425400,\n          \"name\": \"summarize(test.data, \\\"30min\\\", \\\"sum\\\")\",\n          \"color\": \"#859900\",\n          \"data\": [null, null, 1.0, null, 1.0, null, 1.0, null, 1.0, null, 1.0, null, null, null, null],\n          \"options\": {},\n          \"valuesPerPoint\": 1\n        }\n      ],\n      \"y\": {\n        \"labelValues\": [0, 0.25, 0.5, 0.75, 1.0],\n        \"top\": 1.0,\n        \"labels\": [\"0 \", \"0.25 \", \"0.50 \", \"0.75 \", \"1.00  \"],\n        \"step\": 0.25,\n        \"bottom\": 0\n      },\n      \"x\": {\n        \"start\": 1335398400,\n        \"end\": 1335423600\n      },\n      \"font\": {\n        \"bold\": false,\n        \"name\": \"Sans\",\n        \"italic\": false,\n        \"size\": 10\n      },\n      \"options\": {\n        \"lineWidth\": 1.2\n      }\n    }\n  ]]>\n</script>\n```\n\n#### pdf\n\nRenders the graph as a PDF of size determined by [width](#width) and [height](#height).\n\n#### dygraph\n\nRenders the data as a json object suitable for passing to a [Dygraph](http://dygraphs.com/data.html) object.\n\n``` none\n{\n  \"labels\" : [\n    \"Time\",\n    \"entries\"\n  ],\n  \"data\" : [\n    [1468791890000, 0.0],\n    [1468791900000, 0.0]\n  ]\n}\n```\n\n#### rickshaw\n\nRenders the data as a json object suitable for passing to a [Rickshaw](http://code.shutterstock.com/rickshaw/tutorial/introduction.html) object.\n\n``` none\n[{\n  \"target\": \"entries\",\n  \"datapoints\": [{\n    \"y\": 0.0,\n    \"x\": 1468791890\n  }, {\n    \"y\": 0.0,\n    \"x\": 1468791900\n  }]\n}]\n```\n\n#### pickle\n\nReturns a Python [pickle](http://docs.python.org/library/pickle.html) (serialized Python object). The response will have the MIME type ‘application/pickle’. The pickled object is a list of dictionaries with the keys: `name`, `start`, `end`, `step`, and `values` as below:\n\n``` python\n[\n  {\n    'name' : 'summarize(test.data, \"30min\", \"sum\")',\n    'start': 1335398400,\n    'end'  : 1335425400,\n    'step' : 1800,\n    'values' : [None, None, 1.0, None, 1.0, None, 1.0, None, 1.0, None, 1.0, None, None, None, None],\n  }\n]\n```\n\n### rawData\n\nDeprecated since version 0.9.9: This option is deprecated in favor of format\n\nUsed to get numerical data out of the webapp instead of an image. Can be set to true, false, csv. Affects all `&targets` passed in the URL.\n\nExample:\n\n``` none\n&target=carbon.agents.graphiteServer01.cpuUsage&from=-5min&rawData=true\n```\n\nReturns the following text:\n\n``` none\ncarbon.agents.graphiteServer01.cpuUsage,1306217160,1306217460,60|0.0,0.00666666520965,0.00666666624282,0.0,0.0133345399694\n```\n\n## Graph Parameters\n\n### areaAlpha\n\n*Default: 1.0*\n\nTakes a floating point number between 0.0 and 1.0\n\nSets the alpha (transparency) value of filled areas when using an [areaMode](#areamode)\n\n### areaMode\n\n*Default: none*\n\nEnables filling of the area below the graphed lines. Fill area is the same color as the line color associated with it. See [areaAlpha](#areaalpha) to make this area transparent. Takes one of the following parameters which determines the fill mode to use:\n\n`none`  \nDisables areaMode\n\n`first`  \nFills the area under the first target and no other\n\n`all`  \nFills the areas under each target\n\n`stacked`  \nCreates a graph where the filled area of each target is stacked on one another. Each target line is displayed as the sum of all previous lines plus the value of the current line.\n\n### bgcolor\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nSets the background color of the graph.\n\n| Color Names | RGB Value   |\n|-------------|-------------|\n| black       | 0,0,0       |\n| white       | 255,255,255 |\n| blue        | 100,100,255 |\n| green       | 0,200,0     |\n| red         | 200,0,50    |\n| yellow      | 255,255,0   |\n| orange      | 255, 165, 0 |\n| purple      | 200,100,255 |\n| brown       | 150,100,50  |\n| aqua        | 0,150,150   |\n| gray        | 175,175,175 |\n| grey        | 175,175,175 |\n| magenta     | 255,0,255   |\n| pink        | 255,100,100 |\n| gold        | 200,200,0   |\n| rose        | 200,150,200 |\n| darkblue    | 0,0,255     |\n| darkgreen   | 0,255,0     |\n| darkred     | 255,0,0     |\n| darkgray    | 111,111,111 |\n| darkgrey    | 111,111,111 |\n\nRGB can be passed directly in the format \\#RRGGBB\\[AA\\] where RR, GG, and BB are 2-digit hex vaules for red, green and blue, respectively. AA is an optional addition describing the opacity (“alpha”). Where FF is fully opaque, 00 fully transparent.\n\nExamples:\n\n``` none\n&bgcolor=blue\n&bgcolor=2222FF\n&bgcolor=5522FF60\n```\n\n### cacheTimeout\n\n*Default: The value of DEFAULT_CACHE_DURATION from local_settings.py*\n\nThe time in seconds for the rendered graph to be cached (only relevant if memcached is configured)\n\n### colorList\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nTakes one or more comma-separated color names or RGB values (see bgcolor for a list of color names) and uses that list in order as the colors of the lines. If more lines / metrics are drawn than colors passed, the list is reused in order. Any RGB value can also have an optional transparency (00 being fully transparent, FF being opaque), as shown in the second example.\n\nExample:\n\n``` none\n&colorList=green,yellow,orange,red,purple,DECAFF\n&colorList=FF000055,00FF00AA,DECAFFEF\n```\n\n### drawNullAsZero\n\n*Default: false*\n\nConverts any None (null) values in the displayed metrics to zero at render time.\n\n### fgcolor\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nSets the foreground color. This only affects the title, legend text, and axis labels.\n\nSee [majorGridLineColor](#majorgridlinecolor), and [minorGridLineColor](#minorgridlinecolor) for further control of colors.\n\nSee [bgcolor](#bgcolor) for a list of color names and details on formatting this parameter.\n\n### fontBold\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nIf set to true, makes the font bold.\n\nExample:\n\n``` none\n&fontBold=true\n```\n\n### fontItalic\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nIf set to true, makes the font italic / oblique. Default is false.\n\nExample:\n\n``` none\n&fontItalic=true\n```\n\n### fontName\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nChange the font used to render text on the graph. The font must be installed on the Graphite Server.\n\nExample:\n\n``` none\n&fontName=FreeMono\n```\n\n### fontSize\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nChanges the font size. Must be passed a positive floating point number or integer equal to or greater than 1. Default is 10\n\nExample:\n\n``` none\n&fontSize=8\n```\n\n### format\n\nSee: [Data Display Formats](#data-display-formats)\n\n### from\n\nSee: [from / until](#from-until)\n\n### graphOnly\n\n*Default: False*\n\nDisplay only the graph area with no grid lines, axes, or legend\n\n### graphType\n\n*Default: line*\n\nSets the type of graph to be rendered. Currently there are only two graph types:\n\n`line`  \nA line graph displaying metrics as lines over time\n\n`pie`  \nA pie graph with each slice displaying an aggregate of each metric calculated using the function specified by [pieMode](#piemode)\n\n### hideLegend\n\n*Default: \\<unset\\>*\n\nIf set to `true`, the legend is not drawn. If set to `false`, the legend is drawn. If unset, the `LEGEND_MAX_ITEMS` settings in `local_settings.py` is used to determine whether or not to display the legend.\n\nHint: If set to `false` the `&height` parameter may need to be increased to accommodate the additional text.\n\nExample:\n\n``` none\n&hideLegend=false\n```\n\n### hideNullFromLegend\n\n*Default: False*\n\nIf set to `true`, series with all null values will not be reported in the legend.\n\nExample:\n\n``` none\n&hideNullFromLegend=true\n```\n\n### hideAxes\n\n*Default: False*\n\nIf set to `true` the X and Y axes will not be rendered\n\nExample:\n\n``` none\n&hideAxes=true\n```\n\n### hideXAxis\n\n*Default: False*\n\nIf set to `true` the X Axis will not be rendered\n\n### hideYAxis\n\n*Default: False*\n\nIf set to `true` the Y Axis will not be rendered\n\n### hideGrid\n\n*Default: False*\n\nIf set to `true` the grid lines will not be rendered\n\nExample:\n\n``` none\n&hideGrid=true\n```\n\n### height\n\n*Default: 250*\n\nSets the height of the generated graph image in pixels.\n\nSee also: [width](#width)\n\nExample:\n\n``` none\n&width=650&height=250\n```\n\n### jsonp\n\n*Default: \\<unset\\>*\n\nIf set and combined with `format=json`, wraps the JSON response in a function call named by the parameter specified.\n\n### leftColor\n\n*Default: color chosen from* [colorList](#colorlist)\n\nIn dual Y-axis mode, sets the color of all metrics associated with the left Y-axis.\n\n### leftDashed\n\n*Default: False*\n\nIn dual Y-axis mode, draws all metrics associated with the left Y-axis using dashed lines\n\n### leftWidth\n\n*Default: value of the parameter* [lineWidth](#linewidth)\n\nIn dual Y-axis mode, sets the line width of all metrics associated with the left Y-axis\n\n### lineMode\n\n*Default: slope*\n\nSets the line drawing behavior. Takes one of the following parameters:\n\n`slope`  \nSlope line mode draws a line from each point to the next. Periods with Null values will not be drawn\n\n`staircase`  \nStaircase draws a flat line for the duration of a time period and then a vertical line up or down to the next value\n\n`connected`  \nLike a slope line, but values are always connected with a slope line, regardless of whether or not there are Null values between them\n\nExample:\n\n``` none\n&lineMode=staircase\n```\n\n### lineWidth\n\n*Default: 1.2*\n\nTakes any floating point or integer (negative numbers do not error but will cause no line to be drawn). Changes the width of the line in pixels.\n\nExample:\n\n``` none\n&lineWidth=2\n```\n\n### logBase\n\n*Default: \\<unset\\>*\n\nIf set, draws the graph with a logarithmic scale of the specified base (e.g. 10 for common logarithm)\n\n### localOnly\n\n*Default: False*\n\nSet to prevent fetching from remote Graphite servers, only returning metrics which are accessible locally\n\n### majorGridLineColor\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nSets the color of the major grid lines.\n\nSee [bgcolor](#bgcolor) for valid color names and formats.\n\nExample:\n\n``` none\n&majorGridLineColor=FF22FF\n```\n\n### margin\n\n*Default: 10* Sets the margin around a graph image in pixels on all sides.\n\nExample:\n\n``` none\n&margin=20\n```\n\n### max\n\nDeprecated since version 0.9.0: See [yMax](#ymax)\n\n### maxDataPoints\n\nSet the maximum numbers of datapoints for each series returned when using json content.\n\nIf for any output series the number of datapoints in a selected range exceeds the maxDataPoints value then the datapoints over the whole period are consolidated.\n\nThe function used to consolidate points can be set using the [consolidateBy](functions#graphite.render.functions.consolidateBy) function.\n\n### minorGridLineColor\n\n*Default: value from the \\[default\\] template in graphTemplates.conf*\n\nSets the color of the minor grid lines.\n\nSee [bgcolor](#bgcolor) for valid color names and formats.\n\nExample:\n\n``` none\n&minorGridLineColor=darkgrey\n```\n\n### minorY\n\nSets the number of minor grid lines per major line on the y-axis.\n\nExample:\n\n``` none\n&minorY=3\n```\n\n### min\n\nDeprecated since version 0.9.0: See [yMin](#ymin)\n\n### minXStep\n\n*Default: 1*\n\nSets the minimum pixel-step to use between datapoints drawn. Any value below this will trigger a point consolidation of the series at render time. The default value of `1` combined with the default lineWidth of `1.2` will cause a minimal amount of line overlap between close-together points. To disable render-time point consolidation entirely, set this to `0` though note that series with more points than there are pixels in the graph area (e.g. a few month’s worth of per-minute data) will look very ‘smooshed’ as there will be a good deal of line overlap. In response, one may use [lineWidth](#linewidth) to compensate for this.\n\n### noCache\n\n*Default: False*\n\nSet to disable caching of rendered images\n\n### noNullPoints\n\n*Default: False*\n\nIf set and combined with `format=json`, removes all null datapoints from the series returned.\n\n### pickle\n\nDeprecated since version 0.9.10: See [Data Display Formats](#data-display-formats)\n\n### pieLabels\n\n*Default: horizontal*\n\nOrientation to use for slice labels inside of a pie chart.\n\n`horizontal`  \nLabels are oriented horizontally within each slice\n\n`rotated`  \nLabels are oriented radially within each slice\n\n### pieMode\n\n*Default: average*\n\nThe type of aggregation to use to calculate slices of a pie when `graphType=pie`. One of:\n\n`average`  \nThe average of non-null points in the series\n\n`maximum`  \nThe maximum of non-null points in the series\n\n`minimum`  \nTHe minimum of non-null points in the series\n\n### pretty\n\n*Default: \\<unset\\>*\n\nIf set to 1 and combined with `format=json`, outputs human-friendly json.\n\n### rightColor\n\n*Default: color chosen from* [colorList](#colorlist)\n\nIn dual Y-axis mode, sets the color of all metrics associated with the right Y-axis.\n\n### rightDashed\n\n*Default: False*\n\nIn dual Y-axis mode, draws all metrics associated with the right Y-axis using dashed lines\n\n### rightWidth\n\n*Default: value of the parameter* [lineWidth](#linewidth)\n\nIn dual Y-axis mode, sets the line width of all metrics associated with the right Y-axis\n\n### template\n\n*Default: default*\n\nUsed to specify a template from `graphTemplates.conf` to use for default colors and graph styles.\n\nExample:\n\n``` none\n&template=plain\n```\n\n### thickness\n\nDeprecated since version 0.9.0: See: [lineWidth](#linewidth)\n\n### title\n\n*Default: \\<unset\\>*\n\nPuts a title at the top of the graph, center aligned. If unset, no title is displayed.\n\nExample:\n\n``` none\n&title=Apache Busy Threads, All Servers, Past 24h\n```\n\n### tz\n\n*Default: The timezone specified in local_settings.py*\n\nTime zone to convert all times into.\n\nExamples:\n\n``` none\n&tz=America/Los_Angeles\n&tz=UTC\n```\n\nNote\n\nTo change the default timezone, edit `webapp/graphite/local_settings.py`.\n\n### uniqueLegend\n\n*Default: False*\n\nDisplay only unique legend items, removing any duplicates\n\n### until\n\nSee: [from / until](#from-until)\n\n### valueLabels\n\n*Default: percent*\n\nDetermines how slice labels are rendered within a pie chart.\n\n`none`  \nSlice labels are not shown\n\n`numbers`  \nSlice labels are reported with the original values\n\n`percent`  \nSlice labels are reported as a percent of the whole\n\n### valueLabelsColor\n\n*Default: black*\n\nColor used to draw slice labels within a pie chart.\n\n### valueLabelsMin\n\n*Default: 5*\n\nSlice values below this minimum will not have their labels rendered.\n\n### vtitle\n\n*Default: \\<unset\\>*\n\nLabels the y-axis with vertical text. If unset, no y-axis label is displayed.\n\nExample:\n\n``` none\n&vtitle=Threads\n```\n\n### vtitleRight\n\n*Default: \\<unset\\>*\n\nIn dual Y-axis mode, sets the title of the right Y-Axis (See: [vtitle](#vtitle))\n\n### width\n\n*Default: 330*\n\nSets the width of the generated graph image in pixels.\n\nSee also: [height](#height)\n\nExample:\n\n``` none\n&width=650&height=250\n```\n\n### xFilesFactor\n\n*Default: DEFAULT_XFILES_FACTOR specified in local_settings.py or 0*\n\nSets the default xFilesFactor value used when performing runtime aggregation across multiple series and/or intervals.\n\nSee the [xFilesFactor](functions#graphite.render.functions.setXFilesFactor) function for more information on the xFilesFactor value and how the default can be overridden for specific targets or series.\n\n### xFormat\n\n*Default: Determined automatically based on the time-width of the X axis*\n\nSets the time format used when displaying the X-axis. See [datetime.date.strftime()](http://docs.python.org/library/datetime.html#datetime.date.strftime) for format specification details.\n\n### yAxisSide\n\n*Default: left*\n\nSets the side of the graph on which to render the Y-axis. Accepts values of `left` or `right`\n\n### yDivisors\n\n*Default: 4,5,6*\n\nSets the preferred number of intermediate values to display on the Y-axis (Y values between the minimum and maximum). Note that Graphite will ultimately choose what values (and how many) to display based on a ‘pretty’ factor, which tries to maintain a sensible scale (e.g. preferring intermediary values like 25%,50%,75% over 33.3%,66.6%). To explicitly set the Y-axis values, see [yStep](#ystep)\n\n### yLimit\n\n*Reserved for future use* See: [yMax](#ymax)\n\n### yLimitLeft\n\n*Reserved for future use* See: [yMaxLeft](#ymaxleft)\n\n### yLimitRight\n\n*Reserved for future use* See: [yMaxRight](#ymaxright)\n\n### yMin\n\n*Default: The lowest value of any of the series displayed*\n\nManually sets the lower bound of the graph. Can be passed any integer or floating point number.\n\nExample:\n\n``` none\n&yMin=0\n```\n\n### yMax\n\n*Default: The highest value of any of the series displayed*\n\nManually sets the upper bound of the graph. Can be passed any integer or floating point number.\n\nExample:\n\n``` none\n&yMax=0.2345\n```\n\n### yMaxLeft\n\nIn dual Y-axis mode, sets the upper bound of the left Y-Axis (See: [yMax](#ymax))\n\n### yMaxRight\n\nIn dual Y-axis mode, sets the upper bound of the right Y-Axis (See: [yMax](#ymax))\n\n### yMinLeft\n\nIn dual Y-axis mode, sets the lower bound of the left Y-Axis (See: [yMin](#ymin))\n\n### yMinRight\n\nIn dual Y-axis mode, sets the lower bound of the right Y-Axis (See: [yMin](#ymin))\n\n### yStep\n\n*Default: Calculated automatically*\n\nManually set the value step between Y-axis labels and grid lines\n\n### yStepLeft\n\nIn dual Y-axis mode, Manually set the value step between the left Y-axis labels and grid lines (See: [yStep](#ystep))\n\n### yStepRight\n\nIn dual Y-axis mode, Manually set the value step between the right Y-axis labels and grid lines (See: [yStep](#ystep))\n\n### yUnitSystem\n\n*Default: si*\n\nSet the unit system for compacting Y-axis values (e.g. 23,000,000 becomes 23M). Value can be one of:\n\n`si`  \nUse si units (powers of 1000) - K, M, G, T, P\n\n`binary`  \nUse binary units (powers of 1024) - Ki, Mi, Gi, Ti, Pi\n\n`sec`  \nUse time units (seconds) - m, H, D, M, Y\n\n`msec`  \nUse time units (milliseconds) - s, m, H, D, M, Y\n\n`none`  \nDont compact values, display the raw number\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/render_api.html](https://graphite.readthedocs.io/en/latest/render_api.html)"
- name: The Whisper Database
  id: whisper
  summary: Whisper is a fixed-size database, similar in design and purpose to RRD (round-robin-database)
  description: "# The Whisper Database\n\nWhisper is a fixed-size database, similar in design and purpose to RRD (round-robin-database). It provides fast, reliable storage of numeric data over time. Whisper allows for higher resolution (seconds per point) of recent data to degrade into lower resolutions for long-term retention of historical data.\n\n## Data Points\n\nData points in Whisper are stored on-disk as big-endian double-precision floats. Each value is paired with a timestamp in seconds since the UNIX Epoch (01-01-1970). The data value is parsed by the Python [float()](http://docs.python.org/library/functions.html#float) function and as such behaves in the same way for special strings such as `'inf'`. Maximum and minimum values are determined by the Python interpreter’s allowable range for float values which can be found by executing:\n\n``` default\npython -c 'import sys; print sys.float_info'\n```\n\n## Archives: Retention and Precision\n\nWhisper databases contain one or more archives, each with a specific data resolution and retention (defined in number of points or max timestamp age). Archives are ordered from the highest-resolution and shortest retention archive to the lowest-resolution and longest retention period archive.\n\nTo support accurate aggregation from higher to lower resolution archives, the precision of a longer retention archive must be divisible by precision of next lower retention archive. For example, an archive with 1 data point every 60 seconds can have a lower-resolution archive following it with a resolution of 1 data point every 300 seconds because 60 cleanly divides 300. In contrast, a 180 second precision (3 minutes) could not be followed by a 600 second precision (10 minutes) because the ratio of points to be propagated from the first archive to the next would be 3 1/3 and Whisper will not do partial point interpolation.\n\nThe total retention time of the database is determined by the archive with the highest retention as the time period covered by each archive is overlapping (see [Multi-Archive Storage and Retrieval Behavior](#multi-archive-storage-and-retrieval-behavior)). That is, a pair of archives with retentions of 1 month and 1 year will not provide 13 months of data storage as may be guessed. Instead, it will provide 1 year of storage - the length of its longest archive.\n\n## Rollup Aggregation\n\nWhisper databases with more than a single archive need a strategy to collapse multiple data points for when the data rolls up a lower precision archive. By default, an average function is used. Available aggregation methods are:\n\n- average\n- sum\n- last\n- max\n- min\n\n## Multi-Archive Storage and Retrieval Behavior\n\nWhen Whisper writes to a database with multiple archives, the incoming data point is written to all archives at once. The data point will be written to the highest resolution archive as-is, and will be aggregated by the configured aggregation method (see [Rollup Aggregation](#rollup-aggregation)) and placed into each of the higher-retention archives. If you are in need for aggregation of the highest resolution points, please consider using [carbon-aggregator](carbon-daemons) for that purpose.\n\nWhen data is retrieved (scoped by a time range), the first archive which can satisfy the entire time period is used. If the time period overlaps an archive boundary, the lower-resolution archive will be used. This allows for a simpler behavior while retrieving data as the data’s resolution is consistent through an entire returned series.\n\n## Disk Space Efficiency\n\nWhisper is somewhat inefficient in its usage of disk space because of certain design choices:\n\n*Each data point is stored with its timestamp*  \nRather than a timestamp being inferred from its position in the archive, timestamps are stored with each point. The timestamps are used during data retrieval to check the validity of the data point. If a timestamp does not match the expected value for its position relative to the beginning of the requested series, it is known to be out of date and a null value is returned\n\n*Archives overlap time periods*  \nDuring the write of a data point, Whisper stores the same data in all archives at once (see [Multi-Archive Storage and Retrieval Behavior](#multi-archive-storage-and-retrieval-behavior)). Implied by this behavior is that all archives store from now until each of their retention times. Because of this, lower-resolution archives should be configured to significantly lower resolution and higher retentions than their higher-resolution counterparts so as to reduce the overlap.\n\n*All time-slots within an archive take up space whether or not a value is stored*  \nWhile Whisper allows for reliable storage of irregular updates, it is most space efficient when data points are stored at every update interval. This behavior is a consequence of the fixed-size design of the database and allows the reading and writing of series data to be performed in a single contiguous disk operation (for each archive in a database).\n\n## Differences Between Whisper and RRD\n\n*RRD can not take updates to a time-slot prior to its most recent update*  \nThis means that there is no way to back-fill data in an RRD series. Whisper does not have this limitation, and this makes importing historical data into Graphite much more simple and easy\n\n*RRD was not designed with irregular updates in mind*  \nIn many cases (depending on configuration) if an update is made to an RRD series but is not followed up by another update soon, the original update will be lost. This makes it less suitable for recording data such as operational metrics (e.g. code pushes)\n\n*Whisper requires that metric updates occur at the same interval as the finest resolution storage archive*  \nThis pushes the onus of aggregating values to fit into the finest precision archive to the user rather than the database. It also means that updates are written immediately into the finest precision archive rather than being staged first for aggregation and written later (during a subsequent write operation) as they are in RRD.\n\n## Performance\n\nWhisper is fast enough for most purposes. It is slower than RRDtool primarily as a consequence of Whisper being written in Python, while RRDtool is written in C. The speed difference between the two in practice is quite small as much effort was spent to optimize Whisper to be as close to RRDtool’s speed as possible. Testing has shown that update operations take anywhere from 2 to 3 times as long as RRDtool, and fetch operations take anywhere from 2 to 5 times as long. In practice the actual difference is measured in hundreds of microseconds (10^-4) which means less than a millisecond difference for simple cases.\n\n## Database Format\n\n|             |               |                         |                                                        |                 |\n|-------------|---------------|-------------------------|--------------------------------------------------------|-----------------|\n| WhisperFile | *Header,Data* |                         |                                                        |                 |\n|             | Header        | *Metadata,ArchiveInfo+* |                                                        |                 |\n|             |               | Metadata                | aggregationType,maxRetention,xFilesFactor,archiveCount |                 |\n|             |               | ArchiveInfo             | Offset,SecondsPerPoint,Points                          |                 |\n|             | Data          | *Archive+*              |                                                        |                 |\n|             |               | Archive                 | *Point+*                                               |                 |\n|             |               |                         | Point                                                  | timestamp,value |\n\nData types in Python’s [struct format](http://docs.python.org/library/struct.html#format-strings):\n\n|             |         |\n|-------------|---------|\n| Metadata    | `!2LfL` |\n| ArchiveInfo | `!3L`   |\n| Point       | `!Ld`   |\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/whisper.html](https://graphite.readthedocs.io/en/latest/whisper.html)"
- name: thickness
  id: render_api#thickness
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### thickness

    Deprecated since version 0.9.0: See: [lineWidth](#linewidth)
- name: threshold()
  id: functions#graphite.render.functions.threshold
  summary: Takes a float F, followed by a label (in double quotes) and a color
  belongs_to: Functions
  description: |-
    threshold(value, label=None, color=None)

    Takes a float F, followed by a label (in double quotes) and a color. (See `bgcolor` in the [Render API](render_api) for valid color names & formats.)

    Draws a horizontal line at value F across the graph.

    Example:

    ``` none
    &target=threshold(123.456, "omgwtfbbq", "red")
    ```
- name: timeFunction()
  id: functions#graphite.render.functions.timeFunction
  summary: Just returns the timestamp for each X value
  belongs_to: Functions
  description: |-
    timeFunction(name, step=60)

    Short Alias: time()

    Just returns the timestamp for each X value. T

    Example:

    ``` none
    &target=time("The.time.series")
    ```

    This would create a series named “The.time.series” that contains in Y the same value (in seconds) as X. Accepts optional second argument as ‘step’ parameter (default step is 60 sec)
- name: timeShift()
  id: functions#graphite.render.functions.timeShift
  summary: Takes one metric or a wildcard seriesList, followed by a quoted string with the length of time (See from``/``until in the Render API for examples of time formats)
  belongs_to: Functions
  description: |-
    timeShift(seriesList, timeShift, resetEnd=True, alignDST=False)

    Takes one metric or a wildcard seriesList, followed by a quoted string with the length of time (See `from``/``until` in the [Render API](render_api) for examples of time formats).

    Draws the selected metrics shifted in time. If no sign is given, a minus sign ( - ) is implied which will shift the metric back in time. If a plus sign ( + ) is given, the metric will be shifted forward in time.

    Will reset the end date range automatically to the end of the base stat unless resetEnd is False. Example case is when you timeshift to last week and have the graph date range set to include a time in the future, will limit this timeshift to pretend ending at the current time. If resetEnd is False, will instead draw full range including future time.

    Because time is shifted by a fixed number of seconds, comparing a time period with DST to a time period without DST, and vice-versa, will result in an apparent misalignment. For example, 8am might be overlaid with 7am. To compensate for this, use the alignDST option.

    Useful for comparing a metric against itself at a past periods or correcting data stored at an offset.

    Example:

    ``` none
    &target=timeShift(Sales.widgets.largeBlue,"7d")
    &target=timeShift(Sales.widgets.largeBlue,"-7d")
    &target=timeShift(Sales.widgets.largeBlue,"+1h")
    ```
- name: timeSlice()
  id: functions#graphite.render.functions.timeSlice
  summary: Takes one metric or a wildcard metric, followed by a quoted string with the time to start the line and another quoted string with the time to end the line
  belongs_to: Functions
  description: |-
    timeSlice(seriesList, startSliceAt, endSliceAt='now')

    Takes one metric or a wildcard metric, followed by a quoted string with the time to start the line and another quoted string with the time to end the line. The start and end times are inclusive. See `from``/``until` in the [Render API](render_api) for examples of time formats.

    Useful for filtering out a part of a series of data from a wider range of data.

    Example:

    ``` none
    &target=timeSlice(network.core.port1,"00:00 20140101","11:59 20140630")
    &target=timeSlice(network.core.port1,"12:00 20140630","now")
    ```
- name: timeStack()
  id: functions#graphite.render.functions.timeStack
  summary: Takes one metric or a wildcard seriesList, followed by a quoted string with the length of time (See from``/``until in the Render API for examples of time formats)
  belongs_to: Functions
  description: |-
    timeStack(seriesList, timeShiftUnit='1d', timeShiftStart=0, timeShiftEnd=7)

    Takes one metric or a wildcard seriesList, followed by a quoted string with the length of time (See `from``/``until` in the [Render API](render_api) for examples of time formats). Also takes a start multiplier and end multiplier for the length of time

    create a seriesList which is composed the original metric series stacked with time shifts starting time shifts from the start multiplier through the end multiplier

    Useful for looking at history, or feeding into averageSeries or stddevSeries.

    Example:

    ``` none
    &target=timeStack(Sales.widgets.largeBlue,"1d",0,7)    # create a series for today and each of the previous 7 days
    ```
- name: title
  id: render_api#title
  summary: Puts a title at the top of the graph, center aligned
  belongs_to: The Render URL API
  description: |-
    ### title

    *Default: \<unset\>*

    Puts a title at the top of the graph, center aligned. If unset, no title is displayed.

    Example:

    ``` none
    &title=Apache Busy Threads, All Servers, Past 24h
    ```
- name: Tools That Work With Graphite
  id: tools
  summary: Brubeck A statsd-compatible stats aggregator written in C
  description: "# Tools That Work With Graphite\n\n## Collection\n\n[Brubeck](https://github.com/github/brubeck)  \nA statsd-compatible stats aggregator written in C.\n\n[Bucky](http://pypi.python.org/pypi/bucky)  \nA small service implemented in Python for collecting and translating metrics for Graphite. It can currently collect metric data from CollectD daemons and from StatsD clients.\n\n[Carbonator Windows Service](https://github.com/CryptonZylog/carbonator)  \nSimple lightweight Windows Service that collects Performance Counter metrics and sends them over to the Graphite server. Configured via .NET xml application configuration.\n\n[collectd](http://collectd.org)  \nA daemon which collects system performance statistics periodically and provides mechanisms to store the values in a variety of ways, including RRD. To send collectd metrics into carbon/graphite, use collectd’s [write-graphite](http://collectd.org/wiki/index.php/Plugin:Write_Graphite) plugin (available as of 5.1). Other options include:\n\n- Jordan Sissel’s node [collectd-to-graphite](https://github.com/loggly/collectd-to-graphite) proxy\n- Joe Miller’s perl [collectd-graphite](https://github.com/joemiller/collectd-graphite) plugin\n- Gregory Szorc’s python [collectd-carbon](https://github.com/indygreg/collectd-carbon) plugin\n- Paul J. Davis’s [Bucky](http://pypi.python.org/pypi/bucky) service\n\nGraphite can also read directly from [collectd](http://collectd.org)’s RRD files. RRD files can simply be added to `STORAGE_DIR/rrd` (as long as directory names and files do not contain any `.` characters). For example, collectd’s `host.name/load/load.rrd` can be symlinked to `rrd/collectd/host_name/load/load.rrd` to graph `collectd.host_name.load.load.{short,mid,long}term`.\n\n[Collectl](http://collectl.sourceforge.net)  \nA collection tool for system metrics that can be run both interactively and as a daemon and has support for collecting from a broad set of subsystems. Collectl includes a Graphite interface which allows data to easily be fed to Graphite for storage.\n\n[Diamond](https://diamond.readthedocs.io/en/latest/)  \na Python daemon that collects system metrics and publishes them to Graphite. It is capable of collecting cpu, memory, network, I/O, load and disk metrics. Additionally, it features an API for implementing custom collectors for gathering metrics from almost any source.\n\n[Ganglia](http://ganglia.info)  \nA scalable distributed monitoring system for high-performance computing systems such as clusters and Grids. It collects system performance metrics and stores them in RRD, but now there is an [add-on](https://github.com/ganglia/ganglia_contrib/tree/master/graphite_integration/) that allows Ganglia to send metrics directly to Graphite. Further integration work is underway.\n\n[graphite-pollers](https://github.com/phreakocious/graphite-pollers)  \nA collection of scripts that shovel data into Graphite including a multi-threaded SNMP poller for network interface IF-MIB statistics and another which pulls linux network stack data from files in /proc/net. Add to cron and go.\n\n[Graphite PowerShell Functions](https://github.com/MattHodge/Graphite-PowerShell-Functions)  \nA group of functions that can be used to collect Windows Performance Counters and send them over to the Graphite server. The main function can be run as a Windows service, and everything is configurable via an XML file.\n\n[HoardD](https://github.com/coredump/hoardd)  \nA Node.js app written in CoffeeScript to send data from servers to Graphite, much like collectd does, but aimed at being easier to expand and with less footprint. It comes by default with basic collectors plus Redis and MySQL metrics, and can be expanded with Javascript or CoffeeScript.\n\n[Host sFlow](http://host-sflow.sourceforge.net)  \nAn open source implementation of the sFlow protocol ([http://www.sflow.org](http://www.sflow.org)), exporting a standard set of host cpu, memory, disk and network I/O metrics. The sflow2graphite utility converts sFlow to Graphite’s plaintext protocol, allowing Graphite to receive sFlow metrics.\n\n[jmx2graphite](https://github.com/logzio/jmx2graphite)  \nThe easiest way to poll JMX metrics and write them to Graphite. This tool runs as a Docker container, polling your JMX every X seconds and writing the metrics to Graphite. Requires a minimum of configuration to get started.\n\n[jmxtrans](https://github.com/jmxtrans/jmxtrans)  \nA powerful tool that performs JMX queries to collect metrics from Java applications. It is requires very little configuration and is capable of sending metric data to several backend applications, including Graphite.\n\n[Logster](https://github.com/etsy/logster)  \nA utility for reading log files and generating metrics in Graphite or Ganglia. It is ideal for visualizing trends of events that are occurring in your application/system/error logs. For example, you might use logster to graph the number of occurrences of HTTP response code that appears in your web server logs.\n\n[metrics-sampler](https://github.com/dimovelev/metrics-sampler)  \nA java program which regularly queries metrics from a configured set of inputs, selects and renames them using regular expressions and sends them to a configured set of outputs. It supports JMX and JDBC as inputs and Graphite as output out of the box.\n\n[Sensu](http://sensuapp.org)  \nA monitoring framework that can route metrics to Graphite. Servers subscribe to sets of checks, so getting metrics from a new server to Graphite is as simple as installing the Sensu client and subscribing.\n\n[snort2graphite](https://github.com/gregvolk/snort2graphite)  \nSnort IDS/IPS can be configured to generate a rich set of metrics about network traffic. Presently there are more than 130 metrics available. Snort2graphite will pick up the most recent data from your snort.stats file and send all the metrics into Graphite.\n\n[SqlToGraphite](https://github.com/perryofpeek/SqlToGraphite)  \nAn agent for windows written in .net to collect metrics using plugins (WMI, SQL Server, Oracle) by polling an endpoint with a SQL query and pushing the results into graphite. It uses either a local or a centralised configuration over HTTP.\n\n[SSC Serv](https://ssc-serv.com)  \nA Windows service (agent) which periodically publishes system metrics, for example CPU, memory and disk usage. It can store data in Graphite using a naming schema that’s identical to that used by collectd.\n\n[telegraf](https://github.com/influxdata/telegraf)  \nTelegraf is an agent written in Go for collecting, processing, aggregating, and writing metrics. It also supports metric output to Graphite.\n\n## Forwarding\n\n[Backstop](https://github.com/obfuscurity/backstop)  \nA simple endpoint for submitting metrics to Graphite. It accepts JSON data via HTTP POST and proxies the data to one or more Carbon/Graphite listeners.\n\n[carbon-c-relay](https://github.com/grobian/carbon-c-relay)  \nEnhanced C implementation of Carbon relay, aggregator and rewriter.\n\n[carbon-relay-ng](https://github.com/graphite-ng/carbon-relay-ng)  \nFast carbon relay+aggregator with admin interfaces for making changes online - production ready.\n\n[Evenflow](https://github.com/github/evenflow)  \nA simple service for submitting sFlow datagrams to Graphite. It accepts sFlow datagrams from multiple network devices and proxies the data to a Carbon listener. Currently only Generic Interface Counters are supported. All other message types are discarded.\n\n[Grafsy](https://github.com/leoleovich/grafsy)  \nVery light caching proxy for graphite metrics with additional features:\n\n- Caching metrics in case of outage and sending them later\n- Validation of metrics\n- Aggregating of metrics, including SUM and AVG functions\n- Much more\n\n[Graphite-Newrelic](https://github.com/gingerlime/graphite-newrelic)  \nGet your graphite data into [New Relic](https://newrelic.com/platform) via a New Relic Platform plugin.\n\n[Graphite-relay](https://github.com/markchadwick/graphite-relay)  \nA fast Graphite relay written in Scala with the Netty framework.\n\n[Graphios](https://github.com/shawn-sterling/graphios)  \nA small Python daemon to send Nagios performance data (perfdata) to Graphite.\n\n[Graphout](http://shamil.github.io/graphout)  \nA Node.js application that lets you forward Graphite based queries (using the render API) out to different external services. There are built in modules for Zabbix and CloudWatch. Custom modules are very easy to write.\n\n[Grockets](https://github.com/disqus/grockets)  \nA node.js application which provides streaming JSON data over HTTP from Graphite.\n\n[Gruffalo](https://github.com/outbrain/gruffalo)  \nAn asynchronous Netty based graphite proxy, for large scale installations. It protects Graphite from the herds of clients by minimizing context switches and interrupts; by batching and aggregating metrics. Gruffalo also allows you to replicate metrics between Graphite installations for DR scenarios, for example.\n\n[Ledbetter](https://github.com/github/ledbetter)  \nA simple script for gathering Nagios problem statistics and submitting them to Graphite. It focuses on summary (overall, servicegroup and hostgroup) statistics and writes them to the nagios.problems metrics namespace within Graphite.\n\n[pipe-to-graphite](https://github.com/iFixit/pipe-to-graphite)  \nA small shell script that makes it easy to report the output of any other cli program to Graphite.\n\n[Polymur](https://github.com/jamiealquiza/polymur)  \nA fast relay and HTTPS forwarder toolset written in Go.\n\n[statsd](https://github.com/etsy/statsd)  \nA simple daemon for easy stats aggregation, developed by the folks at Etsy. A list of forks and alternative implementations can be found at \\<[http://joemiller.me/2011/09/21/list-of-statsd-server-implementations/](http://joemiller.me/2011/09/21/list-of-statsd-server-implementations/)\\>\n\n## Visualization\n\n[Charcoal](https://github.com/cebailey59/charcoal)  \nA simple Sinatra dashboarding frontend for Graphite or any other system status service which can generate images directly from a URL. Charcoal configuration is driven by a YAML config file.\n\n[Descartes](https://github.com/obfuscurity/descartes)  \nA Sinatra-based dashboard that allows users to correlate multiple metrics in a single chart, review long-term trends across one or more charts, and to collaborate with other users through a combination of shared dashboards and rich layouts.\n\n[Dusk](https://github.com/obfuscurity/dusk)  \nA simple dashboard for isolating “hotspots” across a fleet of systems. It incorporates horizon charts using Cubism.js to maximize data visualization in a constrained space.\n\n[Firefly](https://github.com/Yelp/firefly)  \nA web application aimed at powerful, flexible time series graphing for web developers.\n\n[Gdash](https://github.com/ripienaar/gdash.git)  \nA simple Graphite dashboard built using Twitters Bootstrap driven by a small DSL.\n\n[Giraffe](http://kenhub.github.com/giraffe)  \nA Graphite real-time dashboard based on [Rickshaw](http://code.shutterstock.com/rickshaw) and requires no server backend. Inspired by [Gdash](https://github.com/ripienaar/gdash.git), [Tasseo](https://github.com/obfuscurity/tasseo) and [Graphene](http://jondot.github.com/graphene) it mixes features from all three into a slightly different animal.\n\n[Grafana](http://grafana.org)  \nA general purpose graphite dashboard replacement with feature rich graph editing and dashboard creation interface. It contains a unique Graphite target parser that enables easy metric and function editing. Fast client side rendering (even over large time ranges) using Flot with a multitude of display options (Multiple Y-axis, Bars, Lines, Points, smart Y-axis formats and much more). Click and drag selection rectangle to zoom in on any graph.\n\n[Graphene](http://jondot.github.com/graphene)  \nA Graphite dashboard toolkit based on [D3.js](http://mbostock.github.com/d3) and [Backbone.js](http://documentcloud.github.com/backbone) which was made to offer a very aesthetic realtime dashboard. Graphene provides a solution capable of displaying thousands upon thousands of datapoints all updated in realtime.\n\n[graphite-dashboardcli](https://github.com/blacked/graphite-dashboardcli)  \nA tool for manage graphite dashboards from command line:\n\n- importExport dashboards fromto Graphite servers\n- synchronize dashboards between multiple Graphite servers\n- keep dashboards in YAML format\n\n[Graphite-Tattle](https://github.com/wayfair/Graphite-Tattle)  \nA self-service dashboard frontend for Graphite and [Ganglia](http://ganglia.info).\n\n[Graphiti](https://github.com/paperlesspost/graphiti)  \nA powerful dashboard front end with a focus on ease of access, ease of recovery and ease of tweaking and manipulation.\n\n[Graphitoid](https://market.android.com/details?id=com.tnc.android.graphite)  \nAn Android app which allows one to browse and display Graphite graphs on an Android device.\n\n[graphitus](https://github.com/ezbz/graphitus)  \nA client side dashboard for graphite built using bootstrap and underscore.js.\n\n[Graphsky](https://github.com/hyves-org/graphsky)  \nA flexible and easy to configure PHP based dashboard. It uses JSON template files to build graphs and specify which graphs need to be displayed when, similar to Ganglia-web. Just like Ganglia, it uses a hierarchial structure: Environment/Cluster/Host/Metric to be able to display overview graphs and host-specific metrics. It communicates directly to the Graphite API to determine which Environments, Clusters, Hosts and Metrics are currently stored in Graphite.\n\n[Graph-Explorer](http://vimeo.github.io/graph-explorer)  \nA graphite dashboard which uses plugins to add tags and metadata to metrics and a query language with lets you filter through them and compose/manipulate graphs on the fly. Also aims for high interactivity using [TimeseriesWidget](https://github.com/Dieterbe/timeserieswidget) and minimal hassle to set up and get running.\n\n[Graph-Index](https://github.com/douban/graph-index)  \nAn index of graphs for [Diamond](https://diamond.readthedocs.io/en/latest/).\n\n[Hubot](https://github.com/github/hubot)  \nA Campfire bot written in Node.js and CoffeeScript. The related [hubot-scripts](https://github.com/github/hubot-scripts) project includes a Graphite script which supports searching and displaying saved graphs from the Composer directory in your Campfire rooms.\n\n[Leonardo](https://github.com/PrFalken/leonardo)  \nA Graphite dashboard inspired by Gdash. It’s written in Python using the Flask framework. The interface is built with Bootstrap. The graphs and dashboards are configured through the YAML files.\n\n[Orion](https://github.com/gree/Orion)  \nA powerful tool to create, view and manage dashboards for your Graphite data. It allows easy implementation of custom authentication to manage access to the dashboard.\n\n[Pencil](https://github.com/fetep/pencil)  \nA monitoring frontend for graphite. It runs a webserver that dishes out pretty Graphite URLs in interesting and intuitive layouts.\n\n[Targets-io](https://github.com/dmoll1974/targets-io)  \nA dashboard application for organizing, analyzing, benchmarking and reporting of performance test results. All performance test metrics are stored in Graphite and can be benchmarked between test runs, providing automated feedback on the performance of an application.\n\n[Tasseo](https://github.com/obfuscurity/tasseo)  \nA lightweight, easily configurable, real-time dashboard for Graphite metrics.\n\n[Terphite](https://github.com/benwtr/terphite)  \nTerminal tool for displaying Graphite metrics.\n\n[Tessera](https://github.com/urbanairship/tessera)  \nA flexible front-end for creating dashboards with a wide variety of data presentations.\n\n[TimeseriesWidget](https://github.com/Dieterbe/timeserieswidget)  \nAdds timeseries graphs to your webpages/dashboards using a simple api, focuses on high interactivity and modern features (realtime zooming, datapoint inspection, annotated events, etc). Supports Graphite, flot, rickshaw and anthracite.\n\n## Monitoring\n\n[Cabot](https://github.com/arachnys/cabot)  \nA self-hosted monitoring and alerting server that watches Graphite metrics and can alert on them by phone, SMS, Hipchat or email. It is designed to be deployed to cloud or physical hardware in minutes and configured via web interface.\n\n[graphite-beacon](https://github.com/klen/graphite-beacon)  \nA simple alerting application for Graphite. It asynchronous and sends notification alerts based on Graphite metrics. It hasn’t any dependencies except Tornado package. Very light and really very easy deployed.\n\n[graphite-to-zabbix](https://github.com/blacked/graphite-to-zabbix)  \nA tool to make zabbix alerts based on Graphite data.\n\n[Icinga](http://docs.icinga.org/icinga2/latest/doc/module/icinga2/chapter/icinga2-features#graphite-carbon-cache-writer)  \nIcinga 2 will directly write metrics to the defined Graphite Carbon daemon tcp socket if the graphite feature is enabled. This feature is a more simple integration compared to Icinga 1.x and Graphios.\n\n[Moira](http://moira.readthedocs.io)  \nAn alerting system based on Graphite data. Moira is a real-time alerting tool, independent from graphite storage, custom expressions and extendable notification channels.\n\n[rearview](http://github.com/livingsocial/rearview)  \nA real-time monitoring framework that sits on top of Graphite’s time series data. This allows users to create monitors that both visualize and alert on data as it streams from Graphite. The monitors themselves are simple Ruby scripts which run in a sandbox to provide additional security. Monitors are also configured with a crontab compatible time specification used by the scheduler. Alerts can be sent via email, pagerduty, or campfire.\n\n[Rocksteady](http://code.google.com/p/rocksteady)  \nA system that ties together Graphite, [RabbitMQ](http://www.rabbitmq.com), and [Esper](http://esper.codehaus.org). Developed by AdMob (who was then bought by Google), this was released by Google as open source ([http://google-opensource.blogspot.com/2010/09/get-ready-to-rocksteady.html](http://google-opensource.blogspot.com/2010/09/get-ready-to-rocksteady.html)).\n\n[Seyren](https://github.com/scobal/seyren)  \nAn alerting dashboard for Graphite.\n\n[Shinken](http://www.shinken-monitoring.org)  \nA system monitoring solution compatible with Nagios which emphasizes scalability, flexibility, and ease of setup. Shinken provides complete integration with Graphite for processing and display of performance data.\n\n[Skyline](https://github.com/earthgecko/skyline)  \nAn anomaly detection/deflection system that receives all Graphite metrics data in real time via a carbon-relay pickle and analyses each time series to detect anomalies, drops off cliffs, user defined thresholds, handles multiple seasonality, records all anomalies and cross correlates all metrics to anomalies for the purpose of root cause analysis. Skyline can also be trained on what is not anomalous and thereafter it can independently learn what is not anomalous using a time series similarities comparison method. It can alert via smtp, hipchat and pagerduty.\n\n## Storage Backend Alternates\n\nIf you wish to use a backend to graphite other than Whisper, there are some options available to you.\n\n[BigGraphite](https://github.com/criteo/biggraphite)  \nA time-series database written in Python on top of Cassandra. It integrates with Graphite as a plugin.\n\n[carbon-clickhouse](https://github.com/lomik/carbon-clickhouse)  \nGraphite metrics receiver with [ClickHouse](https://clickhouse.yandex) as storage. You will also need [graphite-clickhouse](https://github.com/lomik/graphite-clickhouse) as backend for Graphite-web.\n\n[cassabon](https://github.com/jeffpierce/cassabon)  \nCarbon daemon using Cassandra as the backend, implemented in Go. It also acts as an API for Graphite (using the [Cyanite](http://cyanite.io/) reader) to retrieve the stats to display.\n\n[Ceres](https://github.com/graphite-project/ceres)  \nAn alternate storage backend provided by the Graphite Project. It it intended to be a distributable time-series database. It is currently in a pre-release status.\n\n[Cyanite](http://cyanite.io/)  \nA highly available, elastic, and low-latency time-series storage wirtten on top of Cassandra\n\n[graphite-clickhouse](https://github.com/lomik/graphite-clickhouse)  \nGraphite-web backend with [ClickHouse](https://clickhouse.yandex) support. Please also see [carbon-clickhouse](https://github.com/lomik/carbon-clickhouse).\n\n[Graphouse](https://github.com/yandex/graphouse)  \nGraphouse allows you to use [ClickHouse](https://clickhouse.yandex) as a Graphite storage.\n\n[go-carbon](https://github.com/lomik/go-carbon)  \nGolang implementation of Graphite/Carbon server with classic architecture: Agent -\\> Cache -\\> Persister.\n\n[influxgraph](https://github.com/InfluxGraph/influxgraph)  \nGraphite [InfluxDB](https://influxdb.com/) backend. [InfluxDB](https://influxdb.com/) storage finder / plugin for Graphite API.\n\n[Kenshin](https://github.com/douban/Kenshin)  \nA time-series database alternative to Graphite Whisper with 40x improvement in IOPS. It integrates with Graphite as a plugin.\n\n[metrictank](https://github.com/grafana/metrictank)  \nCassandra-backed, metrics2.0 based, multi-tenant timeseries database for Graphite and friends.\n\n## Other\n\n[bosun](http://bosun.org)  \nTime Series Alerting Framework. Can use Graphite as time series source.\n\n[carbonapi](https://github.com/go-graphite/carbonapi)  \n3rd party reimplementation of graphite-web in Go, which supports a significant subset of graphite functions. In some testing it has shown to be 5x-10x faster than requesting data from graphite-web.\n\n[Bryans-Graphite-Tools](https://github.com/linkslice/graphite-tools)  \nA collection of miscellaneous scripts for pulling data from various devices, F5, Infoblox, Nutanix, etc.\n\n[buckytools](https://github.com/jjneely/buckytools)  \nGo implementation of useful tools for dealing with Graphite’s Whisper DBs and Carbon hashing.\n\n[carbonate](https://github.com/graphite-project/carbonate)  \nUtilities for managing graphite clusters.\n\n[graphite-remote-adapter](https://github.com/criteo/graphite-remote-adapter)  \nFully featured graphite remote adapter for [Prometheus](https://github.com/prometheus/prometheus).\n\n[riemann](http://riemann.io)  \nA network event stream processing system, in Clojure. Can use Graphite as source of event stream.\n\n[Therry](https://github.com/obfuscurity/therry)  \nA simple web service that caches Graphite metrics and exposes an endpoint for dumping or searching against them by substring.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/tools.html](https://graphite.readthedocs.io/en/latest/tools.html)"
- name: transformNull()
  id: functions#graphite.render.functions.transformNull
  summary: Takes a metric or wildcard seriesList and replaces null values with the value specified by default
  belongs_to: Functions
  description: |-
    transformNull(seriesList, default=0, referenceSeries=None)

    Takes a metric or wildcard seriesList and replaces null values with the value specified by default. The value 0 used if not specified. The optional referenceSeries, if specified, is a metric or wildcard series list that governs which time intervals nulls should be replaced. If specified, nulls are replaced only in intervals where a non-null is found for the same interval in any of referenceSeries. This method compliments the drawNullAsZero function in graphical mode, but also works in text-only mode.

    Example:

    ``` none
    &target=transformNull(webapp.pages.*.views,-1)
    ```

    This would take any page that didn’t have values and supply negative 1 as a default. Any other numeric value may be used as well.
- name: txCarbonClient
  id: client-apis#txcarbonclient
  summary: txCarbonClient is a simple Twisted API for reporting metrics to Carbon
  belongs_to: Client APIs
  description: "## txCarbonClient\n\n[txCarbonClient](https://github.com/fdChasm/txCarbonClient) is a simple Twisted API for reporting metrics to Carbon.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/client-apis.html](https://graphite.readthedocs.io/en/latest/client-apis.html)"
- name: tz
  id: render_api#tz
  summary: Time zone to convert all times into
  belongs_to: The Render URL API
  description: |-
    ### tz

    *Default: The timezone specified in local_settings.py*

    Time zone to convert all times into.

    Examples:

    ``` none
    &tz=America/Los_Angeles
    &tz=UTC
    ```

    Note

    To change the default timezone, edit `webapp/graphite/local_settings.py`.
- name: unique()
  id: functions#graphite.render.functions.unique
  summary: Takes an arbitrary number of seriesLists and returns unique series, filtered by name
  belongs_to: Functions
  description: |-
    unique(\*seriesLists)

    Takes an arbitrary number of seriesLists and returns unique series, filtered by name.

    Example:

    ``` none
    &target=unique(mostDeviant(server.*.disk_free,5),lowestCurrent(server.*.disk_free,5))
    ```

    Draws servers with low disk space, and servers with highly deviant disk space, but never the same series twice.
- name: uniqueLegend
  id: render_api#uniquelegend
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### uniqueLegend

    *Default: False*

    Display only unique legend items, removing any duplicates
- name: until
  id: render_api#until
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### until

    See: [from / until](#from-until)
- name: Usage
  id: functions#usage
  summary: Most functions are applied to one series list
  belongs_to: Functions
  description: |-
    ## Usage

    Most functions are applied to one [series list](terminology#term-series-list). Functions with the parameter `*seriesLists` can take an arbitrary number of series lists. To pass multiple series lists to a function which only takes one, use the `group()` function.
- name: useSeriesAbove()
  id: functions#graphite.render.functions.useSeriesAbove
  summary: Compares the maximum of each series against the given value
  belongs_to: Functions
  description: |-
    useSeriesAbove(seriesList, value, search, replace)

    Compares the maximum of each series against the given value. If the series maximum is greater than value, the regular expression search and replace is applied against the series name to plot a related metric

    e.g. given useSeriesAbove(ganglia.metric1.reqs,10,’reqs’,’time’), the response time metric will be plotted only when the maximum value of the corresponding request/s metric is \> 10

    ``` none
    &target=useSeriesAbove(ganglia.metric1.reqs,10,"reqs","time")
    ```
- name: Using AMQP
  id: feeding-carbon#using-amqp
  summary: When AMQP_METRIC_NAME_IN_BODY is set to True in your carbon.conf file, the data should be of the same format as the plaintext protocol, e.g
  belongs_to: Feeding In Your Data
  description: |-
    ## Using AMQP

    When AMQP_METRIC_NAME_IN_BODY is set to True in your carbon.conf file, the data should be of the same format as the plaintext protocol, e.g. echo “local.random.diceroll 4 date +%s”. When AMQP_METRIC_NAME_IN_BODY is set to False, you should omit ‘local.random.diceroll’.

    # Getting Your Data Into Graphite
- name: uWSGI
  id: install-virtualenv#uwsgi
  summary: Execute uWSGI using the -H option to specify the virtualenv root
  belongs_to: Installing in Virtualenv
  description: "### uWSGI\n\nExecute [uWSGI](http://projects.unbit.it/uwsgi) using the `-H` option to specify the virtualenv root. See the [uWSGI documentation on virtualenv](http://projects.unbit.it/uwsgi/wiki/VirtualEnv) for more details.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install-virtualenv.html](https://graphite.readthedocs.io/en/latest/install-virtualenv.html)"
- name: valueLabels
  id: render_api#valuelabels
  summary: Determines how slice labels are rendered within a pie chart
  belongs_to: The Render URL API
  description: |-
    ### valueLabels

    *Default: percent*

    Determines how slice labels are rendered within a pie chart.

    ` ``none`` `

    Slice labels are not shown

    ` ``numbers`` `

    Slice labels are reported with the original values

    ` ``percent`` `

    Slice labels are reported as a percent of the whole
- name: valueLabelsColor
  id: render_api#valuelabelscolor
  summary: Color used to draw slice labels within a pie chart
  belongs_to: The Render URL API
  description: |-
    ### valueLabelsColor

    *Default: black*

    Color used to draw slice labels within a pie chart.
- name: valueLabelsMin
  id: render_api#valuelabelsmin
  summary: Slice values below this minimum will not have their labels rendered
  belongs_to: The Render URL API
  description: |-
    ### valueLabelsMin

    *Default: 5*

    Slice values below this minimum will not have their labels rendered.
- name: verticalLine()
  id: functions#graphite.render.functions.verticalLine
  summary: Takes a timestamp string ts
  belongs_to: Functions
  description: |-
    verticalLine(ts, label=None, color=None)

    Takes a timestamp string ts.

    Draws a vertical line at the designated timestamp with optional ‘label’ and ‘color’. Supported timestamp formats include both relative (e.g. -3h) and absolute (e.g. 16:00_20110501) strings, such as those used with `from` and `until` parameters. When set, the ‘label’ will appear in the graph legend.

    Note: Any timestamps defined outside the requested range will raise a ‘ValueError’ exception.

    Example:

    ``` none
    &target=verticalLine("12:3420131108","event","blue")
    &target=verticalLine("16:00_20110501","event")
    &target=verticalLine("-5mins")
    ```
- name: Viewing a Dashboard
  id: dashboard#viewing-a-dashboard
  summary: This section explains the options available when viewing an existing dashboard
  belongs_to: The Dashboard User Interface
  description: |-
    ## Viewing a Dashboard

    This section explains the options available when viewing an existing dashboard. Once you’ve defined the dashboards you need, you’ll spend most of your time in this mode.

    Note that you’ll most likely want to hide the completer when working in this mode - see earlier.
- name: Visualization
  id: tools#visualization
  summary: A simple Sinatra dashboarding frontend for Graphite or any other system status service which can generate images directly from a URL
  belongs_to: Tools That Work With Graphite
  description: |-
    ## Visualization

    [Charcoal](https://github.com/cebailey59/charcoal)

    A simple Sinatra dashboarding frontend for Graphite or any other system status service which can generate images directly from a URL. Charcoal configuration is driven by a YAML config file.

    [Descartes](https://github.com/obfuscurity/descartes)

    A Sinatra-based dashboard that allows users to correlate multiple metrics in a single chart, review long-term trends across one or more charts, and to collaborate with other users through a combination of shared dashboards and rich layouts.

    [Dusk](https://github.com/obfuscurity/dusk)

    A simple dashboard for isolating “hotspots” across a fleet of systems. It incorporates horizon charts using Cubism.js to maximize data visualization in a constrained space.

    [Firefly](https://github.com/Yelp/firefly)

    A web application aimed at powerful, flexible time series graphing for web developers.

    [Gdash](https://github.com/ripienaar/gdash.git)

    A simple Graphite dashboard built using Twitters Bootstrap driven by a small DSL.

    [Giraffe](http://kenhub.github.com/giraffe)

    A Graphite real-time dashboard based on [Rickshaw](http://code.shutterstock.com/rickshaw) and requires no server backend. Inspired by [Gdash](https://github.com/ripienaar/gdash.git), [Tasseo](https://github.com/obfuscurity/tasseo) and [Graphene](http://jondot.github.com/graphene) it mixes features from all three into a slightly different animal.

    [Grafana](http://grafana.org)

    A general purpose graphite dashboard replacement with feature rich graph editing and dashboard creation interface. It contains a unique Graphite target parser that enables easy metric and function editing. Fast client side rendering (even over large time ranges) using Flot with a multitude of display options (Multiple Y-axis, Bars, Lines, Points, smart Y-axis formats and much more). Click and drag selection rectangle to zoom in on any graph.

    [Graphene](http://jondot.github.com/graphene)

    A Graphite dashboard toolkit based on [D3.js](http://mbostock.github.com/d3) and [Backbone.js](http://documentcloud.github.com/backbone) which was made to offer a very aesthetic realtime dashboard. Graphene provides a solution capable of displaying thousands upon thousands of datapoints all updated in realtime.

    [graphite-dashboardcli](https://github.com/blacked/graphite-dashboardcli)

    A tool for manage graphite dashboards from command line:

    - importExport dashboards fromto Graphite servers
    - synchronize dashboards between multiple Graphite servers
    - keep dashboards in YAML format

    [Graphite-Tattle](https://github.com/wayfair/Graphite-Tattle)

    A self-service dashboard frontend for Graphite and [Ganglia](http://ganglia.info).

    [Graphiti](https://github.com/paperlesspost/graphiti)

    A powerful dashboard front end with a focus on ease of access, ease of recovery and ease of tweaking and manipulation.

    [Graphitoid](https://market.android.com/details?id=com.tnc.android.graphite)

    An Android app which allows one to browse and display Graphite graphs on an Android device.

    [graphitus](https://github.com/ezbz/graphitus)

    A client side dashboard for graphite built using bootstrap and underscore.js.

    [Graphsky](https://github.com/hyves-org/graphsky)

    A flexible and easy to configure PHP based dashboard. It uses JSON template files to build graphs and specify which graphs need to be displayed when, similar to Ganglia-web. Just like Ganglia, it uses a hierarchial structure: Environment/Cluster/Host/Metric to be able to display overview graphs and host-specific metrics. It communicates directly to the Graphite API to determine which Environments, Clusters, Hosts and Metrics are currently stored in Graphite.

    [Graph-Explorer](http://vimeo.github.io/graph-explorer)

    A graphite dashboard which uses plugins to add tags and metadata to metrics and a query language with lets you filter through them and compose/manipulate graphs on the fly. Also aims for high interactivity using [TimeseriesWidget](https://github.com/Dieterbe/timeserieswidget) and minimal hassle to set up and get running.

    [Graph-Index](https://github.com/douban/graph-index)

    An index of graphs for [Diamond](https://diamond.readthedocs.io/en/latest/).

    [Hubot](https://github.com/github/hubot)

    A Campfire bot written in Node.js and CoffeeScript. The related [hubot-scripts](https://github.com/github/hubot-scripts) project includes a Graphite script which supports searching and displaying saved graphs from the Composer directory in your Campfire rooms.

    [Leonardo](https://github.com/PrFalken/leonardo)

    A Graphite dashboard inspired by Gdash. It’s written in Python using the Flask framework. The interface is built with Bootstrap. The graphs and dashboards are configured through the YAML files.

    [Orion](https://github.com/gree/Orion)

    A powerful tool to create, view and manage dashboards for your Graphite data. It allows easy implementation of custom authentication to manage access to the dashboard.

    [Pencil](https://github.com/fetep/pencil)

    A monitoring frontend for graphite. It runs a webserver that dishes out pretty Graphite URLs in interesting and intuitive layouts.

    [Targets-io](https://github.com/dmoll1974/targets-io)

    A dashboard application for organizing, analyzing, benchmarking and reporting of performance test results. All performance test metrics are stored in Graphite and can be benchmarked between test runs, providing automated feedback on the performance of an application.

    [Tasseo](https://github.com/obfuscurity/tasseo)

    A lightweight, easily configurable, real-time dashboard for Graphite metrics.

    [Terphite](https://github.com/benwtr/terphite)

    Terminal tool for displaying Graphite metrics.

    [Tessera](https://github.com/urbanairship/tessera)

    A flexible front-end for creating dashboards with a wide variety of data presentations.

    [TimeseriesWidget](https://github.com/Dieterbe/timeserieswidget)

    Adds timeseries graphs to your webpages/dashboards using a simple api, focuses on high interactivity and modern features (realtime zooming, datapoint inspection, annotated events, etc). Supports Graphite, flot, rickshaw and anthracite.
- name: vtitle
  id: render_api#vtitle
  summary: Labels the y-axis with vertical text
  belongs_to: The Render URL API
  description: |-
    ### vtitle

    *Default: \<unset\>*

    Labels the y-axis with vertical text. If unset, no y-axis label is displayed.

    Example:

    ``` none
    &vtitle=Threads
    ```
- name: vtitleRight
  id: render_api#vtitleright
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### vtitleRight

    *Default: \<unset\>*

    In dual Y-axis mode, sets the title of the right Y-Axis (See: [vtitle](#vtitle))
- name: Webapp Database Setup
  id: config-database-setup
  summary: You must tell Django to create the database tables used by the graphite webapp
  description: "# Webapp Database Setup\n\nYou must tell Django to create the database tables used by the graphite webapp. This is very straight forward, especially if you are using the default SQLite setup.\n\nThe following configures the Django database settings. Graphite uses the database for storing user profiles, dashboards, and for the Events functionality. Graphite uses an SQLite database file located at `STORAGE_DIR/graphite.db` by default. If running multiple Graphite-web instances, a database such as PostgreSQL or MySQL is required so that all instances may share the same data source.\n\nNote\n\nAs of Django 1.2, the database configuration is specified by the DATABASES dictionary instead of the old `DATABASE_*` format. Users must use the new specification to have a working database.\n\nSee the [Django documentation](https://docs.djangoproject.com/en/dev/ref/settings/#databases) for full documentation of the DATABASES setting.\n\nNote\n\nIf you are using a custom database backend (other than SQLite) you must first create a $GRAPHITE_ROOT/webapp/graphite/local_settings.py file that overrides the database related settings from settings.py. Use $GRAPHITE_ROOT/webapp/graphite/local_settings.py.example as a template.\n\nTo set up a new database and create the initial schema, run:\n\n``` none\nPYTHONPATH=$GRAPHITE_ROOT/webapp django-admin.py migrate --settings=graphite.settings --run-syncdb\n```\n\nIf you are experiencing problems, uncomment the following line in /opt/graphite/webapp/graphite/local_settings.py:\n\n``` none\n# DEBUG = True\n```\n\nand review your webapp logs. If you’re using the default graphite-example-vhost.conf, your logs will be found in /opt/graphite/storage/log/webapp/.\n\nIf you’re using the default SQLite database, your webserver will need permissions to read and write to the database file. So, for example, if your webapp is running in Apache as the ‘nobody’ user, you will need to fix the permissions like this:\n\n``` none\nsudo chown nobody:nobody /opt/graphite/storage/graphite.db\n```\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-database-setup.html](https://graphite.readthedocs.io/en/latest/config-database-setup.html)"
- name: weightedAverage()
  id: functions#graphite.render.functions.weightedAverage
  summary: Takes a series of average values and a series of weights and produces a weighted average for all values
  belongs_to: Functions
  description: |-
    weightedAverage(seriesListAvg, seriesListWeight, \*nodes)

    Takes a series of average values and a series of weights and produces a weighted average for all values. The corresponding values should share one or more zero-indexed nodes and/or tags.

    Example:

    ``` none
    &target=weightedAverage(*.transactions.mean,*.transactions.count,0)
    ```

    Each node may be an integer referencing a node in the series name or a string identifying a tag.
- name: What Graphite is and is not
  id: overview#what-graphite-is-and-is-not
  summary: What Graphite does not do is collect data for you, however there are some tools out there that know how to send data to graphite
  belongs_to: Overview
  description: |-
    ## What Graphite is and is not

    Graphite does two things:

    1.  Store numeric time-series data
    2.  Render graphs of this data on demand

    What Graphite does not do is collect data for you, however there are some [tools](tools) out there that know how to send data to graphite. Even though it often requires a little code, [sending data](feeding-carbon) to Graphite is very simple.
- name: What is Graphite written in?
  id: faq#what-is-graphite-written-in
  summary: Python2
  belongs_to: FAQ
  description: |-
    ## What is Graphite written in?

    Python2. The Graphite webapp is built on the [Django](http://www.djangoproject.com/) web framework and uses the ExtJS javascript GUI toolkit. The graph rendering is done using the Cairo graphics library. The backend and database are written in pure Python.
- name: What is Graphite?
  id: faq#what-is-graphite
  summary: Graphite is a highly scalable real-time graphing system
  belongs_to: FAQ
  description: |-
    ## What is Graphite?

    Graphite is a highly scalable real-time graphing system. As a user, you write an application that collects numeric time-series data that you are interested in graphing, and send it to Graphite’s processing backend, [carbon](carbon-daemons), which stores the data in Graphite’s specialized database. The data can then be visualized through graphite’s web interfaces.
- name: What license is Graphite released under?
  id: faq#what-license-is-graphite-released-under
  summary: The Apache 2.0 License
  belongs_to: FAQ
  description: |-
    ## What license is Graphite released under?

    The [Apache 2.0 License](http://www.apache.org/licenses/LICENSE-2.0.html).
- name: Whisper
  id: install#whisper
  summary: Whisper is installed Python’s system-wide site-packages directory with Whisper’s utilities installed in the bin dir of the system’s default prefix (generally /usr/bin/)
  belongs_to: Installing Graphite
  description: |-
    ### Whisper

    Whisper is installed Python’s system-wide site-packages directory with Whisper’s utilities installed in the bin dir of the system’s default prefix (generally `/usr/bin/`).
- name: whitelist and blacklist
  id: config-carbon#whitelist-and-blacklist
  summary: The whitelist functionality allows any of the carbon daemons to only accept metrics that are explicitly whitelisted and/or to reject blacklisted metrics
  belongs_to: Configuring Carbon
  description: "## whitelist and blacklist\n\nThe whitelist functionality allows any of the carbon daemons to only accept metrics that are explicitly whitelisted and/or to reject blacklisted metrics. The functionality can be enabled in carbon.conf with the `USE_WHITELIST` flag. This can be useful when too many metrics are being sent to a Graphite instance or when there are metric senders sending useless or invalid metrics.\n\n`GRAPHITE_CONF_DIR` is searched for `whitelist.conf` and `blacklist.conf`. Each file contains one regular expressions per line to match against metric values. If the whitelist configuration is missing or empty, all metrics will be passed through by default.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/config-carbon.html](https://graphite.readthedocs.io/en/latest/config-carbon.html)"
- name: Who already uses Graphite?
  id: faq#who-already-uses-graphite
  summary: Graphite was internally developed by Orbitz where it is used to visualize a variety of operations-critical data including application metrics, database metrics, sales, etc
  belongs_to: FAQ
  description: |-
    ## Who already uses Graphite?

    Graphite was internally developed by [Orbitz](http://www.orbitz.com/) where it is used to visualize a variety of operations-critical data including application metrics, database metrics, sales, etc. At the time of this writing, the production system at Orbitz can handle approximately 160,000 distinct metrics per minute running on two niagra-2 Sun servers on a very fast SAN.
- name: Who should use Graphite?
  id: faq#who-should-use-graphite
  summary: Anybody who would want to track values of anything over time
  belongs_to: FAQ
  description: |-
    ## Who should use Graphite?

    Anybody who would want to track values of anything over time. If you have a number that could potentially change over time, and you might want to represent the value over time on a graph, then Graphite can probably meet your needs.

    Specifically, Graphite is designed to handle numeric time-series data. For example, Graphite would be good at graphing stock prices because they are numbers that change over time. Whether it’s a few data points, or dozens of performance metrics from thousands of servers, then Graphite is for you. As a bonus, you don’t necessarily know the names of those things in advance (who wants to maintain such huge configuration?); you simply send a metric name, a timestamp, and a value, and Graphite takes care of the rest!
- name: Who writes and maintains Graphite?
  id: faq#who-writes-and-maintains-graphite
  summary: Graphite was initially developed by Chris Davis at Orbitz
  belongs_to: FAQ
  description: |-
    ## Who writes and maintains Graphite?

    Graphite was initially developed by [Chris Davis](mailto:chrismd%40gmail.com) at [Orbitz](http://www.orbitz.com/). Orbitz has long been a part of the open source community and has published several other internally developed products.

    Graphite is currently developed by a team of volunteers under the [Graphite-Project](https://github.com/graphite-project/) GitHub Organization.
- name: width
  id: render_api#width
  summary: Sets the width of the generated graph image in pixels
  belongs_to: The Render URL API
  description: |-
    ### width

    *Default: 330*

    Sets the width of the generated graph image in pixels.

    See also: [height](#height)

    Example:

    ``` none
    &width=650&height=250
    ```
- name: Windows Users
  id: install#windows-users
  summary: Unfortunately, native Graphite on Windows is completely unsupported, but you can run Graphite on Windows in Docker or the Installing via Synthesize article will help you set up a Vagrant VM that will run Graphite
  belongs_to: Installing Graphite
  description: "## Windows Users\n\nUnfortunately, native Graphite on Windows is completely unsupported, but you can run Graphite on Windows in [Docker](https://www.docker.com/) or the [Installing via Synthesize](install-synthesize) article will help you set up a Vagrant VM that will run Graphite. In order to leverage this, you will need to install [Vagrant](https://www.vagrantup.com/).\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/install.html](https://graphite.readthedocs.io/en/latest/install.html)"
- name: Working on Graphite-web
  id: development
  summary: Graphite-web accepts contributions on GitHub, in the form of issues or pull requests
  description: "# Working on Graphite-web\n\nGraphite-web accepts contributions on [GitHub](https://github.com/graphite-project/graphite-web), in the form of issues or pull requests. If you’re comfortable with Python, here is how to get started.\n\nFirst, keep in mind that Graphite-web supports Python versions **2.6 to 2.7** and Django versions **1.4 and above**.\n\n## Setting up a development environment\n\nThe recommended workflow is to use [virtualenv](http://www.virtualenv.org/) / [virtualenvwrapper](http://virtualenvwrapper.readthedocs.io/) to isolate projects between each other. This document uses virtualenv as the lowest common denominator.\n\nCreate a virtualenv at the root of your graphite-web repository:\n\n``` default\nvirtualenv env\nsource env/bin/activate\n```\n\nInstall the required dependencies:\n\n``` default\npip install -r requirements.txt\n```\n\nCreate the default storage directories:\n\n``` default\nmkdir -p storage/{ceres,whisper,log/webapp}\n```\n\nThen you should be able to run the graphite development server:\n\n``` default\ncd webapp\n./manage.py runserver\n```\n\n## Running the tests\n\nTo run the tests for the Python and Django versions of your virtualenv:\n\n``` default\ncd webapp\n./manage.py test --settings=tests.settings\n```\n\nIf you want to run the tests for all combinations of Python and Django versions, you can use the [tox](http://tox.readthedocs.io/) tool.\n\n``` default\npip install tox\ntox\n```\n\nThis will run the tests for all configurations declared in the `tox.ini` file at the root of the repository.\n\nYou can see all the configurations available by running:\n\n``` default\ntox -l\n```\n\nYou can run a single configuration with:\n\n``` default\ntox -e <configuration>\n```\n\nNote that you need the corresponding python version on your system. Most systems only provide one or two different python versions, it is up to you to install other versions.\n\n## Writing tests\n\nPull requests for new features or bugfixes should come with tests to demonstrate that your feature or fix actually works. Tests are located in the `webapp/tests` directory.\n\nWhen writing a new test, look at the existing files to see if your test would fit in one. Otherwise simply create a new file named `test_<whatever>.py` with the following content:\n\n``` python\nfrom django.test import TestCase\n\nclass WhateverTest(TestCase):\n    def test_something(self):\n        self.assertEqual(1, 2 / 2)\n```\n\nYou can read [Django’s testing docs](https://docs.djangoproject.com/en/stable/topics/testing/) for more information on `django.test.TestCase` and how tests work with Django.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/development.html](https://graphite.readthedocs.io/en/latest/development.html)"
- name: Writing tests
  id: development#writing-tests
  summary: Pull requests for new features or bugfixes should come with tests to demonstrate that your feature or fix actually works
  belongs_to: Working on Graphite-web
  description: "## Writing tests\n\nPull requests for new features or bugfixes should come with tests to demonstrate that your feature or fix actually works. Tests are located in the `webapp/tests` directory.\n\nWhen writing a new test, look at the existing files to see if your test would fit in one. Otherwise simply create a new file named `test_<whatever>.py` with the following content:\n\n``` python\nfrom django.test import TestCase\n\nclass WhateverTest(TestCase):\n    def test_something(self):\n        self.assertEqual(1, 2 / 2)\n```\n\nYou can read [Django’s testing docs](https://docs.djangoproject.com/en/stable/topics/testing/) for more information on `django.test.TestCase` and how tests work with Django.\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/development.html](https://graphite.readthedocs.io/en/latest/development.html)"
- name: xFilesFactor
  id: render_api#xfilesfactor
  summary: Sets the default xFilesFactor value used when performing runtime aggregation across multiple series and/or intervals
  belongs_to: The Render URL API
  description: |-
    ### xFilesFactor

    *Default: DEFAULT_XFILES_FACTOR specified in local_settings.py or 0*

    Sets the default xFilesFactor value used when performing runtime aggregation across multiple series and/or intervals.

    See the [xFilesFactor](functions#graphite.render.functions.setXFilesFactor) function for more information on the xFilesFactor value and how the default can be overridden for specific targets or series.
- name: xFormat
  id: render_api#xformat
  summary: Sets the time format used when displaying the X-axis
  belongs_to: The Render URL API
  description: |-
    ### xFormat

    *Default: Determined automatically based on the time-width of the X axis*

    Sets the time format used when displaying the X-axis. See [datetime.date.strftime()](http://docs.python.org/library/datetime.html#datetime.date.strftime) for format specification details.
- name: yAxisSide
  id: render_api#yaxisside
  summary: Sets the side of the graph on which to render the Y-axis
  belongs_to: The Render URL API
  description: |-
    ### yAxisSide

    *Default: left*

    Sets the side of the graph on which to render the Y-axis. Accepts values of `left` or `right`
- name: yDivisors
  id: render_api#ydivisors
  summary: Sets the preferred number of intermediate values to display on the Y-axis (Y values between the minimum and maximum)
  belongs_to: The Render URL API
  description: |-
    ### yDivisors

    *Default: 4,5,6*

    Sets the preferred number of intermediate values to display on the Y-axis (Y values between the minimum and maximum). Note that Graphite will ultimately choose what values (and how many) to display based on a ‘pretty’ factor, which tries to maintain a sensible scale (e.g. preferring intermediary values like 25%,50%,75% over 33.3%,66.6%). To explicitly set the Y-axis values, see [yStep](#ystep)
- name: yLimit
  id: render_api#ylimit
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yLimit

    *Reserved for future use* See: [yMax](#ymax)
- name: yLimitLeft
  id: render_api#ylimitleft
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yLimitLeft

    *Reserved for future use* See: [yMaxLeft](#ymaxleft)
- name: yLimitRight
  id: render_api#ylimitright
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yLimitRight

    *Reserved for future use* See: [yMaxRight](#ymaxright)
- name: yMax
  id: render_api#ymax
  summary: Manually sets the upper bound of the graph
  belongs_to: The Render URL API
  description: |-
    ### yMax

    *Default: The highest value of any of the series displayed*

    Manually sets the upper bound of the graph. Can be passed any integer or floating point number.

    Example:

    ``` none
    &yMax=0.2345
    ```
- name: yMaxLeft
  id: render_api#ymaxleft
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yMaxLeft

    In dual Y-axis mode, sets the upper bound of the left Y-Axis (See: [yMax](#ymax))
- name: yMaxRight
  id: render_api#ymaxright
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yMaxRight

    In dual Y-axis mode, sets the upper bound of the right Y-Axis (See: [yMax](#ymax))
- name: yMin
  id: render_api#ymin
  summary: Manually sets the lower bound of the graph
  belongs_to: The Render URL API
  description: |-
    ### yMin

    *Default: The lowest value of any of the series displayed*

    Manually sets the lower bound of the graph. Can be passed any integer or floating point number.

    Example:

    ``` none
    &yMin=0
    ```
- name: yMinLeft
  id: render_api#yminleft
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yMinLeft

    In dual Y-axis mode, sets the lower bound of the left Y-Axis (See: [yMin](#ymin))
- name: yMinRight
  id: render_api#yminright
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yMinRight

    In dual Y-axis mode, sets the lower bound of the right Y-Axis (See: [yMin](#ymin))
- name: yStep
  id: render_api#ystep
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yStep

    *Default: Calculated automatically*

    Manually set the value step between Y-axis labels and grid lines
- name: yStepLeft
  id: render_api#ystepleft
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yStepLeft

    In dual Y-axis mode, Manually set the value step between the left Y-axis labels and grid lines (See: [yStep](#ystep))
- name: yStepRight
  id: render_api#ystepright
  summary: null
  belongs_to: The Render URL API
  description: |-
    ### yStepRight

    In dual Y-axis mode, Manually set the value step between the right Y-axis labels and grid lines (See: [yStep](#ystep))
- name: yUnitSystem
  id: render_api#yunitsystem
  summary: Set the unit system for compacting Y-axis values (e.g
  belongs_to: The Render URL API
  description: "### yUnitSystem\n\n*Default: si*\n\nSet the unit system for compacting Y-axis values (e.g. 23,000,000 becomes 23M). Value can be one of:\n\n` ``si`` `\n\nUse si units (powers of 1000) - K, M, G, T, P\n\n` ``binary`` `\n\nUse binary units (powers of 1024) - Ki, Mi, Gi, Ti, Pi\n\n` ``sec`` `\n\nUse time units (seconds) - m, H, D, M, Y\n\n` ``msec`` `\n\nUse time units (milliseconds) - s, m, H, D, M, Y\n\n` ``none`` `\n\nDont compact values, display the raw number\n\n© 2008–2012 Chris Davis  \n© 2011–2016 The Graphite Project  \nLicensed under the Apache License, Version 2.0.  \n[https://graphite.readthedocs.io/en/latest/render_api.html](https://graphite.readthedocs.io/en/latest/render_api.html)"
