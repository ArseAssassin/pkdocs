---
name: Trio
slug: trio
text_format: markdown
generator: src:devdocs
generator_command: src:devdocs
version: null
copyright: |-
  © 2017 Nathaniel J. Smith
  Licensed under the MIT License.
  https://trio.readthedocs.io/en/v0.22.2/index.html
homepage: https://trio.readthedocs.io/

---
- name: Asynchronous file interface
  id: reference-io#trio.Asynchronous-file-interface
  summary: Trio’s asynchronous file objects have an interface that automatically adapts to the object being wrapped
  belongs_to: I/O in Trio
  description: |-
    ### `Asynchronous file interface`

    Trio’s asynchronous file objects have an interface that automatically adapts to the object being wrapped. Intuitively, you can mostly treat them like a regular [file object](https://docs.python.org/3/glossary.html#term-file-object "(in Python v3.11)"), except adding an `await` in front of any of methods that do I/O. The definition of [file object](https://docs.python.org/3/glossary.html#term-file-object "(in Python v3.11)") is a little vague in Python though, so here are the details:

    - Synchronous attributes/methods: if any of the following attributes or methods are present, then they’re re-exported unchanged: `closed`, `encoding`, `errors`, `fileno`, `isatty`, `newlines`, `readable`, `seekable`, `writable`, `buffer`, `raw`, `line_buffering`, `closefd`, `name`, `mode`, `getvalue`, `getbuffer`.

    - Async methods: if any of the following methods are present, then they’re re-exported as an async method: `flush`, `read`, `read1`, `readall`, `readinto`, `readline`, `readlines`, `seek`, `tell`, `truncate`, `write`, `writelines`, `readinto1`, `peek`, `detach`.

    Special notes:

    - Async file objects implement Trio’s [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") interface: you close them by calling [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") instead of `close` (!!), and they can be used as async context managers. Like all [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") methods, the `aclose` method on async file objects is guaranteed to close the file before returning, even if it is cancelled or otherwise raises an error.

    - Using the same async file object from multiple tasks simultaneously: because the async methods on async file objects are implemented using threads, it’s only safe to call two of them at the same time from different tasks IF the underlying synchronous file object is thread-safe. You should consult the documentation for the object you’re wrapping. For objects returned from [`trio.open_file()`](#trio.open_file "trio.open_file") or [`trio.Path.open()`](#trio.Path.open "trio.Path.open"), it depends on whether you open the file in binary mode or text mode: [binary mode files are task-safe/thread-safe, text mode files are not](https://docs.python.org/3/library/io.html#multi-threading).

    - Async file objects can be used as async iterators to iterate over the lines of the file:

      ``` python
      async with await trio.open_file(...) as f:
          async for line in f:
              print(line)
      ```

    - The `detach` method, if present, returns an async file object.

    This should include all the attributes exposed by classes in [`io`](https://docs.python.org/3/library/io.html#module-io "(in Python v3.11)"). But if you’re wrapping an object that has other attributes that aren’t on the list above, then you can access them via the `.wrapped` attribute:
- name: Asynchronous file interface.wrapped
  id: reference-io#trio.Asynchronous-file-interface.wrapped
  summary: The underlying synchronous file object
  belongs_to: I/O in Trio
  description: |-
    ### `wrapped`

    The underlying synchronous file object.

    ## Spawning subprocesses

    Trio provides support for spawning other programs as subprocesses, communicating with them via pipes, sending them signals, and waiting for them to exit.

    Most of the time, this is done through our high-level interface, [`trio.run_process`](#trio.run_process "trio.run_process"). It lets you either run a process to completion while optionally capturing the output, or else run it in a background task and interact with it while it’s running:
- name: available_tokens
  id: reference-core#trio.CapacityLimiter.available_tokens
  summary: The amount of capacity that’s available to use
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` available_tokens`

    The amount of capacity that’s available to use.
- name: borrowed_tokens
  id: reference-core#trio.CapacityLimiter.borrowed_tokens
  summary: The amount of capacity that’s currently in use
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` borrowed_tokens`

    The amount of capacity that’s currently in use.
- name: child_tasks
  id: reference-core#trio.Nursery.child_tasks
  summary: Contains all the child Task objects which are still running
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` child_tasks`

    Contains all the child [`Task`](reference-lowlevel#trio.lowlevel.Task "trio.lowlevel.Task") objects which are still running.

    #### Type:

    ([`frozenset`](https://docs.python.org/3/library/stdtypes.html#frozenset "(in Python v3.11)"))
- name: I/O in Trio
  id: reference-io
  summary: Trio provides a set of abstract base classes that define a standard interface for unidirectional and bidirectional byte streams
  description: "# I/O in Trio\n\n## The abstract Stream API\n\nTrio provides a set of abstract base classes that define a standard interface for unidirectional and bidirectional byte streams.\n\nWhy is this useful? Because it lets you write generic protocol implementations that can work over arbitrary transports, and easily create complex transport configurations. Here’s some examples:\n\n- [`trio.SocketStream`](#trio.SocketStream \"trio.SocketStream\") wraps a raw socket (like a TCP connection over the network), and converts it to the standard stream interface.\n\n- [`trio.SSLStream`](#trio.SSLStream \"trio.SSLStream\") is a “stream adapter” that can take any object that implements the [`trio.abc.Stream`](#trio.abc.Stream \"trio.abc.Stream\") interface, and convert it into an encrypted stream. In Trio the standard way to speak SSL over the network is to wrap an [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") around a [`SocketStream`](#trio.SocketStream \"trio.SocketStream\").\n\n- If you spawn a [subprocess](#subprocess), you can get a [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\") that lets you write to its stdin, and a [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") that lets you read from its stdout. If for some reason you wanted to speak SSL to a subprocess, you could use a [`StapledStream`](#trio.StapledStream \"trio.StapledStream\") to combine its stdin/stdout into a single bidirectional [`Stream`](#trio.abc.Stream \"trio.abc.Stream\"), and then wrap that in an [`SSLStream`](#trio.SSLStream \"trio.SSLStream\"):\n\n  ``` python\n  ssl_context = ssl.create_default_context()\n  ssl_context.check_hostname = False\n  s = SSLStream(StapledStream(process.stdin, process.stdout), ssl_context)\n  ```\n\n- It sometimes happens that you want to connect to an HTTPS server, but you have to go through a web proxy… and the proxy also uses HTTPS. So you end up having to do [SSL-on-top-of-SSL](https://daniel.haxx.se/blog/2016/11/26/https-proxy-with-curl/). In Trio this is trivial – just wrap your first [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") in a second [`SSLStream`](#trio.SSLStream \"trio.SSLStream\"):\n\n  ``` python\n  # Get a raw SocketStream connection to the proxy:\n  s0 = await open_tcp_stream(\"proxy\", 443)\n\n  # Set up SSL connection to proxy:\n  s1 = SSLStream(s0, proxy_ssl_context, server_hostname=\"proxy\")\n  # Request a connection to the website\n  await s1.send_all(b\"CONNECT website:443 / HTTP/1.0\\r\\n\\r\\n\")\n  await check_CONNECT_response(s1)\n\n  # Set up SSL connection to the real website. Notice that s1 is\n  # already an SSLStream object, and here we're wrapping a second\n  # SSLStream object around it.\n  s2 = SSLStream(s1, website_ssl_context, server_hostname=\"website\")\n  # Make our request\n  await s2.send_all(b\"GET /index.html HTTP/1.0\\r\\n\\r\\n\")\n  ...\n  ```\n\n- The [`trio.testing`](reference-testing#module-trio.testing \"trio.testing\") module provides a set of [flexible in-memory stream object implementations](reference-testing#testing-streams), so if you have a protocol implementation to test then you can can start two tasks, set up a virtual “socket” connecting them, and then do things like inject random-but-repeatable delays into the connection.\n\n### Abstract base classes\n\n| Abstract base class                                                                   | Inherits from…                                                                                                                        | Adds these abstract methods…                                                                                                                                                                                              | And these concrete methods. | Example implementations                                                                                               |\n|---------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------|-----------------------------------------------------------------------------------------------------------------------|\n| [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")                   |                                                                                                                                       | [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\")                                                                                                                                              | `__aenter__`, `__aexit__`   | [Asynchronous file objects](#async-file-objects)                                                                      |\n| [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\")                            | [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")                                                                   | [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\") |                             | [`MemorySendStream`](reference-testing#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\")                 |\n| [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")                   | [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")                                                                   | [`receive_some()`](#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\")                                                                                                                            | `__aiter__`, `__anext__`    | [`MemoryReceiveStream`](reference-testing#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\")        |\n| [`Stream`](#trio.abc.Stream \"trio.abc.Stream\")                                        | [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\"), [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")       |                                                                                                                                                                                                                           |                             | [`SSLStream`](#trio.SSLStream \"trio.SSLStream\")                                                                       |\n| [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\") | [`Stream`](#trio.abc.Stream \"trio.abc.Stream\")                                                                                        | [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\")                                                                                                                            |                             | [`SocketStream`](#trio.SocketStream \"trio.SocketStream\"), [`StapledStream`](#trio.StapledStream \"trio.StapledStream\") |\n| [`Listener`](#trio.abc.Listener \"trio.abc.Listener\")                                  | [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")                                                                   | [`accept()`](#trio.abc.Listener.accept \"trio.abc.Listener.accept\")                                                                                                                                                        |                             | [`SocketListener`](#trio.SocketListener \"trio.SocketListener\"), [`SSLListener`](#trio.SSLListener \"trio.SSLListener\") |\n| [`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\")                         | [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")                                                                   | [`send()`](#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\")                                                                                                                                                        |                             | [`MemorySendChannel`](reference-core#trio.MemorySendChannel \"trio.MemorySendChannel\")                                 |\n| [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\")                | [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")                                                                   | [`receive()`](#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\")                                                                                                                                         | `__aiter__`, `__anext__`    | [`MemoryReceiveChannel`](reference-core#trio.MemoryReceiveChannel \"trio.MemoryReceiveChannel\")                        |\n| [`Channel`](#trio.abc.Channel \"trio.abc.Channel\")                                     | [`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\"), [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\") |                                                                                                                                                                                                                           |                             |                                                                                                                       |\n\nOverview: abstract base classes for I/O {#id1}\n\n### *`class`*` trio.abc.AsyncResource`\n\nA standard interface for resources that needs to be cleaned up, and where that cleanup may require blocking operations.\n\nThis class distinguishes between “graceful” closes, which may perform I/O and thus block, and a “forceful” close, which cannot. For example, cleanly shutting down a TLS-encrypted connection requires sending a “goodbye” message; but if a peer has become non-responsive, then sending this message might block forever, so we may want to just drop the connection instead. Therefore the [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") method is unusual in that it should always close the connection (or at least make its best attempt) *even if it fails*; failure indicates a failure to achieve grace, not a failure to close the connection.\n\nObjects that implement this interface can be used as async context managers, i.e., you can write:\n\n``` python\nasync with create_resource() as some_async_resource:\n    ...\n```\n\nEntering the context manager is synchronous (not a checkpoint); exiting it calls [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\"). The default implementations of `__aenter__` and `__aexit__` should be adequate for all subclasses.\n\n### *`abstractmethod await`*` aclose()`\n\nClose this resource, possibly blocking.\n\nIMPORTANT: This method may block in order to perform a “graceful” shutdown. But, if this fails, then it still *must* close any underlying resources before returning. An error from this method indicates a failure to achieve grace, *not* a failure to close the connection.\n\nFor example, suppose we call [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") on a TLS-encrypted connection. This requires sending a “goodbye” message; but if the peer has become non-responsive, then our attempt to send this message might block forever, and eventually time out and be cancelled. In this case the [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") method on [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") will immediately close the underlying transport stream using [`trio.aclose_forcefully()`](#trio.aclose_forcefully \"trio.aclose_forcefully\") before raising [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\").\n\nIf the resource is already closed, then this method should silently succeed.\n\nOnce this method completes, any other pending or future operations on this resource should generally raise [`ClosedResourceError`](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\"), unless there’s a good reason to do otherwise.\n\nSee also: [`trio.aclose_forcefully()`](#trio.aclose_forcefully \"trio.aclose_forcefully\").\n\n### *`await`*` trio.aclose_forcefully(resource)`\n\nClose an async resource or async generator immediately, without blocking to do any graceful cleanup.\n\n[`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") objects guarantee that if their [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") method is cancelled, then they will still close the resource (albeit in a potentially ungraceful fashion). [`aclose_forcefully()`](#trio.aclose_forcefully \"trio.aclose_forcefully\") is a convenience function that exploits this behavior to let you force a resource to be closed without blocking: it works by calling `await`` ``resource.aclose()` and then cancelling it immediately.\n\nMost users won’t need this, but it may be useful on cleanup paths where you can’t afford to block, or if you want to close a resource and don’t care about handling it gracefully. For example, if [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") encounters an error and cannot perform its own graceful close, then there’s no point in waiting to gracefully shut down the underlying transport either, so it calls `await`` ``aclose_forcefully(self.transport_stream)`.\n\nNote that this function is async, and that it acts as a checkpoint, but unlike most async functions it cannot block indefinitely (at least, assuming the underlying resource object is correctly implemented).\n\n### *`class`*` trio.abc.SendStream`\n\nBases: [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")\n\nA standard interface for sending data on a byte stream.\n\nThe underlying stream may be unidirectional, or bidirectional. If it’s bidirectional, then you probably want to also implement [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\"), which makes your object a [`Stream`](#trio.abc.Stream \"trio.abc.Stream\").\n\n[`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") interface, so they can be closed by calling [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") or using an `async`` ``with` block.\n\nIf you want to send Python objects rather than raw bytes, see [`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\").\n\n### *`abstractmethod await`*` send_all(data)`\n\nSends the given data through the stream, blocking if necessary.\n\n#### Parameters:\n\n**data** ([*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")*,* [*bytearray*](https://docs.python.org/3/library/stdtypes.html#bytearray \"(in Python v3.11)\")*, or* [*memoryview*](https://docs.python.org/3/library/stdtypes.html#memoryview \"(in Python v3.11)\")) – The data to send.\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if another task is already executing a [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\"), or [`HalfCloseableStream.send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") on this stream.\n\n- [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\") – if something has gone wrong, and the stream is broken.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this stream object, or if another task closes this stream object while [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") is running.\n\nMost low-level operations in Trio provide a guarantee: if they raise [`trio.Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\"), this means that they had no effect, so the system remains in a known state. This is **not true** for [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\"). If this operation raises [`trio.Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\") (or any other exception for that matter), then it may have sent some, all, or none of the requested data, and there is no way to know which.\n\n### *`abstractmethod await`*` wait_send_all_might_not_block()`\n\nBlock until it’s possible that [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") might not block.\n\nThis method may return early: it’s possible that after it returns, [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") will still block. (In the worst case, if no better implementation is available, then it might always return immediately without blocking. It’s nice to do better than that when possible, though.)\n\nThis method **must not** return *late*: if it’s possible for [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") to complete without blocking, then it must return. When implementing it, err on the side of returning early.\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if another task is already executing a [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\"), or [`HalfCloseableStream.send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") on this stream.\n\n- [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\") – if something has gone wrong, and the stream is broken.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this stream object, or if another task closes this stream object while [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\") is running.\n\n> #### Note\n>\n> This method is intended to aid in implementing protocols that want to delay choosing which data to send until the last moment. E.g., suppose you’re working on an implementation of a remote display server like [VNC](https://en.wikipedia.org/wiki/Virtual_Network_Computing), and the network connection is currently backed up so that if you call [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") now then it will sit for 0.5 seconds before actually sending anything. In this case it doesn’t make sense to take a screenshot, then wait 0.5 seconds, and then send it, because the screen will keep changing while you wait; it’s better to wait 0.5 seconds, then take the screenshot, and then send it, because this way the data you deliver will be more up-to-date. Using [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\") makes it possible to implement the better strategy.\n>\n> If you use this method, you might also want to read up on `TCP_NOTSENT_LOWAT`.\n>\n> Further reading:\n>\n> - [Prioritization Only Works When There’s Pending Data to Prioritize](https://insouciant.org/tech/prioritization-only-works-when-theres-pending-data-to-prioritize/)\n>\n> - WWDC 2015: Your App and Next Generation Networks: [slides](http://devstreaming.apple.com/videos/wwdc/2015/719ui2k57m/719/719_your_app_and_next_generation_networks.pdf?dl=1), [video and transcript](https://developer.apple.com/videos/play/wwdc2015/719/)\n\n### *`class`*` trio.abc.ReceiveStream`\n\nBases: [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")\n\nA standard interface for receiving data on a byte stream.\n\nThe underlying stream may be unidirectional, or bidirectional. If it’s bidirectional, then you probably want to also implement [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\"), which makes your object a [`Stream`](#trio.abc.Stream \"trio.abc.Stream\").\n\n[`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") interface, so they can be closed by calling [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") or using an `async`` ``with` block.\n\nIf you want to receive Python objects rather than raw bytes, see [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\").\n\n[`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") objects can be used in `async`` ``for` loops. Each iteration will produce an arbitrary sized chunk of bytes, like calling [`receive_some`](#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\") with no arguments. Every chunk will contain at least one byte, and the loop automatically exits when reaching end-of-file.\n\n### *`abstractmethod await`*` receive_some(max_bytes=None)`\n\nWait until there is data available on this stream, and then return some of it.\n\nA return value of `b\"\"` (an empty bytestring) indicates that the stream has reached end-of-file. Implementations should be careful that they return `b\"\"` if, and only if, the stream has reached end-of-file!\n\n#### Parameters:\n\n**max_bytes** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The maximum number of bytes to return. Must be greater than zero. Optional; if omitted, then the stream object is free to pick a reasonable default.\n\n#### Returns:\n\nThe data received.\n\n#### Return type:\n\n[bytes](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\") or [bytearray](https://docs.python.org/3/library/stdtypes.html#bytearray \"(in Python v3.11)\")\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if two tasks attempt to call [`receive_some()`](#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\") on the same stream at the same time.\n\n- [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\") – if something has gone wrong, and the stream is broken.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this stream object, or if another task closes this stream object while [`receive_some()`](#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\") is running.\n\n### *`class`*` trio.abc.Stream`\n\nBases: [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\"), [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")\n\nA standard interface for interacting with bidirectional byte streams.\n\nA [`Stream`](#trio.abc.Stream \"trio.abc.Stream\") is an object that implements both the [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\") and [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") interfaces.\n\nIf implementing this interface, you should consider whether you can go one step further and implement [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\").\n\n### *`class`*` trio.abc.HalfCloseableStream`\n\nBases: [`Stream`](#trio.abc.Stream \"trio.abc.Stream\")\n\nThis interface extends [`Stream`](#trio.abc.Stream \"trio.abc.Stream\") to also allow closing the send part of the stream without closing the receive part.\n\n### *`abstractmethod await`*` send_eof()`\n\nSend an end-of-file indication on this stream, if possible.\n\nThe difference between [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") and [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") is that [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") is a *unidirectional* end-of-file indication. After you call this method, you shouldn’t try sending any more data on this stream, and your remote peer should receive an end-of-file indication (eventually, after receiving all the data you sent before that). But, they may continue to send data to you, and you can continue to receive it by calling [`receive_some()`](#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\"). You can think of it as calling [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") on just the [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\") “half” of the stream object (and in fact that’s literally how [`trio.StapledStream`](#trio.StapledStream \"trio.StapledStream\") implements it).\n\nExamples:\n\n- On a socket, this corresponds to `shutdown(...,`` ``SHUT_WR)` ([man page](https://linux.die.net/man/2/shutdown)).\n\n- The SSH protocol provides the ability to multiplex bidirectional “channels” on top of a single encrypted connection. A Trio implementation of SSH could expose these channels as [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\") objects, and calling [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") would send an `SSH_MSG_CHANNEL_EOF` request (see [RFC 4254 §5.3](https://tools.ietf.org/html/rfc4254#section-5.3)).\n\n- On an SSL/TLS-encrypted connection, the protocol doesn’t provide any way to do a unidirectional shutdown without closing the connection entirely, so [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") implements [`Stream`](#trio.abc.Stream \"trio.abc.Stream\"), not [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\").\n\nIf an EOF has already been sent, then this method should silently succeed.\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if another task is already executing a [`send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\"), or [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") on this stream.\n\n- [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\") – if something has gone wrong, and the stream is broken.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this stream object, or if another task closes this stream object while [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof \"trio.abc.HalfCloseableStream.send_eof\") is running.\n\n### *`class`*` trio.abc.Listener`\n\nBases: [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\"), [`Generic`](https://docs.python.org/3/library/typing.html#typing.Generic \"(in Python v3.11)\")\\[`T_resource`\\]\n\nA standard interface for listening for incoming connections.\n\n[`Listener`](#trio.abc.Listener \"trio.abc.Listener\") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") interface, so they can be closed by calling [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") or using an `async`` ``with` block.\n\n### *`abstractmethod await`*` accept()`\n\nWait until an incoming connection arrives, and then return it.\n\n#### Returns:\n\nAn object representing the incoming connection. In practice this is generally some kind of [`Stream`](#trio.abc.Stream \"trio.abc.Stream\"), but in principle you could also define a [`Listener`](#trio.abc.Listener \"trio.abc.Listener\") that returned, say, channel objects.\n\n#### Return type:\n\n[AsyncResource](#trio.abc.AsyncResource \"trio.abc.AsyncResource\")\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if two tasks attempt to call [`accept()`](#trio.abc.Listener.accept \"trio.abc.Listener.accept\") on the same listener at the same time.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this listener object, or if another task closes this listener object while [`accept()`](#trio.abc.Listener.accept \"trio.abc.Listener.accept\") is running.\n\nListeners don’t generally raise [`BrokenResourceError`](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\"), because for listeners there is no general condition of “the network/remote peer broke the connection” that can be handled in a generic way, like there is for streams. Other errors *can* occur and be raised from [`accept()`](#trio.abc.Listener.accept \"trio.abc.Listener.accept\") – for example, if you run out of file descriptors then you might get an [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") with its errno set to `EMFILE`.\n\n### *`class`*` trio.abc.SendChannel`\n\nBases: [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\"), [`Generic`](https://docs.python.org/3/library/typing.html#typing.Generic \"(in Python v3.11)\")\\[`SendType`\\]\n\nA standard interface for sending Python objects to some receiver.\n\n[`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") interface, so they can be closed by calling [`aclose`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") or using an `async`` ``with` block.\n\nIf you want to send raw bytes rather than Python objects, see [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\").\n\n### *`abstractmethod await`*` send(value: SendType) → None`\n\nAttempt to send an object through the channel, blocking if necessary.\n\n#### Parameters:\n\n**value** ([*object*](https://docs.python.org/3/library/functions.html#object \"(in Python v3.11)\")) – The object to send.\n\n#### Raises:\n\n- [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\") – if something has gone wrong, and the channel is broken. For example, you may get this if the receiver has already been closed.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this [`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\") object, or if another task closes it while [`send()`](#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") is running.\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – some channels allow multiple tasks to call [`send`](#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") at the same time, but others don’t. If you try to call [`send`](#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") simultaneously from multiple tasks on a channel that doesn’t support it, then you can get [`BusyResourceError`](reference-core#trio.BusyResourceError \"trio.BusyResourceError\").\n\n### *`class`*` trio.abc.ReceiveChannel`\n\nBases: [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\"), [`Generic`](https://docs.python.org/3/library/typing.html#typing.Generic \"(in Python v3.11)\")\\[`ReceiveType`\\]\n\nA standard interface for receiving Python objects from some sender.\n\nYou can iterate over a [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\") using an `async`` ``for` loop:\n\n``` python\nasync for value in receive_channel:\n    ...\n```\n\nThis is equivalent to calling [`receive()`](#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\") repeatedly. The loop exits without error when [`receive`](#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\") raises [`EndOfChannel`](reference-core#trio.EndOfChannel \"trio.EndOfChannel\").\n\n[`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") interface, so they can be closed by calling [`aclose`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") or using an `async`` ``with` block.\n\nIf you want to receive raw bytes rather than Python objects, see [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\").\n\n### *`abstractmethod await`*` receive() → ReceiveType`\n\nAttempt to receive an incoming object, blocking if necessary.\n\n#### Returns:\n\nWhatever object was received.\n\n#### Return type:\n\n[object](https://docs.python.org/3/library/functions.html#object \"(in Python v3.11)\")\n\n#### Raises:\n\n- [**trio.EndOfChannel**](reference-core#trio.EndOfChannel \"trio.EndOfChannel\") – if the sender has been closed cleanly, and no more objects are coming. This is not an error condition.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you previously closed this [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\") object.\n\n- [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\") – if something has gone wrong, and the channel is broken.\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – some channels allow multiple tasks to call [`receive`](#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\") at the same time, but others don’t. If you try to call [`receive`](#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\") simultaneously from multiple tasks on a channel that doesn’t support it, then you can get [`BusyResourceError`](reference-core#trio.BusyResourceError \"trio.BusyResourceError\").\n\n### *`class`*` trio.abc.Channel`\n\nBases: [`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\")\\[`T`\\], [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\")\\[`T`\\]\n\nA standard interface for interacting with bidirectional channels.\n\nA [`Channel`](#trio.abc.Channel \"trio.abc.Channel\") is an object that implements both the [`SendChannel`](#trio.abc.SendChannel \"trio.abc.SendChannel\") and [`ReceiveChannel`](#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\") interfaces, so you can both send and receive objects.\n\n### Generic stream tools\n\nTrio currently provides a generic helper for writing servers that listen for connections using one or more [`Listener`](#trio.abc.Listener \"trio.abc.Listener\")s, and a generic utility class for working with streams. And if you want to test code that’s written against the streams interface, you should also check out [Streams](reference-testing#testing-streams) in [`trio.testing`](reference-testing#module-trio.testing \"trio.testing\").\n\n### *`await`*` trio.serve_listeners(handler, listeners, *, handler_nursery=None, task_status=TASK_STATUS_IGNORED)`\n\nListen for incoming connections on `listeners`, and for each one start a task running `handler(stream)`.\n\n> #### Warning\n>\n> If `handler` raises an exception, then this function doesn’t do anything special to catch it – so by default the exception will propagate out and crash your server. If you don’t want this, then catch exceptions inside your `handler`, or use a `handler_nursery` object that responds to exceptions in some other way.\n\n#### Parameters:\n\n- **handler** – An async callable, that will be invoked like `handler_nursery.start_soon(handler,`` ``stream)` for each incoming connection.\n\n- **listeners** – A list of [`Listener`](#trio.abc.Listener \"trio.abc.Listener\") objects. [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\") takes responsibility for closing them.\n\n- **handler_nursery** – The nursery used to start handlers, or any object with a `start_soon` method. If `None` (the default), then [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\") will create a new nursery internally and use that.\n\n- **task_status** – This function can be used with `nursery.start`, which will return `listeners`.\n\n#### Returns:\n\nThis function never returns unless cancelled.\n\nResource handling:\n\n> If `handler` neglects to close the `stream`, then it will be closed using [`trio.aclose_forcefully()`](#trio.aclose_forcefully \"trio.aclose_forcefully\").\n\nError handling:\n\n> Most errors coming from [`accept()`](#trio.abc.Listener.accept \"trio.abc.Listener.accept\") are allowed to propagate out (crashing the server in the process). However, some errors – those which indicate that the server is temporarily overloaded – are handled specially. These are [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\")s with one of the following errnos:\n>\n> - `EMFILE`: process is out of file descriptors\n>\n> - `ENFILE`: system is out of file descriptors\n>\n> - `ENOBUFS`, `ENOMEM`: the kernel hit some sort of memory limitation when trying to create a socket object\n>\n> When [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\") gets one of these errors, then it:\n>\n> - Logs the error to the standard library logger `trio.serve_listeners` (level = ERROR, with exception information included). By default this causes it to be printed to stderr.\n>\n> - Waits 100 ms before calling `accept` again, in hopes that the system will recover.\n\n### *`class`*` trio.StapledStream(send_stream, receive_stream)`\n\nBases: [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\")\n\nThis class [staples](https://en.wikipedia.org/wiki/Staple_(fastener)) together two unidirectional streams to make single bidirectional stream.\n\n#### Parameters:\n\n- **send_stream** ([*SendStream*](#trio.abc.SendStream \"trio.abc.SendStream\")) – The stream to use for sending.\n\n- **receive_stream** ([*ReceiveStream*](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")) – The stream to use for receiving.\n\nExample\n\nA silly way to make a stream that echoes back whatever you write to it:\n\n``` python\nleft, right = trio.testing.memory_stream_pair()\necho_stream = StapledStream(SocketStream(left), SocketStream(right))\nawait echo_stream.send_all(b\"x\")\nassert await echo_stream.receive_some() == b\"x\"\n```\n\n[`StapledStream`](#trio.StapledStream \"trio.StapledStream\") objects implement the methods in the [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\") interface. They also have two additional public attributes:\n\n### `send_stream`\n\nThe underlying [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\"). [`send_all()`](#trio.StapledStream.send_all \"trio.StapledStream.send_all\") and [`wait_send_all_might_not_block()`](#trio.StapledStream.wait_send_all_might_not_block \"trio.StapledStream.wait_send_all_might_not_block\") are delegated to this object.\n\n### `receive_stream`\n\nThe underlying [`ReceiveStream`](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\"). [`receive_some()`](#trio.StapledStream.receive_some \"trio.StapledStream.receive_some\") is delegated to this object.\n\n### *`await`*` aclose()`\n\nCalls `aclose` on both underlying streams.\n\n### *`await`*` receive_some(max_bytes=None)`\n\nCalls `self.receive_stream.receive_some`.\n\n### *`await`*` send_all(data)`\n\nCalls `self.send_stream.send_all`.\n\n### *`await`*` send_eof()`\n\nShuts down the send side of the stream.\n\nIf `self.send_stream.send_eof` exists, then calls it. Otherwise, calls `self.send_stream.aclose()`.\n\n### *`await`*` wait_send_all_might_not_block()`\n\nCalls `self.send_stream.wait_send_all_might_not_block`.\n\n### Sockets and networking\n\nThe high-level network interface is built on top of our stream abstraction.\n\n### *`await`*` trio.open_tcp_stream(host, port, *, happy_eyeballs_delay=0.25, local_address=None)`\n\nConnect to the given host and port over TCP.\n\nIf the given `host` has multiple IP addresses associated with it, then we have a problem: which one do we use?\n\nOne approach would be to attempt to connect to the first one, and then if that fails, attempt to connect to the second one … until we’ve tried all of them. But the problem with this is that if the first IP address is unreachable (for example, because it’s an IPv6 address and our network discards IPv6 packets), then we might end up waiting tens of seconds for the first connection attempt to timeout before we try the second address.\n\nAnother approach would be to attempt to connect to all of the addresses at the same time, in parallel, and then use whichever connection succeeds first, abandoning the others. This would be fast, but create a lot of unnecessary load on the network and the remote server.\n\nThis function strikes a balance between these two extremes: it works its way through the available addresses one at a time, like the first approach; but, if `happy_eyeballs_delay` seconds have passed and it’s still waiting for an attempt to succeed or fail, then it gets impatient and starts the next connection attempt in parallel. As soon as any one connection attempt succeeds, all the other attempts are cancelled. This avoids unnecessary load because most connections will succeed after just one or two attempts, but if one of the addresses is unreachable then it doesn’t slow us down too much.\n\nThis is known as a “happy eyeballs” algorithm, and our particular variant is modelled after how Chrome connects to webservers; see [RFC 6555](https://tools.ietf.org/html/rfc6555) for more details.\n\n#### Parameters:\n\n- **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\") *or* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")) – The host to connect to. Can be an IPv4 address, IPv6 address, or a hostname.\n\n- **port** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The port to connect to.\n\n- **happy_eyeballs_delay** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – How many seconds to wait for each connection attempt to succeed or fail before getting impatient and starting another one in parallel. Set to [`math.inf`](https://docs.python.org/3/library/math.html#math.inf \"(in Python v3.11)\") if you want to limit to only one connection attempt at a time (like [`socket.create_connection()`](https://docs.python.org/3/library/socket.html#socket.create_connection \"(in Python v3.11)\")). Default: 0.25 (250 ms).\n\n- **local_address** (*None* *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")) –\n\n  The local IP address or hostname to use as the source for outgoing connections. If `None`, we let the OS pick the source IP.\n\n  This is useful in some exotic networking configurations where your host has multiple IP addresses, and you want to force the use of a specific one.\n\n  Note that if you pass an IPv4 `local_address`, then you won’t be able to connect to IPv6 hosts, and vice-versa. If you want to take advantage of this to force the use of IPv4 or IPv6 without specifying an exact source address, you can use the IPv4 wildcard address `local_address=\"0.0.0.0\"`, or the IPv6 wildcard address `local_address=\"::\"`.\n\n#### Returns:\n\na [`Stream`](#trio.abc.Stream \"trio.abc.Stream\") connected to the given server.\n\n#### Return type:\n\n[SocketStream](#trio.SocketStream \"trio.SocketStream\")\n\n#### Raises:\n\n[**OSError**](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") – if the connection fails.\n\n> #### See also\n>\n> open_ssl_over_tcp_stream\n\n### *`await`*` trio.serve_tcp(handler, port, *, host=None, backlog=None, handler_nursery=None, task_status=TASK_STATUS_IGNORED)`\n\nListen for incoming TCP connections, and for each one start a task running `handler(stream)`.\n\nThis is a thin convenience wrapper around [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\") and [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\") – see them for full details.\n\n> #### Warning\n>\n> If `handler` raises an exception, then this function doesn’t do anything special to catch it – so by default the exception will propagate out and crash your server. If you don’t want this, then catch exceptions inside your `handler`, or use a `handler_nursery` object that responds to exceptions in some other way.\n\nWhen used with `nursery.start` you get back the newly opened listeners. So, for example, if you want to start a server in your test suite and then connect to it to check that it’s working properly, you can use something like:\n\n``` python\nfrom trio.testing import open_stream_to_socket_listener\n\nasync with trio.open_nursery() as nursery:\n    listeners = await nursery.start(serve_tcp, handler, 0)\n    client_stream = await open_stream_to_socket_listener(listeners[0])\n\n    # Then send and receive data on 'client_stream', for example:\n    await client_stream.send_all(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n```\n\nThis avoids several common pitfalls:\n\n1.  It lets the kernel pick a random open port, so your test suite doesn’t depend on any particular port being open.\n\n2.  It waits for the server to be accepting connections on that port before `start` returns, so there’s no race condition where the incoming connection arrives before the server is ready.\n\n3.  It uses the Listener object to find out which port was picked, so it can connect to the right place.\n\n#### Parameters:\n\n- **handler** – The handler to start for each incoming connection. Passed to [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\").\n\n- **port** – The port to listen on. Use 0 to let the kernel pick an open port. Passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")*,* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")*, or* *None*) – The host interface to listen on; use `None` to bind to the wildcard address. Passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **backlog** – The listen backlog, or None to have a good default picked. Passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **handler_nursery** – The nursery to start handlers in, or None to use an internal nursery. Passed to [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\").\n\n- **task_status** – This function can be used with `nursery.start`.\n\n#### Returns:\n\nThis function only returns when cancelled.\n\n### *`await`*` trio.open_ssl_over_tcp_stream(host, port, *, https_compatible=False, ssl_context=None, happy_eyeballs_delay=0.25)`\n\nMake a TLS-encrypted Connection to the given host and port over TCP.\n\nThis is a convenience wrapper that calls [`open_tcp_stream()`](#trio.open_tcp_stream \"trio.open_tcp_stream\") and wraps the result in an [`SSLStream`](#trio.SSLStream \"trio.SSLStream\").\n\nThis function does not perform the TLS handshake; you can do it manually by calling [`do_handshake()`](#trio.SSLStream.do_handshake \"trio.SSLStream.do_handshake\"), or else it will be performed automatically the first time you send or receive data.\n\n#### Parameters:\n\n- **host** ([*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\") *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")) – The host to connect to. We require the server to have a TLS certificate valid for this hostname.\n\n- **port** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The port to connect to.\n\n- **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – Set this to True if you’re connecting to a web server. See [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") for details. Default: False.\n\n- **ssl_context** ([`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\") or None) – The SSL context to use. If None (the default), [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context \"(in Python v3.11)\") will be called to create a context.\n\n- **happy_eyeballs_delay** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – See [`open_tcp_stream()`](#trio.open_tcp_stream \"trio.open_tcp_stream\").\n\n#### Returns:\n\nthe encrypted connection to the server.\n\n#### Return type:\n\n[trio.SSLStream](#trio.SSLStream \"trio.SSLStream\")\n\n### *`await`*` trio.serve_ssl_over_tcp(handler, port, ssl_context, *, host=None, https_compatible=False, backlog=None, handler_nursery=None, task_status=TASK_STATUS_IGNORED)`\n\nListen for incoming TCP connections, and for each one start a task running `handler(stream)`.\n\nThis is a thin convenience wrapper around [`open_ssl_over_tcp_listeners()`](#trio.open_ssl_over_tcp_listeners \"trio.open_ssl_over_tcp_listeners\") and [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\") – see them for full details.\n\n> #### Warning\n>\n> If `handler` raises an exception, then this function doesn’t do anything special to catch it – so by default the exception will propagate out and crash your server. If you don’t want this, then catch exceptions inside your `handler`, or use a `handler_nursery` object that responds to exceptions in some other way.\n\nWhen used with `nursery.start` you get back the newly opened listeners. See the documentation for [`serve_tcp()`](#trio.serve_tcp \"trio.serve_tcp\") for an example where this is useful.\n\n#### Parameters:\n\n- **handler** – The handler to start for each incoming connection. Passed to [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\").\n\n- **port** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The port to listen on. Use 0 to let the kernel pick an open port. Ultimately passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\")) – The SSL context to use for all incoming connections. Passed to [`open_ssl_over_tcp_listeners()`](#trio.open_ssl_over_tcp_listeners \"trio.open_ssl_over_tcp_listeners\").\n\n- **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")*,* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")*, or* *None*) – The address to bind to; use `None` to bind to the wildcard address. Ultimately passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – Set this to True if you want to use “HTTPS-style” TLS. See [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") for details.\n\n- **backlog** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *None*) – See [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") for details.\n\n- **handler_nursery** – The nursery to start handlers in, or None to use an internal nursery. Passed to [`serve_listeners()`](#trio.serve_listeners \"trio.serve_listeners\").\n\n- **task_status** – This function can be used with `nursery.start`.\n\n#### Returns:\n\nThis function only returns when cancelled.\n\n### *`await`*` trio.open_unix_socket(filename)`\n\nOpens a connection to the specified [Unix domain socket](https://en.wikipedia.org/wiki/Unix_domain_socket).\n\nYou must have read/write permission on the specified file to connect.\n\n#### Parameters:\n\n**filename** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\") *or* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")) – The filename to open the connection to.\n\n#### Returns:\n\na [`Stream`](#trio.abc.Stream \"trio.abc.Stream\") connected to the given file.\n\n#### Return type:\n\n[SocketStream](#trio.SocketStream \"trio.SocketStream\")\n\n#### Raises:\n\n- [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") – If the socket file could not be connected to.\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – If AF_UNIX sockets are not supported.\n\n### *`class`*` trio.SocketStream(socket)`\n\nBases: [`HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\")\n\nAn implementation of the [`trio.abc.HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\") interface based on a raw network socket.\n\n#### Parameters:\n\n**socket** – The Trio socket object to wrap. Must have type `SOCK_STREAM`, and be connected.\n\nBy default for TCP sockets, [`SocketStream`](#trio.SocketStream \"trio.SocketStream\") enables `TCP_NODELAY`, and (on platforms where it’s supported) enables `TCP_NOTSENT_LOWAT` with a reasonable buffer size (currently 16 KiB) – see [issue \\#72](https://github.com/python-trio/trio/issues/72) for discussion. You can of course override these defaults by calling [`setsockopt()`](#trio.SocketStream.setsockopt \"trio.SocketStream.setsockopt\").\n\nOnce a [`SocketStream`](#trio.SocketStream \"trio.SocketStream\") object is constructed, it implements the full [`trio.abc.HalfCloseableStream`](#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\") interface. In addition, it provides a few extra features:\n\n### `socket`\n\nThe Trio socket object that this stream wraps.\n\n### *`await`*` aclose()`\n\n### `getsockopt(level, option, buffersize=0)`\n\nCheck the current value of an option on the underlying socket.\n\nSee [`socket.socket.getsockopt()`](https://docs.python.org/3/library/socket.html#socket.socket.getsockopt \"(in Python v3.11)\") for details.\n\n### *`await`*` receive_some(max_bytes=None)`\n\n### *`await`*` send_all(data)`\n\n### *`await`*` send_eof()`\n\n### `setsockopt(level, option, value)`\n\nSet an option on the underlying socket.\n\nSee [`socket.socket.setsockopt()`](https://docs.python.org/3/library/socket.html#socket.socket.setsockopt \"(in Python v3.11)\") for details.\n\n### *`await`*` wait_send_all_might_not_block()`\n\n### *`class`*` trio.SocketListener(socket)`\n\nBases: [`Listener`](#trio.abc.Listener \"trio.abc.Listener\")\\[[`SocketStream`](#trio.SocketStream \"trio.SocketStream\")\\]\n\nA [`Listener`](#trio.abc.Listener \"trio.abc.Listener\") that uses a listening socket to accept incoming connections as [`SocketStream`](#trio.SocketStream \"trio.SocketStream\") objects.\n\n#### Parameters:\n\n**socket** – The Trio socket object to wrap. Must have type `SOCK_STREAM`, and be listening.\n\nNote that the [`SocketListener`](#trio.SocketListener \"trio.SocketListener\") “takes ownership” of the given socket; closing the [`SocketListener`](#trio.SocketListener \"trio.SocketListener\") will also close the socket.\n\n### `socket`\n\nThe Trio socket object that this stream wraps.\n\n### *`await`*` accept()`\n\nAccept an incoming connection.\n\n#### Returns:\n\n[`SocketStream`](#trio.SocketStream \"trio.SocketStream\")\n\n#### Raises:\n\n- [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") – if the underlying call to `accept` raises an unexpected error.\n\n- [**ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you already closed the socket.\n\nThis method handles routine errors like `ECONNABORTED`, but passes other errors on to its caller. In particular, it does *not* make any special effort to handle resource exhaustion errors like `EMFILE`, `ENFILE`, `ENOBUFS`, `ENOMEM`.\n\n### *`await`*` aclose()`\n\nClose this listener and its underlying socket.\n\n### *`await`*` trio.open_tcp_listeners(port, *, host=None, backlog=None)`\n\nCreate [`SocketListener`](#trio.SocketListener \"trio.SocketListener\") objects to listen for TCP connections.\n\n#### Parameters:\n\n- **port** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) –\n\n  The port to listen on.\n\n  If you use 0 as your port, then the kernel will automatically pick an arbitrary open port. But be careful: if you use this feature when binding to multiple IP addresses, then each IP address will get its own random port, and the returned listeners will probably be listening on different ports. In particular, this will happen if you use `host=None` – which is the default – because in this case [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\") will bind to both the IPv4 wildcard address (`0.0.0.0`) and also the IPv6 wildcard address (`::`).\n\n- **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")*,* *bytes-like, or* *None*) –\n\n  The local interface to bind to. This is passed to [`getaddrinfo()`](#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") with the `AI_PASSIVE` flag set.\n\n  If you want to bind to the wildcard address on both IPv4 and IPv6, in order to accept connections on all available interfaces, then pass `None`. This is the default.\n\n  If you have a specific interface you want to bind to, pass its IP address or hostname here. If a hostname resolves to multiple IP addresses, this function will open one listener on each of them.\n\n  If you want to use only IPv4, or only IPv6, but want to accept on all interfaces, pass the family-specific wildcard address: `\"0.0.0.0\"` for IPv4-only and `\"::\"` for IPv6-only.\n\n- **backlog** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *None*) – The listen backlog to use. If you leave this as `None` then Trio will pick a good default. (Currently: whatever your system has configured as the maximum backlog.)\n\n#### Returns:\n\nlist of [`SocketListener`](#trio.SocketListener \"trio.SocketListener\")\n\n### *`await`*` trio.open_ssl_over_tcp_listeners(port, ssl_context, *, host=None, https_compatible=False, backlog=None)`\n\nStart listening for SSL/TLS-encrypted TCP connections to the given port.\n\n#### Parameters:\n\n- **port** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The port to listen on. See [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\")) – The SSL context to use for all incoming connections.\n\n- **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")*,* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")*, or* *None*) – The address to bind to; use `None` to bind to the wildcard address. See [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\").\n\n- **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – See [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") for details.\n\n- **backlog** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *None*) – See [`open_tcp_listeners()`](#trio.open_tcp_listeners \"trio.open_tcp_listeners\") for details.\n\n### SSL / TLS support\n\nTrio provides SSL/TLS support based on the standard library [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl \"(in Python v3.11)\") module. Trio’s [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") and [`SSLListener`](#trio.SSLListener \"trio.SSLListener\") take their configuration from a [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\"), which you can create using [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context \"(in Python v3.11)\") and customize using the other constants and functions in the [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl \"(in Python v3.11)\") module.\n\n> #### Warning\n>\n> Avoid instantiating [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\") directly. A newly constructed [`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\") has less secure defaults than one returned by [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context \"(in Python v3.11)\").\n\nInstead of using [`ssl.SSLContext.wrap_socket()`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext.wrap_socket \"(in Python v3.11)\"), you create a [`SSLStream`](#trio.SSLStream \"trio.SSLStream\"):\n\n### *`class`*` trio.SSLStream(transport_stream, ssl_context, *, server_hostname=None, server_side=False, https_compatible=False)`\n\nBases: [`Stream`](#trio.abc.Stream \"trio.abc.Stream\")\n\nEncrypted communication using SSL/TLS.\n\n[`SSLStream`](#trio.SSLStream \"trio.SSLStream\") wraps an arbitrary [`Stream`](#trio.abc.Stream \"trio.abc.Stream\"), and allows you to perform encrypted communication over it using the usual [`Stream`](#trio.abc.Stream \"trio.abc.Stream\") interface. You pass regular data to [`send_all()`](#trio.SSLStream.send_all \"trio.SSLStream.send_all\"), then it encrypts it and sends the encrypted data on the underlying [`Stream`](#trio.abc.Stream \"trio.abc.Stream\"); [`receive_some()`](#trio.SSLStream.receive_some \"trio.SSLStream.receive_some\") takes encrypted data out of the underlying [`Stream`](#trio.abc.Stream \"trio.abc.Stream\") and decrypts it before returning it.\n\nYou should read the standard library’s [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl \"(in Python v3.11)\") documentation carefully before attempting to use this class, and probably other general documentation on SSL/TLS as well. SSL/TLS is subtle and quick to anger. Really. I’m not kidding.\n\n#### Parameters:\n\n- **transport_stream** ([*Stream*](#trio.abc.Stream \"trio.abc.Stream\")) – The stream used to transport encrypted data. Required.\n\n- **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\")) – The [`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\") used for this connection. Required. Usually created by calling [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context \"(in Python v3.11)\").\n\n- **server_hostname** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\") *or* *None*) – The name of the server being connected to. Used for [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) and for validating the server’s certificate (if hostname checking is enabled). This is effectively mandatory for clients, and actually mandatory if `ssl_context.check_hostname` is `True`.\n\n- **server_side** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – Whether this stream is acting as a client or server. Defaults to False, i.e. client mode.\n\n- **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) –\n\n  There are two versions of SSL/TLS commonly encountered in the wild: the standard version, and the version used for HTTPS (HTTP-over-SSL/TLS).\n\n  Standard-compliant SSL/TLS implementations always send a cryptographically signed `close_notify` message before closing the connection. This is important because if the underlying transport were simply closed, then there wouldn’t be any way for the other side to know whether the connection was intentionally closed by the peer that they negotiated a cryptographic connection to, or by some [man-in-the-middle](https://en.wikipedia.org/wiki/Man-in-the-middle_attack) attacker who can’t manipulate the cryptographic stream, but can manipulate the transport layer (a so-called “truncation attack”).\n\n  However, this part of the standard is widely ignored by real-world HTTPS implementations, which means that if you want to interoperate with them, then you NEED to ignore it too.\n\n  Fortunately this isn’t as bad as it sounds, because the HTTP protocol already includes its own equivalent of `close_notify`, so doing this again at the SSL/TLS level is redundant. But not all protocols do! Therefore, by default Trio implements the safer standard-compliant version (`https_compatible=False`). But if you’re speaking HTTPS or some other protocol where `close_notify`s are commonly skipped, then you should set `https_compatible=True`; with this setting, Trio will neither expect nor send `close_notify` messages.\n\n  If you have code that was written to use [`ssl.SSLSocket`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket \"(in Python v3.11)\") and now you’re porting it to Trio, then it may be useful to know that a difference between [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") and [`ssl.SSLSocket`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket \"(in Python v3.11)\") is that [`SSLSocket`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket \"(in Python v3.11)\") implements the `https_compatible=True` behavior by default.\n\n### `transport_stream`\n\nThe underlying transport stream that was passed to `__init__`. An example of when this would be useful is if you’re using [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") over a [`SocketStream`](#trio.SocketStream \"trio.SocketStream\") and want to call the [`SocketStream`](#trio.SocketStream \"trio.SocketStream\")’s [`setsockopt()`](#trio.SocketStream.setsockopt \"trio.SocketStream.setsockopt\") method.\n\n#### Type:\n\n[trio.abc.Stream](#trio.abc.Stream \"trio.abc.Stream\")\n\nInternally, this class is implemented using an instance of [`ssl.SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject \"(in Python v3.11)\"), and all of [`SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject \"(in Python v3.11)\")’s methods and attributes are re-exported as methods and attributes on this class. However, there is one difference: [`SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject \"(in Python v3.11)\") has several methods that return information about the encrypted connection, like [`cipher()`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket.cipher \"(in Python v3.11)\") or [`selected_alpn_protocol()`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket.selected_alpn_protocol \"(in Python v3.11)\"). If you call them before the handshake, when they can’t possibly return useful data, then [`ssl.SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject \"(in Python v3.11)\") returns None, but [`trio.SSLStream`](#trio.SSLStream \"trio.SSLStream\") raises [`NeedHandshakeError`](#trio.NeedHandshakeError \"trio.NeedHandshakeError\").\n\nThis also means that if you register a SNI callback using [`sni_callback`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext.sni_callback \"(in Python v3.11)\"), then the first argument your callback receives will be a [`ssl.SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject \"(in Python v3.11)\").\n\n### *`await`*` aclose()`\n\nGracefully shut down this connection, and close the underlying transport.\n\nIf `https_compatible` is False (the default), then this attempts to first send a `close_notify` and then close the underlying stream by calling its [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") method.\n\nIf `https_compatible` is set to True, then this simply closes the underlying stream and marks this stream as closed.\n\n### *`await`*` do_handshake()`\n\nEnsure that the initial handshake has completed.\n\nThe SSL protocol requires an initial handshake to exchange certificates, select cryptographic keys, and so forth, before any actual data can be sent or received. You don’t have to call this method; if you don’t, then [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") will automatically perform the handshake as needed, the first time you try to send or receive data. But if you want to trigger it manually – for example, because you want to look at the peer’s certificate before you start talking to them – then you can call this method.\n\nIf the initial handshake is already in progress in another task, this waits for it to complete and then returns.\n\nIf the initial handshake has already completed, this returns immediately without doing anything (except executing a checkpoint).\n\n> #### Warning\n>\n> If this method is cancelled, then it may leave the [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") in an unusable state. If this happens then any future attempt to use the object will raise [`trio.BrokenResourceError`](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\").\n\n### *`await`*` receive_some(max_bytes=None)`\n\nRead some data from the underlying transport, decrypt it, and return it.\n\nSee [`trio.abc.ReceiveStream.receive_some()`](#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\") for details.\n\n> #### Warning\n>\n> If this method is cancelled while the initial handshake or a renegotiation are in progress, then it may leave the [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") in an unusable state. If this happens then any future attempt to use the object will raise [`trio.BrokenResourceError`](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\").\n\n### *`await`*` send_all(data)`\n\nEncrypt some data and then send it on the underlying transport.\n\nSee [`trio.abc.SendStream.send_all()`](#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") for details.\n\n> #### Warning\n>\n> If this method is cancelled, then it may leave the [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") in an unusable state. If this happens then any attempt to use the object will raise [`trio.BrokenResourceError`](reference-core#trio.BrokenResourceError \"trio.BrokenResourceError\").\n\n### *`await`*` unwrap()`\n\nCleanly close down the SSL/TLS encryption layer, allowing the underlying stream to be used for unencrypted communication.\n\nYou almost certainly don’t need this.\n\n#### Returns:\n\nA pair `(transport_stream,`` ``trailing_bytes)`, where `transport_stream` is the underlying transport stream, and `trailing_bytes` is a byte string. Since [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") doesn’t necessarily know where the end of the encrypted data will be, it can happen that it accidentally reads too much from the underlying stream. `trailing_bytes` contains this extra data; you should process it as if it was returned from a call to `transport_stream.receive_some(...)`.\n\n### *`await`*` wait_send_all_might_not_block()`\n\nSee [`trio.abc.SendStream.wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block \"trio.abc.SendStream.wait_send_all_might_not_block\").\n\nAnd if you’re implementing a server, you can use [`SSLListener`](#trio.SSLListener \"trio.SSLListener\"):\n\n### *`class`*` trio.SSLListener(transport_listener, ssl_context, *, https_compatible=False)`\n\nBases: [`Listener`](#trio.abc.Listener \"trio.abc.Listener\")\\[[`SSLStream`](#trio.SSLStream \"trio.SSLStream\")\\]\n\nA [`Listener`](#trio.abc.Listener \"trio.abc.Listener\") for SSL/TLS-encrypted servers.\n\n[`SSLListener`](#trio.SSLListener \"trio.SSLListener\") wraps around another Listener, and converts all incoming connections to encrypted connections by wrapping them in a [`SSLStream`](#trio.SSLStream \"trio.SSLStream\").\n\n#### Parameters:\n\n- **transport_listener** ([*Listener*](#trio.abc.Listener \"trio.abc.Listener\")) – The listener whose incoming connections will be wrapped in [`SSLStream`](#trio.SSLStream \"trio.SSLStream\").\n\n- **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\")) – The [`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext \"(in Python v3.11)\") that will be used for incoming connections.\n\n- **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – Passed on to [`SSLStream`](#trio.SSLStream \"trio.SSLStream\").\n\n### `transport_listener`\n\nThe underlying listener that was passed to `__init__`.\n\n#### Type:\n\n[trio.abc.Listener](#trio.abc.Listener \"trio.abc.Listener\")\n\n### *`await`*` accept()`\n\nAccept the next connection and wrap it in an [`SSLStream`](#trio.SSLStream \"trio.SSLStream\").\n\nSee [`trio.abc.Listener.accept()`](#trio.abc.Listener.accept \"trio.abc.Listener.accept\") for details.\n\n### *`await`*` aclose()`\n\nClose the transport listener.\n\nSome methods on [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") raise [`NeedHandshakeError`](#trio.NeedHandshakeError \"trio.NeedHandshakeError\") if you call them before the handshake completes:\n\n### *`exception`*` trio.NeedHandshakeError`\n\nSome [`SSLStream`](#trio.SSLStream \"trio.SSLStream\") methods can’t return any meaningful data until after the handshake. If you call them before the handshake, they raise this error.\n\n### Datagram TLS support\n\nTrio also has support for Datagram TLS (DTLS), which is like TLS but for unreliable UDP connections. This can be useful for applications where TCP’s reliable in-order delivery is problematic, like teleconferencing, latency-sensitive games, and VPNs.\n\nCurrently, using DTLS with Trio requires PyOpenSSL. We hope to eventually allow the use of the stdlib [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl \"(in Python v3.11)\") module as well, but unfortunately that’s not yet possible.\n\n> #### Warning\n>\n> Note that PyOpenSSL is in many ways lower-level than the [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl \"(in Python v3.11)\") module – in particular, it currently **HAS NO BUILT-IN MECHANISM TO VALIDATE CERTIFICATES**. We *strongly* recommend that you use the [service-identity](https://pypi.org/project/service-identity/) library to validate hostnames and certificates.\n\n### *`class`*` trio.DTLSEndpoint(socket, *, incoming_packets_buffer=10)`\n\nA DTLS endpoint.\n\nA single UDP socket can handle arbitrarily many DTLS connections simultaneously, acting as a client or server as needed. A [`DTLSEndpoint`](#trio.DTLSEndpoint \"trio.DTLSEndpoint\") object holds a UDP socket and manages these connections, which are represented as [`DTLSChannel`](#trio.DTLSChannel \"trio.DTLSChannel\") objects.\n\n#### Parameters:\n\n- **socket** – (trio.socket.SocketType): A `SOCK_DGRAM` socket. If you want to accept incoming connections in server mode, then you should probably bind the socket to some known port.\n\n- **incoming_packets_buffer** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – Each [`DTLSChannel`](#trio.DTLSChannel \"trio.DTLSChannel\") using this socket has its own buffer that holds incoming packets until you call [`receive`](#trio.DTLSChannel.receive \"trio.DTLSChannel.receive\") to read them. This lets you adjust the size of this buffer. [`statistics`](#trio.DTLSChannel.statistics \"trio.DTLSChannel.statistics\") lets you check if the buffer has overflowed.\n\n### `socket`\n\n### `incoming_packets_buffer`\n\nBoth constructor arguments are also exposed as attributes, in case you need to access them later.\n\n### `connect(address, ssl_context)`\n\nInitiate an outgoing DTLS connection.\n\nNotice that this is a synchronous method. That’s because it doesn’t actually initiate any I/O – it just sets up a [`DTLSChannel`](#trio.DTLSChannel \"trio.DTLSChannel\") object. The actual handshake doesn’t occur until you start using the [`DTLSChannel`](#trio.DTLSChannel \"trio.DTLSChannel\"). This gives you a chance to do further configuration first, like setting MTU etc.\n\n#### Parameters:\n\n- **address** – The address to connect to. Usually a (host, port) tuple, like `(\"127.0.0.1\",`` ``12345)`.\n\n- **ssl_context** ([*OpenSSL.SSL.Context*](https://www.pyopenssl.org/en/stable/api/ssl.html#OpenSSL.SSL.Context \"(in pyOpenSSL v23.2.0)\")) – The PyOpenSSL context object to use for this connection.\n\n#### Returns:\n\nDTLSChannel\n\n### *`await`*` serve(ssl_context, async_fn, *args, task_status=TASK_STATUS_IGNORED)`\n\nListen for incoming connections, and spawn a handler for each using an internal nursery.\n\nSimilar to [`serve_tcp`](#trio.serve_tcp \"trio.serve_tcp\"), this function never returns until cancelled, or the [`DTLSEndpoint`](#trio.DTLSEndpoint \"trio.DTLSEndpoint\") is closed and all handlers have exited.\n\nUsage commonly looks like:\n\n``` python\nasync def handler(dtls_channel):\n    ...\n\nasync with trio.open_nursery() as nursery:\n    await nursery.start(dtls_endpoint.serve, ssl_context, handler)\n    # ... do other things here ...\n```\n\nThe `dtls_channel` passed into the handler function has already performed the “cookie exchange” part of the DTLS handshake, so the peer address is trustworthy. But the actual cryptographic handshake doesn’t happen until you start using it, giving you a chance for any last minute configuration, and the option to catch and handle handshake errors.\n\n#### Parameters:\n\n- **ssl_context** ([*OpenSSL.SSL.Context*](https://www.pyopenssl.org/en/stable/api/ssl.html#OpenSSL.SSL.Context \"(in pyOpenSSL v23.2.0)\")) – The PyOpenSSL context object to use for incoming connections.\n\n- **async_fn** – The handler function that will be invoked for each incoming connection.\n\n### `close()`\n\nClose this socket, and all associated DTLS connections.\n\nThis object can also be used as a context manager.\n\n### *`class`*` trio.DTLSChannel(*args: object, **kwargs: object)`\n\nBases: [`Channel`](#trio.abc.Channel \"trio.abc.Channel\")\\[[`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\")\\]\n\nA DTLS connection.\n\nThis class has no public constructor – you get instances by calling [`DTLSEndpoint.serve`](#trio.DTLSEndpoint.serve \"trio.DTLSEndpoint.serve\") or [`connect`](#trio.DTLSEndpoint.connect \"trio.DTLSEndpoint.connect\").\n\n### `endpoint`\n\nThe [`DTLSEndpoint`](#trio.DTLSEndpoint \"trio.DTLSEndpoint\") that this connection is using.\n\n### `peer_address`\n\nThe IP/port of the remote peer that this connection is associated with.\n\n### *`await`*` do_handshake(*, initial_retransmit_timeout=1.0)`\n\nPerform the handshake.\n\nCalling this is optional – if you don’t, then it will be automatically called the first time you call [`send`](#trio.DTLSChannel.send \"trio.DTLSChannel.send\") or [`receive`](#trio.DTLSChannel.receive \"trio.DTLSChannel.receive\"). But calling it explicitly can be useful in case you want to control the retransmit timeout, use a cancel scope to place an overall timeout on the handshake, or catch errors from the handshake specifically.\n\nIt’s safe to call this multiple times, or call it simultaneously from multiple tasks – the first call will perform the handshake, and the rest will be no-ops.\n\n#### Parameters:\n\n**initial_retransmit_timeout** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) –\n\nSince UDP is an unreliable protocol, it’s possible that some of the packets we send during the handshake will get lost. To handle this, DTLS uses a timer to automatically retransmit handshake packets that don’t receive a response. This lets you set the timeout we use to detect packet loss. Ideally, it should be set to ~1.5 times the round-trip time to your peer, but 1 second is a reasonable default. There’s [some useful guidance here](https://tlswg.org/dtls13-spec/draft-ietf-tls-dtls13.html#name-timer-values).\n\nThis is the *initial* timeout, because if packets keep being lost then Trio will automatically back off to longer values, to avoid overloading the network.\n\n### *`await`*` send(data)`\n\nSend a packet of data, securely.\n\n### *`await`*` receive()`\n\nFetch the next packet of data from this connection’s peer, waiting if necessary.\n\nThis is safe to call from multiple tasks simultaneously, in case you have some reason to do that. And more importantly, it’s cancellation-safe, meaning that cancelling a call to [`receive`](#trio.DTLSChannel.receive \"trio.DTLSChannel.receive\") will never cause a packet to be lost or corrupt the underlying connection.\n\n### `close()`\n\nClose this connection.\n\n[`DTLSChannel`](#trio.DTLSChannel \"trio.DTLSChannel\")s don’t actually own any OS-level resources – the socket is owned by the [`DTLSEndpoint`](#trio.DTLSEndpoint \"trio.DTLSEndpoint\"), not the individual connections. So you don’t really *have* to call this. But it will interrupt any other tasks calling [`receive`](#trio.DTLSChannel.receive \"trio.DTLSChannel.receive\") with a [`ClosedResourceError`](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\"), and cause future attempts to use this connection to fail.\n\nYou can also use this object as a synchronous or asynchronous context manager.\n\n### *`await`*` aclose()`\n\nClose this connection, but asynchronously.\n\nThis is included to satisfy the [`trio.abc.Channel`](#trio.abc.Channel \"trio.abc.Channel\") contract. It’s identical to [`close`](#trio.DTLSChannel.close \"trio.DTLSChannel.close\"), but async.\n\n### `set_ciphertext_mtu(new_mtu)`\n\nTells Trio the [largest amount of data that can be sent in a single packet to this peer](https://en.wikipedia.org/wiki/Maximum_transmission_unit).\n\nTrio doesn’t actually enforce this limit – if you pass a huge packet to [`send`](#trio.DTLSChannel.send \"trio.DTLSChannel.send\"), then we’ll dutifully encrypt it and attempt to send it. But calling this method does have two useful effects:\n\n- If called before the handshake is performed, then Trio will automatically fragment handshake messages to fit within the given MTU. It also might fragment them even smaller, if it detects signs of packet loss, so setting this should never be necessary to make a successful connection. But, the packet loss detection only happens after multiple timeouts have expired, so if you have reason to believe that a smaller MTU is required, then you can set this to skip those timeouts and establish the connection more quickly.\n\n- It changes the value returned from [`get_cleartext_mtu`](#trio.DTLSChannel.get_cleartext_mtu \"trio.DTLSChannel.get_cleartext_mtu\"). So if you have some kind of estimate of the network-level MTU, then you can use this to figure out how much overhead DTLS will need for hashes/padding/etc., and how much space you have left for your application data.\n\nThe MTU here is measuring the largest UDP *payload* you think can be sent, the amount of encrypted data that can be handed to the operating system in a single call to [`send`](#trio.DTLSChannel.send \"trio.DTLSChannel.send\"). It should *not* include IP/UDP headers. Note that OS estimates of the MTU often are link-layer MTUs, so you have to subtract off 28 bytes on IPv4 and 48 bytes on IPv6 to get the ciphertext MTU.\n\nBy default, Trio assumes an MTU of 1472 bytes on IPv4, and 1452 bytes on IPv6, which correspond to the common Ethernet MTU of 1500 bytes after accounting for IP/UDP overhead.\n\n### `get_cleartext_mtu()`\n\nReturns the largest number of bytes that you can pass in a single call to [`send`](#trio.DTLSChannel.send \"trio.DTLSChannel.send\") while still fitting within the network-level MTU.\n\nSee [`set_ciphertext_mtu`](#trio.DTLSChannel.set_ciphertext_mtu \"trio.DTLSChannel.set_ciphertext_mtu\") for more details.\n\n### `statistics()`\n\nReturns an object with statistics about this connection.\n\nCurrently this has only one attribute:\n\n- `incoming_packets_dropped_in_trio` (`int`): Gives a count of the number of incoming packets from this peer that Trio successfully received from the network, but then got dropped because the internal channel buffer was full. If this is non-zero, then you might want to call `receive` more often, or use a larger `incoming_packets_buffer`, or just not worry about it because your UDP-based protocol should be able to handle the occasional lost packet, right?\n\n## Low-level networking with [`trio.socket`](#module-trio.socket \"trio.socket\")\n\nThe [`trio.socket`](#module-trio.socket \"trio.socket\") module provides Trio’s basic low-level networking API. If you’re doing ordinary things with stream-oriented connections over IPv4/IPv6/Unix domain sockets, then you probably want to stick to the high-level API described above. If you want to use UDP, or exotic address families like `AF_BLUETOOTH`, or otherwise get direct access to all the quirky bits of your system’s networking API, then you’re in the right place.\n\n### Top-level exports\n\nGenerally, the API exposed by [`trio.socket`](#module-trio.socket \"trio.socket\") mirrors that of the standard library [`socket`](https://docs.python.org/3/library/socket.html#module-socket \"(in Python v3.11)\") module. Most constants (like `SOL_SOCKET`) and simple utilities (like [`inet_aton()`](https://docs.python.org/3/library/socket.html#socket.inet_aton \"(in Python v3.11)\")) are simply re-exported unchanged. But there are also some differences, which are described here.\n\nFirst, Trio provides analogues to all the standard library functions that return socket objects; their interface is identical, except that they’re modified to return Trio socket objects instead:\n\n### `trio.socket.socket(family=-1, type=-1, proto=-1, fileno=None)`\n\nCreate a new Trio socket, like [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket \"(in Python v3.11)\").\n\nThis function’s behavior can be customized using [`set_custom_socket_factory()`](reference-testing#trio.socket.set_custom_socket_factory \"trio.socket.set_custom_socket_factory\").\n\n### `trio.socket.socketpair(family=None, type=SocketKind.SOCK_STREAM, proto=0)`\n\nLike [`socket.socketpair()`](https://docs.python.org/3/library/socket.html#socket.socketpair \"(in Python v3.11)\"), but returns a pair of Trio socket objects.\n\n### `trio.socket.fromfd(fd, family, type, proto=0)`\n\nLike [`socket.fromfd()`](https://docs.python.org/3/library/socket.html#socket.fromfd \"(in Python v3.11)\"), but returns a Trio socket object.\n\n### `trio.socket.fromshare(data)`\n\nLike [`socket.fromshare()`](https://docs.python.org/3/library/socket.html#socket.fromshare \"(in Python v3.11)\"), but returns a Trio socket object.\n\nIn addition, there is a new function to directly convert a standard library socket into a Trio socket:\n\n### `trio.socket.from_stdlib_socket(sock)`\n\nConvert a standard library [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket \"(in Python v3.11)\") object into a Trio socket object.\n\nUnlike [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket \"(in Python v3.11)\"), [`trio.socket.socket()`](#trio.socket.socket \"trio.socket.socket\") is a function, not a class; if you want to check whether an object is a Trio socket, use `isinstance(obj,`` ``trio.socket.SocketType)`.\n\nFor name lookup, Trio provides the standard functions, but with some changes:\n\n### *`await`*` trio.socket.getaddrinfo(host, port, family=0, type=0, proto=0, flags=0)`\n\nLook up a numeric address given a name.\n\nArguments and return values are identical to [`socket.getaddrinfo()`](https://docs.python.org/3/library/socket.html#socket.getaddrinfo \"(in Python v3.11)\"), except that this version is async.\n\nAlso, [`trio.socket.getaddrinfo()`](#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") correctly uses IDNA 2008 to process non-ASCII domain names. ([`socket.getaddrinfo()`](https://docs.python.org/3/library/socket.html#socket.getaddrinfo \"(in Python v3.11)\") uses IDNA 2003, which can give the wrong result in some cases and cause you to connect to a different host than the one you intended; see [bpo-17305](https://bugs.python.org/issue17305).)\n\nThis function’s behavior can be customized using [`set_custom_hostname_resolver()`](reference-testing#trio.socket.set_custom_hostname_resolver \"trio.socket.set_custom_hostname_resolver\").\n\n### *`await`*` trio.socket.getnameinfo(sockaddr, flags)`\n\nLook up a name given a numeric address.\n\nArguments and return values are identical to [`socket.getnameinfo()`](https://docs.python.org/3/library/socket.html#socket.getnameinfo \"(in Python v3.11)\"), except that this version is async.\n\nThis function’s behavior can be customized using [`set_custom_hostname_resolver()`](reference-testing#trio.socket.set_custom_hostname_resolver \"trio.socket.set_custom_hostname_resolver\").\n\n### *`await`*` trio.socket.getprotobyname(name)`\n\nLook up a protocol number by name. (Rarely used.)\n\nLike [`socket.getprotobyname()`](https://docs.python.org/3/library/socket.html#socket.getprotobyname \"(in Python v3.11)\"), but async.\n\nTrio intentionally DOES NOT include some obsolete, redundant, or broken features:\n\n- [`gethostbyname()`](https://docs.python.org/3/library/socket.html#socket.gethostbyname \"(in Python v3.11)\"), [`gethostbyname_ex()`](https://docs.python.org/3/library/socket.html#socket.gethostbyname_ex \"(in Python v3.11)\"), [`gethostbyaddr()`](https://docs.python.org/3/library/socket.html#socket.gethostbyaddr \"(in Python v3.11)\"): obsolete; use [`getaddrinfo()`](https://docs.python.org/3/library/socket.html#socket.getaddrinfo \"(in Python v3.11)\") and [`getnameinfo()`](https://docs.python.org/3/library/socket.html#socket.getnameinfo \"(in Python v3.11)\") instead.\n\n- [`getservbyport()`](https://docs.python.org/3/library/socket.html#socket.getservbyport \"(in Python v3.11)\"): obsolete and [buggy](https://bugs.python.org/issue30482); instead, do:\n\n  ``` python\n  _, service_name = await getnameinfo((127.0.0.1, port), NI_NUMERICHOST))\n  ```\n\n- [`getservbyname()`](https://docs.python.org/3/library/socket.html#socket.getservbyname \"(in Python v3.11)\"): obsolete and [buggy](https://bugs.python.org/issue30482); instead, do:\n\n  ``` python\n  await getaddrinfo(None, service_name)\n  ```\n\n- [`getfqdn()`](https://docs.python.org/3/library/socket.html#socket.getfqdn \"(in Python v3.11)\"): obsolete; use [`getaddrinfo()`](#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") with the `AI_CANONNAME` flag.\n\n- [`getdefaulttimeout()`](https://docs.python.org/3/library/socket.html#socket.getdefaulttimeout \"(in Python v3.11)\"), [`setdefaulttimeout()`](https://docs.python.org/3/library/socket.html#socket.setdefaulttimeout \"(in Python v3.11)\"): instead, use Trio’s standard support for [Cancellation and timeouts](reference-core#cancellation).\n\n- On Windows, `SO_REUSEADDR` is not exported, because it’s a trap: the name is the same as Unix `SO_REUSEADDR`, but the semantics are [different and extremely broken](https://msdn.microsoft.com/en-us/library/windows/desktop/ms740621(v=vs.85).aspx). In the very rare cases where you actually want `SO_REUSEADDR` on Windows, then it can still be accessed from the standard library’s [`socket`](https://docs.python.org/3/library/socket.html#module-socket \"(in Python v3.11)\") module.\n\n### Socket objects\n\n### *`class`*` trio.socket.SocketType`\n\n> #### Note\n>\n> [`trio.socket.SocketType`](#trio.socket.SocketType \"trio.socket.SocketType\") is an abstract class and cannot be instantiated directly; you get concrete socket objects by calling constructors like [`trio.socket.socket()`](#trio.socket.socket \"trio.socket.socket\"). However, you can use it to check if an object is a Trio socket via `isinstance(obj,`` ``trio.socket.SocketType)`.\n\nTrio socket objects are overall very similar to the [standard library socket objects](https://docs.python.org/3/library/socket.html#socket-objects \"(in Python v3.11)\"), with a few important differences:\n\nFirst, and most obviously, everything is made “Trio-style”: blocking methods become async methods, and the following attributes are *not* supported:\n\n- [`setblocking()`](https://docs.python.org/3/library/socket.html#socket.socket.setblocking \"(in Python v3.11)\"): Trio sockets always act like blocking sockets; if you need to read/write from multiple sockets at once, then create multiple tasks.\n\n- [`settimeout()`](https://docs.python.org/3/library/socket.html#socket.socket.settimeout \"(in Python v3.11)\"): see [Cancellation and timeouts](reference-core#cancellation) instead.\n\n- [`makefile()`](https://docs.python.org/3/library/socket.html#socket.socket.makefile \"(in Python v3.11)\"): Python’s file-like API is synchronous, so it can’t be implemented on top of an async socket.\n\n- [`sendall()`](https://docs.python.org/3/library/socket.html#socket.socket.sendall \"(in Python v3.11)\"): Could be supported, but you’re better off using the higher-level [`SocketStream`](#trio.SocketStream \"trio.SocketStream\"), and specifically its [`send_all()`](#trio.SocketStream.send_all \"trio.SocketStream.send_all\") method, which also does additional error checking.\n\nIn addition, the following methods are similar to the equivalents in [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket \"(in Python v3.11)\"), but have some Trio-specific quirks:\n\n### *`await`*` connect()`\n\nConnect the socket to a remote address.\n\nSimilar to [`socket.socket.connect()`](https://docs.python.org/3/library/socket.html#socket.socket.connect \"(in Python v3.11)\"), except async.\n\n> #### Warning\n>\n> Due to limitations of the underlying operating system APIs, it is not always possible to properly cancel a connection attempt once it has begun. If [`connect()`](#trio.socket.SocketType.connect \"trio.socket.SocketType.connect\") is cancelled, and is unable to abort the connection attempt, then it will:\n>\n> 1.  forcibly close the socket to prevent accidental re-use\n>\n> 2.  raise [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\").\n>\n> tl;dr: if [`connect()`](#trio.socket.SocketType.connect \"trio.socket.SocketType.connect\") is cancelled then the socket is left in an unknown state – possibly open, and possibly closed. The only reasonable thing to do is to close it.\n\n### `is_readable()`\n\nCheck whether the socket is readable or not.\n\n### `sendfile()`\n\n[Not implemented yet!](https://github.com/python-trio/trio/issues/45)\n\nWe also keep track of an extra bit of state, because it turns out to be useful for [`trio.SocketStream`](#trio.SocketStream \"trio.SocketStream\"):\n\n### `did_shutdown_SHUT_WR`\n\nThis [`bool`](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\") attribute is True if you’ve called `sock.shutdown(SHUT_WR)` or `sock.shutdown(SHUT_RDWR)`, and False otherwise.\n\nThe following methods are identical to their equivalents in [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket \"(in Python v3.11)\"), except async, and the ones that take address arguments require pre-resolved addresses:\n\n- [`accept()`](https://docs.python.org/3/library/socket.html#socket.socket.accept \"(in Python v3.11)\")\n\n- [`bind()`](https://docs.python.org/3/library/socket.html#socket.socket.bind \"(in Python v3.11)\")\n\n- [`recv()`](https://docs.python.org/3/library/socket.html#socket.socket.recv \"(in Python v3.11)\")\n\n- [`recv_into()`](https://docs.python.org/3/library/socket.html#socket.socket.recv_into \"(in Python v3.11)\")\n\n- [`recvfrom()`](https://docs.python.org/3/library/socket.html#socket.socket.recvfrom \"(in Python v3.11)\")\n\n- [`recvfrom_into()`](https://docs.python.org/3/library/socket.html#socket.socket.recvfrom_into \"(in Python v3.11)\")\n\n- [`recvmsg()`](https://docs.python.org/3/library/socket.html#socket.socket.recvmsg \"(in Python v3.11)\") (if available)\n\n- [`recvmsg_into()`](https://docs.python.org/3/library/socket.html#socket.socket.recvmsg_into \"(in Python v3.11)\") (if available)\n\n- [`send()`](https://docs.python.org/3/library/socket.html#socket.socket.send \"(in Python v3.11)\")\n\n- [`sendto()`](https://docs.python.org/3/library/socket.html#socket.socket.sendto \"(in Python v3.11)\")\n\n- [`sendmsg()`](https://docs.python.org/3/library/socket.html#socket.socket.sendmsg \"(in Python v3.11)\") (if available)\n\nAll methods and attributes *not* mentioned above are identical to their equivalents in [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket \"(in Python v3.11)\"):\n\n- [`family`](https://docs.python.org/3/library/socket.html#socket.socket.family \"(in Python v3.11)\")\n\n- [`type`](https://docs.python.org/3/library/socket.html#socket.socket.type \"(in Python v3.11)\")\n\n- [`proto`](https://docs.python.org/3/library/socket.html#socket.socket.proto \"(in Python v3.11)\")\n\n- [`fileno()`](https://docs.python.org/3/library/socket.html#socket.socket.fileno \"(in Python v3.11)\")\n\n- [`listen()`](https://docs.python.org/3/library/socket.html#socket.socket.listen \"(in Python v3.11)\")\n\n- [`getpeername()`](https://docs.python.org/3/library/socket.html#socket.socket.getpeername \"(in Python v3.11)\")\n\n- [`getsockname()`](https://docs.python.org/3/library/socket.html#socket.socket.getsockname \"(in Python v3.11)\")\n\n- [`close()`](https://docs.python.org/3/library/socket.html#socket.socket.close \"(in Python v3.11)\")\n\n- [`shutdown()`](https://docs.python.org/3/library/socket.html#socket.socket.shutdown \"(in Python v3.11)\")\n\n- [`setsockopt()`](https://docs.python.org/3/library/socket.html#socket.socket.setsockopt \"(in Python v3.11)\")\n\n- [`getsockopt()`](https://docs.python.org/3/library/socket.html#socket.socket.getsockopt \"(in Python v3.11)\")\n\n- [`dup()`](https://docs.python.org/3/library/socket.html#socket.socket.dup \"(in Python v3.11)\")\n\n- [`detach()`](https://docs.python.org/3/library/socket.html#socket.socket.detach \"(in Python v3.11)\")\n\n- [`share()`](https://docs.python.org/3/library/socket.html#socket.socket.share \"(in Python v3.11)\")\n\n- [`set_inheritable()`](https://docs.python.org/3/library/socket.html#socket.socket.set_inheritable \"(in Python v3.11)\")\n\n- [`get_inheritable()`](https://docs.python.org/3/library/socket.html#socket.socket.get_inheritable \"(in Python v3.11)\")\n\n## Asynchronous filesystem I/O\n\nTrio provides built-in facilities for performing asynchronous filesystem operations like reading or renaming a file. Generally, we recommend that you use these instead of Python’s normal synchronous file APIs. But the tradeoffs here are somewhat subtle: sometimes people switch to async I/O, and then they’re surprised and confused when they find it doesn’t speed up their program. The next section explains the theory behind async file I/O, to help you better understand your code’s behavior. Or, if you just want to get started, you can [jump down to the API overview](#async-file-io-overview).\n\n### Background: Why is async file I/O useful? The answer may surprise you\n\nMany people expect that switching from synchronous file I/O to async file I/O will always make their program faster. This is not true! If we just look at total throughput, then async file I/O might be faster, slower, or about the same, and it depends in a complicated way on things like your exact patterns of disk access, or how much RAM you have. The main motivation for async file I/O is not to improve throughput, but to **reduce the frequency of latency glitches.**\n\nTo understand why, you need to know two things.\n\nFirst, right now no mainstream operating system offers a generic, reliable, native API for async file or filesystem operations, so we have to fake it by using threads (specifically, [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync \"trio.to_thread.run_sync\")). This is cheap but isn’t free: on a typical PC, dispatching to a worker thread adds something like ~100 µs of overhead to each operation. (“µs” is pronounced “microseconds”, and there are 1,000,000 µs in a second. Note that all the numbers here are going to be rough orders of magnitude to give you a sense of scale; if you need precise numbers for your environment, measure!)\n\nAnd second, the cost of a disk operation is incredibly bimodal. Sometimes, the data you need is already cached in RAM, and then accessing it is very, very fast – calling [`io.FileIO`](https://docs.python.org/3/library/io.html#io.FileIO \"(in Python v3.11)\")'s `read` method on a cached file takes on the order of ~1 µs. But when the data isn’t cached, then accessing it is much, much slower: the average is ~100 µs for SSDs and ~10,000 µs for spinning disks, and if you look at tail latencies then for both types of storage you’ll see cases where occasionally some operation will be 10x or 100x slower than average. And that’s assuming your program is the only thing trying to use that disk – if you’re on some oversold cloud VM fighting for I/O with other tenants then who knows what will happen. And some operations can require multiple disk accesses.\n\nPutting these together: if your data is in RAM then it should be clear that using a thread is a terrible idea – if you add 100 µs of overhead to a 1 µs operation, then that’s a 100x slowdown! On the other hand, if your data’s on a spinning disk, then using a thread is *great* – instead of blocking the main thread and all tasks for 10,000 µs, we only block them for 100 µs and can spend the rest of that time running other tasks to get useful work done, which can effectively be a 100x speedup.\n\nBut here’s the problem: for any individual I/O operation, there’s no way to know in advance whether it’s going to be one of the fast ones or one of the slow ones, so you can’t pick and choose. When you switch to async file I/O, it makes all the fast operations slower, and all the slow operations faster. Is that a win? In terms of overall speed, it’s hard to say: it depends what kind of disks you’re using and your kernel’s disk cache hit rate, which in turn depends on your file access patterns, how much spare RAM you have, the load on your service, … all kinds of things. If the answer is important to you, then there’s no substitute for measuring your code’s actual behavior in your actual deployment environment. But what we *can* say is that async disk I/O makes performance much more predictable across a wider range of runtime conditions.\n\n**If you’re not sure what to do, then we recommend that you use async disk I/O by default,** because it makes your code more robust when conditions are bad, especially with regards to tail latencies; this improves the chances that what your users see matches what you saw in testing. Blocking the main thread stops *all* tasks from running for that time. 10,000 µs is 10 ms, and it doesn’t take many 10 ms glitches to start adding up to [real money](https://google.com/search?q=latency+cost); async disk I/O can help prevent those. Just don’t expect it to be magic, and be aware of the tradeoffs.\n\n### API overview\n\nIf you want to perform general filesystem operations like creating and listing directories, renaming files, or checking file metadata – or if you just want a friendly way to work with filesystem paths – then you want [`trio.Path`](#trio.Path \"trio.Path\"). It’s an asyncified replacement for the standard library’s [`pathlib.Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path \"(in Python v3.11)\"), and provides the same comprehensive set of operations.\n\nFor reading and writing to files and file-like objects, Trio also provides a mechanism for wrapping any synchronous file-like object into an asynchronous interface. If you have a [`trio.Path`](#trio.Path \"trio.Path\") object you can get one of these by calling its [`open()`](#trio.Path.open \"trio.Path.open\") method; or if you know the file’s name you can open it directly with [`trio.open_file()`](#trio.open_file \"trio.open_file\"). Alternatively, if you already have an open file-like object, you can wrap it with [`trio.wrap_file()`](#trio.wrap_file \"trio.wrap_file\") – one case where this is especially useful is to wrap [`io.BytesIO`](https://docs.python.org/3/library/io.html#io.BytesIO \"(in Python v3.11)\") or [`io.StringIO`](https://docs.python.org/3/library/io.html#io.StringIO \"(in Python v3.11)\") when writing tests.\n\n### Asynchronous path objects\n\n### *`class`*` trio.Path(*args)`\n\nA [`pathlib.Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path \"(in Python v3.11)\") wrapper that executes blocking methods in [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync \"trio.to_thread.run_sync\").\n\n### `as_posix()`\n\nReturn the string representation of the path with forward (/) slashes.\n\n### `as_uri()`\n\nReturn the path as a ‘file’ URI.\n\n### *`await`*` chmod(*args, **kwargs)`\n\nLike [`chmod()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.chmod \"(in Python v3.11)\"), but async.\n\n### *`classmethod await`*` cwd(*args, **kwargs)`\n\nLike [`cwd()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.cwd \"(in Python v3.11)\"), but async.\n\n### *`await`*` exists(*args, **kwargs)`\n\nLike [`exists()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.exists \"(in Python v3.11)\"), but async.\n\n### *`await`*` expanduser(*args, **kwargs)`\n\nLike [`expanduser()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.expanduser \"(in Python v3.11)\"), but async.\n\n### *`await`*` glob(*args, **kwargs)`\n\nLike [`glob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob \"(in Python v3.11)\"), but async.\n\n### *`await`*` group(*args, **kwargs)`\n\nLike [`group()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.group \"(in Python v3.11)\"), but async.\n\n### *`await`*` hardlink_to(*args, **kwargs)`\n\nLike [`hardlink_to()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.hardlink_to \"(in Python v3.11)\"), but async.\n\n### *`classmethod await`*` home(*args, **kwargs)`\n\nLike [`home()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.home \"(in Python v3.11)\"), but async.\n\n### `is_absolute()`\n\nTrue if the path is absolute (has both a root and, if applicable, a drive).\n\n### *`await`*` is_block_device(*args, **kwargs)`\n\nLike [`is_block_device()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_block_device \"(in Python v3.11)\"), but async.\n\n### *`await`*` is_char_device(*args, **kwargs)`\n\nLike [`is_char_device()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_char_device \"(in Python v3.11)\"), but async.\n\n### *`await`*` is_dir(*args, **kwargs)`\n\nLike [`is_dir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_dir \"(in Python v3.11)\"), but async.\n\n### *`await`*` is_fifo(*args, **kwargs)`\n\nLike [`is_fifo()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_fifo \"(in Python v3.11)\"), but async.\n\n### *`await`*` is_file(*args, **kwargs)`\n\nLike [`is_file()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_file \"(in Python v3.11)\"), but async.\n\n### *`await`*` is_mount(*args, **kwargs)`\n\nLike [`is_mount()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_mount \"(in Python v3.11)\"), but async.\n\n### `is_relative_to(*other)`\n\nReturn True if the path is relative to another path or False.\n\n### `is_reserved()`\n\nReturn True if the path contains one of the special names reserved by the system, if any.\n\n### *`await`*` is_socket(*args, **kwargs)`\n\nLike [`is_socket()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_socket \"(in Python v3.11)\"), but async.\n\n### *`await`*` is_symlink(*args, **kwargs)`\n\nLike [`is_symlink()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_symlink \"(in Python v3.11)\"), but async.\n\n### *`await`*` iterdir(*args, **kwargs)`\n\nLike [`pathlib.Path.iterdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.iterdir \"(in Python v3.11)\"), but async.\n\nThis is an async method that returns a synchronous iterator, so you use it like:\n\n``` python\nfor subpath in await mypath.iterdir():\n    ...\n```\n\nNote that it actually loads the whole directory list into memory immediately, during the initial call. (See [issue \\#501](https://github.com/python-trio/trio/issues/501) for discussion.)\n\n### `joinpath(*args)`\n\nCombine this path with one or several arguments, and return a new path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored).\n\n### *`await`*` lchmod(*args, **kwargs)`\n\nLike [`lchmod()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.lchmod \"(in Python v3.11)\"), but async.\n\n### *`await`*` link_to(*args, **kwargs)`\n\nLike [`link_to()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.link_to \"(in Python v3.11)\"), but async.\n\n### *`await`*` lstat(*args, **kwargs)`\n\nLike [`lstat()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.lstat \"(in Python v3.11)\"), but async.\n\n### `match(path_pattern)`\n\nReturn True if this path matches the given pattern.\n\n### *`await`*` mkdir(*args, **kwargs)`\n\nLike [`mkdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir \"(in Python v3.11)\"), but async.\n\n### *`await`*` open(mode='r', buffering=-1, encoding=None, errors=None, newline=None)`\n\nOpen the file pointed by this path and return a file object, as the built-in open() function does.\n\n### *`await`*` owner(*args, **kwargs)`\n\nLike [`owner()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.owner \"(in Python v3.11)\"), but async.\n\n### *`await`*` read_bytes(*args, **kwargs)`\n\nLike [`read_bytes()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.read_bytes \"(in Python v3.11)\"), but async.\n\n### *`await`*` read_text(*args, **kwargs)`\n\nLike [`read_text()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.read_text \"(in Python v3.11)\"), but async.\n\n### *`await`*` readlink(*args, **kwargs)`\n\nLike [`readlink()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.readlink \"(in Python v3.11)\"), but async.\n\n### `relative_to(*other)`\n\nReturn the relative path to another path identified by the passed arguments. If the operation is not possible (because this is not a subpath of the other path), raise ValueError.\n\n### *`await`*` rename(*args, **kwargs)`\n\nLike [`rename()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rename \"(in Python v3.11)\"), but async.\n\n### *`await`*` replace(*args, **kwargs)`\n\nLike [`replace()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.replace \"(in Python v3.11)\"), but async.\n\n### *`await`*` resolve(*args, **kwargs)`\n\nLike [`resolve()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.resolve \"(in Python v3.11)\"), but async.\n\n### *`await`*` rglob(*args, **kwargs)`\n\nLike [`rglob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rglob \"(in Python v3.11)\"), but async.\n\n### *`await`*` rmdir(*args, **kwargs)`\n\nLike [`rmdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rmdir \"(in Python v3.11)\"), but async.\n\n### *`await`*` samefile(*args, **kwargs)`\n\nLike [`samefile()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.samefile \"(in Python v3.11)\"), but async.\n\n### *`await`*` stat(*args, **kwargs)`\n\nLike [`stat()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat \"(in Python v3.11)\"), but async.\n\n### *`await`*` symlink_to(*args, **kwargs)`\n\nLike [`symlink_to()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.symlink_to \"(in Python v3.11)\"), but async.\n\n### *`await`*` touch(*args, **kwargs)`\n\nLike [`touch()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.touch \"(in Python v3.11)\"), but async.\n\n### *`await`*` unlink(*args, **kwargs)`\n\nLike [`unlink()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink \"(in Python v3.11)\"), but async.\n\n### `with_name(name)`\n\nReturn a new path with the file name changed.\n\n### `with_stem(stem)`\n\nReturn a new path with the stem changed.\n\n### `with_suffix(suffix)`\n\nReturn a new path with the file suffix changed. If the path has no suffix, add given suffix. If the given suffix is an empty string, remove the suffix from the path.\n\n### *`await`*` write_bytes(*args, **kwargs)`\n\nLike [`write_bytes()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.write_bytes \"(in Python v3.11)\"), but async.\n\n### *`await`*` write_text(*args, **kwargs)`\n\nLike [`write_text()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.write_text \"(in Python v3.11)\"), but async.\n\n### Asynchronous file objects\n\n### *`await`*` trio.open_file(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)`\n\nAsynchronous version of [`io.open()`](https://docs.python.org/3/library/io.html#io.open \"(in Python v3.11)\").\n\n#### Returns:\n\nAn [asynchronous file object](https://trio.readthedocs.io/en/v0.22.2/glossary.html#term-asynchronous-file-object)\n\nExample:\n\n``` python\nasync with await trio.open_file(filename) as f:\n    async for line in f:\n        pass\n\nassert f.closed\n```\n\n> #### See also\n>\n> [`trio.Path.open()`](#trio.Path.open \"trio.Path.open\")\n\n### `trio.wrap_file(file)`\n\nThis wraps any file object in a wrapper that provides an asynchronous file object interface.\n\n#### Parameters:\n\n**file** – a [file object](https://docs.python.org/3/glossary.html#term-file-object \"(in Python v3.11)\")\n\n#### Returns:\n\nAn [asynchronous file object](https://trio.readthedocs.io/en/v0.22.2/glossary.html#term-asynchronous-file-object) that wraps `file`\n\nExample:\n\n``` python\nasync_file = trio.wrap_file(StringIO('asdf'))\n\nassert await async_file.read() == 'asdf'\n```\n\n### `Asynchronous file interface`\n\nTrio’s asynchronous file objects have an interface that automatically adapts to the object being wrapped. Intuitively, you can mostly treat them like a regular [file object](https://docs.python.org/3/glossary.html#term-file-object \"(in Python v3.11)\"), except adding an `await` in front of any of methods that do I/O. The definition of [file object](https://docs.python.org/3/glossary.html#term-file-object \"(in Python v3.11)\") is a little vague in Python though, so here are the details:\n\n- Synchronous attributes/methods: if any of the following attributes or methods are present, then they’re re-exported unchanged: `closed`, `encoding`, `errors`, `fileno`, `isatty`, `newlines`, `readable`, `seekable`, `writable`, `buffer`, `raw`, `line_buffering`, `closefd`, `name`, `mode`, `getvalue`, `getbuffer`.\n\n- Async methods: if any of the following methods are present, then they’re re-exported as an async method: `flush`, `read`, `read1`, `readall`, `readinto`, `readline`, `readlines`, `seek`, `tell`, `truncate`, `write`, `writelines`, `readinto1`, `peek`, `detach`.\n\nSpecial notes:\n\n- Async file objects implement Trio’s [`AsyncResource`](#trio.abc.AsyncResource \"trio.abc.AsyncResource\") interface: you close them by calling [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") instead of `close` (!!), and they can be used as async context managers. Like all [`aclose()`](#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") methods, the `aclose` method on async file objects is guaranteed to close the file before returning, even if it is cancelled or otherwise raises an error.\n\n- Using the same async file object from multiple tasks simultaneously: because the async methods on async file objects are implemented using threads, it’s only safe to call two of them at the same time from different tasks IF the underlying synchronous file object is thread-safe. You should consult the documentation for the object you’re wrapping. For objects returned from [`trio.open_file()`](#trio.open_file \"trio.open_file\") or [`trio.Path.open()`](#trio.Path.open \"trio.Path.open\"), it depends on whether you open the file in binary mode or text mode: [binary mode files are task-safe/thread-safe, text mode files are not](https://docs.python.org/3/library/io.html#multi-threading).\n\n- Async file objects can be used as async iterators to iterate over the lines of the file:\n\n  ``` python\n  async with await trio.open_file(...) as f:\n      async for line in f:\n          print(line)\n  ```\n\n- The `detach` method, if present, returns an async file object.\n\nThis should include all the attributes exposed by classes in [`io`](https://docs.python.org/3/library/io.html#module-io \"(in Python v3.11)\"). But if you’re wrapping an object that has other attributes that aren’t on the list above, then you can access them via the `.wrapped` attribute:\n\n### `wrapped`\n\nThe underlying synchronous file object.\n\n## Spawning subprocesses\n\nTrio provides support for spawning other programs as subprocesses, communicating with them via pipes, sending them signals, and waiting for them to exit.\n\nMost of the time, this is done through our high-level interface, [`trio.run_process`](#trio.run_process \"trio.run_process\"). It lets you either run a process to completion while optionally capturing the output, or else run it in a background task and interact with it while it’s running:\n\n### *`await`*` trio.run_process(command, *, stdin=b'', capture_stdout=False, capture_stderr=False, check=True, deliver_cancel=None, task_status=TASK_STATUS_IGNORED, **options)`\n\nRun `command` in a subprocess and wait for it to complete.\n\nThis function can be called in two different ways.\n\nOne option is a direct call, like:\n\n``` python\ncompleted_process_info = await trio.run_process(...)\n```\n\nIn this case, it returns a [`subprocess.CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess \"(in Python v3.11)\") instance describing the results. Use this if you want to treat a process like a function call.\n\nThe other option is to run it as a task using [`Nursery.start`](reference-core#trio.Nursery.start \"trio.Nursery.start\") – the enhanced version of [`start_soon`](reference-core#trio.Nursery.start_soon \"trio.Nursery.start_soon\") that lets a task pass back a value during startup:\n\n``` python\nprocess = await nursery.start(trio.run_process, ...)\n```\n\nIn this case, [`start`](reference-core#trio.Nursery.start \"trio.Nursery.start\") returns a [`Process`](#trio.Process \"trio.Process\") object that you can use to interact with the process while it’s running. Use this if you want to treat a process like a background task.\n\nEither way, [`run_process`](#trio.run_process \"trio.run_process\") makes sure that the process has exited before returning, handles cancellation, optionally checks for errors, and provides some convenient shorthands for dealing with the child’s input/output.\n\n**Input:** [`run_process`](#trio.run_process \"trio.run_process\") supports all the same `stdin=` arguments as [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen \"(in Python v3.11)\"). In addition, if you simply want to pass in some fixed data, you can pass a plain [`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\") object, and [`run_process`](#trio.run_process \"trio.run_process\") will take care of setting up a pipe, feeding in the data you gave, and then sending end-of-file. The default is `b\"\"`, which means that the child will receive an empty stdin. If you want the child to instead read from the parent’s stdin, use `stdin=None`.\n\n**Output:** By default, any output produced by the subprocess is passed through to the standard output and error streams of the parent Trio process.\n\nWhen calling [`run_process`](#trio.run_process \"trio.run_process\") directly, you can capture the subprocess’s output by passing `capture_stdout=True` to capture the subprocess’s standard output, and/or `capture_stderr=True` to capture its standard error. Captured data is collected up by Trio into an in-memory buffer, and then provided as the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stdout \"(in Python v3.11)\") and/or [`stderr`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stderr \"(in Python v3.11)\") attributes of the returned [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess \"(in Python v3.11)\") object. The value for any stream that was not captured will be `None`.\n\nIf you want to capture both stdout and stderr while keeping them separate, pass `capture_stdout=True,`` ``capture_stderr=True`.\n\nIf you want to capture both stdout and stderr but mixed together in the order they were printed, use: `capture_stdout=True,`` ``stderr=subprocess.STDOUT`. This directs the child’s stderr into its stdout, so the combined output will be available in the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stdout \"(in Python v3.11)\") attribute.\n\nIf you’re using `await`` ``nursery.start(trio.run_process,`` ``...)` and want to capture the subprocess’s output for further processing, then use `stdout=subprocess.PIPE` and then make sure to read the data out of the [`Process.stdout`](#trio.Process.stdout \"trio.Process.stdout\") stream. If you want to capture stderr separately, use `stderr=subprocess.PIPE`. If you want to capture both, but mixed together in the correct order, use `stdout=subprocess.PIPE,`` ``stderr=subprocess.STDOUT`.\n\n**Error checking:** If the subprocess exits with a nonzero status code, indicating failure, [`run_process()`](#trio.run_process \"trio.run_process\") raises a [`subprocess.CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError \"(in Python v3.11)\") exception rather than returning normally. The captured outputs are still available as the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError.stdout \"(in Python v3.11)\") and [`stderr`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError.stderr \"(in Python v3.11)\") attributes of that exception. To disable this behavior, so that [`run_process()`](#trio.run_process \"trio.run_process\") returns normally even if the subprocess exits abnormally, pass `check=False`.\n\nNote that this can make the `capture_stdout` and `capture_stderr` arguments useful even when starting [`run_process`](#trio.run_process \"trio.run_process\") as a task: if you only care about the output if the process fails, then you can enable capturing and then read the output off of the [`CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError \"(in Python v3.11)\").\n\n**Cancellation:** If cancelled, [`run_process`](#trio.run_process \"trio.run_process\") sends a termination request to the subprocess, then waits for it to fully exit. The `deliver_cancel` argument lets you control how the process is terminated.\n\n> #### Note\n>\n> [`run_process`](#trio.run_process \"trio.run_process\") is intentionally similar to the standard library [`subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run \"(in Python v3.11)\"), but some of the defaults are different. Specifically, we default to:\n>\n> - `check=True`, because [“errors should never pass silently / unless explicitly silenced”](https://www.python.org/dev/peps/pep-0020/).\n>\n> - `stdin=b\"\"`, because it produces less-confusing results if a subprocess unexpectedly tries to read from stdin.\n>\n> To get the [`subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run \"(in Python v3.11)\") semantics, use `check=False,`` ``stdin=None`.\n\n#### Parameters:\n\n- **command** ([*list*](https://docs.python.org/3/library/stdtypes.html#list \"(in Python v3.11)\") *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")) – The command to run. Typically this is a sequence of strings such as `['ls',`` ``'-l',`` ``'directory`` ``with`` ``spaces']`, where the first element names the executable to invoke and the other elements specify its arguments. With `shell=True` in the `**options`, or on Windows, `command` may alternatively be a string, which will be parsed following platform-dependent [quoting rules](#subprocess-quoting).\n\n- **stdin** ([`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes \"(in Python v3.11)\"), subprocess.PIPE, file descriptor, or None) –\n\n  The bytes to provide to the subprocess on its standard input stream, or `None` if the subprocess’s standard input should come from the same place as the parent Trio process’s standard input. As is the case with the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess \"(in Python v3.11)\") module, you can also pass a file descriptor or an object with a `fileno()` method, in which case the subprocess’s standard input will come from that file.\n\n  When starting [`run_process`](#trio.run_process \"trio.run_process\") as a background task, you can also use `stdin=subprocess.PIPE`, in which case [`Process.stdin`](#trio.Process.stdin \"trio.Process.stdin\") will be a [`SendStream`](#trio.abc.SendStream \"trio.abc.SendStream\") that you can use to send data to the child.\n\n- **capture_stdout** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – If true, capture the bytes that the subprocess writes to its standard output stream and return them in the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stdout \"(in Python v3.11)\") attribute of the returned [`subprocess.CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess \"(in Python v3.11)\") or [`subprocess.CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError \"(in Python v3.11)\").\n\n- **capture_stderr** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – If true, capture the bytes that the subprocess writes to its standard error stream and return them in the [`stderr`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stderr \"(in Python v3.11)\") attribute of the returned [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess \"(in Python v3.11)\") or [`subprocess.CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError \"(in Python v3.11)\").\n\n- **check** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – If false, don’t validate that the subprocess exits successfully. You should be sure to check the `returncode` attribute of the returned object if you pass `check=False`, so that errors don’t pass silently.\n\n- **deliver_cancel** (*async function* *or* *None*) –\n\n  If [`run_process`](#trio.run_process \"trio.run_process\") is cancelled, then it needs to kill the child process. There are multiple ways to do this, so we let you customize it.\n\n  If you pass None (the default), then the behavior depends on the platform:\n\n  - On Windows, Trio calls `TerminateProcess`, which should kill the process immediately.\n\n  - On Unix-likes, the default behavior is to send a `SIGTERM`, wait 5 seconds, and send a `SIGKILL`.\n\n  Alternatively, you can customize this behavior by passing in an arbitrary async function, which will be called with the [`Process`](#trio.Process \"trio.Process\") object as an argument. For example, the default Unix behavior could be implemented like this:\n\n  ``` python\n  async def my_deliver_cancel(process):\n      process.send_signal(signal.SIGTERM)\n      await trio.sleep(5)\n      process.send_signal(signal.SIGKILL)\n  ```\n\n  When the process actually exits, the `deliver_cancel` function will automatically be cancelled – so if the process exits after `SIGTERM`, then we’ll never reach the `SIGKILL`.\n\n  In any case, [`run_process`](#trio.run_process \"trio.run_process\") will always wait for the child process to exit before raising [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\").\n\n- **\\*\\*options** – [`run_process()`](#trio.run_process \"trio.run_process\") also accepts any [general subprocess options](#subprocess-options) and passes them on to the [`Process`](#trio.Process \"trio.Process\") constructor. This includes the `stdout` and `stderr` options, which provide additional redirection possibilities such as `stderr=subprocess.STDOUT`, `stdout=subprocess.DEVNULL`, or file descriptors.\n\n#### Returns:\n\nWhen called normally – a [`subprocess.CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess \"(in Python v3.11)\") instance describing the return code and outputs.\n\nWhen called via [`Nursery.start`](reference-core#trio.Nursery.start \"trio.Nursery.start\") – a [`trio.Process`](#trio.Process \"trio.Process\") instance.\n\n#### Raises:\n\n- [**UnicodeError**](https://docs.python.org/3/library/exceptions.html#UnicodeError \"(in Python v3.11)\") – if `stdin` is specified as a Unicode string, rather than bytes\n\n- [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if multiple redirections are specified for the same stream, e.g., both `capture_stdout=True` and `stdout=subprocess.DEVNULL`\n\n- [**subprocess.CalledProcessError**](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError \"(in Python v3.11)\") – if `check=False` is not passed and the process exits with a nonzero exit status\n\n- [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") – if an error is encountered starting or communicating with the process\n\n> #### Note\n>\n> The child process runs in the same process group as the parent Trio process, so a Ctrl+C will be delivered simultaneously to both parent and child. If you don’t want this behavior, consult your platform’s documentation for starting child processes in a different process group.\n\n### *`class`*` trio.Process(*args: object, **kwargs: object)`\n\nA child process. Like [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen \"(in Python v3.11)\"), but async.\n\nThis class has no public constructor. The most common way to get a [`Process`](#trio.Process \"trio.Process\") object is to combine [`Nursery.start`](reference-core#trio.Nursery.start \"trio.Nursery.start\") with [`run_process`](#trio.run_process \"trio.run_process\"):\n\n``` python\nprocess_object = await nursery.start(run_process, ...)\n```\n\nThis way, [`run_process`](#trio.run_process \"trio.run_process\") supervises the process and makes sure that it is cleaned up properly, while optionally checking the return value, feeding it input, and so on.\n\nIf you need more control – for example, because you want to spawn a child process that outlives your program – then another option is to use [`trio.lowlevel.open_process`](reference-lowlevel#trio.lowlevel.open_process \"trio.lowlevel.open_process\"):\n\n``` python\nprocess_object = await trio.lowlevel.open_process(...)\n```\n\n### `args`\n\nThe `command` passed at construction time, specifying the process to execute and its arguments.\n\n#### Type:\n\n[str](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\") or [list](https://docs.python.org/3/library/stdtypes.html#list \"(in Python v3.11)\")\n\n### `pid`\n\nThe process ID of the child process managed by this object.\n\n#### Type:\n\n[int](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")\n\n### `stdin`\n\nA stream connected to the child’s standard input stream: when you write bytes here, they become available for the child to read. Only available if the [`Process`](#trio.Process \"trio.Process\") was constructed using `stdin=PIPE`; otherwise this will be None.\n\n#### Type:\n\n[trio.abc.SendStream](#trio.abc.SendStream \"trio.abc.SendStream\") or None\n\n### `stdout`\n\nA stream connected to the child’s standard output stream: when the child writes to standard output, the written bytes become available for you to read here. Only available if the [`Process`](#trio.Process \"trio.Process\") was constructed using `stdout=PIPE`; otherwise this will be None.\n\n#### Type:\n\n[trio.abc.ReceiveStream](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") or None\n\n### `stderr`\n\nA stream connected to the child’s standard error stream: when the child writes to standard error, the written bytes become available for you to read here. Only available if the [`Process`](#trio.Process \"trio.Process\") was constructed using `stderr=PIPE`; otherwise this will be None.\n\n#### Type:\n\n[trio.abc.ReceiveStream](#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") or None\n\n### `stdio`\n\nA stream that sends data to the child’s standard input and receives from the child’s standard output. Only available if both [`stdin`](#trio.Process.stdin \"trio.Process.stdin\") and [`stdout`](#trio.Process.stdout \"trio.Process.stdout\") are available; otherwise this will be None.\n\n#### Type:\n\n[trio.StapledStream](#trio.StapledStream \"trio.StapledStream\") or None\n\n### `returncode`\n\nThe exit status of the process (an integer), or `None` if it’s still running.\n\nBy convention, a return code of zero indicates success. On UNIX, negative values indicate termination due to a signal, e.g., -11 if terminated by signal 11 (`SIGSEGV`). On Windows, a process that exits due to a call to [`Process.terminate()`](#trio.Process.terminate \"trio.Process.terminate\") will have an exit status of 1.\n\nUnlike the standard library [`subprocess.Popen.returncode`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.returncode \"(in Python v3.11)\"), you don’t have to call [`poll`](#trio.Process.poll \"trio.Process.poll\") or [`wait`](#trio.Process.wait \"trio.Process.wait\") to update this attribute; it’s automatically updated as needed, and will always give you the latest information.\n\n### *`await`*` wait()`\n\nBlock until the process exits.\n\n#### Returns:\n\nThe exit status of the process; see [`returncode`](#trio.Process.returncode \"trio.Process.returncode\").\n\n### `poll()`\n\nReturns the exit status of the process (an integer), or `None` if it’s still running.\n\nNote that on Trio (unlike the standard library [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen \"(in Python v3.11)\")), `process.poll()` and `process.returncode` always give the same result. See [`returncode`](#trio.Process.returncode \"trio.Process.returncode\") for more details. This method is only included to make it easier to port code from [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess \"(in Python v3.11)\").\n\n### `kill()`\n\nImmediately terminate the process.\n\nOn UNIX, this is equivalent to `send_signal(signal.SIGKILL)`. On Windows, it calls `TerminateProcess`. In both cases, the process cannot prevent itself from being killed, but the termination will be delivered asynchronously; use [`wait()`](#trio.Process.wait \"trio.Process.wait\") if you want to ensure the process is actually dead before proceeding.\n\n### `terminate()`\n\nTerminate the process, politely if possible.\n\nOn UNIX, this is equivalent to `send_signal(signal.SIGTERM)`; by convention this requests graceful termination, but a misbehaving or buggy process might ignore it. On Windows, [`terminate()`](#trio.Process.terminate \"trio.Process.terminate\") forcibly terminates the process in the same manner as [`kill()`](#trio.Process.kill \"trio.Process.kill\").\n\n### `send_signal(sig)`\n\nSend signal `sig` to the process.\n\nOn UNIX, `sig` may be any signal defined in the [`signal`](https://docs.python.org/3/library/signal.html#module-signal \"(in Python v3.11)\") module, such as `signal.SIGINT` or `signal.SIGTERM`. On Windows, it may be anything accepted by the standard library [`subprocess.Popen.send_signal()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal \"(in Python v3.11)\").\n\n> #### Note\n>\n> [`communicate()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.communicate \"(in Python v3.11)\") is not provided as a method on [`Process`](#trio.Process \"trio.Process\") objects; call [`run_process()`](#trio.run_process \"trio.run_process\") normally for simple capturing, or write the loop yourself if you have unusual needs. [`communicate()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.communicate \"(in Python v3.11)\") has quite unusual cancellation behavior in the standard library (on some platforms it spawns a background thread which continues to read from the child process even after the timeout has expired) and we wanted to provide an interface with fewer surprises.\n\nIf [`trio.run_process`](#trio.run_process \"trio.run_process\") is too limiting, we also offer a low-level API, [`trio.lowlevel.open_process`](reference-lowlevel#trio.lowlevel.open_process \"trio.lowlevel.open_process\"). For example, if you want to spawn a child process that will outlive the parent process and be orphaned, then [`run_process`](#trio.run_process \"trio.run_process\") can’t do that, but [`open_process`](reference-lowlevel#trio.lowlevel.open_process \"trio.lowlevel.open_process\") can.\n\n### Options for starting subprocesses\n\nAll of Trio’s subprocess APIs accept the numerous keyword arguments used by the standard [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess \"(in Python v3.11)\") module to control the environment in which a process starts and the mechanisms used for communicating with it. These may be passed wherever you see `**options` in the documentation below. See the [full list](https://docs.python.org/3/library/subprocess.html#popen-constructor) or just the [frequently used ones](https://docs.python.org/3/library/subprocess.html#frequently-used-arguments) in the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess \"(in Python v3.11)\") documentation. (You may need to `import`` ``subprocess` in order to access constants such as `PIPE` or `DEVNULL`.)\n\nCurrently, Trio always uses unbuffered byte streams for communicating with a process, so it does not support the `encoding`, `errors`, `universal_newlines` (alias `text`), and `bufsize` options.\n\n### Quoting: more than you wanted to know\n\nThe command to run and its arguments usually must be passed to Trio’s subprocess APIs as a sequence of strings, where the first element in the sequence specifies the command to run and the remaining elements specify its arguments, one argument per element. This form is used because it avoids potential quoting pitfalls; for example, you can run `[\"cp\",`` ``\"-f\",`` ``source_file,`` ``dest_file]` without worrying about whether `source_file` or `dest_file` contains spaces.\n\nIf you only run subprocesses without `shell=True` and on UNIX, that’s all you need to know about specifying the command. If you use `shell=True` or run on Windows, you probably should read the rest of this section to be aware of potential pitfalls.\n\nWith `shell=True` on UNIX, you must specify the command as a single string, which will be passed to the shell as if you’d entered it at an interactive prompt. The advantage of this option is that it lets you use shell features like pipes and redirection without writing code to handle them. For example, you can write `Process(\"ls`` ``|`` ``grep`` ``some_string\",`` ``shell=True)`. The disadvantage is that you must account for the shell’s quoting rules, generally by wrapping in [`shlex.quote()`](https://docs.python.org/3/library/shlex.html#shlex.quote \"(in Python v3.11)\") any argument that might contain spaces, quotes, or other shell metacharacters. If you don’t do that, your safe-looking `f\"ls`` ``|`` ``grep`` ``{some_string}\"` might end in disaster when invoked with `some_string`` ``=`` ``\"foo;`` ``rm`` ``-rf`` ``/\"`.\n\nOn Windows, the fundamental API for process spawning (the `CreateProcess()` system call) takes a string, not a list, and it’s actually up to the child process to decide how it wants to split that string into individual arguments. Since the C language specifies that `main()` should take a list of arguments, *most* programs you encounter will follow the rules used by the Microsoft C/C++ runtime. [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen \"(in Python v3.11)\"), and thus also Trio, uses these rules when it converts an argument sequence to a string, and they are [documented](https://docs.python.org/3/library/subprocess.html#converting-argument-sequence) alongside the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess \"(in Python v3.11)\") module. There is no documented Python standard library function that can directly perform that conversion, so even on Windows, you almost always want to pass an argument sequence rather than a string. But if the program you’re spawning doesn’t split its command line back into individual arguments in the standard way, you might need to pass a string to work around this. (Or you might just be out of luck: as far as I can tell, there’s simply no way to pass an argument containing a double-quote to a Windows batch file.)\n\nOn Windows with `shell=True`, things get even more chaotic. Now there are two separate sets of quoting rules applied, one by the Windows command shell `CMD.EXE` and one by the process being spawned, and they’re *different*. (And there’s no [`shlex.quote()`](https://docs.python.org/3/library/shlex.html#shlex.quote \"(in Python v3.11)\") to save you: it uses UNIX-style quoting rules, even on Windows.) Most special characters interpreted by the shell `&<>()^|` are not treated as special if the shell thinks they’re inside double quotes, but `%FOO%` environment variable substitutions still are, and the shell doesn’t provide any way to write a double quote inside a double-quoted string. Outside double quotes, any character (including a double quote) can be escaped using a leading `^`. But since a pipeline is processed by running each command in the pipeline in a subshell, multiple layers of escaping can be needed:\n\n``` python\necho ^^^&x | find \"x\" | find \"x\"          # prints: &x\n```\n\nAnd if you combine pipelines with () grouping, you can need even more levels of escaping:\n\n``` python\n(echo ^^^^^^^&x | find \"x\") | find \"x\"    # prints: &x\n```\n\nSince process creation takes a single arguments string, `CMD.EXE`'s quoting does not influence word splitting, and double quotes are not removed during CMD.EXE’s expansion pass. Double quotes are troublesome because CMD.EXE handles them differently from the MSVC runtime rules; in:\n\n``` python\nprog.exe \"foo \\\"bar\\\" baz\"\n```\n\nthe program will see one argument `foo`` ``\"bar\"`` ``baz` but CMD.EXE thinks `bar\\` is not quoted while `foo`` ``\\` and `baz` are. All of this makes it a formidable task to reliably interpolate anything into a `shell=True` command line on Windows, and Trio falls back on the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess \"(in Python v3.11)\") behavior: If you pass a sequence with `shell=True`, it’s quoted in the same way as a sequence with `shell=False`, and had better not contain any shell metacharacters you weren’t planning on.\n\nFurther reading:\n\n- [https://stackoverflow.com/questions/30620876/how-to-properly-escape-filenames-in-windows-cmd-exe](https://stackoverflow.com/questions/30620876/how-to-properly-escape-filenames-in-windows-cmd-exe)\n\n- [https://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts](https://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts)\n\n## Signals\n\n### *`with`*` trio.open_signal_receiver(*signals) as signal_aiter`\n\nA context manager for catching signals.\n\nEntering this context manager starts listening for the given signals and returns an async iterator; exiting the context manager stops listening.\n\nThe async iterator blocks until a signal arrives, and then yields it.\n\nNote that if you leave the `with` block while the iterator has unextracted signals still pending inside it, then they will be re-delivered using Python’s regular signal handling logic. This avoids a race condition when signals arrives just before we exit the `with` block.\n\n#### Parameters:\n\n**signals** – the signals to listen for.\n\n#### Raises:\n\n- [**TypeError**](https://docs.python.org/3/library/exceptions.html#TypeError \"(in Python v3.11)\") – if no signals were provided.\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if you try to use this anywhere except Python’s main thread. (This is a Python limitation.)\n\nExample\n\nA common convention for Unix daemons is that they should reload their configuration when they receive a `SIGHUP`. Here’s a sketch of what that might look like using [`open_signal_receiver()`](#trio.open_signal_receiver \"trio.open_signal_receiver\"):\n\n``` python\nwith trio.open_signal_receiver(signal.SIGHUP) as signal_aiter:\n    async for signum in signal_aiter:\n        assert signum == signal.SIGHUP\n        reload_configuration()\n```\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-io.html](https://trio.readthedocs.io/en/v0.22.2/reference-io.html)"
- name: Introspecting and extending Trio with trio.lowlevel
  id: reference-lowlevel
  summary: trio.lowlevel contains low-level APIs for introspecting and extending Trio
  description: "# Introspecting and extending Trio with `trio.lowlevel`\n\n[`trio.lowlevel`](#module-trio.lowlevel \"trio.lowlevel\") contains low-level APIs for introspecting and extending Trio. If you’re writing ordinary, everyday code, then you can ignore this module completely. But sometimes you need something a bit lower level. Here are some examples of situations where you should reach for [`trio.lowlevel`](#module-trio.lowlevel \"trio.lowlevel\"):\n\n- You want to implement a new [synchronization primitive](reference-core#synchronization) that Trio doesn’t (yet) provide, like a reader-writer lock.\n\n- You want to extract low-level metrics to monitor the health of your application.\n\n- You want to use a low-level operating system interface that Trio doesn’t (yet) provide its own wrappers for, like watching a filesystem directory for changes.\n\n- You want to implement an interface for calling between Trio and another event loop within the same process.\n\n- You’re writing a debugger and want to visualize Trio’s task tree.\n\n- You need to interoperate with a C library whose API exposes raw file descriptors.\n\nYou don’t need to be scared of [`trio.lowlevel`](#module-trio.lowlevel \"trio.lowlevel\"), as long as you take proper precautions. These are real public APIs, with strictly defined and carefully documented semantics. They’re the same tools we use to implement all the nice high-level APIs in the [`trio`](reference-core#module-trio \"trio\") namespace. But, be careful. Some of those strict semantics have [nasty big pointy teeth](https://en.wikipedia.org/wiki/Rabbit_of_Caerbannog). If you make a mistake, Trio may not be able to handle it gracefully; conventions and guarantees that are followed strictly in the rest of Trio do not always apply. When you use this module, it’s your job to think about how you’re going to handle the tricky cases so you can expose a friendly Trio-style API to your users.\n\n## Debugging and instrumentation\n\nTrio tries hard to provide useful hooks for debugging and instrumentation. Some are documented above (the nursery introspection attributes, [`trio.Lock.statistics()`](reference-core#trio.Lock.statistics \"trio.Lock.statistics\"), etc.). Here are some more.\n\n### Global statistics\n\n### `trio.lowlevel.current_statistics()`\n\nReturns an object containing run-loop-level debugging information.\n\nCurrently the following fields are defined:\n\n- `tasks_living` (int): The number of tasks that have been spawned and not yet exited.\n\n- `tasks_runnable` (int): The number of tasks that are currently queued on the run queue (as opposed to blocked waiting for something to happen).\n\n- `seconds_to_next_deadline` (float): The time until the next pending cancel scope deadline. May be negative if the deadline has expired but we haven’t yet processed cancellations. May be [`inf`](https://docs.python.org/3/library/math.html#math.inf \"(in Python v3.11)\") if there are no pending deadlines.\n\n- `run_sync_soon_queue_size` (int): The number of unprocessed callbacks queued via [`trio.lowlevel.TrioToken.run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon \"trio.lowlevel.TrioToken.run_sync_soon\").\n\n- `io_statistics` (object): Some statistics from Trio’s I/O backend. This always has an attribute `backend` which is a string naming which operating-system-specific I/O backend is in use; the other attributes vary between backends.\n\n### The current clock\n\n### `trio.lowlevel.current_clock()`\n\nReturns the current [`Clock`](reference-core#trio.abc.Clock \"trio.abc.Clock\").\n\n### Instrument API\n\nThe instrument API provides a standard way to add custom instrumentation to the run loop. Want to make a histogram of scheduling latencies, log a stack trace of any task that blocks the run loop for \\>50 ms, or measure what percentage of your process’s running time is spent waiting for I/O? This is the place.\n\nThe general idea is that at any given moment, [`trio.run()`](reference-core#trio.run \"trio.run\") maintains a set of “instruments”, which are objects that implement the [`trio.abc.Instrument`](#trio.abc.Instrument \"trio.abc.Instrument\") interface. When an interesting event happens, it loops over these instruments and notifies them by calling an appropriate method. The tutorial has [a simple example of using this for tracing](https://trio.readthedocs.io/en/v0.22.2/tutorial.html#tutorial-instrument-example).\n\nSince this hooks into Trio at a rather low level, you do have to be careful. The callbacks are run synchronously, and in many cases if they error out then there isn’t any plausible way to propagate this exception (for instance, we might be deep in the guts of the exception propagation machinery…). Therefore our [current strategy](https://github.com/python-trio/trio/issues/47) for handling exceptions raised by instruments is to (a) log an exception to the `\"trio.abc.Instrument\"` logger, which by default prints a stack trace to standard error and (b) disable the offending instrument.\n\nYou can register an initial list of instruments by passing them to [`trio.run()`](reference-core#trio.run \"trio.run\"). [`add_instrument()`](#trio.lowlevel.add_instrument \"trio.lowlevel.add_instrument\") and [`remove_instrument()`](#trio.lowlevel.remove_instrument \"trio.lowlevel.remove_instrument\") let you add and remove instruments at runtime.\n\n### `trio.lowlevel.add_instrument(instrument: Instrument) → None`\n\nStart instrumenting the current run loop with the given instrument.\n\n#### Parameters:\n\n**instrument** ([*trio.abc.Instrument*](#trio.abc.Instrument \"trio.abc.Instrument\")) – The instrument to activate.\n\nIf `instrument` is already active, does nothing.\n\n### `trio.lowlevel.remove_instrument(instrument: Instrument) → None`\n\nStop instrumenting the current run loop with the given instrument.\n\n#### Parameters:\n\n**instrument** ([*trio.abc.Instrument*](#trio.abc.Instrument \"trio.abc.Instrument\")) – The instrument to de-activate.\n\n#### Raises:\n\n[**KeyError**](https://docs.python.org/3/library/exceptions.html#KeyError \"(in Python v3.11)\") – if the instrument is not currently active. This could occur either because you never added it, or because you added it and then it raised an unhandled exception and was automatically deactivated.\n\nAnd here’s the interface to implement if you want to build your own [`Instrument`](#trio.abc.Instrument \"trio.abc.Instrument\"):\n\n### *`class`*` trio.abc.Instrument`\n\nThe interface for run loop instrumentation.\n\nInstruments don’t have to inherit from this abstract base class, and all of these methods are optional. This class serves mostly as documentation.\n\n### `after_io_wait(timeout)`\n\nCalled after handling pending I/O.\n\n#### Parameters:\n\n**timeout** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The number of seconds we were willing to wait. This much time may or may not have elapsed, depending on whether any I/O was ready.\n\n### `after_run()`\n\nCalled just before [`trio.run()`](reference-core#trio.run \"trio.run\") returns.\n\n### `after_task_step(task)`\n\nCalled when we return to the main run loop after a task has yielded.\n\n#### Parameters:\n\n**task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The task that just ran.\n\n### `before_io_wait(timeout)`\n\nCalled before blocking to wait for I/O readiness.\n\n#### Parameters:\n\n**timeout** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The number of seconds we are willing to wait.\n\n### `before_run()`\n\nCalled at the beginning of [`trio.run()`](reference-core#trio.run \"trio.run\").\n\n### `before_task_step(task)`\n\nCalled immediately before we resume running the given task.\n\n#### Parameters:\n\n**task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The task that is about to run.\n\n### `task_exited(task)`\n\nCalled when the given task exits.\n\n#### Parameters:\n\n**task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The finished task.\n\n### `task_scheduled(task)`\n\nCalled when the given task becomes runnable.\n\nIt may still be some time before it actually runs, if there are other runnable tasks ahead of it.\n\n#### Parameters:\n\n**task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The task that became runnable.\n\n### `task_spawned(task)`\n\nCalled when the given task is created.\n\n#### Parameters:\n\n**task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The new task.\n\nThe tutorial has a [fully-worked example](https://trio.readthedocs.io/en/v0.22.2/tutorial.html#tutorial-instrument-example) of defining a custom instrument to log Trio’s internal scheduling decisions.\n\n## Low-level process spawning\n\n### *`await`*` trio.lowlevel.open_process(command, *, stdin=None, stdout=None, stderr=None, **options) → Process`\n\nExecute a child program in a new process.\n\nAfter construction, you can interact with the child process by writing data to its [`stdin`](reference-io#trio.Process.stdin \"trio.Process.stdin\") stream (a [`SendStream`](reference-io#trio.abc.SendStream \"trio.abc.SendStream\")), reading data from its [`stdout`](reference-io#trio.Process.stdout \"trio.Process.stdout\") and/or [`stderr`](reference-io#trio.Process.stderr \"trio.Process.stderr\") streams (both [`ReceiveStream`](reference-io#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")s), sending it signals using [`terminate`](reference-io#trio.Process.terminate \"trio.Process.terminate\"), [`kill`](reference-io#trio.Process.kill \"trio.Process.kill\"), or [`send_signal`](reference-io#trio.Process.send_signal \"trio.Process.send_signal\"), and waiting for it to exit using [`wait`](reference-io#trio.Process.wait \"trio.Process.wait\"). See [`trio.Process`](reference-io#trio.Process \"trio.Process\") for details.\n\nEach standard stream is only available if you specify that a pipe should be created for it. For example, if you pass `stdin=subprocess.PIPE`, you can write to the [`stdin`](reference-io#trio.Process.stdin \"trio.Process.stdin\") stream, else [`stdin`](reference-io#trio.Process.stdin \"trio.Process.stdin\") will be `None`.\n\nUnlike [`trio.run_process`](reference-io#trio.run_process \"trio.run_process\"), this function doesn’t do any kind of automatic management of the child process. It’s up to you to implement whatever semantics you want.\n\n#### Parameters:\n\n- **command** ([*list*](https://docs.python.org/3/library/stdtypes.html#list \"(in Python v3.11)\") *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")) – The command to run. Typically this is a sequence of strings such as `['ls',`` ``'-l',`` ``'directory`` ``with`` ``spaces']`, where the first element names the executable to invoke and the other elements specify its arguments. With `shell=True` in the `**options`, or on Windows, `command` may alternatively be a string, which will be parsed following platform-dependent [quoting rules](reference-io#subprocess-quoting).\n\n- **stdin** – Specifies what the child process’s standard input stream should connect to: output written by the parent (`subprocess.PIPE`), nothing (`subprocess.DEVNULL`), or an open file (pass a file descriptor or something whose `fileno` method returns one). If `stdin` is unspecified, the child process will have the same standard input stream as its parent.\n\n- **stdout** – Like `stdin`, but for the child process’s standard output stream.\n\n- **stderr** – Like `stdin`, but for the child process’s standard error stream. An additional value `subprocess.STDOUT` is supported, which causes the child’s standard output and standard error messages to be intermixed on a single standard output stream, attached to whatever the `stdout` option says to attach it to.\n\n- **\\*\\*options** – Other [general subprocess options](reference-io#subprocess-options) are also accepted.\n\n#### Returns:\n\nA new [`trio.Process`](reference-io#trio.Process \"trio.Process\") object.\n\n#### Raises:\n\n[**OSError**](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") – if the process spawning fails, for example because the specified command could not be found.\n\n## Low-level I/O primitives\n\nDifferent environments expose different low-level APIs for performing async I/O. [`trio.lowlevel`](#module-trio.lowlevel \"trio.lowlevel\") exposes these APIs in a relatively direct way, so as to allow maximum power and flexibility for higher level code. However, this means that the exact API provided may vary depending on what system Trio is running on.\n\n### Universally available API\n\nAll environments provide the following functions:\n\n### *`await`*` trio.lowlevel.wait_readable(obj)`\n\nBlock until the kernel reports that the given object is readable.\n\nOn Unix systems, `obj` must either be an integer file descriptor, or else an object with a `.fileno()` method which returns an integer file descriptor. Any kind of file descriptor can be passed, though the exact semantics will depend on your kernel. For example, this probably won’t do anything useful for on-disk files.\n\nOn Windows systems, `obj` must either be an integer `SOCKET` handle, or else an object with a `.fileno()` method which returns an integer `SOCKET` handle. File descriptors aren’t supported, and neither are handles that refer to anything besides a `SOCKET`.\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if another task is already waiting for the given socket to become readable.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if another task calls [`notify_closing()`](#trio.lowlevel.notify_closing \"trio.lowlevel.notify_closing\") while this function is still working.\n\n### *`await`*` trio.lowlevel.wait_writable(obj)`\n\nBlock until the kernel reports that the given object is writable.\n\nSee [`wait_readable`](#trio.lowlevel.wait_readable \"trio.lowlevel.wait_readable\") for the definition of `obj`.\n\n#### Raises:\n\n- [**trio.BusyResourceError**](reference-core#trio.BusyResourceError \"trio.BusyResourceError\") – if another task is already waiting for the given socket to become writable.\n\n- [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\") – if another task calls [`notify_closing()`](#trio.lowlevel.notify_closing \"trio.lowlevel.notify_closing\") while this function is still working.\n\n### `trio.lowlevel.notify_closing(obj)`\n\nCall this before closing a file descriptor (on Unix) or socket (on Windows). This will cause any [`wait_readable`](#trio.lowlevel.wait_readable \"trio.lowlevel.wait_readable\") or [`wait_writable`](#trio.lowlevel.wait_writable \"trio.lowlevel.wait_writable\") calls on the given object to immediately wake up and raise [`ClosedResourceError`](reference-core#trio.ClosedResourceError \"trio.ClosedResourceError\").\n\nThis doesn’t actually close the object – you still have to do that yourself afterwards. Also, you want to be careful to make sure no new tasks start waiting on the object in between when you call this and when it’s actually closed. So to close something properly, you usually want to do these steps in order:\n\n1.  Explicitly mark the object as closed, so that any new attempts to use it will abort before they start.\n\n2.  Call [`notify_closing`](#trio.lowlevel.notify_closing \"trio.lowlevel.notify_closing\") to wake up any already-existing users.\n\n3.  Actually close the object.\n\nIt’s also possible to do them in a different order if that’s more convenient, *but only if* you make sure not to have any checkpoints in between the steps. This way they all happen in a single atomic step, so other tasks won’t be able to tell what order they happened in anyway.\n\n### Unix-specific API\n\n[`FdStream`](#trio.lowlevel.FdStream \"trio.lowlevel.FdStream\") supports wrapping Unix files (such as a pipe or TTY) as a stream.\n\nIf you have two different file descriptors for sending and receiving, and want to bundle them together into a single bidirectional [`Stream`](reference-io#trio.abc.Stream \"trio.abc.Stream\"), then use [`trio.StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\"):\n\n``` python\nbidirectional_stream = trio.StapledStream(\n    trio.lowlevel.FdStream(write_fd),\n    trio.lowlevel.FdStream(read_fd)\n)\n```\n\n### *`class`*` trio.lowlevel.FdStream(fd: int)`\n\nBases: [`Stream`](reference-io#trio.abc.Stream \"trio.abc.Stream\")\n\nRepresents a stream given the file descriptor to a pipe, TTY, etc.\n\n*fd* must refer to a file that is open for reading and/or writing and supports non-blocking I/O (pipes and TTYs will work, on-disk files probably not). The returned stream takes ownership of the fd, so closing the stream will close the fd too. As with [`os.fdopen`](https://docs.python.org/3/library/os.html#os.fdopen \"(in Python v3.11)\"), you should not directly use an fd after you have wrapped it in a stream using this function.\n\nTo be used as a Trio stream, an open file must be placed in non-blocking mode. Unfortunately, this impacts all I/O that goes through the underlying open file, including I/O that uses a different file descriptor than the one that was passed to Trio. If other threads or processes are using file descriptors that are related through [`os.dup`](https://docs.python.org/3/library/os.html#os.dup \"(in Python v3.11)\") or inheritance across [`os.fork`](https://docs.python.org/3/library/os.html#os.fork \"(in Python v3.11)\") to the one that Trio is using, they are unlikely to be prepared to have non-blocking I/O semantics suddenly thrust upon them. For example, you can use `FdStream(os.dup(sys.stdin.fileno()))` to obtain a stream for reading from standard input, but it is only safe to do so with heavy caveats: your stdin must not be shared by any other processes, and you must not make any calls to synchronous methods of [`sys.stdin`](https://docs.python.org/3/library/sys.html#sys.stdin \"(in Python v3.11)\") until the stream returned by [`FdStream`](#trio.lowlevel.FdStream \"trio.lowlevel.FdStream\") is closed. See [issue \\#174](https://github.com/python-trio/trio/issues/174) for a discussion of the challenges involved in relaxing this restriction.\n\n#### Parameters:\n\n**fd** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The fd to be wrapped.\n\n#### Returns:\n\nA new [`FdStream`](#trio.lowlevel.FdStream \"trio.lowlevel.FdStream\") object.\n\n### Kqueue-specific API\n\nTODO: these are implemented, but are currently more of a sketch than anything real. See [\\#26](https://github.com/python-trio/trio/issues/26).\n\n### `trio.lowlevel.current_kqueue()`\n\n### *`await`*` trio.lowlevel.wait_kevent(ident, filter, abort_func)`\n\n### *`with`*` trio.lowlevel.monitor_kevent(ident, filter) as queue`\n\n### Windows-specific API\n\n### *`await`*` trio.lowlevel.WaitForSingleObject(handle)`\n\nAsync and cancellable variant of [WaitForSingleObject](https://msdn.microsoft.com/en-us/library/windows/desktop/ms687032(v=vs.85).aspx). Windows only.\n\n#### Parameters:\n\n**handle** – A Win32 object handle, as a Python integer.\n\n#### Raises:\n\n[**OSError**](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") – If the handle is invalid, e.g. when it is already closed.\n\nTODO: these are implemented, but are currently more of a sketch than anything real. See [\\#26](https://github.com/python-trio/trio/issues/26) and [\\#52](https://github.com/python-trio/trio/issues/52).\n\n### `trio.lowlevel.register_with_iocp(handle)`\n\n### *`await`*` trio.lowlevel.wait_overlapped(handle, lpOverlapped)`\n\n### `trio.lowlevel.current_iocp()`\n\n### *`with`*` trio.lowlevel.monitor_completion_key() as queue`\n\n## Global state: system tasks and run-local variables\n\n### *`class`*` trio.lowlevel.RunVar(name, default=`\n\nThe run-local variant of a context variable.\n\n[`RunVar`](#trio.lowlevel.RunVar \"trio.lowlevel.RunVar\") objects are similar to context variable objects, except that they are shared across a single call to [`trio.run()`](reference-core#trio.run \"trio.run\") rather than a single task.\n\n### `trio.lowlevel.spawn_system_task(async_fn, *args, name=None, context=None)`\n\nSpawn a “system” task.\n\nSystem tasks have a few differences from regular tasks:\n\n- They don’t need an explicit nursery; instead they go into the internal “system nursery”.\n\n- If a system task raises an exception, then it’s converted into a [`TrioInternalError`](reference-core#trio.TrioInternalError \"trio.TrioInternalError\") and *all* tasks are cancelled. If you write a system task, you should be careful to make sure it doesn’t crash.\n\n- System tasks are automatically cancelled when the main task exits.\n\n- By default, system tasks have [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") protection *enabled*. If you want your task to be interruptible by control-C, then you need to use [`disable_ki_protection()`](#trio.lowlevel.disable_ki_protection \"trio.lowlevel.disable_ki_protection\") explicitly (and come up with some plan for what to do with a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\"), given that system tasks aren’t allowed to raise exceptions).\n\n- System tasks do not inherit context variables from their creator.\n\nTowards the end of a call to [`trio.run()`](reference-core#trio.run \"trio.run\"), after the main task and all system tasks have exited, the system nursery becomes closed. At this point, new calls to [`spawn_system_task()`](#trio.lowlevel.spawn_system_task \"trio.lowlevel.spawn_system_task\") will raise `RuntimeError(\"Nursery`` ``is`` ``closed`` ``to`` ``new`` ``arrivals\")` instead of creating a system task. It’s possible to encounter this state either in a `finally` block in an async generator, or in a callback passed to [`TrioToken.run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon \"trio.lowlevel.TrioToken.run_sync_soon\") at the right moment.\n\n#### Parameters:\n\n- **async_fn** – An async callable.\n\n- **args** – Positional arguments for `async_fn`. If you want to pass keyword arguments, use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial \"(in Python v3.11)\").\n\n- **name** – The name for this task. Only used for debugging/introspection (e.g. `repr(task_obj)`). If this isn’t a string, [`spawn_system_task()`](#trio.lowlevel.spawn_system_task \"trio.lowlevel.spawn_system_task\") will try to make it one. A common use case is if you’re wrapping a function before spawning a new task, you might pass the original function as the `name=` to make debugging easier.\n\n- **context** – An optional `contextvars.Context` object with context variables to use for this task. You would normally get a copy of the current context with `context`` ``=`` ``contextvars.copy_context()` and then you would pass that `context` object here.\n\n#### Returns:\n\nthe newly spawned task\n\n#### Return type:\n\n[Task](#trio.lowlevel.Task \"trio.lowlevel.Task\")\n\n## Trio tokens\n\n### *`class`*` trio.lowlevel.TrioToken`\n\nAn opaque object representing a single call to [`trio.run()`](reference-core#trio.run \"trio.run\").\n\nIt has no public constructor; instead, see [`current_trio_token()`](#trio.lowlevel.current_trio_token \"trio.lowlevel.current_trio_token\").\n\nThis object has two uses:\n\n1.  It lets you re-enter the Trio run loop from external threads or signal handlers. This is the low-level primitive that [`trio.to_thread()`](reference-core#module-trio.to_thread \"trio.to_thread\") and [`trio.from_thread`](reference-core#module-trio.from_thread \"trio.from_thread\") use to communicate with worker threads, that [`trio.open_signal_receiver`](reference-io#trio.open_signal_receiver \"trio.open_signal_receiver\") uses to receive notifications about signals, and so forth.\n\n2.  Each call to [`trio.run()`](reference-core#trio.run \"trio.run\") has exactly one associated [`TrioToken`](#trio.lowlevel.TrioToken \"trio.lowlevel.TrioToken\") object, so you can use it to identify a particular call.\n\n### `run_sync_soon(sync_fn, *args, idempotent=False)`\n\nSchedule a call to `sync_fn(*args)` to occur in the context of a Trio task.\n\nThis is safe to call from the main thread, from other threads, and from signal handlers. This is the fundamental primitive used to re-enter the Trio run loop from outside of it.\n\nThe call will happen “soon”, but there’s no guarantee about exactly when, and no mechanism provided for finding out when it’s happened. If you need this, you’ll have to build your own.\n\nThe call is effectively run as part of a system task (see [`spawn_system_task()`](#trio.lowlevel.spawn_system_task \"trio.lowlevel.spawn_system_task\")). In particular this means that:\n\n- [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") protection is *enabled* by default; if you want `sync_fn` to be interruptible by control-C, then you need to use [`disable_ki_protection()`](#trio.lowlevel.disable_ki_protection \"trio.lowlevel.disable_ki_protection\") explicitly.\n\n- If `sync_fn` raises an exception, then it’s converted into a [`TrioInternalError`](reference-core#trio.TrioInternalError \"trio.TrioInternalError\") and *all* tasks are cancelled. You should be careful that `sync_fn` doesn’t crash.\n\nAll calls with `idempotent=False` are processed in strict first-in first-out order.\n\nIf `idempotent=True`, then `sync_fn` and `args` must be hashable, and Trio will make a best-effort attempt to discard any call submission which is equal to an already-pending call. Trio will process these in first-in first-out order.\n\nAny ordering guarantees apply separately to `idempotent=False` and `idempotent=True` calls; there’s no rule for how calls in the different categories are ordered with respect to each other.\n\n#### Raises:\n\n[**trio.RunFinishedError**](reference-core#trio.RunFinishedError \"trio.RunFinishedError\") – if the associated call to [`trio.run()`](reference-core#trio.run \"trio.run\") has already exited. (Any call that *doesn’t* raise this error is guaranteed to be fully processed before [`trio.run()`](reference-core#trio.run \"trio.run\") exits.)\n\n### `trio.lowlevel.current_trio_token()`\n\nRetrieve the [`TrioToken`](#trio.lowlevel.TrioToken \"trio.lowlevel.TrioToken\") for the current call to [`trio.run()`](reference-core#trio.run \"trio.run\").\n\n## Spawning threads\n\n### `trio.lowlevel.start_thread_soon(fn, deliver, name: str | None = None)`\n\nRuns `deliver(outcome.capture(fn))` in a worker thread.\n\nGenerally `fn` does some blocking work, and `deliver` delivers the result back to whoever is interested.\n\nThis is a low-level, no-frills interface, very similar to using [`threading.Thread`](https://docs.python.org/3/library/threading.html#threading.Thread \"(in Python v3.11)\") to spawn a thread directly. The main difference is that this function tries to re-use threads when possible, so it can be a bit faster than [`threading.Thread`](https://docs.python.org/3/library/threading.html#threading.Thread \"(in Python v3.11)\").\n\nWorker threads have the [`daemon`](https://docs.python.org/3/library/threading.html#threading.Thread.daemon \"(in Python v3.11)\") flag set, which means that if your main thread exits, worker threads will automatically be killed. If you want to make sure that your `fn` runs to completion, then you should make sure that the main thread remains alive until `deliver` is called.\n\nIt is safe to call this function simultaneously from multiple threads.\n\n#### Parameters:\n\n- **fn** (*sync function*) – Performs arbitrary blocking work.\n\n- **deliver** (*sync function*) – Takes the [`outcome.Outcome`](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome \"(in outcome v1.2.0+dev)\") of `fn`, and delivers it. *Must not block.*\n\nBecause worker threads are cached and reused for multiple calls, neither function should mutate thread-level state, like [`threading.local`](https://docs.python.org/3/library/threading.html#threading.local \"(in Python v3.11)\") objects – or if they do, they should be careful to revert their changes before returning.\n\n> #### Note\n>\n> The split between `fn` and `deliver` serves two purposes. First, it’s convenient, since most callers need something like this anyway.\n>\n> Second, it avoids a small race condition that could cause too many threads to be spawned. Consider a program that wants to run several jobs sequentially on a thread, so the main thread submits a job, waits for it to finish, submits another job, etc. In theory, this program should only need one worker thread. But what could happen is:\n>\n> 1.  Worker thread: First job finishes, and calls `deliver`.\n>\n> 2.  Main thread: receives notification that the job finished, and calls `start_thread_soon`.\n>\n> 3.  Main thread: sees that no worker threads are marked idle, so spawns a second worker thread.\n>\n> 4.  Original worker thread: marks itself as idle.\n>\n> To avoid this, threads mark themselves as idle *before* calling `deliver`.\n>\n> Is this potential extra thread a major problem? Maybe not, but it’s easy enough to avoid, and we figure that if the user is trying to limit how many threads they’re using then it’s polite to respect that.\n\n## Safer KeyboardInterrupt handling\n\nTrio’s handling of control-C is designed to balance usability and safety. On the one hand, there are sensitive regions (like the core scheduling loop) where it’s simply impossible to handle arbitrary [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") exceptions while maintaining our core correctness invariants. On the other, if the user accidentally writes an infinite loop, we do want to be able to break out of that. Our solution is to install a default signal handler which checks whether it’s safe to raise [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") at the place where the signal is received. If so, then we do; otherwise, we schedule a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") to be delivered to the main task at the next available opportunity (similar to how [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\") is delivered).\n\nSo that’s great, but – how do we know whether we’re in one of the sensitive parts of the program or not?\n\nThis is determined on a function-by-function basis. By default:\n\n- The top-level function in regular user tasks is unprotected.\n\n- The top-level function in system tasks is protected.\n\n- If a function doesn’t specify otherwise, then it inherits the protection state of its caller.\n\nThis means you only need to override the defaults at places where you transition from protected code to unprotected code or vice-versa.\n\nThese transitions are accomplished using two function decorators:\n\n### `@trio.lowlevel.disable_ki_protection`\n\nDecorator that marks the given regular function, generator function, async function, or async generator function as unprotected against [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\"), i.e., the code inside this function *can* be rudely interrupted by [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") at any moment.\n\nIf you have multiple decorators on the same function, then this should be at the bottom of the stack (closest to the actual function).\n\nAn example of where you’d use this is in implementing something like [`trio.from_thread.run()`](reference-core#trio.from_thread.run \"trio.from_thread.run\"), which uses [`TrioToken.run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon \"trio.lowlevel.TrioToken.run_sync_soon\") to get into the Trio thread. [`run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon \"trio.lowlevel.TrioToken.run_sync_soon\") callbacks are run with [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") protection enabled, and [`trio.from_thread.run()`](reference-core#trio.from_thread.run \"trio.from_thread.run\") takes advantage of this to safely set up the machinery for sending a response back to the original thread, but then uses [`disable_ki_protection()`](#trio.lowlevel.disable_ki_protection \"trio.lowlevel.disable_ki_protection\") when entering the user-provided function.\n\n### `@trio.lowlevel.enable_ki_protection`\n\nDecorator that marks the given regular function, generator function, async function, or async generator function as protected against [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\"), i.e., the code inside this function *won’t* be rudely interrupted by [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\"). (Though if it contains any [checkpoints](reference-core#checkpoints), then it can still receive [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") at those. This is considered a polite interruption.)\n\n> #### Warning\n>\n> Be very careful to only use this decorator on functions that you know will either exit in bounded time, or else pass through a checkpoint regularly. (Of course all of your functions should have this property, but if you mess it up here then you won’t even be able to use control-C to escape!)\n\nIf you have multiple decorators on the same function, then this should be at the bottom of the stack (closest to the actual function).\n\nAn example of where you’d use this is on the `__exit__` implementation for something like a [`Lock`](reference-core#trio.Lock \"trio.Lock\"), where a poorly-timed [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") could leave the lock in an inconsistent state and cause a deadlock.\n\n### `trio.lowlevel.currently_ki_protected()`\n\nCheck whether the calling code has [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") protection enabled.\n\nIt’s surprisingly easy to think that one’s [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") protection is enabled when it isn’t, or vice-versa. This function tells you what Trio thinks of the matter, which makes it useful for `assert`s and unit tests.\n\n#### Returns:\n\nTrue if protection is enabled, and False otherwise.\n\n#### Return type:\n\n[bool](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")\n\n## Sleeping and waking\n\n### Wait queue abstraction\n\n### *`class`*` trio.lowlevel.ParkingLot`\n\nA fair wait queue with cancellation and requeueing.\n\nThis class encapsulates the tricky parts of implementing a wait queue. It’s useful for implementing higher-level synchronization primitives like queues and locks.\n\nIn addition to the methods below, you can use `len(parking_lot)` to get the number of parked tasks, and `if`` ``parking_lot:`` ``...` to check whether there are any parked tasks.\n\n### *`await`*` park()`\n\nPark the current task until woken by a call to [`unpark()`](#trio.lowlevel.ParkingLot.unpark \"trio.lowlevel.ParkingLot.unpark\") or [`unpark_all()`](#trio.lowlevel.ParkingLot.unpark_all \"trio.lowlevel.ParkingLot.unpark_all\").\n\n### `repark(new_lot, *, count=1)`\n\nMove parked tasks from one [`ParkingLot`](#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\") object to another.\n\nThis dequeues `count` tasks from one lot, and requeues them on another, preserving order. For example:\n\n``` python\nasync def parker(lot):\n    print(\"sleeping\")\n    await lot.park()\n    print(\"woken\")\n\nasync def main():\n    lot1 = trio.lowlevel.ParkingLot()\n    lot2 = trio.lowlevel.ParkingLot()\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(parker, lot1)\n        await trio.testing.wait_all_tasks_blocked()\n        assert len(lot1) == 1\n        assert len(lot2) == 0\n        lot1.repark(lot2)\n        assert len(lot1) == 0\n        assert len(lot2) == 1\n        # This wakes up the task that was originally parked in lot1\n        lot2.unpark()\n```\n\nIf there are fewer than `count` tasks parked, then reparks as many tasks as are available and then returns successfully.\n\n#### Parameters:\n\n- **new_lot** ([*ParkingLot*](#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\")) – the parking lot to move tasks to.\n\n- **count** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – the number of tasks to move.\n\n### `repark_all(new_lot)`\n\nMove all parked tasks from one [`ParkingLot`](#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\") object to another.\n\nSee [`repark()`](#trio.lowlevel.ParkingLot.repark \"trio.lowlevel.ParkingLot.repark\") for details.\n\n### `statistics()`\n\nReturn an object containing debugging information.\n\nCurrently the following fields are defined:\n\n- `tasks_waiting`: The number of tasks blocked on this lot’s [`park()`](#trio.lowlevel.ParkingLot.park \"trio.lowlevel.ParkingLot.park\") method.\n\n### `unpark(*, count=1)`\n\nUnpark one or more tasks.\n\nThis wakes up `count` tasks that are blocked in [`park()`](#trio.lowlevel.ParkingLot.park \"trio.lowlevel.ParkingLot.park\"). If there are fewer than `count` tasks parked, then wakes as many tasks are available and then returns successfully.\n\n#### Parameters:\n\n**count** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – the number of tasks to unpark.\n\n### `unpark_all()`\n\nUnpark all parked tasks.\n\n### Low-level checkpoint functions\n\n### *`await`*` trio.lowlevel.checkpoint()`\n\nA pure [checkpoint](reference-core#checkpoints).\n\nThis checks for cancellation and allows other tasks to be scheduled, without otherwise blocking.\n\nNote that the scheduler has the option of ignoring this and continuing to run the current task if it decides this is appropriate (e.g. for increased efficiency).\n\nEquivalent to `await`` ``trio.sleep(0)` (which is implemented by calling [`checkpoint()`](#trio.lowlevel.checkpoint \"trio.lowlevel.checkpoint\").)\n\nThe next two functions are used *together* to make up a checkpoint:\n\n### *`await`*` trio.lowlevel.checkpoint_if_cancelled()`\n\nIssue a [checkpoint](reference-core#checkpoints) if the calling context has been cancelled.\n\nEquivalent to (but potentially more efficient than):\n\n``` python\nif trio.current_effective_deadline() == -inf:\n    await trio.lowlevel.checkpoint()\n```\n\nThis is either a no-op, or else it allow other tasks to be scheduled and then raises [`trio.Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\").\n\nTypically used together with [`cancel_shielded_checkpoint()`](#trio.lowlevel.cancel_shielded_checkpoint \"trio.lowlevel.cancel_shielded_checkpoint\").\n\n### *`await`*` trio.lowlevel.cancel_shielded_checkpoint()`\n\nIntroduce a schedule point, but not a cancel point.\n\nThis is *not* a [checkpoint](reference-core#checkpoints), but it is half of a checkpoint, and when combined with [`checkpoint_if_cancelled()`](#trio.lowlevel.checkpoint_if_cancelled \"trio.lowlevel.checkpoint_if_cancelled\") it can make a full checkpoint.\n\nEquivalent to (but potentially more efficient than):\n\n``` python\nwith trio.CancelScope(shield=True):\n    await trio.lowlevel.checkpoint()\n```\n\nThese are commonly used in cases where you have an operation that might-or-might-not block, and you want to implement Trio’s standard checkpoint semantics. Example:\n\n``` python\nasync def operation_that_maybe_blocks():\n    await checkpoint_if_cancelled()\n    try:\n        ret = attempt_operation()\n    except BlockingIOError:\n        # need to block and then retry, which we do below\n        pass\n    else:\n        # operation succeeded, finish the checkpoint then return\n        await cancel_shielded_checkpoint()\n        return ret\n    while True:\n        await wait_for_operation_to_be_ready()\n        try:\n            return attempt_operation()\n        except BlockingIOError:\n            pass\n```\n\nThis logic is a bit convoluted, but accomplishes all of the following:\n\n- Every successful execution path passes through a checkpoint (assuming that `wait_for_operation_to_be_ready` is an unconditional checkpoint)\n\n- Our [cancellation semantics](reference-core#cancellable-primitives) say that [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\") should only be raised if the operation didn’t happen. Using [`cancel_shielded_checkpoint()`](#trio.lowlevel.cancel_shielded_checkpoint \"trio.lowlevel.cancel_shielded_checkpoint\") on the early-exit branch accomplishes this.\n\n- On the path where we do end up blocking, we don’t pass through any schedule points before that, which avoids some unnecessary work.\n\n- Avoids implicitly chaining the [`BlockingIOError`](https://docs.python.org/3/library/exceptions.html#BlockingIOError \"(in Python v3.11)\") with any errors raised by `attempt_operation` or `wait_for_operation_to_be_ready`, by keeping the `while`` ``True:` loop outside of the `except`` ``BlockingIOError:` block.\n\nThese functions can also be useful in other situations. For example, when [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync \"trio.to_thread.run_sync\") schedules some work to run in a worker thread, it blocks until the work is finished (so it’s a schedule point), but by default it doesn’t allow cancellation. So to make sure that the call always acts as a checkpoint, it calls [`checkpoint_if_cancelled()`](#trio.lowlevel.checkpoint_if_cancelled \"trio.lowlevel.checkpoint_if_cancelled\") before starting the thread.\n\n### Low-level blocking\n\n### *`await`*` trio.lowlevel.wait_task_rescheduled(abort_func: Callable[[Callable[[], NoReturn]], Abort]) → Any`\n\nPut the current task to sleep, with cancellation support.\n\nThis is the lowest-level API for blocking in Trio. Every time a [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") blocks, it does so by calling this function (usually indirectly via some higher-level API).\n\nThis is a tricky interface with no guard rails. If you can use [`ParkingLot`](#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\") or the built-in I/O wait functions instead, then you should.\n\nGenerally the way it works is that before calling this function, you make arrangements for “someone” to call [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\") on the current task at some later point.\n\nThen you call [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\"), passing in `abort_func`, an “abort callback”.\n\n(Terminology: in Trio, “aborting” is the process of attempting to interrupt a blocked task to deliver a cancellation.)\n\nThere are two possibilities for what happens next:\n\n1.  “Someone” calls [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\") on the current task, and [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\") returns or raises whatever value or error was passed to [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\").\n\n2.  The call’s context transitions to a cancelled state (e.g. due to a timeout expiring). When this happens, the `abort_func` is called. Its interface looks like:\n\n    ``` python\n    def abort_func(raise_cancel):\n        ...\n        return trio.lowlevel.Abort.SUCCEEDED  # or FAILED\n    ```\n\n    It should attempt to clean up any state associated with this call, and in particular, arrange that [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\") will *not* be called later. If (and only if!) it is successful, then it should return [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED \"trio.lowlevel.Abort.SUCCEEDED\"), in which case the task will automatically be rescheduled with an appropriate [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\") error.\n\n    Otherwise, it should return [`Abort.FAILED`](#trio.lowlevel.Abort.FAILED \"trio.lowlevel.Abort.FAILED\"). This means that the task can’t be cancelled at this time, and still has to make sure that “someone” eventually calls [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\").\n\n    At that point there are again two possibilities. You can simply ignore the cancellation altogether: wait for the operation to complete and then reschedule and continue as normal. (For example, this is what [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync \"trio.to_thread.run_sync\") does if cancellation is disabled.) The other possibility is that the `abort_func` does succeed in cancelling the operation, but for some reason isn’t able to report that right away. (Example: on Windows, it’s possible to request that an async (“overlapped”) I/O operation be cancelled, but this request is *also* asynchronous – you don’t find out until later whether the operation was actually cancelled or not.) To report a delayed cancellation, then you should reschedule the task yourself, and call the `raise_cancel` callback passed to `abort_func` to raise a [`Cancelled`](reference-core#trio.Cancelled \"trio.Cancelled\") (or possibly [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\")) exception into this task. Either of the approaches sketched below can work:\n\n    ``` python\n    # Option 1:\n    # Catch the exception from raise_cancel and inject it into the task.\n    # (This is what Trio does automatically for you if you return\n    # Abort.SUCCEEDED.)\n    trio.lowlevel.reschedule(task, outcome.capture(raise_cancel))\n\n    # Option 2:\n    # wait to be woken by \"someone\", and then decide whether to raise\n    # the error from inside the task.\n    outer_raise_cancel = None\n    def abort(inner_raise_cancel):\n        nonlocal outer_raise_cancel\n        outer_raise_cancel = inner_raise_cancel\n        TRY_TO_CANCEL_OPERATION()\n        return trio.lowlevel.Abort.FAILED\n    await wait_task_rescheduled(abort)\n    if OPERATION_WAS_SUCCESSFULLY_CANCELLED:\n        # raises the error\n        outer_raise_cancel()\n    ```\n\n    In any case it’s guaranteed that we only call the `abort_func` at most once per call to [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\").\n\nSometimes, it’s useful to be able to share some mutable sleep-related data between the sleeping task, the abort function, and the waking task. You can use the sleeping task’s [`custom_sleep_data`](#trio.lowlevel.Task.custom_sleep_data \"trio.lowlevel.Task.custom_sleep_data\") attribute to store this data, and Trio won’t touch it, except to make sure that it gets cleared when the task is rescheduled.\n\n> #### Warning\n>\n> If your `abort_func` raises an error, or returns any value other than [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED \"trio.lowlevel.Abort.SUCCEEDED\") or [`Abort.FAILED`](#trio.lowlevel.Abort.FAILED \"trio.lowlevel.Abort.FAILED\"), then Trio will crash violently. Be careful! Similarly, it is entirely possible to deadlock a Trio program by failing to reschedule a blocked task, or cause havoc by calling [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\") too many times. Remember what we said up above about how you should use a higher-level API if at all possible?\n\n### *`class`*` trio.lowlevel.Abort(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)`\n\n[`enum.Enum`](https://docs.python.org/3/library/enum.html#enum.Enum \"(in Python v3.11)\") used as the return value from abort functions.\n\nSee [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\") for details.\n\n### `SUCCEEDED`\n\n### `FAILED`\n\n### `trio.lowlevel.reschedule(task, next_send=`\n\nReschedule the given task with the given [`outcome.Outcome`](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome \"(in outcome v1.2.0+dev)\").\n\nSee [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\") for the gory details.\n\nThere must be exactly one call to [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\") for every call to [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\"). (And when counting, keep in mind that returning [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED \"trio.lowlevel.Abort.SUCCEEDED\") from an abort callback is equivalent to calling [`reschedule()`](#trio.lowlevel.reschedule \"trio.lowlevel.reschedule\") once.)\n\n#### Parameters:\n\n- **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – the task to be rescheduled. Must be blocked in a call to [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\").\n\n- **next_send** ([*outcome.Outcome*](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome \"(in outcome v1.2.0+dev)\")) – the value (or error) to return (or raise) from [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\").\n\nHere’s an example lock class implemented using [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\") directly. This implementation has a number of flaws, including lack of fairness, O(n) cancellation, missing error checking, failure to insert a checkpoint on the non-blocking path, etc. If you really want to implement your own lock, then you should study the implementation of [`trio.Lock`](reference-core#trio.Lock \"trio.Lock\") and use [`ParkingLot`](#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\"), which handles some of these issues for you. But this does serve to illustrate the basic structure of the [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\") API:\n\n``` python\nclass NotVeryGoodLock:\n    def __init__(self):\n        self._blocked_tasks = collections.deque()\n        self._held = False\n\n    async def acquire(self):\n        # We might have to try several times to acquire the lock.\n        while self._held:\n            # Someone else has the lock, so we have to wait.\n            task = trio.lowlevel.current_task()\n            self._blocked_tasks.append(task)\n            def abort_fn(_):\n                self._blocked_tasks.remove(task)\n                return trio.lowlevel.Abort.SUCCEEDED\n            await trio.lowlevel.wait_task_rescheduled(abort_fn)\n            # At this point the lock was released -- but someone else\n            # might have swooped in and taken it again before we\n            # woke up. So we loop around to check the 'while' condition\n            # again.\n        # if we reach this point, it means that the 'while' condition\n        # has just failed, so we know no-one is holding the lock, and\n        # we can take it.\n        self._held = True\n\n    def release(self):\n        self._held = False\n        if self._blocked_tasks:\n            woken_task = self._blocked_tasks.popleft()\n            trio.lowlevel.reschedule(woken_task)\n```\n\n## Task API\n\n### `trio.lowlevel.current_root_task()`\n\nReturns the current root [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\").\n\nThis is the task that is the ultimate parent of all other tasks.\n\n### `trio.lowlevel.current_task()`\n\nReturn the [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") object representing the current task.\n\n#### Returns:\n\nthe [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") that called [`current_task()`](#trio.lowlevel.current_task \"trio.lowlevel.current_task\").\n\n#### Return type:\n\n[Task](#trio.lowlevel.Task \"trio.lowlevel.Task\")\n\n### *`class`*` trio.lowlevel.Task`\n\nA [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") object represents a concurrent “thread” of execution. It has no public constructor; Trio internally creates a [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") object for each call to `nursery.start(...)` or `nursery.start_soon(...)`.\n\nIts public members are mostly useful for introspection and debugging:\n\n### `name`\n\nString containing this [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\")'s name. Usually the name of the function this [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") is running, but can be overridden by passing `name=` to `start` or `start_soon`.\n\n### `coro`\n\nThis task’s coroutine object.\n\n### *`for ... in`*` iter_await_frames()`\n\nIterates recursively over the coroutine-like objects this task is waiting on, yielding the frame and line number at each frame.\n\nThis is similar to [`traceback.walk_stack`](https://docs.python.org/3/library/traceback.html#traceback.walk_stack \"(in Python v3.11)\") in a synchronous context. Note that [`traceback.walk_stack`](https://docs.python.org/3/library/traceback.html#traceback.walk_stack \"(in Python v3.11)\") returns frames from the bottom of the call stack to the top, while this function starts from [`Task.coro`](#trio.lowlevel.Task.coro \"trio.lowlevel.Task.coro\") and works it way down.\n\nExample usage: extracting a stack trace:\n\n``` python\nimport traceback\n\ndef print_stack_for_task(task):\n    ss = traceback.StackSummary.extract(task.iter_await_frames())\n    print(\"\".join(ss.format()))\n```\n\n### `context`\n\nThis task’s [`contextvars.Context`](https://docs.python.org/3/library/contextvars.html#contextvars.Context \"(in Python v3.11)\") object.\n\n### `parent_nursery`\n\nThe nursery this task is inside (or None if this is the “init” task).\n\nExample use case: drawing a visualization of the task tree in a debugger.\n\n### `eventual_parent_nursery`\n\nThe nursery this task will be inside after it calls `task_status.started()`.\n\nIf this task has already called `started()`, or if it was not spawned using [`nursery.start()`](reference-core#trio.Nursery.start \"trio.Nursery.start\"), then its [`eventual_parent_nursery`](#trio.lowlevel.Task.eventual_parent_nursery \"trio.lowlevel.Task.eventual_parent_nursery\") is `None`.\n\n### `child_nurseries`\n\nThe nurseries this task contains.\n\nThis is a list, with outer nurseries before inner nurseries.\n\n### `custom_sleep_data`\n\nTrio doesn’t assign this variable any meaning, except that it sets it to `None` whenever a task is rescheduled. It can be used to share data between the different tasks involved in putting a task to sleep and then waking it up again. (See [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\") for details.)\n\n## Using “guest mode” to run Trio on top of other event loops\n\n### What is “guest mode”?\n\nAn event loop acts as a central coordinator to manage all the IO happening in your program. Normally, that means that your application has to pick one event loop, and use it for everything. But what if you like Trio, but also need to use a framework like [Qt](https://en.wikipedia.org/wiki/Qt_(software)) or [PyGame](https://www.pygame.org/) that has its own event loop? Then you need some way to run both event loops at once.\n\nIt is possible to combine event loops, but the standard approaches all have significant downsides:\n\n- **Polling:** this is where you use a [busy-loop](https://en.wikipedia.org/wiki/Busy_waiting) to manually check for IO on both event loops many times per second. This adds latency, and wastes CPU time and electricity.\n\n- **Pluggable IO backends:** this is where you reimplement one of the event loop APIs on top of the other, so you effectively end up with just one event loop. This requires a significant amount of work for each pair of event loops you want to integrate, and different backends inevitably end up with inconsistent behavior, forcing users to program against the least-common-denominator. And if the two event loops expose different feature sets, it may not even be possible to implement one in terms of the other.\n\n- **Running the two event loops in separate threads:** This works, but most event loop APIs aren’t thread-safe, so in this approach you need to keep careful track of which code runs on which event loop, and remember to use explicit inter-thread messaging whenever you interact with the other loop – or else risk obscure race conditions and data corruption.\n\nThat’s why Trio offers a fourth option: **guest mode**. Guest mode lets you execute [`trio.run`](reference-core#trio.run \"trio.run\") on top of some other “host” event loop, like Qt. Its advantages are:\n\n- Efficiency: guest mode is event-driven instead of using a busy-loop, so it has low latency and doesn’t waste electricity.\n\n- No need to think about threads: your Trio code runs in the same thread as the host event loop, so you can freely call sync Trio APIs from the host, and call sync host APIs from Trio. For example, if you’re making a GUI app with Qt as the host loop, then making a [cancel button](https://doc.qt.io/qt-5/qpushbutton.html) and connecting it to a [`trio.CancelScope`](reference-core#trio.CancelScope \"trio.CancelScope\") is as easy as writing:\n\n  ``` python\n  # Trio code can create Qt objects without any special ceremony...\n  my_cancel_button = QPushButton(\"Cancel\")\n  # ...and Qt can call back to Trio just as easily\n  my_cancel_button.clicked.connect(my_cancel_scope.cancel)\n  ```\n\n  (For async APIs, it’s not that simple, but you can use sync APIs to build explicit bridges between the two worlds, e.g. by passing async functions and their results back and forth through queues.)\n\n- Consistent behavior: guest mode uses the same code as regular Trio: the same scheduler, same IO code, same everything. So you get the full feature set and everything acts the way you expect.\n\n- Simple integration and broad compatibility: pretty much every event loop offers some threadsafe “schedule a callback” operation, and that’s all you need to use it as a host loop.\n\n### Really? How is that possible?\n\n> #### Note\n>\n> You can use guest mode without reading this section. It’s included for those who enjoy understanding how things work.\n\nAll event loops have the same basic structure. They loop through two operations, over and over:\n\n1.  Wait for the operating system to notify them that something interesting has happened, like data arriving on a socket or a timeout passing. They do this by invoking a platform-specific `sleep_until_something_happens()` system call – `select`, `epoll`, `kqueue`, `GetQueuedCompletionEvents`, etc.\n\n2.  Run all the user tasks that care about whatever happened, then go back to step 1.\n\nThe problem here is step 1. Two different event loops on the same thread can take turns running user tasks in step 2, but when they’re idle and nothing is happening, they can’t both invoke their own `sleep_until_something_happens()` function at the same time.\n\nThe “polling” and “pluggable backend” strategies solve this by hacking the loops so both step 1s can run at the same time in the same thread. Keeping everything in one thread is great for step 2, but the step 1 hacks create problems.\n\nThe “separate threads” strategy solves this by moving both steps into separate threads. This makes step 1 work, but the downside is that now the user tasks in step 2 are running separate threads as well, so users are forced to deal with inter-thread coordination.\n\nThe idea behind guest mode is to combine the best parts of each approach: we move Trio’s step 1 into a separate worker thread, while keeping Trio’s step 2 in the main host thread. This way, when the application is idle, both event loops do their `sleep_until_something_happens()` at the same time in their own threads. But when the app wakes up and your code is actually running, it all happens in a single thread. The threading trickiness is all handled transparently inside Trio.\n\nConcretely, we unroll Trio’s internal event loop into a chain of callbacks, and as each callback finishes, it schedules the next callback onto the host loop or a worker thread as appropriate. So the only thing the host loop has to provide is a way to schedule a callback onto the main thread from a worker thread.\n\nCoordinating between Trio and the host loop does add some overhead. The main cost is switching in and out of the background thread, since this requires cross-thread messaging. This is cheap (on the order of a few microseconds, assuming your host loop is implemented efficiently), but it’s not free.\n\nBut, there’s a nice optimization we can make: we only *need* the thread when our `sleep_until_something_happens()` call actually sleeps, that is, when the Trio part of your program is idle and has nothing to do. So before we switch into the worker thread, we double-check whether we’re idle, and if not, then we skip the worker thread and jump directly to step 2. This means that your app only pays the extra thread-switching penalty at moments when it would otherwise be sleeping, so it should have minimal effect on your app’s overall performance.\n\nThe total overhead will depend on your host loop, your platform, your application, etc. But we expect that in most cases, apps running in guest mode should only be 5-10% slower than the same code using [`trio.run`](reference-core#trio.run \"trio.run\"). If you find that’s not true for your app, then please let us know and we’ll see if we can fix it!\n\n### Implementing guest mode for your favorite event loop\n\nLet’s walk through what you need to do to integrate Trio’s guest mode with your favorite event loop. Treat this section like a checklist.\n\n**Getting started:** The first step is to get something basic working. Here’s a minimal example of running Trio on top of asyncio, that you can use as a model:\n\n``` python\nimport asyncio, trio\n\n# A tiny Trio program\nasync def trio_main():\n    for _ in range(5):\n        print(\"Hello from Trio!\")\n        # This is inside Trio, so we have to use Trio APIs\n        await trio.sleep(1)\n    return \"trio done!\"\n\n# The code to run it as a guest inside asyncio\nasync def asyncio_main():\n    asyncio_loop = asyncio.get_running_loop()\n\n    def run_sync_soon_threadsafe(fn):\n        asyncio_loop.call_soon_threadsafe(fn)\n\n    def done_callback(trio_main_outcome):\n        print(f\"Trio program ended with: {trio_main_outcome}\")\n\n    # This is where the magic happens:\n    trio.lowlevel.start_guest_run(\n        trio_main,\n        run_sync_soon_threadsafe=run_sync_soon_threadsafe,\n        done_callback=done_callback,\n    )\n\n    # Let the host loop run for a while to give trio_main time to\n    # finish. (WARNING: This is a hack. See below for better\n    # approaches.)\n    #\n    # This function is in asyncio, so we have to use asyncio APIs.\n    await asyncio.sleep(10)\n\nasyncio.run(asyncio_main())\n```\n\nYou can see we’re using asyncio-specific APIs to start up a loop, and then we call [`trio.lowlevel.start_guest_run`](#trio.lowlevel.start_guest_run \"trio.lowlevel.start_guest_run\"). This function is very similar to [`trio.run`](reference-core#trio.run \"trio.run\"), and takes all the same arguments. But it has two differences:\n\nFirst, instead of blocking until `trio_main` has finished, it schedules `trio_main` to start running on top of the host loop, and then returns immediately. So `trio_main` is running in the background – that’s why we have to sleep and give it time to finish.\n\nAnd second, it requires two extra keyword arguments: `run_sync_soon_threadsafe`, and `done_callback`.\n\nFor `run_sync_soon_threadsafe`, we need a function that takes a synchronous callback, and schedules it to run on your host loop. And this function needs to be “threadsafe” in the sense that you can safely call it from any thread. So you need to figure out how to write a function that does that using your host loop’s API. For asyncio, this is easy because [`call_soon_threadsafe`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_soon_threadsafe \"(in Python v3.11)\") does exactly what we need; for your loop, it might be more or less complicated.\n\nFor `done_callback`, you pass in a function that Trio will automatically invoke when the Trio run finishes, so you know it’s done and what happened. For this basic starting version, we just print the result; in the next section we’ll discuss better alternatives.\n\nAt this stage you should be able to run a simple Trio program inside your host loop. Now we’ll turn that prototype into something solid.\n\n**Loop lifetimes:** One of the trickiest things in most event loops is shutting down correctly. And having two event loops makes this even harder!\n\nIf you can, we recommend following this pattern:\n\n- Start up your host loop\n\n- Immediately call [`start_guest_run`](#trio.lowlevel.start_guest_run \"trio.lowlevel.start_guest_run\") to start Trio\n\n- When Trio finishes and your `done_callback` is invoked, shut down the host loop\n\n- Make sure that nothing else shuts down your host loop\n\nThis way, your two event loops have the same lifetime, and your program automatically exits when your Trio function finishes.\n\nHere’s how we’d extend our asyncio example to implement this pattern:\n\n``` python\n# Improved version, that shuts down properly after Trio finishes\nasync def asyncio_main():\n    asyncio_loop = asyncio.get_running_loop()\n\n    def run_sync_soon_threadsafe(fn):\n        asyncio_loop.call_soon_threadsafe(fn)\n\n    # Revised 'done' callback: set a Future\n    done_fut = asyncio_loop.create_future()\n    def done_callback(trio_main_outcome):\n        done_fut.set_result(trio_main_outcome)\n\n    trio.lowlevel.start_guest_run(\n        trio_main,\n        run_sync_soon_threadsafe=run_sync_soon_threadsafe,\n        done_callback=done_callback,\n    )\n\n    # Wait for the guest run to finish\n    trio_main_outcome = await done_fut\n    # Pass through the return value or exception from the guest run\n    return trio_main_outcome.unwrap()\n```\n\nAnd then you can encapsulate all this machinery in a utility function that exposes a [`trio.run`](reference-core#trio.run \"trio.run\")-like API, but runs both loops together:\n\n``` python\ndef trio_run_with_asyncio(trio_main, *args, **trio_run_kwargs):\n    async def asyncio_main():\n        # same as above\n        ...\n\n    return asyncio.run(asyncio_main())\n```\n\nTechnically, it is possible to use other patterns. But there are some important limitations you have to respect:\n\n- **You must let the Trio program run to completion.** Many event loops let you stop the event loop at any point, and any pending callbacks/tasks/etc. just… don’t run. Trio follows a more structured system, where you can cancel things, but the code always runs to completion, so `finally` blocks run, resources are cleaned up, etc. If you stop your host loop early, before the `done_callback` is invoked, then that cuts off the Trio run in the middle without a chance to clean up. This can leave your code in an inconsistent state, and will definitely leave Trio’s internals in an inconsistent state, which will cause errors if you try to use Trio again in that thread.\n\n  Some programs need to be able to quit at any time, for example in response to a GUI window being closed or a user selecting a “Quit” from a menu. In these cases, we recommend wrapping your whole program in a [`trio.CancelScope`](reference-core#trio.CancelScope \"trio.CancelScope\"), and cancelling it when you want to quit.\n\n- Each host loop can only have one [`start_guest_run`](#trio.lowlevel.start_guest_run \"trio.lowlevel.start_guest_run\") at a time. If you try to start a second one, you’ll get an error. If you need to run multiple Trio functions at the same time, then start up a single Trio run, open a nursery, and then start your functions as child tasks in that nursery.\n\n- Unless you or your host loop register a handler for [`signal.SIGINT`](https://docs.python.org/3/library/signal.html#signal.SIGINT \"(in Python v3.11)\") before starting Trio (this is not common), then Trio will take over delivery of [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\")s. And since Trio can’t tell which host code is safe to interrupt, it will only deliver [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") into the Trio part of your code. This is fine if your program is set up to exit when the Trio part exits, because the [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") will propagate out of Trio and then trigger the shutdown of your host loop, which is just what you want.\n\nGiven these constraints, we think the simplest approach is to always start and stop the two loops together.\n\n**Signal management:** [“Signals”](https://en.wikipedia.org/wiki/Signal_(IPC)) are a low-level inter-process communication primitive. When you hit control-C to kill a program, that uses a signal. Signal handling in Python has [a lot of moving parts](https://vorpus.org/blog/control-c-handling-in-python-and-trio/). One of those parts is [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\"), which event loops use to make sure that they wake up when a signal arrives so they can respond to it. (If you’ve ever had an event loop ignore you when you hit control-C, it was probably because they weren’t using [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\") correctly.)\n\nBut, only one event loop can use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\") at a time. And in guest mode that can cause problems: Trio and the host loop might start fighting over who’s using [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\").\n\nSome event loops, like asyncio, won’t work correctly unless they win this fight. Fortunately, Trio is a little less picky: as long as *someone* makes sure that the program wakes up when a signal arrives, it should work correctly. So if your host loop wants [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\"), then you should disable Trio’s [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\") support, and then both loops will work correctly.\n\nOn the other hand, if your host loop doesn’t use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\"), then the only way to make everything work correctly is to *enable* Trio’s [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\") support.\n\nBy default, Trio assumes that your host loop doesn’t use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\"). It does try to detect when this creates a conflict with the host loop, and print a warning – but unfortunately, by the time it detects it, the damage has already been done. So if you’re getting this warning, then you should disable Trio’s [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\") support by passing `host_uses_signal_set_wakeup_fd=True` to [`start_guest_run`](#trio.lowlevel.start_guest_run \"trio.lowlevel.start_guest_run\").\n\nIf you aren’t seeing any warnings with your initial prototype, you’re *probably* fine. But the only way to be certain is to check your host loop’s source. For example, asyncio may or may not use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\") depending on the Python version and operating system.\n\n**A small optimization:** Finally, consider a small optimization. Some event loops offer two versions of their “call this function soon” API: one that can be used from any thread, and one that can only be used from the event loop thread, with the latter being cheaper. For example, asyncio has both [`call_soon_threadsafe`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_soon_threadsafe \"(in Python v3.11)\") and [`call_soon`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_soon \"(in Python v3.11)\").\n\nIf you have a loop like this, then you can also pass a `run_sync_soon_not_threadsafe=...` kwarg to [`start_guest_run`](#trio.lowlevel.start_guest_run \"trio.lowlevel.start_guest_run\"), and Trio will automatically use it when appropriate.\n\nIf your loop doesn’t have a split like this, then don’t worry about it; `run_sync_soon_not_threadsafe=` is optional. (If it’s not passed, then Trio will just use your threadsafe version in all cases.)\n\n**That’s it!** If you’ve followed all these steps, you should now have a cleanly-integrated hybrid event loop. Go make some cool GUIs/games/whatever!\n\n### Limitations\n\nIn general, almost all Trio features should work in guest mode. The exception is features which rely on Trio having a complete picture of everything that your program is doing, since obviously, it can’t control the host loop or see what it’s doing.\n\nCustom clocks can be used in guest mode, but they only affect Trio timeouts, not host loop timeouts. And the [autojump clock](reference-testing#testing-time) and related [`trio.testing.wait_all_tasks_blocked`](reference-testing#trio.testing.wait_all_tasks_blocked \"trio.testing.wait_all_tasks_blocked\") can technically be used in guest mode, but they’ll only take Trio tasks into account when decided whether to jump the clock or whether all tasks are blocked.\n\n### Reference\n\n### `trio.lowlevel.start_guest_run(async_fn, *args, run_sync_soon_threadsafe, done_callback, run_sync_soon_not_threadsafe=None, host_uses_signal_set_wakeup_fd: bool = False, clock=None, instruments=(), restrict_keyboard_interrupt_to_checkpoints: bool = False, strict_exception_groups: bool = False)`\n\nStart a “guest” run of Trio on top of some other “host” event loop.\n\nEach host loop can only have one guest run at a time.\n\nYou should always let the Trio run finish before stopping the host loop; if not, it may leave Trio’s internal data structures in an inconsistent state. You might be able to get away with it if you immediately exit the program, but it’s safest not to go there in the first place.\n\nGenerally, the best way to do this is wrap this in a function that starts the host loop and then immediately starts the guest run, and then shuts down the host when the guest run completes.\n\n#### Parameters:\n\n- **run_sync_soon_threadsafe** –\n\n  An arbitrary callable, which will be passed a function as its sole argument:\n\n  ``` python\n  def my_run_sync_soon_threadsafe(fn):\n      ...\n  ```\n\n  This callable should schedule `fn()` to be run by the host on its next pass through its loop. **Must support being called from arbitrary threads.**\n\n- **done_callback** –\n\n  An arbitrary callable:\n\n  ``` python\n  def my_done_callback(run_outcome):\n      ...\n  ```\n\n  When the Trio run has finished, Trio will invoke this callback to let you know. The argument is an [`outcome.Outcome`](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome \"(in outcome v1.2.0+dev)\"), reporting what would have been returned or raised by [`trio.run`](reference-core#trio.run \"trio.run\"). This function can do anything you want, but commonly you’ll want it to shut down the host loop, unwrap the outcome, etc.\n\n- **run_sync_soon_not_threadsafe** – Like `run_sync_soon_threadsafe`, but will only be called from inside the host loop’s main thread. Optional, but if your host loop allows you to implement this more efficiently than `run_sync_soon_threadsafe` then passing it will make things a bit faster.\n\n- **host_uses_signal_set_wakeup_fd** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – Pass [`True`](https://docs.python.org/3/library/constants.html#True \"(in Python v3.11)\") if your host loop uses [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd \"(in Python v3.11)\"), and [`False`](https://docs.python.org/3/library/constants.html#False \"(in Python v3.11)\") otherwise. For more details, see [Implementing guest mode for your favorite event loop](#guest-run-implementation).\n\nFor the meaning of other arguments, see [`trio.run`](reference-core#trio.run \"trio.run\").\n\n## Handing off live coroutine objects between coroutine runners\n\nInternally, Python’s async/await syntax is built around the idea of “coroutine objects” and “coroutine runners”. A coroutine object represents the state of an async callstack. But by itself, this is just a static object that sits there. If you want it to do anything, you need a coroutine runner to push it forward. Every Trio task has an associated coroutine object (see [`Task.coro`](#trio.lowlevel.Task.coro \"trio.lowlevel.Task.coro\")), and the Trio scheduler acts as their coroutine runner.\n\nBut of course, Trio isn’t the only coroutine runner in Python – [`asyncio`](https://docs.python.org/3/library/asyncio.html#module-asyncio \"(in Python v3.11)\") has one, other event loops have them, you can even define your own.\n\nAnd in some very, very unusual circumstances, it even makes sense to transfer a single coroutine object back and forth between different coroutine runners. That’s what this section is about. This is an *extremely* exotic use case, and assumes a lot of expertise in how Python async/await works internally. For motivating examples, see [trio-asyncio issue \\#42](https://github.com/python-trio/trio-asyncio/issues/42), and [trio issue \\#649](https://github.com/python-trio/trio/issues/649). For more details on how coroutines work, we recommend André Caron’s [A tale of event loops](https://github.com/AndreLouisCaron/a-tale-of-event-loops), or going straight to [PEP 492](https://www.python.org/dev/peps/pep-0492/) for the full details.\n\n### *`await`*` trio.lowlevel.permanently_detach_coroutine_object(final_outcome)`\n\nPermanently detach the current task from the Trio scheduler.\n\nNormally, a Trio task doesn’t exit until its coroutine object exits. When you call this function, Trio acts like the coroutine object just exited and the task terminates with the given outcome. This is useful if you want to permanently switch the coroutine object over to a different coroutine runner.\n\nWhen the calling coroutine enters this function it’s running under Trio, and when the function returns it’s running under the foreign coroutine runner.\n\nYou should make sure that the coroutine object has released any Trio-specific resources it has acquired (e.g. nurseries).\n\n#### Parameters:\n\n**final_outcome** ([*outcome.Outcome*](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome \"(in outcome v1.2.0+dev)\")) – Trio acts as if the current task exited with the given return value or exception.\n\nReturns or raises whatever value or exception the new coroutine runner uses to resume the coroutine.\n\n### *`await`*` trio.lowlevel.temporarily_detach_coroutine_object(abort_func)`\n\nTemporarily detach the current coroutine object from the Trio scheduler.\n\nWhen the calling coroutine enters this function it’s running under Trio, and when the function returns it’s running under the foreign coroutine runner.\n\nThe Trio [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") will continue to exist, but will be suspended until you use [`reattach_detached_coroutine_object()`](#trio.lowlevel.reattach_detached_coroutine_object \"trio.lowlevel.reattach_detached_coroutine_object\") to resume it. In the mean time, you can use another coroutine runner to schedule the coroutine object. In fact, you have to – the function doesn’t return until the coroutine is advanced from outside.\n\nNote that you’ll need to save the current [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") object to later resume; you can retrieve it with [`current_task()`](#trio.lowlevel.current_task \"trio.lowlevel.current_task\"). You can also use this [`Task`](#trio.lowlevel.Task \"trio.lowlevel.Task\") object to retrieve the coroutine object – see [`Task.coro`](#trio.lowlevel.Task.coro \"trio.lowlevel.Task.coro\").\n\n#### Parameters:\n\n**abort_func** – Same as for [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled \"trio.lowlevel.wait_task_rescheduled\"), except that it must return [`Abort.FAILED`](#trio.lowlevel.Abort.FAILED \"trio.lowlevel.Abort.FAILED\"). (If it returned [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED \"trio.lowlevel.Abort.SUCCEEDED\"), then Trio would attempt to reschedule the detached task directly without going through [`reattach_detached_coroutine_object()`](#trio.lowlevel.reattach_detached_coroutine_object \"trio.lowlevel.reattach_detached_coroutine_object\"), which would be bad.) Your `abort_func` should still arrange for whatever the coroutine object is doing to be cancelled, and then reattach to Trio and call the `raise_cancel` callback, if possible.\n\nReturns or raises whatever value or exception the new coroutine runner uses to resume the coroutine.\n\n### *`await`*` trio.lowlevel.reattach_detached_coroutine_object(task, yield_value)`\n\nReattach a coroutine object that was detached using [`temporarily_detach_coroutine_object()`](#trio.lowlevel.temporarily_detach_coroutine_object \"trio.lowlevel.temporarily_detach_coroutine_object\").\n\nWhen the calling coroutine enters this function it’s running under the foreign coroutine runner, and when the function returns it’s running under Trio.\n\nThis must be called from inside the coroutine being resumed, and yields whatever value you pass in. (Presumably you’ll pass a value that will cause the current coroutine runner to stop scheduling this task.) Then the coroutine is resumed by the Trio scheduler at the next opportunity.\n\n#### Parameters:\n\n- **task** ([*Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The Trio task object that the current coroutine was detached from.\n\n- **yield_value** ([*object*](https://docs.python.org/3/library/functions.html#object \"(in Python v3.11)\")) – The object to yield to the current coroutine runner.\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-lowlevel.html](https://trio.readthedocs.io/en/v0.22.2/reference-lowlevel.html)"
- name: max_value
  id: reference-core#trio.Semaphore.max_value
  summary: The maximum allowed value
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` max_value`

    The maximum allowed value. May be None to indicate no limit.
- name: parent_task
  id: reference-core#trio.Nursery.parent_task
  summary: The Task that opened this nursery
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` parent_task`

    The Task that opened this nursery.

    #### Type:

    ([`Task`](reference-lowlevel#trio.lowlevel.Task "trio.lowlevel.Task"))
- name: Testing made easier with trio.testing
  id: reference-testing
  summary: The trio.testing module provides various utilities to make it easier to test Trio code
  description: "# Testing made easier with `trio.testing`\n\nThe [`trio.testing`](#module-trio.testing \"trio.testing\") module provides various utilities to make it easier to test Trio code. Unlike the other submodules in the [`trio`](reference-core#module-trio \"trio\") namespace, [`trio.testing`](#module-trio.testing \"trio.testing\") is *not* automatically imported when you do `import`` ``trio`; you must `import`` ``trio.testing` explicitly.\n\n## Test harness integration\n\n### `@trio.testing.trio_test`\n\n## Time and timeouts\n\n[`trio.testing.MockClock`](#trio.testing.MockClock \"trio.testing.MockClock\") is a [`Clock`](reference-core#trio.abc.Clock \"trio.abc.Clock\") with a few tricks up its sleeve to help you efficiently test code involving timeouts:\n\n- By default, it starts at time 0, and clock time only advances when you explicitly call [`jump()`](#trio.testing.MockClock.jump \"trio.testing.MockClock.jump\"). This provides an extremely controllable clock for testing.\n\n- You can set [`rate`](#trio.testing.MockClock.rate \"trio.testing.MockClock.rate\") to 1.0 if you want it to start running in real time like a regular clock. You can stop and start the clock within a test. You can set [`rate`](#trio.testing.MockClock.rate \"trio.testing.MockClock.rate\") to 10.0 to make clock time pass at 10x real speed (so e.g. `await`` ``trio.sleep(10)` returns after 1 second).\n\n- But even more interestingly, you can set [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold \"trio.testing.MockClock.autojump_threshold\") to zero or a small value, and then it will watch the execution of the run loop, and any time things have settled down and everyone’s waiting for a timeout, it jumps the clock forward to that timeout. In many cases this allows natural-looking code involving timeouts to be automatically run at near full CPU utilization with no changes. (Thanks to [fluxcapacitor](https://github.com/majek/fluxcapacitor) for this awesome idea.)\n\n- And of course these can be mixed and matched at will.\n\nRegardless of these shenanigans, from “inside” Trio the passage of time still seems normal so long as you restrict yourself to Trio’s time functions (see [Time and clocks](reference-core#time-and-clocks)). Below is an example demonstrating two different ways of making time pass quickly. Notice how in both cases, the two tasks keep a consistent view of reality and events happen in the expected order, despite being wildly divorced from real time:\n\n``` python\n# across-realtime.py\n\nimport time\nimport trio\nimport trio.testing\n\nYEAR = 365 * 24 * 60 * 60  # seconds\n\n\nasync def task1():\n    start = trio.current_time()\n\n    print(\"task1: sleeping for 1 year\")\n    await trio.sleep(YEAR)\n\n    duration = trio.current_time() - start\n    print(f\"task1: woke up; clock says I've slept {duration / YEAR} years\")\n\n    print(\"task1: sleeping for 1 year, 100 times\")\n    for _ in range(100):\n        await trio.sleep(YEAR)\n\n    duration = trio.current_time() - start\n    print(f\"task1: slept {duration / YEAR} years total\")\n\n\nasync def task2():\n    start = trio.current_time()\n\n    print(\"task2: sleeping for 5 years\")\n    await trio.sleep(5 * YEAR)\n\n    duration = trio.current_time() - start\n    print(f\"task2: woke up; clock says I've slept {duration / YEAR} years\")\n\n    print(\"task2: sleeping for 500 years\")\n    await trio.sleep(500 * YEAR)\n\n    duration = trio.current_time() - start\n    print(f\"task2: slept {duration / YEAR} years total\")\n\n\nasync def main():\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(task1)\n        nursery.start_soon(task2)\n\n\ndef run_example(clock):\n    real_start = time.perf_counter()\n    trio.run(main, clock=clock)\n    real_duration = time.perf_counter() - real_start\n    print(f\"Total real time elapsed: {real_duration} seconds\")\n\n\nprint(\"Clock where time passes at 100 years per second:\\n\")\nrun_example(trio.testing.MockClock(rate=100 * YEAR))\n\nprint(\"\\nClock where time automatically skips past the boring parts:\\n\")\nrun_example(trio.testing.MockClock(autojump_threshold=0))\n```\n\nOutput:\n\n    Clock where time passes at 100 years per second:\n\n    task2: sleeping for 5 years\n    task1: sleeping for 1 year\n    task1: woke up; clock says I've slept 1.0365006048232317 years\n    task1: sleeping for 1 year, 100 times\n    task2: woke up; clock says I've slept 5.0572111969813704 years\n    task2: sleeping for 500 years\n    task1: slept 104.77677842136472 years total\n    task2: slept 505.25014589075 years total\n    Total real time elapsed: 5.053582429885864 seconds\n\n    Clock where time automatically skips past the boring parts:\n\n    task2: sleeping for 5 years\n    task1: sleeping for 1 year\n    task1: woke up; clock says I've slept 1.0 years\n    task1: sleeping for 1 year, 100 times\n    task2: woke up; clock says I've slept 5.0 years\n    task2: sleeping for 500 years\n    task1: slept 101.0 years total\n    task2: slept 505.0 years total\n    Total real time elapsed: 0.019298791885375977 seconds\n\n### *`class`*` trio.testing.MockClock(rate=0.0, autojump_threshold=inf)`\n\nA user-controllable clock suitable for writing tests.\n\n#### Parameters:\n\n- **rate** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – the initial [`rate`](#trio.testing.MockClock.rate \"trio.testing.MockClock.rate\").\n\n- **autojump_threshold** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – the initial [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold \"trio.testing.MockClock.autojump_threshold\").\n\n### `rate`\n\nHow many seconds of clock time pass per second of real time. Default is 0.0, i.e. the clock only advances through manuals calls to [`jump()`](#trio.testing.MockClock.jump \"trio.testing.MockClock.jump\") or when the [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold \"trio.testing.MockClock.autojump_threshold\") is triggered. You can assign to this attribute to change it.\n\n### `autojump_threshold`\n\nThe clock keeps an eye on the run loop, and if at any point it detects that all tasks have been blocked for this many real seconds (i.e., according to the actual clock, not this clock), then the clock automatically jumps ahead to the run loop’s next scheduled timeout. Default is [`math.inf`](https://docs.python.org/3/library/math.html#math.inf \"(in Python v3.11)\"), i.e., to never autojump. You can assign to this attribute to change it.\n\nBasically the idea is that if you have code or tests that use sleeps and timeouts, you can use this to make it run much faster, totally automatically. (At least, as long as those sleeps/timeouts are happening inside Trio; if your test involves talking to external service and waiting for it to timeout then obviously we can’t help you there.)\n\nYou should set this to the smallest value that lets you reliably avoid “false alarms” where some I/O is in flight (e.g. between two halves of a socketpair) but the threshold gets triggered and time gets advanced anyway. This will depend on the details of your tests and test environment. If you aren’t doing any I/O (like in our sleeping example above) then just set it to zero, and the clock will jump whenever all tasks are blocked.\n\n> #### Note\n>\n> If you use `autojump_threshold` and [`wait_all_tasks_blocked`](#trio.testing.wait_all_tasks_blocked \"trio.testing.wait_all_tasks_blocked\") at the same time, then you might wonder how they interact, since they both cause things to happen after the run loop goes idle for some time. The answer is: [`wait_all_tasks_blocked`](#trio.testing.wait_all_tasks_blocked \"trio.testing.wait_all_tasks_blocked\") takes priority. If there’s a task blocked in [`wait_all_tasks_blocked`](#trio.testing.wait_all_tasks_blocked \"trio.testing.wait_all_tasks_blocked\"), then the autojump feature treats that as active task and does *not* jump the clock.\n\n### `jump(seconds)`\n\nManually advance the clock by the given number of seconds.\n\n#### Parameters:\n\n**seconds** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – the number of seconds to jump the clock forward.\n\n#### Raises:\n\n[**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if you try to pass a negative value for `seconds`.\n\n## Inter-task ordering\n\n### *`class`*` trio.testing.Sequencer`\n\nA convenience class for forcing code in different tasks to run in an explicit linear order.\n\nInstances of this class implement a `__call__` method which returns an async context manager. The idea is that you pass a sequence number to `__call__` to say where this block of code should go in the linear sequence. Block 0 starts immediately, and then block N doesn’t start until block N-1 has finished.\n\nExample\n\nAn extremely elaborate way to print the numbers 0-5, in order:\n\n``` python\nasync def worker1(seq):\n    async with seq(0):\n        print(0)\n    async with seq(4):\n        print(4)\n\nasync def worker2(seq):\n    async with seq(2):\n        print(2)\n    async with seq(5):\n        print(5)\n\nasync def worker3(seq):\n    async with seq(1):\n        print(1)\n    async with seq(3):\n        print(3)\n\nasync def main():\n   seq = trio.testing.Sequencer()\n   async with trio.open_nursery() as nursery:\n       nursery.start_soon(worker1, seq)\n       nursery.start_soon(worker2, seq)\n       nursery.start_soon(worker3, seq)\n```\n\n### *`await`*` trio.testing.wait_all_tasks_blocked(cushion=0.0)`\n\nBlock until there are no runnable tasks.\n\nThis is useful in testing code when you want to give other tasks a chance to “settle down”. The calling task is blocked, and doesn’t wake up until all other tasks are also blocked for at least `cushion` seconds. (Setting a non-zero `cushion` is intended to handle cases like two tasks talking to each other over a local socket, where we want to ignore the potential brief moment between a send and receive when all tasks are blocked.)\n\nNote that `cushion` is measured in *real* time, not the Trio clock time.\n\nIf there are multiple tasks blocked in [`wait_all_tasks_blocked()`](#trio.testing.wait_all_tasks_blocked \"trio.testing.wait_all_tasks_blocked\"), then the one with the shortest `cushion` is the one woken (and this task becoming unblocked resets the timers for the remaining tasks). If there are multiple tasks that have exactly the same `cushion`, then all are woken.\n\nYou should also consider [`trio.testing.Sequencer`](#trio.testing.Sequencer \"trio.testing.Sequencer\"), which provides a more explicit way to control execution ordering within a test, and will often produce more readable tests.\n\nExample\n\nHere’s an example of one way to test that Trio’s locks are fair: we take the lock in the parent, start a child, wait for the child to be blocked waiting for the lock (!), and then check that we can’t release and immediately re-acquire the lock:\n\n``` python\nasync def lock_taker(lock):\n    await lock.acquire()\n    lock.release()\n\nasync def test_lock_fairness():\n    lock = trio.Lock()\n    await lock.acquire()\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(lock_taker, lock)\n        # child hasn't run yet, we have the lock\n        assert lock.locked()\n        assert lock._owner is trio.lowlevel.current_task()\n        await trio.testing.wait_all_tasks_blocked()\n        # now the child has run and is blocked on lock.acquire(), we\n        # still have the lock\n        assert lock.locked()\n        assert lock._owner is trio.lowlevel.current_task()\n        lock.release()\n        try:\n            # The child has a prior claim, so we can't have it\n            lock.acquire_nowait()\n        except trio.WouldBlock:\n            assert lock._owner is not trio.lowlevel.current_task()\n            print(\"PASS\")\n        else:\n            print(\"FAIL\")\n```\n\n## Streams\n\n### Connecting to an in-process socket server\n\n### *`await`*` trio.testing.open_stream_to_socket_listener(socket_listener)`\n\nConnect to the given [`SocketListener`](reference-io#trio.SocketListener \"trio.SocketListener\").\n\nThis is particularly useful in tests when you want to let a server pick its own port, and then connect to it:\n\n``` python\nlisteners = await trio.open_tcp_listeners(0)\nclient = await trio.testing.open_stream_to_socket_listener(listeners[0])\n```\n\n#### Parameters:\n\n**socket_listener** ([*SocketListener*](reference-io#trio.SocketListener \"trio.SocketListener\")) – The [`SocketListener`](reference-io#trio.SocketListener \"trio.SocketListener\") to connect to.\n\n#### Returns:\n\na stream connected to the given listener.\n\n#### Return type:\n\n[SocketStream](reference-io#trio.SocketStream \"trio.SocketStream\")\n\n### Virtual, controllable streams\n\nOne particularly challenging problem when testing network protocols is making sure that your implementation can handle data whose flow gets broken up in weird ways and arrives with weird timings: localhost connections tend to be much better behaved than real networks, so if you only test on localhost then you might get bitten later. To help you out, Trio provides some fully in-memory implementations of the stream interfaces (see [The abstract Stream API](reference-io#abstract-stream-api)), that let you write all kinds of interestingly evil tests.\n\nThere are a few pieces here, so here’s how they fit together:\n\n[`memory_stream_pair()`](#trio.testing.memory_stream_pair \"trio.testing.memory_stream_pair\") gives you a pair of connected, bidirectional streams. It’s like [`socket.socketpair()`](https://docs.python.org/3/library/socket.html#socket.socketpair \"(in Python v3.11)\"), but without any involvement from that pesky operating system and its networking stack.\n\nTo build a bidirectional stream, [`memory_stream_pair()`](#trio.testing.memory_stream_pair \"trio.testing.memory_stream_pair\") uses two unidirectional streams. It gets these by calling [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair \"trio.testing.memory_stream_one_way_pair\").\n\n[`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair \"trio.testing.memory_stream_one_way_pair\"), in turn, is implemented using the low-ish level classes [`MemorySendStream`](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\") and [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\"). These are implementations of (you guessed it) [`trio.abc.SendStream`](reference-io#trio.abc.SendStream \"trio.abc.SendStream\") and [`trio.abc.ReceiveStream`](reference-io#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") that on their own, aren’t attached to anything – “sending” and “receiving” just put data into and get data out of a private internal buffer that each object owns. They also have some interesting hooks you can set, that let you customize the behavior of their methods. This is where you can insert the evil, if you want it. [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair \"trio.testing.memory_stream_one_way_pair\") takes advantage of these hooks in a relatively boring way: it just sets it up so that when you call `send_all`, or when you close the send stream, then it automatically triggers a call to [`memory_stream_pump()`](#trio.testing.memory_stream_pump \"trio.testing.memory_stream_pump\"), which is a convenience function that takes data out of a [`MemorySendStream`](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\")´s buffer and puts it into a [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\")´s buffer. But that’s just the default – you can replace this with whatever arbitrary behavior you want.\n\nTrio also provides some specialized functions for testing completely **un**buffered streams: [`lockstep_stream_one_way_pair()`](#trio.testing.lockstep_stream_one_way_pair \"trio.testing.lockstep_stream_one_way_pair\") and [`lockstep_stream_pair()`](#trio.testing.lockstep_stream_pair \"trio.testing.lockstep_stream_pair\"). These aren’t customizable, but they do exhibit an extreme kind of behavior that’s good at catching out edge cases in protocol implementations.\n\n### API details\n\n### *`class`*` trio.testing.MemorySendStream(send_all_hook=None, wait_send_all_might_not_block_hook=None, close_hook=None)`\n\nAn in-memory [`SendStream`](reference-io#trio.abc.SendStream \"trio.abc.SendStream\").\n\n#### Parameters:\n\n- **send_all_hook** – An async function, or None. Called from [`send_all()`](#trio.testing.MemorySendStream.send_all \"trio.testing.MemorySendStream.send_all\"). Can do whatever you like.\n\n- **wait_send_all_might_not_block_hook** – An async function, or None. Called from [`wait_send_all_might_not_block()`](#trio.testing.MemorySendStream.wait_send_all_might_not_block \"trio.testing.MemorySendStream.wait_send_all_might_not_block\"). Can do whatever you like.\n\n- **close_hook** – A synchronous function, or None. Called from [`close()`](#trio.testing.MemorySendStream.close \"trio.testing.MemorySendStream.close\") and [`aclose()`](#trio.testing.MemorySendStream.aclose \"trio.testing.MemorySendStream.aclose\"). Can do whatever you like.\n\n### `send_all_hook`\n\n### `wait_send_all_might_not_block_hook`\n\n### `close_hook`\n\nAll of these hooks are also exposed as attributes on the object, and you can change them at any time.\n\n### *`await`*` aclose()`\n\nSame as [`close()`](#trio.testing.MemorySendStream.close \"trio.testing.MemorySendStream.close\"), but async.\n\n### `close()`\n\nMarks this stream as closed, and then calls the [`close_hook`](#trio.testing.MemorySendStream.close_hook \"trio.testing.MemorySendStream.close_hook\") (if any).\n\n### *`await`*` get_data(max_bytes=None)`\n\nRetrieves data from the internal buffer, blocking if necessary.\n\n#### Parameters:\n\n**max_bytes** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *None*) – The maximum amount of data to retrieve. None (the default) means to retrieve all the data that’s present (but still blocks until at least one byte is available).\n\n#### Returns:\n\nIf this stream has been closed, an empty bytearray. Otherwise, the requested data.\n\n### `get_data_nowait(max_bytes=None)`\n\nRetrieves data from the internal buffer, but doesn’t block.\n\nSee [`get_data()`](#trio.testing.MemorySendStream.get_data \"trio.testing.MemorySendStream.get_data\") for details.\n\n#### Raises:\n\n[**trio.WouldBlock**](reference-core#trio.WouldBlock \"trio.WouldBlock\") – if no data is available to retrieve.\n\n### *`await`*` send_all(data)`\n\nPlaces the given data into the object’s internal buffer, and then calls the [`send_all_hook`](#trio.testing.MemorySendStream.send_all_hook \"trio.testing.MemorySendStream.send_all_hook\") (if any).\n\n### *`await`*` wait_send_all_might_not_block()`\n\nCalls the [`wait_send_all_might_not_block_hook`](#trio.testing.MemorySendStream.wait_send_all_might_not_block_hook \"trio.testing.MemorySendStream.wait_send_all_might_not_block_hook\") (if any), and then returns immediately.\n\n### *`class`*` trio.testing.MemoryReceiveStream(receive_some_hook=None, close_hook=None)`\n\nAn in-memory [`ReceiveStream`](reference-io#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\").\n\n#### Parameters:\n\n- **receive_some_hook** – An async function, or None. Called from [`receive_some()`](#trio.testing.MemoryReceiveStream.receive_some \"trio.testing.MemoryReceiveStream.receive_some\"). Can do whatever you like.\n\n- **close_hook** – A synchronous function, or None. Called from [`close()`](#trio.testing.MemoryReceiveStream.close \"trio.testing.MemoryReceiveStream.close\") and [`aclose()`](#trio.testing.MemoryReceiveStream.aclose \"trio.testing.MemoryReceiveStream.aclose\"). Can do whatever you like.\n\n### `receive_some_hook`\n\n### `close_hook`\n\nBoth hooks are also exposed as attributes on the object, and you can change them at any time.\n\n### *`await`*` aclose()`\n\nSame as [`close()`](#trio.testing.MemoryReceiveStream.close \"trio.testing.MemoryReceiveStream.close\"), but async.\n\n### `close()`\n\nDiscards any pending data from the internal buffer, and marks this stream as closed.\n\n### `put_data(data)`\n\nAppends the given data to the internal buffer.\n\n### `put_eof()`\n\nAdds an end-of-file marker to the internal buffer.\n\n### *`await`*` receive_some(max_bytes=None)`\n\nCalls the [`receive_some_hook`](#trio.testing.MemoryReceiveStream.receive_some_hook \"trio.testing.MemoryReceiveStream.receive_some_hook\") (if any), and then retrieves data from the internal buffer, blocking if necessary.\n\n### `trio.testing.memory_stream_pump(memory_send_stream, memory_receive_stream, *, max_bytes=None)`\n\nTake data out of the given [`MemorySendStream`](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\")’s internal buffer, and put it into the given [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\")’s internal buffer.\n\n#### Parameters:\n\n- **memory_send_stream** ([*MemorySendStream*](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\")) – The stream to get data from.\n\n- **memory_receive_stream** ([*MemoryReceiveStream*](#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\")) – The stream to put data into.\n\n- **max_bytes** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *None*) – The maximum amount of data to transfer in this call, or None to transfer all available data.\n\n#### Returns:\n\nTrue if it successfully transferred some data, or False if there was no data to transfer.\n\nThis is used to implement [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair \"trio.testing.memory_stream_one_way_pair\") and [`memory_stream_pair()`](#trio.testing.memory_stream_pair \"trio.testing.memory_stream_pair\"); see the latter’s docstring for an example of how you might use it yourself.\n\n### `trio.testing.memory_stream_one_way_pair()`\n\nCreate a connected, pure-Python, unidirectional stream with infinite buffering and flexible configuration options.\n\nYou can think of this as being a no-operating-system-involved Trio-streamsified version of [`os.pipe()`](https://docs.python.org/3/library/os.html#os.pipe \"(in Python v3.11)\") (except that [`os.pipe()`](https://docs.python.org/3/library/os.html#os.pipe \"(in Python v3.11)\") returns the streams in the wrong order – we follow the superior convention that data flows from left to right).\n\n#### Returns:\n\nA tuple ([`MemorySendStream`](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\"), [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\")), where the [`MemorySendStream`](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\") has its hooks set up so that it calls [`memory_stream_pump()`](#trio.testing.memory_stream_pump \"trio.testing.memory_stream_pump\") from its [`send_all_hook`](#trio.testing.MemorySendStream.send_all_hook \"trio.testing.MemorySendStream.send_all_hook\") and [`close_hook`](#trio.testing.MemorySendStream.close_hook \"trio.testing.MemorySendStream.close_hook\").\n\nThe end result is that data automatically flows from the [`MemorySendStream`](#trio.testing.MemorySendStream \"trio.testing.MemorySendStream\") to the [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream \"trio.testing.MemoryReceiveStream\"). But you’re also free to rearrange things however you like. For example, you can temporarily set the [`send_all_hook`](#trio.testing.MemorySendStream.send_all_hook \"trio.testing.MemorySendStream.send_all_hook\") to None if you want to simulate a stall in data transmission. Or see [`memory_stream_pair()`](#trio.testing.memory_stream_pair \"trio.testing.memory_stream_pair\") for a more elaborate example.\n\n### `trio.testing.memory_stream_pair()`\n\nCreate a connected, pure-Python, bidirectional stream with infinite buffering and flexible configuration options.\n\nThis is a convenience function that creates two one-way streams using [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair \"trio.testing.memory_stream_one_way_pair\"), and then uses [`StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\") to combine them into a single bidirectional stream.\n\nThis is like a no-operating-system-involved, Trio-streamsified version of [`socket.socketpair()`](https://docs.python.org/3/library/socket.html#socket.socketpair \"(in Python v3.11)\").\n\n#### Returns:\n\nA pair of [`StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\") objects that are connected so that data automatically flows from one to the other in both directions.\n\nAfter creating a stream pair, you can send data back and forth, which is enough for simple tests:\n\n``` python\nleft, right = memory_stream_pair()\nawait left.send_all(b\"123\")\nassert await right.receive_some() == b\"123\"\nawait right.send_all(b\"456\")\nassert await left.receive_some() == b\"456\"\n```\n\nBut if you read the docs for [`StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\") and [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair \"trio.testing.memory_stream_one_way_pair\"), you’ll see that all the pieces involved in wiring this up are public APIs, so you can adjust to suit the requirements of your tests. For example, here’s how to tweak a stream so that data flowing from left to right trickles in one byte at a time (but data flowing from right to left proceeds at full speed):\n\n``` python\nleft, right = memory_stream_pair()\nasync def trickle():\n    # left is a StapledStream, and left.send_stream is a MemorySendStream\n    # right is a StapledStream, and right.recv_stream is a MemoryReceiveStream\n    while memory_stream_pump(left.send_stream, right.recv_stream, max_bytes=1):\n        # Pause between each byte\n        await trio.sleep(1)\n# Normally this send_all_hook calls memory_stream_pump directly without\n# passing in a max_bytes. We replace it with our custom version:\nleft.send_stream.send_all_hook = trickle\n```\n\nAnd here’s a simple test using our modified stream objects:\n\n``` python\nasync def sender():\n    await left.send_all(b\"12345\")\n    await left.send_eof()\n\nasync def receiver():\n    async for data in right:\n        print(data)\n\nasync with trio.open_nursery() as nursery:\n    nursery.start_soon(sender)\n    nursery.start_soon(receiver)\n```\n\nBy default, this will print `b\"12345\"` and then immediately exit; with our trickle stream it instead sleeps 1 second, then prints `b\"1\"`, then sleeps 1 second, then prints `b\"2\"`, etc.\n\nPro-tip: you can insert sleep calls (like in our example above) to manipulate the flow of data across tasks… and then use [`MockClock`](#trio.testing.MockClock \"trio.testing.MockClock\") and its [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold \"trio.testing.MockClock.autojump_threshold\") functionality to keep your test suite running quickly.\n\nIf you want to stress test a protocol implementation, one nice trick is to use the [`random`](https://docs.python.org/3/library/random.html#module-random \"(in Python v3.11)\") module (preferably with a fixed seed) to move random numbers of bytes at a time, and insert random sleeps in between them. You can also set up a custom [`receive_some_hook`](#trio.testing.MemoryReceiveStream.receive_some_hook \"trio.testing.MemoryReceiveStream.receive_some_hook\") if you want to manipulate things on the receiving side, and not just the sending side.\n\n### `trio.testing.lockstep_stream_one_way_pair()`\n\nCreate a connected, pure Python, unidirectional stream where data flows in lockstep.\n\n#### Returns:\n\nA tuple ([`SendStream`](reference-io#trio.abc.SendStream \"trio.abc.SendStream\"), [`ReceiveStream`](reference-io#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")).\n\nThis stream has *absolutely no* buffering. Each call to [`send_all()`](reference-io#trio.abc.SendStream.send_all \"trio.abc.SendStream.send_all\") will block until all the given data has been returned by a call to [`receive_some()`](reference-io#trio.abc.ReceiveStream.receive_some \"trio.abc.ReceiveStream.receive_some\").\n\nThis can be useful for testing flow control mechanisms in an extreme case, or for setting up “clogged” streams to use with [`check_one_way_stream()`](#trio.testing.check_one_way_stream \"trio.testing.check_one_way_stream\") and friends.\n\nIn addition to fulfilling the [`SendStream`](reference-io#trio.abc.SendStream \"trio.abc.SendStream\") and [`ReceiveStream`](reference-io#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\") interfaces, the return objects also have a synchronous `close` method.\n\n### `trio.testing.lockstep_stream_pair()`\n\nCreate a connected, pure-Python, bidirectional stream where data flows in lockstep.\n\n#### Returns:\n\nA tuple ([`StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\"), [`StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\")).\n\nThis is a convenience function that creates two one-way streams using [`lockstep_stream_one_way_pair()`](#trio.testing.lockstep_stream_one_way_pair \"trio.testing.lockstep_stream_one_way_pair\"), and then uses [`StapledStream`](reference-io#trio.StapledStream \"trio.StapledStream\") to combine them into a single bidirectional stream.\n\n### Testing custom stream implementations\n\nTrio also provides some functions to help you test your custom stream implementations:\n\n### *`await`*` trio.testing.check_one_way_stream(stream_maker, clogged_stream_maker)`\n\nPerform a number of generic tests on a custom one-way stream implementation.\n\n#### Parameters:\n\n- **stream_maker** – An async (!) function which returns a connected ([`SendStream`](reference-io#trio.abc.SendStream \"trio.abc.SendStream\"), [`ReceiveStream`](reference-io#trio.abc.ReceiveStream \"trio.abc.ReceiveStream\")) pair.\n\n- **clogged_stream_maker** – Either None, or an async function similar to stream_maker, but with the extra property that the returned stream is in a state where `send_all` and `wait_send_all_might_not_block` will block until `receive_some` has been called. This allows for more thorough testing of some edge cases, especially around `wait_send_all_might_not_block`.\n\n#### Raises:\n\n[**AssertionError**](https://docs.python.org/3/library/exceptions.html#AssertionError \"(in Python v3.11)\") – if a test fails.\n\n### *`await`*` trio.testing.check_two_way_stream(stream_maker, clogged_stream_maker)`\n\nPerform a number of generic tests on a custom two-way stream implementation.\n\nThis is similar to [`check_one_way_stream()`](#trio.testing.check_one_way_stream \"trio.testing.check_one_way_stream\"), except that the maker functions are expected to return objects implementing the [`Stream`](reference-io#trio.abc.Stream \"trio.abc.Stream\") interface.\n\nThis function tests a *superset* of what [`check_one_way_stream()`](#trio.testing.check_one_way_stream \"trio.testing.check_one_way_stream\") checks – if you call this, then you don’t need to also call [`check_one_way_stream()`](#trio.testing.check_one_way_stream \"trio.testing.check_one_way_stream\").\n\n### *`await`*` trio.testing.check_half_closeable_stream(stream_maker, clogged_stream_maker)`\n\nPerform a number of generic tests on a custom half-closeable stream implementation.\n\nThis is similar to [`check_two_way_stream()`](#trio.testing.check_two_way_stream \"trio.testing.check_two_way_stream\"), except that the maker functions are expected to return objects that implement the [`HalfCloseableStream`](reference-io#trio.abc.HalfCloseableStream \"trio.abc.HalfCloseableStream\") interface.\n\nThis function tests a *superset* of what [`check_two_way_stream()`](#trio.testing.check_two_way_stream \"trio.testing.check_two_way_stream\") checks – if you call this, then you don’t need to also call [`check_two_way_stream()`](#trio.testing.check_two_way_stream \"trio.testing.check_two_way_stream\").\n\n## Virtual networking for testing\n\nIn the previous section you learned how to use virtual in-memory streams to test protocols that are written against Trio’s [`Stream`](reference-io#trio.abc.Stream \"trio.abc.Stream\") abstraction. But what if you have more complicated networking code – the kind of code that makes connections to multiple hosts, or opens a listening socket, or sends UDP packets?\n\nTrio doesn’t itself provide a virtual in-memory network implementation for testing – but [`trio.socket`](reference-io#module-trio.socket \"trio.socket\") module does provide the hooks you need to write your own! And if you’re interested in helping implement a reusable virtual network for testing, then [please get in touch](https://github.com/python-trio/trio/issues/170).\n\nNote that these APIs are actually in [`trio.socket`](reference-io#module-trio.socket \"trio.socket\") and `trio.abc`, but we document them here because they’re primarily intended for testing.\n\n### `trio.socket.set_custom_hostname_resolver(hostname_resolver)`\n\nSet a custom hostname resolver.\n\nBy default, Trio’s [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") and [`getnameinfo()`](reference-io#trio.socket.getnameinfo \"trio.socket.getnameinfo\") functions use the standard system resolver functions. This function allows you to customize that behavior. The main intended use case is for testing, but it might also be useful for using third-party resolvers like [c-ares](https://c-ares.haxx.se/) (though be warned that these rarely make perfect drop-in replacements for the system resolver). See [`trio.abc.HostnameResolver`](#trio.abc.HostnameResolver \"trio.abc.HostnameResolver\") for more details.\n\nSetting a custom hostname resolver affects all future calls to [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") and [`getnameinfo()`](reference-io#trio.socket.getnameinfo \"trio.socket.getnameinfo\") within the enclosing call to [`trio.run()`](reference-core#trio.run \"trio.run\"). All other hostname resolution in Trio is implemented in terms of these functions.\n\nGenerally you should call this function just once, right at the beginning of your program.\n\n#### Parameters:\n\n**hostname_resolver** ([*trio.abc.HostnameResolver*](#trio.abc.HostnameResolver \"trio.abc.HostnameResolver\") *or* *None*) – The new custom hostname resolver, or None to restore the default behavior.\n\n#### Returns:\n\nThe previous hostname resolver (which may be None).\n\n### *`class`*` trio.abc.HostnameResolver`\n\nIf you have a custom hostname resolver, then implementing [`HostnameResolver`](#trio.abc.HostnameResolver \"trio.abc.HostnameResolver\") allows you to register this to be used by Trio.\n\nSee [`trio.socket.set_custom_hostname_resolver()`](#trio.socket.set_custom_hostname_resolver \"trio.socket.set_custom_hostname_resolver\").\n\n### *`abstractmethod await`*` getaddrinfo(host, port, family=0, type=0, proto=0, flags=0)`\n\nA custom implementation of [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\").\n\nCalled by [`trio.socket.getaddrinfo()`](reference-io#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\").\n\nIf `host` is given as a numeric IP address, then [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") may handle the request itself rather than calling this method.\n\nAny required IDNA encoding is handled before calling this function; your implementation can assume that it will never see U-labels like `\"café.com\"`, and only needs to handle A-labels like `b\"xn--caf-dma.com\"`.\n\n### *`abstractmethod await`*` getnameinfo(sockaddr, flags)`\n\nA custom implementation of [`getnameinfo()`](reference-io#trio.socket.getnameinfo \"trio.socket.getnameinfo\").\n\nCalled by [`trio.socket.getnameinfo()`](reference-io#trio.socket.getnameinfo \"trio.socket.getnameinfo\").\n\n### `trio.socket.set_custom_socket_factory(socket_factory)`\n\nSet a custom socket object factory.\n\nThis function allows you to replace Trio’s normal socket class with a custom class. This is very useful for testing, and probably a bad idea in any other circumstance. See [`trio.abc.HostnameResolver`](#trio.abc.HostnameResolver \"trio.abc.HostnameResolver\") for more details.\n\nSetting a custom socket factory affects all future calls to [`socket()`](reference-io#trio.socket.socket \"trio.socket.socket\") within the enclosing call to [`trio.run()`](reference-core#trio.run \"trio.run\").\n\nGenerally you should call this function just once, right at the beginning of your program.\n\n#### Parameters:\n\n**socket_factory** ([*trio.abc.SocketFactory*](#trio.abc.SocketFactory \"trio.abc.SocketFactory\") *or* *None*) – The new custom socket factory, or None to restore the default behavior.\n\n#### Returns:\n\nThe previous socket factory (which may be None).\n\n### *`class`*` trio.abc.SocketFactory`\n\nIf you write a custom class implementing the Trio socket interface, then you can use a [`SocketFactory`](#trio.abc.SocketFactory \"trio.abc.SocketFactory\") to get Trio to use it.\n\nSee [`trio.socket.set_custom_socket_factory()`](#trio.socket.set_custom_socket_factory \"trio.socket.set_custom_socket_factory\").\n\n### *`abstractmethod`*` socket(family=None, type=None, proto=None)`\n\nCreate and return a socket object.\n\nYour socket object must inherit from [`trio.socket.SocketType`](reference-io#trio.socket.SocketType \"trio.socket.SocketType\"), which is an empty class whose only purpose is to “mark” which classes should be considered valid Trio sockets.\n\nCalled by [`trio.socket.socket()`](reference-io#trio.socket.socket \"trio.socket.socket\").\n\nNote that unlike [`trio.socket.socket()`](reference-io#trio.socket.socket \"trio.socket.socket\"), this does not take a `fileno=` argument. If a `fileno=` is specified, then [`trio.socket.socket()`](reference-io#trio.socket.socket \"trio.socket.socket\") returns a regular Trio socket object instead of calling this method.\n\n## Testing checkpoints\n\n### *`with`*` trio.testing.assert_checkpoints()`\n\nUse as a context manager to check that the code inside the `with` block either exits with an exception or executes at least one [checkpoint](reference-core#checkpoints).\n\n#### Raises:\n\n[**AssertionError**](https://docs.python.org/3/library/exceptions.html#AssertionError \"(in Python v3.11)\") – if no checkpoint was executed.\n\nExample\n\nCheck that [`trio.sleep()`](reference-core#trio.sleep \"trio.sleep\") is a checkpoint, even if it doesn’t block:\n\n``` python\nwith trio.testing.assert_checkpoints():\n    await trio.sleep(0)\n```\n\n### *`with`*` trio.testing.assert_no_checkpoints()`\n\nUse as a context manager to check that the code inside the `with` block does not execute any [checkpoints](reference-core#checkpoints).\n\n#### Raises:\n\n[**AssertionError**](https://docs.python.org/3/library/exceptions.html#AssertionError \"(in Python v3.11)\") – if a checkpoint was executed.\n\nExample\n\nSynchronous code never contains any checkpoints, but we can double-check that:\n\n``` python\nsend_channel, receive_channel = trio.open_memory_channel(10)\nwith trio.testing.assert_no_checkpoints():\n    send_channel.send_nowait(None)\n```\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-testing.html](https://trio.readthedocs.io/en/v0.22.2/reference-testing.html)"
- name: total_tokens
  id: reference-core#trio.CapacityLimiter.total_tokens
  summary: The total capacity available
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` total_tokens`

    The total capacity available.

    You can change [`total_tokens`](#trio.CapacityLimiter.total_tokens "trio.CapacityLimiter.total_tokens") by assigning to this attribute. If you make it larger, then the appropriate number of waiting tasks will be woken immediately to take the new tokens. If you decrease total_tokens below the number of tasks that are currently using the resource, then all current tasks will be allowed to finish as normal, but no new tasks will be allowed in until the total number of tasks drops below the new total_tokens.
- name: trio.abc.AsyncResource
  id: reference-io#trio.abc.AsyncResource
  summary: A standard interface for resources that needs to be cleaned up, and where that cleanup may require blocking operations
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.AsyncResource`

    A standard interface for resources that needs to be cleaned up, and where that cleanup may require blocking operations.

    This class distinguishes between “graceful” closes, which may perform I/O and thus block, and a “forceful” close, which cannot. For example, cleanly shutting down a TLS-encrypted connection requires sending a “goodbye” message; but if a peer has become non-responsive, then sending this message might block forever, so we may want to just drop the connection instead. Therefore the [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") method is unusual in that it should always close the connection (or at least make its best attempt) *even if it fails*; failure indicates a failure to achieve grace, not a failure to close the connection.

    Objects that implement this interface can be used as async context managers, i.e., you can write:

    ``` python
    async with create_resource() as some_async_resource:
        ...
    ```

    Entering the context manager is synchronous (not a checkpoint); exiting it calls [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose"). The default implementations of `__aenter__` and `__aexit__` should be adequate for all subclasses.
- name: trio.abc.AsyncResource.aclose
  id: reference-io#trio.abc.AsyncResource.aclose
  summary: Close this resource, possibly blocking
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` aclose()`

    Close this resource, possibly blocking.

    IMPORTANT: This method may block in order to perform a “graceful” shutdown. But, if this fails, then it still *must* close any underlying resources before returning. An error from this method indicates a failure to achieve grace, *not* a failure to close the connection.

    For example, suppose we call [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") on a TLS-encrypted connection. This requires sending a “goodbye” message; but if the peer has become non-responsive, then our attempt to send this message might block forever, and eventually time out and be cancelled. In this case the [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") method on [`SSLStream`](#trio.SSLStream "trio.SSLStream") will immediately close the underlying transport stream using [`trio.aclose_forcefully()`](#trio.aclose_forcefully "trio.aclose_forcefully") before raising [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled").

    If the resource is already closed, then this method should silently succeed.

    Once this method completes, any other pending or future operations on this resource should generally raise [`ClosedResourceError`](reference-core#trio.ClosedResourceError "trio.ClosedResourceError"), unless there’s a good reason to do otherwise.

    See also: [`trio.aclose_forcefully()`](#trio.aclose_forcefully "trio.aclose_forcefully").
- name: trio.abc.Channel
  id: reference-io#trio.abc.Channel
  summary: A standard interface for interacting with bidirectional channels
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.Channel`

    Bases: [`SendChannel`](#trio.abc.SendChannel "trio.abc.SendChannel")\[`T`\], [`ReceiveChannel`](#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel")\[`T`\]

    A standard interface for interacting with bidirectional channels.

    A [`Channel`](#trio.abc.Channel "trio.abc.Channel") is an object that implements both the [`SendChannel`](#trio.abc.SendChannel "trio.abc.SendChannel") and [`ReceiveChannel`](#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel") interfaces, so you can both send and receive objects.

    ### Generic stream tools

    Trio currently provides a generic helper for writing servers that listen for connections using one or more [`Listener`](#trio.abc.Listener "trio.abc.Listener")s, and a generic utility class for working with streams. And if you want to test code that’s written against the streams interface, you should also check out [Streams](reference-testing#testing-streams) in [`trio.testing`](reference-testing#module-trio.testing "trio.testing").
- name: trio.abc.Clock
  id: reference-core#trio.abc.Clock
  summary: The interface for custom run loop clocks
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.abc.Clock`

    The interface for custom run loop clocks.
- name: trio.abc.Clock.current_time
  id: reference-core#trio.abc.Clock.current_time
  summary: Return the current time, according to this clock
  belongs_to: Trio’s core functionality
  description: |-
    ### *`abstractmethod`*` current_time()`

    Return the current time, according to this clock.

    This is used to implement functions like [`trio.current_time()`](#trio.current_time "trio.current_time") and [`trio.move_on_after()`](#trio.move_on_after "trio.move_on_after").

    #### Returns:

    The current time.

    #### Return type:

    [float](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")
- name: trio.abc.Clock.deadline_to_sleep_time
  id: reference-core#trio.abc.Clock.deadline_to_sleep_time
  summary: Compute the real time until the given deadline
  belongs_to: Trio’s core functionality
  description: |-
    ### *`abstractmethod`*` deadline_to_sleep_time(deadline)`

    Compute the real time until the given deadline.

    This is called before we enter a system-specific wait function like [`select.select()`](https://docs.python.org/3/library/select.html#select.select "(in Python v3.11)"), to get the timeout to pass.

    For a clock using wall-time, this should be something like:

    ``` python
    return deadline - self.current_time()
    ```

    but of course it may be different if you’re implementing some kind of virtual clock.

    #### Parameters:

    **deadline** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The absolute time of the next deadline, according to this clock.

    #### Returns:

    The number of real seconds to sleep until the given deadline. May be [`math.inf`](https://docs.python.org/3/library/math.html#math.inf "(in Python v3.11)").

    #### Return type:

    [float](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")
- name: trio.abc.Clock.start_clock
  id: reference-core#trio.abc.Clock.start_clock
  summary: Do any setup this clock might need
  belongs_to: Trio’s core functionality
  description: |-
    ### *`abstractmethod`*` start_clock()`

    Do any setup this clock might need.

    Called at the beginning of the run.

    ## Cancellation and timeouts

    Trio has a rich, composable system for cancelling work, either explicitly or when a timeout expires.

    ### A simple timeout example

    In the simplest case, you can apply a timeout to a block of code:

    ``` python
    with trio.move_on_after(30):
        result = await do_http_get("https://...")
        print("result is", result)
    print("with block finished")
    ```

    We refer to [`move_on_after()`](#trio.move_on_after "trio.move_on_after") as creating a “cancel scope”, which contains all the code that runs inside the `with` block. If the HTTP request takes more than 30 seconds to run, then it will be cancelled: we’ll abort the request and we *won’t* see `result``is``...` printed on the console; instead we’ll go straight to printing the `with``block``finished` message.

    > #### Note
    >
    > Note that this is a single 30 second timeout for the entire body of the `with` statement. This is different from what you might have seen with other Python libraries, where timeouts often refer to something [more complicated](https://requests.kennethreitz.org/en/master/user/quickstart/#timeouts). We think this way is easier to reason about.

    How does this work? There’s no magic here: Trio is built using ordinary Python functionality, so we can’t just abandon the code inside the `with` block. Instead, we take advantage of Python’s standard way of aborting a large and complex piece of code: we raise an exception.

    Here’s the idea: whenever you call a cancellable function like `await``trio.sleep(...)` or `await``sock.recv(...)` – see [Checkpoints](#checkpoints) – then the first thing that function does is to check if there’s a surrounding cancel scope whose timeout has expired, or otherwise been cancelled. If so, then instead of performing the requested operation, the function fails immediately with a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception. In this example, this probably happens somewhere deep inside the bowels of `do_http_get`. The exception then propagates out like any normal exception (you could even catch it if you wanted, but that’s generally a bad idea), until it reaches the `with``move_on_after(...):`. And at this point, the [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception has done its job – it’s successfully unwound the whole cancelled scope – so [`move_on_after()`](#trio.move_on_after "trio.move_on_after") catches it, and execution continues as normal after the `with` block. And this all works correctly even if you have nested cancel scopes, because every [`Cancelled`](#trio.Cancelled "trio.Cancelled") object carries an invisible marker that makes sure that the cancel scope that triggered it is the only one that will catch it.

    ### Handling cancellation

    Pretty much any code you write using Trio needs to have some strategy to handle [`Cancelled`](#trio.Cancelled "trio.Cancelled") exceptions – even if you didn’t set a timeout, then your caller might (and probably will).

    You can catch [`Cancelled`](#trio.Cancelled "trio.Cancelled"), but you shouldn’t! Or more precisely, if you do catch it, then you should do some cleanup and then re-raise it or otherwise let it continue propagating (unless you encounter an error, in which case it’s OK to let that propagate instead). To help remind you of this fact, [`Cancelled`](#trio.Cancelled "trio.Cancelled") inherits from [`BaseException`](https://docs.python.org/3/library/exceptions.html#BaseException "(in Python v3.11)"), like [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") and [`SystemExit`](https://docs.python.org/3/library/exceptions.html#SystemExit "(in Python v3.11)") do, so that it won’t be caught by catch-all `except``Exception:` blocks.

    It’s also important in any long-running code to make sure that you regularly check for cancellation, because otherwise timeouts won’t work! This happens implicitly every time you call a cancellable operation; see [below](#cancellable-primitives) for details. If you have a task that has to do a lot of work without any I/O, then you can use `await``sleep(0)` to insert an explicit cancel+schedule point.

    Here’s a rule of thumb for designing good Trio-style (“trionic”?) APIs: if you’re writing a reusable function, then you shouldn’t take a `timeout=` parameter, and instead let your caller worry about it. This has several advantages. First, it leaves the caller’s options open for deciding how they prefer to handle timeouts – for example, they might find it easier to work with absolute deadlines instead of relative timeouts. If they’re the ones calling into the cancellation machinery, then they get to pick, and you don’t have to worry about it. Second, and more importantly, this makes it easier for others to re-use your code. If you write a `http_get` function, and then I come along later and write a `log_in_to_twitter` function that needs to internally make several `http_get` calls, I don’t want to have to figure out how to configure the individual timeouts on each of those calls – and with Trio’s timeout system, it’s totally unnecessary.

    Of course, this rule doesn’t apply to APIs that need to impose internal timeouts. For example, if you write a `start_http_server` function, then you probably should give your caller some way to configure timeouts on individual requests.

    ### Cancellation semantics

    You can freely nest cancellation blocks, and each [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception “knows” which block it belongs to. So long as you don’t stop it, the exception will keep propagating until it reaches the block that raised it, at which point it will stop automatically.

    Here’s an example:

    ``` python
    print("starting...")
    with trio.move_on_after(5):
        with trio.move_on_after(10):
            await trio.sleep(20)
            print("sleep finished without error")
        print("move_on_after(10) finished without error")
    print("move_on_after(5) finished without error")
    ```

    In this code, the outer scope will expire after 5 seconds, causing the [`sleep()`](#trio.sleep "trio.sleep") call to return early with a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception. Then this exception will propagate through the `with``move_on_after(10)` line until it’s caught by the `with``move_on_after(5)` context manager. So this code will print:

        starting...
        move_on_after(5) finished without error

    The end result is that Trio has successfully cancelled exactly the work that was happening within the scope that was cancelled.

    Looking at this, you might wonder how you can tell whether the inner block timed out – perhaps you want to do something different, like try a fallback procedure or report a failure to our caller. To make this easier, [`move_on_after()`](#trio.move_on_after "trio.move_on_after")´s `__enter__` function returns an object representing this cancel scope, which we can use to check whether this scope caught a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception:

    ``` python
    with trio.move_on_after(5) as cancel_scope:
        await trio.sleep(10)
    print(cancel_scope.cancelled_caught)  # prints "True"
    ```

    The `cancel_scope` object also allows you to check or adjust this scope’s deadline, explicitly trigger a cancellation without waiting for the deadline, check if the scope has already been cancelled, and so forth – see [`CancelScope`](#trio.CancelScope "trio.CancelScope") below for the full details.

    Cancellations in Trio are “level triggered”, meaning that once a block has been cancelled, *all* cancellable operations in that block will keep raising [`Cancelled`](#trio.Cancelled "trio.Cancelled"). This helps avoid some pitfalls around resource clean-up. For example, imagine that we have a function that connects to a remote server and sends some messages, and then cleans up on the way out:

    ``` python
    with trio.move_on_after(TIMEOUT):
        conn = make_connection()
        try:
            await conn.send_hello_msg()
        finally:
            await conn.send_goodbye_msg()
    ```

    Now suppose that the remote server stops responding, so our call to `await``conn.send_hello_msg()` hangs forever. Fortunately, we were clever enough to put a timeout around this code, so eventually the timeout will expire and `send_hello_msg` will raise [`Cancelled`](#trio.Cancelled "trio.Cancelled"). But then, in the `finally` block, we make another blocking operation, which will also hang forever! At this point, if we were using [`asyncio`](https://docs.python.org/3/library/asyncio.html#module-asyncio "(in Python v3.11)") or another library with “edge-triggered” cancellation, we’d be in trouble: since our timeout already fired, it wouldn’t fire again, and at this point our application would lock up forever. But in Trio, this *doesn’t* happen: the `await``conn.send_goodbye_msg()` call is still inside the cancelled block, so it will also raise [`Cancelled`](#trio.Cancelled "trio.Cancelled").

    Of course, if you really want to make another blocking call in your cleanup handler, Trio will let you; it’s trying to prevent you from accidentally shooting yourself in the foot. Intentional foot-shooting is no problem (or at least – it’s not Trio’s problem). To do this, create a new scope, and set its [`shield`](#trio.CancelScope.shield "trio.CancelScope.shield") attribute to [`True`](https://docs.python.org/3/library/constants.html#True "(in Python v3.11)"):

    ``` python
    with trio.move_on_after(TIMEOUT):
        conn = make_connection()
        try:
            await conn.send_hello_msg()
        finally:
            with trio.move_on_after(CLEANUP_TIMEOUT) as cleanup_scope:
                cleanup_scope.shield = True
                await conn.send_goodbye_msg()
    ```

    So long as you’re inside a scope with `shield``=``True` set, then you’ll be protected from outside cancellations. Note though that this *only* applies to *outside* cancellations: if `CLEANUP_TIMEOUT` expires then `await``conn.send_goodbye_msg()` will still be cancelled, and if `await``conn.send_goodbye_msg()` call uses any timeouts internally, then those will continue to work normally as well. This is a pretty advanced feature that most people probably won’t use, but it’s there for the rare cases where you need it.

    ### Cancellation and primitive operations

    We’ve talked a lot about what happens when an operation is cancelled, and how you need to be prepared for this whenever calling a cancellable operation… but we haven’t gone into the details about which operations are cancellable, and how exactly they behave when they’re cancelled.

    Here’s the rule: if it’s in the `trio` namespace, and you use `await` to call it, then it’s cancellable (see [Checkpoints](#checkpoints) above). Cancellable means:

    - If you try to call it when inside a cancelled scope, then it will raise [`Cancelled`](#trio.Cancelled "trio.Cancelled").

    - If it blocks, and while it’s blocked then one of the scopes around it becomes cancelled, it will return early and raise [`Cancelled`](#trio.Cancelled "trio.Cancelled").

    - Raising [`Cancelled`](#trio.Cancelled "trio.Cancelled") means that the operation *did not happen*. If a Trio socket’s `send` method raises [`Cancelled`](#trio.Cancelled "trio.Cancelled"), then no data was sent. If a Trio socket’s `recv` method raises [`Cancelled`](#trio.Cancelled "trio.Cancelled") then no data was lost – it’s still sitting in the socket receive buffer waiting for you to call `recv` again. And so forth.

    There are a few idiosyncratic cases where external constraints make it impossible to fully implement these semantics. These are always documented. There is also one systematic exception:

    - Async cleanup operations – like `__aexit__` methods or async close methods – are cancellable just like anything else *except* that if they are cancelled, they still perform a minimum level of cleanup before raising [`Cancelled`](#trio.Cancelled "trio.Cancelled").

    For example, closing a TLS-wrapped socket normally involves sending a notification to the remote peer, so that they can be cryptographically assured that you really meant to close the socket, and your connection wasn’t just broken by a man-in-the-middle attacker. But handling this robustly is a bit tricky. Remember our [example](#blocking-cleanup-example) above where the blocking `send_goodbye_msg` caused problems? That’s exactly how closing a TLS socket works: if the remote peer has disappeared, then our code may never be able to actually send our shutdown notification, and it would be nice if it didn’t block forever trying. Therefore, the method for closing a TLS-wrapped socket will *try* to send that notification – and if it gets cancelled, then it will give up on sending the message, but *will* still close the underlying socket before raising [`Cancelled`](#trio.Cancelled "trio.Cancelled"), so at least you don’t leak that resource.

    ### Cancellation API details

    [`move_on_after()`](#trio.move_on_after "trio.move_on_after") and all the other cancellation facilities provided by Trio are ultimately implemented in terms of [`CancelScope`](#trio.CancelScope "trio.CancelScope") objects.
- name: trio.abc.HalfCloseableStream
  id: reference-io#trio.abc.HalfCloseableStream
  summary: This interface extends Stream to also allow closing the send part of the stream without closing the receive part
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.HalfCloseableStream`

    Bases: [`Stream`](#trio.abc.Stream "trio.abc.Stream")

    This interface extends [`Stream`](#trio.abc.Stream "trio.abc.Stream") to also allow closing the send part of the stream without closing the receive part.
- name: trio.abc.HalfCloseableStream.send_eof
  id: reference-io#trio.abc.HalfCloseableStream.send_eof
  summary: Send an end-of-file indication on this stream, if possible
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` send_eof()`

    Send an end-of-file indication on this stream, if possible.

    The difference between [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") and [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") is that [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") is a *unidirectional* end-of-file indication. After you call this method, you shouldn’t try sending any more data on this stream, and your remote peer should receive an end-of-file indication (eventually, after receiving all the data you sent before that). But, they may continue to send data to you, and you can continue to receive it by calling [`receive_some()`](#trio.abc.ReceiveStream.receive_some "trio.abc.ReceiveStream.receive_some"). You can think of it as calling [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") on just the [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream") “half” of the stream object (and in fact that’s literally how [`trio.StapledStream`](#trio.StapledStream "trio.StapledStream") implements it).

    Examples:

    - On a socket, this corresponds to `shutdown(...,``SHUT_WR)` ([man page](https://linux.die.net/man/2/shutdown)).

    - The SSH protocol provides the ability to multiplex bidirectional “channels” on top of a single encrypted connection. A Trio implementation of SSH could expose these channels as [`HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream") objects, and calling [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") would send an `SSH_MSG_CHANNEL_EOF` request (see [RFC 4254 §5.3](https://tools.ietf.org/html/rfc4254#section-5.3)).

    - On an SSL/TLS-encrypted connection, the protocol doesn’t provide any way to do a unidirectional shutdown without closing the connection entirely, so [`SSLStream`](#trio.SSLStream "trio.SSLStream") implements [`Stream`](#trio.abc.Stream "trio.abc.Stream"), not [`HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream").

    If an EOF has already been sent, then this method should silently succeed.

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if another task is already executing a [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block "trio.abc.SendStream.wait_send_all_might_not_block"), or [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") on this stream.

    - [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError "trio.BrokenResourceError") – if something has gone wrong, and the stream is broken.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this stream object, or if another task closes this stream object while [`send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") is running.
- name: trio.abc.HostnameResolver
  id: reference-testing#trio.abc.HostnameResolver
  summary: If you have a custom hostname resolver, then implementing HostnameResolver allows you to register this to be used by Trio
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`class`*` trio.abc.HostnameResolver`

    If you have a custom hostname resolver, then implementing [`HostnameResolver`](#trio.abc.HostnameResolver "trio.abc.HostnameResolver") allows you to register this to be used by Trio.

    See [`trio.socket.set_custom_hostname_resolver()`](#trio.socket.set_custom_hostname_resolver "trio.socket.set_custom_hostname_resolver").
- name: trio.abc.HostnameResolver.getaddrinfo
  id: reference-testing#trio.abc.HostnameResolver.getaddrinfo
  summary: A custom implementation of getaddrinfo()
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`abstractmethod await`*` getaddrinfo(host, port, family=0, type=0, proto=0, flags=0)`

    A custom implementation of [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo "trio.socket.getaddrinfo").

    Called by [`trio.socket.getaddrinfo()`](reference-io#trio.socket.getaddrinfo "trio.socket.getaddrinfo").

    If `host` is given as a numeric IP address, then [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo "trio.socket.getaddrinfo") may handle the request itself rather than calling this method.

    Any required IDNA encoding is handled before calling this function; your implementation can assume that it will never see U-labels like `"café.com"`, and only needs to handle A-labels like `b"xn--caf-dma.com"`.
- name: trio.abc.HostnameResolver.getnameinfo
  id: reference-testing#trio.abc.HostnameResolver.getnameinfo
  summary: A custom implementation of getnameinfo()
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`abstractmethod await`*` getnameinfo(sockaddr, flags)`

    A custom implementation of [`getnameinfo()`](reference-io#trio.socket.getnameinfo "trio.socket.getnameinfo").

    Called by [`trio.socket.getnameinfo()`](reference-io#trio.socket.getnameinfo "trio.socket.getnameinfo").
- name: trio.abc.Instrument
  id: reference-lowlevel#trio.abc.Instrument
  summary: The interface for run loop instrumentation
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.abc.Instrument`

    The interface for run loop instrumentation.

    Instruments don’t have to inherit from this abstract base class, and all of these methods are optional. This class serves mostly as documentation.
- name: trio.abc.Instrument.after_io_wait
  id: reference-lowlevel#trio.abc.Instrument.after_io_wait
  summary: Called after handling pending I/O
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `after_io_wait(timeout)`

    Called after handling pending I/O.

    #### Parameters:

    **timeout** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The number of seconds we were willing to wait. This much time may or may not have elapsed, depending on whether any I/O was ready.
- name: trio.abc.Instrument.after_run
  id: reference-lowlevel#trio.abc.Instrument.after_run
  summary: Called just before trio.run() returns
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `after_run()`

    Called just before [`trio.run()`](reference-core#trio.run "trio.run") returns.
- name: trio.abc.Instrument.after_task_step
  id: reference-lowlevel#trio.abc.Instrument.after_task_step
  summary: Called when we return to the main run loop after a task has yielded
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `after_task_step(task)`

    Called when we return to the main run loop after a task has yielded.

    #### Parameters:

    **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task "trio.lowlevel.Task")) – The task that just ran.
- name: trio.abc.Instrument.before_io_wait
  id: reference-lowlevel#trio.abc.Instrument.before_io_wait
  summary: Called before blocking to wait for I/O readiness
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `before_io_wait(timeout)`

    Called before blocking to wait for I/O readiness.

    #### Parameters:

    **timeout** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The number of seconds we are willing to wait.
- name: trio.abc.Instrument.before_run
  id: reference-lowlevel#trio.abc.Instrument.before_run
  summary: Called at the beginning of trio.run()
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `before_run()`

    Called at the beginning of [`trio.run()`](reference-core#trio.run "trio.run").
- name: trio.abc.Instrument.before_task_step
  id: reference-lowlevel#trio.abc.Instrument.before_task_step
  summary: Called immediately before we resume running the given task
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `before_task_step(task)`

    Called immediately before we resume running the given task.

    #### Parameters:

    **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task "trio.lowlevel.Task")) – The task that is about to run.
- name: trio.abc.Instrument.task_exited
  id: reference-lowlevel#trio.abc.Instrument.task_exited
  summary: Called when the given task exits
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `task_exited(task)`

    Called when the given task exits.

    #### Parameters:

    **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task "trio.lowlevel.Task")) – The finished task.
- name: trio.abc.Instrument.task_scheduled
  id: reference-lowlevel#trio.abc.Instrument.task_scheduled
  summary: Called when the given task becomes runnable
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `task_scheduled(task)`

    Called when the given task becomes runnable.

    It may still be some time before it actually runs, if there are other runnable tasks ahead of it.

    #### Parameters:

    **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task "trio.lowlevel.Task")) – The task that became runnable.
- name: trio.abc.Instrument.task_spawned
  id: reference-lowlevel#trio.abc.Instrument.task_spawned
  summary: Called when the given task is created
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `task_spawned(task)`

    Called when the given task is created.

    #### Parameters:

    **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task "trio.lowlevel.Task")) – The new task.

    The tutorial has a [fully-worked example](https://trio.readthedocs.io/en/v0.22.2/tutorial.html#tutorial-instrument-example) of defining a custom instrument to log Trio’s internal scheduling decisions.

    ## Low-level process spawning
- name: trio.abc.Listener
  id: reference-io#trio.abc.Listener
  summary: A standard interface for listening for incoming connections
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.Listener`

    Bases: [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource"), [`Generic`](https://docs.python.org/3/library/typing.html#typing.Generic "(in Python v3.11)")\[`T_resource`\]

    A standard interface for listening for incoming connections.

    [`Listener`](#trio.abc.Listener "trio.abc.Listener") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") interface, so they can be closed by calling [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") or using an `async``with` block.
- name: trio.abc.Listener.accept
  id: reference-io#trio.abc.Listener.accept
  summary: Wait until an incoming connection arrives, and then return it
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` accept()`

    Wait until an incoming connection arrives, and then return it.

    #### Returns:

    An object representing the incoming connection. In practice this is generally some kind of [`Stream`](#trio.abc.Stream "trio.abc.Stream"), but in principle you could also define a [`Listener`](#trio.abc.Listener "trio.abc.Listener") that returned, say, channel objects.

    #### Return type:

    [AsyncResource](#trio.abc.AsyncResource "trio.abc.AsyncResource")

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if two tasks attempt to call [`accept()`](#trio.abc.Listener.accept "trio.abc.Listener.accept") on the same listener at the same time.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this listener object, or if another task closes this listener object while [`accept()`](#trio.abc.Listener.accept "trio.abc.Listener.accept") is running.

    Listeners don’t generally raise [`BrokenResourceError`](reference-core#trio.BrokenResourceError "trio.BrokenResourceError"), because for listeners there is no general condition of “the network/remote peer broke the connection” that can be handled in a generic way, like there is for streams. Other errors *can* occur and be raised from [`accept()`](#trio.abc.Listener.accept "trio.abc.Listener.accept") – for example, if you run out of file descriptors then you might get an [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") with its errno set to `EMFILE`.
- name: trio.abc.ReceiveChannel
  id: reference-io#trio.abc.ReceiveChannel
  summary: A standard interface for receiving Python objects from some sender
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.ReceiveChannel`

    Bases: [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource"), [`Generic`](https://docs.python.org/3/library/typing.html#typing.Generic "(in Python v3.11)")\[`ReceiveType`\]

    A standard interface for receiving Python objects from some sender.

    You can iterate over a [`ReceiveChannel`](#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel") using an `async``for` loop:

    ``` python
    async for value in receive_channel:
        ...
    ```

    This is equivalent to calling [`receive()`](#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive") repeatedly. The loop exits without error when [`receive`](#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive") raises [`EndOfChannel`](reference-core#trio.EndOfChannel "trio.EndOfChannel").

    [`ReceiveChannel`](#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") interface, so they can be closed by calling [`aclose`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") or using an `async``with` block.

    If you want to receive raw bytes rather than Python objects, see [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream").
- name: trio.abc.ReceiveChannel.receive
  id: reference-io#trio.abc.ReceiveChannel.receive
  summary: Attempt to receive an incoming object, blocking if necessary
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` receive() → ReceiveType`

    Attempt to receive an incoming object, blocking if necessary.

    #### Returns:

    Whatever object was received.

    #### Return type:

    [object](https://docs.python.org/3/library/functions.html#object "(in Python v3.11)")

    #### Raises:

    - [**trio.EndOfChannel**](reference-core#trio.EndOfChannel "trio.EndOfChannel") – if the sender has been closed cleanly, and no more objects are coming. This is not an error condition.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this [`ReceiveChannel`](#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel") object.

    - [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError "trio.BrokenResourceError") – if something has gone wrong, and the channel is broken.

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – some channels allow multiple tasks to call [`receive`](#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive") at the same time, but others don’t. If you try to call [`receive`](#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive") simultaneously from multiple tasks on a channel that doesn’t support it, then you can get [`BusyResourceError`](reference-core#trio.BusyResourceError "trio.BusyResourceError").
- name: trio.abc.ReceiveStream
  id: reference-io#trio.abc.ReceiveStream
  summary: A standard interface for receiving data on a byte stream
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.ReceiveStream`

    Bases: [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource")

    A standard interface for receiving data on a byte stream.

    The underlying stream may be unidirectional, or bidirectional. If it’s bidirectional, then you probably want to also implement [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream"), which makes your object a [`Stream`](#trio.abc.Stream "trio.abc.Stream").

    [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") interface, so they can be closed by calling [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") or using an `async``with` block.

    If you want to receive Python objects rather than raw bytes, see [`ReceiveChannel`](#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel").

    [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream") objects can be used in `async``for` loops. Each iteration will produce an arbitrary sized chunk of bytes, like calling [`receive_some`](#trio.abc.ReceiveStream.receive_some "trio.abc.ReceiveStream.receive_some") with no arguments. Every chunk will contain at least one byte, and the loop automatically exits when reaching end-of-file.
- name: trio.abc.ReceiveStream.receive_some
  id: reference-io#trio.abc.ReceiveStream.receive_some
  summary: Wait until there is data available on this stream, and then return some of it
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` receive_some(max_bytes=None)`

    Wait until there is data available on this stream, and then return some of it.

    A return value of `b""` (an empty bytestring) indicates that the stream has reached end-of-file. Implementations should be careful that they return `b""` if, and only if, the stream has reached end-of-file!

    #### Parameters:

    **max_bytes** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The maximum number of bytes to return. Must be greater than zero. Optional; if omitted, then the stream object is free to pick a reasonable default.

    #### Returns:

    The data received.

    #### Return type:

    [bytes](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)") or [bytearray](https://docs.python.org/3/library/stdtypes.html#bytearray "(in Python v3.11)")

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if two tasks attempt to call [`receive_some()`](#trio.abc.ReceiveStream.receive_some "trio.abc.ReceiveStream.receive_some") on the same stream at the same time.

    - [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError "trio.BrokenResourceError") – if something has gone wrong, and the stream is broken.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this stream object, or if another task closes this stream object while [`receive_some()`](#trio.abc.ReceiveStream.receive_some "trio.abc.ReceiveStream.receive_some") is running.
- name: trio.abc.SendChannel
  id: reference-io#trio.abc.SendChannel
  summary: A standard interface for sending Python objects to some receiver
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.SendChannel`

    Bases: [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource"), [`Generic`](https://docs.python.org/3/library/typing.html#typing.Generic "(in Python v3.11)")\[`SendType`\]

    A standard interface for sending Python objects to some receiver.

    [`SendChannel`](#trio.abc.SendChannel "trio.abc.SendChannel") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") interface, so they can be closed by calling [`aclose`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") or using an `async``with` block.

    If you want to send raw bytes rather than Python objects, see [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream").
- name: trio.abc.SendChannel.send
  id: reference-io#trio.abc.SendChannel.send
  summary: Attempt to send an object through the channel, blocking if necessary
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` send(value: SendType) → None`

    Attempt to send an object through the channel, blocking if necessary.

    #### Parameters:

    **value** ([*object*](https://docs.python.org/3/library/functions.html#object "(in Python v3.11)")) – The object to send.

    #### Raises:

    - [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError "trio.BrokenResourceError") – if something has gone wrong, and the channel is broken. For example, you may get this if the receiver has already been closed.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this [`SendChannel`](#trio.abc.SendChannel "trio.abc.SendChannel") object, or if another task closes it while [`send()`](#trio.abc.SendChannel.send "trio.abc.SendChannel.send") is running.

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – some channels allow multiple tasks to call [`send`](#trio.abc.SendChannel.send "trio.abc.SendChannel.send") at the same time, but others don’t. If you try to call [`send`](#trio.abc.SendChannel.send "trio.abc.SendChannel.send") simultaneously from multiple tasks on a channel that doesn’t support it, then you can get [`BusyResourceError`](reference-core#trio.BusyResourceError "trio.BusyResourceError").
- name: trio.abc.SendStream
  id: reference-io#trio.abc.SendStream
  summary: A standard interface for sending data on a byte stream
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.SendStream`

    Bases: [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource")

    A standard interface for sending data on a byte stream.

    The underlying stream may be unidirectional, or bidirectional. If it’s bidirectional, then you probably want to also implement [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream"), which makes your object a [`Stream`](#trio.abc.Stream "trio.abc.Stream").

    [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream") objects also implement the [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") interface, so they can be closed by calling [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") or using an `async``with` block.

    If you want to send Python objects rather than raw bytes, see [`SendChannel`](#trio.abc.SendChannel "trio.abc.SendChannel").
- name: trio.abc.SendStream.send_all
  id: reference-io#trio.abc.SendStream.send_all
  summary: Sends the given data through the stream, blocking if necessary
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` send_all(data)`

    Sends the given data through the stream, blocking if necessary.

    #### Parameters:

    **data** ([*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")*,* [*bytearray*](https://docs.python.org/3/library/stdtypes.html#bytearray "(in Python v3.11)")*, or* [*memoryview*](https://docs.python.org/3/library/stdtypes.html#memoryview "(in Python v3.11)")) – The data to send.

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if another task is already executing a [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block "trio.abc.SendStream.wait_send_all_might_not_block"), or [`HalfCloseableStream.send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") on this stream.

    - [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError "trio.BrokenResourceError") – if something has gone wrong, and the stream is broken.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this stream object, or if another task closes this stream object while [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") is running.

    Most low-level operations in Trio provide a guarantee: if they raise [`trio.Cancelled`](reference-core#trio.Cancelled "trio.Cancelled"), this means that they had no effect, so the system remains in a known state. This is **not true** for [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all"). If this operation raises [`trio.Cancelled`](reference-core#trio.Cancelled "trio.Cancelled") (or any other exception for that matter), then it may have sent some, all, or none of the requested data, and there is no way to know which.
- name: trio.abc.SendStream.wait_send_all_might_not_block
  id: reference-io#trio.abc.SendStream.wait_send_all_might_not_block
  summary: Block until it’s possible that send_all() might not block
  belongs_to: I/O in Trio
  description: |-
    ### *`abstractmethod await`*` wait_send_all_might_not_block()`

    Block until it’s possible that [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") might not block.

    This method may return early: it’s possible that after it returns, [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") will still block. (In the worst case, if no better implementation is available, then it might always return immediately without blocking. It’s nice to do better than that when possible, though.)

    This method **must not** return *late*: if it’s possible for [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") to complete without blocking, then it must return. When implementing it, err on the side of returning early.

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if another task is already executing a [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all"), [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block "trio.abc.SendStream.wait_send_all_might_not_block"), or [`HalfCloseableStream.send_eof()`](#trio.abc.HalfCloseableStream.send_eof "trio.abc.HalfCloseableStream.send_eof") on this stream.

    - [**trio.BrokenResourceError**](reference-core#trio.BrokenResourceError "trio.BrokenResourceError") – if something has gone wrong, and the stream is broken.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you previously closed this stream object, or if another task closes this stream object while [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block "trio.abc.SendStream.wait_send_all_might_not_block") is running.

    > #### Note
    >
    > This method is intended to aid in implementing protocols that want to delay choosing which data to send until the last moment. E.g., suppose you’re working on an implementation of a remote display server like [VNC](https://en.wikipedia.org/wiki/Virtual_Network_Computing), and the network connection is currently backed up so that if you call [`send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") now then it will sit for 0.5 seconds before actually sending anything. In this case it doesn’t make sense to take a screenshot, then wait 0.5 seconds, and then send it, because the screen will keep changing while you wait; it’s better to wait 0.5 seconds, then take the screenshot, and then send it, because this way the data you deliver will be more up-to-date. Using [`wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block "trio.abc.SendStream.wait_send_all_might_not_block") makes it possible to implement the better strategy.
    >
    > If you use this method, you might also want to read up on `TCP_NOTSENT_LOWAT`.
    >
    > Further reading:
    >
    > - [Prioritization Only Works When There’s Pending Data to Prioritize](https://insouciant.org/tech/prioritization-only-works-when-theres-pending-data-to-prioritize/)
    >
    > - WWDC 2015: Your App and Next Generation Networks: [slides](http://devstreaming.apple.com/videos/wwdc/2015/719ui2k57m/719/719_your_app_and_next_generation_networks.pdf?dl=1), [video and transcript](https://developer.apple.com/videos/play/wwdc2015/719/)
- name: trio.abc.SocketFactory
  id: reference-testing#trio.abc.SocketFactory
  summary: If you write a custom class implementing the Trio socket interface, then you can use a SocketFactory to get Trio to use it
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`class`*` trio.abc.SocketFactory`

    If you write a custom class implementing the Trio socket interface, then you can use a [`SocketFactory`](#trio.abc.SocketFactory "trio.abc.SocketFactory") to get Trio to use it.

    See [`trio.socket.set_custom_socket_factory()`](#trio.socket.set_custom_socket_factory "trio.socket.set_custom_socket_factory").
- name: trio.abc.SocketFactory.socket
  id: reference-testing#trio.abc.SocketFactory.socket
  summary: Create and return a socket object
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`abstractmethod`*` socket(family=None, type=None, proto=None)`

    Create and return a socket object.

    Your socket object must inherit from [`trio.socket.SocketType`](reference-io#trio.socket.SocketType "trio.socket.SocketType"), which is an empty class whose only purpose is to “mark” which classes should be considered valid Trio sockets.

    Called by [`trio.socket.socket()`](reference-io#trio.socket.socket "trio.socket.socket").

    Note that unlike [`trio.socket.socket()`](reference-io#trio.socket.socket "trio.socket.socket"), this does not take a `fileno=` argument. If a `fileno=` is specified, then [`trio.socket.socket()`](reference-io#trio.socket.socket "trio.socket.socket") returns a regular Trio socket object instead of calling this method.

    ## Testing checkpoints
- name: trio.abc.Stream
  id: reference-io#trio.abc.Stream
  summary: A standard interface for interacting with bidirectional byte streams
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.abc.Stream`

    Bases: [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream"), [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream")

    A standard interface for interacting with bidirectional byte streams.

    A [`Stream`](#trio.abc.Stream "trio.abc.Stream") is an object that implements both the [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream") and [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream") interfaces.

    If implementing this interface, you should consider whether you can go one step further and implement [`HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream").
- name: trio.aclose_forcefully
  id: reference-io#trio.aclose_forcefully
  summary: Close an async resource or async generator immediately, without blocking to do any graceful cleanup
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.aclose_forcefully(resource)`

    Close an async resource or async generator immediately, without blocking to do any graceful cleanup.

    [`AsyncResource`](#trio.abc.AsyncResource "trio.abc.AsyncResource") objects guarantee that if their [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") method is cancelled, then they will still close the resource (albeit in a potentially ungraceful fashion). [`aclose_forcefully()`](#trio.aclose_forcefully "trio.aclose_forcefully") is a convenience function that exploits this behavior to let you force a resource to be closed without blocking: it works by calling `await``resource.aclose()` and then cancelling it immediately.

    Most users won’t need this, but it may be useful on cleanup paths where you can’t afford to block, or if you want to close a resource and don’t care about handling it gracefully. For example, if [`SSLStream`](#trio.SSLStream "trio.SSLStream") encounters an error and cannot perform its own graceful close, then there’s no point in waiting to gracefully shut down the underlying transport either, so it calls `await``aclose_forcefully(self.transport_stream)`.

    Note that this function is async, and that it acts as a checkpoint, but unlike most async functions it cannot block indefinitely (at least, assuming the underlying resource object is correctly implemented).
- name: trio.BrokenResourceError
  id: reference-core#trio.BrokenResourceError
  summary: Raised when an attempt to use a resource fails due to external circumstances
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.BrokenResourceError`

    Raised when an attempt to use a resource fails due to external circumstances.

    For example, you might get this if you try to send data on a stream where the remote side has already closed the connection.

    You *don’t* get this error if *you* closed the resource – in that case you get [`ClosedResourceError`](#trio.ClosedResourceError "trio.ClosedResourceError").

    This exception’s `__cause__` attribute will often contain more information about the underlying error.
- name: trio.BusyResourceError
  id: reference-core#trio.BusyResourceError
  summary: Raised when a task attempts to use a resource that some other task is already using, and this would lead to bugs and nonsense
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.BusyResourceError`

    Raised when a task attempts to use a resource that some other task is already using, and this would lead to bugs and nonsense.

    For example, if two tasks try to send data through the same socket at the same time, Trio will raise [`BusyResourceError`](#trio.BusyResourceError "trio.BusyResourceError") instead of letting the data get scrambled.
- name: trio.Cancelled
  id: reference-core#trio.Cancelled
  summary: Raised by blocking calls if the surrounding scope has been cancelled
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.Cancelled(*args: object, **kwargs: object)`

    Raised by blocking calls if the surrounding scope has been cancelled.

    You should let this exception propagate, to be caught by the relevant cancel scope. To remind you of this, it inherits from [`BaseException`](https://docs.python.org/3/library/exceptions.html#BaseException "(in Python v3.11)") instead of [`Exception`](https://docs.python.org/3/library/exceptions.html#Exception "(in Python v3.11)"), just like [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") and [`SystemExit`](https://docs.python.org/3/library/exceptions.html#SystemExit "(in Python v3.11)") do. This means that if you write something like:

    ``` python
    try:
        ...
    except Exception:
        ...
    ```

    then this *won’t* catch a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception.

    You cannot raise [`Cancelled`](#trio.Cancelled "trio.Cancelled") yourself. Attempting to do so will produce a [`TypeError`](https://docs.python.org/3/library/exceptions.html#TypeError "(in Python v3.11)"). Use [`cancel_scope.cancel()`](#trio.CancelScope.cancel "trio.CancelScope.cancel") instead.

    > #### Note
    >
    > In the US it’s also common to see this word spelled “canceled”, with only one “l”. This is a [recent](https://books.google.com/ngrams/graph?content=canceled%2Ccancelled&year_start=1800&year_end=2000&corpus=5&smoothing=3&direct_url=t1%3B%2Ccanceled%3B%2Cc0%3B.t1%3B%2Ccancelled%3B%2Cc0) and [US-specific](https://books.google.com/ngrams/graph?content=canceled%2Ccancelled&year_start=1800&year_end=2000&corpus=18&smoothing=3&share=&direct_url=t1%3B%2Ccanceled%3B%2Cc0%3B.t1%3B%2Ccancelled%3B%2Cc0) innovation, and even in the US both forms are still commonly used. So for consistency with the rest of the world and with “cancellation” (which always has two “l”s), Trio uses the two “l” spelling everywhere.
- name: trio.CancelScope
  id: reference-core#trio.CancelScope
  summary: 'A cancellation scope: the link between a unit of cancellable work and Trio’s cancellation system'
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.CancelScope(*, deadline: float = inf, shield: bool = False)`

    A *cancellation scope*: the link between a unit of cancellable work and Trio’s cancellation system.

    A [`CancelScope`](#trio.CancelScope "trio.CancelScope") becomes associated with some cancellable work when it is used as a context manager surrounding that work:

    ``` python
    cancel_scope = trio.CancelScope()
    ...
    with cancel_scope:
        await long_running_operation()
    ```

    Inside the `with` block, a cancellation of `cancel_scope` (via a call to its [`cancel()`](#trio.CancelScope.cancel "trio.CancelScope.cancel") method or via the expiry of its [`deadline`](#trio.CancelScope.deadline "trio.CancelScope.deadline")) will immediately interrupt the `long_running_operation()` by raising [`Cancelled`](#trio.Cancelled "trio.Cancelled") at its next [checkpoint](#checkpoints).

    The context manager `__enter__` returns the [`CancelScope`](#trio.CancelScope "trio.CancelScope") object itself, so you can also write `with``trio.CancelScope()``as``cancel_scope:`.

    If a cancel scope becomes cancelled before entering its `with` block, the [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception will be raised at the first checkpoint inside the `with` block. This allows a [`CancelScope`](#trio.CancelScope "trio.CancelScope") to be created in one [task](#tasks) and passed to another, so that the first task can later cancel some work inside the second.

    Cancel scopes are not reusable or reentrant; that is, each cancel scope can be used for at most one `with` block. (You’ll get a [`RuntimeError`](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") if you violate this rule.)

    The [`CancelScope`](#trio.CancelScope "trio.CancelScope") constructor takes initial values for the cancel scope’s [`deadline`](#trio.CancelScope.deadline "trio.CancelScope.deadline") and [`shield`](#trio.CancelScope.shield "trio.CancelScope.shield") attributes; these may be freely modified after construction, whether or not the scope has been entered yet, and changes take immediate effect.
- name: trio.CancelScope.cancel
  id: reference-core#trio.CancelScope.cancel
  summary: Cancels this scope immediately
  belongs_to: Trio’s core functionality
  description: |-
    ### `cancel()`

    Cancels this scope immediately.

    This method is idempotent, i.e., if the scope was already cancelled then this method silently does nothing.
- name: trio.CancelScope.cancel_called
  id: reference-core#trio.CancelScope.cancel_called
  summary: Readonly bool
  belongs_to: Trio’s core functionality
  description: |-
    ### `cancel_called`

    Readonly [`bool`](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)"). Records whether cancellation has been requested for this scope, either by an explicit call to [`cancel()`](#trio.CancelScope.cancel "trio.CancelScope.cancel") or by the deadline expiring.

    This attribute being True does *not* necessarily mean that the code within the scope has been, or will be, affected by the cancellation. For example, if [`cancel()`](#trio.CancelScope.cancel "trio.CancelScope.cancel") was called after the last checkpoint in the `with` block, when it’s too late to deliver a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception, then this attribute will still be True.

    This attribute is mostly useful for debugging and introspection. If you want to know whether or not a chunk of code was actually cancelled, then [`cancelled_caught`](#trio.CancelScope.cancelled_caught "trio.CancelScope.cancelled_caught") is usually more appropriate.

    Often there is no need to create [`CancelScope`](#trio.CancelScope "trio.CancelScope") object. Trio already includes [`cancel_scope`](#trio.Nursery.cancel_scope "trio.Nursery.cancel_scope") attribute in a task-related [`Nursery`](#trio.Nursery "trio.Nursery") object. We will cover nurseries later in the manual.

    Trio also provides several convenience functions for the common situation of just wanting to impose a timeout on some code:
- name: trio.CancelScope.cancelled_caught
  id: reference-core#trio.CancelScope.cancelled_caught
  summary: Readonly bool
  belongs_to: Trio’s core functionality
  description: |-
    ### `cancelled_caught`

    Readonly [`bool`](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)"). Records whether this scope caught a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception. This requires two things: (1) the `with` block exited with a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception, and (2) this scope is the one that was responsible for triggering this [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception.
- name: trio.CancelScope.deadline
  id: reference-core#trio.CancelScope.deadline
  summary: Read-write, float
  belongs_to: Trio’s core functionality
  description: |-
    ### `deadline`

    Read-write, [`float`](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)"). An absolute time on the current run’s clock at which this scope will automatically become cancelled. You can adjust the deadline by modifying this attribute, e.g.:

    ``` python
    # I need a little more time!
    cancel_scope.deadline += 30
    ```

    Note that for efficiency, the core run loop only checks for expired deadlines every once in a while. This means that in certain cases there may be a short delay between when the clock says the deadline should have expired, and when checkpoints start raising [`Cancelled`](#trio.Cancelled "trio.Cancelled"). This is a very obscure corner case that you’re unlikely to notice, but we document it for completeness. (If this *does* cause problems for you, of course, then [we want to know!](https://github.com/python-trio/trio/issues))

    Defaults to [`math.inf`](https://docs.python.org/3/library/math.html#math.inf "(in Python v3.11)"), which means “no deadline”, though this can be overridden by the `deadline=` argument to the [`CancelScope`](#trio.CancelScope "trio.CancelScope") constructor.
- name: trio.CancelScope.shield
  id: reference-core#trio.CancelScope.shield
  summary: Read-write, bool, default False
  belongs_to: Trio’s core functionality
  description: |-
    ### `shield`

    Read-write, [`bool`](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)"), default [`False`](https://docs.python.org/3/library/constants.html#False "(in Python v3.11)"). So long as this is set to [`True`](https://docs.python.org/3/library/constants.html#True "(in Python v3.11)"), then the code inside this scope will not receive [`Cancelled`](#trio.Cancelled "trio.Cancelled") exceptions from scopes that are outside this scope. They can still receive [`Cancelled`](#trio.Cancelled "trio.Cancelled") exceptions from (1) this scope, or (2) scopes inside this scope. You can modify this attribute:

    ``` python
    with trio.CancelScope() as cancel_scope:
        cancel_scope.shield = True
        # This cannot be interrupted by any means short of
        # killing the process:
        await sleep(10)

        cancel_scope.shield = False
        # Now this can be cancelled normally:
        await sleep(10)
    ```

    Defaults to [`False`](https://docs.python.org/3/library/constants.html#False "(in Python v3.11)"), though this can be overridden by the `shield=` argument to the [`CancelScope`](#trio.CancelScope "trio.CancelScope") constructor.
- name: trio.CapacityLimiter
  id: reference-core#trio.CapacityLimiter
  summary: An object for controlling access to a resource with limited capacity
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.CapacityLimiter(total_tokens)`

    An object for controlling access to a resource with limited capacity.

    Sometimes you need to put a limit on how many tasks can do something at the same time. For example, you might want to use some threads to run multiple blocking I/O operations in parallel… but if you use too many threads at once, then your system can become overloaded and it’ll actually make things slower. One popular solution is to impose a policy like “run up to 40 threads at the same time, but no more”. But how do you implement a policy like this?

    That’s what [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") is for. You can think of a [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") object as a sack that starts out holding some fixed number of tokens:

    ``` python
    limit = trio.CapacityLimiter(40)
    ```

    Then tasks can come along and borrow a token out of the sack:

    ``` python
    # Borrow a token:
    async with limit:
        # We are holding a token!
        await perform_expensive_operation()
    # Exiting the 'async with' block puts the token back into the sack
    ```

    And crucially, if you try to borrow a token but the sack is empty, then you have to wait for another task to finish what it’s doing and put its token back first before you can take it and continue.

    Another way to think of it: a [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") is like a sofa with a fixed number of seats, and if they’re all taken then you have to wait for someone to get up before you can sit down.

    By default, [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync "trio.to_thread.run_sync") uses a [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") to limit the number of threads running at once; see [`trio.to_thread.current_default_thread_limiter`](#trio.to_thread.current_default_thread_limiter "trio.to_thread.current_default_thread_limiter") for details.

    If you’re familiar with semaphores, then you can think of this as a restricted semaphore that’s specialized for one common use case, with additional error checking. For a more traditional semaphore, see [`Semaphore`](#trio.Semaphore "trio.Semaphore").

    > #### Note
    >
    > Don’t confuse this with the [“leaky bucket”](https://en.wikipedia.org/wiki/Leaky_bucket) or [“token bucket”](https://en.wikipedia.org/wiki/Token_bucket) algorithms used to limit bandwidth usage on networks. The basic idea of using tokens to track a resource limit is similar, but this is a very simple sack where tokens aren’t automatically created or destroyed over time; they’re just borrowed and then put back.
- name: trio.CapacityLimiter.acquire
  id: reference-core#trio.CapacityLimiter.acquire
  summary: Borrow a token from the sack, blocking if necessary
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` acquire()`

    Borrow a token from the sack, blocking if necessary.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the current task already holds one of this sack’s tokens.
- name: trio.CapacityLimiter.acquire_nowait
  id: reference-core#trio.CapacityLimiter.acquire_nowait
  summary: Borrow a token from the sack, without blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `acquire_nowait()`

    Borrow a token from the sack, without blocking.

    #### Raises:

    - [**WouldBlock**](#trio.WouldBlock "trio.WouldBlock") – if no tokens are available.

    - [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the current task already holds one of this sack’s tokens.
- name: trio.CapacityLimiter.acquire_on_behalf_of
  id: reference-core#trio.CapacityLimiter.acquire_on_behalf_of
  summary: Borrow a token from the sack on behalf of borrower, blocking if necessary
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` acquire_on_behalf_of(borrower)`

    Borrow a token from the sack on behalf of `borrower`, blocking if necessary.

    #### Parameters:

    **borrower** – A [`trio.lowlevel.Task`](reference-lowlevel#trio.lowlevel.Task "trio.lowlevel.Task") or arbitrary opaque object used to record who is borrowing this token; see [`acquire_on_behalf_of_nowait()`](#trio.CapacityLimiter.acquire_on_behalf_of_nowait "trio.CapacityLimiter.acquire_on_behalf_of_nowait") for details.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if `borrower` task already holds one of this sack’s tokens.
- name: trio.CapacityLimiter.acquire_on_behalf_of_nowait
  id: reference-core#trio.CapacityLimiter.acquire_on_behalf_of_nowait
  summary: Borrow a token from the sack on behalf of borrower, without blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `acquire_on_behalf_of_nowait(borrower)`

    Borrow a token from the sack on behalf of `borrower`, without blocking.

    #### Parameters:

    **borrower** – A [`trio.lowlevel.Task`](reference-lowlevel#trio.lowlevel.Task "trio.lowlevel.Task") or arbitrary opaque object used to record who is borrowing this token. This is used by [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync "trio.to_thread.run_sync") to allow threads to “hold tokens”, with the intention in the future of using it to [allow deadlock detection and other useful things](https://github.com/python-trio/trio/issues/182)

    #### Raises:

    - [**WouldBlock**](#trio.WouldBlock "trio.WouldBlock") – if no tokens are available.

    - [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if `borrower` already holds one of this sack’s tokens.
- name: trio.CapacityLimiter.release
  id: reference-core#trio.CapacityLimiter.release
  summary: Put a token back into the sack
  belongs_to: Trio’s core functionality
  description: |-
    ### `release()`

    Put a token back into the sack.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the current task has not acquired one of this sack’s tokens.
- name: trio.CapacityLimiter.release_on_behalf_of
  id: reference-core#trio.CapacityLimiter.release_on_behalf_of
  summary: Put a token back into the sack on behalf of borrower
  belongs_to: Trio’s core functionality
  description: |-
    ### `release_on_behalf_of(borrower)`

    Put a token back into the sack on behalf of `borrower`.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the given borrower has not acquired one of this sack’s tokens.
- name: trio.CapacityLimiter.statistics
  id: reference-core#trio.CapacityLimiter.statistics
  summary: Return an object containing debugging information
  belongs_to: Trio’s core functionality
  description: |-
    ### `statistics()`

    Return an object containing debugging information.

    Currently the following fields are defined:

    - `borrowed_tokens`: The number of tokens currently borrowed from the sack.

    - `total_tokens`: The total number of tokens in the sack. Usually this will be larger than `borrowed_tokens`, but it’s possibly for it to be smaller if [`total_tokens`](#trio.CapacityLimiter.total_tokens "trio.CapacityLimiter.total_tokens") was recently decreased.

    - `borrowers`: A list of all tasks or other entities that currently hold a token.

    - `tasks_waiting`: The number of tasks blocked on this [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter")’s [`acquire()`](#trio.CapacityLimiter.acquire "trio.CapacityLimiter.acquire") or [`acquire_on_behalf_of()`](#trio.CapacityLimiter.acquire_on_behalf_of "trio.CapacityLimiter.acquire_on_behalf_of") methods.
- name: trio.ClosedResourceError
  id: reference-core#trio.ClosedResourceError
  summary: Raised when attempting to use a resource after it has been closed
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.ClosedResourceError`

    Raised when attempting to use a resource after it has been closed.

    Note that “closed” here means that *your* code closed the resource, generally by calling a method with a name like `close` or `aclose`, or by exiting a context manager. If a problem arises elsewhere – for example, because of a network failure, or because a remote peer closed their end of a connection – then that should be indicated by a different exception class, like [`BrokenResourceError`](#trio.BrokenResourceError "trio.BrokenResourceError") or an [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") subclass.
- name: trio.Condition
  id: reference-core#trio.Condition
  summary: A classic condition variable, similar to threading.Condition
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.Condition(lock=None)`

    A classic [condition variable](https://en.wikipedia.org/wiki/Monitor_(synchronization)), similar to [`threading.Condition`](https://docs.python.org/3/library/threading.html#threading.Condition "(in Python v3.11)").

    A [`Condition`](#trio.Condition "trio.Condition") object can be used as an async context manager to acquire the underlying lock; it blocks on entry but not on exit.

    #### Parameters:

    **lock** ([*Lock*](#trio.Lock "trio.Lock")) – the lock object to use. If given, must be a [`trio.Lock`](#trio.Lock "trio.Lock"). If None, a new [`Lock`](#trio.Lock "trio.Lock") will be allocated and used.
- name: trio.Condition.acquire
  id: reference-core#trio.Condition.acquire
  summary: Acquire the underlying lock, blocking if necessary
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` acquire()`

    Acquire the underlying lock, blocking if necessary.
- name: trio.Condition.acquire_nowait
  id: reference-core#trio.Condition.acquire_nowait
  summary: Attempt to acquire the underlying lock, without blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `acquire_nowait()`

    Attempt to acquire the underlying lock, without blocking.

    #### Raises:

    [**WouldBlock**](#trio.WouldBlock "trio.WouldBlock") – if the lock is currently held.
- name: trio.Condition.locked
  id: reference-core#trio.Condition.locked
  summary: Check whether the underlying lock is currently held
  belongs_to: Trio’s core functionality
  description: |-
    ### `locked()`

    Check whether the underlying lock is currently held.

    #### Returns:

    True if the lock is held, False otherwise.

    #### Return type:

    [bool](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")
- name: trio.Condition.notify
  id: reference-core#trio.Condition.notify
  summary: Wake one or more tasks that are blocked in wait()
  belongs_to: Trio’s core functionality
  description: |-
    ### `notify(n=1)`

    Wake one or more tasks that are blocked in [`wait()`](#trio.Condition.wait "trio.Condition.wait").

    #### Parameters:

    **n** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The number of tasks to wake.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the calling task does not hold the lock.
- name: trio.Condition.notify_all
  id: reference-core#trio.Condition.notify_all
  summary: Wake all tasks that are currently blocked in wait()
  belongs_to: Trio’s core functionality
  description: |-
    ### `notify_all()`

    Wake all tasks that are currently blocked in [`wait()`](#trio.Condition.wait "trio.Condition.wait").

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the calling task does not hold the lock.
- name: trio.Condition.release
  id: reference-core#trio.Condition.release
  summary: Release the underlying lock
  belongs_to: Trio’s core functionality
  description: |-
    ### `release()`

    Release the underlying lock.
- name: trio.Condition.statistics
  id: reference-core#trio.Condition.statistics
  summary: Return an object containing debugging information
  belongs_to: Trio’s core functionality
  description: |-
    ### `statistics()`

    Return an object containing debugging information.

    Currently the following fields are defined:

    - `tasks_waiting`: The number of tasks blocked on this condition’s [`wait()`](#trio.Condition.wait "trio.Condition.wait") method.

    - `lock_statistics`: The result of calling the underlying [`Lock`](#trio.Lock "trio.Lock")s [`statistics()`](#trio.Lock.statistics "trio.Lock.statistics") method.
- name: trio.Condition.wait
  id: reference-core#trio.Condition.wait
  summary: Wait for another task to call notify() or notify_all()
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` wait()`

    Wait for another task to call [`notify()`](#trio.Condition.notify "trio.Condition.notify") or [`notify_all()`](#trio.Condition.notify_all "trio.Condition.notify_all").

    When calling this method, you must hold the lock. It releases the lock while waiting, and then re-acquires it before waking up.

    There is a subtlety with how this method interacts with cancellation: when cancelled it will block to re-acquire the lock before raising [`Cancelled`](#trio.Cancelled "trio.Cancelled"). This may cause cancellation to be less prompt than expected. The advantage is that it makes code like this work:

    ``` python
    async with condition:
        await condition.wait()
    ```

    If we didn’t re-acquire the lock before waking up, and [`wait()`](#trio.Condition.wait "trio.Condition.wait") were cancelled here, then we’d crash in `condition.__aexit__` when we tried to release the lock we no longer held.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the calling task does not hold the lock.

    ## Notes on async generators

    Python 3.6 added support for *async generators*, which can use `await`, `async``for`, and `async``with` in between their `yield` statements. As you might expect, you use `async``for` to iterate over them. [**PEP 525**](https://peps.python.org/pep-0525/) has many more details if you want them.

    For example, the following is a roundabout way to print the numbers 0 through 9 with a 1-second delay before each one:

    ``` python
    async def range_slowly(*args):
        """Like range(), but adds a 1-second sleep before each value."""
        for value in range(*args):
            await trio.sleep(1)
            yield value

    async def use_it():
        async for value in range_slowly(10):
            print(value)

    trio.run(use_it)
    ```

    Trio supports async generators, with some caveats described in this section.

    ### Finalization

    If you iterate over an async generator in its entirety, like the example above does, then the execution of the async generator will occur completely in the context of the code that’s iterating over it, and there aren’t too many surprises.

    If you abandon a partially-completed async generator, though, such as by `break`ing out of the iteration, things aren’t so simple. The async generator iterator object is still alive, waiting for you to resume iterating it so it can produce more values. At some point, Python will realize that you’ve dropped all references to the iterator, and will call on Trio to throw in a [`GeneratorExit`](https://docs.python.org/3/library/exceptions.html#GeneratorExit "(in Python v3.11)") exception so that any remaining cleanup code inside the generator has a chance to run: `finally` blocks, `__aexit__` handlers, and so on.

    So far, so good. Unfortunately, Python provides no guarantees about *when* this happens. It could be as soon as you break out of the `async``for` loop, or an arbitrary amount of time later. It could even be after the entire Trio run has finished! Just about the only guarantee is that it *won’t* happen in the task that was using the generator. That task will continue on with whatever else it’s doing, and the async generator cleanup will happen “sometime later, somewhere else”: potentially with different context variables, not subject to timeouts, and/or after any nurseries you’re using have been closed.

    If you don’t like that ambiguity, and you want to ensure that a generator’s `finally` blocks and `__aexit__` handlers execute as soon as you’re done using it, then you’ll need to wrap your use of the generator in something like [async_generator.aclosing()](https://async-generator.readthedocs.io/en/latest/reference.html#context-managers):

    ``` python
    # Instead of this:
    async for value in my_generator():
        if value == 42:
            break

    # Do this:
    async with aclosing(my_generator()) as aiter:
        async for value in aiter:
            if value == 42:
                break
    ```

    This is cumbersome, but Python unfortunately doesn’t provide any other reliable options. If you use `aclosing()`, then your generator’s cleanup code executes in the same context as the rest of its iterations, so timeouts, exceptions, and context variables work like you’d expect.

    If you don’t use `aclosing()`, then Trio will do its best anyway, but you’ll have to contend with the following semantics:

    - The cleanup of the generator occurs in a cancelled context, i.e., all blocking calls executed during cleanup will raise [`Cancelled`](#trio.Cancelled "trio.Cancelled"). This is to compensate for the fact that any timeouts surrounding the original use of the generator have been long since forgotten.

    - The cleanup runs without access to any [context variables](#task-local-storage) that may have been present when the generator was originally being used.

    - If the generator raises an exception during cleanup, then it’s printed to the `trio.async_generator_errors` logger and otherwise ignored.

    - If an async generator is still alive at the end of the whole call to [`trio.run()`](#trio.run "trio.run"), then it will be cleaned up after all tasks have exited and before [`trio.run()`](#trio.run "trio.run") returns. Since the “system nursery” has already been closed at this point, Trio isn’t able to support any new calls to [`trio.lowlevel.spawn_system_task()`](reference-lowlevel#trio.lowlevel.spawn_system_task "trio.lowlevel.spawn_system_task").

    If you plan to run your code on PyPy to take advantage of its better performance, you should be aware that PyPy is *far more likely* than CPython to perform async generator cleanup at a time well after the last use of the generator. (This is a consequence of the fact that PyPy does not use reference counting to manage memory.) To help catch issues like this, Trio will issue a [`ResourceWarning`](https://docs.python.org/3/library/exceptions.html#ResourceWarning "(in Python v3.11)") (ignored by default, but enabled when running under `python``-X``dev` for example) for each async generator that needs to be handled through the fallback finalization path.

    ### Cancel scopes and nurseries

    > #### Warning
    >
    > You may not write a `yield` statement that suspends an async generator inside a [`CancelScope`](#trio.CancelScope "trio.CancelScope") or [`Nursery`](#trio.Nursery "trio.Nursery") that was entered within the generator.

    That is, this is OK:

    ``` python
    async def some_agen():
        with trio.move_on_after(1):
            await long_operation()
        yield "first"
        async with trio.open_nursery() as nursery:
            nursery.start_soon(task1)
            nursery.start_soon(task2)
        yield "second"
        ...
    ```

    But this is not:

    ``` python
    async def some_agen():
        with trio.move_on_after(1):
            yield "first"
        async with trio.open_nursery() as nursery:
            yield "second"
        ...
    ```

    Async generators decorated with `@asynccontextmanager` to serve as the template for an async context manager are *not* subject to this constraint, because `@asynccontextmanager` uses them in a limited way that doesn’t create problems.

    Violating the rule described in this section will sometimes get you a useful error message, but Trio is not able to detect all such cases, so sometimes you’ll get an unhelpful [`TrioInternalError`](#trio.TrioInternalError "trio.TrioInternalError"). (And sometimes it will seem to work, which is probably the worst outcome of all, since then you might not notice the issue until you perform some minor refactoring of the generator or the code that’s iterating it, or just get unlucky. There is a [proposed Python enhancement](https://discuss.python.org/t/preventing-yield-inside-certain-context-managers/1091) that would at least make it fail consistently.)

    The reason for the restriction on cancel scopes has to do with the difficulty of noticing when a generator gets suspended and resumed. The cancel scopes inside the generator shouldn’t affect code running outside the generator, but Trio isn’t involved in the process of exiting and reentering the generator, so it would be hard pressed to keep its cancellation plumbing in the correct state. Nurseries use a cancel scope internally, so they have all the problems of cancel scopes plus a number of problems of their own: for example, when the generator is suspended, what should the background tasks do? There’s no good way to suspend them, but if they keep running and throw an exception, where can that exception be reraised?

    If you have an async generator that wants to `yield` from within a nursery or cancel scope, your best bet is to refactor it to be a separate task that communicates over memory channels. The `trio_util` package offers a [decorator that does this for you transparently](https://trio-util.readthedocs.io/en/latest/#trio_util.trio_async_generator).

    For more discussion, see Trio issues [264](https://github.com/python-trio/trio/issues/264) (especially [this comment](https://github.com/python-trio/trio/issues/264#issuecomment-418989328)) and [638](https://github.com/python-trio/trio/issues/638).

    ## Threads (if you must)

    In a perfect world, all third-party libraries and low-level APIs would be natively async and integrated into Trio, and all would be happiness and rainbows.

    That world, alas, does not (yet) exist. Until it does, you may find yourself needing to interact with non-Trio APIs that do rude things like “blocking”.

    In acknowledgment of this reality, Trio provides two useful utilities for working with real, operating-system level, [`threading`](https://docs.python.org/3/library/threading.html#module-threading "(in Python v3.11)")-module-style threads. First, if you’re in Trio but need to push some blocking I/O into a thread, there’s [`trio.to_thread.run_sync`](#trio.to_thread.run_sync "trio.to_thread.run_sync"). And if you’re in a thread and need to communicate back with Trio, you can use [`trio.from_thread.run()`](#trio.from_thread.run "trio.from_thread.run") and [`trio.from_thread.run_sync()`](#trio.from_thread.run_sync "trio.from_thread.run_sync").

    ### Trio’s philosophy about managing worker threads

    If you’ve used other I/O frameworks, you may have encountered the concept of a “thread pool”, which is most commonly implemented as a fixed size collection of threads that hang around waiting for jobs to be assigned to them. These solve two different problems: First, re-using the same threads over and over is more efficient than starting and stopping a new thread for every job you need done; basically, the pool acts as a kind of cache for idle threads. And second, having a fixed size avoids getting into a situation where 100,000 jobs are submitted simultaneously, and then 100,000 threads are spawned and the system gets overloaded and crashes. Instead, the N threads start executing the first N jobs, while the other (100,000 - N) jobs sit in a queue and wait their turn. Which is generally what you want, and this is how [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync "trio.to_thread.run_sync") works by default.

    The downside of this kind of thread pool is that sometimes, you need more sophisticated logic for controlling how many threads are run at once. For example, you might want a policy like “at most 20 threads total, but no more than 3 of those can be running jobs associated with the same user account”, or you might want a pool whose size is dynamically adjusted over time in response to system conditions.

    It’s even possible for a fixed-size policy to cause unexpected [deadlocks](https://en.wikipedia.org/wiki/Deadlock). Imagine a situation where we have two different types of blocking jobs that you want to run in the thread pool, type A and type B. Type A is pretty simple: it just runs and completes pretty quickly. But type B is more complicated: it has to stop in the middle and wait for some other work to finish, and that other work includes running a type A job. Now, suppose you submit N jobs of type B to the pool. They all start running, and then eventually end up submitting one or more jobs of type A. But since every thread in our pool is already busy, the type A jobs don’t actually start running – they just sit in a queue waiting for the type B jobs to finish. But the type B jobs will never finish, because they’re waiting for the type A jobs. Our system has deadlocked. The ideal solution to this problem is to avoid having type B jobs in the first place – generally it’s better to keep complex synchronization logic in the main Trio thread. But if you can’t do that, then you need a custom thread allocation policy that tracks separate limits for different types of jobs, and make it impossible for type B jobs to fill up all the slots that type A jobs need to run.

    So, we can see that it’s important to be able to change the policy controlling the allocation of threads to jobs. But in many frameworks, this requires implementing a new thread pool from scratch, which is highly non-trivial; and if different types of jobs need different policies, then you may have to create multiple pools, which is inefficient because now you effectively have two different thread caches that aren’t sharing resources.

    Trio’s solution to this problem is to split worker thread management into two layers. The lower layer is responsible for taking blocking I/O jobs and arranging for them to run immediately on some worker thread. It takes care of solving the tricky concurrency problems involved in managing threads and is responsible for optimizations like re-using threads, but has no admission control policy: if you give it 100,000 jobs, it will spawn 100,000 threads. The upper layer is responsible for providing the policy to make sure that this doesn’t happen – but since it *only* has to worry about policy, it can be much simpler. In fact, all there is to it is the `limiter=` argument passed to [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync "trio.to_thread.run_sync"). This defaults to a global [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") object, which gives us the classic fixed-size thread pool behavior. (See [`trio.to_thread.current_default_thread_limiter()`](#trio.to_thread.current_default_thread_limiter "trio.to_thread.current_default_thread_limiter").) But if you want to use “separate pools” for type A jobs and type B jobs, then it’s just a matter of creating two separate [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") objects and passing them in when running these jobs. Or here’s an example of defining a custom policy that respects the global thread limit, while making sure that no individual user can use more than 3 threads at a time:

    ``` python
    class CombinedLimiter:
         def __init__(self, first, second):
             self._first = first
             self._second = second

         async def acquire_on_behalf_of(self, borrower):
             # Acquire both, being careful to clean up properly on error
             await self._first.acquire_on_behalf_of(borrower)
             try:
                 await self._second.acquire_on_behalf_of(borrower)
             except:
                 self._first.release_on_behalf_of(borrower)
                 raise

         def release_on_behalf_of(self, borrower):
             # Release both, being careful to clean up properly on error
             try:
                 self._second.release_on_behalf_of(borrower)
             finally:
                 self._first.release_on_behalf_of(borrower)


    # Use a weak value dictionary, so that we don't waste memory holding
    # limiter objects for users who don't have any worker threads running.
    USER_LIMITERS = weakref.WeakValueDictionary()
    MAX_THREADS_PER_USER = 3

    def get_user_limiter(user_id):
        try:
            return USER_LIMITERS[user_id]
        except KeyError:
            per_user_limiter = trio.CapacityLimiter(MAX_THREADS_PER_USER)
            global_limiter = trio.current_default_thread_limiter()
            # IMPORTANT: acquire the per_user_limiter before the global_limiter.
            # If we get 100 jobs for a user at the same time, we want
            # to only allow 3 of them at a time to even compete for the
            # global thread slots.
            combined_limiter = CombinedLimiter(per_user_limiter, global_limiter)
            USER_LIMITERS[user_id] = combined_limiter
            return combined_limiter


    async def run_sync_in_thread_for_user(user_id, sync_fn, *args):
        combined_limiter = get_user_limiter(user_id)
        return await trio.to_thread.run_sync(sync_fn, *args, limiter=combined_limiter)
    ```

    ### Putting blocking I/O into worker threads
- name: trio.current_effective_deadline
  id: reference-core#trio.current_effective_deadline
  summary: Returns the current effective deadline for the current task
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.current_effective_deadline()`

    Returns the current effective deadline for the current task.

    This function examines all the cancellation scopes that are currently in effect (taking into account shielding), and returns the deadline that will expire first.

    One example of where this might be is useful is if your code is trying to decide whether to begin an expensive operation like an RPC call, but wants to skip it if it knows that it can’t possibly complete in the available time. Another example would be if you’re using a protocol like gRPC that [propagates timeout information to the remote peer](http://www.grpc.io/docs/guides/concepts.html#deadlines); this function gives a way to fetch that information so you can send it along.

    If this is called in a context where a cancellation is currently active (i.e., a blocking call will immediately raise [`Cancelled`](#trio.Cancelled "trio.Cancelled")), then returned deadline is `-inf`. If it is called in a context where no scopes have a deadline set, it returns `inf`.

    #### Returns:

    the effective deadline, as an absolute time.

    #### Return type:

    [float](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")

    ## Tasks let you do multiple things at once

    One of Trio’s core design principles is: *no implicit concurrency*. Every function executes in a straightforward, top-to-bottom manner, finishing each operation before moving on to the next – *like Guido intended*.

    But, of course, the entire point of an async library is to let you do multiple things at once. The one and only way to do that in Trio is through the task spawning interface. So if you want your program to walk *and* chew gum, this is the section for you.

    ### Nurseries and spawning

    Most libraries for concurrent programming let you start new child tasks (or threads, or whatever) willy-nilly, whenever and where-ever you feel like it. Trio is a bit different: you can’t start a child task unless you’re prepared to be a responsible parent. The way you demonstrate your responsibility is by creating a nursery:

    ``` python
    async with trio.open_nursery() as nursery:
        ...
    ```

    And once you have a reference to a nursery object, you can start children in that nursery:

    ``` python
    async def child():
        ...

    async def parent():
        async with trio.open_nursery() as nursery:
            # Make two concurrent calls to child()
            nursery.start_soon(child)
            nursery.start_soon(child)
    ```

    This means that tasks form a tree: when you call [`run()`](#trio.run "trio.run"), then this creates an initial task, and all your other tasks will be children, grandchildren, etc. of the initial task.

    Essentially, the body of the `async``with` block acts like an initial task that’s running inside the nursery, and then each call to `nursery.start_soon` adds another task that runs in parallel. Two crucial things to keep in mind:

    - If any task inside the nursery finishes with an unhandled exception, then the nursery immediately cancels all the tasks inside the nursery.

    - Since all of the tasks are running concurrently inside the `async``with` block, the block does not exit until *all* tasks have completed. If you’ve used other concurrency frameworks, then you can think of it as, the de-indentation at the end of the `async``with` automatically “joins” (waits for) all of the tasks in the nursery.

    - Once all the tasks have finished, then:

      - The nursery is marked as “closed”, meaning that no new tasks can be started inside it.

      - Any unhandled exceptions are re-raised inside the parent task. If there are multiple exceptions, then they’re collected up into a single [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup "(in Python v3.11)") or [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") exception.

    Since all tasks are descendents of the initial task, one consequence of this is that [`run()`](#trio.run "trio.run") can’t finish until all tasks have finished.

    > #### Note
    >
    > A return statement will not cancel the nursery if it still has tasks running:
    >
    > ``` python
    > async def main():
    >     async with trio.open_nursery() as nursery:
    >         nursery.start_soon(trio.sleep, 5)
    >         return
    >
    > trio.run(main)
    > ```
    >
    > This code will wait 5 seconds (for the child task to finish), and then return.

    ### Child tasks and cancellation

    In Trio, child tasks inherit the parent nursery’s cancel scopes. So in this example, both the child tasks will be cancelled when the timeout expires:

    ``` python
    with trio.move_on_after(TIMEOUT):
        async with trio.open_nursery() as nursery:
            nursery.start_soon(child1)
            nursery.start_soon(child2)
    ```

    Note that what matters here is the scopes that were active when [`open_nursery()`](#trio.open_nursery "trio.open_nursery") was called, *not* the scopes active when `start_soon` is called. So for example, the timeout block below does nothing at all:

    ``` python
    async with trio.open_nursery() as nursery:
        with trio.move_on_after(TIMEOUT):  # don't do this!
            nursery.start_soon(child)
    ```

    Why is this so? Well, `start_soon()` returns as soon as it has scheduled the new task to start running. The flow of execution in the parent then continues on to exit the `with``trio.move_on_after(TIMEOUT):` block, at which point Trio forgets about the timeout entirely. In order for the timeout to apply to the child task, Trio must be able to tell that its associated cancel scope will stay open for at least as long as the child task is executing. And Trio can only know that for sure if the cancel scope block is outside the nursery block.

    You might wonder why Trio can’t just remember “this task should be cancelled in `TIMEOUT` seconds”, even after the `with``trio.move_on_after(TIMEOUT):` block is gone. The reason has to do with [how cancellation is implemented](#cancellation). Recall that cancellation is represented by a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception, which eventually needs to be caught by the cancel scope that caused it. (Otherwise, the exception would take down your whole program!) In order to be able to cancel the child tasks, the cancel scope has to be able to “see” the [`Cancelled`](#trio.Cancelled "trio.Cancelled") exceptions that they raise – and those exceptions come out of the `async``with``open_nursery()` block, not out of the call to `start_soon()`.

    If you want a timeout to apply to one task but not another, then you need to put the cancel scope in that individual task’s function – `child()`, in this example.

    ### Errors in multiple child tasks

    Normally, in Python, only one thing happens at a time, which means that only one thing can wrong at a time. Trio has no such limitation. Consider code like:

    ``` python
    async def broken1():
        d = {}
        return d["missing"]

    async def broken2():
        seq = range(10)
        return seq[20]

    async def parent():
        async with trio.open_nursery() as nursery:
            nursery.start_soon(broken1)
            nursery.start_soon(broken2)
    ```

    `broken1` raises `KeyError`. `broken2` raises `IndexError`. Obviously `parent` should raise some error, but what? The answer is that both exceptions are grouped in an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)"). [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") and its parent class [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup "(in Python v3.11)") are used to encapsulate multiple exceptions being raised at once.

    To catch individual exceptions encapsulated in an exception group, the `except*` clause was introduced in Python 3.11 ([**PEP 654**](https://peps.python.org/pep-0654/)). Here’s how it works:

    ``` python
    try:
        async with trio.open_nursery() as nursery:
            nursery.start_soon(broken1)
            nursery.start_soon(broken2)
    except* KeyError as excgroup:
        for exc in excgroup.exceptions:
            ...  # handle each KeyError
    except* IndexError as excgroup:
        for exc in excgroup.exceptions:
            ...  # handle each IndexError
    ```

    If you want to reraise exceptions, or raise new ones, you can do so, but be aware that exceptions raised in `except*` sections will be raised together in a new exception group.

    But what if you can’t use `except*` just yet? Well, for that there is the handy [exceptiongroup](https://pypi.org/project/exceptiongroup/) library which lets you approximate this behavior with exception handler callbacks:

    ``` python
    from exceptiongroup import catch

    def handle_keyerrors(excgroup):
        for exc in excgroup.exceptions:
            ...  # handle each KeyError

    def handle_indexerrors(excgroup):
        for exc in excgroup.exceptions:
            ...  # handle each IndexError

    with catch({
        KeyError: handle_keyerrors,
        IndexError: handle_indexerrors
    }):
        async with trio.open_nursery() as nursery:
            nursery.start_soon(broken1)
            nursery.start_soon(broken2)
    ```

    The semantics for the handler functions are equal to `except*` blocks, except for setting local variables. If you need to set local variables, you need to declare them inside the handler function(s) with the `nonlocal` keyword:

    ``` python
    def handle_keyerrors(excgroup):
        nonlocal myflag
        myflag = True

    myflag = False
    with catch({KeyError: handle_keyerrors}):
        async with trio.open_nursery() as nursery:
            nursery.start_soon(broken1)
    ```

    For reasons of backwards compatibility, nurseries raise `trio.MultiError` and `trio.NonBaseMultiError` which inherit from [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup "(in Python v3.11)") and [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)"), respectively. Users should refrain from attempting to raise or catch the Trio specific exceptions themselves, and treat them as if they were standard [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup "(in Python v3.11)") or [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") instances instead.

    #### “Strict” versus “loose” ExceptionGroup semantics

    Ideally, in some abstract sense we’d want everything that *can* raise an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") to *always* raise an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") (rather than, say, a single [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)")). Otherwise, it would be easy to accidentally write something like `except``ValueError:` (not `except*`), which works if a single exception is raised but fails to catch \_anything\_ in the case of multiple simultaneous exceptions (even if one of them is a ValueError). However, this is not how Trio worked in the past: as a concession to practicality when the `except*` syntax hadn’t been dreamed up yet, the old `trio.MultiError` was raised only when at least two exceptions occurred simultaneously. Adding a layer of [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") around every nursery, while theoretically appealing, would probably break a lot of existing code in practice.

    Therefore, we’ve chosen to gate the newer, “stricter” behavior behind a parameter called `strict_exception_groups`. This is accepted as a parameter to [`open_nursery()`](#trio.open_nursery "trio.open_nursery"), to set the behavior for that nursery, and to [`trio.run()`](#trio.run "trio.run"), to set the default behavior for any nursery in your program that doesn’t override it.

    - With `strict_exception_groups=True`, the exception(s) coming out of a nursery will always be wrapped in an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)"), so you’ll know that if you’re handling single errors correctly, multiple simultaneous errors will work as well.

    - With `strict_exception_groups=False`, a nursery in which only one task has failed will raise that task’s exception without an additional layer of [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup "(in Python v3.11)") wrapping, so you’ll get maximum compatibility with code that was written to support older versions of Trio.

    To maintain backwards compatibility, the default is `strict_exception_groups=False`. The default will eventually change to `True` in a future version of Trio, once Python 3.11 and later versions are in wide use.

    ### Spawning tasks without becoming a parent

    Sometimes it doesn’t make sense for the task that starts a child to take on responsibility for watching it. For example, a server task may want to start a new task for each connection, but it can’t listen for connections and supervise children at the same time.

    The solution here is simple once you see it: there’s no requirement that a nursery object stay in the task that created it! We can write code like this:

    ``` python
    async def new_connection_listener(handler, nursery):
        while True:
            conn = await get_new_connection()
            nursery.start_soon(handler, conn)

    async def server(handler):
        async with trio.open_nursery() as nursery:
            nursery.start_soon(new_connection_listener, handler, nursery)
    ```

    Notice that `server` opens a nursery and passes it to `new_connection_listener`, and then `new_connection_listener` is able to start new tasks as “siblings” of itself. Of course, in this case, we could just as well have written:

    ``` python
    async def server(handler):
        async with trio.open_nursery() as nursery:
            while True:
                conn = await get_new_connection()
                nursery.start_soon(handler, conn)
    ```

    ...but sometimes things aren’t so simple, and this trick comes in handy.

    One thing to remember, though: cancel scopes are inherited from the nursery, **not** from the task that calls `start_soon`. So in this example, the timeout does *not* apply to `child` (or to anything else):

    ``` python
    async def do_spawn(nursery):
        with trio.move_on_after(TIMEOUT):  # don't do this, it has no effect
            nursery.start_soon(child)

    async with trio.open_nursery() as nursery:
        nursery.start_soon(do_spawn, nursery)
    ```

    ### Custom supervisors

    The default cleanup logic is often sufficient for simple cases, but what if you want a more sophisticated supervisor? For example, maybe you have [Erlang envy](http://learnyousomeerlang.com/supervisors) and want features like automatic restart of crashed tasks. Trio itself doesn’t provide these kinds of features, but you can build them on top; Trio’s goal is to enforce basic hygiene and then get out of your way. (Specifically: Trio won’t let you build a supervisor that exits and leaves orphaned tasks behind, and if you have an unhandled exception due to bugs or laziness then Trio will make sure they propagate.) And then you can wrap your fancy supervisor up in a library and put it on PyPI, because supervisors are tricky and there’s no reason everyone should have to write their own.

    For example, here’s a function that takes a list of functions, runs them all concurrently, and returns the result from the one that finishes first:

    ``` python
    async def race(*async_fns):
        if not async_fns:
            raise ValueError("must pass at least one argument")

        winner = None

        async def jockey(async_fn, cancel_scope):
            nonlocal winner
            winner = await async_fn()
            cancel_scope.cancel()

        async with trio.open_nursery() as nursery:
            for async_fn in async_fns:
                nursery.start_soon(jockey, async_fn, nursery.cancel_scope)

        return winner
    ```

    This works by starting a set of tasks which each try to run their function. As soon as the first function completes its execution, the task will set the nonlocal variable `winner` from the outer scope to the result of the function, and cancel the other tasks using the passed in cancel scope. Once all tasks have been cancelled (which exits the nursery block), the variable `winner` will be returned.

    Here if one or more of the racing functions raises an unhandled exception then Trio’s normal handling kicks in: it cancels the others and then propagates the exception. If you want different behavior, you can get that by adding a `try` block to the `jockey` function to catch exceptions and handle them however you like.

    ### Task-related API details

    #### The nursery API
- name: trio.current_time
  id: reference-core#trio.current_time
  summary: Returns the current time according to Trio’s internal clock
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.current_time()`

    Returns the current time according to Trio’s internal clock.

    #### Returns:

    The current time.

    #### Return type:

    [float](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if not inside a call to [`trio.run()`](#trio.run "trio.run").
- name: trio.DTLSChannel
  id: reference-io#trio.DTLSChannel
  summary: A DTLS connection
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.DTLSChannel(*args: object, **kwargs: object)`

    Bases: [`Channel`](#trio.abc.Channel "trio.abc.Channel")\[[`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")\]

    A DTLS connection.

    This class has no public constructor – you get instances by calling [`DTLSEndpoint.serve`](#trio.DTLSEndpoint.serve "trio.DTLSEndpoint.serve") or [`connect`](#trio.DTLSEndpoint.connect "trio.DTLSEndpoint.connect").
- name: trio.DTLSChannel.aclose
  id: reference-io#trio.DTLSChannel.aclose
  summary: Close this connection, but asynchronously
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` aclose()`

    Close this connection, but asynchronously.

    This is included to satisfy the [`trio.abc.Channel`](#trio.abc.Channel "trio.abc.Channel") contract. It’s identical to [`close`](#trio.DTLSChannel.close "trio.DTLSChannel.close"), but async.
- name: trio.DTLSChannel.close
  id: reference-io#trio.DTLSChannel.close
  summary: Close this connection
  belongs_to: I/O in Trio
  description: |-
    ### `close()`

    Close this connection.

    [`DTLSChannel`](#trio.DTLSChannel "trio.DTLSChannel")s don’t actually own any OS-level resources – the socket is owned by the [`DTLSEndpoint`](#trio.DTLSEndpoint "trio.DTLSEndpoint"), not the individual connections. So you don’t really *have* to call this. But it will interrupt any other tasks calling [`receive`](#trio.DTLSChannel.receive "trio.DTLSChannel.receive") with a [`ClosedResourceError`](reference-core#trio.ClosedResourceError "trio.ClosedResourceError"), and cause future attempts to use this connection to fail.

    You can also use this object as a synchronous or asynchronous context manager.
- name: trio.DTLSChannel.do_handshake
  id: reference-io#trio.DTLSChannel.do_handshake
  summary: Perform the handshake
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` do_handshake(*, initial_retransmit_timeout=1.0)`

    Perform the handshake.

    Calling this is optional – if you don’t, then it will be automatically called the first time you call [`send`](#trio.DTLSChannel.send "trio.DTLSChannel.send") or [`receive`](#trio.DTLSChannel.receive "trio.DTLSChannel.receive"). But calling it explicitly can be useful in case you want to control the retransmit timeout, use a cancel scope to place an overall timeout on the handshake, or catch errors from the handshake specifically.

    It’s safe to call this multiple times, or call it simultaneously from multiple tasks – the first call will perform the handshake, and the rest will be no-ops.

    #### Parameters:

    **initial_retransmit_timeout** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) –

    Since UDP is an unreliable protocol, it’s possible that some of the packets we send during the handshake will get lost. To handle this, DTLS uses a timer to automatically retransmit handshake packets that don’t receive a response. This lets you set the timeout we use to detect packet loss. Ideally, it should be set to ~1.5 times the round-trip time to your peer, but 1 second is a reasonable default. There’s [some useful guidance here](https://tlswg.org/dtls13-spec/draft-ietf-tls-dtls13.html#name-timer-values).

    This is the *initial* timeout, because if packets keep being lost then Trio will automatically back off to longer values, to avoid overloading the network.
- name: trio.DTLSChannel.endpoint
  id: reference-io#trio.DTLSChannel.endpoint
  summary: The DTLSEndpoint that this connection is using
  belongs_to: I/O in Trio
  description: |-
    ### `endpoint`

    The [`DTLSEndpoint`](#trio.DTLSEndpoint "trio.DTLSEndpoint") that this connection is using.
- name: trio.DTLSChannel.get_cleartext_mtu
  id: reference-io#trio.DTLSChannel.get_cleartext_mtu
  summary: Returns the largest number of bytes that you can pass in a single call to send while still fitting within the network-level MTU
  belongs_to: I/O in Trio
  description: |-
    ### `get_cleartext_mtu()`

    Returns the largest number of bytes that you can pass in a single call to [`send`](#trio.DTLSChannel.send "trio.DTLSChannel.send") while still fitting within the network-level MTU.

    See [`set_ciphertext_mtu`](#trio.DTLSChannel.set_ciphertext_mtu "trio.DTLSChannel.set_ciphertext_mtu") for more details.
- name: trio.DTLSChannel.peer_address
  id: reference-io#trio.DTLSChannel.peer_address
  summary: The IP/port of the remote peer that this connection is associated with
  belongs_to: I/O in Trio
  description: |-
    ### `peer_address`

    The IP/port of the remote peer that this connection is associated with.
- name: trio.DTLSChannel.receive
  id: reference-io#trio.DTLSChannel.receive
  summary: Fetch the next packet of data from this connection’s peer, waiting if necessary
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` receive()`

    Fetch the next packet of data from this connection’s peer, waiting if necessary.

    This is safe to call from multiple tasks simultaneously, in case you have some reason to do that. And more importantly, it’s cancellation-safe, meaning that cancelling a call to [`receive`](#trio.DTLSChannel.receive "trio.DTLSChannel.receive") will never cause a packet to be lost or corrupt the underlying connection.
- name: trio.DTLSChannel.send
  id: reference-io#trio.DTLSChannel.send
  summary: Send a packet of data, securely
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` send(data)`

    Send a packet of data, securely.
- name: trio.DTLSChannel.set_ciphertext_mtu
  id: reference-io#trio.DTLSChannel.set_ciphertext_mtu
  summary: Tells Trio the largest amount of data that can be sent in a single packet to this peer
  belongs_to: I/O in Trio
  description: |-
    ### `set_ciphertext_mtu(new_mtu)`

    Tells Trio the [largest amount of data that can be sent in a single packet to this peer](https://en.wikipedia.org/wiki/Maximum_transmission_unit).

    Trio doesn’t actually enforce this limit – if you pass a huge packet to [`send`](#trio.DTLSChannel.send "trio.DTLSChannel.send"), then we’ll dutifully encrypt it and attempt to send it. But calling this method does have two useful effects:

    - If called before the handshake is performed, then Trio will automatically fragment handshake messages to fit within the given MTU. It also might fragment them even smaller, if it detects signs of packet loss, so setting this should never be necessary to make a successful connection. But, the packet loss detection only happens after multiple timeouts have expired, so if you have reason to believe that a smaller MTU is required, then you can set this to skip those timeouts and establish the connection more quickly.

    - It changes the value returned from [`get_cleartext_mtu`](#trio.DTLSChannel.get_cleartext_mtu "trio.DTLSChannel.get_cleartext_mtu"). So if you have some kind of estimate of the network-level MTU, then you can use this to figure out how much overhead DTLS will need for hashes/padding/etc., and how much space you have left for your application data.

    The MTU here is measuring the largest UDP *payload* you think can be sent, the amount of encrypted data that can be handed to the operating system in a single call to [`send`](#trio.DTLSChannel.send "trio.DTLSChannel.send"). It should *not* include IP/UDP headers. Note that OS estimates of the MTU often are link-layer MTUs, so you have to subtract off 28 bytes on IPv4 and 48 bytes on IPv6 to get the ciphertext MTU.

    By default, Trio assumes an MTU of 1472 bytes on IPv4, and 1452 bytes on IPv6, which correspond to the common Ethernet MTU of 1500 bytes after accounting for IP/UDP overhead.
- name: trio.DTLSChannel.statistics
  id: reference-io#trio.DTLSChannel.statistics
  summary: Returns an object with statistics about this connection
  belongs_to: I/O in Trio
  description: |-
    ### `statistics()`

    Returns an object with statistics about this connection.

    Currently this has only one attribute:

    - `incoming_packets_dropped_in_trio` (`int`): Gives a count of the number of incoming packets from this peer that Trio successfully received from the network, but then got dropped because the internal channel buffer was full. If this is non-zero, then you might want to call `receive` more often, or use a larger `incoming_packets_buffer`, or just not worry about it because your UDP-based protocol should be able to handle the occasional lost packet, right?

    ## Low-level networking with [`trio.socket`](#module-trio.socket "trio.socket")

    The [`trio.socket`](#module-trio.socket "trio.socket") module provides Trio’s basic low-level networking API. If you’re doing ordinary things with stream-oriented connections over IPv4/IPv6/Unix domain sockets, then you probably want to stick to the high-level API described above. If you want to use UDP, or exotic address families like `AF_BLUETOOTH`, or otherwise get direct access to all the quirky bits of your system’s networking API, then you’re in the right place.

    ### Top-level exports

    Generally, the API exposed by [`trio.socket`](#module-trio.socket "trio.socket") mirrors that of the standard library [`socket`](https://docs.python.org/3/library/socket.html#module-socket "(in Python v3.11)") module. Most constants (like `SOL_SOCKET`) and simple utilities (like [`inet_aton()`](https://docs.python.org/3/library/socket.html#socket.inet_aton "(in Python v3.11)")) are simply re-exported unchanged. But there are also some differences, which are described here.

    First, Trio provides analogues to all the standard library functions that return socket objects; their interface is identical, except that they’re modified to return Trio socket objects instead:
- name: trio.DTLSEndpoint
  id: reference-io#trio.DTLSEndpoint
  summary: A DTLS endpoint
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.DTLSEndpoint(socket, *, incoming_packets_buffer=10)`

    A DTLS endpoint.

    A single UDP socket can handle arbitrarily many DTLS connections simultaneously, acting as a client or server as needed. A [`DTLSEndpoint`](#trio.DTLSEndpoint "trio.DTLSEndpoint") object holds a UDP socket and manages these connections, which are represented as [`DTLSChannel`](#trio.DTLSChannel "trio.DTLSChannel") objects.

    #### Parameters:

    - **socket** – (trio.socket.SocketType): A `SOCK_DGRAM` socket. If you want to accept incoming connections in server mode, then you should probably bind the socket to some known port.

    - **incoming_packets_buffer** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – Each [`DTLSChannel`](#trio.DTLSChannel "trio.DTLSChannel") using this socket has its own buffer that holds incoming packets until you call [`receive`](#trio.DTLSChannel.receive "trio.DTLSChannel.receive") to read them. This lets you adjust the size of this buffer. [`statistics`](#trio.DTLSChannel.statistics "trio.DTLSChannel.statistics") lets you check if the buffer has overflowed.
- name: trio.DTLSEndpoint.close
  id: reference-io#trio.DTLSEndpoint.close
  summary: Close this socket, and all associated DTLS connections
  belongs_to: I/O in Trio
  description: |-
    ### `close()`

    Close this socket, and all associated DTLS connections.

    This object can also be used as a context manager.
- name: trio.DTLSEndpoint.connect
  id: reference-io#trio.DTLSEndpoint.connect
  summary: Initiate an outgoing DTLS connection
  belongs_to: I/O in Trio
  description: |-
    ### `connect(address, ssl_context)`

    Initiate an outgoing DTLS connection.

    Notice that this is a synchronous method. That’s because it doesn’t actually initiate any I/O – it just sets up a [`DTLSChannel`](#trio.DTLSChannel "trio.DTLSChannel") object. The actual handshake doesn’t occur until you start using the [`DTLSChannel`](#trio.DTLSChannel "trio.DTLSChannel"). This gives you a chance to do further configuration first, like setting MTU etc.

    #### Parameters:

    - **address** – The address to connect to. Usually a (host, port) tuple, like `("127.0.0.1",``12345)`.

    - **ssl_context** ([*OpenSSL.SSL.Context*](https://www.pyopenssl.org/en/stable/api/ssl.html#OpenSSL.SSL.Context "(in pyOpenSSL v23.2.0)")) – The PyOpenSSL context object to use for this connection.

    #### Returns:

    DTLSChannel
- name: trio.DTLSEndpoint.incoming_packets_buffer
  id: reference-io#trio.DTLSEndpoint.incoming_packets_buffer
  summary: Both constructor arguments are also exposed as attributes, in case you need to access them later
  belongs_to: I/O in Trio
  description: |-
    ### `incoming_packets_buffer`

    Both constructor arguments are also exposed as attributes, in case you need to access them later.
- name: trio.DTLSEndpoint.serve
  id: reference-io#trio.DTLSEndpoint.serve
  summary: Listen for incoming connections, and spawn a handler for each using an internal nursery
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` serve(ssl_context, async_fn, *args, task_status=TASK_STATUS_IGNORED)`

    Listen for incoming connections, and spawn a handler for each using an internal nursery.

    Similar to [`serve_tcp`](#trio.serve_tcp "trio.serve_tcp"), this function never returns until cancelled, or the [`DTLSEndpoint`](#trio.DTLSEndpoint "trio.DTLSEndpoint") is closed and all handlers have exited.

    Usage commonly looks like:

    ``` python
    async def handler(dtls_channel):
        ...

    async with trio.open_nursery() as nursery:
        await nursery.start(dtls_endpoint.serve, ssl_context, handler)
        # ... do other things here ...
    ```

    The `dtls_channel` passed into the handler function has already performed the “cookie exchange” part of the DTLS handshake, so the peer address is trustworthy. But the actual cryptographic handshake doesn’t happen until you start using it, giving you a chance for any last minute configuration, and the option to catch and handle handshake errors.

    #### Parameters:

    - **ssl_context** ([*OpenSSL.SSL.Context*](https://www.pyopenssl.org/en/stable/api/ssl.html#OpenSSL.SSL.Context "(in pyOpenSSL v23.2.0)")) – The PyOpenSSL context object to use for incoming connections.

    - **async_fn** – The handler function that will be invoked for each incoming connection.
- name: trio.DTLSEndpoint.socket
  id: reference-io#trio.DTLSEndpoint.socket
  summary: null
  belongs_to: I/O in Trio
  description: '### `socket`'
- name: trio.EndOfChannel
  id: reference-core#trio.EndOfChannel
  summary: Raised when trying to receive from a trio.abc.ReceiveChannel that has no more data to receive
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.EndOfChannel`

    Raised when trying to receive from a [`trio.abc.ReceiveChannel`](reference-io#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel") that has no more data to receive.

    This is analogous to an “end-of-file” condition, but for channels.
- name: trio.Event
  id: reference-core#trio.Event
  summary: A waitable boolean value useful for inter-task synchronization, inspired by threading.Event
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.Event`

    A waitable boolean value useful for inter-task synchronization, inspired by [`threading.Event`](https://docs.python.org/3/library/threading.html#threading.Event "(in Python v3.11)").

    An event object has an internal boolean flag, representing whether the event has happened yet. The flag is initially False, and the [`wait()`](#trio.Event.wait "trio.Event.wait") method waits until the flag is True. If the flag is already True, then [`wait()`](#trio.Event.wait "trio.Event.wait") returns immediately. (If the event has already happened, there’s nothing to wait for.) The [`set()`](#trio.Event.set "trio.Event.set") method sets the flag to True, and wakes up any waiters.

    This behavior is useful because it helps avoid race conditions and lost wakeups: it doesn’t matter whether [`set()`](#trio.Event.set "trio.Event.set") gets called just before or after [`wait()`](#trio.Event.wait "trio.Event.wait"). If you want a lower-level wakeup primitive that doesn’t have this protection, consider [`Condition`](#trio.Condition "trio.Condition") or [`trio.lowlevel.ParkingLot`](reference-lowlevel#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot").

    > #### Note
    >
    > Unlike [`threading.Event`](https://docs.python.org/3/library/threading.html#threading.Event "(in Python v3.11)"), [`trio.Event`](#trio.Event "trio.Event") has no [`clear`](https://docs.python.org/3/library/threading.html#threading.Event.clear "(in Python v3.11)") method. In Trio, once an [`Event`](#trio.Event "trio.Event") has happened, it cannot un-happen. If you need to represent a series of events, consider creating a new [`Event`](#trio.Event "trio.Event") object for each one (they’re cheap!), or other synchronization methods like [channels](#channels) or [`trio.lowlevel.ParkingLot`](reference-lowlevel#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot").
- name: trio.Event.is_set
  id: reference-core#trio.Event.is_set
  summary: Return the current value of the internal flag
  belongs_to: Trio’s core functionality
  description: |-
    ### `is_set()`

    Return the current value of the internal flag.
- name: trio.Event.set
  id: reference-core#trio.Event.set
  summary: Set the internal flag value to True, and wake any waiting tasks
  belongs_to: Trio’s core functionality
  description: |-
    ### `set()`

    Set the internal flag value to True, and wake any waiting tasks.
- name: trio.Event.statistics
  id: reference-core#trio.Event.statistics
  summary: Return an object containing debugging information
  belongs_to: Trio’s core functionality
  description: |-
    ### `statistics()`

    Return an object containing debugging information.

    Currently the following fields are defined:

    - `tasks_waiting`: The number of tasks blocked on this event’s [`wait()`](#trio.Event.wait "trio.Event.wait") method.
- name: trio.Event.wait
  id: reference-core#trio.Event.wait
  summary: Block until the internal flag value becomes True
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` wait()`

    Block until the internal flag value becomes True.

    If it’s already True, then this method returns immediately.

    ### Using channels to pass values between tasks

    *Channels* allow you to safely and conveniently send objects between different tasks. They’re particularly useful for implementing producer/consumer patterns.

    The core channel API is defined by the abstract base classes [`trio.abc.SendChannel`](reference-io#trio.abc.SendChannel "trio.abc.SendChannel") and [`trio.abc.ReceiveChannel`](reference-io#trio.abc.ReceiveChannel "trio.abc.ReceiveChannel"). You can use these to implement your own custom channels, that do things like pass objects between processes or over the network. But in many cases, you just want to pass objects between different tasks inside a single process, and for that you can use [`trio.open_memory_channel()`](#trio.open_memory_channel "trio.open_memory_channel"):
- name: trio.fail_after
  id: reference-core#trio.fail_after
  summary: Creates a cancel scope with the given timeout, and raises an error if it is actually cancelled
  belongs_to: Trio’s core functionality
  description: |-
    ### *`with`*` trio.fail_after(seconds: float) → AbstractContextManager[CancelScope] as cancel_scope`

    Creates a cancel scope with the given timeout, and raises an error if it is actually cancelled.

    This function and [`move_on_after()`](#trio.move_on_after "trio.move_on_after") are similar in that both create a cancel scope with a given timeout, and if the timeout expires then both will cause [`Cancelled`](#trio.Cancelled "trio.Cancelled") to be raised within the scope. The difference is that when the [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception reaches [`move_on_after()`](#trio.move_on_after "trio.move_on_after"), it’s caught and discarded. When it reaches [`fail_after()`](#trio.fail_after "trio.fail_after"), then it’s caught and [`TooSlowError`](#trio.TooSlowError "trio.TooSlowError") is raised in its place.

    #### Parameters:

    **seconds** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The timeout.

    #### Raises:

    - [**TooSlowError**](#trio.TooSlowError "trio.TooSlowError") – if a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception is raised in this scope and caught by the context manager.

    - [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if *seconds* is less than zero or NaN.
- name: trio.fail_at
  id: reference-core#trio.fail_at
  summary: Creates a cancel scope with the given deadline, and raises an error if it is actually cancelled
  belongs_to: Trio’s core functionality
  description: |-
    ### *`with`*` trio.fail_at(deadline: float) → AbstractContextManager[CancelScope] as cancel_scope`

    Creates a cancel scope with the given deadline, and raises an error if it is actually cancelled.

    This function and [`move_on_at()`](#trio.move_on_at "trio.move_on_at") are similar in that both create a cancel scope with a given absolute deadline, and if the deadline expires then both will cause [`Cancelled`](#trio.Cancelled "trio.Cancelled") to be raised within the scope. The difference is that when the [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception reaches [`move_on_at()`](#trio.move_on_at "trio.move_on_at"), it’s caught and discarded. When it reaches [`fail_at()`](#trio.fail_at "trio.fail_at"), then it’s caught and [`TooSlowError`](#trio.TooSlowError "trio.TooSlowError") is raised in its place.

    #### Parameters:

    **deadline** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The deadline.

    #### Raises:

    - [**TooSlowError**](#trio.TooSlowError "trio.TooSlowError") – if a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception is raised in this scope and caught by the context manager.

    - [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if deadline is NaN.

    Cheat sheet:

    - If you want to impose a timeout on a function, but you don’t care whether it timed out or not:

      ``` python
      with trio.move_on_after(TIMEOUT):
          await do_whatever()
      # carry on!
      ```

    - If you want to impose a timeout on a function, and then do some recovery if it timed out:

      ``` python
      with trio.move_on_after(TIMEOUT) as cancel_scope:
          await do_whatever()
      if cancel_scope.cancelled_caught:
          # The operation timed out, try something else
          try_to_recover()
      ```

    - If you want to impose a timeout on a function, and then if it times out then just give up and raise an error for your caller to deal with:

      ``` python
      with trio.fail_after(TIMEOUT):
          await do_whatever()
      ```

    It’s also possible to check what the current effective deadline is, which is sometimes useful:
- name: trio.from_thread.run
  id: reference-core#trio.from_thread.run
  summary: Run the given async function in the parent Trio thread, blocking until it is complete
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.from_thread.run(afn, *args, trio_token=None)`

    Run the given async function in the parent Trio thread, blocking until it is complete.

    #### Returns:

    Whatever `afn(*args)` returns.

    Returns or raises whatever the given function returns or raises. It can also raise exceptions of its own:

    #### Raises:

    - [**RunFinishedError**](#trio.RunFinishedError "trio.RunFinishedError") – if the corresponding call to [`trio.run()`](#trio.run "trio.run") has already completed, or if the run has started its final cleanup phase and can no longer spawn new system tasks.

    - [**Cancelled**](#trio.Cancelled "trio.Cancelled") – if the corresponding call to [`trio.run()`](#trio.run "trio.run") completes while `afn(*args)` is running, then `afn` is likely to raise [`trio.Cancelled`](#trio.Cancelled "trio.Cancelled"), and this will propagate out into

    - [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if you try calling this from inside the Trio thread, which would otherwise cause a deadlock.

    - [**AttributeError**](https://docs.python.org/3/library/exceptions.html#AttributeError "(in Python v3.11)") – if no `trio_token` was provided, and we can’t infer one from context.

    - [**TypeError**](https://docs.python.org/3/library/exceptions.html#TypeError "(in Python v3.11)") – if `afn` is not an asynchronous function.

    **Locating a Trio Token**: There are two ways to specify which [`trio.run`](#trio.run "trio.run") loop to reenter:

    > - Spawn this thread from [`trio.to_thread.run_sync`](#trio.to_thread.run_sync "trio.to_thread.run_sync"). Trio will automatically capture the relevant Trio token and use it when you want to re-enter Trio.
    >
    > - Pass a keyword argument, `trio_token` specifying a specific [`trio.run`](#trio.run "trio.run") loop to re-enter. This is useful in case you have a “foreign” thread, spawned using some other framework, and still want to enter Trio.
- name: trio.from_thread.run_sync
  id: reference-core#trio.from_thread.run_sync
  summary: Run the given sync function in the parent Trio thread, blocking until it is complete
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.from_thread.run_sync(fn, *args, trio_token=None)`

    Run the given sync function in the parent Trio thread, blocking until it is complete.

    #### Returns:

    Whatever `fn(*args)` returns.

    Returns or raises whatever the given function returns or raises. It can also raise exceptions of its own:

    #### Raises:

    - [**RunFinishedError**](#trio.RunFinishedError "trio.RunFinishedError") – if the corresponding call to [`trio.run`](#trio.run "trio.run") has already completed.

    - [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if you try calling this from inside the Trio thread, which would otherwise cause a deadlock.

    - [**AttributeError**](https://docs.python.org/3/library/exceptions.html#AttributeError "(in Python v3.11)") – if no `trio_token` was provided, and we can’t infer one from context.

    - [**TypeError**](https://docs.python.org/3/library/exceptions.html#TypeError "(in Python v3.11)") – if `fn` is an async function.

    **Locating a Trio Token**: There are two ways to specify which [`trio.run`](#trio.run "trio.run") loop to reenter:

    > - Spawn this thread from [`trio.to_thread.run_sync`](#trio.to_thread.run_sync "trio.to_thread.run_sync"). Trio will automatically capture the relevant Trio token and use it when you want to re-enter Trio.
    >
    > - Pass a keyword argument, `trio_token` specifying a specific [`trio.run`](#trio.run "trio.run") loop to re-enter. This is useful in case you have a “foreign” thread, spawned using some other framework, and still want to enter Trio.

    This will probably be clearer with an example. Here we demonstrate how to spawn a child thread, and then use a [memory channel](#channels) to send messages between the thread and a Trio task:

    ``` python
    import trio


    def thread_fn(receive_from_trio, send_to_trio):
        while True:
            # Since we're in a thread, we can't call methods on Trio
            # objects directly -- so we use trio.from_thread to call them.
            try:
                request = trio.from_thread.run(receive_from_trio.receive)
            except trio.EndOfChannel:
                trio.from_thread.run(send_to_trio.aclose)
                return
            else:
                response = request + 1
                trio.from_thread.run(send_to_trio.send, response)


    async def main():
        send_to_thread, receive_from_trio = trio.open_memory_channel(0)
        send_to_trio, receive_from_thread = trio.open_memory_channel(0)

        async with trio.open_nursery() as nursery:
            # In a background thread, run:
            #   thread_fn(receive_from_trio, send_to_trio)
            nursery.start_soon(
                trio.to_thread.run_sync, thread_fn, receive_from_trio, send_to_trio
            )

            # prints "1"
            await send_to_thread.send(0)
            print(await receive_from_thread.receive())

            # prints "2"
            await send_to_thread.send(1)
            print(await receive_from_thread.receive())

            # When we close the channel, it signals the thread to exit.
            await send_to_thread.aclose()

            # When we exit the nursery, it waits for the background thread to
            # exit.


    trio.run(main)
    ```

    ### Threads and task-local storage

    When working with threads, you can use the same [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)") we discussed above, because their values are preserved.

    This is done by automatically copying the [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)") context when you use any of:

    - [` ``trio.to_thread.run_sync`` `](#trio.to_thread.run_sync "trio.to_thread.run_sync")

    - [` ``trio.from_thread.run`` `](#trio.from_thread.run "trio.from_thread.run")

    - [` ``trio.from_thread.run_sync`` `](#trio.from_thread.run_sync "trio.from_thread.run_sync")

    That means that the values of the context variables are accessible even in worker threads, or when sending a function to be run in the main/parent Trio thread using [`trio.from_thread.run`](#trio.from_thread.run "trio.from_thread.run") *from* one of these worker threads.

    But it also means that as the context is not the same but a copy, if you [`set`](https://docs.python.org/3/library/stdtypes.html#set "(in Python v3.11)") the context variable value *inside* one of these functions that work in threads, the new value will only be available in that context (that was copied). So, the new value will be available for that function and other internal/children tasks, but the value won’t be available in the parent thread.

    If you need to modify values that would live in the context variables and you need to make those modifications from the child threads, you can instead set a mutable object (e.g. a dictionary) in the context variable of the top level/parent Trio thread. Then in the children, instead of setting the context variable, you can `get` the same object, and modify its values. That way you keep the same object in the context variable and only mutate it in child threads.

    This way, you can modify the object content in child threads and still access the new content in the parent thread.

    Here’s an example:

    ``` python
    import contextvars
    import time

    import trio

    request_state = contextvars.ContextVar("request_state")

    # Blocking function that should be run on a thread
    # It could be reading or writing files, communicating with a database
    # with a driver not compatible with async / await, etc.
    def work_in_thread(msg):
        # Only use request_state.get() inside the worker thread
        state_value = request_state.get()
        current_user_id = state_value["current_user_id"]
        time.sleep(3)  # this would be some blocking call, like reading a file
        print(f"Processed user {current_user_id} with message {msg} in a thread worker")
        # Modify/mutate the state object, without setting the entire
        # contextvar with request_state.set()
        state_value["msg"] = msg


    # An example "request handler" that does some work itself and also
    # spawns some helper tasks in threads to execute blocking code.
    async def handle_request(current_user_id):
        # Write to task-local storage:
        current_state = {"current_user_id": current_user_id, "msg": ""}
        request_state.set(current_state)

        # Here the current implicit contextvars context will be automatically copied
        # inside the worker thread
        await trio.to_thread.run_sync(work_in_thread, f"Hello {current_user_id}")
        # Extract the value set inside the thread in the same object stored in a contextvar
        new_msg = current_state["msg"]
        print(
            f"New contextvar value from worker thread for user {current_user_id}: {new_msg}"
        )


    # Spawn several "request handlers" simultaneously, to simulate a
    # busy server handling multiple requests at the same time.
    async def main():
        async with trio.open_nursery() as nursery:
            for i in range(3):
                nursery.start_soon(handle_request, i)


    trio.run(main)
    ```

    Running that script will result in the output:

        Processed user 2 with message Hello 2 in a thread worker
        Processed user 0 with message Hello 0 in a thread worker
        Processed user 1 with message Hello 1 in a thread worker
        New contextvar value from worker thread for user 2: Hello 2
        New contextvar value from worker thread for user 1: Hello 1
        New contextvar value from worker thread for user 0: Hello 0

    If you are using `contextvars` or you are using a library that uses them, now you know how they interact when working with threads in Trio.

    But have in mind that in many cases it might be a lot simpler to *not* use context variables in your own code and instead pass values in arguments, as it might be more explicit and might be easier to reason about.

    > #### Note
    >
    > The context is automatically copied instead of using the same parent context because a single context can’t be used in more than one thread, it’s not supported by `contextvars`.

    ## Exceptions and warnings
- name: trio.Lock
  id: reference-core#trio.Lock
  summary: A classic mutex
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.Lock`

    A classic [mutex](https://en.wikipedia.org/wiki/Lock_(computer_science)).

    This is a non-reentrant, single-owner lock. Unlike [`threading.Lock`](https://docs.python.org/3/library/threading.html#threading.Lock "(in Python v3.11)"), only the owner of the lock is allowed to release it.

    A [`Lock`](#trio.Lock "trio.Lock") object can be used as an async context manager; it blocks on entry but not on exit.
- name: trio.Lock.acquire
  id: reference-core#trio.Lock.acquire
  summary: Acquire the lock, blocking if necessary
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` acquire()`

    Acquire the lock, blocking if necessary.
- name: trio.Lock.acquire_nowait
  id: reference-core#trio.Lock.acquire_nowait
  summary: Attempt to acquire the lock, without blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `acquire_nowait()`

    Attempt to acquire the lock, without blocking.

    #### Raises:

    [**WouldBlock**](#trio.WouldBlock "trio.WouldBlock") – if the lock is held.
- name: trio.Lock.locked
  id: reference-core#trio.Lock.locked
  summary: Check whether the lock is currently held
  belongs_to: Trio’s core functionality
  description: |-
    ### `locked()`

    Check whether the lock is currently held.

    #### Returns:

    True if the lock is held, False otherwise.

    #### Return type:

    [bool](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")
- name: trio.Lock.release
  id: reference-core#trio.Lock.release
  summary: Release the lock
  belongs_to: Trio’s core functionality
  description: |-
    ### `release()`

    Release the lock.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – if the calling task does not hold the lock.
- name: trio.Lock.statistics
  id: reference-core#trio.Lock.statistics
  summary: Return an object containing debugging information
  belongs_to: Trio’s core functionality
  description: |-
    ### `statistics()`

    Return an object containing debugging information.

    Currently the following fields are defined:

    - `locked`: boolean indicating whether the lock is held.

    - `owner`: the [`trio.lowlevel.Task`](reference-lowlevel#trio.lowlevel.Task "trio.lowlevel.Task") currently holding the lock, or None if the lock is not held.

    - `tasks_waiting`: The number of tasks blocked on this lock’s [`acquire()`](#trio.Lock.acquire "trio.Lock.acquire") method.
- name: trio.lowlevel.Abort
  id: reference-lowlevel#trio.lowlevel.Abort
  summary: enum.Enum used as the return value from abort functions
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.lowlevel.Abort(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)`

    [`enum.Enum`](https://docs.python.org/3/library/enum.html#enum.Enum "(in Python v3.11)") used as the return value from abort functions.

    See [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled") for details.
- name: trio.lowlevel.Abort.FAILED
  id: reference-lowlevel#trio.lowlevel.Abort.FAILED
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### `FAILED`'
- name: trio.lowlevel.Abort.SUCCEEDED
  id: reference-lowlevel#trio.lowlevel.Abort.SUCCEEDED
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### `SUCCEEDED`'
- name: trio.lowlevel.add_instrument
  id: reference-lowlevel#trio.lowlevel.add_instrument
  summary: Start instrumenting the current run loop with the given instrument
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.add_instrument(instrument: Instrument) → None`

    Start instrumenting the current run loop with the given instrument.

    #### Parameters:

    **instrument** ([*trio.abc.Instrument*](#trio.abc.Instrument "trio.abc.Instrument")) – The instrument to activate.

    If `instrument` is already active, does nothing.
- name: trio.lowlevel.cancel_shielded_checkpoint
  id: reference-lowlevel#trio.lowlevel.cancel_shielded_checkpoint
  summary: Introduce a schedule point, but not a cancel point
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.cancel_shielded_checkpoint()`

    Introduce a schedule point, but not a cancel point.

    This is *not* a [checkpoint](reference-core#checkpoints), but it is half of a checkpoint, and when combined with [`checkpoint_if_cancelled()`](#trio.lowlevel.checkpoint_if_cancelled "trio.lowlevel.checkpoint_if_cancelled") it can make a full checkpoint.

    Equivalent to (but potentially more efficient than):

    ``` python
    with trio.CancelScope(shield=True):
        await trio.lowlevel.checkpoint()
    ```

    These are commonly used in cases where you have an operation that might-or-might-not block, and you want to implement Trio’s standard checkpoint semantics. Example:

    ``` python
    async def operation_that_maybe_blocks():
        await checkpoint_if_cancelled()
        try:
            ret = attempt_operation()
        except BlockingIOError:
            # need to block and then retry, which we do below
            pass
        else:
            # operation succeeded, finish the checkpoint then return
            await cancel_shielded_checkpoint()
            return ret
        while True:
            await wait_for_operation_to_be_ready()
            try:
                return attempt_operation()
            except BlockingIOError:
                pass
    ```

    This logic is a bit convoluted, but accomplishes all of the following:

    - Every successful execution path passes through a checkpoint (assuming that `wait_for_operation_to_be_ready` is an unconditional checkpoint)

    - Our [cancellation semantics](reference-core#cancellable-primitives) say that [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled") should only be raised if the operation didn’t happen. Using [`cancel_shielded_checkpoint()`](#trio.lowlevel.cancel_shielded_checkpoint "trio.lowlevel.cancel_shielded_checkpoint") on the early-exit branch accomplishes this.

    - On the path where we do end up blocking, we don’t pass through any schedule points before that, which avoids some unnecessary work.

    - Avoids implicitly chaining the [`BlockingIOError`](https://docs.python.org/3/library/exceptions.html#BlockingIOError "(in Python v3.11)") with any errors raised by `attempt_operation` or `wait_for_operation_to_be_ready`, by keeping the `while``True:` loop outside of the `except``BlockingIOError:` block.

    These functions can also be useful in other situations. For example, when [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync "trio.to_thread.run_sync") schedules some work to run in a worker thread, it blocks until the work is finished (so it’s a schedule point), but by default it doesn’t allow cancellation. So to make sure that the call always acts as a checkpoint, it calls [`checkpoint_if_cancelled()`](#trio.lowlevel.checkpoint_if_cancelled "trio.lowlevel.checkpoint_if_cancelled") before starting the thread.

    ### Low-level blocking
- name: trio.lowlevel.checkpoint
  id: reference-lowlevel#trio.lowlevel.checkpoint
  summary: A pure checkpoint
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.checkpoint()`

    A pure [checkpoint](reference-core#checkpoints).

    This checks for cancellation and allows other tasks to be scheduled, without otherwise blocking.

    Note that the scheduler has the option of ignoring this and continuing to run the current task if it decides this is appropriate (e.g. for increased efficiency).

    Equivalent to `await``trio.sleep(0)` (which is implemented by calling [`checkpoint()`](#trio.lowlevel.checkpoint "trio.lowlevel.checkpoint").)

    The next two functions are used *together* to make up a checkpoint:
- name: trio.lowlevel.checkpoint_if_cancelled
  id: reference-lowlevel#trio.lowlevel.checkpoint_if_cancelled
  summary: Issue a checkpoint if the calling context has been cancelled
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.checkpoint_if_cancelled()`

    Issue a [checkpoint](reference-core#checkpoints) if the calling context has been cancelled.

    Equivalent to (but potentially more efficient than):

    ``` python
    if trio.current_effective_deadline() == -inf:
        await trio.lowlevel.checkpoint()
    ```

    This is either a no-op, or else it allow other tasks to be scheduled and then raises [`trio.Cancelled`](reference-core#trio.Cancelled "trio.Cancelled").

    Typically used together with [`cancel_shielded_checkpoint()`](#trio.lowlevel.cancel_shielded_checkpoint "trio.lowlevel.cancel_shielded_checkpoint").
- name: trio.lowlevel.current_clock
  id: reference-lowlevel#trio.lowlevel.current_clock
  summary: Returns the current Clock
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.current_clock()`

    Returns the current [`Clock`](reference-core#trio.abc.Clock "trio.abc.Clock").

    ### Instrument API

    The instrument API provides a standard way to add custom instrumentation to the run loop. Want to make a histogram of scheduling latencies, log a stack trace of any task that blocks the run loop for \>50 ms, or measure what percentage of your process’s running time is spent waiting for I/O? This is the place.

    The general idea is that at any given moment, [`trio.run()`](reference-core#trio.run "trio.run") maintains a set of “instruments”, which are objects that implement the [`trio.abc.Instrument`](#trio.abc.Instrument "trio.abc.Instrument") interface. When an interesting event happens, it loops over these instruments and notifies them by calling an appropriate method. The tutorial has [a simple example of using this for tracing](https://trio.readthedocs.io/en/v0.22.2/tutorial.html#tutorial-instrument-example).

    Since this hooks into Trio at a rather low level, you do have to be careful. The callbacks are run synchronously, and in many cases if they error out then there isn’t any plausible way to propagate this exception (for instance, we might be deep in the guts of the exception propagation machinery…). Therefore our [current strategy](https://github.com/python-trio/trio/issues/47) for handling exceptions raised by instruments is to (a) log an exception to the `"trio.abc.Instrument"` logger, which by default prints a stack trace to standard error and (b) disable the offending instrument.

    You can register an initial list of instruments by passing them to [`trio.run()`](reference-core#trio.run "trio.run"). [`add_instrument()`](#trio.lowlevel.add_instrument "trio.lowlevel.add_instrument") and [`remove_instrument()`](#trio.lowlevel.remove_instrument "trio.lowlevel.remove_instrument") let you add and remove instruments at runtime.
- name: trio.lowlevel.current_iocp
  id: reference-lowlevel#trio.lowlevel.current_iocp
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### `trio.lowlevel.current_iocp()`'
- name: trio.lowlevel.current_kqueue
  id: reference-lowlevel#trio.lowlevel.current_kqueue
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### `trio.lowlevel.current_kqueue()`'
- name: trio.lowlevel.current_root_task
  id: reference-lowlevel#trio.lowlevel.current_root_task
  summary: Returns the current root Task
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.current_root_task()`

    Returns the current root [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task").

    This is the task that is the ultimate parent of all other tasks.
- name: trio.lowlevel.current_statistics
  id: reference-lowlevel#trio.lowlevel.current_statistics
  summary: Returns an object containing run-loop-level debugging information
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.current_statistics()`

    Returns an object containing run-loop-level debugging information.

    Currently the following fields are defined:

    - `tasks_living` (int): The number of tasks that have been spawned and not yet exited.

    - `tasks_runnable` (int): The number of tasks that are currently queued on the run queue (as opposed to blocked waiting for something to happen).

    - `seconds_to_next_deadline` (float): The time until the next pending cancel scope deadline. May be negative if the deadline has expired but we haven’t yet processed cancellations. May be [`inf`](https://docs.python.org/3/library/math.html#math.inf "(in Python v3.11)") if there are no pending deadlines.

    - `run_sync_soon_queue_size` (int): The number of unprocessed callbacks queued via [`trio.lowlevel.TrioToken.run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon "trio.lowlevel.TrioToken.run_sync_soon").

    - `io_statistics` (object): Some statistics from Trio’s I/O backend. This always has an attribute `backend` which is a string naming which operating-system-specific I/O backend is in use; the other attributes vary between backends.

    ### The current clock
- name: trio.lowlevel.current_task
  id: reference-lowlevel#trio.lowlevel.current_task
  summary: Return the Task object representing the current task
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.current_task()`

    Return the [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") object representing the current task.

    #### Returns:

    the [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") that called [`current_task()`](#trio.lowlevel.current_task "trio.lowlevel.current_task").

    #### Return type:

    [Task](#trio.lowlevel.Task "trio.lowlevel.Task")
- name: trio.lowlevel.current_trio_token
  id: reference-lowlevel#trio.lowlevel.current_trio_token
  summary: Retrieve the TrioToken for the current call to trio.run()
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.current_trio_token()`

    Retrieve the [`TrioToken`](#trio.lowlevel.TrioToken "trio.lowlevel.TrioToken") for the current call to [`trio.run()`](reference-core#trio.run "trio.run").

    ## Spawning threads
- name: trio.lowlevel.currently_ki_protected
  id: reference-lowlevel#trio.lowlevel.currently_ki_protected
  summary: Check whether the calling code has KeyboardInterrupt protection enabled
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.currently_ki_protected()`

    Check whether the calling code has [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") protection enabled.

    It’s surprisingly easy to think that one’s [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") protection is enabled when it isn’t, or vice-versa. This function tells you what Trio thinks of the matter, which makes it useful for `assert`s and unit tests.

    #### Returns:

    True if protection is enabled, and False otherwise.

    #### Return type:

    [bool](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")

    ## Sleeping and waking

    ### Wait queue abstraction
- name: trio.lowlevel.disable_ki_protection
  id: reference-lowlevel#trio.lowlevel.disable_ki_protection
  summary: Decorator that marks the given regular function, generator function, async function, or async generator function as unprotected against KeyboardInterrupt, i.e., the code inside this function can be rudely interrupted by KeyboardInterrupt at any moment
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `@trio.lowlevel.disable_ki_protection`

    Decorator that marks the given regular function, generator function, async function, or async generator function as unprotected against [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)"), i.e., the code inside this function *can* be rudely interrupted by [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") at any moment.

    If you have multiple decorators on the same function, then this should be at the bottom of the stack (closest to the actual function).

    An example of where you’d use this is in implementing something like [`trio.from_thread.run()`](reference-core#trio.from_thread.run "trio.from_thread.run"), which uses [`TrioToken.run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon "trio.lowlevel.TrioToken.run_sync_soon") to get into the Trio thread. [`run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon "trio.lowlevel.TrioToken.run_sync_soon") callbacks are run with [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") protection enabled, and [`trio.from_thread.run()`](reference-core#trio.from_thread.run "trio.from_thread.run") takes advantage of this to safely set up the machinery for sending a response back to the original thread, but then uses [`disable_ki_protection()`](#trio.lowlevel.disable_ki_protection "trio.lowlevel.disable_ki_protection") when entering the user-provided function.
- name: trio.lowlevel.enable_ki_protection
  id: reference-lowlevel#trio.lowlevel.enable_ki_protection
  summary: Decorator that marks the given regular function, generator function, async function, or async generator function as protected against KeyboardInterrupt, i.e., the code inside this function won’t be rudely interrupted by KeyboardInterrupt
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `@trio.lowlevel.enable_ki_protection`

    Decorator that marks the given regular function, generator function, async function, or async generator function as protected against [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)"), i.e., the code inside this function *won’t* be rudely interrupted by [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)"). (Though if it contains any [checkpoints](reference-core#checkpoints), then it can still receive [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") at those. This is considered a polite interruption.)

    > #### Warning
    >
    > Be very careful to only use this decorator on functions that you know will either exit in bounded time, or else pass through a checkpoint regularly. (Of course all of your functions should have this property, but if you mess it up here then you won’t even be able to use control-C to escape!)

    If you have multiple decorators on the same function, then this should be at the bottom of the stack (closest to the actual function).

    An example of where you’d use this is on the `__exit__` implementation for something like a [`Lock`](reference-core#trio.Lock "trio.Lock"), where a poorly-timed [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") could leave the lock in an inconsistent state and cause a deadlock.
- name: trio.lowlevel.FdStream
  id: reference-lowlevel#trio.lowlevel.FdStream
  summary: Represents a stream given the file descriptor to a pipe, TTY, etc
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.lowlevel.FdStream(fd: int)`

    Bases: [`Stream`](reference-io#trio.abc.Stream "trio.abc.Stream")

    Represents a stream given the file descriptor to a pipe, TTY, etc.

    *fd* must refer to a file that is open for reading and/or writing and supports non-blocking I/O (pipes and TTYs will work, on-disk files probably not). The returned stream takes ownership of the fd, so closing the stream will close the fd too. As with [`os.fdopen`](https://docs.python.org/3/library/os.html#os.fdopen "(in Python v3.11)"), you should not directly use an fd after you have wrapped it in a stream using this function.

    To be used as a Trio stream, an open file must be placed in non-blocking mode. Unfortunately, this impacts all I/O that goes through the underlying open file, including I/O that uses a different file descriptor than the one that was passed to Trio. If other threads or processes are using file descriptors that are related through [`os.dup`](https://docs.python.org/3/library/os.html#os.dup "(in Python v3.11)") or inheritance across [`os.fork`](https://docs.python.org/3/library/os.html#os.fork "(in Python v3.11)") to the one that Trio is using, they are unlikely to be prepared to have non-blocking I/O semantics suddenly thrust upon them. For example, you can use `FdStream(os.dup(sys.stdin.fileno()))` to obtain a stream for reading from standard input, but it is only safe to do so with heavy caveats: your stdin must not be shared by any other processes, and you must not make any calls to synchronous methods of [`sys.stdin`](https://docs.python.org/3/library/sys.html#sys.stdin "(in Python v3.11)") until the stream returned by [`FdStream`](#trio.lowlevel.FdStream "trio.lowlevel.FdStream") is closed. See [issue \#174](https://github.com/python-trio/trio/issues/174) for a discussion of the challenges involved in relaxing this restriction.

    #### Parameters:

    **fd** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The fd to be wrapped.

    #### Returns:

    A new [`FdStream`](#trio.lowlevel.FdStream "trio.lowlevel.FdStream") object.

    ### Kqueue-specific API

    TODO: these are implemented, but are currently more of a sketch than anything real. See [\#26](https://github.com/python-trio/trio/issues/26).
- name: trio.lowlevel.monitor_completion_key
  id: reference-lowlevel#trio.lowlevel.monitor_completion_key
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`with`*` trio.lowlevel.monitor_completion_key() as queue`

    ## Global state: system tasks and run-local variables
- name: trio.lowlevel.monitor_kevent
  id: reference-lowlevel#trio.lowlevel.monitor_kevent
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`with`*` trio.lowlevel.monitor_kevent(ident, filter) as queue`

    ### Windows-specific API
- name: trio.lowlevel.notify_closing
  id: reference-lowlevel#trio.lowlevel.notify_closing
  summary: Call this before closing a file descriptor (on Unix) or socket (on Windows)
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.notify_closing(obj)`

    Call this before closing a file descriptor (on Unix) or socket (on Windows). This will cause any [`wait_readable`](#trio.lowlevel.wait_readable "trio.lowlevel.wait_readable") or [`wait_writable`](#trio.lowlevel.wait_writable "trio.lowlevel.wait_writable") calls on the given object to immediately wake up and raise [`ClosedResourceError`](reference-core#trio.ClosedResourceError "trio.ClosedResourceError").

    This doesn’t actually close the object – you still have to do that yourself afterwards. Also, you want to be careful to make sure no new tasks start waiting on the object in between when you call this and when it’s actually closed. So to close something properly, you usually want to do these steps in order:

    1.  Explicitly mark the object as closed, so that any new attempts to use it will abort before they start.

    2.  Call [`notify_closing`](#trio.lowlevel.notify_closing "trio.lowlevel.notify_closing") to wake up any already-existing users.

    3.  Actually close the object.

    It’s also possible to do them in a different order if that’s more convenient, *but only if* you make sure not to have any checkpoints in between the steps. This way they all happen in a single atomic step, so other tasks won’t be able to tell what order they happened in anyway.

    ### Unix-specific API

    [`FdStream`](#trio.lowlevel.FdStream "trio.lowlevel.FdStream") supports wrapping Unix files (such as a pipe or TTY) as a stream.

    If you have two different file descriptors for sending and receiving, and want to bundle them together into a single bidirectional [`Stream`](reference-io#trio.abc.Stream "trio.abc.Stream"), then use [`trio.StapledStream`](reference-io#trio.StapledStream "trio.StapledStream"):

    ``` python
    bidirectional_stream = trio.StapledStream(
        trio.lowlevel.FdStream(write_fd),
        trio.lowlevel.FdStream(read_fd)
    )
    ```
- name: trio.lowlevel.open_process
  id: reference-lowlevel#trio.lowlevel.open_process
  summary: Execute a child program in a new process
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.open_process(command, *, stdin=None, stdout=None, stderr=None, **options) → Process`

    Execute a child program in a new process.

    After construction, you can interact with the child process by writing data to its [`stdin`](reference-io#trio.Process.stdin "trio.Process.stdin") stream (a [`SendStream`](reference-io#trio.abc.SendStream "trio.abc.SendStream")), reading data from its [`stdout`](reference-io#trio.Process.stdout "trio.Process.stdout") and/or [`stderr`](reference-io#trio.Process.stderr "trio.Process.stderr") streams (both [`ReceiveStream`](reference-io#trio.abc.ReceiveStream "trio.abc.ReceiveStream")s), sending it signals using [`terminate`](reference-io#trio.Process.terminate "trio.Process.terminate"), [`kill`](reference-io#trio.Process.kill "trio.Process.kill"), or [`send_signal`](reference-io#trio.Process.send_signal "trio.Process.send_signal"), and waiting for it to exit using [`wait`](reference-io#trio.Process.wait "trio.Process.wait"). See [`trio.Process`](reference-io#trio.Process "trio.Process") for details.

    Each standard stream is only available if you specify that a pipe should be created for it. For example, if you pass `stdin=subprocess.PIPE`, you can write to the [`stdin`](reference-io#trio.Process.stdin "trio.Process.stdin") stream, else [`stdin`](reference-io#trio.Process.stdin "trio.Process.stdin") will be `None`.

    Unlike [`trio.run_process`](reference-io#trio.run_process "trio.run_process"), this function doesn’t do any kind of automatic management of the child process. It’s up to you to implement whatever semantics you want.

    #### Parameters:

    - **command** ([*list*](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.11)") *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")) – The command to run. Typically this is a sequence of strings such as `['ls',``'-l',``'directory``with``spaces']`, where the first element names the executable to invoke and the other elements specify its arguments. With `shell=True` in the `**options`, or on Windows, `command` may alternatively be a string, which will be parsed following platform-dependent [quoting rules](reference-io#subprocess-quoting).

    - **stdin** – Specifies what the child process’s standard input stream should connect to: output written by the parent (`subprocess.PIPE`), nothing (`subprocess.DEVNULL`), or an open file (pass a file descriptor or something whose `fileno` method returns one). If `stdin` is unspecified, the child process will have the same standard input stream as its parent.

    - **stdout** – Like `stdin`, but for the child process’s standard output stream.

    - **stderr** – Like `stdin`, but for the child process’s standard error stream. An additional value `subprocess.STDOUT` is supported, which causes the child’s standard output and standard error messages to be intermixed on a single standard output stream, attached to whatever the `stdout` option says to attach it to.

    - **\*\*options** – Other [general subprocess options](reference-io#subprocess-options) are also accepted.

    #### Returns:

    A new [`trio.Process`](reference-io#trio.Process "trio.Process") object.

    #### Raises:

    [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") – if the process spawning fails, for example because the specified command could not be found.

    ## Low-level I/O primitives

    Different environments expose different low-level APIs for performing async I/O. [`trio.lowlevel`](#module-trio.lowlevel "trio.lowlevel") exposes these APIs in a relatively direct way, so as to allow maximum power and flexibility for higher level code. However, this means that the exact API provided may vary depending on what system Trio is running on.

    ### Universally available API

    All environments provide the following functions:
- name: trio.lowlevel.ParkingLot
  id: reference-lowlevel#trio.lowlevel.ParkingLot
  summary: A fair wait queue with cancellation and requeueing
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.lowlevel.ParkingLot`

    A fair wait queue with cancellation and requeueing.

    This class encapsulates the tricky parts of implementing a wait queue. It’s useful for implementing higher-level synchronization primitives like queues and locks.

    In addition to the methods below, you can use `len(parking_lot)` to get the number of parked tasks, and `if``parking_lot:``...` to check whether there are any parked tasks.
- name: trio.lowlevel.ParkingLot.park
  id: reference-lowlevel#trio.lowlevel.ParkingLot.park
  summary: Park the current task until woken by a call to unpark() or unpark_all()
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` park()`

    Park the current task until woken by a call to [`unpark()`](#trio.lowlevel.ParkingLot.unpark "trio.lowlevel.ParkingLot.unpark") or [`unpark_all()`](#trio.lowlevel.ParkingLot.unpark_all "trio.lowlevel.ParkingLot.unpark_all").
- name: trio.lowlevel.ParkingLot.repark
  id: reference-lowlevel#trio.lowlevel.ParkingLot.repark
  summary: Move parked tasks from one ParkingLot object to another
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `repark(new_lot, *, count=1)`

    Move parked tasks from one [`ParkingLot`](#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot") object to another.

    This dequeues `count` tasks from one lot, and requeues them on another, preserving order. For example:

    ``` python
    async def parker(lot):
        print("sleeping")
        await lot.park()
        print("woken")

    async def main():
        lot1 = trio.lowlevel.ParkingLot()
        lot2 = trio.lowlevel.ParkingLot()
        async with trio.open_nursery() as nursery:
            nursery.start_soon(parker, lot1)
            await trio.testing.wait_all_tasks_blocked()
            assert len(lot1) == 1
            assert len(lot2) == 0
            lot1.repark(lot2)
            assert len(lot1) == 0
            assert len(lot2) == 1
            # This wakes up the task that was originally parked in lot1
            lot2.unpark()
    ```

    If there are fewer than `count` tasks parked, then reparks as many tasks as are available and then returns successfully.

    #### Parameters:

    - **new_lot** ([*ParkingLot*](#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot")) – the parking lot to move tasks to.

    - **count** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – the number of tasks to move.
- name: trio.lowlevel.ParkingLot.repark_all
  id: reference-lowlevel#trio.lowlevel.ParkingLot.repark_all
  summary: Move all parked tasks from one ParkingLot object to another
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `repark_all(new_lot)`

    Move all parked tasks from one [`ParkingLot`](#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot") object to another.

    See [`repark()`](#trio.lowlevel.ParkingLot.repark "trio.lowlevel.ParkingLot.repark") for details.
- name: trio.lowlevel.ParkingLot.statistics
  id: reference-lowlevel#trio.lowlevel.ParkingLot.statistics
  summary: Return an object containing debugging information
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `statistics()`

    Return an object containing debugging information.

    Currently the following fields are defined:

    - `tasks_waiting`: The number of tasks blocked on this lot’s [`park()`](#trio.lowlevel.ParkingLot.park "trio.lowlevel.ParkingLot.park") method.
- name: trio.lowlevel.ParkingLot.unpark
  id: reference-lowlevel#trio.lowlevel.ParkingLot.unpark
  summary: Unpark one or more tasks
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `unpark(*, count=1)`

    Unpark one or more tasks.

    This wakes up `count` tasks that are blocked in [`park()`](#trio.lowlevel.ParkingLot.park "trio.lowlevel.ParkingLot.park"). If there are fewer than `count` tasks parked, then wakes as many tasks are available and then returns successfully.

    #### Parameters:

    **count** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – the number of tasks to unpark.
- name: trio.lowlevel.ParkingLot.unpark_all
  id: reference-lowlevel#trio.lowlevel.ParkingLot.unpark_all
  summary: Unpark all parked tasks
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `unpark_all()`

    Unpark all parked tasks.

    ### Low-level checkpoint functions
- name: trio.lowlevel.permanently_detach_coroutine_object
  id: reference-lowlevel#trio.lowlevel.permanently_detach_coroutine_object
  summary: Permanently detach the current task from the Trio scheduler
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.permanently_detach_coroutine_object(final_outcome)`

    Permanently detach the current task from the Trio scheduler.

    Normally, a Trio task doesn’t exit until its coroutine object exits. When you call this function, Trio acts like the coroutine object just exited and the task terminates with the given outcome. This is useful if you want to permanently switch the coroutine object over to a different coroutine runner.

    When the calling coroutine enters this function it’s running under Trio, and when the function returns it’s running under the foreign coroutine runner.

    You should make sure that the coroutine object has released any Trio-specific resources it has acquired (e.g. nurseries).

    #### Parameters:

    **final_outcome** ([*outcome.Outcome*](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome "(in outcome v1.2.0+dev)")) – Trio acts as if the current task exited with the given return value or exception.

    Returns or raises whatever value or exception the new coroutine runner uses to resume the coroutine.
- name: trio.lowlevel.reattach_detached_coroutine_object
  id: reference-lowlevel#trio.lowlevel.reattach_detached_coroutine_object
  summary: Reattach a coroutine object that was detached using temporarily_detach_coroutine_object()
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: "### *`await`*` trio.lowlevel.reattach_detached_coroutine_object(task, yield_value)`\n\nReattach a coroutine object that was detached using [`temporarily_detach_coroutine_object()`](#trio.lowlevel.temporarily_detach_coroutine_object \"trio.lowlevel.temporarily_detach_coroutine_object\").\n\nWhen the calling coroutine enters this function it’s running under the foreign coroutine runner, and when the function returns it’s running under Trio.\n\nThis must be called from inside the coroutine being resumed, and yields whatever value you pass in. (Presumably you’ll pass a value that will cause the current coroutine runner to stop scheduling this task.) Then the coroutine is resumed by the Trio scheduler at the next opportunity.\n\n#### Parameters:\n\n- **task** ([*Task*](#trio.lowlevel.Task \"trio.lowlevel.Task\")) – The Trio task object that the current coroutine was detached from.\n\n- **yield_value** ([*object*](https://docs.python.org/3/library/functions.html#object \"(in Python v3.11)\")) – The object to yield to the current coroutine runner.\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-lowlevel.html](https://trio.readthedocs.io/en/v0.22.2/reference-lowlevel.html)"
- name: trio.lowlevel.register_with_iocp
  id: reference-lowlevel#trio.lowlevel.register_with_iocp
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### `trio.lowlevel.register_with_iocp(handle)`'
- name: trio.lowlevel.remove_instrument
  id: reference-lowlevel#trio.lowlevel.remove_instrument
  summary: Stop instrumenting the current run loop with the given instrument
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.remove_instrument(instrument: Instrument) → None`

    Stop instrumenting the current run loop with the given instrument.

    #### Parameters:

    **instrument** ([*trio.abc.Instrument*](#trio.abc.Instrument "trio.abc.Instrument")) – The instrument to de-activate.

    #### Raises:

    [**KeyError**](https://docs.python.org/3/library/exceptions.html#KeyError "(in Python v3.11)") – if the instrument is not currently active. This could occur either because you never added it, or because you added it and then it raised an unhandled exception and was automatically deactivated.

    And here’s the interface to implement if you want to build your own [`Instrument`](#trio.abc.Instrument "trio.abc.Instrument"):
- name: trio.lowlevel.reschedule
  id: reference-lowlevel#trio.lowlevel.reschedule
  summary: Reschedule the given task with the given outcome.Outcome
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.reschedule(task, next_send=`

    Reschedule the given task with the given [`outcome.Outcome`](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome "(in outcome v1.2.0+dev)").

    See [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled") for the gory details.

    There must be exactly one call to [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule") for every call to [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled"). (And when counting, keep in mind that returning [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED "trio.lowlevel.Abort.SUCCEEDED") from an abort callback is equivalent to calling [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule") once.)

    #### Parameters:

    - **task** ([*trio.lowlevel.Task*](#trio.lowlevel.Task "trio.lowlevel.Task")) – the task to be rescheduled. Must be blocked in a call to [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled").

    - **next_send** ([*outcome.Outcome*](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome "(in outcome v1.2.0+dev)")) – the value (or error) to return (or raise) from [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled").

    Here’s an example lock class implemented using [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled") directly. This implementation has a number of flaws, including lack of fairness, O(n) cancellation, missing error checking, failure to insert a checkpoint on the non-blocking path, etc. If you really want to implement your own lock, then you should study the implementation of [`trio.Lock`](reference-core#trio.Lock "trio.Lock") and use [`ParkingLot`](#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot"), which handles some of these issues for you. But this does serve to illustrate the basic structure of the [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled") API:

    ``` python
    class NotVeryGoodLock:
        def __init__(self):
            self._blocked_tasks = collections.deque()
            self._held = False

        async def acquire(self):
            # We might have to try several times to acquire the lock.
            while self._held:
                # Someone else has the lock, so we have to wait.
                task = trio.lowlevel.current_task()
                self._blocked_tasks.append(task)
                def abort_fn(_):
                    self._blocked_tasks.remove(task)
                    return trio.lowlevel.Abort.SUCCEEDED
                await trio.lowlevel.wait_task_rescheduled(abort_fn)
                # At this point the lock was released -- but someone else
                # might have swooped in and taken it again before we
                # woke up. So we loop around to check the 'while' condition
                # again.
            # if we reach this point, it means that the 'while' condition
            # has just failed, so we know no-one is holding the lock, and
            # we can take it.
            self._held = True

        def release(self):
            self._held = False
            if self._blocked_tasks:
                woken_task = self._blocked_tasks.popleft()
                trio.lowlevel.reschedule(woken_task)
    ```

    ## Task API
- name: trio.lowlevel.RunVar
  id: reference-lowlevel#trio.lowlevel.RunVar
  summary: The run-local variant of a context variable
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.lowlevel.RunVar(name, default=`

    The run-local variant of a context variable.

    [`RunVar`](#trio.lowlevel.RunVar "trio.lowlevel.RunVar") objects are similar to context variable objects, except that they are shared across a single call to [`trio.run()`](reference-core#trio.run "trio.run") rather than a single task.
- name: trio.lowlevel.spawn_system_task
  id: reference-lowlevel#trio.lowlevel.spawn_system_task
  summary: Spawn a “system” task
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.spawn_system_task(async_fn, *args, name=None, context=None)`

    Spawn a “system” task.

    System tasks have a few differences from regular tasks:

    - They don’t need an explicit nursery; instead they go into the internal “system nursery”.

    - If a system task raises an exception, then it’s converted into a [`TrioInternalError`](reference-core#trio.TrioInternalError "trio.TrioInternalError") and *all* tasks are cancelled. If you write a system task, you should be careful to make sure it doesn’t crash.

    - System tasks are automatically cancelled when the main task exits.

    - By default, system tasks have [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") protection *enabled*. If you want your task to be interruptible by control-C, then you need to use [`disable_ki_protection()`](#trio.lowlevel.disable_ki_protection "trio.lowlevel.disable_ki_protection") explicitly (and come up with some plan for what to do with a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)"), given that system tasks aren’t allowed to raise exceptions).

    - System tasks do not inherit context variables from their creator.

    Towards the end of a call to [`trio.run()`](reference-core#trio.run "trio.run"), after the main task and all system tasks have exited, the system nursery becomes closed. At this point, new calls to [`spawn_system_task()`](#trio.lowlevel.spawn_system_task "trio.lowlevel.spawn_system_task") will raise `RuntimeError("Nursery``is``closed``to``new``arrivals")` instead of creating a system task. It’s possible to encounter this state either in a `finally` block in an async generator, or in a callback passed to [`TrioToken.run_sync_soon()`](#trio.lowlevel.TrioToken.run_sync_soon "trio.lowlevel.TrioToken.run_sync_soon") at the right moment.

    #### Parameters:

    - **async_fn** – An async callable.

    - **args** – Positional arguments for `async_fn`. If you want to pass keyword arguments, use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial "(in Python v3.11)").

    - **name** – The name for this task. Only used for debugging/introspection (e.g. `repr(task_obj)`). If this isn’t a string, [`spawn_system_task()`](#trio.lowlevel.spawn_system_task "trio.lowlevel.spawn_system_task") will try to make it one. A common use case is if you’re wrapping a function before spawning a new task, you might pass the original function as the `name=` to make debugging easier.

    - **context** – An optional `contextvars.Context` object with context variables to use for this task. You would normally get a copy of the current context with `context``=``contextvars.copy_context()` and then you would pass that `context` object here.

    #### Returns:

    the newly spawned task

    #### Return type:

    [Task](#trio.lowlevel.Task "trio.lowlevel.Task")

    ## Trio tokens
- name: trio.lowlevel.start_guest_run
  id: reference-lowlevel#trio.lowlevel.start_guest_run
  summary: Start a “guest” run of Trio on top of some other “host” event loop
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.start_guest_run(async_fn, *args, run_sync_soon_threadsafe, done_callback, run_sync_soon_not_threadsafe=None, host_uses_signal_set_wakeup_fd: bool = False, clock=None, instruments=(), restrict_keyboard_interrupt_to_checkpoints: bool = False, strict_exception_groups: bool = False)`

    Start a “guest” run of Trio on top of some other “host” event loop.

    Each host loop can only have one guest run at a time.

    You should always let the Trio run finish before stopping the host loop; if not, it may leave Trio’s internal data structures in an inconsistent state. You might be able to get away with it if you immediately exit the program, but it’s safest not to go there in the first place.

    Generally, the best way to do this is wrap this in a function that starts the host loop and then immediately starts the guest run, and then shuts down the host when the guest run completes.

    #### Parameters:

    - **run_sync_soon_threadsafe** –

      An arbitrary callable, which will be passed a function as its sole argument:

      ``` python
      def my_run_sync_soon_threadsafe(fn):
          ...
      ```

      This callable should schedule `fn()` to be run by the host on its next pass through its loop. **Must support being called from arbitrary threads.**

    - **done_callback** –

      An arbitrary callable:

      ``` python
      def my_done_callback(run_outcome):
          ...
      ```

      When the Trio run has finished, Trio will invoke this callback to let you know. The argument is an [`outcome.Outcome`](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome "(in outcome v1.2.0+dev)"), reporting what would have been returned or raised by [`trio.run`](reference-core#trio.run "trio.run"). This function can do anything you want, but commonly you’ll want it to shut down the host loop, unwrap the outcome, etc.

    - **run_sync_soon_not_threadsafe** – Like `run_sync_soon_threadsafe`, but will only be called from inside the host loop’s main thread. Optional, but if your host loop allows you to implement this more efficiently than `run_sync_soon_threadsafe` then passing it will make things a bit faster.

    - **host_uses_signal_set_wakeup_fd** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – Pass [`True`](https://docs.python.org/3/library/constants.html#True "(in Python v3.11)") if your host loop uses [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)"), and [`False`](https://docs.python.org/3/library/constants.html#False "(in Python v3.11)") otherwise. For more details, see [Implementing guest mode for your favorite event loop](#guest-run-implementation).

    For the meaning of other arguments, see [`trio.run`](reference-core#trio.run "trio.run").

    ## Handing off live coroutine objects between coroutine runners

    Internally, Python’s async/await syntax is built around the idea of “coroutine objects” and “coroutine runners”. A coroutine object represents the state of an async callstack. But by itself, this is just a static object that sits there. If you want it to do anything, you need a coroutine runner to push it forward. Every Trio task has an associated coroutine object (see [`Task.coro`](#trio.lowlevel.Task.coro "trio.lowlevel.Task.coro")), and the Trio scheduler acts as their coroutine runner.

    But of course, Trio isn’t the only coroutine runner in Python – [`asyncio`](https://docs.python.org/3/library/asyncio.html#module-asyncio "(in Python v3.11)") has one, other event loops have them, you can even define your own.

    And in some very, very unusual circumstances, it even makes sense to transfer a single coroutine object back and forth between different coroutine runners. That’s what this section is about. This is an *extremely* exotic use case, and assumes a lot of expertise in how Python async/await works internally. For motivating examples, see [trio-asyncio issue \#42](https://github.com/python-trio/trio-asyncio/issues/42), and [trio issue \#649](https://github.com/python-trio/trio/issues/649). For more details on how coroutines work, we recommend André Caron’s [A tale of event loops](https://github.com/AndreLouisCaron/a-tale-of-event-loops), or going straight to [PEP 492](https://www.python.org/dev/peps/pep-0492/) for the full details.
- name: trio.lowlevel.start_thread_soon
  id: reference-lowlevel#trio.lowlevel.start_thread_soon
  summary: Runs deliver(outcome.capture(fn)) in a worker thread
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `trio.lowlevel.start_thread_soon(fn, deliver, name: str | None = None)`

    Runs `deliver(outcome.capture(fn))` in a worker thread.

    Generally `fn` does some blocking work, and `deliver` delivers the result back to whoever is interested.

    This is a low-level, no-frills interface, very similar to using [`threading.Thread`](https://docs.python.org/3/library/threading.html#threading.Thread "(in Python v3.11)") to spawn a thread directly. The main difference is that this function tries to re-use threads when possible, so it can be a bit faster than [`threading.Thread`](https://docs.python.org/3/library/threading.html#threading.Thread "(in Python v3.11)").

    Worker threads have the [`daemon`](https://docs.python.org/3/library/threading.html#threading.Thread.daemon "(in Python v3.11)") flag set, which means that if your main thread exits, worker threads will automatically be killed. If you want to make sure that your `fn` runs to completion, then you should make sure that the main thread remains alive until `deliver` is called.

    It is safe to call this function simultaneously from multiple threads.

    #### Parameters:

    - **fn** (*sync function*) – Performs arbitrary blocking work.

    - **deliver** (*sync function*) – Takes the [`outcome.Outcome`](https://outcome.readthedocs.io/en/latest/api.html#outcome.Outcome "(in outcome v1.2.0+dev)") of `fn`, and delivers it. *Must not block.*

    Because worker threads are cached and reused for multiple calls, neither function should mutate thread-level state, like [`threading.local`](https://docs.python.org/3/library/threading.html#threading.local "(in Python v3.11)") objects – or if they do, they should be careful to revert their changes before returning.

    > #### Note
    >
    > The split between `fn` and `deliver` serves two purposes. First, it’s convenient, since most callers need something like this anyway.
    >
    > Second, it avoids a small race condition that could cause too many threads to be spawned. Consider a program that wants to run several jobs sequentially on a thread, so the main thread submits a job, waits for it to finish, submits another job, etc. In theory, this program should only need one worker thread. But what could happen is:
    >
    > 1.  Worker thread: First job finishes, and calls `deliver`.
    >
    > 2.  Main thread: receives notification that the job finished, and calls `start_thread_soon`.
    >
    > 3.  Main thread: sees that no worker threads are marked idle, so spawns a second worker thread.
    >
    > 4.  Original worker thread: marks itself as idle.
    >
    > To avoid this, threads mark themselves as idle *before* calling `deliver`.
    >
    > Is this potential extra thread a major problem? Maybe not, but it’s easy enough to avoid, and we figure that if the user is trying to limit how many threads they’re using then it’s polite to respect that.

    ## Safer KeyboardInterrupt handling

    Trio’s handling of control-C is designed to balance usability and safety. On the one hand, there are sensitive regions (like the core scheduling loop) where it’s simply impossible to handle arbitrary [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") exceptions while maintaining our core correctness invariants. On the other, if the user accidentally writes an infinite loop, we do want to be able to break out of that. Our solution is to install a default signal handler which checks whether it’s safe to raise [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") at the place where the signal is received. If so, then we do; otherwise, we schedule a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") to be delivered to the main task at the next available opportunity (similar to how [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled") is delivered).

    So that’s great, but – how do we know whether we’re in one of the sensitive parts of the program or not?

    This is determined on a function-by-function basis. By default:

    - The top-level function in regular user tasks is unprotected.

    - The top-level function in system tasks is protected.

    - If a function doesn’t specify otherwise, then it inherits the protection state of its caller.

    This means you only need to override the defaults at places where you transition from protected code to unprotected code or vice-versa.

    These transitions are accomplished using two function decorators:
- name: trio.lowlevel.Task
  id: reference-lowlevel#trio.lowlevel.Task
  summary: A Task object represents a concurrent “thread” of execution
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.lowlevel.Task`

    A [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") object represents a concurrent “thread” of execution. It has no public constructor; Trio internally creates a [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") object for each call to `nursery.start(...)` or `nursery.start_soon(...)`.

    Its public members are mostly useful for introspection and debugging:
- name: trio.lowlevel.Task.child_nurseries
  id: reference-lowlevel#trio.lowlevel.Task.child_nurseries
  summary: The nurseries this task contains
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `child_nurseries`

    The nurseries this task contains.

    This is a list, with outer nurseries before inner nurseries.
- name: trio.lowlevel.Task.context
  id: reference-lowlevel#trio.lowlevel.Task.context
  summary: This task’s contextvars.Context object
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `context`

    This task’s [`contextvars.Context`](https://docs.python.org/3/library/contextvars.html#contextvars.Context "(in Python v3.11)") object.
- name: trio.lowlevel.Task.coro
  id: reference-lowlevel#trio.lowlevel.Task.coro
  summary: This task’s coroutine object
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `coro`

    This task’s coroutine object.
- name: trio.lowlevel.Task.custom_sleep_data
  id: reference-lowlevel#trio.lowlevel.Task.custom_sleep_data
  summary: Trio doesn’t assign this variable any meaning, except that it sets it to None whenever a task is rescheduled
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `custom_sleep_data`

    Trio doesn’t assign this variable any meaning, except that it sets it to `None` whenever a task is rescheduled. It can be used to share data between the different tasks involved in putting a task to sleep and then waking it up again. (See [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled") for details.)

    ## Using “guest mode” to run Trio on top of other event loops

    ### What is “guest mode”?

    An event loop acts as a central coordinator to manage all the IO happening in your program. Normally, that means that your application has to pick one event loop, and use it for everything. But what if you like Trio, but also need to use a framework like [Qt](https://en.wikipedia.org/wiki/Qt_(software)) or [PyGame](https://www.pygame.org/) that has its own event loop? Then you need some way to run both event loops at once.

    It is possible to combine event loops, but the standard approaches all have significant downsides:

    - **Polling:** this is where you use a [busy-loop](https://en.wikipedia.org/wiki/Busy_waiting) to manually check for IO on both event loops many times per second. This adds latency, and wastes CPU time and electricity.

    - **Pluggable IO backends:** this is where you reimplement one of the event loop APIs on top of the other, so you effectively end up with just one event loop. This requires a significant amount of work for each pair of event loops you want to integrate, and different backends inevitably end up with inconsistent behavior, forcing users to program against the least-common-denominator. And if the two event loops expose different feature sets, it may not even be possible to implement one in terms of the other.

    - **Running the two event loops in separate threads:** This works, but most event loop APIs aren’t thread-safe, so in this approach you need to keep careful track of which code runs on which event loop, and remember to use explicit inter-thread messaging whenever you interact with the other loop – or else risk obscure race conditions and data corruption.

    That’s why Trio offers a fourth option: **guest mode**. Guest mode lets you execute [`trio.run`](reference-core#trio.run "trio.run") on top of some other “host” event loop, like Qt. Its advantages are:

    - Efficiency: guest mode is event-driven instead of using a busy-loop, so it has low latency and doesn’t waste electricity.

    - No need to think about threads: your Trio code runs in the same thread as the host event loop, so you can freely call sync Trio APIs from the host, and call sync host APIs from Trio. For example, if you’re making a GUI app with Qt as the host loop, then making a [cancel button](https://doc.qt.io/qt-5/qpushbutton.html) and connecting it to a [`trio.CancelScope`](reference-core#trio.CancelScope "trio.CancelScope") is as easy as writing:

      ``` python
      # Trio code can create Qt objects without any special ceremony...
      my_cancel_button = QPushButton("Cancel")
      # ...and Qt can call back to Trio just as easily
      my_cancel_button.clicked.connect(my_cancel_scope.cancel)
      ```

      (For async APIs, it’s not that simple, but you can use sync APIs to build explicit bridges between the two worlds, e.g. by passing async functions and their results back and forth through queues.)

    - Consistent behavior: guest mode uses the same code as regular Trio: the same scheduler, same IO code, same everything. So you get the full feature set and everything acts the way you expect.

    - Simple integration and broad compatibility: pretty much every event loop offers some threadsafe “schedule a callback” operation, and that’s all you need to use it as a host loop.

    ### Really? How is that possible?

    > #### Note
    >
    > You can use guest mode without reading this section. It’s included for those who enjoy understanding how things work.

    All event loops have the same basic structure. They loop through two operations, over and over:

    1.  Wait for the operating system to notify them that something interesting has happened, like data arriving on a socket or a timeout passing. They do this by invoking a platform-specific `sleep_until_something_happens()` system call – `select`, `epoll`, `kqueue`, `GetQueuedCompletionEvents`, etc.

    2.  Run all the user tasks that care about whatever happened, then go back to step 1.

    The problem here is step 1. Two different event loops on the same thread can take turns running user tasks in step 2, but when they’re idle and nothing is happening, they can’t both invoke their own `sleep_until_something_happens()` function at the same time.

    The “polling” and “pluggable backend” strategies solve this by hacking the loops so both step 1s can run at the same time in the same thread. Keeping everything in one thread is great for step 2, but the step 1 hacks create problems.

    The “separate threads” strategy solves this by moving both steps into separate threads. This makes step 1 work, but the downside is that now the user tasks in step 2 are running separate threads as well, so users are forced to deal with inter-thread coordination.

    The idea behind guest mode is to combine the best parts of each approach: we move Trio’s step 1 into a separate worker thread, while keeping Trio’s step 2 in the main host thread. This way, when the application is idle, both event loops do their `sleep_until_something_happens()` at the same time in their own threads. But when the app wakes up and your code is actually running, it all happens in a single thread. The threading trickiness is all handled transparently inside Trio.

    Concretely, we unroll Trio’s internal event loop into a chain of callbacks, and as each callback finishes, it schedules the next callback onto the host loop or a worker thread as appropriate. So the only thing the host loop has to provide is a way to schedule a callback onto the main thread from a worker thread.

    Coordinating between Trio and the host loop does add some overhead. The main cost is switching in and out of the background thread, since this requires cross-thread messaging. This is cheap (on the order of a few microseconds, assuming your host loop is implemented efficiently), but it’s not free.

    But, there’s a nice optimization we can make: we only *need* the thread when our `sleep_until_something_happens()` call actually sleeps, that is, when the Trio part of your program is idle and has nothing to do. So before we switch into the worker thread, we double-check whether we’re idle, and if not, then we skip the worker thread and jump directly to step 2. This means that your app only pays the extra thread-switching penalty at moments when it would otherwise be sleeping, so it should have minimal effect on your app’s overall performance.

    The total overhead will depend on your host loop, your platform, your application, etc. But we expect that in most cases, apps running in guest mode should only be 5-10% slower than the same code using [`trio.run`](reference-core#trio.run "trio.run"). If you find that’s not true for your app, then please let us know and we’ll see if we can fix it!

    ### Implementing guest mode for your favorite event loop

    Let’s walk through what you need to do to integrate Trio’s guest mode with your favorite event loop. Treat this section like a checklist.

    **Getting started:** The first step is to get something basic working. Here’s a minimal example of running Trio on top of asyncio, that you can use as a model:

    ``` python
    import asyncio, trio

    # A tiny Trio program
    async def trio_main():
        for _ in range(5):
            print("Hello from Trio!")
            # This is inside Trio, so we have to use Trio APIs
            await trio.sleep(1)
        return "trio done!"

    # The code to run it as a guest inside asyncio
    async def asyncio_main():
        asyncio_loop = asyncio.get_running_loop()

        def run_sync_soon_threadsafe(fn):
            asyncio_loop.call_soon_threadsafe(fn)

        def done_callback(trio_main_outcome):
            print(f"Trio program ended with: {trio_main_outcome}")

        # This is where the magic happens:
        trio.lowlevel.start_guest_run(
            trio_main,
            run_sync_soon_threadsafe=run_sync_soon_threadsafe,
            done_callback=done_callback,
        )

        # Let the host loop run for a while to give trio_main time to
        # finish. (WARNING: This is a hack. See below for better
        # approaches.)
        #
        # This function is in asyncio, so we have to use asyncio APIs.
        await asyncio.sleep(10)

    asyncio.run(asyncio_main())
    ```

    You can see we’re using asyncio-specific APIs to start up a loop, and then we call [`trio.lowlevel.start_guest_run`](#trio.lowlevel.start_guest_run "trio.lowlevel.start_guest_run"). This function is very similar to [`trio.run`](reference-core#trio.run "trio.run"), and takes all the same arguments. But it has two differences:

    First, instead of blocking until `trio_main` has finished, it schedules `trio_main` to start running on top of the host loop, and then returns immediately. So `trio_main` is running in the background – that’s why we have to sleep and give it time to finish.

    And second, it requires two extra keyword arguments: `run_sync_soon_threadsafe`, and `done_callback`.

    For `run_sync_soon_threadsafe`, we need a function that takes a synchronous callback, and schedules it to run on your host loop. And this function needs to be “threadsafe” in the sense that you can safely call it from any thread. So you need to figure out how to write a function that does that using your host loop’s API. For asyncio, this is easy because [`call_soon_threadsafe`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_soon_threadsafe "(in Python v3.11)") does exactly what we need; for your loop, it might be more or less complicated.

    For `done_callback`, you pass in a function that Trio will automatically invoke when the Trio run finishes, so you know it’s done and what happened. For this basic starting version, we just print the result; in the next section we’ll discuss better alternatives.

    At this stage you should be able to run a simple Trio program inside your host loop. Now we’ll turn that prototype into something solid.

    **Loop lifetimes:** One of the trickiest things in most event loops is shutting down correctly. And having two event loops makes this even harder!

    If you can, we recommend following this pattern:

    - Start up your host loop

    - Immediately call [`start_guest_run`](#trio.lowlevel.start_guest_run "trio.lowlevel.start_guest_run") to start Trio

    - When Trio finishes and your `done_callback` is invoked, shut down the host loop

    - Make sure that nothing else shuts down your host loop

    This way, your two event loops have the same lifetime, and your program automatically exits when your Trio function finishes.

    Here’s how we’d extend our asyncio example to implement this pattern:

    ``` python
    # Improved version, that shuts down properly after Trio finishes
    async def asyncio_main():
        asyncio_loop = asyncio.get_running_loop()

        def run_sync_soon_threadsafe(fn):
            asyncio_loop.call_soon_threadsafe(fn)

        # Revised 'done' callback: set a Future
        done_fut = asyncio_loop.create_future()
        def done_callback(trio_main_outcome):
            done_fut.set_result(trio_main_outcome)

        trio.lowlevel.start_guest_run(
            trio_main,
            run_sync_soon_threadsafe=run_sync_soon_threadsafe,
            done_callback=done_callback,
        )

        # Wait for the guest run to finish
        trio_main_outcome = await done_fut
        # Pass through the return value or exception from the guest run
        return trio_main_outcome.unwrap()
    ```

    And then you can encapsulate all this machinery in a utility function that exposes a [`trio.run`](reference-core#trio.run "trio.run")-like API, but runs both loops together:

    ``` python
    def trio_run_with_asyncio(trio_main, *args, **trio_run_kwargs):
        async def asyncio_main():
            # same as above
            ...

        return asyncio.run(asyncio_main())
    ```

    Technically, it is possible to use other patterns. But there are some important limitations you have to respect:

    - **You must let the Trio program run to completion.** Many event loops let you stop the event loop at any point, and any pending callbacks/tasks/etc. just… don’t run. Trio follows a more structured system, where you can cancel things, but the code always runs to completion, so `finally` blocks run, resources are cleaned up, etc. If you stop your host loop early, before the `done_callback` is invoked, then that cuts off the Trio run in the middle without a chance to clean up. This can leave your code in an inconsistent state, and will definitely leave Trio’s internals in an inconsistent state, which will cause errors if you try to use Trio again in that thread.

      Some programs need to be able to quit at any time, for example in response to a GUI window being closed or a user selecting a “Quit” from a menu. In these cases, we recommend wrapping your whole program in a [`trio.CancelScope`](reference-core#trio.CancelScope "trio.CancelScope"), and cancelling it when you want to quit.

    - Each host loop can only have one [`start_guest_run`](#trio.lowlevel.start_guest_run "trio.lowlevel.start_guest_run") at a time. If you try to start a second one, you’ll get an error. If you need to run multiple Trio functions at the same time, then start up a single Trio run, open a nursery, and then start your functions as child tasks in that nursery.

    - Unless you or your host loop register a handler for [`signal.SIGINT`](https://docs.python.org/3/library/signal.html#signal.SIGINT "(in Python v3.11)") before starting Trio (this is not common), then Trio will take over delivery of [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)")s. And since Trio can’t tell which host code is safe to interrupt, it will only deliver [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") into the Trio part of your code. This is fine if your program is set up to exit when the Trio part exits, because the [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") will propagate out of Trio and then trigger the shutdown of your host loop, which is just what you want.

    Given these constraints, we think the simplest approach is to always start and stop the two loops together.

    **Signal management:**[“Signals”](https://en.wikipedia.org/wiki/Signal_(IPC)) are a low-level inter-process communication primitive. When you hit control-C to kill a program, that uses a signal. Signal handling in Python has [a lot of moving parts](https://vorpus.org/blog/control-c-handling-in-python-and-trio/). One of those parts is [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)"), which event loops use to make sure that they wake up when a signal arrives so they can respond to it. (If you’ve ever had an event loop ignore you when you hit control-C, it was probably because they weren’t using [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)") correctly.)

    But, only one event loop can use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)") at a time. And in guest mode that can cause problems: Trio and the host loop might start fighting over who’s using [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)").

    Some event loops, like asyncio, won’t work correctly unless they win this fight. Fortunately, Trio is a little less picky: as long as *someone* makes sure that the program wakes up when a signal arrives, it should work correctly. So if your host loop wants [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)"), then you should disable Trio’s [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)") support, and then both loops will work correctly.

    On the other hand, if your host loop doesn’t use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)"), then the only way to make everything work correctly is to *enable* Trio’s [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)") support.

    By default, Trio assumes that your host loop doesn’t use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)"). It does try to detect when this creates a conflict with the host loop, and print a warning – but unfortunately, by the time it detects it, the damage has already been done. So if you’re getting this warning, then you should disable Trio’s [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)") support by passing `host_uses_signal_set_wakeup_fd=True` to [`start_guest_run`](#trio.lowlevel.start_guest_run "trio.lowlevel.start_guest_run").

    If you aren’t seeing any warnings with your initial prototype, you’re *probably* fine. But the only way to be certain is to check your host loop’s source. For example, asyncio may or may not use [`signal.set_wakeup_fd`](https://docs.python.org/3/library/signal.html#signal.set_wakeup_fd "(in Python v3.11)") depending on the Python version and operating system.

    **A small optimization:** Finally, consider a small optimization. Some event loops offer two versions of their “call this function soon” API: one that can be used from any thread, and one that can only be used from the event loop thread, with the latter being cheaper. For example, asyncio has both [`call_soon_threadsafe`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_soon_threadsafe "(in Python v3.11)") and [`call_soon`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_soon "(in Python v3.11)").

    If you have a loop like this, then you can also pass a `run_sync_soon_not_threadsafe=...` kwarg to [`start_guest_run`](#trio.lowlevel.start_guest_run "trio.lowlevel.start_guest_run"), and Trio will automatically use it when appropriate.

    If your loop doesn’t have a split like this, then don’t worry about it; `run_sync_soon_not_threadsafe=` is optional. (If it’s not passed, then Trio will just use your threadsafe version in all cases.)

    **That’s it!** If you’ve followed all these steps, you should now have a cleanly-integrated hybrid event loop. Go make some cool GUIs/games/whatever!

    ### Limitations

    In general, almost all Trio features should work in guest mode. The exception is features which rely on Trio having a complete picture of everything that your program is doing, since obviously, it can’t control the host loop or see what it’s doing.

    Custom clocks can be used in guest mode, but they only affect Trio timeouts, not host loop timeouts. And the [autojump clock](reference-testing#testing-time) and related [`trio.testing.wait_all_tasks_blocked`](reference-testing#trio.testing.wait_all_tasks_blocked "trio.testing.wait_all_tasks_blocked") can technically be used in guest mode, but they’ll only take Trio tasks into account when decided whether to jump the clock or whether all tasks are blocked.

    ### Reference
- name: trio.lowlevel.Task.eventual_parent_nursery
  id: reference-lowlevel#trio.lowlevel.Task.eventual_parent_nursery
  summary: The nursery this task will be inside after it calls task_status.started()
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `eventual_parent_nursery`

    The nursery this task will be inside after it calls `task_status.started()`.

    If this task has already called `started()`, or if it was not spawned using [`nursery.start()`](reference-core#trio.Nursery.start "trio.Nursery.start"), then its [`eventual_parent_nursery`](#trio.lowlevel.Task.eventual_parent_nursery "trio.lowlevel.Task.eventual_parent_nursery") is `None`.
- name: trio.lowlevel.Task.iter_await_frames
  id: reference-lowlevel#trio.lowlevel.Task.iter_await_frames
  summary: Iterates recursively over the coroutine-like objects this task is waiting on, yielding the frame and line number at each frame
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`for ... in`*` iter_await_frames()`

    Iterates recursively over the coroutine-like objects this task is waiting on, yielding the frame and line number at each frame.

    This is similar to [`traceback.walk_stack`](https://docs.python.org/3/library/traceback.html#traceback.walk_stack "(in Python v3.11)") in a synchronous context. Note that [`traceback.walk_stack`](https://docs.python.org/3/library/traceback.html#traceback.walk_stack "(in Python v3.11)") returns frames from the bottom of the call stack to the top, while this function starts from [`Task.coro`](#trio.lowlevel.Task.coro "trio.lowlevel.Task.coro") and works it way down.

    Example usage: extracting a stack trace:

    ``` python
    import traceback

    def print_stack_for_task(task):
        ss = traceback.StackSummary.extract(task.iter_await_frames())
        print("".join(ss.format()))
    ```
- name: trio.lowlevel.Task.name
  id: reference-lowlevel#trio.lowlevel.Task.name
  summary: String containing this Task's name
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `name`

    String containing this [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task")'s name. Usually the name of the function this [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") is running, but can be overridden by passing `name=` to `start` or `start_soon`.
- name: trio.lowlevel.Task.parent_nursery
  id: reference-lowlevel#trio.lowlevel.Task.parent_nursery
  summary: The nursery this task is inside (or None if this is the “init” task)
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `parent_nursery`

    The nursery this task is inside (or None if this is the “init” task).

    Example use case: drawing a visualization of the task tree in a debugger.
- name: trio.lowlevel.temporarily_detach_coroutine_object
  id: reference-lowlevel#trio.lowlevel.temporarily_detach_coroutine_object
  summary: Temporarily detach the current coroutine object from the Trio scheduler
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.temporarily_detach_coroutine_object(abort_func)`

    Temporarily detach the current coroutine object from the Trio scheduler.

    When the calling coroutine enters this function it’s running under Trio, and when the function returns it’s running under the foreign coroutine runner.

    The Trio [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") will continue to exist, but will be suspended until you use [`reattach_detached_coroutine_object()`](#trio.lowlevel.reattach_detached_coroutine_object "trio.lowlevel.reattach_detached_coroutine_object") to resume it. In the mean time, you can use another coroutine runner to schedule the coroutine object. In fact, you have to – the function doesn’t return until the coroutine is advanced from outside.

    Note that you’ll need to save the current [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") object to later resume; you can retrieve it with [`current_task()`](#trio.lowlevel.current_task "trio.lowlevel.current_task"). You can also use this [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") object to retrieve the coroutine object – see [`Task.coro`](#trio.lowlevel.Task.coro "trio.lowlevel.Task.coro").

    #### Parameters:

    **abort_func** – Same as for [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled"), except that it must return [`Abort.FAILED`](#trio.lowlevel.Abort.FAILED "trio.lowlevel.Abort.FAILED"). (If it returned [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED "trio.lowlevel.Abort.SUCCEEDED"), then Trio would attempt to reschedule the detached task directly without going through [`reattach_detached_coroutine_object()`](#trio.lowlevel.reattach_detached_coroutine_object "trio.lowlevel.reattach_detached_coroutine_object"), which would be bad.) Your `abort_func` should still arrange for whatever the coroutine object is doing to be cancelled, and then reattach to Trio and call the `raise_cancel` callback, if possible.

    Returns or raises whatever value or exception the new coroutine runner uses to resume the coroutine.
- name: trio.lowlevel.TrioToken
  id: reference-lowlevel#trio.lowlevel.TrioToken
  summary: An opaque object representing a single call to trio.run()
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`class`*` trio.lowlevel.TrioToken`

    An opaque object representing a single call to [`trio.run()`](reference-core#trio.run "trio.run").

    It has no public constructor; instead, see [`current_trio_token()`](#trio.lowlevel.current_trio_token "trio.lowlevel.current_trio_token").

    This object has two uses:

    1.  It lets you re-enter the Trio run loop from external threads or signal handlers. This is the low-level primitive that [`trio.to_thread()`](reference-core#module-trio.to_thread "trio.to_thread") and [`trio.from_thread`](reference-core#module-trio.from_thread "trio.from_thread") use to communicate with worker threads, that [`trio.open_signal_receiver`](reference-io#trio.open_signal_receiver "trio.open_signal_receiver") uses to receive notifications about signals, and so forth.

    2.  Each call to [`trio.run()`](reference-core#trio.run "trio.run") has exactly one associated [`TrioToken`](#trio.lowlevel.TrioToken "trio.lowlevel.TrioToken") object, so you can use it to identify a particular call.
- name: trio.lowlevel.TrioToken.run_sync_soon
  id: reference-lowlevel#trio.lowlevel.TrioToken.run_sync_soon
  summary: Schedule a call to sync_fn(*args) to occur in the context of a Trio task
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### `run_sync_soon(sync_fn, *args, idempotent=False)`

    Schedule a call to `sync_fn(*args)` to occur in the context of a Trio task.

    This is safe to call from the main thread, from other threads, and from signal handlers. This is the fundamental primitive used to re-enter the Trio run loop from outside of it.

    The call will happen “soon”, but there’s no guarantee about exactly when, and no mechanism provided for finding out when it’s happened. If you need this, you’ll have to build your own.

    The call is effectively run as part of a system task (see [`spawn_system_task()`](#trio.lowlevel.spawn_system_task "trio.lowlevel.spawn_system_task")). In particular this means that:

    - [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") protection is *enabled* by default; if you want `sync_fn` to be interruptible by control-C, then you need to use [`disable_ki_protection()`](#trio.lowlevel.disable_ki_protection "trio.lowlevel.disable_ki_protection") explicitly.

    - If `sync_fn` raises an exception, then it’s converted into a [`TrioInternalError`](reference-core#trio.TrioInternalError "trio.TrioInternalError") and *all* tasks are cancelled. You should be careful that `sync_fn` doesn’t crash.

    All calls with `idempotent=False` are processed in strict first-in first-out order.

    If `idempotent=True`, then `sync_fn` and `args` must be hashable, and Trio will make a best-effort attempt to discard any call submission which is equal to an already-pending call. Trio will process these in first-in first-out order.

    Any ordering guarantees apply separately to `idempotent=False` and `idempotent=True` calls; there’s no rule for how calls in the different categories are ordered with respect to each other.

    #### Raises:

    [**trio.RunFinishedError**](reference-core#trio.RunFinishedError "trio.RunFinishedError") – if the associated call to [`trio.run()`](reference-core#trio.run "trio.run") has already exited. (Any call that *doesn’t* raise this error is guaranteed to be fully processed before [`trio.run()`](reference-core#trio.run "trio.run") exits.)
- name: trio.lowlevel.wait_kevent
  id: reference-lowlevel#trio.lowlevel.wait_kevent
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### *`await`*` trio.lowlevel.wait_kevent(ident, filter, abort_func)`'
- name: trio.lowlevel.wait_overlapped
  id: reference-lowlevel#trio.lowlevel.wait_overlapped
  summary: null
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: '### *`await`*` trio.lowlevel.wait_overlapped(handle, lpOverlapped)`'
- name: trio.lowlevel.wait_readable
  id: reference-lowlevel#trio.lowlevel.wait_readable
  summary: Block until the kernel reports that the given object is readable
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.wait_readable(obj)`

    Block until the kernel reports that the given object is readable.

    On Unix systems, `obj` must either be an integer file descriptor, or else an object with a `.fileno()` method which returns an integer file descriptor. Any kind of file descriptor can be passed, though the exact semantics will depend on your kernel. For example, this probably won’t do anything useful for on-disk files.

    On Windows systems, `obj` must either be an integer `SOCKET` handle, or else an object with a `.fileno()` method which returns an integer `SOCKET` handle. File descriptors aren’t supported, and neither are handles that refer to anything besides a `SOCKET`.

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if another task is already waiting for the given socket to become readable.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if another task calls [`notify_closing()`](#trio.lowlevel.notify_closing "trio.lowlevel.notify_closing") while this function is still working.
- name: trio.lowlevel.wait_task_rescheduled
  id: reference-lowlevel#trio.lowlevel.wait_task_rescheduled
  summary: Put the current task to sleep, with cancellation support
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.wait_task_rescheduled(abort_func: Callable[[Callable[[], NoReturn]], Abort]) → Any`

    Put the current task to sleep, with cancellation support.

    This is the lowest-level API for blocking in Trio. Every time a [`Task`](#trio.lowlevel.Task "trio.lowlevel.Task") blocks, it does so by calling this function (usually indirectly via some higher-level API).

    This is a tricky interface with no guard rails. If you can use [`ParkingLot`](#trio.lowlevel.ParkingLot "trio.lowlevel.ParkingLot") or the built-in I/O wait functions instead, then you should.

    Generally the way it works is that before calling this function, you make arrangements for “someone” to call [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule") on the current task at some later point.

    Then you call [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled"), passing in `abort_func`, an “abort callback”.

    (Terminology: in Trio, “aborting” is the process of attempting to interrupt a blocked task to deliver a cancellation.)

    There are two possibilities for what happens next:

    1.  “Someone” calls [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule") on the current task, and [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled") returns or raises whatever value or error was passed to [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule").

    2.  The call’s context transitions to a cancelled state (e.g. due to a timeout expiring). When this happens, the `abort_func` is called. Its interface looks like:

        ``` python
        def abort_func(raise_cancel):
            ...
            return trio.lowlevel.Abort.SUCCEEDED  # or FAILED
        ```

        It should attempt to clean up any state associated with this call, and in particular, arrange that [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule") will *not* be called later. If (and only if!) it is successful, then it should return [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED "trio.lowlevel.Abort.SUCCEEDED"), in which case the task will automatically be rescheduled with an appropriate [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled") error.

        Otherwise, it should return [`Abort.FAILED`](#trio.lowlevel.Abort.FAILED "trio.lowlevel.Abort.FAILED"). This means that the task can’t be cancelled at this time, and still has to make sure that “someone” eventually calls [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule").

        At that point there are again two possibilities. You can simply ignore the cancellation altogether: wait for the operation to complete and then reschedule and continue as normal. (For example, this is what [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync "trio.to_thread.run_sync") does if cancellation is disabled.) The other possibility is that the `abort_func` does succeed in cancelling the operation, but for some reason isn’t able to report that right away. (Example: on Windows, it’s possible to request that an async (“overlapped”) I/O operation be cancelled, but this request is *also* asynchronous – you don’t find out until later whether the operation was actually cancelled or not.) To report a delayed cancellation, then you should reschedule the task yourself, and call the `raise_cancel` callback passed to `abort_func` to raise a [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled") (or possibly [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)")) exception into this task. Either of the approaches sketched below can work:

        ``` python
        # Option 1:
        # Catch the exception from raise_cancel and inject it into the task.
        # (This is what Trio does automatically for you if you return
        # Abort.SUCCEEDED.)
        trio.lowlevel.reschedule(task, outcome.capture(raise_cancel))

        # Option 2:
        # wait to be woken by "someone", and then decide whether to raise
        # the error from inside the task.
        outer_raise_cancel = None
        def abort(inner_raise_cancel):
            nonlocal outer_raise_cancel
            outer_raise_cancel = inner_raise_cancel
            TRY_TO_CANCEL_OPERATION()
            return trio.lowlevel.Abort.FAILED
        await wait_task_rescheduled(abort)
        if OPERATION_WAS_SUCCESSFULLY_CANCELLED:
            # raises the error
            outer_raise_cancel()
        ```

        In any case it’s guaranteed that we only call the `abort_func` at most once per call to [`wait_task_rescheduled()`](#trio.lowlevel.wait_task_rescheduled "trio.lowlevel.wait_task_rescheduled").

    Sometimes, it’s useful to be able to share some mutable sleep-related data between the sleeping task, the abort function, and the waking task. You can use the sleeping task’s [`custom_sleep_data`](#trio.lowlevel.Task.custom_sleep_data "trio.lowlevel.Task.custom_sleep_data") attribute to store this data, and Trio won’t touch it, except to make sure that it gets cleared when the task is rescheduled.

    > #### Warning
    >
    > If your `abort_func` raises an error, or returns any value other than [`Abort.SUCCEEDED`](#trio.lowlevel.Abort.SUCCEEDED "trio.lowlevel.Abort.SUCCEEDED") or [`Abort.FAILED`](#trio.lowlevel.Abort.FAILED "trio.lowlevel.Abort.FAILED"), then Trio will crash violently. Be careful! Similarly, it is entirely possible to deadlock a Trio program by failing to reschedule a blocked task, or cause havoc by calling [`reschedule()`](#trio.lowlevel.reschedule "trio.lowlevel.reschedule") too many times. Remember what we said up above about how you should use a higher-level API if at all possible?
- name: trio.lowlevel.wait_writable
  id: reference-lowlevel#trio.lowlevel.wait_writable
  summary: Block until the kernel reports that the given object is writable
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.wait_writable(obj)`

    Block until the kernel reports that the given object is writable.

    See [`wait_readable`](#trio.lowlevel.wait_readable "trio.lowlevel.wait_readable") for the definition of `obj`.

    #### Raises:

    - [**trio.BusyResourceError**](reference-core#trio.BusyResourceError "trio.BusyResourceError") – if another task is already waiting for the given socket to become writable.

    - [**trio.ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if another task calls [`notify_closing()`](#trio.lowlevel.notify_closing "trio.lowlevel.notify_closing") while this function is still working.
- name: trio.lowlevel.WaitForSingleObject
  id: reference-lowlevel#trio.lowlevel.WaitForSingleObject
  summary: Async and cancellable variant of WaitForSingleObject
  belongs_to: Introspecting and extending Trio with trio.lowlevel
  description: |-
    ### *`await`*` trio.lowlevel.WaitForSingleObject(handle)`

    Async and cancellable variant of [WaitForSingleObject](https://msdn.microsoft.com/en-us/library/windows/desktop/ms687032(v=vs.85).aspx). Windows only.

    #### Parameters:

    **handle** – A Win32 object handle, as a Python integer.

    #### Raises:

    [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") – If the handle is invalid, e.g. when it is already closed.

    TODO: these are implemented, but are currently more of a sketch than anything real. See [\#26](https://github.com/python-trio/trio/issues/26) and [\#52](https://github.com/python-trio/trio/issues/52).
- name: trio.MemoryReceiveChannel
  id: reference-core#trio.MemoryReceiveChannel
  summary: null
  belongs_to: Trio’s core functionality
  description: '### *`class`*` trio.MemoryReceiveChannel(*args: object, **kwargs: object)`'
- name: trio.MemoryReceiveChannel.clone
  id: reference-core#trio.MemoryReceiveChannel.clone
  summary: Clone this receive channel object
  belongs_to: Trio’s core functionality
  description: |-
    ### `clone() → MemoryReceiveChannel[ReceiveType]`

    Clone this receive channel object.

    This returns a new [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel "trio.MemoryReceiveChannel") object, which acts as a duplicate of the original: receiving on the new object does exactly the same thing as receiving on the old object.

    However, closing one of the objects does not close the other, and the underlying channel is not closed until all clones are closed. (If you’re familiar with [`os.dup`](https://docs.python.org/3/library/os.html#os.dup "(in Python v3.11)"), then this is a similar idea.)

    This is useful for communication patterns that involve multiple consumers all receiving objects from the same underlying channel. See [Managing multiple producers and/or multiple consumers](#channel-mpmc) for examples.

    > #### Warning
    >
    > The clones all share the same underlying channel. Whenever a clone [`receive()`](#trio.MemoryReceiveChannel.receive "trio.MemoryReceiveChannel.receive")s a value, it is removed from the channel and the other clones do *not* receive that value. If you want to send multiple copies of the same stream of values to multiple destinations, like [`itertools.tee()`](https://docs.python.org/3/library/itertools.html#itertools.tee "(in Python v3.11)"), then you need to find some other solution; this method does *not* do that.

    #### Raises:

    [**trio.ClosedResourceError**](#trio.ClosedResourceError "trio.ClosedResourceError") – if you already closed this [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel "trio.MemoryReceiveChannel") object.
- name: trio.MemoryReceiveChannel.close
  id: reference-core#trio.MemoryReceiveChannel.close
  summary: Close this receive channel object synchronously
  belongs_to: Trio’s core functionality
  description: |-
    ### `close() → None`

    Close this receive channel object synchronously.

    All channel objects have an asynchronous [`aclose`](reference-io#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") method. Memory channels can also be closed synchronously. This has the same effect on the channel and other tasks using it, but [`close`](#trio.MemoryReceiveChannel.close "trio.MemoryReceiveChannel.close") is not a trio checkpoint. This simplifies cleaning up in cancelled tasks.

    Using `with``receive_channel:` will close the channel object on leaving the with block.
- name: trio.MemoryReceiveChannel.receive
  id: reference-core#trio.MemoryReceiveChannel.receive
  summary: See ReceiveChannel.receive
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` receive() → ReceiveType`

    See [`ReceiveChannel.receive`](reference-io#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive").

    Memory channels allow multiple tasks to call [`receive`](#trio.MemoryReceiveChannel.receive "trio.MemoryReceiveChannel.receive") at the same time. The first task will get the first item sent, the second task will get the second item sent, and so on.
- name: trio.MemoryReceiveChannel.receive_nowait
  id: reference-core#trio.MemoryReceiveChannel.receive_nowait
  summary: Like receive, but if there’s nothing ready to receive, raises WouldBlock instead of blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `receive_nowait() → ReceiveType`

    Like [`receive`](reference-io#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive"), but if there’s nothing ready to receive, raises [`WouldBlock`](#trio.WouldBlock "trio.WouldBlock") instead of blocking.

    #### A simple channel example

    Here’s a simple example of how to use memory channels:

    ``` python
    import trio


    async def main():
        async with trio.open_nursery() as nursery:
            # Open a channel:
            send_channel, receive_channel = trio.open_memory_channel(0)
            # Start a producer and a consumer, passing one end of the channel to
            # each of them:
            nursery.start_soon(producer, send_channel)
            nursery.start_soon(consumer, receive_channel)


    async def producer(send_channel):
        # Producer sends 3 messages
        for i in range(3):
            # The producer sends using 'await send_channel.send(...)'
            await send_channel.send(f"message {i}")


    async def consumer(receive_channel):
        # The consumer uses an 'async for' loop to receive the values:
        async for value in receive_channel:
            print(f"got value {value!r}")


    trio.run(main)
    ```

    If you run this, it prints:

        got value "message 0"
        got value "message 1"
        got value "message 2"

    And then it hangs forever. (Use control-C to quit.)

    #### Clean shutdown with channels

    Of course we don’t generally like it when programs hang. What happened? The problem is that the producer sent 3 messages and then exited, but the consumer has no way to tell that the producer is gone: for all it knows, another message might be coming along any moment. So it hangs forever waiting for the 4th message.

    Here’s a new version that fixes this: it produces the same output as the previous version, and then exits cleanly. The only change is the addition of `async``with` blocks inside the producer and consumer:

    ``` python
    import trio


    async def main():
        async with trio.open_nursery() as nursery:
            send_channel, receive_channel = trio.open_memory_channel(0)
            nursery.start_soon(producer, send_channel)
            nursery.start_soon(consumer, receive_channel)


    async def producer(send_channel):
        async with send_channel:
            for i in range(3):
                await send_channel.send(f"message {i}")


    async def consumer(receive_channel):
        async with receive_channel:
            async for value in receive_channel:
                print(f"got value {value!r}")


    trio.run(main)
    ```

    The really important thing here is the producer’s `async``with` . When the producer exits, this closes the `send_channel`, and that tells the consumer that no more messages are coming, so it can cleanly exit its `async``for` loop. Then the program shuts down because both tasks have exited.

    We also added an `async``with` to the consumer. This isn’t as important, but it can help us catch mistakes or other problems. For example, suppose that the consumer exited early for some reason – maybe because of a bug. Then the producer would be sending messages into the void, and might get stuck indefinitely. But, if the consumer closes its `receive_channel`, then the producer will get a [`BrokenResourceError`](#trio.BrokenResourceError "trio.BrokenResourceError") to alert it that it should stop sending messages because no-one is listening.

    If you want to see the effect of the consumer exiting early, try adding a `break` statement to the `async``for` loop – you should see a [`BrokenResourceError`](#trio.BrokenResourceError "trio.BrokenResourceError") from the producer.

    #### Managing multiple producers and/or multiple consumers

    You can also have multiple producers, and multiple consumers, all sharing the same channel. However, this makes shutdown a little more complicated.

    For example, consider this naive extension of our previous example, now with two producers and two consumers:

    ``` python
    # This example usually crashes!

    import trio
    import random


    async def main():
        async with trio.open_nursery() as nursery:
            send_channel, receive_channel = trio.open_memory_channel(0)
            # Start two producers
            nursery.start_soon(producer, "A", send_channel)
            nursery.start_soon(producer, "B", send_channel)
            # And two consumers
            nursery.start_soon(consumer, "X", receive_channel)
            nursery.start_soon(consumer, "Y", receive_channel)


    async def producer(name, send_channel):
        async with send_channel:
            for i in range(3):
                await send_channel.send(f"{i} from producer {name}")
                # Random sleeps help trigger the problem more reliably
                await trio.sleep(random.random())


    async def consumer(name, receive_channel):
        async with receive_channel:
            async for value in receive_channel:
                print(f"consumer {name} got value {value!r}")
                # Random sleeps help trigger the problem more reliably
                await trio.sleep(random.random())


    trio.run(main)
    ```

    The two producers, A and B, send 3 messages apiece. These are then randomly distributed between the two consumers, X and Y. So we’re hoping to see some output like:

        consumer Y got value '0 from producer B'
        consumer X got value '0 from producer A'
        consumer Y got value '1 from producer A'
        consumer Y got value '1 from producer B'
        consumer X got value '2 from producer B'
        consumer X got value '2 from producer A'

    However, on most runs, that’s not what happens – the first part of the output is OK, and then when we get to the end the program crashes with [`ClosedResourceError`](#trio.ClosedResourceError "trio.ClosedResourceError"). If you run the program a few times, you’ll see that sometimes the traceback shows `send` crashing, and other times it shows `receive` crashing, and you might even find that on some runs it doesn’t crash at all.

    Here’s what’s happening: suppose that producer A finishes first. It exits, and its `async``with` block closes the `send_channel`. But wait! Producer B was still using that `send_channel`… so the next time B calls `send`, it gets a [`ClosedResourceError`](#trio.ClosedResourceError "trio.ClosedResourceError").

    Sometimes, though if we’re lucky, the two producers might finish at the same time (or close enough), so they both make their last `send` before either of them closes the `send_channel`.

    But, even if that happens, we’re not out of the woods yet! After the producers exit, the two consumers race to be the first to notice that the `send_channel` has closed. Suppose that X wins the race. It exits its `async``for` loop, then exits the `async``with` block… and closes the `receive_channel`, while Y is still using it. Again, this causes a crash.

    We could avoid this by using some complicated bookkeeping to make sure that only the *last* producer and the *last* consumer close their channel endpoints… but that would be tiresome and fragile. Fortunately, there’s a better way! Here’s a fixed version of our program above:

    ``` python
    import trio
    import random


    async def main():
        async with trio.open_nursery() as nursery:
            send_channel, receive_channel = trio.open_memory_channel(0)
            async with send_channel, receive_channel:
                # Start two producers, giving each its own private clone
                nursery.start_soon(producer, "A", send_channel.clone())
                nursery.start_soon(producer, "B", send_channel.clone())
                # And two consumers, giving each its own private clone
                nursery.start_soon(consumer, "X", receive_channel.clone())
                nursery.start_soon(consumer, "Y", receive_channel.clone())


    async def producer(name, send_channel):
        async with send_channel:
            for i in range(3):
                await send_channel.send(f"{i} from producer {name}")
                # Random sleeps help trigger the problem more reliably
                await trio.sleep(random.random())


    async def consumer(name, receive_channel):
        async with receive_channel:
            async for value in receive_channel:
                print(f"consumer {name} got value {value!r}")
                # Random sleeps help trigger the problem more reliably
                await trio.sleep(random.random())


    trio.run(main)
    ```

    This example demonstrates using the [`MemorySendChannel.clone`](#trio.MemorySendChannel.clone "trio.MemorySendChannel.clone") and [`MemoryReceiveChannel.clone`](#trio.MemoryReceiveChannel.clone "trio.MemoryReceiveChannel.clone") methods. What these do is create copies of our endpoints, that act just like the original – except that they can be closed independently. And the underlying channel is only closed after *all* the clones have been closed. So this completely solves our problem with shutdown, and if you run this program, you’ll see it print its six lines of output and then exits cleanly.

    Notice a small trick we use: the code in `main` creates clone objects to pass into all the child tasks, and then closes the original objects using `async``with`. Another option is to pass clones into all-but-one of the child tasks, and then pass the original object into the last task, like:

    ``` python
    # Also works, but is more finicky:
    send_channel, receive_channel = trio.open_memory_channel(0)
    nursery.start_soon(producer, "A", send_channel.clone())
    nursery.start_soon(producer, "B", send_channel)
    nursery.start_soon(consumer, "X", receive_channel.clone())
    nursery.start_soon(consumer, "Y", receive_channel)
    ```

    But this is more error-prone, especially if you use a loop to spawn the producers/consumers.

    Just make sure that you don’t write:

    ``` python
    # Broken, will cause program to hang:
    send_channel, receive_channel = trio.open_memory_channel(0)
    nursery.start_soon(producer, "A", send_channel.clone())
    nursery.start_soon(producer, "B", send_channel.clone())
    nursery.start_soon(consumer, "X", receive_channel.clone())
    nursery.start_soon(consumer, "Y", receive_channel.clone())
    ```

    Here we pass clones into the tasks, but never close the original objects. That means we have 3 send channel objects (the original + two clones), but we only close 2 of them, so the consumers will hang around forever waiting for that last one to be closed.

    #### Buffering in channels

    When you call [`open_memory_channel()`](#trio.open_memory_channel "trio.open_memory_channel"), you have to specify how many values can be buffered internally in the channel. If the buffer is full, then any task that calls [`send()`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send") will stop and wait for another task to call [`receive()`](reference-io#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive"). This is useful because it produces *backpressure*: if the channel producers are running faster than the consumers, then it forces the producers to slow down.

    You can disable buffering entirely, by doing `open_memory_channel(0)`. In that case any task that calls [`send()`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send") will wait until another task calls [`receive()`](reference-io#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive"), and vice versa. This is similar to how channels work in the [classic Communicating Sequential Processes model](https://en.wikipedia.org/wiki/Channel_(programming)), and is a reasonable default if you aren’t sure what size buffer to use. (That’s why we used it in the examples above.)

    At the other extreme, you can make the buffer unbounded by using `open_memory_channel(math.inf)`. In this case, [`send()`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send") *always* returns immediately. Normally, this is a bad idea. To see why, consider a program where the producer runs more quickly than the consumer:

    ``` python
    # Simulate a producer that generates values 10x faster than the
    # consumer can handle them.

    import trio
    import math


    async def producer(send_channel):
        count = 0
        while True:
            # Pretend that we have to do some work to create this message, and it
            # takes 0.1 seconds:
            await trio.sleep(0.1)
            await send_channel.send(count)
            print("Sent message:", count)
            count += 1


    async def consumer(receive_channel):
        async for value in receive_channel:
            print("Received message:", value)
            # Pretend that we have to do some work to handle this message, and it
            # takes 1 second
            await trio.sleep(1)


    async def main():
        send_channel, receive_channel = trio.open_memory_channel(math.inf)
        async with trio.open_nursery() as nursery:
            nursery.start_soon(producer, send_channel)
            nursery.start_soon(consumer, receive_channel)


    trio.run(main)
    ```

    If you run this program, you’ll see output like:

        Sent message: 0
        Received message: 0
        Sent message: 1
        Sent message: 2
        Sent message: 3
        Sent message: 4
        Sent message: 5
        Sent message: 6
        Sent message: 7
        Sent message: 8
        Sent message: 9
        Received message: 1
        Sent message: 10
        Sent message: 11
        Sent message: 12
        ...

    On average, the producer sends ten messages per second, but the consumer only calls `receive` once per second. That means that each second, the channel’s internal buffer has to grow to hold an extra nine items. After a minute, the buffer will have ~540 items in it; after an hour, that grows to ~32,400. Eventually, the program will run out of memory. And well before we run out of memory, our latency on handling individual messages will become abysmal. For example, at the one minute mark, the producer is sending message ~600, but the consumer is still processing message ~60. Message 600 will have to sit in the channel for ~9 minutes before the consumer catches up and processes it.

    Now try replacing `open_memory_channel(math.inf)` with `open_memory_channel(0)`, and run it again. We get output like:

        Sent message: 0
        Received message: 0
        Received message: 1
        Sent message: 1
        Received message: 2
        Sent message: 2
        Sent message: 3
        Received message: 3
        ...

    Now the `send` calls wait for the `receive` calls to finish, which forces the producer to slow down to match the consumer’s speed. (It might look strange that some values are reported as “Received” before they’re reported as “Sent”; this happens because the actual send/receive happen at the same time, so which line gets printed first is random.)

    Now, let’s try setting a small but nonzero buffer size, like `open_memory_channel(3)`. what do you think will happen?

    I get:

        Sent message: 0
        Received message: 0
        Sent message: 1
        Sent message: 2
        Sent message: 3
        Received message: 1
        Sent message: 4
        Received message: 2
        Sent message: 5
        ...

    So you can see that the producer runs ahead by 3 messages, and then stops to wait: when the consumer reads message 1, it sends message 4, then when the consumer reads message 2, it sends message 5, and so on. Once it reaches the steady state, this version acts just like our previous version where we set the buffer size to 0, except that it uses a bit more memory and each message sits in the buffer for a bit longer before being processed (i.e., the message latency is higher).

    Of course real producers and consumers are usually more complicated than this, and in some situations, a modest amount of buffering might improve throughput. But too much buffering wastes memory and increases latency, so if you want to tune your application you should experiment to see what value works best for you.

    **Why do we even support unbounded buffers then?** Good question! Despite everything we saw above, there are times when you actually do need an unbounded buffer. For example, consider a web crawler that uses a channel to keep track of all the URLs it still wants to crawl. Each crawler runs a loop where it takes a URL from the channel, fetches it, checks the HTML for outgoing links, and then adds the new URLs to the channel. This creates a *circular flow*, where each consumer is also a producer. In this case, if your channel buffer gets full, then the crawlers will block when they try to add new URLs to the channel, and if all the crawlers got blocked, then they aren’t taking any URLs out of the channel, so they’re stuck forever in a deadlock. Using an unbounded channel avoids this, because it means that [`send()`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send") never blocks.

    ### Lower-level synchronization primitives

    Personally, I find that events and channels are usually enough to implement most things I care about, and lead to easier to read code than the lower-level primitives discussed in this section. But if you need them, they’re here. (If you find yourself reaching for these because you’re trying to implement a new higher-level synchronization primitive, then you might also want to check out the facilities in [`trio.lowlevel`](reference-lowlevel#module-trio.lowlevel "trio.lowlevel") for a more direct exposure of Trio’s underlying synchronization logic. All of classes discussed in this section are implemented on top of the public APIs in [`trio.lowlevel`](reference-lowlevel#module-trio.lowlevel "trio.lowlevel"); they don’t have any special access to Trio’s internals.)
- name: trio.MemorySendChannel
  id: reference-core#trio.MemorySendChannel
  summary: null
  belongs_to: Trio’s core functionality
  description: '### *`class`*` trio.MemorySendChannel(*args: object, **kwargs: object)`'
- name: trio.MemorySendChannel.clone
  id: reference-core#trio.MemorySendChannel.clone
  summary: Clone this send channel object
  belongs_to: Trio’s core functionality
  description: |-
    ### `clone() → MemorySendChannel[SendType]`

    Clone this send channel object.

    This returns a new [`MemorySendChannel`](#trio.MemorySendChannel "trio.MemorySendChannel") object, which acts as a duplicate of the original: sending on the new object does exactly the same thing as sending on the old object. (If you’re familiar with [`os.dup`](https://docs.python.org/3/library/os.html#os.dup "(in Python v3.11)"), then this is a similar idea.)

    However, closing one of the objects does not close the other, and receivers don’t get [`EndOfChannel`](#trio.EndOfChannel "trio.EndOfChannel") until *all* clones have been closed.

    This is useful for communication patterns that involve multiple producers all sending objects to the same destination. If you give each producer its own clone of the [`MemorySendChannel`](#trio.MemorySendChannel "trio.MemorySendChannel"), and then make sure to close each [`MemorySendChannel`](#trio.MemorySendChannel "trio.MemorySendChannel") when it’s finished, receivers will automatically get notified when all producers are finished. See [Managing multiple producers and/or multiple consumers](#channel-mpmc) for examples.

    #### Raises:

    [**trio.ClosedResourceError**](#trio.ClosedResourceError "trio.ClosedResourceError") – if you already closed this [`MemorySendChannel`](#trio.MemorySendChannel "trio.MemorySendChannel") object.
- name: trio.MemorySendChannel.close
  id: reference-core#trio.MemorySendChannel.close
  summary: Close this send channel object synchronously
  belongs_to: Trio’s core functionality
  description: |-
    ### `close() → None`

    Close this send channel object synchronously.

    All channel objects have an asynchronous [`aclose`](reference-io#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") method. Memory channels can also be closed synchronously. This has the same effect on the channel and other tasks using it, but [`close`](#trio.MemorySendChannel.close "trio.MemorySendChannel.close") is not a trio checkpoint. This simplifies cleaning up in cancelled tasks.

    Using `with``send_channel:` will close the channel object on leaving the with block.
- name: trio.MemorySendChannel.send
  id: reference-core#trio.MemorySendChannel.send
  summary: See SendChannel.send
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` send(value: SendType) → None`

    See [`SendChannel.send`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send").

    Memory channels allow multiple tasks to call [`send`](#trio.MemorySendChannel.send "trio.MemorySendChannel.send") at the same time.
- name: trio.MemorySendChannel.send_nowait
  id: reference-core#trio.MemorySendChannel.send_nowait
  summary: Like send, but if the channel’s buffer is full, raises WouldBlock instead of blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `send_nowait(value: SendType) → None`

    Like [`send`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send"), but if the channel’s buffer is full, raises [`WouldBlock`](#trio.WouldBlock "trio.WouldBlock") instead of blocking.
- name: trio.move_on_after
  id: reference-core#trio.move_on_after
  summary: Use as a context manager to create a cancel scope whose deadline is set to now + seconds
  belongs_to: Trio’s core functionality
  description: |-
    ### *`with`*` trio.move_on_after(seconds: float) → CancelScope as cancel_scope`

    Use as a context manager to create a cancel scope whose deadline is set to now + *seconds*.

    #### Parameters:

    **seconds** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The timeout.

    #### Raises:

    [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if timeout is less than zero or NaN.
- name: trio.move_on_at
  id: reference-core#trio.move_on_at
  summary: Use as a context manager to create a cancel scope with the given absolute deadline
  belongs_to: Trio’s core functionality
  description: |-
    ### *`with`*` trio.move_on_at(deadline: float) → CancelScope as cancel_scope`

    Use as a context manager to create a cancel scope with the given absolute deadline.

    #### Parameters:

    **deadline** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The deadline.

    #### Raises:

    [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if deadline is NaN.
- name: trio.NeedHandshakeError
  id: reference-io#trio.NeedHandshakeError
  summary: Some SSLStream methods can’t return any meaningful data until after the handshake
  belongs_to: I/O in Trio
  description: |-
    ### *`exception`*` trio.NeedHandshakeError`

    Some [`SSLStream`](#trio.SSLStream "trio.SSLStream") methods can’t return any meaningful data until after the handshake. If you call them before the handshake, they raise this error.

    ### Datagram TLS support

    Trio also has support for Datagram TLS (DTLS), which is like TLS but for unreliable UDP connections. This can be useful for applications where TCP’s reliable in-order delivery is problematic, like teleconferencing, latency-sensitive games, and VPNs.

    Currently, using DTLS with Trio requires PyOpenSSL. We hope to eventually allow the use of the stdlib [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl "(in Python v3.11)") module as well, but unfortunately that’s not yet possible.

    > #### Warning
    >
    > Note that PyOpenSSL is in many ways lower-level than the [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl "(in Python v3.11)") module – in particular, it currently **HAS NO BUILT-IN MECHANISM TO VALIDATE CERTIFICATES**. We *strongly* recommend that you use the [service-identity](https://pypi.org/project/service-identity/) library to validate hostnames and certificates.
- name: trio.Nursery
  id: reference-core#trio.Nursery
  summary: A context which may be used to spawn (or cancel) child tasks
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.Nursery`

    A context which may be used to spawn (or cancel) child tasks.

    Not constructed directly, use [`open_nursery`](#trio.open_nursery "trio.open_nursery") instead.

    The nursery will remain open until all child tasks have completed, or until it is cancelled, at which point it will cancel all its remaining child tasks and close.

    Nurseries ensure the absence of orphaned Tasks, since all running tasks will belong to an open Nursery.
- name: trio.Nursery.cancel_scope
  id: reference-core#trio.Nursery.cancel_scope
  summary: Creating a nursery also implicitly creates a cancellation scope, which is exposed as the cancel_scope attribute
  belongs_to: Trio’s core functionality
  description: |-
    ### `cancel_scope`

    Creating a nursery also implicitly creates a cancellation scope, which is exposed as the [`cancel_scope`](#trio.Nursery.cancel_scope "trio.Nursery.cancel_scope") attribute. This is used internally to implement the logic where if an error occurs then `__aexit__` cancels all children, but you can use it for other things, e.g. if you want to explicitly cancel all children in response to some external event.
- name: trio.Nursery.start
  id: reference-core#trio.Nursery.start
  summary: Creates and initializes a child task
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` start(async_fn, *args, name=None)`

    Creates and initializes a child task.

    Like [`start_soon()`](#trio.Nursery.start_soon "trio.Nursery.start_soon"), but blocks until the new task has finished initializing itself, and optionally returns some information from it.

    The `async_fn` must accept a `task_status` keyword argument, and it must make sure that it (or someone) eventually calls `task_status.started()`.

    The conventional way to define `async_fn` is like:

    ``` python
    async def async_fn(arg1, arg2, *, task_status=trio.TASK_STATUS_IGNORED):
        ...  # Caller is blocked waiting for this code to run
        task_status.started()
        ...  # This async code can be interleaved with the caller
    ```

    [`trio.TASK_STATUS_IGNORED`](#trio.TASK_STATUS_IGNORED "trio.TASK_STATUS_IGNORED") is a special global object with a do-nothing `started` method. This way your function supports being called either like `await``nursery.start(async_fn,``arg1,``arg2)` or directly like `await``async_fn(arg1,``arg2)`, and either way it can call `task_status.started()` without worrying about which mode it’s in. Defining your function like this will make it obvious to readers that it supports being used in both modes.

    Before the child calls `task_status.started()`, it’s effectively run underneath the call to [`start()`](#trio.Nursery.start "trio.Nursery.start"): if it raises an exception then that exception is reported by [`start()`](#trio.Nursery.start "trio.Nursery.start"), and does *not* propagate out of the nursery. If [`start()`](#trio.Nursery.start "trio.Nursery.start") is cancelled, then the child task is also cancelled.

    When the child calls `task_status.started()`, it’s moved out from underneath [`start()`](#trio.Nursery.start "trio.Nursery.start") and into the given nursery.

    If the child task passes a value to `task_status.started(value)`, then [`start()`](#trio.Nursery.start "trio.Nursery.start") returns this value. Otherwise it returns `None`.
- name: trio.Nursery.start_soon
  id: reference-core#trio.Nursery.start_soon
  summary: Creates a child task, scheduling await``async_fn(*args)
  belongs_to: Trio’s core functionality
  description: |-
    ### `start_soon(async_fn, *args, name=None)`

    Creates a child task, scheduling `await``async_fn(*args)`.

    If you want to run a function and immediately wait for its result, then you don’t need a nursery; just use `await``async_fn(*args)`. If you want to wait for the task to initialize itself before continuing, see [`start()`](#trio.Nursery.start "trio.Nursery.start"), the other fundamental method for creating concurrent tasks in Trio.

    Note that this is *not* an async function and you don’t use await when calling it. It sets up the new task, but then returns immediately, *before* the new task has a chance to do anything. New tasks may start running in any order, and at any checkpoint the scheduler chooses - at latest when the nursery is waiting to exit.

    It’s possible to pass a nursery object into another task, which allows that task to start new child tasks in the first task’s nursery.

    The child task inherits its parent nursery’s cancel scopes.

    #### Parameters:

    - **async_fn** – An async callable.

    - **args** – Positional arguments for `async_fn`. If you want to pass keyword arguments, use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial "(in Python v3.11)").

    - **name** – The name for this task. Only used for debugging/introspection (e.g. `repr(task_obj)`). If this isn’t a string, [`start_soon()`](#trio.Nursery.start_soon "trio.Nursery.start_soon") will try to make it one. A common use case is if you’re wrapping a function before spawning a new task, you might pass the original function as the `name=` to make debugging easier.

    #### Raises:

    [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – If this nursery is no longer open (i.e. its `async``with` block has exited).
- name: trio.open_file
  id: reference-io#trio.open_file
  summary: Asynchronous version of io.open()
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.open_file(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)`

    Asynchronous version of [`io.open()`](https://docs.python.org/3/library/io.html#io.open "(in Python v3.11)").

    #### Returns:

    An [asynchronous file object](https://trio.readthedocs.io/en/v0.22.2/glossary.html#term-asynchronous-file-object)

    Example:

    ``` python
    async with await trio.open_file(filename) as f:
        async for line in f:
            pass

    assert f.closed
    ```

    > #### See also
    >
    > [` ``trio.Path.open()`` `](#trio.Path.open "trio.Path.open")
- name: trio.open_memory_channel
  id: reference-core#trio.open_memory_channel
  summary: Open a channel for passing objects between tasks within a process
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.open_memory_channel(max_buffer_size)`

    Open a channel for passing objects between tasks within a process.

    Memory channels are lightweight, cheap to allocate, and entirely in-memory. They don’t involve any operating-system resources, or any kind of serialization. They just pass Python objects directly between tasks (with a possible stop in an internal buffer along the way).

    Channel objects can be closed by calling [`aclose`](reference-io#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") or using `async``with`. They are *not* automatically closed when garbage collected. Closing memory channels isn’t mandatory, but it is generally a good idea, because it helps avoid situations where tasks get stuck waiting on a channel when there’s no-one on the other side. See [Clean shutdown with channels](#channel-shutdown) for details.

    Memory channel operations are all atomic with respect to cancellation, either [`receive`](reference-io#trio.abc.ReceiveChannel.receive "trio.abc.ReceiveChannel.receive") will successfully return an object, or it will raise [`Cancelled`](#trio.Cancelled "trio.Cancelled") while leaving the channel unchanged.

    #### Parameters:

    **max_buffer_size** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *math.inf*) – The maximum number of items that can be buffered in the channel before [`send()`](reference-io#trio.abc.SendChannel.send "trio.abc.SendChannel.send") blocks. Choosing a sensible value here is important to ensure that backpressure is communicated promptly and avoid unnecessary latency; see [Buffering in channels](#channel-buffering) for more details. If in doubt, use 0.

    #### Returns:

    A pair `(send_channel,``receive_channel)`. If you have trouble remembering which order these go in, remember: data flows from left → right.

    In addition to the standard channel methods, all memory channel objects provide a `statistics()` method, which returns an object with the following fields:

    - `current_buffer_used`: The number of items currently stored in the channel buffer.

    - `max_buffer_size`: The maximum number of items allowed in the buffer, as passed to [`open_memory_channel()`](#trio.open_memory_channel "trio.open_memory_channel").

    - `open_send_channels`: The number of open [`MemorySendChannel`](#trio.MemorySendChannel "trio.MemorySendChannel") endpoints pointing to this channel. Initially 1, but can be increased by [`MemorySendChannel.clone()`](#trio.MemorySendChannel.clone "trio.MemorySendChannel.clone").

    - `open_receive_channels`: Likewise, but for open [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel "trio.MemoryReceiveChannel") endpoints.

    - `tasks_waiting_send`: The number of tasks blocked in `send` on this channel (summing over all clones).

    - `tasks_waiting_receive`: The number of tasks blocked in `receive` on this channel (summing over all clones).

    > #### Note
    >
    > If you’ve used the [`threading`](https://docs.python.org/3/library/threading.html#module-threading "(in Python v3.11)") or [`asyncio`](https://docs.python.org/3/library/asyncio.html#module-asyncio "(in Python v3.11)") modules, you may be familiar with [`queue.Queue`](https://docs.python.org/3/library/queue.html#queue.Queue "(in Python v3.11)") or [`asyncio.Queue`](https://docs.python.org/3/library/asyncio-queue.html#asyncio.Queue "(in Python v3.11)"). In Trio, [`open_memory_channel()`](#trio.open_memory_channel "trio.open_memory_channel") is what you use when you’re looking for a queue. The main difference is that Trio splits the classic queue interface up into two objects. The advantage of this is that it makes it possible to put the two ends in different processes without rewriting your code, and that we can close the two sides separately.

    [`MemorySendChannel`](#trio.MemorySendChannel "trio.MemorySendChannel") and [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel "trio.MemoryReceiveChannel") also expose several more features beyond the core channel interface:
- name: trio.open_nursery
  id: reference-core#trio.open_nursery
  summary: Returns an async context manager which must be used to create a new Nursery
  belongs_to: Trio’s core functionality
  description: |-
    ### *`async with`*` trio.open_nursery(strict_exception_groups: bool | None = None) → AbstractAsyncContextManager[Nursery] as nursery`

    Returns an async context manager which must be used to create a new [`Nursery`](#trio.Nursery "trio.Nursery").

    It does not block on entry; on exit it blocks until all child tasks have exited.

    #### Parameters:

    **strict_exception_groups** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – If true, even a single raised exception will be wrapped in an exception group. This will eventually become the default behavior. If not specified, uses the value passed to [`run()`](#trio.run "trio.run").
- name: trio.open_signal_receiver
  id: reference-io#trio.open_signal_receiver
  summary: A context manager for catching signals
  belongs_to: I/O in Trio
  description: "### *`with`*` trio.open_signal_receiver(*signals) as signal_aiter`\n\nA context manager for catching signals.\n\nEntering this context manager starts listening for the given signals and returns an async iterator; exiting the context manager stops listening.\n\nThe async iterator blocks until a signal arrives, and then yields it.\n\nNote that if you leave the `with` block while the iterator has unextracted signals still pending inside it, then they will be re-delivered using Python’s regular signal handling logic. This avoids a race condition when signals arrives just before we exit the `with` block.\n\n#### Parameters:\n\n**signals** – the signals to listen for.\n\n#### Raises:\n\n- [**TypeError**](https://docs.python.org/3/library/exceptions.html#TypeError \"(in Python v3.11)\") – if no signals were provided.\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if you try to use this anywhere except Python’s main thread. (This is a Python limitation.)\n\nExample\n\nA common convention for Unix daemons is that they should reload their configuration when they receive a `SIGHUP`. Here’s a sketch of what that might look like using [`open_signal_receiver()`](#trio.open_signal_receiver \"trio.open_signal_receiver\"):\n\n``` python\nwith trio.open_signal_receiver(signal.SIGHUP) as signal_aiter:\n    async for signum in signal_aiter:\n        assert signum == signal.SIGHUP\n        reload_configuration()\n```\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-io.html](https://trio.readthedocs.io/en/v0.22.2/reference-io.html)"
- name: trio.open_ssl_over_tcp_listeners
  id: reference-io#trio.open_ssl_over_tcp_listeners
  summary: Start listening for SSL/TLS-encrypted TCP connections to the given port
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.open_ssl_over_tcp_listeners(port, ssl_context, *, host=None, https_compatible=False, backlog=None)`

    Start listening for SSL/TLS-encrypted TCP connections to the given port.

    #### Parameters:

    - **port** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The port to listen on. See [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)")) – The SSL context to use for all incoming connections.

    - **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")*,* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")*, or* *None*) – The address to bind to; use `None` to bind to the wildcard address. See [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – See [`SSLStream`](#trio.SSLStream "trio.SSLStream") for details.

    - **backlog** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *None*) – See [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners") for details.

    ### SSL / TLS support

    Trio provides SSL/TLS support based on the standard library [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl "(in Python v3.11)") module. Trio’s [`SSLStream`](#trio.SSLStream "trio.SSLStream") and [`SSLListener`](#trio.SSLListener "trio.SSLListener") take their configuration from a [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)"), which you can create using [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context "(in Python v3.11)") and customize using the other constants and functions in the [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl "(in Python v3.11)") module.

    > #### Warning
    >
    > Avoid instantiating [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)") directly. A newly constructed [`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)") has less secure defaults than one returned by [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context "(in Python v3.11)").

    Instead of using [`ssl.SSLContext.wrap_socket()`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext.wrap_socket "(in Python v3.11)"), you create a [`SSLStream`](#trio.SSLStream "trio.SSLStream"):
- name: trio.open_ssl_over_tcp_stream
  id: reference-io#trio.open_ssl_over_tcp_stream
  summary: Make a TLS-encrypted Connection to the given host and port over TCP
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.open_ssl_over_tcp_stream(host, port, *, https_compatible=False, ssl_context=None, happy_eyeballs_delay=0.25)`

    Make a TLS-encrypted Connection to the given host and port over TCP.

    This is a convenience wrapper that calls [`open_tcp_stream()`](#trio.open_tcp_stream "trio.open_tcp_stream") and wraps the result in an [`SSLStream`](#trio.SSLStream "trio.SSLStream").

    This function does not perform the TLS handshake; you can do it manually by calling [`do_handshake()`](#trio.SSLStream.do_handshake "trio.SSLStream.do_handshake"), or else it will be performed automatically the first time you send or receive data.

    #### Parameters:

    - **host** ([*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)") *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")) – The host to connect to. We require the server to have a TLS certificate valid for this hostname.

    - **port** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The port to connect to.

    - **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – Set this to True if you’re connecting to a web server. See [`SSLStream`](#trio.SSLStream "trio.SSLStream") for details. Default: False.

    - **ssl_context** ([`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)") or None) – The SSL context to use. If None (the default), [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context "(in Python v3.11)") will be called to create a context.

    - **happy_eyeballs_delay** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – See [`open_tcp_stream()`](#trio.open_tcp_stream "trio.open_tcp_stream").

    #### Returns:

    the encrypted connection to the server.

    #### Return type:

    [trio.SSLStream](#trio.SSLStream "trio.SSLStream")
- name: trio.open_tcp_listeners
  id: reference-io#trio.open_tcp_listeners
  summary: Create SocketListener objects to listen for TCP connections
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.open_tcp_listeners(port, *, host=None, backlog=None)`

    Create [`SocketListener`](#trio.SocketListener "trio.SocketListener") objects to listen for TCP connections.

    #### Parameters:

    - **port** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) –

      The port to listen on.

      If you use 0 as your port, then the kernel will automatically pick an arbitrary open port. But be careful: if you use this feature when binding to multiple IP addresses, then each IP address will get its own random port, and the returned listeners will probably be listening on different ports. In particular, this will happen if you use `host=None` – which is the default – because in this case [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners") will bind to both the IPv4 wildcard address (`0.0.0.0`) and also the IPv6 wildcard address (`::`).

    - **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")*,* *bytes-like, or* *None*) –

      The local interface to bind to. This is passed to [`getaddrinfo()`](#trio.socket.getaddrinfo "trio.socket.getaddrinfo") with the `AI_PASSIVE` flag set.

      If you want to bind to the wildcard address on both IPv4 and IPv6, in order to accept connections on all available interfaces, then pass `None`. This is the default.

      If you have a specific interface you want to bind to, pass its IP address or hostname here. If a hostname resolves to multiple IP addresses, this function will open one listener on each of them.

      If you want to use only IPv4, or only IPv6, but want to accept on all interfaces, pass the family-specific wildcard address: `"0.0.0.0"` for IPv4-only and `"::"` for IPv6-only.

    - **backlog** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *None*) – The listen backlog to use. If you leave this as `None` then Trio will pick a good default. (Currently: whatever your system has configured as the maximum backlog.)

    #### Returns:

    list of [`SocketListener`](#trio.SocketListener "trio.SocketListener")
- name: trio.open_tcp_stream
  id: reference-io#trio.open_tcp_stream
  summary: Connect to the given host and port over TCP
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.open_tcp_stream(host, port, *, happy_eyeballs_delay=0.25, local_address=None)`

    Connect to the given host and port over TCP.

    If the given `host` has multiple IP addresses associated with it, then we have a problem: which one do we use?

    One approach would be to attempt to connect to the first one, and then if that fails, attempt to connect to the second one … until we’ve tried all of them. But the problem with this is that if the first IP address is unreachable (for example, because it’s an IPv6 address and our network discards IPv6 packets), then we might end up waiting tens of seconds for the first connection attempt to timeout before we try the second address.

    Another approach would be to attempt to connect to all of the addresses at the same time, in parallel, and then use whichever connection succeeds first, abandoning the others. This would be fast, but create a lot of unnecessary load on the network and the remote server.

    This function strikes a balance between these two extremes: it works its way through the available addresses one at a time, like the first approach; but, if `happy_eyeballs_delay` seconds have passed and it’s still waiting for an attempt to succeed or fail, then it gets impatient and starts the next connection attempt in parallel. As soon as any one connection attempt succeeds, all the other attempts are cancelled. This avoids unnecessary load because most connections will succeed after just one or two attempts, but if one of the addresses is unreachable then it doesn’t slow us down too much.

    This is known as a “happy eyeballs” algorithm, and our particular variant is modelled after how Chrome connects to webservers; see [RFC 6555](https://tools.ietf.org/html/rfc6555) for more details.

    #### Parameters:

    - **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)") *or* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")) – The host to connect to. Can be an IPv4 address, IPv6 address, or a hostname.

    - **port** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The port to connect to.

    - **happy_eyeballs_delay** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – How many seconds to wait for each connection attempt to succeed or fail before getting impatient and starting another one in parallel. Set to [`math.inf`](https://docs.python.org/3/library/math.html#math.inf "(in Python v3.11)") if you want to limit to only one connection attempt at a time (like [`socket.create_connection()`](https://docs.python.org/3/library/socket.html#socket.create_connection "(in Python v3.11)")). Default: 0.25 (250 ms).

    - **local_address** (*None* *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")) –

      The local IP address or hostname to use as the source for outgoing connections. If `None`, we let the OS pick the source IP.

      This is useful in some exotic networking configurations where your host has multiple IP addresses, and you want to force the use of a specific one.

      Note that if you pass an IPv4 `local_address`, then you won’t be able to connect to IPv6 hosts, and vice-versa. If you want to take advantage of this to force the use of IPv4 or IPv6 without specifying an exact source address, you can use the IPv4 wildcard address `local_address="0.0.0.0"`, or the IPv6 wildcard address `local_address="::"`.

    #### Returns:

    a [`Stream`](#trio.abc.Stream "trio.abc.Stream") connected to the given server.

    #### Return type:

    [SocketStream](#trio.SocketStream "trio.SocketStream")

    #### Raises:

    [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") – if the connection fails.

    > #### See also
    >
    > open_ssl_over_tcp_stream
- name: trio.open_unix_socket
  id: reference-io#trio.open_unix_socket
  summary: Opens a connection to the specified Unix domain socket
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.open_unix_socket(filename)`

    Opens a connection to the specified [Unix domain socket](https://en.wikipedia.org/wiki/Unix_domain_socket).

    You must have read/write permission on the specified file to connect.

    #### Parameters:

    **filename** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)") *or* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")) – The filename to open the connection to.

    #### Returns:

    a [`Stream`](#trio.abc.Stream "trio.abc.Stream") connected to the given file.

    #### Return type:

    [SocketStream](#trio.SocketStream "trio.SocketStream")

    #### Raises:

    - [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") – If the socket file could not be connected to.

    - [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError "(in Python v3.11)") – If AF_UNIX sockets are not supported.
- name: trio.Path
  id: reference-io#trio.Path
  summary: A pathlib.Path wrapper that executes blocking methods in trio.to_thread.run_sync()
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.Path(*args)`

    A [`pathlib.Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path "(in Python v3.11)") wrapper that executes blocking methods in [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync "trio.to_thread.run_sync").
- name: trio.Path.as_posix
  id: reference-io#trio.Path.as_posix
  summary: Return the string representation of the path with forward (/) slashes
  belongs_to: I/O in Trio
  description: |-
    ### `as_posix()`

    Return the string representation of the path with forward (/) slashes.
- name: trio.Path.as_uri
  id: reference-io#trio.Path.as_uri
  summary: Return the path as a ‘file’ URI
  belongs_to: I/O in Trio
  description: |-
    ### `as_uri()`

    Return the path as a ‘file’ URI.
- name: trio.Path.chmod
  id: reference-io#trio.Path.chmod
  summary: Like chmod(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` chmod(*args, **kwargs)`

    Like [`chmod()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.chmod "(in Python v3.11)"), but async.
- name: trio.Path.cwd
  id: reference-io#trio.Path.cwd
  summary: Like cwd(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`classmethod await`*` cwd(*args, **kwargs)`

    Like [`cwd()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.cwd "(in Python v3.11)"), but async.
- name: trio.Path.exists
  id: reference-io#trio.Path.exists
  summary: Like exists(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` exists(*args, **kwargs)`

    Like [`exists()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.exists "(in Python v3.11)"), but async.
- name: trio.Path.expanduser
  id: reference-io#trio.Path.expanduser
  summary: Like expanduser(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` expanduser(*args, **kwargs)`

    Like [`expanduser()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.expanduser "(in Python v3.11)"), but async.
- name: trio.Path.glob
  id: reference-io#trio.Path.glob
  summary: Like glob(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` glob(*args, **kwargs)`

    Like [`glob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob "(in Python v3.11)"), but async.
- name: trio.Path.group
  id: reference-io#trio.Path.group
  summary: Like group(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` group(*args, **kwargs)`

    Like [`group()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.group "(in Python v3.11)"), but async.
- name: trio.Path.hardlink_to
  id: reference-io#trio.Path.hardlink_to
  summary: Like hardlink_to(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` hardlink_to(*args, **kwargs)`

    Like [`hardlink_to()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.hardlink_to "(in Python v3.11)"), but async.
- name: trio.Path.home
  id: reference-io#trio.Path.home
  summary: Like home(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`classmethod await`*` home(*args, **kwargs)`

    Like [`home()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.home "(in Python v3.11)"), but async.
- name: trio.Path.is_absolute
  id: reference-io#trio.Path.is_absolute
  summary: True if the path is absolute (has both a root and, if applicable, a drive)
  belongs_to: I/O in Trio
  description: |-
    ### `is_absolute()`

    True if the path is absolute (has both a root and, if applicable, a drive).
- name: trio.Path.is_block_device
  id: reference-io#trio.Path.is_block_device
  summary: Like is_block_device(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_block_device(*args, **kwargs)`

    Like [`is_block_device()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_block_device "(in Python v3.11)"), but async.
- name: trio.Path.is_char_device
  id: reference-io#trio.Path.is_char_device
  summary: Like is_char_device(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_char_device(*args, **kwargs)`

    Like [`is_char_device()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_char_device "(in Python v3.11)"), but async.
- name: trio.Path.is_dir
  id: reference-io#trio.Path.is_dir
  summary: Like is_dir(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_dir(*args, **kwargs)`

    Like [`is_dir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_dir "(in Python v3.11)"), but async.
- name: trio.Path.is_fifo
  id: reference-io#trio.Path.is_fifo
  summary: Like is_fifo(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_fifo(*args, **kwargs)`

    Like [`is_fifo()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_fifo "(in Python v3.11)"), but async.
- name: trio.Path.is_file
  id: reference-io#trio.Path.is_file
  summary: Like is_file(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_file(*args, **kwargs)`

    Like [`is_file()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_file "(in Python v3.11)"), but async.
- name: trio.Path.is_mount
  id: reference-io#trio.Path.is_mount
  summary: Like is_mount(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_mount(*args, **kwargs)`

    Like [`is_mount()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_mount "(in Python v3.11)"), but async.
- name: trio.Path.is_relative_to
  id: reference-io#trio.Path.is_relative_to
  summary: Return True if the path is relative to another path or False
  belongs_to: I/O in Trio
  description: |-
    ### `is_relative_to(*other)`

    Return True if the path is relative to another path or False.
- name: trio.Path.is_reserved
  id: reference-io#trio.Path.is_reserved
  summary: Return True if the path contains one of the special names reserved by the system, if any
  belongs_to: I/O in Trio
  description: |-
    ### `is_reserved()`

    Return True if the path contains one of the special names reserved by the system, if any.
- name: trio.Path.is_socket
  id: reference-io#trio.Path.is_socket
  summary: Like is_socket(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_socket(*args, **kwargs)`

    Like [`is_socket()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_socket "(in Python v3.11)"), but async.
- name: trio.Path.is_symlink
  id: reference-io#trio.Path.is_symlink
  summary: Like is_symlink(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` is_symlink(*args, **kwargs)`

    Like [`is_symlink()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_symlink "(in Python v3.11)"), but async.
- name: trio.Path.iterdir
  id: reference-io#trio.Path.iterdir
  summary: Like pathlib.Path.iterdir(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` iterdir(*args, **kwargs)`

    Like [`pathlib.Path.iterdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.iterdir "(in Python v3.11)"), but async.

    This is an async method that returns a synchronous iterator, so you use it like:

    ``` python
    for subpath in await mypath.iterdir():
        ...
    ```

    Note that it actually loads the whole directory list into memory immediately, during the initial call. (See [issue \#501](https://github.com/python-trio/trio/issues/501) for discussion.)
- name: trio.Path.joinpath
  id: reference-io#trio.Path.joinpath
  summary: Combine this path with one or several arguments, and return a new path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored)
  belongs_to: I/O in Trio
  description: |-
    ### `joinpath(*args)`

    Combine this path with one or several arguments, and return a new path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored).
- name: trio.Path.lchmod
  id: reference-io#trio.Path.lchmod
  summary: Like lchmod(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` lchmod(*args, **kwargs)`

    Like [`lchmod()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.lchmod "(in Python v3.11)"), but async.
- name: trio.Path.link_to
  id: reference-io#trio.Path.link_to
  summary: Like link_to(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` link_to(*args, **kwargs)`

    Like [`link_to()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.link_to "(in Python v3.11)"), but async.
- name: trio.Path.lstat
  id: reference-io#trio.Path.lstat
  summary: Like lstat(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` lstat(*args, **kwargs)`

    Like [`lstat()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.lstat "(in Python v3.11)"), but async.
- name: trio.Path.match
  id: reference-io#trio.Path.match
  summary: Return True if this path matches the given pattern
  belongs_to: I/O in Trio
  description: |-
    ### `match(path_pattern)`

    Return True if this path matches the given pattern.
- name: trio.Path.mkdir
  id: reference-io#trio.Path.mkdir
  summary: Like mkdir(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` mkdir(*args, **kwargs)`

    Like [`mkdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir "(in Python v3.11)"), but async.
- name: trio.Path.open
  id: reference-io#trio.Path.open
  summary: Open the file pointed by this path and return a file object, as the built-in open() function does
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` open(mode='r', buffering=-1, encoding=None, errors=None, newline=None)`

    Open the file pointed by this path and return a file object, as the built-in open() function does.
- name: trio.Path.owner
  id: reference-io#trio.Path.owner
  summary: Like owner(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` owner(*args, **kwargs)`

    Like [`owner()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.owner "(in Python v3.11)"), but async.
- name: trio.Path.read_bytes
  id: reference-io#trio.Path.read_bytes
  summary: Like read_bytes(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` read_bytes(*args, **kwargs)`

    Like [`read_bytes()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.read_bytes "(in Python v3.11)"), but async.
- name: trio.Path.read_text
  id: reference-io#trio.Path.read_text
  summary: Like read_text(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` read_text(*args, **kwargs)`

    Like [`read_text()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.read_text "(in Python v3.11)"), but async.
- name: trio.Path.readlink
  id: reference-io#trio.Path.readlink
  summary: Like readlink(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` readlink(*args, **kwargs)`

    Like [`readlink()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.readlink "(in Python v3.11)"), but async.
- name: trio.Path.relative_to
  id: reference-io#trio.Path.relative_to
  summary: Return the relative path to another path identified by the passed arguments
  belongs_to: I/O in Trio
  description: |-
    ### `relative_to(*other)`

    Return the relative path to another path identified by the passed arguments. If the operation is not possible (because this is not a subpath of the other path), raise ValueError.
- name: trio.Path.rename
  id: reference-io#trio.Path.rename
  summary: Like rename(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` rename(*args, **kwargs)`

    Like [`rename()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rename "(in Python v3.11)"), but async.
- name: trio.Path.replace
  id: reference-io#trio.Path.replace
  summary: Like replace(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` replace(*args, **kwargs)`

    Like [`replace()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.replace "(in Python v3.11)"), but async.
- name: trio.Path.resolve
  id: reference-io#trio.Path.resolve
  summary: Like resolve(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` resolve(*args, **kwargs)`

    Like [`resolve()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.resolve "(in Python v3.11)"), but async.
- name: trio.Path.rglob
  id: reference-io#trio.Path.rglob
  summary: Like rglob(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` rglob(*args, **kwargs)`

    Like [`rglob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rglob "(in Python v3.11)"), but async.
- name: trio.Path.rmdir
  id: reference-io#trio.Path.rmdir
  summary: Like rmdir(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` rmdir(*args, **kwargs)`

    Like [`rmdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rmdir "(in Python v3.11)"), but async.
- name: trio.Path.samefile
  id: reference-io#trio.Path.samefile
  summary: Like samefile(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` samefile(*args, **kwargs)`

    Like [`samefile()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.samefile "(in Python v3.11)"), but async.
- name: trio.Path.stat
  id: reference-io#trio.Path.stat
  summary: Like stat(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` stat(*args, **kwargs)`

    Like [`stat()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat "(in Python v3.11)"), but async.
- name: trio.Path.symlink_to
  id: reference-io#trio.Path.symlink_to
  summary: Like symlink_to(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` symlink_to(*args, **kwargs)`

    Like [`symlink_to()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.symlink_to "(in Python v3.11)"), but async.
- name: trio.Path.touch
  id: reference-io#trio.Path.touch
  summary: Like touch(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` touch(*args, **kwargs)`

    Like [`touch()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.touch "(in Python v3.11)"), but async.
- name: trio.Path.unlink
  id: reference-io#trio.Path.unlink
  summary: Like unlink(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` unlink(*args, **kwargs)`

    Like [`unlink()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink "(in Python v3.11)"), but async.
- name: trio.Path.with_name
  id: reference-io#trio.Path.with_name
  summary: Return a new path with the file name changed
  belongs_to: I/O in Trio
  description: |-
    ### `with_name(name)`

    Return a new path with the file name changed.
- name: trio.Path.with_stem
  id: reference-io#trio.Path.with_stem
  summary: Return a new path with the stem changed
  belongs_to: I/O in Trio
  description: |-
    ### `with_stem(stem)`

    Return a new path with the stem changed.
- name: trio.Path.with_suffix
  id: reference-io#trio.Path.with_suffix
  summary: Return a new path with the file suffix changed
  belongs_to: I/O in Trio
  description: |-
    ### `with_suffix(suffix)`

    Return a new path with the file suffix changed. If the path has no suffix, add given suffix. If the given suffix is an empty string, remove the suffix from the path.
- name: trio.Path.write_bytes
  id: reference-io#trio.Path.write_bytes
  summary: Like write_bytes(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` write_bytes(*args, **kwargs)`

    Like [`write_bytes()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.write_bytes "(in Python v3.11)"), but async.
- name: trio.Path.write_text
  id: reference-io#trio.Path.write_text
  summary: Like write_text(), but async
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` write_text(*args, **kwargs)`

    Like [`write_text()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.write_text "(in Python v3.11)"), but async.

    ### Asynchronous file objects
- name: trio.Process
  id: reference-io#trio.Process
  summary: A child process
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.Process(*args: object, **kwargs: object)`

    A child process. Like [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen "(in Python v3.11)"), but async.

    This class has no public constructor. The most common way to get a [`Process`](#trio.Process "trio.Process") object is to combine [`Nursery.start`](reference-core#trio.Nursery.start "trio.Nursery.start") with [`run_process`](#trio.run_process "trio.run_process"):

    ``` python
    process_object = await nursery.start(run_process, ...)
    ```

    This way, [`run_process`](#trio.run_process "trio.run_process") supervises the process and makes sure that it is cleaned up properly, while optionally checking the return value, feeding it input, and so on.

    If you need more control – for example, because you want to spawn a child process that outlives your program – then another option is to use [`trio.lowlevel.open_process`](reference-lowlevel#trio.lowlevel.open_process "trio.lowlevel.open_process"):

    ``` python
    process_object = await trio.lowlevel.open_process(...)
    ```
- name: trio.Process.args
  id: reference-io#trio.Process.args
  summary: The command passed at construction time, specifying the process to execute and its arguments
  belongs_to: I/O in Trio
  description: |-
    ### `args`

    The `command` passed at construction time, specifying the process to execute and its arguments.

    #### Type:

    [str](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)") or [list](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.11)")
- name: trio.Process.kill
  id: reference-io#trio.Process.kill
  summary: Immediately terminate the process
  belongs_to: I/O in Trio
  description: |-
    ### `kill()`

    Immediately terminate the process.

    On UNIX, this is equivalent to `send_signal(signal.SIGKILL)`. On Windows, it calls `TerminateProcess`. In both cases, the process cannot prevent itself from being killed, but the termination will be delivered asynchronously; use [`wait()`](#trio.Process.wait "trio.Process.wait") if you want to ensure the process is actually dead before proceeding.
- name: trio.Process.pid
  id: reference-io#trio.Process.pid
  summary: The process ID of the child process managed by this object
  belongs_to: I/O in Trio
  description: |-
    ### `pid`

    The process ID of the child process managed by this object.

    #### Type:

    [int](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")
- name: trio.Process.poll
  id: reference-io#trio.Process.poll
  summary: Returns the exit status of the process (an integer), or None if it’s still running
  belongs_to: I/O in Trio
  description: |-
    ### `poll()`

    Returns the exit status of the process (an integer), or `None` if it’s still running.

    Note that on Trio (unlike the standard library [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen "(in Python v3.11)")), `process.poll()` and `process.returncode` always give the same result. See [`returncode`](#trio.Process.returncode "trio.Process.returncode") for more details. This method is only included to make it easier to port code from [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess "(in Python v3.11)").
- name: trio.Process.returncode
  id: reference-io#trio.Process.returncode
  summary: The exit status of the process (an integer), or None if it’s still running
  belongs_to: I/O in Trio
  description: |-
    ### `returncode`

    The exit status of the process (an integer), or `None` if it’s still running.

    By convention, a return code of zero indicates success. On UNIX, negative values indicate termination due to a signal, e.g., -11 if terminated by signal 11 (`SIGSEGV`). On Windows, a process that exits due to a call to [`Process.terminate()`](#trio.Process.terminate "trio.Process.terminate") will have an exit status of 1.

    Unlike the standard library [`subprocess.Popen.returncode`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.returncode "(in Python v3.11)"), you don’t have to call [`poll`](#trio.Process.poll "trio.Process.poll") or [`wait`](#trio.Process.wait "trio.Process.wait") to update this attribute; it’s automatically updated as needed, and will always give you the latest information.
- name: trio.Process.send_signal
  id: reference-io#trio.Process.send_signal
  summary: Send signal sig to the process
  belongs_to: I/O in Trio
  description: |-
    ### `send_signal(sig)`

    Send signal `sig` to the process.

    On UNIX, `sig` may be any signal defined in the [`signal`](https://docs.python.org/3/library/signal.html#module-signal "(in Python v3.11)") module, such as `signal.SIGINT` or `signal.SIGTERM`. On Windows, it may be anything accepted by the standard library [`subprocess.Popen.send_signal()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal "(in Python v3.11)").

    > #### Note
    >
    > [`communicate()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.communicate "(in Python v3.11)") is not provided as a method on [`Process`](#trio.Process "trio.Process") objects; call [`run_process()`](#trio.run_process "trio.run_process") normally for simple capturing, or write the loop yourself if you have unusual needs. [`communicate()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen.communicate "(in Python v3.11)") has quite unusual cancellation behavior in the standard library (on some platforms it spawns a background thread which continues to read from the child process even after the timeout has expired) and we wanted to provide an interface with fewer surprises.

    If [`trio.run_process`](#trio.run_process "trio.run_process") is too limiting, we also offer a low-level API, [`trio.lowlevel.open_process`](reference-lowlevel#trio.lowlevel.open_process "trio.lowlevel.open_process"). For example, if you want to spawn a child process that will outlive the parent process and be orphaned, then [`run_process`](#trio.run_process "trio.run_process") can’t do that, but [`open_process`](reference-lowlevel#trio.lowlevel.open_process "trio.lowlevel.open_process") can.

    ### Options for starting subprocesses

    All of Trio’s subprocess APIs accept the numerous keyword arguments used by the standard [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess "(in Python v3.11)") module to control the environment in which a process starts and the mechanisms used for communicating with it. These may be passed wherever you see `**options` in the documentation below. See the [full list](https://docs.python.org/3/library/subprocess.html#popen-constructor) or just the [frequently used ones](https://docs.python.org/3/library/subprocess.html#frequently-used-arguments) in the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess "(in Python v3.11)") documentation. (You may need to `import``subprocess` in order to access constants such as `PIPE` or `DEVNULL`.)

    Currently, Trio always uses unbuffered byte streams for communicating with a process, so it does not support the `encoding`, `errors`, `universal_newlines` (alias `text`), and `bufsize` options.

    ### Quoting: more than you wanted to know

    The command to run and its arguments usually must be passed to Trio’s subprocess APIs as a sequence of strings, where the first element in the sequence specifies the command to run and the remaining elements specify its arguments, one argument per element. This form is used because it avoids potential quoting pitfalls; for example, you can run `["cp",``"-f",``source_file,``dest_file]` without worrying about whether `source_file` or `dest_file` contains spaces.

    If you only run subprocesses without `shell=True` and on UNIX, that’s all you need to know about specifying the command. If you use `shell=True` or run on Windows, you probably should read the rest of this section to be aware of potential pitfalls.

    With `shell=True` on UNIX, you must specify the command as a single string, which will be passed to the shell as if you’d entered it at an interactive prompt. The advantage of this option is that it lets you use shell features like pipes and redirection without writing code to handle them. For example, you can write `Process("ls``|``grep``some_string",``shell=True)`. The disadvantage is that you must account for the shell’s quoting rules, generally by wrapping in [`shlex.quote()`](https://docs.python.org/3/library/shlex.html#shlex.quote "(in Python v3.11)") any argument that might contain spaces, quotes, or other shell metacharacters. If you don’t do that, your safe-looking `f"ls``|``grep``{some_string}"` might end in disaster when invoked with `some_string``=``"foo;``rm``-rf``/"`.

    On Windows, the fundamental API for process spawning (the `CreateProcess()` system call) takes a string, not a list, and it’s actually up to the child process to decide how it wants to split that string into individual arguments. Since the C language specifies that `main()` should take a list of arguments, *most* programs you encounter will follow the rules used by the Microsoft C/C++ runtime. [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen "(in Python v3.11)"), and thus also Trio, uses these rules when it converts an argument sequence to a string, and they are [documented](https://docs.python.org/3/library/subprocess.html#converting-argument-sequence) alongside the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess "(in Python v3.11)") module. There is no documented Python standard library function that can directly perform that conversion, so even on Windows, you almost always want to pass an argument sequence rather than a string. But if the program you’re spawning doesn’t split its command line back into individual arguments in the standard way, you might need to pass a string to work around this. (Or you might just be out of luck: as far as I can tell, there’s simply no way to pass an argument containing a double-quote to a Windows batch file.)

    On Windows with `shell=True`, things get even more chaotic. Now there are two separate sets of quoting rules applied, one by the Windows command shell `CMD.EXE` and one by the process being spawned, and they’re *different*. (And there’s no [`shlex.quote()`](https://docs.python.org/3/library/shlex.html#shlex.quote "(in Python v3.11)") to save you: it uses UNIX-style quoting rules, even on Windows.) Most special characters interpreted by the shell `&<>()^|` are not treated as special if the shell thinks they’re inside double quotes, but `%FOO%` environment variable substitutions still are, and the shell doesn’t provide any way to write a double quote inside a double-quoted string. Outside double quotes, any character (including a double quote) can be escaped using a leading `^`. But since a pipeline is processed by running each command in the pipeline in a subshell, multiple layers of escaping can be needed:

    ``` python
    echo ^^^&x | find "x" | find "x"          # prints: &x
    ```

    And if you combine pipelines with () grouping, you can need even more levels of escaping:

    ``` python
    (echo ^^^^^^^&x | find "x") | find "x"    # prints: &x
    ```

    Since process creation takes a single arguments string, `CMD.EXE`'s quoting does not influence word splitting, and double quotes are not removed during CMD.EXE’s expansion pass. Double quotes are troublesome because CMD.EXE handles them differently from the MSVC runtime rules; in:

    ``` python
    prog.exe "foo \"bar\" baz"
    ```

    the program will see one argument `foo``"bar"``baz` but CMD.EXE thinks `bar\` is not quoted while `foo``\` and `baz` are. All of this makes it a formidable task to reliably interpolate anything into a `shell=True` command line on Windows, and Trio falls back on the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess "(in Python v3.11)") behavior: If you pass a sequence with `shell=True`, it’s quoted in the same way as a sequence with `shell=False`, and had better not contain any shell metacharacters you weren’t planning on.

    Further reading:

    - [https://stackoverflow.com/questions/30620876/how-to-properly-escape-filenames-in-windows-cmd-exe](https://stackoverflow.com/questions/30620876/how-to-properly-escape-filenames-in-windows-cmd-exe)

    - [https://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts](https://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts)

    ## Signals
- name: trio.Process.stderr
  id: reference-io#trio.Process.stderr
  summary: 'A stream connected to the child’s standard error stream: when the child writes to standard error, the written bytes become available for you to read here'
  belongs_to: I/O in Trio
  description: |-
    ### `stderr`

    A stream connected to the child’s standard error stream: when the child writes to standard error, the written bytes become available for you to read here. Only available if the [`Process`](#trio.Process "trio.Process") was constructed using `stderr=PIPE`; otherwise this will be None.

    #### Type:

    [trio.abc.ReceiveStream](#trio.abc.ReceiveStream "trio.abc.ReceiveStream") or None
- name: trio.Process.stdin
  id: reference-io#trio.Process.stdin
  summary: 'A stream connected to the child’s standard input stream: when you write bytes here, they become available for the child to read'
  belongs_to: I/O in Trio
  description: |-
    ### `stdin`

    A stream connected to the child’s standard input stream: when you write bytes here, they become available for the child to read. Only available if the [`Process`](#trio.Process "trio.Process") was constructed using `stdin=PIPE`; otherwise this will be None.

    #### Type:

    [trio.abc.SendStream](#trio.abc.SendStream "trio.abc.SendStream") or None
- name: trio.Process.stdio
  id: reference-io#trio.Process.stdio
  summary: A stream that sends data to the child’s standard input and receives from the child’s standard output
  belongs_to: I/O in Trio
  description: |-
    ### `stdio`

    A stream that sends data to the child’s standard input and receives from the child’s standard output. Only available if both [`stdin`](#trio.Process.stdin "trio.Process.stdin") and [`stdout`](#trio.Process.stdout "trio.Process.stdout") are available; otherwise this will be None.

    #### Type:

    [trio.StapledStream](#trio.StapledStream "trio.StapledStream") or None
- name: trio.Process.stdout
  id: reference-io#trio.Process.stdout
  summary: 'A stream connected to the child’s standard output stream: when the child writes to standard output, the written bytes become available for you to read here'
  belongs_to: I/O in Trio
  description: |-
    ### `stdout`

    A stream connected to the child’s standard output stream: when the child writes to standard output, the written bytes become available for you to read here. Only available if the [`Process`](#trio.Process "trio.Process") was constructed using `stdout=PIPE`; otherwise this will be None.

    #### Type:

    [trio.abc.ReceiveStream](#trio.abc.ReceiveStream "trio.abc.ReceiveStream") or None
- name: trio.Process.terminate
  id: reference-io#trio.Process.terminate
  summary: Terminate the process, politely if possible
  belongs_to: I/O in Trio
  description: |-
    ### `terminate()`

    Terminate the process, politely if possible.

    On UNIX, this is equivalent to `send_signal(signal.SIGTERM)`; by convention this requests graceful termination, but a misbehaving or buggy process might ignore it. On Windows, [`terminate()`](#trio.Process.terminate "trio.Process.terminate") forcibly terminates the process in the same manner as [`kill()`](#trio.Process.kill "trio.Process.kill").
- name: trio.Process.wait
  id: reference-io#trio.Process.wait
  summary: Block until the process exits
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` wait()`

    Block until the process exits.

    #### Returns:

    The exit status of the process; see [`returncode`](#trio.Process.returncode "trio.Process.returncode").
- name: trio.run
  id: reference-core#trio.run
  summary: Run a Trio-flavored async function, and return the result
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.run(async_fn, *args, clock=None, instruments=(), restrict_keyboard_interrupt_to_checkpoints: bool = False, strict_exception_groups: bool = False)`

    Run a Trio-flavored async function, and return the result.

    Calling:

    ``` python
    run(async_fn, *args)
    ```

    is the equivalent of:

    ``` python
    await async_fn(*args)
    ```

    except that [`run()`](#trio.run "trio.run") can (and must) be called from a synchronous context.

    This is Trio’s main entry point. Almost every other function in Trio requires that you be inside a call to [`run()`](#trio.run "trio.run").

    #### Parameters:

    - **async_fn** – An async function.

    - **args** – Positional arguments to be passed to *async_fn*. If you need to pass keyword arguments, then use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial "(in Python v3.11)").

    - **clock** – `None` to use the default system-specific monotonic clock; otherwise, an object implementing the [`trio.abc.Clock`](#trio.abc.Clock "trio.abc.Clock") interface, like (for example) a [`trio.testing.MockClock`](reference-testing#trio.testing.MockClock "trio.testing.MockClock") instance.

    - **instruments** (list of [`trio.abc.Instrument`](reference-lowlevel#trio.abc.Instrument "trio.abc.Instrument") objects) – Any instrumentation you want to apply to this run. This can also be modified during the run; see [Instrument API](reference-lowlevel#instrumentation).

    - **restrict_keyboard_interrupt_to_checkpoints** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) –

      What happens if the user hits control-C while [`run()`](#trio.run "trio.run") is running? If this argument is False (the default), then you get the standard Python behavior: a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") exception will immediately interrupt whatever task is running (or if no task is running, then Trio will wake up a task to be interrupted). Alternatively, if you set this argument to True, then [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") delivery will be delayed: it will be *only* be raised at [checkpoints](#checkpoints), like a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception.

      The default behavior is nice because it means that even if you accidentally write an infinite loop that never executes any checkpoints, then you can still break out of it using control-C. The alternative behavior is nice if you’re paranoid about a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") at just the wrong place leaving your program in an inconsistent state, because it means that you only have to worry about [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt "(in Python v3.11)") at the exact same places where you already have to worry about [`Cancelled`](#trio.Cancelled "trio.Cancelled").

      This setting has no effect if your program has registered a custom SIGINT handler, or if [`run()`](#trio.run "trio.run") is called from anywhere but the main thread (this is a Python limitation), or if you use [`open_signal_receiver()`](reference-io#trio.open_signal_receiver "trio.open_signal_receiver") to catch SIGINT.

    - **strict_exception_groups** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – If true, nurseries will always wrap even a single raised exception in an exception group. This can be overridden on the level of individual nurseries. This will eventually become the default behavior.

    #### Returns:

    Whatever `async_fn` returns.

    #### Raises:

    - [**TrioInternalError**](#trio.TrioInternalError "trio.TrioInternalError") – if an unexpected error is encountered inside Trio’s internal machinery. This is a bug and you should [let us know](https://github.com/python-trio/trio/issues).

    - **Anything else** – if `async_fn` raises an exception, then [`run()`](#trio.run "trio.run") propagates it.

    ## General principles

    ### Checkpoints

    When writing code using Trio, it’s very important to understand the concept of a *checkpoint*. Many of Trio’s functions act as checkpoints.

    A checkpoint is two things:

    1.  It’s a point where Trio checks for cancellation. For example, if the code that called your function set a timeout, and that timeout has expired, then the next time your function executes a checkpoint Trio will raise a [`Cancelled`](#trio.Cancelled "trio.Cancelled") exception. See [Cancellation and timeouts](#cancellation) below for more details.

    2.  It’s a point where the Trio scheduler checks its scheduling policy to see if it’s a good time to switch to another task, and potentially does so. (Currently, this check is very simple: the scheduler always switches at every checkpoint. But [this might change in the future](https://github.com/python-trio/trio/issues/32).)

    When writing Trio code, you need to keep track of where your checkpoints are. Why? First, because checkpoints require extra scrutiny: whenever you execute a checkpoint, you need to be prepared to handle a [`Cancelled`](#trio.Cancelled "trio.Cancelled") error, or for another task to run and [rearrange some state out from under you](https://glyph.twistedmatrix.com/2014/02/unyielding.html). And second, because you also need to make sure that you have *enough* checkpoints: if your code doesn’t pass through a checkpoint on a regular basis, then it will be slow to notice and respond to cancellation and – much worse – since Trio is a cooperative multi-tasking system where the *only* place the scheduler can switch tasks is at checkpoints, it’ll also prevent the scheduler from fairly allocating time between different tasks and adversely effect the response latency of all the other code running in the same process. (Informally we say that a task that does this is “hogging the run loop”.)

    So when you’re doing code review on a project that uses Trio, one of the things you’ll want to think about is whether there are enough checkpoints, and whether each one is handled correctly. Of course this means you need a way to recognize checkpoints. How do you do that? The underlying principle is that any operation that blocks has to be a checkpoint. This makes sense: if an operation blocks, then it might block for a long time, and you’ll want to be able to cancel it if a timeout expires; and in any case, while this task is blocked we want another task to be scheduled to run so our code can make full use of the CPU.

    But if we want to write correct code in practice, then this principle is a little too sloppy and imprecise to be useful. How do we know which functions might block? What if a function blocks sometimes, but not others, depending on the arguments passed / network speed / phase of the moon? How do we figure out where the checkpoints are when we’re stressed and sleep deprived but still want to get this code review right, and would prefer to reserve our mental energy for thinking about the actual logic instead of worrying about checkpoints?

    Don’t worry – Trio’s got your back. Since checkpoints are important and ubiquitous, we make it as simple as possible to keep track of them. Here are the rules:

    - Regular (synchronous) functions never contain any checkpoints.

    - If you call an async function provided by Trio (`await``<something``in``trio>`), and it doesn’t raise an exception, then it *always* acts as a checkpoint. (If it does raise an exception, it might act as a checkpoint or might not.)

      - This includes async iterators: If you write `async``for``...``in``<a``trio``object>`, then there will be at least one checkpoint in each iteration of the loop, and it will still checkpoint if the iterable is empty.

      - Partial exception for async context managers: Both the entry and exit of an `async``with` block are defined as async functions; but for a particular type of async context manager, it’s often the case that only one of them is able to block, which means only that one will act as a checkpoint. This is documented on a case-by-case basis.

    - Third-party async functions / iterators / context managers can act as checkpoints; if you see `await``<something>` or one of its friends, then that *might* be a checkpoint. So to be safe, you should prepare for scheduling or cancellation happening there.

    The reason we distinguish between Trio functions and other functions is that we can’t make any guarantees about third party code. Checkpoint-ness is a transitive property: if function A acts as a checkpoint, and you write a function that calls function A, then your function also acts as a checkpoint. If you don’t, then it isn’t. So there’s nothing stopping someone from writing a function like:

    ``` python
    # technically legal, but bad style:
    async def why_is_this_async():
        return 7
    ```

    that never calls any of Trio’s async functions. This is an async function, but it’s not a checkpoint. But why make a function async if it never calls any async functions? It’s possible, but it’s a bad idea. If you have a function that’s not calling any async functions, then you should make it synchronous. The people who use your function will thank you, because it makes it obvious that your function is not a checkpoint, and their code reviews will go faster.

    (Remember how in the tutorial we emphasized the importance of the [“async sandwich”](https://trio.readthedocs.io/en/v0.22.2/tutorial.html#async-sandwich), and the way it means that `await` ends up being a marker that shows when you’re calling a function that calls a function that … eventually calls one of Trio’s built-in async functions? The transitivity of async-ness is a technical requirement that Python imposes, but since it exactly matches the transitivity of checkpoint-ness, we’re able to exploit it to help you keep track of checkpoints. Pretty sneaky, eh?)

    A slightly trickier case is a function like:

    ``` python
    async def sleep_or_not(should_sleep):
        if should_sleep:
            await trio.sleep(1)
        else:
            pass
    ```

    Here the function acts as a checkpoint if you call it with `should_sleep` set to a true value, but not otherwise. This is why we emphasize that Trio’s own async functions are *unconditional* checkpoints: they *always* check for cancellation and check for scheduling, regardless of what arguments they’re passed. If you find an async function in Trio that doesn’t follow this rule, then it’s a bug and you should [let us know](https://github.com/python-trio/trio/issues).

    Inside Trio, we’re very picky about this, because Trio is the foundation of the whole system so we think it’s worth the extra effort to make things extra predictable. It’s up to you how picky you want to be in your code. To give you a more realistic example of what this kind of issue looks like in real life, consider this function:

    ``` python
    async def recv_exactly(sock, nbytes):
        data = bytearray()
        while nbytes > 0:
            # recv() reads up to 'nbytes' bytes each time
            chunk = await sock.recv(nbytes)
            if not chunk:
                raise RuntimeError("socket unexpected closed")
            nbytes -= len(chunk)
            data += chunk
        return data
    ```

    If called with an `nbytes` that’s greater than zero, then it will call `sock.recv` at least once, and `recv` is an async Trio function, and thus an unconditional checkpoint. So in this case, `recv_exactly` acts as a checkpoint. But if we do `await``recv_exactly(sock,``0)`, then it will immediately return an empty buffer without executing a checkpoint. If this were a function in Trio itself, then this wouldn’t be acceptable, but you may decide you don’t want to worry about this kind of minor edge case in your own code.

    If you do want to be careful, or if you have some CPU-bound code that doesn’t have enough checkpoints in it, then it’s useful to know that `await``trio.sleep(0)` is an idiomatic way to execute a checkpoint without doing anything else, and that [`trio.testing.assert_checkpoints()`](reference-testing#trio.testing.assert_checkpoints "trio.testing.assert_checkpoints") can be used to test that an arbitrary block of code contains a checkpoint.

    ### Thread safety

    The vast majority of Trio’s API is *not* thread safe: it can only be used from inside a call to [`trio.run()`](#trio.run "trio.run"). This manual doesn’t bother documenting this on individual calls; unless specifically noted otherwise, you should assume that it isn’t safe to call any Trio functions from anywhere except the Trio thread. (But [see below](#threads) if you really do need to work with threads.)

    ## Time and clocks

    Every call to [`run()`](#trio.run "trio.run") has an associated clock.

    By default, Trio uses an unspecified monotonic clock, but this can be changed by passing a custom clock object to [`run()`](#trio.run "trio.run") (e.g. for testing).

    You should not assume that Trio’s internal clock matches any other clock you have access to, including the clocks of simultaneous calls to [`trio.run()`](#trio.run "trio.run") happening in other processes or threads!

    The default clock is currently implemented as [`time.perf_counter()`](https://docs.python.org/3/library/time.html#time.perf_counter "(in Python v3.11)") plus a large random offset. The idea here is to catch code that accidentally uses [`time.perf_counter()`](https://docs.python.org/3/library/time.html#time.perf_counter "(in Python v3.11)") early, which should help keep our options open for [changing the clock implementation later](https://github.com/python-trio/trio/issues/33), and (more importantly) make sure you can be confident that custom clocks like [`trio.testing.MockClock`](reference-testing#trio.testing.MockClock "trio.testing.MockClock") will work with third-party libraries you don’t control.
- name: trio.run_process
  id: reference-io#trio.run_process
  summary: Run command in a subprocess and wait for it to complete
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.run_process(command, *, stdin=b'', capture_stdout=False, capture_stderr=False, check=True, deliver_cancel=None, task_status=TASK_STATUS_IGNORED, **options)`

    Run `command` in a subprocess and wait for it to complete.

    This function can be called in two different ways.

    One option is a direct call, like:

    ``` python
    completed_process_info = await trio.run_process(...)
    ```

    In this case, it returns a [`subprocess.CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess "(in Python v3.11)") instance describing the results. Use this if you want to treat a process like a function call.

    The other option is to run it as a task using [`Nursery.start`](reference-core#trio.Nursery.start "trio.Nursery.start") – the enhanced version of [`start_soon`](reference-core#trio.Nursery.start_soon "trio.Nursery.start_soon") that lets a task pass back a value during startup:

    ``` python
    process = await nursery.start(trio.run_process, ...)
    ```

    In this case, [`start`](reference-core#trio.Nursery.start "trio.Nursery.start") returns a [`Process`](#trio.Process "trio.Process") object that you can use to interact with the process while it’s running. Use this if you want to treat a process like a background task.

    Either way, [`run_process`](#trio.run_process "trio.run_process") makes sure that the process has exited before returning, handles cancellation, optionally checks for errors, and provides some convenient shorthands for dealing with the child’s input/output.

    **Input:**[`run_process`](#trio.run_process "trio.run_process") supports all the same `stdin=` arguments as [`subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen "(in Python v3.11)"). In addition, if you simply want to pass in some fixed data, you can pass a plain [`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)") object, and [`run_process`](#trio.run_process "trio.run_process") will take care of setting up a pipe, feeding in the data you gave, and then sending end-of-file. The default is `b""`, which means that the child will receive an empty stdin. If you want the child to instead read from the parent’s stdin, use `stdin=None`.

    **Output:** By default, any output produced by the subprocess is passed through to the standard output and error streams of the parent Trio process.

    When calling [`run_process`](#trio.run_process "trio.run_process") directly, you can capture the subprocess’s output by passing `capture_stdout=True` to capture the subprocess’s standard output, and/or `capture_stderr=True` to capture its standard error. Captured data is collected up by Trio into an in-memory buffer, and then provided as the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stdout "(in Python v3.11)") and/or [`stderr`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stderr "(in Python v3.11)") attributes of the returned [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess "(in Python v3.11)") object. The value for any stream that was not captured will be `None`.

    If you want to capture both stdout and stderr while keeping them separate, pass `capture_stdout=True,``capture_stderr=True`.

    If you want to capture both stdout and stderr but mixed together in the order they were printed, use: `capture_stdout=True,``stderr=subprocess.STDOUT`. This directs the child’s stderr into its stdout, so the combined output will be available in the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stdout "(in Python v3.11)") attribute.

    If you’re using `await``nursery.start(trio.run_process,``...)` and want to capture the subprocess’s output for further processing, then use `stdout=subprocess.PIPE` and then make sure to read the data out of the [`Process.stdout`](#trio.Process.stdout "trio.Process.stdout") stream. If you want to capture stderr separately, use `stderr=subprocess.PIPE`. If you want to capture both, but mixed together in the correct order, use `stdout=subprocess.PIPE,``stderr=subprocess.STDOUT`.

    **Error checking:** If the subprocess exits with a nonzero status code, indicating failure, [`run_process()`](#trio.run_process "trio.run_process") raises a [`subprocess.CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError "(in Python v3.11)") exception rather than returning normally. The captured outputs are still available as the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError.stdout "(in Python v3.11)") and [`stderr`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError.stderr "(in Python v3.11)") attributes of that exception. To disable this behavior, so that [`run_process()`](#trio.run_process "trio.run_process") returns normally even if the subprocess exits abnormally, pass `check=False`.

    Note that this can make the `capture_stdout` and `capture_stderr` arguments useful even when starting [`run_process`](#trio.run_process "trio.run_process") as a task: if you only care about the output if the process fails, then you can enable capturing and then read the output off of the [`CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError "(in Python v3.11)").

    **Cancellation:** If cancelled, [`run_process`](#trio.run_process "trio.run_process") sends a termination request to the subprocess, then waits for it to fully exit. The `deliver_cancel` argument lets you control how the process is terminated.

    > #### Note
    >
    > [`run_process`](#trio.run_process "trio.run_process") is intentionally similar to the standard library [`subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run "(in Python v3.11)"), but some of the defaults are different. Specifically, we default to:
    >
    > - `check=True`, because [“errors should never pass silently / unless explicitly silenced”](https://www.python.org/dev/peps/pep-0020/).
    >
    > - `stdin=b""`, because it produces less-confusing results if a subprocess unexpectedly tries to read from stdin.
    >
    > To get the [`subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run "(in Python v3.11)") semantics, use `check=False,``stdin=None`.

    #### Parameters:

    - **command** ([*list*](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.11)") *or* [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")) – The command to run. Typically this is a sequence of strings such as `['ls',``'-l',``'directory``with``spaces']`, where the first element names the executable to invoke and the other elements specify its arguments. With `shell=True` in the `**options`, or on Windows, `command` may alternatively be a string, which will be parsed following platform-dependent [quoting rules](#subprocess-quoting).

    - **stdin** ([`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)"), subprocess.PIPE, file descriptor, or None) –

      The bytes to provide to the subprocess on its standard input stream, or `None` if the subprocess’s standard input should come from the same place as the parent Trio process’s standard input. As is the case with the [`subprocess`](https://docs.python.org/3/library/subprocess.html#module-subprocess "(in Python v3.11)") module, you can also pass a file descriptor or an object with a `fileno()` method, in which case the subprocess’s standard input will come from that file.

      When starting [`run_process`](#trio.run_process "trio.run_process") as a background task, you can also use `stdin=subprocess.PIPE`, in which case [`Process.stdin`](#trio.Process.stdin "trio.Process.stdin") will be a [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream") that you can use to send data to the child.

    - **capture_stdout** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – If true, capture the bytes that the subprocess writes to its standard output stream and return them in the [`stdout`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stdout "(in Python v3.11)") attribute of the returned [`subprocess.CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess "(in Python v3.11)") or [`subprocess.CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError "(in Python v3.11)").

    - **capture_stderr** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – If true, capture the bytes that the subprocess writes to its standard error stream and return them in the [`stderr`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess.stderr "(in Python v3.11)") attribute of the returned [`CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess "(in Python v3.11)") or [`subprocess.CalledProcessError`](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError "(in Python v3.11)").

    - **check** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – If false, don’t validate that the subprocess exits successfully. You should be sure to check the `returncode` attribute of the returned object if you pass `check=False`, so that errors don’t pass silently.

    - **deliver_cancel** (*async function* *or* *None*) –

      If [`run_process`](#trio.run_process "trio.run_process") is cancelled, then it needs to kill the child process. There are multiple ways to do this, so we let you customize it.

      If you pass None (the default), then the behavior depends on the platform:

      - On Windows, Trio calls `TerminateProcess`, which should kill the process immediately.

      - On Unix-likes, the default behavior is to send a `SIGTERM`, wait 5 seconds, and send a `SIGKILL`.

      Alternatively, you can customize this behavior by passing in an arbitrary async function, which will be called with the [`Process`](#trio.Process "trio.Process") object as an argument. For example, the default Unix behavior could be implemented like this:

      ``` python
      async def my_deliver_cancel(process):
          process.send_signal(signal.SIGTERM)
          await trio.sleep(5)
          process.send_signal(signal.SIGKILL)
      ```

      When the process actually exits, the `deliver_cancel` function will automatically be cancelled – so if the process exits after `SIGTERM`, then we’ll never reach the `SIGKILL`.

      In any case, [`run_process`](#trio.run_process "trio.run_process") will always wait for the child process to exit before raising [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled").

    - **\*\*options** – [`run_process()`](#trio.run_process "trio.run_process") also accepts any [general subprocess options](#subprocess-options) and passes them on to the [`Process`](#trio.Process "trio.Process") constructor. This includes the `stdout` and `stderr` options, which provide additional redirection possibilities such as `stderr=subprocess.STDOUT`, `stdout=subprocess.DEVNULL`, or file descriptors.

    #### Returns:

    When called normally – a [`subprocess.CompletedProcess`](https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess "(in Python v3.11)") instance describing the return code and outputs.

    When called via [`Nursery.start`](reference-core#trio.Nursery.start "trio.Nursery.start") – a [`trio.Process`](#trio.Process "trio.Process") instance.

    #### Raises:

    - [**UnicodeError**](https://docs.python.org/3/library/exceptions.html#UnicodeError "(in Python v3.11)") – if `stdin` is specified as a Unicode string, rather than bytes

    - [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if multiple redirections are specified for the same stream, e.g., both `capture_stdout=True` and `stdout=subprocess.DEVNULL`

    - [**subprocess.CalledProcessError**](https://docs.python.org/3/library/subprocess.html#subprocess.CalledProcessError "(in Python v3.11)") – if `check=False` is not passed and the process exits with a nonzero exit status

    - [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") – if an error is encountered starting or communicating with the process

    > #### Note
    >
    > The child process runs in the same process group as the parent Trio process, so a Ctrl+C will be delivered simultaneously to both parent and child. If you don’t want this behavior, consult your platform’s documentation for starting child processes in a different process group.
- name: trio.RunFinishedError
  id: reference-core#trio.RunFinishedError
  summary: Raised by trio.from_thread.run and similar functions if the corresponding call to trio.run() has already finished
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.RunFinishedError`

    Raised by [`trio.from_thread.run`](#trio.from_thread.run "trio.from_thread.run") and similar functions if the corresponding call to [`trio.run()`](#trio.run "trio.run") has already finished.
- name: trio.Semaphore
  id: reference-core#trio.Semaphore
  summary: A semaphore
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.Semaphore(initial_value, *, max_value=None)`

    A [semaphore](https://en.wikipedia.org/wiki/Semaphore_(programming)).

    A semaphore holds an integer value, which can be incremented by calling [`release()`](#trio.Semaphore.release "trio.Semaphore.release") and decremented by calling [`acquire()`](#trio.Semaphore.acquire "trio.Semaphore.acquire") – but the value is never allowed to drop below zero. If the value is zero, then [`acquire()`](#trio.Semaphore.acquire "trio.Semaphore.acquire") will block until someone calls [`release()`](#trio.Semaphore.release "trio.Semaphore.release").

    If you’re looking for a [`Semaphore`](#trio.Semaphore "trio.Semaphore") to limit the number of tasks that can access some resource simultaneously, then consider using a [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") instead.

    This object’s interface is similar to, but different from, that of [`threading.Semaphore`](https://docs.python.org/3/library/threading.html#threading.Semaphore "(in Python v3.11)").

    A [`Semaphore`](#trio.Semaphore "trio.Semaphore") object can be used as an async context manager; it blocks on entry but not on exit.

    #### Parameters:

    - **initial_value** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – A non-negative integer giving semaphore’s initial value.

    - **max_value** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *None*) – If given, makes this a “bounded” semaphore that raises an error if the value is about to exceed the given `max_value`.
- name: trio.Semaphore.acquire
  id: reference-core#trio.Semaphore.acquire
  summary: Decrement the semaphore value, blocking if necessary to avoid letting it drop below zero
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` acquire()`

    Decrement the semaphore value, blocking if necessary to avoid letting it drop below zero.
- name: trio.Semaphore.acquire_nowait
  id: reference-core#trio.Semaphore.acquire_nowait
  summary: Attempt to decrement the semaphore value, without blocking
  belongs_to: Trio’s core functionality
  description: |-
    ### `acquire_nowait()`

    Attempt to decrement the semaphore value, without blocking.

    #### Raises:

    [**WouldBlock**](#trio.WouldBlock "trio.WouldBlock") – if the value is zero.
- name: trio.Semaphore.release
  id: reference-core#trio.Semaphore.release
  summary: Increment the semaphore value, possibly waking a task blocked in acquire()
  belongs_to: Trio’s core functionality
  description: |-
    ### `release()`

    Increment the semaphore value, possibly waking a task blocked in [`acquire()`](#trio.Semaphore.acquire "trio.Semaphore.acquire").

    #### Raises:

    [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if incrementing the value would cause it to exceed [`max_value`](#trio.Semaphore.max_value "trio.Semaphore.max_value").
- name: trio.Semaphore.statistics
  id: reference-core#trio.Semaphore.statistics
  summary: Return an object containing debugging information
  belongs_to: Trio’s core functionality
  description: |-
    ### `statistics()`

    Return an object containing debugging information.

    Currently the following fields are defined:

    - `tasks_waiting`: The number of tasks blocked on this semaphore’s [`acquire()`](#trio.Semaphore.acquire "trio.Semaphore.acquire") method.
- name: trio.serve_listeners
  id: reference-io#trio.serve_listeners
  summary: Listen for incoming connections on listeners, and for each one start a task running handler(stream)
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.serve_listeners(handler, listeners, *, handler_nursery=None, task_status=TASK_STATUS_IGNORED)`

    Listen for incoming connections on `listeners`, and for each one start a task running `handler(stream)`.

    > #### Warning
    >
    > If `handler` raises an exception, then this function doesn’t do anything special to catch it – so by default the exception will propagate out and crash your server. If you don’t want this, then catch exceptions inside your `handler`, or use a `handler_nursery` object that responds to exceptions in some other way.

    #### Parameters:

    - **handler** – An async callable, that will be invoked like `handler_nursery.start_soon(handler,``stream)` for each incoming connection.

    - **listeners** – A list of [`Listener`](#trio.abc.Listener "trio.abc.Listener") objects. [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners") takes responsibility for closing them.

    - **handler_nursery** – The nursery used to start handlers, or any object with a `start_soon` method. If `None` (the default), then [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners") will create a new nursery internally and use that.

    - **task_status** – This function can be used with `nursery.start`, which will return `listeners`.

    #### Returns:

    This function never returns unless cancelled.

    Resource handling:

    > If `handler` neglects to close the `stream`, then it will be closed using [`trio.aclose_forcefully()`](#trio.aclose_forcefully "trio.aclose_forcefully").

    Error handling:

    > Most errors coming from [`accept()`](#trio.abc.Listener.accept "trio.abc.Listener.accept") are allowed to propagate out (crashing the server in the process). However, some errors – those which indicate that the server is temporarily overloaded – are handled specially. These are [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)")s with one of the following errnos:
    >
    > - `EMFILE`: process is out of file descriptors
    >
    > - `ENFILE`: system is out of file descriptors
    >
    > - `ENOBUFS`, `ENOMEM`: the kernel hit some sort of memory limitation when trying to create a socket object
    >
    > When [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners") gets one of these errors, then it:
    >
    > - Logs the error to the standard library logger `trio.serve_listeners` (level = ERROR, with exception information included). By default this causes it to be printed to stderr.
    >
    > - Waits 100 ms before calling `accept` again, in hopes that the system will recover.
- name: trio.serve_ssl_over_tcp
  id: reference-io#trio.serve_ssl_over_tcp
  summary: Listen for incoming TCP connections, and for each one start a task running handler(stream)
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.serve_ssl_over_tcp(handler, port, ssl_context, *, host=None, https_compatible=False, backlog=None, handler_nursery=None, task_status=TASK_STATUS_IGNORED)`

    Listen for incoming TCP connections, and for each one start a task running `handler(stream)`.

    This is a thin convenience wrapper around [`open_ssl_over_tcp_listeners()`](#trio.open_ssl_over_tcp_listeners "trio.open_ssl_over_tcp_listeners") and [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners") – see them for full details.

    > #### Warning
    >
    > If `handler` raises an exception, then this function doesn’t do anything special to catch it – so by default the exception will propagate out and crash your server. If you don’t want this, then catch exceptions inside your `handler`, or use a `handler_nursery` object that responds to exceptions in some other way.

    When used with `nursery.start` you get back the newly opened listeners. See the documentation for [`serve_tcp()`](#trio.serve_tcp "trio.serve_tcp") for an example where this is useful.

    #### Parameters:

    - **handler** – The handler to start for each incoming connection. Passed to [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners").

    - **port** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)")) – The port to listen on. Use 0 to let the kernel pick an open port. Ultimately passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)")) – The SSL context to use for all incoming connections. Passed to [`open_ssl_over_tcp_listeners()`](#trio.open_ssl_over_tcp_listeners "trio.open_ssl_over_tcp_listeners").

    - **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")*,* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")*, or* *None*) – The address to bind to; use `None` to bind to the wildcard address. Ultimately passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – Set this to True if you want to use “HTTPS-style” TLS. See [`SSLStream`](#trio.SSLStream "trio.SSLStream") for details.

    - **backlog** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *None*) – See [`SSLStream`](#trio.SSLStream "trio.SSLStream") for details.

    - **handler_nursery** – The nursery to start handlers in, or None to use an internal nursery. Passed to [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners").

    - **task_status** – This function can be used with `nursery.start`.

    #### Returns:

    This function only returns when cancelled.
- name: trio.serve_tcp
  id: reference-io#trio.serve_tcp
  summary: Listen for incoming TCP connections, and for each one start a task running handler(stream)
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.serve_tcp(handler, port, *, host=None, backlog=None, handler_nursery=None, task_status=TASK_STATUS_IGNORED)`

    Listen for incoming TCP connections, and for each one start a task running `handler(stream)`.

    This is a thin convenience wrapper around [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners") and [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners") – see them for full details.

    > #### Warning
    >
    > If `handler` raises an exception, then this function doesn’t do anything special to catch it – so by default the exception will propagate out and crash your server. If you don’t want this, then catch exceptions inside your `handler`, or use a `handler_nursery` object that responds to exceptions in some other way.

    When used with `nursery.start` you get back the newly opened listeners. So, for example, if you want to start a server in your test suite and then connect to it to check that it’s working properly, you can use something like:

    ``` python
    from trio.testing import open_stream_to_socket_listener

    async with trio.open_nursery() as nursery:
        listeners = await nursery.start(serve_tcp, handler, 0)
        client_stream = await open_stream_to_socket_listener(listeners[0])

        # Then send and receive data on 'client_stream', for example:
        await client_stream.send_all(b"GET / HTTP/1.0\r\n\r\n")
    ```

    This avoids several common pitfalls:

    1.  It lets the kernel pick a random open port, so your test suite doesn’t depend on any particular port being open.

    2.  It waits for the server to be accepting connections on that port before `start` returns, so there’s no race condition where the incoming connection arrives before the server is ready.

    3.  It uses the Listener object to find out which port was picked, so it can connect to the right place.

    #### Parameters:

    - **handler** – The handler to start for each incoming connection. Passed to [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners").

    - **port** – The port to listen on. Use 0 to let the kernel pick an open port. Passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **host** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")*,* [*bytes*](https://docs.python.org/3/library/stdtypes.html#bytes "(in Python v3.11)")*, or* *None*) – The host interface to listen on; use `None` to bind to the wildcard address. Passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **backlog** – The listen backlog, or None to have a good default picked. Passed to [`open_tcp_listeners()`](#trio.open_tcp_listeners "trio.open_tcp_listeners").

    - **handler_nursery** – The nursery to start handlers in, or None to use an internal nursery. Passed to [`serve_listeners()`](#trio.serve_listeners "trio.serve_listeners").

    - **task_status** – This function can be used with `nursery.start`.

    #### Returns:

    This function only returns when cancelled.
- name: trio.sleep
  id: reference-core#trio.sleep
  summary: Pause execution of the current task for the given number of seconds
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` trio.sleep(seconds: float) → None`

    Pause execution of the current task for the given number of seconds.

    #### Parameters:

    **seconds** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The number of seconds to sleep. May be zero to insert a checkpoint without actually blocking.

    #### Raises:

    [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if *seconds* is negative or NaN.
- name: trio.sleep_forever
  id: reference-core#trio.sleep_forever
  summary: Pause execution of the current task forever (or until cancelled)
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` trio.sleep_forever() → None`

    Pause execution of the current task forever (or until cancelled).

    Equivalent to calling `await``sleep(math.inf)`.

    If you’re a mad scientist or otherwise feel the need to take direct control over the PASSAGE OF TIME ITSELF, then you can implement a custom [`Clock`](#trio.abc.Clock "trio.abc.Clock") class:
- name: trio.sleep_until
  id: reference-core#trio.sleep_until
  summary: Pause execution of the current task until the given time
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` trio.sleep_until(deadline: float) → None`

    Pause execution of the current task until the given time.

    The difference between [`sleep()`](#trio.sleep "trio.sleep") and [`sleep_until()`](#trio.sleep_until "trio.sleep_until") is that the former takes a relative time and the latter takes an absolute time according to Trio’s internal clock (as returned by [`current_time()`](#trio.current_time "trio.current_time")).

    #### Parameters:

    **deadline** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – The time at which we should wake up again. May be in the past, in which case this function executes a checkpoint but does not block.

    #### Raises:

    [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if deadline is NaN.
- name: trio.socket.from_stdlib_socket
  id: reference-io#trio.socket.from_stdlib_socket
  summary: Convert a standard library socket.socket object into a Trio socket object
  belongs_to: I/O in Trio
  description: |-
    ### `trio.socket.from_stdlib_socket(sock)`

    Convert a standard library [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket "(in Python v3.11)") object into a Trio socket object.

    Unlike [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket "(in Python v3.11)"), [`trio.socket.socket()`](#trio.socket.socket "trio.socket.socket") is a function, not a class; if you want to check whether an object is a Trio socket, use `isinstance(obj,``trio.socket.SocketType)`.

    For name lookup, Trio provides the standard functions, but with some changes:
- name: trio.socket.fromfd
  id: reference-io#trio.socket.fromfd
  summary: Like socket.fromfd(), but returns a Trio socket object
  belongs_to: I/O in Trio
  description: |-
    ### `trio.socket.fromfd(fd, family, type, proto=0)`

    Like [`socket.fromfd()`](https://docs.python.org/3/library/socket.html#socket.fromfd "(in Python v3.11)"), but returns a Trio socket object.
- name: trio.socket.fromshare
  id: reference-io#trio.socket.fromshare
  summary: Like socket.fromshare(), but returns a Trio socket object
  belongs_to: I/O in Trio
  description: |-
    ### `trio.socket.fromshare(data)`

    Like [`socket.fromshare()`](https://docs.python.org/3/library/socket.html#socket.fromshare "(in Python v3.11)"), but returns a Trio socket object.

    In addition, there is a new function to directly convert a standard library socket into a Trio socket:
- name: trio.socket.getaddrinfo
  id: reference-io#trio.socket.getaddrinfo
  summary: Look up a numeric address given a name
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.socket.getaddrinfo(host, port, family=0, type=0, proto=0, flags=0)`

    Look up a numeric address given a name.

    Arguments and return values are identical to [`socket.getaddrinfo()`](https://docs.python.org/3/library/socket.html#socket.getaddrinfo "(in Python v3.11)"), except that this version is async.

    Also, [`trio.socket.getaddrinfo()`](#trio.socket.getaddrinfo "trio.socket.getaddrinfo") correctly uses IDNA 2008 to process non-ASCII domain names. ([`socket.getaddrinfo()`](https://docs.python.org/3/library/socket.html#socket.getaddrinfo "(in Python v3.11)") uses IDNA 2003, which can give the wrong result in some cases and cause you to connect to a different host than the one you intended; see [bpo-17305](https://bugs.python.org/issue17305).)

    This function’s behavior can be customized using [`set_custom_hostname_resolver()`](reference-testing#trio.socket.set_custom_hostname_resolver "trio.socket.set_custom_hostname_resolver").
- name: trio.socket.getnameinfo
  id: reference-io#trio.socket.getnameinfo
  summary: Look up a name given a numeric address
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.socket.getnameinfo(sockaddr, flags)`

    Look up a name given a numeric address.

    Arguments and return values are identical to [`socket.getnameinfo()`](https://docs.python.org/3/library/socket.html#socket.getnameinfo "(in Python v3.11)"), except that this version is async.

    This function’s behavior can be customized using [`set_custom_hostname_resolver()`](reference-testing#trio.socket.set_custom_hostname_resolver "trio.socket.set_custom_hostname_resolver").
- name: trio.socket.getprotobyname
  id: reference-io#trio.socket.getprotobyname
  summary: Look up a protocol number by name
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` trio.socket.getprotobyname(name)`

    Look up a protocol number by name. (Rarely used.)

    Like [`socket.getprotobyname()`](https://docs.python.org/3/library/socket.html#socket.getprotobyname "(in Python v3.11)"), but async.

    Trio intentionally DOES NOT include some obsolete, redundant, or broken features:

    - [`gethostbyname()`](https://docs.python.org/3/library/socket.html#socket.gethostbyname "(in Python v3.11)"), [`gethostbyname_ex()`](https://docs.python.org/3/library/socket.html#socket.gethostbyname_ex "(in Python v3.11)"), [`gethostbyaddr()`](https://docs.python.org/3/library/socket.html#socket.gethostbyaddr "(in Python v3.11)"): obsolete; use [`getaddrinfo()`](https://docs.python.org/3/library/socket.html#socket.getaddrinfo "(in Python v3.11)") and [`getnameinfo()`](https://docs.python.org/3/library/socket.html#socket.getnameinfo "(in Python v3.11)") instead.

    - [`getservbyport()`](https://docs.python.org/3/library/socket.html#socket.getservbyport "(in Python v3.11)"): obsolete and [buggy](https://bugs.python.org/issue30482); instead, do:

      ``` python
      _, service_name = await getnameinfo((127.0.0.1, port), NI_NUMERICHOST))
      ```

    - [`getservbyname()`](https://docs.python.org/3/library/socket.html#socket.getservbyname "(in Python v3.11)"): obsolete and [buggy](https://bugs.python.org/issue30482); instead, do:

      ``` python
      await getaddrinfo(None, service_name)
      ```

    - [`getfqdn()`](https://docs.python.org/3/library/socket.html#socket.getfqdn "(in Python v3.11)"): obsolete; use [`getaddrinfo()`](#trio.socket.getaddrinfo "trio.socket.getaddrinfo") with the `AI_CANONNAME` flag.

    - [`getdefaulttimeout()`](https://docs.python.org/3/library/socket.html#socket.getdefaulttimeout "(in Python v3.11)"), [`setdefaulttimeout()`](https://docs.python.org/3/library/socket.html#socket.setdefaulttimeout "(in Python v3.11)"): instead, use Trio’s standard support for [Cancellation and timeouts](reference-core#cancellation).

    - On Windows, `SO_REUSEADDR` is not exported, because it’s a trap: the name is the same as Unix `SO_REUSEADDR`, but the semantics are [different and extremely broken](https://msdn.microsoft.com/en-us/library/windows/desktop/ms740621(v=vs.85).aspx). In the very rare cases where you actually want `SO_REUSEADDR` on Windows, then it can still be accessed from the standard library’s [`socket`](https://docs.python.org/3/library/socket.html#module-socket "(in Python v3.11)") module.

    ### Socket objects
- name: trio.socket.set_custom_hostname_resolver
  id: reference-testing#trio.socket.set_custom_hostname_resolver
  summary: Set a custom hostname resolver
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.socket.set_custom_hostname_resolver(hostname_resolver)`

    Set a custom hostname resolver.

    By default, Trio’s [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo "trio.socket.getaddrinfo") and [`getnameinfo()`](reference-io#trio.socket.getnameinfo "trio.socket.getnameinfo") functions use the standard system resolver functions. This function allows you to customize that behavior. The main intended use case is for testing, but it might also be useful for using third-party resolvers like [c-ares](https://c-ares.haxx.se/) (though be warned that these rarely make perfect drop-in replacements for the system resolver). See [`trio.abc.HostnameResolver`](#trio.abc.HostnameResolver "trio.abc.HostnameResolver") for more details.

    Setting a custom hostname resolver affects all future calls to [`getaddrinfo()`](reference-io#trio.socket.getaddrinfo "trio.socket.getaddrinfo") and [`getnameinfo()`](reference-io#trio.socket.getnameinfo "trio.socket.getnameinfo") within the enclosing call to [`trio.run()`](reference-core#trio.run "trio.run"). All other hostname resolution in Trio is implemented in terms of these functions.

    Generally you should call this function just once, right at the beginning of your program.

    #### Parameters:

    **hostname_resolver** ([*trio.abc.HostnameResolver*](#trio.abc.HostnameResolver "trio.abc.HostnameResolver") *or* *None*) – The new custom hostname resolver, or None to restore the default behavior.

    #### Returns:

    The previous hostname resolver (which may be None).
- name: trio.socket.set_custom_socket_factory
  id: reference-testing#trio.socket.set_custom_socket_factory
  summary: Set a custom socket object factory
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.socket.set_custom_socket_factory(socket_factory)`

    Set a custom socket object factory.

    This function allows you to replace Trio’s normal socket class with a custom class. This is very useful for testing, and probably a bad idea in any other circumstance. See [`trio.abc.HostnameResolver`](#trio.abc.HostnameResolver "trio.abc.HostnameResolver") for more details.

    Setting a custom socket factory affects all future calls to [`socket()`](reference-io#trio.socket.socket "trio.socket.socket") within the enclosing call to [`trio.run()`](reference-core#trio.run "trio.run").

    Generally you should call this function just once, right at the beginning of your program.

    #### Parameters:

    **socket_factory** ([*trio.abc.SocketFactory*](#trio.abc.SocketFactory "trio.abc.SocketFactory") *or* *None*) – The new custom socket factory, or None to restore the default behavior.

    #### Returns:

    The previous socket factory (which may be None).
- name: trio.socket.socket
  id: reference-io#trio.socket.socket
  summary: Create a new Trio socket, like socket.socket
  belongs_to: I/O in Trio
  description: |-
    ### `trio.socket.socket(family=-1, type=-1, proto=-1, fileno=None)`

    Create a new Trio socket, like [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket "(in Python v3.11)").

    This function’s behavior can be customized using [`set_custom_socket_factory()`](reference-testing#trio.socket.set_custom_socket_factory "trio.socket.set_custom_socket_factory").
- name: trio.socket.socketpair
  id: reference-io#trio.socket.socketpair
  summary: Like socket.socketpair(), but returns a pair of Trio socket objects
  belongs_to: I/O in Trio
  description: |-
    ### `trio.socket.socketpair(family=None, type=SocketKind.SOCK_STREAM, proto=0)`

    Like [`socket.socketpair()`](https://docs.python.org/3/library/socket.html#socket.socketpair "(in Python v3.11)"), but returns a pair of Trio socket objects.
- name: trio.socket.SocketType
  id: reference-io#trio.socket.SocketType
  summary: trio.socket.SocketType is an abstract class and cannot be instantiated directly; you get concrete socket objects by calling constructors like trio.socket.socket()
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.socket.SocketType`

    > #### Note
    >
    > [`trio.socket.SocketType`](#trio.socket.SocketType "trio.socket.SocketType") is an abstract class and cannot be instantiated directly; you get concrete socket objects by calling constructors like [`trio.socket.socket()`](#trio.socket.socket "trio.socket.socket"). However, you can use it to check if an object is a Trio socket via `isinstance(obj,``trio.socket.SocketType)`.

    Trio socket objects are overall very similar to the [standard library socket objects](https://docs.python.org/3/library/socket.html#socket-objects "(in Python v3.11)"), with a few important differences:

    First, and most obviously, everything is made “Trio-style”: blocking methods become async methods, and the following attributes are *not* supported:

    - [`setblocking()`](https://docs.python.org/3/library/socket.html#socket.socket.setblocking "(in Python v3.11)"): Trio sockets always act like blocking sockets; if you need to read/write from multiple sockets at once, then create multiple tasks.

    - [`settimeout()`](https://docs.python.org/3/library/socket.html#socket.socket.settimeout "(in Python v3.11)"): see [Cancellation and timeouts](reference-core#cancellation) instead.

    - [`makefile()`](https://docs.python.org/3/library/socket.html#socket.socket.makefile "(in Python v3.11)"): Python’s file-like API is synchronous, so it can’t be implemented on top of an async socket.

    - [`sendall()`](https://docs.python.org/3/library/socket.html#socket.socket.sendall "(in Python v3.11)"): Could be supported, but you’re better off using the higher-level [`SocketStream`](#trio.SocketStream "trio.SocketStream"), and specifically its [`send_all()`](#trio.SocketStream.send_all "trio.SocketStream.send_all") method, which also does additional error checking.

    In addition, the following methods are similar to the equivalents in [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket "(in Python v3.11)"), but have some Trio-specific quirks:
- name: trio.socket.SocketType.connect
  id: reference-io#trio.socket.SocketType.connect
  summary: Connect the socket to a remote address
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` connect()`

    Connect the socket to a remote address.

    Similar to [`socket.socket.connect()`](https://docs.python.org/3/library/socket.html#socket.socket.connect "(in Python v3.11)"), except async.

    > #### Warning
    >
    > Due to limitations of the underlying operating system APIs, it is not always possible to properly cancel a connection attempt once it has begun. If [`connect()`](#trio.socket.SocketType.connect "trio.socket.SocketType.connect") is cancelled, and is unable to abort the connection attempt, then it will:
    >
    > 1.  forcibly close the socket to prevent accidental re-use
    >
    > 2.  raise [`Cancelled`](reference-core#trio.Cancelled "trio.Cancelled").
    >
    > tl;dr: if [`connect()`](#trio.socket.SocketType.connect "trio.socket.SocketType.connect") is cancelled then the socket is left in an unknown state – possibly open, and possibly closed. The only reasonable thing to do is to close it.
- name: trio.socket.SocketType.did_shutdown_SHUT_WR
  id: reference-io#trio.socket.SocketType.did_shutdown_SHUT_WR
  summary: This bool attribute is True if you’ve called sock.shutdown(SHUT_WR) or sock.shutdown(SHUT_RDWR), and False otherwise
  belongs_to: I/O in Trio
  description: |-
    ### `did_shutdown_SHUT_WR`

    This [`bool`](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)") attribute is True if you’ve called `sock.shutdown(SHUT_WR)` or `sock.shutdown(SHUT_RDWR)`, and False otherwise.

    The following methods are identical to their equivalents in [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket "(in Python v3.11)"), except async, and the ones that take address arguments require pre-resolved addresses:

    - [` ``accept()`` `](https://docs.python.org/3/library/socket.html#socket.socket.accept "(in Python v3.11)")

    - [` ``bind()`` `](https://docs.python.org/3/library/socket.html#socket.socket.bind "(in Python v3.11)")

    - [` ``recv()`` `](https://docs.python.org/3/library/socket.html#socket.socket.recv "(in Python v3.11)")

    - [` ``recv_into()`` `](https://docs.python.org/3/library/socket.html#socket.socket.recv_into "(in Python v3.11)")

    - [` ``recvfrom()`` `](https://docs.python.org/3/library/socket.html#socket.socket.recvfrom "(in Python v3.11)")

    - [` ``recvfrom_into()`` `](https://docs.python.org/3/library/socket.html#socket.socket.recvfrom_into "(in Python v3.11)")

    - [`recvmsg()`](https://docs.python.org/3/library/socket.html#socket.socket.recvmsg "(in Python v3.11)") (if available)

    - [`recvmsg_into()`](https://docs.python.org/3/library/socket.html#socket.socket.recvmsg_into "(in Python v3.11)") (if available)

    - [` ``send()`` `](https://docs.python.org/3/library/socket.html#socket.socket.send "(in Python v3.11)")

    - [` ``sendto()`` `](https://docs.python.org/3/library/socket.html#socket.socket.sendto "(in Python v3.11)")

    - [`sendmsg()`](https://docs.python.org/3/library/socket.html#socket.socket.sendmsg "(in Python v3.11)") (if available)

    All methods and attributes *not* mentioned above are identical to their equivalents in [`socket.socket`](https://docs.python.org/3/library/socket.html#socket.socket "(in Python v3.11)"):

    - [` ``family`` `](https://docs.python.org/3/library/socket.html#socket.socket.family "(in Python v3.11)")

    - [` ``type`` `](https://docs.python.org/3/library/socket.html#socket.socket.type "(in Python v3.11)")

    - [` ``proto`` `](https://docs.python.org/3/library/socket.html#socket.socket.proto "(in Python v3.11)")

    - [` ``fileno()`` `](https://docs.python.org/3/library/socket.html#socket.socket.fileno "(in Python v3.11)")

    - [` ``listen()`` `](https://docs.python.org/3/library/socket.html#socket.socket.listen "(in Python v3.11)")

    - [` ``getpeername()`` `](https://docs.python.org/3/library/socket.html#socket.socket.getpeername "(in Python v3.11)")

    - [` ``getsockname()`` `](https://docs.python.org/3/library/socket.html#socket.socket.getsockname "(in Python v3.11)")

    - [` ``close()`` `](https://docs.python.org/3/library/socket.html#socket.socket.close "(in Python v3.11)")

    - [` ``shutdown()`` `](https://docs.python.org/3/library/socket.html#socket.socket.shutdown "(in Python v3.11)")

    - [` ``setsockopt()`` `](https://docs.python.org/3/library/socket.html#socket.socket.setsockopt "(in Python v3.11)")

    - [` ``getsockopt()`` `](https://docs.python.org/3/library/socket.html#socket.socket.getsockopt "(in Python v3.11)")

    - [` ``dup()`` `](https://docs.python.org/3/library/socket.html#socket.socket.dup "(in Python v3.11)")

    - [` ``detach()`` `](https://docs.python.org/3/library/socket.html#socket.socket.detach "(in Python v3.11)")

    - [` ``share()`` `](https://docs.python.org/3/library/socket.html#socket.socket.share "(in Python v3.11)")

    - [` ``set_inheritable()`` `](https://docs.python.org/3/library/socket.html#socket.socket.set_inheritable "(in Python v3.11)")

    - [` ``get_inheritable()`` `](https://docs.python.org/3/library/socket.html#socket.socket.get_inheritable "(in Python v3.11)")

    ## Asynchronous filesystem I/O

    Trio provides built-in facilities for performing asynchronous filesystem operations like reading or renaming a file. Generally, we recommend that you use these instead of Python’s normal synchronous file APIs. But the tradeoffs here are somewhat subtle: sometimes people switch to async I/O, and then they’re surprised and confused when they find it doesn’t speed up their program. The next section explains the theory behind async file I/O, to help you better understand your code’s behavior. Or, if you just want to get started, you can [jump down to the API overview](#async-file-io-overview).

    ### Background: Why is async file I/O useful? The answer may surprise you

    Many people expect that switching from synchronous file I/O to async file I/O will always make their program faster. This is not true! If we just look at total throughput, then async file I/O might be faster, slower, or about the same, and it depends in a complicated way on things like your exact patterns of disk access, or how much RAM you have. The main motivation for async file I/O is not to improve throughput, but to **reduce the frequency of latency glitches.**

    To understand why, you need to know two things.

    First, right now no mainstream operating system offers a generic, reliable, native API for async file or filesystem operations, so we have to fake it by using threads (specifically, [`trio.to_thread.run_sync()`](reference-core#trio.to_thread.run_sync "trio.to_thread.run_sync")). This is cheap but isn’t free: on a typical PC, dispatching to a worker thread adds something like ~100 µs of overhead to each operation. (“µs” is pronounced “microseconds”, and there are 1,000,000 µs in a second. Note that all the numbers here are going to be rough orders of magnitude to give you a sense of scale; if you need precise numbers for your environment, measure!)

    And second, the cost of a disk operation is incredibly bimodal. Sometimes, the data you need is already cached in RAM, and then accessing it is very, very fast – calling [`io.FileIO`](https://docs.python.org/3/library/io.html#io.FileIO "(in Python v3.11)")'s `read` method on a cached file takes on the order of ~1 µs. But when the data isn’t cached, then accessing it is much, much slower: the average is ~100 µs for SSDs and ~10,000 µs for spinning disks, and if you look at tail latencies then for both types of storage you’ll see cases where occasionally some operation will be 10x or 100x slower than average. And that’s assuming your program is the only thing trying to use that disk – if you’re on some oversold cloud VM fighting for I/O with other tenants then who knows what will happen. And some operations can require multiple disk accesses.

    Putting these together: if your data is in RAM then it should be clear that using a thread is a terrible idea – if you add 100 µs of overhead to a 1 µs operation, then that’s a 100x slowdown! On the other hand, if your data’s on a spinning disk, then using a thread is *great* – instead of blocking the main thread and all tasks for 10,000 µs, we only block them for 100 µs and can spend the rest of that time running other tasks to get useful work done, which can effectively be a 100x speedup.

    But here’s the problem: for any individual I/O operation, there’s no way to know in advance whether it’s going to be one of the fast ones or one of the slow ones, so you can’t pick and choose. When you switch to async file I/O, it makes all the fast operations slower, and all the slow operations faster. Is that a win? In terms of overall speed, it’s hard to say: it depends what kind of disks you’re using and your kernel’s disk cache hit rate, which in turn depends on your file access patterns, how much spare RAM you have, the load on your service, … all kinds of things. If the answer is important to you, then there’s no substitute for measuring your code’s actual behavior in your actual deployment environment. But what we *can* say is that async disk I/O makes performance much more predictable across a wider range of runtime conditions.

    **If you’re not sure what to do, then we recommend that you use async disk I/O by default,** because it makes your code more robust when conditions are bad, especially with regards to tail latencies; this improves the chances that what your users see matches what you saw in testing. Blocking the main thread stops *all* tasks from running for that time. 10,000 µs is 10 ms, and it doesn’t take many 10 ms glitches to start adding up to [real money](https://google.com/search?q=latency+cost); async disk I/O can help prevent those. Just don’t expect it to be magic, and be aware of the tradeoffs.

    ### API overview

    If you want to perform general filesystem operations like creating and listing directories, renaming files, or checking file metadata – or if you just want a friendly way to work with filesystem paths – then you want [`trio.Path`](#trio.Path "trio.Path"). It’s an asyncified replacement for the standard library’s [`pathlib.Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path "(in Python v3.11)"), and provides the same comprehensive set of operations.

    For reading and writing to files and file-like objects, Trio also provides a mechanism for wrapping any synchronous file-like object into an asynchronous interface. If you have a [`trio.Path`](#trio.Path "trio.Path") object you can get one of these by calling its [`open()`](#trio.Path.open "trio.Path.open") method; or if you know the file’s name you can open it directly with [`trio.open_file()`](#trio.open_file "trio.open_file"). Alternatively, if you already have an open file-like object, you can wrap it with [`trio.wrap_file()`](#trio.wrap_file "trio.wrap_file") – one case where this is especially useful is to wrap [`io.BytesIO`](https://docs.python.org/3/library/io.html#io.BytesIO "(in Python v3.11)") or [`io.StringIO`](https://docs.python.org/3/library/io.html#io.StringIO "(in Python v3.11)") when writing tests.

    ### Asynchronous path objects
- name: trio.socket.SocketType.is_readable
  id: reference-io#trio.socket.SocketType.is_readable
  summary: Check whether the socket is readable or not
  belongs_to: I/O in Trio
  description: |-
    ### `is_readable()`

    Check whether the socket is readable or not.
- name: trio.socket.SocketType.sendfile
  id: reference-io#trio.socket.SocketType.sendfile
  summary: null
  belongs_to: I/O in Trio
  description: |-
    ### `sendfile()`

    [Not implemented yet!](https://github.com/python-trio/trio/issues/45)

    We also keep track of an extra bit of state, because it turns out to be useful for [`trio.SocketStream`](#trio.SocketStream "trio.SocketStream"):
- name: trio.SocketListener
  id: reference-io#trio.SocketListener
  summary: A Listener that uses a listening socket to accept incoming connections as SocketStream objects
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.SocketListener(socket)`

    Bases: [`Listener`](#trio.abc.Listener "trio.abc.Listener")\[[`SocketStream`](#trio.SocketStream "trio.SocketStream")\]

    A [`Listener`](#trio.abc.Listener "trio.abc.Listener") that uses a listening socket to accept incoming connections as [`SocketStream`](#trio.SocketStream "trio.SocketStream") objects.

    #### Parameters:

    **socket** – The Trio socket object to wrap. Must have type `SOCK_STREAM`, and be listening.

    Note that the [`SocketListener`](#trio.SocketListener "trio.SocketListener") “takes ownership” of the given socket; closing the [`SocketListener`](#trio.SocketListener "trio.SocketListener") will also close the socket.
- name: trio.SocketListener.accept
  id: reference-io#trio.SocketListener.accept
  summary: Accept an incoming connection
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` accept()`

    Accept an incoming connection.

    #### Returns:

    [` ``SocketStream`` `](#trio.SocketStream "trio.SocketStream")

    #### Raises:

    - [**OSError**](https://docs.python.org/3/library/exceptions.html#OSError "(in Python v3.11)") – if the underlying call to `accept` raises an unexpected error.

    - [**ClosedResourceError**](reference-core#trio.ClosedResourceError "trio.ClosedResourceError") – if you already closed the socket.

    This method handles routine errors like `ECONNABORTED`, but passes other errors on to its caller. In particular, it does *not* make any special effort to handle resource exhaustion errors like `EMFILE`, `ENFILE`, `ENOBUFS`, `ENOMEM`.
- name: trio.SocketListener.aclose
  id: reference-io#trio.SocketListener.aclose
  summary: Close this listener and its underlying socket
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` aclose()`

    Close this listener and its underlying socket.
- name: trio.SocketListener.socket
  id: reference-io#trio.SocketListener.socket
  summary: The Trio socket object that this stream wraps
  belongs_to: I/O in Trio
  description: |-
    ### `socket`

    The Trio socket object that this stream wraps.
- name: trio.SocketStream
  id: reference-io#trio.SocketStream
  summary: An implementation of the trio.abc.HalfCloseableStream interface based on a raw network socket
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.SocketStream(socket)`

    Bases: [`HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream")

    An implementation of the [`trio.abc.HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream") interface based on a raw network socket.

    #### Parameters:

    **socket** – The Trio socket object to wrap. Must have type `SOCK_STREAM`, and be connected.

    By default for TCP sockets, [`SocketStream`](#trio.SocketStream "trio.SocketStream") enables `TCP_NODELAY`, and (on platforms where it’s supported) enables `TCP_NOTSENT_LOWAT` with a reasonable buffer size (currently 16 KiB) – see [issue \#72](https://github.com/python-trio/trio/issues/72) for discussion. You can of course override these defaults by calling [`setsockopt()`](#trio.SocketStream.setsockopt "trio.SocketStream.setsockopt").

    Once a [`SocketStream`](#trio.SocketStream "trio.SocketStream") object is constructed, it implements the full [`trio.abc.HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream") interface. In addition, it provides a few extra features:
- name: trio.SocketStream.aclose
  id: reference-io#trio.SocketStream.aclose
  summary: null
  belongs_to: I/O in Trio
  description: '### *`await`*` aclose()`'
- name: trio.SocketStream.getsockopt
  id: reference-io#trio.SocketStream.getsockopt
  summary: Check the current value of an option on the underlying socket
  belongs_to: I/O in Trio
  description: |-
    ### `getsockopt(level, option, buffersize=0)`

    Check the current value of an option on the underlying socket.

    See [`socket.socket.getsockopt()`](https://docs.python.org/3/library/socket.html#socket.socket.getsockopt "(in Python v3.11)") for details.
- name: trio.SocketStream.receive_some
  id: reference-io#trio.SocketStream.receive_some
  summary: null
  belongs_to: I/O in Trio
  description: '### *`await`*` receive_some(max_bytes=None)`'
- name: trio.SocketStream.send_all
  id: reference-io#trio.SocketStream.send_all
  summary: null
  belongs_to: I/O in Trio
  description: '### *`await`*` send_all(data)`'
- name: trio.SocketStream.send_eof
  id: reference-io#trio.SocketStream.send_eof
  summary: null
  belongs_to: I/O in Trio
  description: '### *`await`*` send_eof()`'
- name: trio.SocketStream.setsockopt
  id: reference-io#trio.SocketStream.setsockopt
  summary: Set an option on the underlying socket
  belongs_to: I/O in Trio
  description: |-
    ### `setsockopt(level, option, value)`

    Set an option on the underlying socket.

    See [`socket.socket.setsockopt()`](https://docs.python.org/3/library/socket.html#socket.socket.setsockopt "(in Python v3.11)") for details.
- name: trio.SocketStream.socket
  id: reference-io#trio.SocketStream.socket
  summary: The Trio socket object that this stream wraps
  belongs_to: I/O in Trio
  description: |-
    ### `socket`

    The Trio socket object that this stream wraps.
- name: trio.SocketStream.wait_send_all_might_not_block
  id: reference-io#trio.SocketStream.wait_send_all_might_not_block
  summary: null
  belongs_to: I/O in Trio
  description: '### *`await`*` wait_send_all_might_not_block()`'
- name: trio.SSLListener
  id: reference-io#trio.SSLListener
  summary: A Listener for SSL/TLS-encrypted servers
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.SSLListener(transport_listener, ssl_context, *, https_compatible=False)`

    Bases: [`Listener`](#trio.abc.Listener "trio.abc.Listener")\[[`SSLStream`](#trio.SSLStream "trio.SSLStream")\]

    A [`Listener`](#trio.abc.Listener "trio.abc.Listener") for SSL/TLS-encrypted servers.

    [`SSLListener`](#trio.SSLListener "trio.SSLListener") wraps around another Listener, and converts all incoming connections to encrypted connections by wrapping them in a [`SSLStream`](#trio.SSLStream "trio.SSLStream").

    #### Parameters:

    - **transport_listener** ([*Listener*](#trio.abc.Listener "trio.abc.Listener")) – The listener whose incoming connections will be wrapped in [`SSLStream`](#trio.SSLStream "trio.SSLStream").

    - **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)")) – The [`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)") that will be used for incoming connections.

    - **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – Passed on to [`SSLStream`](#trio.SSLStream "trio.SSLStream").
- name: trio.SSLListener.accept
  id: reference-io#trio.SSLListener.accept
  summary: Accept the next connection and wrap it in an SSLStream
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` accept()`

    Accept the next connection and wrap it in an [`SSLStream`](#trio.SSLStream "trio.SSLStream").

    See [`trio.abc.Listener.accept()`](#trio.abc.Listener.accept "trio.abc.Listener.accept") for details.
- name: trio.SSLListener.aclose
  id: reference-io#trio.SSLListener.aclose
  summary: Close the transport listener
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` aclose()`

    Close the transport listener.

    Some methods on [`SSLStream`](#trio.SSLStream "trio.SSLStream") raise [`NeedHandshakeError`](#trio.NeedHandshakeError "trio.NeedHandshakeError") if you call them before the handshake completes:
- name: trio.SSLListener.transport_listener
  id: reference-io#trio.SSLListener.transport_listener
  summary: null
  belongs_to: I/O in Trio
  description: |-
    ### `transport_listener`

    The underlying listener that was passed to `__init__`.

    #### Type:

    [trio.abc.Listener](#trio.abc.Listener "trio.abc.Listener")
- name: trio.SSLStream
  id: reference-io#trio.SSLStream
  summary: Encrypted communication using SSL/TLS
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.SSLStream(transport_stream, ssl_context, *, server_hostname=None, server_side=False, https_compatible=False)`

    Bases: [`Stream`](#trio.abc.Stream "trio.abc.Stream")

    Encrypted communication using SSL/TLS.

    [`SSLStream`](#trio.SSLStream "trio.SSLStream") wraps an arbitrary [`Stream`](#trio.abc.Stream "trio.abc.Stream"), and allows you to perform encrypted communication over it using the usual [`Stream`](#trio.abc.Stream "trio.abc.Stream") interface. You pass regular data to [`send_all()`](#trio.SSLStream.send_all "trio.SSLStream.send_all"), then it encrypts it and sends the encrypted data on the underlying [`Stream`](#trio.abc.Stream "trio.abc.Stream"); [`receive_some()`](#trio.SSLStream.receive_some "trio.SSLStream.receive_some") takes encrypted data out of the underlying [`Stream`](#trio.abc.Stream "trio.abc.Stream") and decrypts it before returning it.

    You should read the standard library’s [`ssl`](https://docs.python.org/3/library/ssl.html#module-ssl "(in Python v3.11)") documentation carefully before attempting to use this class, and probably other general documentation on SSL/TLS as well. SSL/TLS is subtle and quick to anger. Really. I’m not kidding.

    #### Parameters:

    - **transport_stream** ([*Stream*](#trio.abc.Stream "trio.abc.Stream")) – The stream used to transport encrypted data. Required.

    - **ssl_context** ([*SSLContext*](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)")) – The [`SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext "(in Python v3.11)") used for this connection. Required. Usually created by calling [`ssl.create_default_context()`](https://docs.python.org/3/library/ssl.html#ssl.create_default_context "(in Python v3.11)").

    - **server_hostname** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)") *or* *None*) – The name of the server being connected to. Used for [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) and for validating the server’s certificate (if hostname checking is enabled). This is effectively mandatory for clients, and actually mandatory if `ssl_context.check_hostname` is `True`.

    - **server_side** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – Whether this stream is acting as a client or server. Defaults to False, i.e. client mode.

    - **https_compatible** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) –

      There are two versions of SSL/TLS commonly encountered in the wild: the standard version, and the version used for HTTPS (HTTP-over-SSL/TLS).

      Standard-compliant SSL/TLS implementations always send a cryptographically signed `close_notify` message before closing the connection. This is important because if the underlying transport were simply closed, then there wouldn’t be any way for the other side to know whether the connection was intentionally closed by the peer that they negotiated a cryptographic connection to, or by some [man-in-the-middle](https://en.wikipedia.org/wiki/Man-in-the-middle_attack) attacker who can’t manipulate the cryptographic stream, but can manipulate the transport layer (a so-called “truncation attack”).

      However, this part of the standard is widely ignored by real-world HTTPS implementations, which means that if you want to interoperate with them, then you NEED to ignore it too.

      Fortunately this isn’t as bad as it sounds, because the HTTP protocol already includes its own equivalent of `close_notify`, so doing this again at the SSL/TLS level is redundant. But not all protocols do! Therefore, by default Trio implements the safer standard-compliant version (`https_compatible=False`). But if you’re speaking HTTPS or some other protocol where `close_notify`s are commonly skipped, then you should set `https_compatible=True`; with this setting, Trio will neither expect nor send `close_notify` messages.

      If you have code that was written to use [`ssl.SSLSocket`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket "(in Python v3.11)") and now you’re porting it to Trio, then it may be useful to know that a difference between [`SSLStream`](#trio.SSLStream "trio.SSLStream") and [`ssl.SSLSocket`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket "(in Python v3.11)") is that [`SSLSocket`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket "(in Python v3.11)") implements the `https_compatible=True` behavior by default.
- name: trio.SSLStream.aclose
  id: reference-io#trio.SSLStream.aclose
  summary: Gracefully shut down this connection, and close the underlying transport
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` aclose()`

    Gracefully shut down this connection, and close the underlying transport.

    If `https_compatible` is False (the default), then this attempts to first send a `close_notify` and then close the underlying stream by calling its [`aclose()`](#trio.abc.AsyncResource.aclose "trio.abc.AsyncResource.aclose") method.

    If `https_compatible` is set to True, then this simply closes the underlying stream and marks this stream as closed.
- name: trio.SSLStream.do_handshake
  id: reference-io#trio.SSLStream.do_handshake
  summary: Ensure that the initial handshake has completed
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` do_handshake()`

    Ensure that the initial handshake has completed.

    The SSL protocol requires an initial handshake to exchange certificates, select cryptographic keys, and so forth, before any actual data can be sent or received. You don’t have to call this method; if you don’t, then [`SSLStream`](#trio.SSLStream "trio.SSLStream") will automatically perform the handshake as needed, the first time you try to send or receive data. But if you want to trigger it manually – for example, because you want to look at the peer’s certificate before you start talking to them – then you can call this method.

    If the initial handshake is already in progress in another task, this waits for it to complete and then returns.

    If the initial handshake has already completed, this returns immediately without doing anything (except executing a checkpoint).

    > #### Warning
    >
    > If this method is cancelled, then it may leave the [`SSLStream`](#trio.SSLStream "trio.SSLStream") in an unusable state. If this happens then any future attempt to use the object will raise [`trio.BrokenResourceError`](reference-core#trio.BrokenResourceError "trio.BrokenResourceError").
- name: trio.SSLStream.receive_some
  id: reference-io#trio.SSLStream.receive_some
  summary: Read some data from the underlying transport, decrypt it, and return it
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` receive_some(max_bytes=None)`

    Read some data from the underlying transport, decrypt it, and return it.

    See [`trio.abc.ReceiveStream.receive_some()`](#trio.abc.ReceiveStream.receive_some "trio.abc.ReceiveStream.receive_some") for details.

    > #### Warning
    >
    > If this method is cancelled while the initial handshake or a renegotiation are in progress, then it may leave the [`SSLStream`](#trio.SSLStream "trio.SSLStream") in an unusable state. If this happens then any future attempt to use the object will raise [`trio.BrokenResourceError`](reference-core#trio.BrokenResourceError "trio.BrokenResourceError").
- name: trio.SSLStream.send_all
  id: reference-io#trio.SSLStream.send_all
  summary: Encrypt some data and then send it on the underlying transport
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` send_all(data)`

    Encrypt some data and then send it on the underlying transport.

    See [`trio.abc.SendStream.send_all()`](#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") for details.

    > #### Warning
    >
    > If this method is cancelled, then it may leave the [`SSLStream`](#trio.SSLStream "trio.SSLStream") in an unusable state. If this happens then any attempt to use the object will raise [`trio.BrokenResourceError`](reference-core#trio.BrokenResourceError "trio.BrokenResourceError").
- name: trio.SSLStream.transport_stream
  id: reference-io#trio.SSLStream.transport_stream
  summary: The underlying transport stream that was passed to __init__. An example of when this would be useful is if you’re using SSLStream over a SocketStream and want to call the SocketStream’s setsockopt() method
  belongs_to: I/O in Trio
  description: |-
    ### `transport_stream`

    The underlying transport stream that was passed to `__init__`. An example of when this would be useful is if you’re using [`SSLStream`](#trio.SSLStream "trio.SSLStream") over a [`SocketStream`](#trio.SocketStream "trio.SocketStream") and want to call the [`SocketStream`](#trio.SocketStream "trio.SocketStream")’s [`setsockopt()`](#trio.SocketStream.setsockopt "trio.SocketStream.setsockopt") method.

    #### Type:

    [trio.abc.Stream](#trio.abc.Stream "trio.abc.Stream")

    Internally, this class is implemented using an instance of [`ssl.SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject "(in Python v3.11)"), and all of [`SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject "(in Python v3.11)")’s methods and attributes are re-exported as methods and attributes on this class. However, there is one difference: [`SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject "(in Python v3.11)") has several methods that return information about the encrypted connection, like [`cipher()`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket.cipher "(in Python v3.11)") or [`selected_alpn_protocol()`](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket.selected_alpn_protocol "(in Python v3.11)"). If you call them before the handshake, when they can’t possibly return useful data, then [`ssl.SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject "(in Python v3.11)") returns None, but [`trio.SSLStream`](#trio.SSLStream "trio.SSLStream") raises [`NeedHandshakeError`](#trio.NeedHandshakeError "trio.NeedHandshakeError").

    This also means that if you register a SNI callback using [`sni_callback`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext.sni_callback "(in Python v3.11)"), then the first argument your callback receives will be a [`ssl.SSLObject`](https://docs.python.org/3/library/ssl.html#ssl.SSLObject "(in Python v3.11)").
- name: trio.SSLStream.unwrap
  id: reference-io#trio.SSLStream.unwrap
  summary: Cleanly close down the SSL/TLS encryption layer, allowing the underlying stream to be used for unencrypted communication
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` unwrap()`

    Cleanly close down the SSL/TLS encryption layer, allowing the underlying stream to be used for unencrypted communication.

    You almost certainly don’t need this.

    #### Returns:

    A pair `(transport_stream,``trailing_bytes)`, where `transport_stream` is the underlying transport stream, and `trailing_bytes` is a byte string. Since [`SSLStream`](#trio.SSLStream "trio.SSLStream") doesn’t necessarily know where the end of the encrypted data will be, it can happen that it accidentally reads too much from the underlying stream. `trailing_bytes` contains this extra data; you should process it as if it was returned from a call to `transport_stream.receive_some(...)`.
- name: trio.SSLStream.wait_send_all_might_not_block
  id: reference-io#trio.SSLStream.wait_send_all_might_not_block
  summary: See trio.abc.SendStream.wait_send_all_might_not_block()
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` wait_send_all_might_not_block()`

    See [`trio.abc.SendStream.wait_send_all_might_not_block()`](#trio.abc.SendStream.wait_send_all_might_not_block "trio.abc.SendStream.wait_send_all_might_not_block").

    And if you’re implementing a server, you can use [`SSLListener`](#trio.SSLListener "trio.SSLListener"):
- name: trio.StapledStream
  id: reference-io#trio.StapledStream
  summary: This class staples together two unidirectional streams to make single bidirectional stream
  belongs_to: I/O in Trio
  description: |-
    ### *`class`*` trio.StapledStream(send_stream, receive_stream)`

    Bases: [`HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream")

    This class [staples](https://en.wikipedia.org/wiki/Staple_(fastener)) together two unidirectional streams to make single bidirectional stream.

    #### Parameters:

    - **send_stream** ([*SendStream*](#trio.abc.SendStream "trio.abc.SendStream")) – The stream to use for sending.

    - **receive_stream** ([*ReceiveStream*](#trio.abc.ReceiveStream "trio.abc.ReceiveStream")) – The stream to use for receiving.

    Example

    A silly way to make a stream that echoes back whatever you write to it:

    ``` python
    left, right = trio.testing.memory_stream_pair()
    echo_stream = StapledStream(SocketStream(left), SocketStream(right))
    await echo_stream.send_all(b"x")
    assert await echo_stream.receive_some() == b"x"
    ```

    [`StapledStream`](#trio.StapledStream "trio.StapledStream") objects implement the methods in the [`HalfCloseableStream`](#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream") interface. They also have two additional public attributes:
- name: trio.StapledStream.aclose
  id: reference-io#trio.StapledStream.aclose
  summary: Calls aclose on both underlying streams
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` aclose()`

    Calls `aclose` on both underlying streams.
- name: trio.StapledStream.receive_some
  id: reference-io#trio.StapledStream.receive_some
  summary: Calls self.receive_stream.receive_some
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` receive_some(max_bytes=None)`

    Calls `self.receive_stream.receive_some`.
- name: trio.StapledStream.receive_stream
  id: reference-io#trio.StapledStream.receive_stream
  summary: The underlying ReceiveStream
  belongs_to: I/O in Trio
  description: |-
    ### `receive_stream`

    The underlying [`ReceiveStream`](#trio.abc.ReceiveStream "trio.abc.ReceiveStream"). [`receive_some()`](#trio.StapledStream.receive_some "trio.StapledStream.receive_some") is delegated to this object.
- name: trio.StapledStream.send_all
  id: reference-io#trio.StapledStream.send_all
  summary: Calls self.send_stream.send_all
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` send_all(data)`

    Calls `self.send_stream.send_all`.
- name: trio.StapledStream.send_eof
  id: reference-io#trio.StapledStream.send_eof
  summary: Shuts down the send side of the stream
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` send_eof()`

    Shuts down the send side of the stream.

    If `self.send_stream.send_eof` exists, then calls it. Otherwise, calls `self.send_stream.aclose()`.
- name: trio.StapledStream.send_stream
  id: reference-io#trio.StapledStream.send_stream
  summary: The underlying SendStream
  belongs_to: I/O in Trio
  description: |-
    ### `send_stream`

    The underlying [`SendStream`](#trio.abc.SendStream "trio.abc.SendStream"). [`send_all()`](#trio.StapledStream.send_all "trio.StapledStream.send_all") and [`wait_send_all_might_not_block()`](#trio.StapledStream.wait_send_all_might_not_block "trio.StapledStream.wait_send_all_might_not_block") are delegated to this object.
- name: trio.StapledStream.wait_send_all_might_not_block
  id: reference-io#trio.StapledStream.wait_send_all_might_not_block
  summary: Calls self.send_stream.wait_send_all_might_not_block
  belongs_to: I/O in Trio
  description: |-
    ### *`await`*` wait_send_all_might_not_block()`

    Calls `self.send_stream.wait_send_all_might_not_block`.

    ### Sockets and networking

    The high-level network interface is built on top of our stream abstraction.
- name: trio.StrictFIFOLock
  id: reference-core#trio.StrictFIFOLock
  summary: A variant of Lock where tasks are guaranteed to acquire the lock in strict first-come-first-served order
  belongs_to: Trio’s core functionality
  description: |-
    ### *`class`*` trio.StrictFIFOLock`

    A variant of [`Lock`](#trio.Lock "trio.Lock") where tasks are guaranteed to acquire the lock in strict first-come-first-served order.

    An example of when this is useful is if you’re implementing something like [`trio.SSLStream`](reference-io#trio.SSLStream "trio.SSLStream") or an HTTP/2 server using [h2](https://hyper-h2.readthedocs.io/), where you have multiple concurrent tasks that are interacting with a shared state machine, and at unpredictable moments the state machine requests that a chunk of data be sent over the network. (For example, when using h2 simply reading incoming data can occasionally [create outgoing data to send](https://http2.github.io/http2-spec/#PING).) The challenge is to make sure that these chunks are sent in the correct order, without being garbled.

    One option would be to use a regular [`Lock`](#trio.Lock "trio.Lock"), and wrap it around every interaction with the state machine:

    ``` python
    # This approach is sometimes workable but often sub-optimal; see below
    async with lock:
        state_machine.do_something()
        if state_machine.has_data_to_send():
            await conn.sendall(state_machine.get_data_to_send())
    ```

    But this can be problematic. If you’re using h2 then *usually* reading incoming data doesn’t create the need to send any data, so we don’t want to force every task that tries to read from the network to sit and wait a potentially long time for `sendall` to finish. And in some situations this could even potentially cause a deadlock, if the remote peer is waiting for you to read some data before it accepts the data you’re sending.

    [`StrictFIFOLock`](#trio.StrictFIFOLock "trio.StrictFIFOLock") provides an alternative. We can rewrite our example like:

    ``` python
    # Note: no awaits between when we start using the state machine and
    # when we block to take the lock!
    state_machine.do_something()
    if state_machine.has_data_to_send():
        # Notice that we fetch the data to send out of the state machine
        # *before* sleeping, so that other tasks won't see it.
        chunk = state_machine.get_data_to_send()
        async with strict_fifo_lock:
            await conn.sendall(chunk)
    ```

    First we do all our interaction with the state machine in a single scheduling quantum (notice there are no `await`s in there), so it’s automatically atomic with respect to other tasks. And then if and only if we have data to send, we get in line to send it – and [`StrictFIFOLock`](#trio.StrictFIFOLock "trio.StrictFIFOLock") guarantees that each task will send its data in the same order that the state machine generated it.

    Currently, [`StrictFIFOLock`](#trio.StrictFIFOLock "trio.StrictFIFOLock") is identical to [`Lock`](#trio.Lock "trio.Lock"), but (a) this may not always be true in the future, especially if Trio ever implements [more sophisticated scheduling policies](https://github.com/python-trio/trio/issues/32), and (b) the above code is relying on a pretty subtle property of its lock. Using a [`StrictFIFOLock`](#trio.StrictFIFOLock "trio.StrictFIFOLock") acts as an executable reminder that you’re relying on this property.
- name: trio.TASK_STATUS_IGNORED
  id: reference-core#trio.TASK_STATUS_IGNORED
  summary: See start()
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.TASK_STATUS_IGNORED`

    See [`start()`](#trio.Nursery.start "trio.Nursery.start").

    ## Task-local storage

    Suppose you’re writing a server that responds to network requests, and you log some information about each request as you process it. If the server is busy and there are multiple requests being handled at the same time, then you might end up with logs like this:

        Request handler started
        Request handler started
        Request handler finished
        Request handler finished

    In this log, it’s hard to know which lines came from which request. (Did the request that started first also finish first, or not?) One way to solve this is to assign each request a unique identifier, and then include this identifier in each log message:

        request 1: Request handler started
        request 2: Request handler started
        request 2: Request handler finished
        request 1: Request handler finished

    This way we can see that request 1 was slow: it started before request 2 but finished afterwards. (You can also get [much fancier](https://opentracing.io/docs/), but this is enough for an example.)

    Now, here’s the problem: how does the logging code know what the request identifier is? One approach would be to explicitly pass it around to every function that might want to emit logs… but that’s basically every function, because you never know when you might need to add a `log.debug(...)` call to some utility function buried deep in the call stack, and when you’re in the middle of a debugging a nasty problem that last thing you want is to have to stop first and refactor everything to pass through the request identifier! Sometimes this is the right solution, but other times it would be much more convenient if we could store the identifier in a global variable, so that the logging function could look it up whenever it needed it. Except… a global variable can only have one value at a time, so if we have multiple handlers running at once then this isn’t going to work. What we need is something that’s *like* a global variable, but that can have different values depending on which request handler is accessing it.

    To solve this problem, Python 3.7 added a new module to the standard library: [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)"). And not only does Trio have built-in support for [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)"), but if you’re using an earlier version of Python, then Trio makes sure that a backported version of [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)") is installed. So you can assume [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)") is there and works regardless of what version of Python you’re using.

    Here’s a toy example demonstrating how to use [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars "(in Python v3.11)"):

    ``` python
    import random
    import trio
    import contextvars

    request_info = contextvars.ContextVar("request_info")


    # Example logging function that tags each line with the request identifier.
    def log(msg):
        # Read from task-local storage:
        request_tag = request_info.get()

        print(f"request {request_tag}: {msg}")


    # An example "request handler" that does some work itself and also
    # spawns some helper tasks to do some concurrent work.
    async def handle_request(tag):
        # Write to task-local storage:
        request_info.set(tag)

        log("Request handler started")
        await trio.sleep(random.random())
        async with trio.open_nursery() as nursery:
            nursery.start_soon(concurrent_helper, "a")
            nursery.start_soon(concurrent_helper, "b")
        await trio.sleep(random.random())
        log("Request received finished")


    async def concurrent_helper(job):
        log(f"Helper task {job} started")
        await trio.sleep(random.random())
        log(f"Helper task {job} finished")


    # Spawn several "request handlers" simultaneously, to simulate a
    # busy server handling multiple requests at the same time.
    async def main():
        async with trio.open_nursery() as nursery:
            for i in range(3):
                nursery.start_soon(handle_request, i)


    trio.run(main)
    ```

    Example output (yours may differ slightly):

        request 1: Request handler started
        request 2: Request handler started
        request 0: Request handler started
        request 2: Helper task a started
        request 2: Helper task b started
        request 1: Helper task a started
        request 1: Helper task b started
        request 0: Helper task b started
        request 0: Helper task a started
        request 2: Helper task b finished
        request 2: Helper task a finished
        request 2: Request received finished
        request 0: Helper task a finished
        request 1: Helper task a finished
        request 1: Helper task b finished
        request 1: Request received finished
        request 0: Helper task b finished
        request 0: Request received finished

    For more information, read the [contextvars docs](https://docs.python.org/3.7/library/contextvars.html).

    ## Synchronizing and communicating between tasks

    Trio provides a standard set of synchronization and inter-task communication primitives. These objects’ APIs are generally modelled off of the analogous classes in the standard library, but with some differences.

    ### Blocking and non-blocking methods

    The standard library synchronization primitives have a variety of mechanisms for specifying timeouts and blocking behavior, and of signaling whether an operation returned due to success versus a timeout.

    In Trio, we standardize on the following conventions:

    - We don’t provide timeout arguments. If you want a timeout, then use a cancel scope.

    - For operations that have a non-blocking variant, the blocking and non-blocking variants are different methods with names like `X` and `X_nowait`, respectively. (This is similar to [`queue.Queue`](https://docs.python.org/3/library/queue.html#queue.Queue "(in Python v3.11)"), but unlike most of the classes in [`threading`](https://docs.python.org/3/library/threading.html#module-threading "(in Python v3.11)").) We like this approach because it allows us to make the blocking version async and the non-blocking version sync.

    - When a non-blocking method cannot succeed (the channel is empty, the lock is already held, etc.), then it raises [`trio.WouldBlock`](#trio.WouldBlock "trio.WouldBlock"). There’s no equivalent to the [`queue.Empty`](https://docs.python.org/3/library/queue.html#queue.Empty "(in Python v3.11)") versus [`queue.Full`](https://docs.python.org/3/library/queue.html#queue.Full "(in Python v3.11)") distinction – we just have the one exception that we use consistently.

    ### Fairness

    These classes are all guaranteed to be “fair”, meaning that when it comes time to choose who will be next to acquire a lock, get an item from a queue, etc., then it always goes to the task which has been waiting longest. It’s [not entirely clear](https://github.com/python-trio/trio/issues/54) whether this is the best choice, but for now that’s how it works.

    As an example of what this means, here’s a small program in which two tasks compete for a lock. Notice that the task which releases the lock always immediately attempts to re-acquire it, before the other task has a chance to run. (And remember that we’re doing cooperative multi-tasking here, so it’s actually *deterministic* that the task releasing the lock will call [`acquire()`](#trio.Lock.acquire "trio.Lock.acquire") before the other task wakes up; in Trio releasing a lock is not a checkpoint.) With an unfair lock, this would result in the same task holding the lock forever and the other task being starved out. But if you run this, you’ll see that the two tasks politely take turns:

    ``` python
    # fairness-demo.py

    import trio

    async def loopy_child(number, lock):
        while True:
            async with lock:
                print(f"Child {number} has the lock!")
                await trio.sleep(0.5)

    async def main():
        async with trio.open_nursery() as nursery:
            lock = trio.Lock()
            nursery.start_soon(loopy_child, 1, lock)
            nursery.start_soon(loopy_child, 2, lock)

    trio.run(main)
    ```

    ### Broadcasting an event with [`Event`](#trio.Event "trio.Event")
- name: trio.testing.assert_checkpoints
  id: reference-testing#trio.testing.assert_checkpoints
  summary: Use as a context manager to check that the code inside the with block either exits with an exception or executes at least one checkpoint
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`with`*` trio.testing.assert_checkpoints()`

    Use as a context manager to check that the code inside the `with` block either exits with an exception or executes at least one [checkpoint](reference-core#checkpoints).

    #### Raises:

    [**AssertionError**](https://docs.python.org/3/library/exceptions.html#AssertionError "(in Python v3.11)") – if no checkpoint was executed.

    Example

    Check that [`trio.sleep()`](reference-core#trio.sleep "trio.sleep") is a checkpoint, even if it doesn’t block:

    ``` python
    with trio.testing.assert_checkpoints():
        await trio.sleep(0)
    ```
- name: trio.testing.assert_no_checkpoints
  id: reference-testing#trio.testing.assert_no_checkpoints
  summary: Use as a context manager to check that the code inside the with block does not execute any checkpoints
  belongs_to: Testing made easier with trio.testing
  description: "### *`with`*` trio.testing.assert_no_checkpoints()`\n\nUse as a context manager to check that the code inside the `with` block does not execute any [checkpoints](reference-core#checkpoints).\n\n#### Raises:\n\n[**AssertionError**](https://docs.python.org/3/library/exceptions.html#AssertionError \"(in Python v3.11)\") – if a checkpoint was executed.\n\nExample\n\nSynchronous code never contains any checkpoints, but we can double-check that:\n\n``` python\nsend_channel, receive_channel = trio.open_memory_channel(10)\nwith trio.testing.assert_no_checkpoints():\n    send_channel.send_nowait(None)\n```\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-testing.html](https://trio.readthedocs.io/en/v0.22.2/reference-testing.html)"
- name: trio.testing.check_half_closeable_stream
  id: reference-testing#trio.testing.check_half_closeable_stream
  summary: Perform a number of generic tests on a custom half-closeable stream implementation
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` trio.testing.check_half_closeable_stream(stream_maker, clogged_stream_maker)`

    Perform a number of generic tests on a custom half-closeable stream implementation.

    This is similar to [`check_two_way_stream()`](#trio.testing.check_two_way_stream "trio.testing.check_two_way_stream"), except that the maker functions are expected to return objects that implement the [`HalfCloseableStream`](reference-io#trio.abc.HalfCloseableStream "trio.abc.HalfCloseableStream") interface.

    This function tests a *superset* of what [`check_two_way_stream()`](#trio.testing.check_two_way_stream "trio.testing.check_two_way_stream") checks – if you call this, then you don’t need to also call [`check_two_way_stream()`](#trio.testing.check_two_way_stream "trio.testing.check_two_way_stream").

    ## Virtual networking for testing

    In the previous section you learned how to use virtual in-memory streams to test protocols that are written against Trio’s [`Stream`](reference-io#trio.abc.Stream "trio.abc.Stream") abstraction. But what if you have more complicated networking code – the kind of code that makes connections to multiple hosts, or opens a listening socket, or sends UDP packets?

    Trio doesn’t itself provide a virtual in-memory network implementation for testing – but [`trio.socket`](reference-io#module-trio.socket "trio.socket") module does provide the hooks you need to write your own! And if you’re interested in helping implement a reusable virtual network for testing, then [please get in touch](https://github.com/python-trio/trio/issues/170).

    Note that these APIs are actually in [`trio.socket`](reference-io#module-trio.socket "trio.socket") and `trio.abc`, but we document them here because they’re primarily intended for testing.
- name: trio.testing.check_one_way_stream
  id: reference-testing#trio.testing.check_one_way_stream
  summary: Perform a number of generic tests on a custom one-way stream implementation
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` trio.testing.check_one_way_stream(stream_maker, clogged_stream_maker)`

    Perform a number of generic tests on a custom one-way stream implementation.

    #### Parameters:

    - **stream_maker** – An async (!) function which returns a connected ([`SendStream`](reference-io#trio.abc.SendStream "trio.abc.SendStream"), [`ReceiveStream`](reference-io#trio.abc.ReceiveStream "trio.abc.ReceiveStream")) pair.

    - **clogged_stream_maker** – Either None, or an async function similar to stream_maker, but with the extra property that the returned stream is in a state where `send_all` and `wait_send_all_might_not_block` will block until `receive_some` has been called. This allows for more thorough testing of some edge cases, especially around `wait_send_all_might_not_block`.

    #### Raises:

    [**AssertionError**](https://docs.python.org/3/library/exceptions.html#AssertionError "(in Python v3.11)") – if a test fails.
- name: trio.testing.check_two_way_stream
  id: reference-testing#trio.testing.check_two_way_stream
  summary: Perform a number of generic tests on a custom two-way stream implementation
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` trio.testing.check_two_way_stream(stream_maker, clogged_stream_maker)`

    Perform a number of generic tests on a custom two-way stream implementation.

    This is similar to [`check_one_way_stream()`](#trio.testing.check_one_way_stream "trio.testing.check_one_way_stream"), except that the maker functions are expected to return objects implementing the [`Stream`](reference-io#trio.abc.Stream "trio.abc.Stream") interface.

    This function tests a *superset* of what [`check_one_way_stream()`](#trio.testing.check_one_way_stream "trio.testing.check_one_way_stream") checks – if you call this, then you don’t need to also call [`check_one_way_stream()`](#trio.testing.check_one_way_stream "trio.testing.check_one_way_stream").
- name: trio.testing.lockstep_stream_one_way_pair
  id: reference-testing#trio.testing.lockstep_stream_one_way_pair
  summary: Create a connected, pure Python, unidirectional stream where data flows in lockstep
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.testing.lockstep_stream_one_way_pair()`

    Create a connected, pure Python, unidirectional stream where data flows in lockstep.

    #### Returns:

    A tuple ([`SendStream`](reference-io#trio.abc.SendStream "trio.abc.SendStream"), [`ReceiveStream`](reference-io#trio.abc.ReceiveStream "trio.abc.ReceiveStream")).

    This stream has *absolutely no* buffering. Each call to [`send_all()`](reference-io#trio.abc.SendStream.send_all "trio.abc.SendStream.send_all") will block until all the given data has been returned by a call to [`receive_some()`](reference-io#trio.abc.ReceiveStream.receive_some "trio.abc.ReceiveStream.receive_some").

    This can be useful for testing flow control mechanisms in an extreme case, or for setting up “clogged” streams to use with [`check_one_way_stream()`](#trio.testing.check_one_way_stream "trio.testing.check_one_way_stream") and friends.

    In addition to fulfilling the [`SendStream`](reference-io#trio.abc.SendStream "trio.abc.SendStream") and [`ReceiveStream`](reference-io#trio.abc.ReceiveStream "trio.abc.ReceiveStream") interfaces, the return objects also have a synchronous `close` method.
- name: trio.testing.lockstep_stream_pair
  id: reference-testing#trio.testing.lockstep_stream_pair
  summary: Create a connected, pure-Python, bidirectional stream where data flows in lockstep
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.testing.lockstep_stream_pair()`

    Create a connected, pure-Python, bidirectional stream where data flows in lockstep.

    #### Returns:

    A tuple ([`StapledStream`](reference-io#trio.StapledStream "trio.StapledStream"), [`StapledStream`](reference-io#trio.StapledStream "trio.StapledStream")).

    This is a convenience function that creates two one-way streams using [`lockstep_stream_one_way_pair()`](#trio.testing.lockstep_stream_one_way_pair "trio.testing.lockstep_stream_one_way_pair"), and then uses [`StapledStream`](reference-io#trio.StapledStream "trio.StapledStream") to combine them into a single bidirectional stream.

    ### Testing custom stream implementations

    Trio also provides some functions to help you test your custom stream implementations:
- name: trio.testing.memory_stream_one_way_pair
  id: reference-testing#trio.testing.memory_stream_one_way_pair
  summary: Create a connected, pure-Python, unidirectional stream with infinite buffering and flexible configuration options
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.testing.memory_stream_one_way_pair()`

    Create a connected, pure-Python, unidirectional stream with infinite buffering and flexible configuration options.

    You can think of this as being a no-operating-system-involved Trio-streamsified version of [`os.pipe()`](https://docs.python.org/3/library/os.html#os.pipe "(in Python v3.11)") (except that [`os.pipe()`](https://docs.python.org/3/library/os.html#os.pipe "(in Python v3.11)") returns the streams in the wrong order – we follow the superior convention that data flows from left to right).

    #### Returns:

    A tuple ([`MemorySendStream`](#trio.testing.MemorySendStream "trio.testing.MemorySendStream"), [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream "trio.testing.MemoryReceiveStream")), where the [`MemorySendStream`](#trio.testing.MemorySendStream "trio.testing.MemorySendStream") has its hooks set up so that it calls [`memory_stream_pump()`](#trio.testing.memory_stream_pump "trio.testing.memory_stream_pump") from its [`send_all_hook`](#trio.testing.MemorySendStream.send_all_hook "trio.testing.MemorySendStream.send_all_hook") and [`close_hook`](#trio.testing.MemorySendStream.close_hook "trio.testing.MemorySendStream.close_hook").

    The end result is that data automatically flows from the [`MemorySendStream`](#trio.testing.MemorySendStream "trio.testing.MemorySendStream") to the [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream "trio.testing.MemoryReceiveStream"). But you’re also free to rearrange things however you like. For example, you can temporarily set the [`send_all_hook`](#trio.testing.MemorySendStream.send_all_hook "trio.testing.MemorySendStream.send_all_hook") to None if you want to simulate a stall in data transmission. Or see [`memory_stream_pair()`](#trio.testing.memory_stream_pair "trio.testing.memory_stream_pair") for a more elaborate example.
- name: trio.testing.memory_stream_pair
  id: reference-testing#trio.testing.memory_stream_pair
  summary: Create a connected, pure-Python, bidirectional stream with infinite buffering and flexible configuration options
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.testing.memory_stream_pair()`

    Create a connected, pure-Python, bidirectional stream with infinite buffering and flexible configuration options.

    This is a convenience function that creates two one-way streams using [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair "trio.testing.memory_stream_one_way_pair"), and then uses [`StapledStream`](reference-io#trio.StapledStream "trio.StapledStream") to combine them into a single bidirectional stream.

    This is like a no-operating-system-involved, Trio-streamsified version of [`socket.socketpair()`](https://docs.python.org/3/library/socket.html#socket.socketpair "(in Python v3.11)").

    #### Returns:

    A pair of [`StapledStream`](reference-io#trio.StapledStream "trio.StapledStream") objects that are connected so that data automatically flows from one to the other in both directions.

    After creating a stream pair, you can send data back and forth, which is enough for simple tests:

    ``` python
    left, right = memory_stream_pair()
    await left.send_all(b"123")
    assert await right.receive_some() == b"123"
    await right.send_all(b"456")
    assert await left.receive_some() == b"456"
    ```

    But if you read the docs for [`StapledStream`](reference-io#trio.StapledStream "trio.StapledStream") and [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair "trio.testing.memory_stream_one_way_pair"), you’ll see that all the pieces involved in wiring this up are public APIs, so you can adjust to suit the requirements of your tests. For example, here’s how to tweak a stream so that data flowing from left to right trickles in one byte at a time (but data flowing from right to left proceeds at full speed):

    ``` python
    left, right = memory_stream_pair()
    async def trickle():
        # left is a StapledStream, and left.send_stream is a MemorySendStream
        # right is a StapledStream, and right.recv_stream is a MemoryReceiveStream
        while memory_stream_pump(left.send_stream, right.recv_stream, max_bytes=1):
            # Pause between each byte
            await trio.sleep(1)
    # Normally this send_all_hook calls memory_stream_pump directly without
    # passing in a max_bytes. We replace it with our custom version:
    left.send_stream.send_all_hook = trickle
    ```

    And here’s a simple test using our modified stream objects:

    ``` python
    async def sender():
        await left.send_all(b"12345")
        await left.send_eof()

    async def receiver():
        async for data in right:
            print(data)

    async with trio.open_nursery() as nursery:
        nursery.start_soon(sender)
        nursery.start_soon(receiver)
    ```

    By default, this will print `b"12345"` and then immediately exit; with our trickle stream it instead sleeps 1 second, then prints `b"1"`, then sleeps 1 second, then prints `b"2"`, etc.

    Pro-tip: you can insert sleep calls (like in our example above) to manipulate the flow of data across tasks… and then use [`MockClock`](#trio.testing.MockClock "trio.testing.MockClock") and its [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold "trio.testing.MockClock.autojump_threshold") functionality to keep your test suite running quickly.

    If you want to stress test a protocol implementation, one nice trick is to use the [`random`](https://docs.python.org/3/library/random.html#module-random "(in Python v3.11)") module (preferably with a fixed seed) to move random numbers of bytes at a time, and insert random sleeps in between them. You can also set up a custom [`receive_some_hook`](#trio.testing.MemoryReceiveStream.receive_some_hook "trio.testing.MemoryReceiveStream.receive_some_hook") if you want to manipulate things on the receiving side, and not just the sending side.
- name: trio.testing.memory_stream_pump
  id: reference-testing#trio.testing.memory_stream_pump
  summary: Take data out of the given MemorySendStream’s internal buffer, and put it into the given MemoryReceiveStream’s internal buffer
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `trio.testing.memory_stream_pump(memory_send_stream, memory_receive_stream, *, max_bytes=None)`

    Take data out of the given [`MemorySendStream`](#trio.testing.MemorySendStream "trio.testing.MemorySendStream")’s internal buffer, and put it into the given [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream "trio.testing.MemoryReceiveStream")’s internal buffer.

    #### Parameters:

    - **memory_send_stream** ([*MemorySendStream*](#trio.testing.MemorySendStream "trio.testing.MemorySendStream")) – The stream to get data from.

    - **memory_receive_stream** ([*MemoryReceiveStream*](#trio.testing.MemoryReceiveStream "trio.testing.MemoryReceiveStream")) – The stream to put data into.

    - **max_bytes** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *None*) – The maximum amount of data to transfer in this call, or None to transfer all available data.

    #### Returns:

    True if it successfully transferred some data, or False if there was no data to transfer.

    This is used to implement [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair "trio.testing.memory_stream_one_way_pair") and [`memory_stream_pair()`](#trio.testing.memory_stream_pair "trio.testing.memory_stream_pair"); see the latter’s docstring for an example of how you might use it yourself.
- name: trio.testing.MemoryReceiveStream
  id: reference-testing#trio.testing.MemoryReceiveStream
  summary: An in-memory ReceiveStream
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`class`*` trio.testing.MemoryReceiveStream(receive_some_hook=None, close_hook=None)`

    An in-memory [`ReceiveStream`](reference-io#trio.abc.ReceiveStream "trio.abc.ReceiveStream").

    #### Parameters:

    - **receive_some_hook** – An async function, or None. Called from [`receive_some()`](#trio.testing.MemoryReceiveStream.receive_some "trio.testing.MemoryReceiveStream.receive_some"). Can do whatever you like.

    - **close_hook** – A synchronous function, or None. Called from [`close()`](#trio.testing.MemoryReceiveStream.close "trio.testing.MemoryReceiveStream.close") and [`aclose()`](#trio.testing.MemoryReceiveStream.aclose "trio.testing.MemoryReceiveStream.aclose"). Can do whatever you like.
- name: trio.testing.MemoryReceiveStream.aclose
  id: reference-testing#trio.testing.MemoryReceiveStream.aclose
  summary: Same as close(), but async
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` aclose()`

    Same as [`close()`](#trio.testing.MemoryReceiveStream.close "trio.testing.MemoryReceiveStream.close"), but async.
- name: trio.testing.MemoryReceiveStream.close
  id: reference-testing#trio.testing.MemoryReceiveStream.close
  summary: Discards any pending data from the internal buffer, and marks this stream as closed
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `close()`

    Discards any pending data from the internal buffer, and marks this stream as closed.
- name: trio.testing.MemoryReceiveStream.close_hook
  id: reference-testing#trio.testing.MemoryReceiveStream.close_hook
  summary: Both hooks are also exposed as attributes on the object, and you can change them at any time
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `close_hook`

    Both hooks are also exposed as attributes on the object, and you can change them at any time.
- name: trio.testing.MemoryReceiveStream.put_data
  id: reference-testing#trio.testing.MemoryReceiveStream.put_data
  summary: Appends the given data to the internal buffer
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `put_data(data)`

    Appends the given data to the internal buffer.
- name: trio.testing.MemoryReceiveStream.put_eof
  id: reference-testing#trio.testing.MemoryReceiveStream.put_eof
  summary: Adds an end-of-file marker to the internal buffer
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `put_eof()`

    Adds an end-of-file marker to the internal buffer.
- name: trio.testing.MemoryReceiveStream.receive_some
  id: reference-testing#trio.testing.MemoryReceiveStream.receive_some
  summary: Calls the receive_some_hook (if any), and then retrieves data from the internal buffer, blocking if necessary
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` receive_some(max_bytes=None)`

    Calls the [`receive_some_hook`](#trio.testing.MemoryReceiveStream.receive_some_hook "trio.testing.MemoryReceiveStream.receive_some_hook") (if any), and then retrieves data from the internal buffer, blocking if necessary.
- name: trio.testing.MemoryReceiveStream.receive_some_hook
  id: reference-testing#trio.testing.MemoryReceiveStream.receive_some_hook
  summary: null
  belongs_to: Testing made easier with trio.testing
  description: '### `receive_some_hook`'
- name: trio.testing.MemorySendStream
  id: reference-testing#trio.testing.MemorySendStream
  summary: An in-memory SendStream
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`class`*` trio.testing.MemorySendStream(send_all_hook=None, wait_send_all_might_not_block_hook=None, close_hook=None)`

    An in-memory [`SendStream`](reference-io#trio.abc.SendStream "trio.abc.SendStream").

    #### Parameters:

    - **send_all_hook** – An async function, or None. Called from [`send_all()`](#trio.testing.MemorySendStream.send_all "trio.testing.MemorySendStream.send_all"). Can do whatever you like.

    - **wait_send_all_might_not_block_hook** – An async function, or None. Called from [`wait_send_all_might_not_block()`](#trio.testing.MemorySendStream.wait_send_all_might_not_block "trio.testing.MemorySendStream.wait_send_all_might_not_block"). Can do whatever you like.

    - **close_hook** – A synchronous function, or None. Called from [`close()`](#trio.testing.MemorySendStream.close "trio.testing.MemorySendStream.close") and [`aclose()`](#trio.testing.MemorySendStream.aclose "trio.testing.MemorySendStream.aclose"). Can do whatever you like.
- name: trio.testing.MemorySendStream.aclose
  id: reference-testing#trio.testing.MemorySendStream.aclose
  summary: Same as close(), but async
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` aclose()`

    Same as [`close()`](#trio.testing.MemorySendStream.close "trio.testing.MemorySendStream.close"), but async.
- name: trio.testing.MemorySendStream.close
  id: reference-testing#trio.testing.MemorySendStream.close
  summary: Marks this stream as closed, and then calls the close_hook (if any)
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `close()`

    Marks this stream as closed, and then calls the [`close_hook`](#trio.testing.MemorySendStream.close_hook "trio.testing.MemorySendStream.close_hook") (if any).
- name: trio.testing.MemorySendStream.close_hook
  id: reference-testing#trio.testing.MemorySendStream.close_hook
  summary: All of these hooks are also exposed as attributes on the object, and you can change them at any time
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `close_hook`

    All of these hooks are also exposed as attributes on the object, and you can change them at any time.
- name: trio.testing.MemorySendStream.get_data
  id: reference-testing#trio.testing.MemorySendStream.get_data
  summary: Retrieves data from the internal buffer, blocking if necessary
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` get_data(max_bytes=None)`

    Retrieves data from the internal buffer, blocking if necessary.

    #### Parameters:

    **max_bytes** ([*int*](https://docs.python.org/3/library/functions.html#int "(in Python v3.11)") *or* *None*) – The maximum amount of data to retrieve. None (the default) means to retrieve all the data that’s present (but still blocks until at least one byte is available).

    #### Returns:

    If this stream has been closed, an empty bytearray. Otherwise, the requested data.
- name: trio.testing.MemorySendStream.get_data_nowait
  id: reference-testing#trio.testing.MemorySendStream.get_data_nowait
  summary: Retrieves data from the internal buffer, but doesn’t block
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `get_data_nowait(max_bytes=None)`

    Retrieves data from the internal buffer, but doesn’t block.

    See [`get_data()`](#trio.testing.MemorySendStream.get_data "trio.testing.MemorySendStream.get_data") for details.

    #### Raises:

    [**trio.WouldBlock**](reference-core#trio.WouldBlock "trio.WouldBlock") – if no data is available to retrieve.
- name: trio.testing.MemorySendStream.send_all
  id: reference-testing#trio.testing.MemorySendStream.send_all
  summary: Places the given data into the object’s internal buffer, and then calls the send_all_hook (if any)
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` send_all(data)`

    Places the given data into the object’s internal buffer, and then calls the [`send_all_hook`](#trio.testing.MemorySendStream.send_all_hook "trio.testing.MemorySendStream.send_all_hook") (if any).
- name: trio.testing.MemorySendStream.send_all_hook
  id: reference-testing#trio.testing.MemorySendStream.send_all_hook
  summary: null
  belongs_to: Testing made easier with trio.testing
  description: '### `send_all_hook`'
- name: trio.testing.MemorySendStream.wait_send_all_might_not_block
  id: reference-testing#trio.testing.MemorySendStream.wait_send_all_might_not_block
  summary: Calls the wait_send_all_might_not_block_hook (if any), and then returns immediately
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` wait_send_all_might_not_block()`

    Calls the [`wait_send_all_might_not_block_hook`](#trio.testing.MemorySendStream.wait_send_all_might_not_block_hook "trio.testing.MemorySendStream.wait_send_all_might_not_block_hook") (if any), and then returns immediately.
- name: trio.testing.MemorySendStream.wait_send_all_might_not_block_hook
  id: reference-testing#trio.testing.MemorySendStream.wait_send_all_might_not_block_hook
  summary: null
  belongs_to: Testing made easier with trio.testing
  description: '### `wait_send_all_might_not_block_hook`'
- name: trio.testing.MockClock
  id: reference-testing#trio.testing.MockClock
  summary: A user-controllable clock suitable for writing tests
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`class`*` trio.testing.MockClock(rate=0.0, autojump_threshold=inf)`

    A user-controllable clock suitable for writing tests.

    #### Parameters:

    - **rate** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – the initial [`rate`](#trio.testing.MockClock.rate "trio.testing.MockClock.rate").

    - **autojump_threshold** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – the initial [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold "trio.testing.MockClock.autojump_threshold").
- name: trio.testing.MockClock.autojump_threshold
  id: reference-testing#trio.testing.MockClock.autojump_threshold
  summary: The clock keeps an eye on the run loop, and if at any point it detects that all tasks have been blocked for this many real seconds (i.e., according to the actual clock, not this clock), then the clock automatically jumps ahead to the run loop’s next scheduled timeout
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `autojump_threshold`

    The clock keeps an eye on the run loop, and if at any point it detects that all tasks have been blocked for this many real seconds (i.e., according to the actual clock, not this clock), then the clock automatically jumps ahead to the run loop’s next scheduled timeout. Default is [`math.inf`](https://docs.python.org/3/library/math.html#math.inf "(in Python v3.11)"), i.e., to never autojump. You can assign to this attribute to change it.

    Basically the idea is that if you have code or tests that use sleeps and timeouts, you can use this to make it run much faster, totally automatically. (At least, as long as those sleeps/timeouts are happening inside Trio; if your test involves talking to external service and waiting for it to timeout then obviously we can’t help you there.)

    You should set this to the smallest value that lets you reliably avoid “false alarms” where some I/O is in flight (e.g. between two halves of a socketpair) but the threshold gets triggered and time gets advanced anyway. This will depend on the details of your tests and test environment. If you aren’t doing any I/O (like in our sleeping example above) then just set it to zero, and the clock will jump whenever all tasks are blocked.

    > #### Note
    >
    > If you use `autojump_threshold` and [`wait_all_tasks_blocked`](#trio.testing.wait_all_tasks_blocked "trio.testing.wait_all_tasks_blocked") at the same time, then you might wonder how they interact, since they both cause things to happen after the run loop goes idle for some time. The answer is: [`wait_all_tasks_blocked`](#trio.testing.wait_all_tasks_blocked "trio.testing.wait_all_tasks_blocked") takes priority. If there’s a task blocked in [`wait_all_tasks_blocked`](#trio.testing.wait_all_tasks_blocked "trio.testing.wait_all_tasks_blocked"), then the autojump feature treats that as active task and does *not* jump the clock.
- name: trio.testing.MockClock.jump
  id: reference-testing#trio.testing.MockClock.jump
  summary: Manually advance the clock by the given number of seconds
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `jump(seconds)`

    Manually advance the clock by the given number of seconds.

    #### Parameters:

    **seconds** ([*float*](https://docs.python.org/3/library/functions.html#float "(in Python v3.11)")) – the number of seconds to jump the clock forward.

    #### Raises:

    [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError "(in Python v3.11)") – if you try to pass a negative value for `seconds`.

    ## Inter-task ordering
- name: trio.testing.MockClock.rate
  id: reference-testing#trio.testing.MockClock.rate
  summary: How many seconds of clock time pass per second of real time
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `rate`

    How many seconds of clock time pass per second of real time. Default is 0.0, i.e. the clock only advances through manuals calls to [`jump()`](#trio.testing.MockClock.jump "trio.testing.MockClock.jump") or when the [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold "trio.testing.MockClock.autojump_threshold") is triggered. You can assign to this attribute to change it.
- name: trio.testing.open_stream_to_socket_listener
  id: reference-testing#trio.testing.open_stream_to_socket_listener
  summary: Connect to the given SocketListener
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` trio.testing.open_stream_to_socket_listener(socket_listener)`

    Connect to the given [`SocketListener`](reference-io#trio.SocketListener "trio.SocketListener").

    This is particularly useful in tests when you want to let a server pick its own port, and then connect to it:

    ``` python
    listeners = await trio.open_tcp_listeners(0)
    client = await trio.testing.open_stream_to_socket_listener(listeners[0])
    ```

    #### Parameters:

    **socket_listener** ([*SocketListener*](reference-io#trio.SocketListener "trio.SocketListener")) – The [`SocketListener`](reference-io#trio.SocketListener "trio.SocketListener") to connect to.

    #### Returns:

    a stream connected to the given listener.

    #### Return type:

    [SocketStream](reference-io#trio.SocketStream "trio.SocketStream")

    ### Virtual, controllable streams

    One particularly challenging problem when testing network protocols is making sure that your implementation can handle data whose flow gets broken up in weird ways and arrives with weird timings: localhost connections tend to be much better behaved than real networks, so if you only test on localhost then you might get bitten later. To help you out, Trio provides some fully in-memory implementations of the stream interfaces (see [The abstract Stream API](reference-io#abstract-stream-api)), that let you write all kinds of interestingly evil tests.

    There are a few pieces here, so here’s how they fit together:

    [`memory_stream_pair()`](#trio.testing.memory_stream_pair "trio.testing.memory_stream_pair") gives you a pair of connected, bidirectional streams. It’s like [`socket.socketpair()`](https://docs.python.org/3/library/socket.html#socket.socketpair "(in Python v3.11)"), but without any involvement from that pesky operating system and its networking stack.

    To build a bidirectional stream, [`memory_stream_pair()`](#trio.testing.memory_stream_pair "trio.testing.memory_stream_pair") uses two unidirectional streams. It gets these by calling [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair "trio.testing.memory_stream_one_way_pair").

    [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair "trio.testing.memory_stream_one_way_pair"), in turn, is implemented using the low-ish level classes [`MemorySendStream`](#trio.testing.MemorySendStream "trio.testing.MemorySendStream") and [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream "trio.testing.MemoryReceiveStream"). These are implementations of (you guessed it) [`trio.abc.SendStream`](reference-io#trio.abc.SendStream "trio.abc.SendStream") and [`trio.abc.ReceiveStream`](reference-io#trio.abc.ReceiveStream "trio.abc.ReceiveStream") that on their own, aren’t attached to anything – “sending” and “receiving” just put data into and get data out of a private internal buffer that each object owns. They also have some interesting hooks you can set, that let you customize the behavior of their methods. This is where you can insert the evil, if you want it. [`memory_stream_one_way_pair()`](#trio.testing.memory_stream_one_way_pair "trio.testing.memory_stream_one_way_pair") takes advantage of these hooks in a relatively boring way: it just sets it up so that when you call `send_all`, or when you close the send stream, then it automatically triggers a call to [`memory_stream_pump()`](#trio.testing.memory_stream_pump "trio.testing.memory_stream_pump"), which is a convenience function that takes data out of a [`MemorySendStream`](#trio.testing.MemorySendStream "trio.testing.MemorySendStream")´s buffer and puts it into a [`MemoryReceiveStream`](#trio.testing.MemoryReceiveStream "trio.testing.MemoryReceiveStream")´s buffer. But that’s just the default – you can replace this with whatever arbitrary behavior you want.

    Trio also provides some specialized functions for testing completely **un**buffered streams: [`lockstep_stream_one_way_pair()`](#trio.testing.lockstep_stream_one_way_pair "trio.testing.lockstep_stream_one_way_pair") and [`lockstep_stream_pair()`](#trio.testing.lockstep_stream_pair "trio.testing.lockstep_stream_pair"). These aren’t customizable, but they do exhibit an extreme kind of behavior that’s good at catching out edge cases in protocol implementations.

    ### API details
- name: trio.testing.Sequencer
  id: reference-testing#trio.testing.Sequencer
  summary: A convenience class for forcing code in different tasks to run in an explicit linear order
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`class`*` trio.testing.Sequencer`

    A convenience class for forcing code in different tasks to run in an explicit linear order.

    Instances of this class implement a `__call__` method which returns an async context manager. The idea is that you pass a sequence number to `__call__` to say where this block of code should go in the linear sequence. Block 0 starts immediately, and then block N doesn’t start until block N-1 has finished.

    Example

    An extremely elaborate way to print the numbers 0-5, in order:

    ``` python
    async def worker1(seq):
        async with seq(0):
            print(0)
        async with seq(4):
            print(4)

    async def worker2(seq):
        async with seq(2):
            print(2)
        async with seq(5):
            print(5)

    async def worker3(seq):
        async with seq(1):
            print(1)
        async with seq(3):
            print(3)

    async def main():
       seq = trio.testing.Sequencer()
       async with trio.open_nursery() as nursery:
           nursery.start_soon(worker1, seq)
           nursery.start_soon(worker2, seq)
           nursery.start_soon(worker3, seq)
    ```
- name: trio.testing.trio_test
  id: reference-testing#trio.testing.trio_test
  summary: By default, it starts at time 0, and clock time only advances when you explicitly call jump()
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### `@trio.testing.trio_test`

    ## Time and timeouts

    [`trio.testing.MockClock`](#trio.testing.MockClock "trio.testing.MockClock") is a [`Clock`](reference-core#trio.abc.Clock "trio.abc.Clock") with a few tricks up its sleeve to help you efficiently test code involving timeouts:

    - By default, it starts at time 0, and clock time only advances when you explicitly call [`jump()`](#trio.testing.MockClock.jump "trio.testing.MockClock.jump"). This provides an extremely controllable clock for testing.

    - You can set [`rate`](#trio.testing.MockClock.rate "trio.testing.MockClock.rate") to 1.0 if you want it to start running in real time like a regular clock. You can stop and start the clock within a test. You can set [`rate`](#trio.testing.MockClock.rate "trio.testing.MockClock.rate") to 10.0 to make clock time pass at 10x real speed (so e.g. `await``trio.sleep(10)` returns after 1 second).

    - But even more interestingly, you can set [`autojump_threshold`](#trio.testing.MockClock.autojump_threshold "trio.testing.MockClock.autojump_threshold") to zero or a small value, and then it will watch the execution of the run loop, and any time things have settled down and everyone’s waiting for a timeout, it jumps the clock forward to that timeout. In many cases this allows natural-looking code involving timeouts to be automatically run at near full CPU utilization with no changes. (Thanks to [fluxcapacitor](https://github.com/majek/fluxcapacitor) for this awesome idea.)

    - And of course these can be mixed and matched at will.

    Regardless of these shenanigans, from “inside” Trio the passage of time still seems normal so long as you restrict yourself to Trio’s time functions (see [Time and clocks](reference-core#time-and-clocks)). Below is an example demonstrating two different ways of making time pass quickly. Notice how in both cases, the two tasks keep a consistent view of reality and events happen in the expected order, despite being wildly divorced from real time:

    ``` python
    # across-realtime.py

    import time
    import trio
    import trio.testing

    YEAR = 365 * 24 * 60 * 60  # seconds


    async def task1():
        start = trio.current_time()

        print("task1: sleeping for 1 year")
        await trio.sleep(YEAR)

        duration = trio.current_time() - start
        print(f"task1: woke up; clock says I've slept {duration / YEAR} years")

        print("task1: sleeping for 1 year, 100 times")
        for _ in range(100):
            await trio.sleep(YEAR)

        duration = trio.current_time() - start
        print(f"task1: slept {duration / YEAR} years total")


    async def task2():
        start = trio.current_time()

        print("task2: sleeping for 5 years")
        await trio.sleep(5 * YEAR)

        duration = trio.current_time() - start
        print(f"task2: woke up; clock says I've slept {duration / YEAR} years")

        print("task2: sleeping for 500 years")
        await trio.sleep(500 * YEAR)

        duration = trio.current_time() - start
        print(f"task2: slept {duration / YEAR} years total")


    async def main():
        async with trio.open_nursery() as nursery:
            nursery.start_soon(task1)
            nursery.start_soon(task2)


    def run_example(clock):
        real_start = time.perf_counter()
        trio.run(main, clock=clock)
        real_duration = time.perf_counter() - real_start
        print(f"Total real time elapsed: {real_duration} seconds")


    print("Clock where time passes at 100 years per second:\n")
    run_example(trio.testing.MockClock(rate=100 * YEAR))

    print("\nClock where time automatically skips past the boring parts:\n")
    run_example(trio.testing.MockClock(autojump_threshold=0))
    ```

    Output:

        Clock where time passes at 100 years per second:

        task2: sleeping for 5 years
        task1: sleeping for 1 year
        task1: woke up; clock says I've slept 1.0365006048232317 years
        task1: sleeping for 1 year, 100 times
        task2: woke up; clock says I've slept 5.0572111969813704 years
        task2: sleeping for 500 years
        task1: slept 104.77677842136472 years total
        task2: slept 505.25014589075 years total
        Total real time elapsed: 5.053582429885864 seconds

        Clock where time automatically skips past the boring parts:

        task2: sleeping for 5 years
        task1: sleeping for 1 year
        task1: woke up; clock says I've slept 1.0 years
        task1: sleeping for 1 year, 100 times
        task2: woke up; clock says I've slept 5.0 years
        task2: sleeping for 500 years
        task1: slept 101.0 years total
        task2: slept 505.0 years total
        Total real time elapsed: 0.019298791885375977 seconds
- name: trio.testing.wait_all_tasks_blocked
  id: reference-testing#trio.testing.wait_all_tasks_blocked
  summary: Block until there are no runnable tasks
  belongs_to: Testing made easier with trio.testing
  description: |-
    ### *`await`*` trio.testing.wait_all_tasks_blocked(cushion=0.0)`

    Block until there are no runnable tasks.

    This is useful in testing code when you want to give other tasks a chance to “settle down”. The calling task is blocked, and doesn’t wake up until all other tasks are also blocked for at least `cushion` seconds. (Setting a non-zero `cushion` is intended to handle cases like two tasks talking to each other over a local socket, where we want to ignore the potential brief moment between a send and receive when all tasks are blocked.)

    Note that `cushion` is measured in *real* time, not the Trio clock time.

    If there are multiple tasks blocked in [`wait_all_tasks_blocked()`](#trio.testing.wait_all_tasks_blocked "trio.testing.wait_all_tasks_blocked"), then the one with the shortest `cushion` is the one woken (and this task becoming unblocked resets the timers for the remaining tasks). If there are multiple tasks that have exactly the same `cushion`, then all are woken.

    You should also consider [`trio.testing.Sequencer`](#trio.testing.Sequencer "trio.testing.Sequencer"), which provides a more explicit way to control execution ordering within a test, and will often produce more readable tests.

    Example

    Here’s an example of one way to test that Trio’s locks are fair: we take the lock in the parent, start a child, wait for the child to be blocked waiting for the lock (!), and then check that we can’t release and immediately re-acquire the lock:

    ``` python
    async def lock_taker(lock):
        await lock.acquire()
        lock.release()

    async def test_lock_fairness():
        lock = trio.Lock()
        await lock.acquire()
        async with trio.open_nursery() as nursery:
            nursery.start_soon(lock_taker, lock)
            # child hasn't run yet, we have the lock
            assert lock.locked()
            assert lock._owner is trio.lowlevel.current_task()
            await trio.testing.wait_all_tasks_blocked()
            # now the child has run and is blocked on lock.acquire(), we
            # still have the lock
            assert lock.locked()
            assert lock._owner is trio.lowlevel.current_task()
            lock.release()
            try:
                # The child has a prior claim, so we can't have it
                lock.acquire_nowait()
            except trio.WouldBlock:
                assert lock._owner is not trio.lowlevel.current_task()
                print("PASS")
            else:
                print("FAIL")
    ```

    ## Streams

    ### Connecting to an in-process socket server
- name: trio.to_thread.current_default_thread_limiter
  id: reference-core#trio.to_thread.current_default_thread_limiter
  summary: Get the default CapacityLimiter used by trio.to_thread.run_sync
  belongs_to: Trio’s core functionality
  description: |-
    ### `trio.to_thread.current_default_thread_limiter()`

    Get the default [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter") used by [`trio.to_thread.run_sync`](#trio.to_thread.run_sync "trio.to_thread.run_sync").

    The most common reason to call this would be if you want to modify its [`total_tokens`](#trio.CapacityLimiter.total_tokens "trio.CapacityLimiter.total_tokens") attribute.

    ### Getting back into the Trio thread from another thread
- name: trio.to_thread.run_sync
  id: reference-core#trio.to_thread.run_sync
  summary: Convert a blocking operation into an async operation using a thread
  belongs_to: Trio’s core functionality
  description: |-
    ### *`await`*` trio.to_thread.run_sync(sync_fn, *args, thread_name: str | None = None, cancellable=False, limiter=None)`

    Convert a blocking operation into an async operation using a thread.

    These two lines are equivalent:

    ``` python
    sync_fn(*args)
    await trio.to_thread.run_sync(sync_fn, *args)
    ```

    except that if `sync_fn` takes a long time, then the first line will block the Trio loop while it runs, while the second line allows other Trio tasks to continue working while `sync_fn` runs. This is accomplished by pushing the call to `sync_fn(*args)` off into a worker thread.

    From inside the worker thread, you can get back into Trio using the functions in [`trio.from_thread`](#module-trio.from_thread "trio.from_thread").

    #### Parameters:

    - **sync_fn** – An arbitrary synchronous callable.

    - **\*args** – Positional arguments to pass to sync_fn. If you need keyword arguments, use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial "(in Python v3.11)").

    - **cancellable** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.11)")) – Whether to allow cancellation of this operation. See discussion below.

    - **thread_name** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.11)")) – Optional string to set the name of the thread. Will always set [`threading.Thread.name`](https://docs.python.org/3/library/threading.html#threading.Thread.name "(in Python v3.11)"), but only set the os name if pthread.h is available (i.e. most POSIX installations). pthread names are limited to 15 characters, and can be read from `/proc/<PID>/task/<SPID>/comm` or with `ps``-eT`, among others. Defaults to `{sync_fn.__name__|None}``from``{trio.lowlevel.current_task().name}`.

    - **limiter** (*None, or* *CapacityLimiter-like object*) –

      An object used to limit the number of simultaneous threads. Most commonly this will be a [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter"), but it could be anything providing compatible [`acquire_on_behalf_of()`](#trio.CapacityLimiter.acquire_on_behalf_of "trio.CapacityLimiter.acquire_on_behalf_of") and [`release_on_behalf_of()`](#trio.CapacityLimiter.release_on_behalf_of "trio.CapacityLimiter.release_on_behalf_of") methods. This function will call `acquire_on_behalf_of` before starting the thread, and `release_on_behalf_of` after the thread has finished.

      If None (the default), uses the default [`CapacityLimiter`](#trio.CapacityLimiter "trio.CapacityLimiter"), as returned by [`current_default_thread_limiter()`](#trio.to_thread.current_default_thread_limiter "trio.to_thread.current_default_thread_limiter").

    **Cancellation handling**: Cancellation is a tricky issue here, because neither Python nor the operating systems it runs on provide any general mechanism for cancelling an arbitrary synchronous function running in a thread. This function will always check for cancellation on entry, before starting the thread. But once the thread is running, there are two ways it can handle being cancelled:

    - If `cancellable=False`, the function ignores the cancellation and keeps going, just like if we had called `sync_fn` synchronously. This is the default behavior.

    - If `cancellable=True`, then this function immediately raises [`Cancelled`](#trio.Cancelled "trio.Cancelled"). In this case **the thread keeps running in background** – we just abandon it to do whatever it’s going to do, and silently discard any return value or errors that it raises. Only use this if you know that the operation is safe and side-effect free. (For example: [`trio.socket.getaddrinfo()`](reference-io#trio.socket.getaddrinfo "trio.socket.getaddrinfo") uses a thread with `cancellable=True`, because it doesn’t really affect anything if a stray hostname lookup keeps running in the background.)

      The `limiter` is only released after the thread has *actually* finished – which in the case of cancellation may be some time after this function has returned. If [`trio.run()`](#trio.run "trio.run") finishes before the thread does, then the limiter release method will never be called at all.

    > #### Warning
    >
    > You should not use this function to call long-running CPU-bound functions! In addition to the usual GIL-related reasons why using threads for CPU-bound work is not very effective in Python, there is an additional problem: on CPython, [CPU-bound threads tend to “starve out” IO-bound threads](https://bugs.python.org/issue7946), so using threads for CPU-bound work is likely to adversely affect the main thread running Trio. If you need to do this, you’re better off using a worker process, or perhaps PyPy (which still has a GIL, but may do a better job of fairly allocating CPU time between threads).

    #### Returns:

    Whatever `sync_fn(*args)` returns.

    #### Raises:

    [**Exception**](https://docs.python.org/3/library/exceptions.html#Exception "(in Python v3.11)") – Whatever `sync_fn(*args)` raises.
- name: trio.TooSlowError
  id: reference-core#trio.TooSlowError
  summary: Raised by fail_after() and fail_at() if the timeout expires
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.TooSlowError`

    Raised by [`fail_after()`](#trio.fail_after "trio.fail_after") and [`fail_at()`](#trio.fail_at "trio.fail_at") if the timeout expires.
- name: trio.TrioDeprecationWarning
  id: reference-core#trio.TrioDeprecationWarning
  summary: Warning emitted if you use deprecated Trio functionality
  belongs_to: Trio’s core functionality
  description: "### *`exception`*` trio.TrioDeprecationWarning`\n\nBases: [`FutureWarning`](https://docs.python.org/3/library/exceptions.html#FutureWarning \"(in Python v3.11)\")\n\nWarning emitted if you use deprecated Trio functionality.\n\nAs a young project, Trio is currently quite aggressive about deprecating and/or removing functionality that we realize was a bad idea. If you use Trio, you should subscribe to [issue \\#1](https://github.com/python-trio/trio/issues/1) to get information about upcoming deprecations and other backwards compatibility breaking changes.\n\nDespite the name, this class currently inherits from [`FutureWarning`](https://docs.python.org/3/library/exceptions.html#FutureWarning \"(in Python v3.11)\"), not [`DeprecationWarning`](https://docs.python.org/3/library/exceptions.html#DeprecationWarning \"(in Python v3.11)\"), because while we’re in young-and-aggressive mode we want these warnings to be visible by default. You can hide them by installing a filter or with the `-W` switch: see the [`warnings`](https://docs.python.org/3/library/warnings.html#module-warnings \"(in Python v3.11)\") documentation for details.\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-core.html](https://trio.readthedocs.io/en/v0.22.2/reference-core.html)"
- name: trio.TrioInternalError
  id: reference-core#trio.TrioInternalError
  summary: Raised by run() if we encounter a bug in Trio, or (possibly) a misuse of one of the low-level trio.lowlevel APIs
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.TrioInternalError`

    Raised by [`run()`](#trio.run "trio.run") if we encounter a bug in Trio, or (possibly) a misuse of one of the low-level [`trio.lowlevel`](reference-lowlevel#module-trio.lowlevel "trio.lowlevel") APIs.

    This should never happen! If you get this error, please file a bug.

    Unfortunately, if you get this error it also means that all bets are off – Trio doesn’t know what is going on and its normal invariants may be void. (For example, we might have “lost track” of a task. Or lost track of all tasks.) Again, though, this shouldn’t happen.
- name: trio.WouldBlock
  id: reference-core#trio.WouldBlock
  summary: Raised by X_nowait functions if X would block
  belongs_to: Trio’s core functionality
  description: |-
    ### *`exception`*` trio.WouldBlock`

    Raised by `X_nowait` functions if `X` would block.
- name: trio.wrap_file
  id: reference-io#trio.wrap_file
  summary: This wraps any file object in a wrapper that provides an asynchronous file object interface
  belongs_to: I/O in Trio
  description: |-
    ### `trio.wrap_file(file)`

    This wraps any file object in a wrapper that provides an asynchronous file object interface.

    #### Parameters:

    **file** – a [file object](https://docs.python.org/3/glossary.html#term-file-object "(in Python v3.11)")

    #### Returns:

    An [asynchronous file object](https://trio.readthedocs.io/en/v0.22.2/glossary.html#term-asynchronous-file-object) that wraps `file`

    Example:

    ``` python
    async_file = trio.wrap_file(StringIO('asdf'))

    assert await async_file.read() == 'asdf'
    ```
- name: Trio’s core functionality
  id: reference-core
  summary: Run a Trio-flavored async function, and return the result
  description: "# Trio’s core functionality\n\n## Entering Trio\n\nIf you want to use Trio, then the first thing you have to do is call [`trio.run()`](#trio.run \"trio.run\"):\n\n### `trio.run(async_fn, *args, clock=None, instruments=(), restrict_keyboard_interrupt_to_checkpoints: bool = False, strict_exception_groups: bool = False)`\n\nRun a Trio-flavored async function, and return the result.\n\nCalling:\n\n``` python\nrun(async_fn, *args)\n```\n\nis the equivalent of:\n\n``` python\nawait async_fn(*args)\n```\n\nexcept that [`run()`](#trio.run \"trio.run\") can (and must) be called from a synchronous context.\n\nThis is Trio’s main entry point. Almost every other function in Trio requires that you be inside a call to [`run()`](#trio.run \"trio.run\").\n\n#### Parameters:\n\n- **async_fn** – An async function.\n\n- **args** – Positional arguments to be passed to *async_fn*. If you need to pass keyword arguments, then use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial \"(in Python v3.11)\").\n\n- **clock** – `None` to use the default system-specific monotonic clock; otherwise, an object implementing the [`trio.abc.Clock`](#trio.abc.Clock \"trio.abc.Clock\") interface, like (for example) a [`trio.testing.MockClock`](reference-testing#trio.testing.MockClock \"trio.testing.MockClock\") instance.\n\n- **instruments** (list of [`trio.abc.Instrument`](reference-lowlevel#trio.abc.Instrument \"trio.abc.Instrument\") objects) – Any instrumentation you want to apply to this run. This can also be modified during the run; see [Instrument API](reference-lowlevel#instrumentation).\n\n- **restrict_keyboard_interrupt_to_checkpoints** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) –\n\n  What happens if the user hits control-C while [`run()`](#trio.run \"trio.run\") is running? If this argument is False (the default), then you get the standard Python behavior: a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") exception will immediately interrupt whatever task is running (or if no task is running, then Trio will wake up a task to be interrupted). Alternatively, if you set this argument to True, then [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") delivery will be delayed: it will be *only* be raised at [checkpoints](#checkpoints), like a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception.\n\n  The default behavior is nice because it means that even if you accidentally write an infinite loop that never executes any checkpoints, then you can still break out of it using control-C. The alternative behavior is nice if you’re paranoid about a [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") at just the wrong place leaving your program in an inconsistent state, because it means that you only have to worry about [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") at the exact same places where you already have to worry about [`Cancelled`](#trio.Cancelled \"trio.Cancelled\").\n\n  This setting has no effect if your program has registered a custom SIGINT handler, or if [`run()`](#trio.run \"trio.run\") is called from anywhere but the main thread (this is a Python limitation), or if you use [`open_signal_receiver()`](reference-io#trio.open_signal_receiver \"trio.open_signal_receiver\") to catch SIGINT.\n\n- **strict_exception_groups** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – If true, nurseries will always wrap even a single raised exception in an exception group. This can be overridden on the level of individual nurseries. This will eventually become the default behavior.\n\n#### Returns:\n\nWhatever `async_fn` returns.\n\n#### Raises:\n\n- [**TrioInternalError**](#trio.TrioInternalError \"trio.TrioInternalError\") – if an unexpected error is encountered inside Trio’s internal machinery. This is a bug and you should [let us know](https://github.com/python-trio/trio/issues).\n\n- **Anything else** – if `async_fn` raises an exception, then [`run()`](#trio.run \"trio.run\") propagates it.\n\n## General principles\n\n### Checkpoints\n\nWhen writing code using Trio, it’s very important to understand the concept of a *checkpoint*. Many of Trio’s functions act as checkpoints.\n\nA checkpoint is two things:\n\n1.  It’s a point where Trio checks for cancellation. For example, if the code that called your function set a timeout, and that timeout has expired, then the next time your function executes a checkpoint Trio will raise a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception. See [Cancellation and timeouts](#cancellation) below for more details.\n\n2.  It’s a point where the Trio scheduler checks its scheduling policy to see if it’s a good time to switch to another task, and potentially does so. (Currently, this check is very simple: the scheduler always switches at every checkpoint. But [this might change in the future](https://github.com/python-trio/trio/issues/32).)\n\nWhen writing Trio code, you need to keep track of where your checkpoints are. Why? First, because checkpoints require extra scrutiny: whenever you execute a checkpoint, you need to be prepared to handle a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") error, or for another task to run and [rearrange some state out from under you](https://glyph.twistedmatrix.com/2014/02/unyielding.html). And second, because you also need to make sure that you have *enough* checkpoints: if your code doesn’t pass through a checkpoint on a regular basis, then it will be slow to notice and respond to cancellation and – much worse – since Trio is a cooperative multi-tasking system where the *only* place the scheduler can switch tasks is at checkpoints, it’ll also prevent the scheduler from fairly allocating time between different tasks and adversely effect the response latency of all the other code running in the same process. (Informally we say that a task that does this is “hogging the run loop”.)\n\nSo when you’re doing code review on a project that uses Trio, one of the things you’ll want to think about is whether there are enough checkpoints, and whether each one is handled correctly. Of course this means you need a way to recognize checkpoints. How do you do that? The underlying principle is that any operation that blocks has to be a checkpoint. This makes sense: if an operation blocks, then it might block for a long time, and you’ll want to be able to cancel it if a timeout expires; and in any case, while this task is blocked we want another task to be scheduled to run so our code can make full use of the CPU.\n\nBut if we want to write correct code in practice, then this principle is a little too sloppy and imprecise to be useful. How do we know which functions might block? What if a function blocks sometimes, but not others, depending on the arguments passed / network speed / phase of the moon? How do we figure out where the checkpoints are when we’re stressed and sleep deprived but still want to get this code review right, and would prefer to reserve our mental energy for thinking about the actual logic instead of worrying about checkpoints?\n\nDon’t worry – Trio’s got your back. Since checkpoints are important and ubiquitous, we make it as simple as possible to keep track of them. Here are the rules:\n\n- Regular (synchronous) functions never contain any checkpoints.\n\n- If you call an async function provided by Trio (`await`` ``<something`` ``in`` ``trio>`), and it doesn’t raise an exception, then it *always* acts as a checkpoint. (If it does raise an exception, it might act as a checkpoint or might not.)\n\n  - This includes async iterators: If you write `async`` ``for`` ``...`` ``in`` ``<a`` ``trio`` ``object>`, then there will be at least one checkpoint in each iteration of the loop, and it will still checkpoint if the iterable is empty.\n\n  - Partial exception for async context managers: Both the entry and exit of an `async`` ``with` block are defined as async functions; but for a particular type of async context manager, it’s often the case that only one of them is able to block, which means only that one will act as a checkpoint. This is documented on a case-by-case basis.\n\n- Third-party async functions / iterators / context managers can act as checkpoints; if you see `await`` ``<something>` or one of its friends, then that *might* be a checkpoint. So to be safe, you should prepare for scheduling or cancellation happening there.\n\nThe reason we distinguish between Trio functions and other functions is that we can’t make any guarantees about third party code. Checkpoint-ness is a transitive property: if function A acts as a checkpoint, and you write a function that calls function A, then your function also acts as a checkpoint. If you don’t, then it isn’t. So there’s nothing stopping someone from writing a function like:\n\n``` python\n# technically legal, but bad style:\nasync def why_is_this_async():\n    return 7\n```\n\nthat never calls any of Trio’s async functions. This is an async function, but it’s not a checkpoint. But why make a function async if it never calls any async functions? It’s possible, but it’s a bad idea. If you have a function that’s not calling any async functions, then you should make it synchronous. The people who use your function will thank you, because it makes it obvious that your function is not a checkpoint, and their code reviews will go faster.\n\n(Remember how in the tutorial we emphasized the importance of the [“async sandwich”](https://trio.readthedocs.io/en/v0.22.2/tutorial.html#async-sandwich), and the way it means that `await` ends up being a marker that shows when you’re calling a function that calls a function that … eventually calls one of Trio’s built-in async functions? The transitivity of async-ness is a technical requirement that Python imposes, but since it exactly matches the transitivity of checkpoint-ness, we’re able to exploit it to help you keep track of checkpoints. Pretty sneaky, eh?)\n\nA slightly trickier case is a function like:\n\n``` python\nasync def sleep_or_not(should_sleep):\n    if should_sleep:\n        await trio.sleep(1)\n    else:\n        pass\n```\n\nHere the function acts as a checkpoint if you call it with `should_sleep` set to a true value, but not otherwise. This is why we emphasize that Trio’s own async functions are *unconditional* checkpoints: they *always* check for cancellation and check for scheduling, regardless of what arguments they’re passed. If you find an async function in Trio that doesn’t follow this rule, then it’s a bug and you should [let us know](https://github.com/python-trio/trio/issues).\n\nInside Trio, we’re very picky about this, because Trio is the foundation of the whole system so we think it’s worth the extra effort to make things extra predictable. It’s up to you how picky you want to be in your code. To give you a more realistic example of what this kind of issue looks like in real life, consider this function:\n\n``` python\nasync def recv_exactly(sock, nbytes):\n    data = bytearray()\n    while nbytes > 0:\n        # recv() reads up to 'nbytes' bytes each time\n        chunk = await sock.recv(nbytes)\n        if not chunk:\n            raise RuntimeError(\"socket unexpected closed\")\n        nbytes -= len(chunk)\n        data += chunk\n    return data\n```\n\nIf called with an `nbytes` that’s greater than zero, then it will call `sock.recv` at least once, and `recv` is an async Trio function, and thus an unconditional checkpoint. So in this case, `recv_exactly` acts as a checkpoint. But if we do `await`` ``recv_exactly(sock,`` ``0)`, then it will immediately return an empty buffer without executing a checkpoint. If this were a function in Trio itself, then this wouldn’t be acceptable, but you may decide you don’t want to worry about this kind of minor edge case in your own code.\n\nIf you do want to be careful, or if you have some CPU-bound code that doesn’t have enough checkpoints in it, then it’s useful to know that `await`` ``trio.sleep(0)` is an idiomatic way to execute a checkpoint without doing anything else, and that [`trio.testing.assert_checkpoints()`](reference-testing#trio.testing.assert_checkpoints \"trio.testing.assert_checkpoints\") can be used to test that an arbitrary block of code contains a checkpoint.\n\n### Thread safety\n\nThe vast majority of Trio’s API is *not* thread safe: it can only be used from inside a call to [`trio.run()`](#trio.run \"trio.run\"). This manual doesn’t bother documenting this on individual calls; unless specifically noted otherwise, you should assume that it isn’t safe to call any Trio functions from anywhere except the Trio thread. (But [see below](#threads) if you really do need to work with threads.)\n\n## Time and clocks\n\nEvery call to [`run()`](#trio.run \"trio.run\") has an associated clock.\n\nBy default, Trio uses an unspecified monotonic clock, but this can be changed by passing a custom clock object to [`run()`](#trio.run \"trio.run\") (e.g. for testing).\n\nYou should not assume that Trio’s internal clock matches any other clock you have access to, including the clocks of simultaneous calls to [`trio.run()`](#trio.run \"trio.run\") happening in other processes or threads!\n\nThe default clock is currently implemented as [`time.perf_counter()`](https://docs.python.org/3/library/time.html#time.perf_counter \"(in Python v3.11)\") plus a large random offset. The idea here is to catch code that accidentally uses [`time.perf_counter()`](https://docs.python.org/3/library/time.html#time.perf_counter \"(in Python v3.11)\") early, which should help keep our options open for [changing the clock implementation later](https://github.com/python-trio/trio/issues/33), and (more importantly) make sure you can be confident that custom clocks like [`trio.testing.MockClock`](reference-testing#trio.testing.MockClock \"trio.testing.MockClock\") will work with third-party libraries you don’t control.\n\n### `trio.current_time()`\n\nReturns the current time according to Trio’s internal clock.\n\n#### Returns:\n\nThe current time.\n\n#### Return type:\n\n[float](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if not inside a call to [`trio.run()`](#trio.run \"trio.run\").\n\n### *`await`*` trio.sleep(seconds: float) → None`\n\nPause execution of the current task for the given number of seconds.\n\n#### Parameters:\n\n**seconds** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The number of seconds to sleep. May be zero to insert a checkpoint without actually blocking.\n\n#### Raises:\n\n[**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if *seconds* is negative or NaN.\n\n### *`await`*` trio.sleep_until(deadline: float) → None`\n\nPause execution of the current task until the given time.\n\nThe difference between [`sleep()`](#trio.sleep \"trio.sleep\") and [`sleep_until()`](#trio.sleep_until \"trio.sleep_until\") is that the former takes a relative time and the latter takes an absolute time according to Trio’s internal clock (as returned by [`current_time()`](#trio.current_time \"trio.current_time\")).\n\n#### Parameters:\n\n**deadline** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The time at which we should wake up again. May be in the past, in which case this function executes a checkpoint but does not block.\n\n#### Raises:\n\n[**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if deadline is NaN.\n\n### *`await`*` trio.sleep_forever() → None`\n\nPause execution of the current task forever (or until cancelled).\n\nEquivalent to calling `await`` ``sleep(math.inf)`.\n\nIf you’re a mad scientist or otherwise feel the need to take direct control over the PASSAGE OF TIME ITSELF, then you can implement a custom [`Clock`](#trio.abc.Clock \"trio.abc.Clock\") class:\n\n### *`class`*` trio.abc.Clock`\n\nThe interface for custom run loop clocks.\n\n### *`abstractmethod`*` current_time()`\n\nReturn the current time, according to this clock.\n\nThis is used to implement functions like [`trio.current_time()`](#trio.current_time \"trio.current_time\") and [`trio.move_on_after()`](#trio.move_on_after \"trio.move_on_after\").\n\n#### Returns:\n\nThe current time.\n\n#### Return type:\n\n[float](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")\n\n### *`abstractmethod`*` deadline_to_sleep_time(deadline)`\n\nCompute the real time until the given deadline.\n\nThis is called before we enter a system-specific wait function like [`select.select()`](https://docs.python.org/3/library/select.html#select.select \"(in Python v3.11)\"), to get the timeout to pass.\n\nFor a clock using wall-time, this should be something like:\n\n``` python\nreturn deadline - self.current_time()\n```\n\nbut of course it may be different if you’re implementing some kind of virtual clock.\n\n#### Parameters:\n\n**deadline** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The absolute time of the next deadline, according to this clock.\n\n#### Returns:\n\nThe number of real seconds to sleep until the given deadline. May be [`math.inf`](https://docs.python.org/3/library/math.html#math.inf \"(in Python v3.11)\").\n\n#### Return type:\n\n[float](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")\n\n### *`abstractmethod`*` start_clock()`\n\nDo any setup this clock might need.\n\nCalled at the beginning of the run.\n\n## Cancellation and timeouts\n\nTrio has a rich, composable system for cancelling work, either explicitly or when a timeout expires.\n\n### A simple timeout example\n\nIn the simplest case, you can apply a timeout to a block of code:\n\n``` python\nwith trio.move_on_after(30):\n    result = await do_http_get(\"https://...\")\n    print(\"result is\", result)\nprint(\"with block finished\")\n```\n\nWe refer to [`move_on_after()`](#trio.move_on_after \"trio.move_on_after\") as creating a “cancel scope”, which contains all the code that runs inside the `with` block. If the HTTP request takes more than 30 seconds to run, then it will be cancelled: we’ll abort the request and we *won’t* see `result`` ``is`` ``...` printed on the console; instead we’ll go straight to printing the `with`` ``block`` ``finished` message.\n\n> #### Note\n>\n> Note that this is a single 30 second timeout for the entire body of the `with` statement. This is different from what you might have seen with other Python libraries, where timeouts often refer to something [more complicated](https://requests.kennethreitz.org/en/master/user/quickstart/#timeouts). We think this way is easier to reason about.\n\nHow does this work? There’s no magic here: Trio is built using ordinary Python functionality, so we can’t just abandon the code inside the `with` block. Instead, we take advantage of Python’s standard way of aborting a large and complex piece of code: we raise an exception.\n\nHere’s the idea: whenever you call a cancellable function like `await`` ``trio.sleep(...)` or `await`` ``sock.recv(...)` – see [Checkpoints](#checkpoints) – then the first thing that function does is to check if there’s a surrounding cancel scope whose timeout has expired, or otherwise been cancelled. If so, then instead of performing the requested operation, the function fails immediately with a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception. In this example, this probably happens somewhere deep inside the bowels of `do_http_get`. The exception then propagates out like any normal exception (you could even catch it if you wanted, but that’s generally a bad idea), until it reaches the `with`` ``move_on_after(...):`. And at this point, the [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception has done its job – it’s successfully unwound the whole cancelled scope – so [`move_on_after()`](#trio.move_on_after \"trio.move_on_after\") catches it, and execution continues as normal after the `with` block. And this all works correctly even if you have nested cancel scopes, because every [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") object carries an invisible marker that makes sure that the cancel scope that triggered it is the only one that will catch it.\n\n### Handling cancellation\n\nPretty much any code you write using Trio needs to have some strategy to handle [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exceptions – even if you didn’t set a timeout, then your caller might (and probably will).\n\nYou can catch [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"), but you shouldn’t! Or more precisely, if you do catch it, then you should do some cleanup and then re-raise it or otherwise let it continue propagating (unless you encounter an error, in which case it’s OK to let that propagate instead). To help remind you of this fact, [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") inherits from [`BaseException`](https://docs.python.org/3/library/exceptions.html#BaseException \"(in Python v3.11)\"), like [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") and [`SystemExit`](https://docs.python.org/3/library/exceptions.html#SystemExit \"(in Python v3.11)\") do, so that it won’t be caught by catch-all `except`` ``Exception:` blocks.\n\nIt’s also important in any long-running code to make sure that you regularly check for cancellation, because otherwise timeouts won’t work! This happens implicitly every time you call a cancellable operation; see [below](#cancellable-primitives) for details. If you have a task that has to do a lot of work without any I/O, then you can use `await`` ``sleep(0)` to insert an explicit cancel+schedule point.\n\nHere’s a rule of thumb for designing good Trio-style (“trionic”?) APIs: if you’re writing a reusable function, then you shouldn’t take a `timeout=` parameter, and instead let your caller worry about it. This has several advantages. First, it leaves the caller’s options open for deciding how they prefer to handle timeouts – for example, they might find it easier to work with absolute deadlines instead of relative timeouts. If they’re the ones calling into the cancellation machinery, then they get to pick, and you don’t have to worry about it. Second, and more importantly, this makes it easier for others to re-use your code. If you write a `http_get` function, and then I come along later and write a `log_in_to_twitter` function that needs to internally make several `http_get` calls, I don’t want to have to figure out how to configure the individual timeouts on each of those calls – and with Trio’s timeout system, it’s totally unnecessary.\n\nOf course, this rule doesn’t apply to APIs that need to impose internal timeouts. For example, if you write a `start_http_server` function, then you probably should give your caller some way to configure timeouts on individual requests.\n\n### Cancellation semantics\n\nYou can freely nest cancellation blocks, and each [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception “knows” which block it belongs to. So long as you don’t stop it, the exception will keep propagating until it reaches the block that raised it, at which point it will stop automatically.\n\nHere’s an example:\n\n``` python\nprint(\"starting...\")\nwith trio.move_on_after(5):\n    with trio.move_on_after(10):\n        await trio.sleep(20)\n        print(\"sleep finished without error\")\n    print(\"move_on_after(10) finished without error\")\nprint(\"move_on_after(5) finished without error\")\n```\n\nIn this code, the outer scope will expire after 5 seconds, causing the [`sleep()`](#trio.sleep \"trio.sleep\") call to return early with a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception. Then this exception will propagate through the `with`` ``move_on_after(10)` line until it’s caught by the `with`` ``move_on_after(5)` context manager. So this code will print:\n\n    starting...\n    move_on_after(5) finished without error\n\nThe end result is that Trio has successfully cancelled exactly the work that was happening within the scope that was cancelled.\n\nLooking at this, you might wonder how you can tell whether the inner block timed out – perhaps you want to do something different, like try a fallback procedure or report a failure to our caller. To make this easier, [`move_on_after()`](#trio.move_on_after \"trio.move_on_after\")´s `__enter__` function returns an object representing this cancel scope, which we can use to check whether this scope caught a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception:\n\n``` python\nwith trio.move_on_after(5) as cancel_scope:\n    await trio.sleep(10)\nprint(cancel_scope.cancelled_caught)  # prints \"True\"\n```\n\nThe `cancel_scope` object also allows you to check or adjust this scope’s deadline, explicitly trigger a cancellation without waiting for the deadline, check if the scope has already been cancelled, and so forth – see [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") below for the full details.\n\nCancellations in Trio are “level triggered”, meaning that once a block has been cancelled, *all* cancellable operations in that block will keep raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"). This helps avoid some pitfalls around resource clean-up. For example, imagine that we have a function that connects to a remote server and sends some messages, and then cleans up on the way out:\n\n``` python\nwith trio.move_on_after(TIMEOUT):\n    conn = make_connection()\n    try:\n        await conn.send_hello_msg()\n    finally:\n        await conn.send_goodbye_msg()\n```\n\nNow suppose that the remote server stops responding, so our call to `await`` ``conn.send_hello_msg()` hangs forever. Fortunately, we were clever enough to put a timeout around this code, so eventually the timeout will expire and `send_hello_msg` will raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"). But then, in the `finally` block, we make another blocking operation, which will also hang forever! At this point, if we were using [`asyncio`](https://docs.python.org/3/library/asyncio.html#module-asyncio \"(in Python v3.11)\") or another library with “edge-triggered” cancellation, we’d be in trouble: since our timeout already fired, it wouldn’t fire again, and at this point our application would lock up forever. But in Trio, this *doesn’t* happen: the `await`` ``conn.send_goodbye_msg()` call is still inside the cancelled block, so it will also raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\").\n\nOf course, if you really want to make another blocking call in your cleanup handler, Trio will let you; it’s trying to prevent you from accidentally shooting yourself in the foot. Intentional foot-shooting is no problem (or at least – it’s not Trio’s problem). To do this, create a new scope, and set its [`shield`](#trio.CancelScope.shield \"trio.CancelScope.shield\") attribute to [`True`](https://docs.python.org/3/library/constants.html#True \"(in Python v3.11)\"):\n\n``` python\nwith trio.move_on_after(TIMEOUT):\n    conn = make_connection()\n    try:\n        await conn.send_hello_msg()\n    finally:\n        with trio.move_on_after(CLEANUP_TIMEOUT) as cleanup_scope:\n            cleanup_scope.shield = True\n            await conn.send_goodbye_msg()\n```\n\nSo long as you’re inside a scope with `shield`` ``=`` ``True` set, then you’ll be protected from outside cancellations. Note though that this *only* applies to *outside* cancellations: if `CLEANUP_TIMEOUT` expires then `await`` ``conn.send_goodbye_msg()` will still be cancelled, and if `await`` ``conn.send_goodbye_msg()` call uses any timeouts internally, then those will continue to work normally as well. This is a pretty advanced feature that most people probably won’t use, but it’s there for the rare cases where you need it.\n\n### Cancellation and primitive operations\n\nWe’ve talked a lot about what happens when an operation is cancelled, and how you need to be prepared for this whenever calling a cancellable operation… but we haven’t gone into the details about which operations are cancellable, and how exactly they behave when they’re cancelled.\n\nHere’s the rule: if it’s in the `trio` namespace, and you use `await` to call it, then it’s cancellable (see [Checkpoints](#checkpoints) above). Cancellable means:\n\n- If you try to call it when inside a cancelled scope, then it will raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\").\n\n- If it blocks, and while it’s blocked then one of the scopes around it becomes cancelled, it will return early and raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\").\n\n- Raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") means that the operation *did not happen*. If a Trio socket’s `send` method raises [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"), then no data was sent. If a Trio socket’s `recv` method raises [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") then no data was lost – it’s still sitting in the socket receive buffer waiting for you to call `recv` again. And so forth.\n\nThere are a few idiosyncratic cases where external constraints make it impossible to fully implement these semantics. These are always documented. There is also one systematic exception:\n\n- Async cleanup operations – like `__aexit__` methods or async close methods – are cancellable just like anything else *except* that if they are cancelled, they still perform a minimum level of cleanup before raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\").\n\nFor example, closing a TLS-wrapped socket normally involves sending a notification to the remote peer, so that they can be cryptographically assured that you really meant to close the socket, and your connection wasn’t just broken by a man-in-the-middle attacker. But handling this robustly is a bit tricky. Remember our [example](#blocking-cleanup-example) above where the blocking `send_goodbye_msg` caused problems? That’s exactly how closing a TLS socket works: if the remote peer has disappeared, then our code may never be able to actually send our shutdown notification, and it would be nice if it didn’t block forever trying. Therefore, the method for closing a TLS-wrapped socket will *try* to send that notification – and if it gets cancelled, then it will give up on sending the message, but *will* still close the underlying socket before raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"), so at least you don’t leak that resource.\n\n### Cancellation API details\n\n[`move_on_after()`](#trio.move_on_after \"trio.move_on_after\") and all the other cancellation facilities provided by Trio are ultimately implemented in terms of [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") objects.\n\n### *`class`*` trio.CancelScope(*, deadline: float = inf, shield: bool = False)`\n\nA *cancellation scope*: the link between a unit of cancellable work and Trio’s cancellation system.\n\nA [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") becomes associated with some cancellable work when it is used as a context manager surrounding that work:\n\n``` python\ncancel_scope = trio.CancelScope()\n...\nwith cancel_scope:\n    await long_running_operation()\n```\n\nInside the `with` block, a cancellation of `cancel_scope` (via a call to its [`cancel()`](#trio.CancelScope.cancel \"trio.CancelScope.cancel\") method or via the expiry of its [`deadline`](#trio.CancelScope.deadline \"trio.CancelScope.deadline\")) will immediately interrupt the `long_running_operation()` by raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") at its next [checkpoint](#checkpoints).\n\nThe context manager `__enter__` returns the [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") object itself, so you can also write `with`` ``trio.CancelScope()`` ``as`` ``cancel_scope:`.\n\nIf a cancel scope becomes cancelled before entering its `with` block, the [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception will be raised at the first checkpoint inside the `with` block. This allows a [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") to be created in one [task](#tasks) and passed to another, so that the first task can later cancel some work inside the second.\n\nCancel scopes are not reusable or reentrant; that is, each cancel scope can be used for at most one `with` block. (You’ll get a [`RuntimeError`](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") if you violate this rule.)\n\nThe [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") constructor takes initial values for the cancel scope’s [`deadline`](#trio.CancelScope.deadline \"trio.CancelScope.deadline\") and [`shield`](#trio.CancelScope.shield \"trio.CancelScope.shield\") attributes; these may be freely modified after construction, whether or not the scope has been entered yet, and changes take immediate effect.\n\n### `deadline`\n\nRead-write, [`float`](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\"). An absolute time on the current run’s clock at which this scope will automatically become cancelled. You can adjust the deadline by modifying this attribute, e.g.:\n\n``` python\n# I need a little more time!\ncancel_scope.deadline += 30\n```\n\nNote that for efficiency, the core run loop only checks for expired deadlines every once in a while. This means that in certain cases there may be a short delay between when the clock says the deadline should have expired, and when checkpoints start raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"). This is a very obscure corner case that you’re unlikely to notice, but we document it for completeness. (If this *does* cause problems for you, of course, then [we want to know!](https://github.com/python-trio/trio/issues))\n\nDefaults to [`math.inf`](https://docs.python.org/3/library/math.html#math.inf \"(in Python v3.11)\"), which means “no deadline”, though this can be overridden by the `deadline=` argument to the [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") constructor.\n\n### `shield`\n\nRead-write, [`bool`](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\"), default [`False`](https://docs.python.org/3/library/constants.html#False \"(in Python v3.11)\"). So long as this is set to [`True`](https://docs.python.org/3/library/constants.html#True \"(in Python v3.11)\"), then the code inside this scope will not receive [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exceptions from scopes that are outside this scope. They can still receive [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exceptions from (1) this scope, or (2) scopes inside this scope. You can modify this attribute:\n\n``` python\nwith trio.CancelScope() as cancel_scope:\n    cancel_scope.shield = True\n    # This cannot be interrupted by any means short of\n    # killing the process:\n    await sleep(10)\n\n    cancel_scope.shield = False\n    # Now this can be cancelled normally:\n    await sleep(10)\n```\n\nDefaults to [`False`](https://docs.python.org/3/library/constants.html#False \"(in Python v3.11)\"), though this can be overridden by the `shield=` argument to the [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") constructor.\n\n### `cancel()`\n\nCancels this scope immediately.\n\nThis method is idempotent, i.e., if the scope was already cancelled then this method silently does nothing.\n\n### `cancelled_caught`\n\nReadonly [`bool`](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\"). Records whether this scope caught a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception. This requires two things: (1) the `with` block exited with a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception, and (2) this scope is the one that was responsible for triggering this [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception.\n\n### `cancel_called`\n\nReadonly [`bool`](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\"). Records whether cancellation has been requested for this scope, either by an explicit call to [`cancel()`](#trio.CancelScope.cancel \"trio.CancelScope.cancel\") or by the deadline expiring.\n\nThis attribute being True does *not* necessarily mean that the code within the scope has been, or will be, affected by the cancellation. For example, if [`cancel()`](#trio.CancelScope.cancel \"trio.CancelScope.cancel\") was called after the last checkpoint in the `with` block, when it’s too late to deliver a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception, then this attribute will still be True.\n\nThis attribute is mostly useful for debugging and introspection. If you want to know whether or not a chunk of code was actually cancelled, then [`cancelled_caught`](#trio.CancelScope.cancelled_caught \"trio.CancelScope.cancelled_caught\") is usually more appropriate.\n\nOften there is no need to create [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") object. Trio already includes [`cancel_scope`](#trio.Nursery.cancel_scope \"trio.Nursery.cancel_scope\") attribute in a task-related [`Nursery`](#trio.Nursery \"trio.Nursery\") object. We will cover nurseries later in the manual.\n\nTrio also provides several convenience functions for the common situation of just wanting to impose a timeout on some code:\n\n### *`with`*` trio.move_on_after(seconds: float) → CancelScope as cancel_scope`\n\nUse as a context manager to create a cancel scope whose deadline is set to now + *seconds*.\n\n#### Parameters:\n\n**seconds** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The timeout.\n\n#### Raises:\n\n[**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if timeout is less than zero or NaN.\n\n### *`with`*` trio.move_on_at(deadline: float) → CancelScope as cancel_scope`\n\nUse as a context manager to create a cancel scope with the given absolute deadline.\n\n#### Parameters:\n\n**deadline** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The deadline.\n\n#### Raises:\n\n[**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if deadline is NaN.\n\n### *`with`*` trio.fail_after(seconds: float) → AbstractContextManager[CancelScope] as cancel_scope`\n\nCreates a cancel scope with the given timeout, and raises an error if it is actually cancelled.\n\nThis function and [`move_on_after()`](#trio.move_on_after \"trio.move_on_after\") are similar in that both create a cancel scope with a given timeout, and if the timeout expires then both will cause [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") to be raised within the scope. The difference is that when the [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception reaches [`move_on_after()`](#trio.move_on_after \"trio.move_on_after\"), it’s caught and discarded. When it reaches [`fail_after()`](#trio.fail_after \"trio.fail_after\"), then it’s caught and [`TooSlowError`](#trio.TooSlowError \"trio.TooSlowError\") is raised in its place.\n\n#### Parameters:\n\n**seconds** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The timeout.\n\n#### Raises:\n\n- [**TooSlowError**](#trio.TooSlowError \"trio.TooSlowError\") – if a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception is raised in this scope and caught by the context manager.\n\n- [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if *seconds* is less than zero or NaN.\n\n### *`with`*` trio.fail_at(deadline: float) → AbstractContextManager[CancelScope] as cancel_scope`\n\nCreates a cancel scope with the given deadline, and raises an error if it is actually cancelled.\n\nThis function and [`move_on_at()`](#trio.move_on_at \"trio.move_on_at\") are similar in that both create a cancel scope with a given absolute deadline, and if the deadline expires then both will cause [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") to be raised within the scope. The difference is that when the [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception reaches [`move_on_at()`](#trio.move_on_at \"trio.move_on_at\"), it’s caught and discarded. When it reaches [`fail_at()`](#trio.fail_at \"trio.fail_at\"), then it’s caught and [`TooSlowError`](#trio.TooSlowError \"trio.TooSlowError\") is raised in its place.\n\n#### Parameters:\n\n**deadline** ([*float*](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")) – The deadline.\n\n#### Raises:\n\n- [**TooSlowError**](#trio.TooSlowError \"trio.TooSlowError\") – if a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception is raised in this scope and caught by the context manager.\n\n- [**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if deadline is NaN.\n\nCheat sheet:\n\n- If you want to impose a timeout on a function, but you don’t care whether it timed out or not:\n\n  ``` python\n  with trio.move_on_after(TIMEOUT):\n      await do_whatever()\n  # carry on!\n  ```\n\n- If you want to impose a timeout on a function, and then do some recovery if it timed out:\n\n  ``` python\n  with trio.move_on_after(TIMEOUT) as cancel_scope:\n      await do_whatever()\n  if cancel_scope.cancelled_caught:\n      # The operation timed out, try something else\n      try_to_recover()\n  ```\n\n- If you want to impose a timeout on a function, and then if it times out then just give up and raise an error for your caller to deal with:\n\n  ``` python\n  with trio.fail_after(TIMEOUT):\n      await do_whatever()\n  ```\n\nIt’s also possible to check what the current effective deadline is, which is sometimes useful:\n\n### `trio.current_effective_deadline()`\n\nReturns the current effective deadline for the current task.\n\nThis function examines all the cancellation scopes that are currently in effect (taking into account shielding), and returns the deadline that will expire first.\n\nOne example of where this might be is useful is if your code is trying to decide whether to begin an expensive operation like an RPC call, but wants to skip it if it knows that it can’t possibly complete in the available time. Another example would be if you’re using a protocol like gRPC that [propagates timeout information to the remote peer](http://www.grpc.io/docs/guides/concepts.html#deadlines); this function gives a way to fetch that information so you can send it along.\n\nIf this is called in a context where a cancellation is currently active (i.e., a blocking call will immediately raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\")), then returned deadline is `-inf`. If it is called in a context where no scopes have a deadline set, it returns `inf`.\n\n#### Returns:\n\nthe effective deadline, as an absolute time.\n\n#### Return type:\n\n[float](https://docs.python.org/3/library/functions.html#float \"(in Python v3.11)\")\n\n## Tasks let you do multiple things at once\n\nOne of Trio’s core design principles is: *no implicit concurrency*. Every function executes in a straightforward, top-to-bottom manner, finishing each operation before moving on to the next – *like Guido intended*.\n\nBut, of course, the entire point of an async library is to let you do multiple things at once. The one and only way to do that in Trio is through the task spawning interface. So if you want your program to walk *and* chew gum, this is the section for you.\n\n### Nurseries and spawning\n\nMost libraries for concurrent programming let you start new child tasks (or threads, or whatever) willy-nilly, whenever and where-ever you feel like it. Trio is a bit different: you can’t start a child task unless you’re prepared to be a responsible parent. The way you demonstrate your responsibility is by creating a nursery:\n\n``` python\nasync with trio.open_nursery() as nursery:\n    ...\n```\n\nAnd once you have a reference to a nursery object, you can start children in that nursery:\n\n``` python\nasync def child():\n    ...\n\nasync def parent():\n    async with trio.open_nursery() as nursery:\n        # Make two concurrent calls to child()\n        nursery.start_soon(child)\n        nursery.start_soon(child)\n```\n\nThis means that tasks form a tree: when you call [`run()`](#trio.run \"trio.run\"), then this creates an initial task, and all your other tasks will be children, grandchildren, etc. of the initial task.\n\nEssentially, the body of the `async`` ``with` block acts like an initial task that’s running inside the nursery, and then each call to `nursery.start_soon` adds another task that runs in parallel. Two crucial things to keep in mind:\n\n- If any task inside the nursery finishes with an unhandled exception, then the nursery immediately cancels all the tasks inside the nursery.\n\n- Since all of the tasks are running concurrently inside the `async`` ``with` block, the block does not exit until *all* tasks have completed. If you’ve used other concurrency frameworks, then you can think of it as, the de-indentation at the end of the `async`` ``with` automatically “joins” (waits for) all of the tasks in the nursery.\n\n- Once all the tasks have finished, then:\n\n  - The nursery is marked as “closed”, meaning that no new tasks can be started inside it.\n\n  - Any unhandled exceptions are re-raised inside the parent task. If there are multiple exceptions, then they’re collected up into a single [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup \"(in Python v3.11)\") or [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") exception.\n\nSince all tasks are descendents of the initial task, one consequence of this is that [`run()`](#trio.run \"trio.run\") can’t finish until all tasks have finished.\n\n> #### Note\n>\n> A return statement will not cancel the nursery if it still has tasks running:\n>\n> ``` python\n> async def main():\n>     async with trio.open_nursery() as nursery:\n>         nursery.start_soon(trio.sleep, 5)\n>         return\n>\n> trio.run(main)\n> ```\n>\n> This code will wait 5 seconds (for the child task to finish), and then return.\n\n### Child tasks and cancellation\n\nIn Trio, child tasks inherit the parent nursery’s cancel scopes. So in this example, both the child tasks will be cancelled when the timeout expires:\n\n``` python\nwith trio.move_on_after(TIMEOUT):\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(child1)\n        nursery.start_soon(child2)\n```\n\nNote that what matters here is the scopes that were active when [`open_nursery()`](#trio.open_nursery \"trio.open_nursery\") was called, *not* the scopes active when `start_soon` is called. So for example, the timeout block below does nothing at all:\n\n``` python\nasync with trio.open_nursery() as nursery:\n    with trio.move_on_after(TIMEOUT):  # don't do this!\n        nursery.start_soon(child)\n```\n\nWhy is this so? Well, `start_soon()` returns as soon as it has scheduled the new task to start running. The flow of execution in the parent then continues on to exit the `with`` ``trio.move_on_after(TIMEOUT):` block, at which point Trio forgets about the timeout entirely. In order for the timeout to apply to the child task, Trio must be able to tell that its associated cancel scope will stay open for at least as long as the child task is executing. And Trio can only know that for sure if the cancel scope block is outside the nursery block.\n\nYou might wonder why Trio can’t just remember “this task should be cancelled in `TIMEOUT` seconds”, even after the `with`` ``trio.move_on_after(TIMEOUT):` block is gone. The reason has to do with [how cancellation is implemented](#cancellation). Recall that cancellation is represented by a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception, which eventually needs to be caught by the cancel scope that caused it. (Otherwise, the exception would take down your whole program!) In order to be able to cancel the child tasks, the cancel scope has to be able to “see” the [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exceptions that they raise – and those exceptions come out of the `async`` ``with`` ``open_nursery()` block, not out of the call to `start_soon()`.\n\nIf you want a timeout to apply to one task but not another, then you need to put the cancel scope in that individual task’s function – `child()`, in this example.\n\n### Errors in multiple child tasks\n\nNormally, in Python, only one thing happens at a time, which means that only one thing can wrong at a time. Trio has no such limitation. Consider code like:\n\n``` python\nasync def broken1():\n    d = {}\n    return d[\"missing\"]\n\nasync def broken2():\n    seq = range(10)\n    return seq[20]\n\nasync def parent():\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(broken1)\n        nursery.start_soon(broken2)\n```\n\n`broken1` raises `KeyError`. `broken2` raises `IndexError`. Obviously `parent` should raise some error, but what? The answer is that both exceptions are grouped in an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\"). [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") and its parent class [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup \"(in Python v3.11)\") are used to encapsulate multiple exceptions being raised at once.\n\nTo catch individual exceptions encapsulated in an exception group, the `except*` clause was introduced in Python 3.11 ([**PEP 654**](https://peps.python.org/pep-0654/)). Here’s how it works:\n\n``` python\ntry:\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(broken1)\n        nursery.start_soon(broken2)\nexcept* KeyError as excgroup:\n    for exc in excgroup.exceptions:\n        ...  # handle each KeyError\nexcept* IndexError as excgroup:\n    for exc in excgroup.exceptions:\n        ...  # handle each IndexError\n```\n\nIf you want to reraise exceptions, or raise new ones, you can do so, but be aware that exceptions raised in `except*` sections will be raised together in a new exception group.\n\nBut what if you can’t use `except*` just yet? Well, for that there is the handy [exceptiongroup](https://pypi.org/project/exceptiongroup/) library which lets you approximate this behavior with exception handler callbacks:\n\n``` python\nfrom exceptiongroup import catch\n\ndef handle_keyerrors(excgroup):\n    for exc in excgroup.exceptions:\n        ...  # handle each KeyError\n\ndef handle_indexerrors(excgroup):\n    for exc in excgroup.exceptions:\n        ...  # handle each IndexError\n\nwith catch({\n    KeyError: handle_keyerrors,\n    IndexError: handle_indexerrors\n}):\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(broken1)\n        nursery.start_soon(broken2)\n```\n\nThe semantics for the handler functions are equal to `except*` blocks, except for setting local variables. If you need to set local variables, you need to declare them inside the handler function(s) with the `nonlocal` keyword:\n\n``` python\ndef handle_keyerrors(excgroup):\n    nonlocal myflag\n    myflag = True\n\nmyflag = False\nwith catch({KeyError: handle_keyerrors}):\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(broken1)\n```\n\nFor reasons of backwards compatibility, nurseries raise `trio.MultiError` and `trio.NonBaseMultiError` which inherit from [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup \"(in Python v3.11)\") and [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\"), respectively. Users should refrain from attempting to raise or catch the Trio specific exceptions themselves, and treat them as if they were standard [`BaseExceptionGroup`](https://docs.python.org/3/library/exceptions.html#BaseExceptionGroup \"(in Python v3.11)\") or [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") instances instead.\n\n#### “Strict” versus “loose” ExceptionGroup semantics\n\nIdeally, in some abstract sense we’d want everything that *can* raise an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") to *always* raise an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") (rather than, say, a single [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\")). Otherwise, it would be easy to accidentally write something like `except`` ``ValueError:` (not `except*`), which works if a single exception is raised but fails to catch \\_anything\\_ in the case of multiple simultaneous exceptions (even if one of them is a ValueError). However, this is not how Trio worked in the past: as a concession to practicality when the `except*` syntax hadn’t been dreamed up yet, the old `trio.MultiError` was raised only when at least two exceptions occurred simultaneously. Adding a layer of [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") around every nursery, while theoretically appealing, would probably break a lot of existing code in practice.\n\nTherefore, we’ve chosen to gate the newer, “stricter” behavior behind a parameter called `strict_exception_groups`. This is accepted as a parameter to [`open_nursery()`](#trio.open_nursery \"trio.open_nursery\"), to set the behavior for that nursery, and to [`trio.run()`](#trio.run \"trio.run\"), to set the default behavior for any nursery in your program that doesn’t override it.\n\n- With `strict_exception_groups=True`, the exception(s) coming out of a nursery will always be wrapped in an [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\"), so you’ll know that if you’re handling single errors correctly, multiple simultaneous errors will work as well.\n\n- With `strict_exception_groups=False`, a nursery in which only one task has failed will raise that task’s exception without an additional layer of [`ExceptionGroup`](https://docs.python.org/3/library/exceptions.html#ExceptionGroup \"(in Python v3.11)\") wrapping, so you’ll get maximum compatibility with code that was written to support older versions of Trio.\n\nTo maintain backwards compatibility, the default is `strict_exception_groups=False`. The default will eventually change to `True` in a future version of Trio, once Python 3.11 and later versions are in wide use.\n\n### Spawning tasks without becoming a parent\n\nSometimes it doesn’t make sense for the task that starts a child to take on responsibility for watching it. For example, a server task may want to start a new task for each connection, but it can’t listen for connections and supervise children at the same time.\n\nThe solution here is simple once you see it: there’s no requirement that a nursery object stay in the task that created it! We can write code like this:\n\n``` python\nasync def new_connection_listener(handler, nursery):\n    while True:\n        conn = await get_new_connection()\n        nursery.start_soon(handler, conn)\n\nasync def server(handler):\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(new_connection_listener, handler, nursery)\n```\n\nNotice that `server` opens a nursery and passes it to `new_connection_listener`, and then `new_connection_listener` is able to start new tasks as “siblings” of itself. Of course, in this case, we could just as well have written:\n\n``` python\nasync def server(handler):\n    async with trio.open_nursery() as nursery:\n        while True:\n            conn = await get_new_connection()\n            nursery.start_soon(handler, conn)\n```\n\n...but sometimes things aren’t so simple, and this trick comes in handy.\n\nOne thing to remember, though: cancel scopes are inherited from the nursery, **not** from the task that calls `start_soon`. So in this example, the timeout does *not* apply to `child` (or to anything else):\n\n``` python\nasync def do_spawn(nursery):\n    with trio.move_on_after(TIMEOUT):  # don't do this, it has no effect\n        nursery.start_soon(child)\n\nasync with trio.open_nursery() as nursery:\n    nursery.start_soon(do_spawn, nursery)\n```\n\n### Custom supervisors\n\nThe default cleanup logic is often sufficient for simple cases, but what if you want a more sophisticated supervisor? For example, maybe you have [Erlang envy](http://learnyousomeerlang.com/supervisors) and want features like automatic restart of crashed tasks. Trio itself doesn’t provide these kinds of features, but you can build them on top; Trio’s goal is to enforce basic hygiene and then get out of your way. (Specifically: Trio won’t let you build a supervisor that exits and leaves orphaned tasks behind, and if you have an unhandled exception due to bugs or laziness then Trio will make sure they propagate.) And then you can wrap your fancy supervisor up in a library and put it on PyPI, because supervisors are tricky and there’s no reason everyone should have to write their own.\n\nFor example, here’s a function that takes a list of functions, runs them all concurrently, and returns the result from the one that finishes first:\n\n``` python\nasync def race(*async_fns):\n    if not async_fns:\n        raise ValueError(\"must pass at least one argument\")\n\n    winner = None\n\n    async def jockey(async_fn, cancel_scope):\n        nonlocal winner\n        winner = await async_fn()\n        cancel_scope.cancel()\n\n    async with trio.open_nursery() as nursery:\n        for async_fn in async_fns:\n            nursery.start_soon(jockey, async_fn, nursery.cancel_scope)\n\n    return winner\n```\n\nThis works by starting a set of tasks which each try to run their function. As soon as the first function completes its execution, the task will set the nonlocal variable `winner` from the outer scope to the result of the function, and cancel the other tasks using the passed in cancel scope. Once all tasks have been cancelled (which exits the nursery block), the variable `winner` will be returned.\n\nHere if one or more of the racing functions raises an unhandled exception then Trio’s normal handling kicks in: it cancels the others and then propagates the exception. If you want different behavior, you can get that by adding a `try` block to the `jockey` function to catch exceptions and handle them however you like.\n\n### Task-related API details\n\n#### The nursery API\n\n### *`async with`*` trio.open_nursery(strict_exception_groups: bool | None = None) → AbstractAsyncContextManager[Nursery] as nursery`\n\nReturns an async context manager which must be used to create a new [`Nursery`](#trio.Nursery \"trio.Nursery\").\n\nIt does not block on entry; on exit it blocks until all child tasks have exited.\n\n#### Parameters:\n\n**strict_exception_groups** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – If true, even a single raised exception will be wrapped in an exception group. This will eventually become the default behavior. If not specified, uses the value passed to [`run()`](#trio.run \"trio.run\").\n\n### *`class`*` trio.Nursery`\n\nA context which may be used to spawn (or cancel) child tasks.\n\nNot constructed directly, use [`open_nursery`](#trio.open_nursery \"trio.open_nursery\") instead.\n\nThe nursery will remain open until all child tasks have completed, or until it is cancelled, at which point it will cancel all its remaining child tasks and close.\n\nNurseries ensure the absence of orphaned Tasks, since all running tasks will belong to an open Nursery.\n\n### `cancel_scope`\n\nCreating a nursery also implicitly creates a cancellation scope, which is exposed as the [`cancel_scope`](#trio.Nursery.cancel_scope \"trio.Nursery.cancel_scope\") attribute. This is used internally to implement the logic where if an error occurs then `__aexit__` cancels all children, but you can use it for other things, e.g. if you want to explicitly cancel all children in response to some external event.\n\n### *`property`*` child_tasks`\n\nContains all the child [`Task`](reference-lowlevel#trio.lowlevel.Task \"trio.lowlevel.Task\") objects which are still running.\n\n#### Type:\n\n([`frozenset`](https://docs.python.org/3/library/stdtypes.html#frozenset \"(in Python v3.11)\"))\n\n### *`property`*` parent_task`\n\nThe Task that opened this nursery.\n\n#### Type:\n\n([`Task`](reference-lowlevel#trio.lowlevel.Task \"trio.lowlevel.Task\"))\n\n### *`await`*` start(async_fn, *args, name=None)`\n\nCreates and initializes a child task.\n\nLike [`start_soon()`](#trio.Nursery.start_soon \"trio.Nursery.start_soon\"), but blocks until the new task has finished initializing itself, and optionally returns some information from it.\n\nThe `async_fn` must accept a `task_status` keyword argument, and it must make sure that it (or someone) eventually calls `task_status.started()`.\n\nThe conventional way to define `async_fn` is like:\n\n``` python\nasync def async_fn(arg1, arg2, *, task_status=trio.TASK_STATUS_IGNORED):\n    ...  # Caller is blocked waiting for this code to run\n    task_status.started()\n    ...  # This async code can be interleaved with the caller\n```\n\n[`trio.TASK_STATUS_IGNORED`](#trio.TASK_STATUS_IGNORED \"trio.TASK_STATUS_IGNORED\") is a special global object with a do-nothing `started` method. This way your function supports being called either like `await`` ``nursery.start(async_fn,`` ``arg1,`` ``arg2)` or directly like `await`` ``async_fn(arg1,`` ``arg2)`, and either way it can call `task_status.started()` without worrying about which mode it’s in. Defining your function like this will make it obvious to readers that it supports being used in both modes.\n\nBefore the child calls `task_status.started()`, it’s effectively run underneath the call to [`start()`](#trio.Nursery.start \"trio.Nursery.start\"): if it raises an exception then that exception is reported by [`start()`](#trio.Nursery.start \"trio.Nursery.start\"), and does *not* propagate out of the nursery. If [`start()`](#trio.Nursery.start \"trio.Nursery.start\") is cancelled, then the child task is also cancelled.\n\nWhen the child calls `task_status.started()`, it’s moved out from underneath [`start()`](#trio.Nursery.start \"trio.Nursery.start\") and into the given nursery.\n\nIf the child task passes a value to `task_status.started(value)`, then [`start()`](#trio.Nursery.start \"trio.Nursery.start\") returns this value. Otherwise it returns `None`.\n\n### `start_soon(async_fn, *args, name=None)`\n\nCreates a child task, scheduling `await`` ``async_fn(*args)`.\n\nIf you want to run a function and immediately wait for its result, then you don’t need a nursery; just use `await`` ``async_fn(*args)`. If you want to wait for the task to initialize itself before continuing, see [`start()`](#trio.Nursery.start \"trio.Nursery.start\"), the other fundamental method for creating concurrent tasks in Trio.\n\nNote that this is *not* an async function and you don’t use await when calling it. It sets up the new task, but then returns immediately, *before* the new task has a chance to do anything. New tasks may start running in any order, and at any checkpoint the scheduler chooses - at latest when the nursery is waiting to exit.\n\nIt’s possible to pass a nursery object into another task, which allows that task to start new child tasks in the first task’s nursery.\n\nThe child task inherits its parent nursery’s cancel scopes.\n\n#### Parameters:\n\n- **async_fn** – An async callable.\n\n- **args** – Positional arguments for `async_fn`. If you want to pass keyword arguments, use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial \"(in Python v3.11)\").\n\n- **name** – The name for this task. Only used for debugging/introspection (e.g. `repr(task_obj)`). If this isn’t a string, [`start_soon()`](#trio.Nursery.start_soon \"trio.Nursery.start_soon\") will try to make it one. A common use case is if you’re wrapping a function before spawning a new task, you might pass the original function as the `name=` to make debugging easier.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – If this nursery is no longer open (i.e. its `async`` ``with` block has exited).\n\n### `trio.TASK_STATUS_IGNORED`\n\nSee [`start()`](#trio.Nursery.start \"trio.Nursery.start\").\n\n## Task-local storage\n\nSuppose you’re writing a server that responds to network requests, and you log some information about each request as you process it. If the server is busy and there are multiple requests being handled at the same time, then you might end up with logs like this:\n\n    Request handler started\n    Request handler started\n    Request handler finished\n    Request handler finished\n\nIn this log, it’s hard to know which lines came from which request. (Did the request that started first also finish first, or not?) One way to solve this is to assign each request a unique identifier, and then include this identifier in each log message:\n\n    request 1: Request handler started\n    request 2: Request handler started\n    request 2: Request handler finished\n    request 1: Request handler finished\n\nThis way we can see that request 1 was slow: it started before request 2 but finished afterwards. (You can also get [much fancier](https://opentracing.io/docs/), but this is enough for an example.)\n\nNow, here’s the problem: how does the logging code know what the request identifier is? One approach would be to explicitly pass it around to every function that might want to emit logs… but that’s basically every function, because you never know when you might need to add a `log.debug(...)` call to some utility function buried deep in the call stack, and when you’re in the middle of a debugging a nasty problem that last thing you want is to have to stop first and refactor everything to pass through the request identifier! Sometimes this is the right solution, but other times it would be much more convenient if we could store the identifier in a global variable, so that the logging function could look it up whenever it needed it. Except… a global variable can only have one value at a time, so if we have multiple handlers running at once then this isn’t going to work. What we need is something that’s *like* a global variable, but that can have different values depending on which request handler is accessing it.\n\nTo solve this problem, Python 3.7 added a new module to the standard library: [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\"). And not only does Trio have built-in support for [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\"), but if you’re using an earlier version of Python, then Trio makes sure that a backported version of [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\") is installed. So you can assume [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\") is there and works regardless of what version of Python you’re using.\n\nHere’s a toy example demonstrating how to use [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\"):\n\n``` python\nimport random\nimport trio\nimport contextvars\n\nrequest_info = contextvars.ContextVar(\"request_info\")\n\n\n# Example logging function that tags each line with the request identifier.\ndef log(msg):\n    # Read from task-local storage:\n    request_tag = request_info.get()\n\n    print(f\"request {request_tag}: {msg}\")\n\n\n# An example \"request handler\" that does some work itself and also\n# spawns some helper tasks to do some concurrent work.\nasync def handle_request(tag):\n    # Write to task-local storage:\n    request_info.set(tag)\n\n    log(\"Request handler started\")\n    await trio.sleep(random.random())\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(concurrent_helper, \"a\")\n        nursery.start_soon(concurrent_helper, \"b\")\n    await trio.sleep(random.random())\n    log(\"Request received finished\")\n\n\nasync def concurrent_helper(job):\n    log(f\"Helper task {job} started\")\n    await trio.sleep(random.random())\n    log(f\"Helper task {job} finished\")\n\n\n# Spawn several \"request handlers\" simultaneously, to simulate a\n# busy server handling multiple requests at the same time.\nasync def main():\n    async with trio.open_nursery() as nursery:\n        for i in range(3):\n            nursery.start_soon(handle_request, i)\n\n\ntrio.run(main)\n```\n\nExample output (yours may differ slightly):\n\n    request 1: Request handler started\n    request 2: Request handler started\n    request 0: Request handler started\n    request 2: Helper task a started\n    request 2: Helper task b started\n    request 1: Helper task a started\n    request 1: Helper task b started\n    request 0: Helper task b started\n    request 0: Helper task a started\n    request 2: Helper task b finished\n    request 2: Helper task a finished\n    request 2: Request received finished\n    request 0: Helper task a finished\n    request 1: Helper task a finished\n    request 1: Helper task b finished\n    request 1: Request received finished\n    request 0: Helper task b finished\n    request 0: Request received finished\n\nFor more information, read the [contextvars docs](https://docs.python.org/3.7/library/contextvars.html).\n\n## Synchronizing and communicating between tasks\n\nTrio provides a standard set of synchronization and inter-task communication primitives. These objects’ APIs are generally modelled off of the analogous classes in the standard library, but with some differences.\n\n### Blocking and non-blocking methods\n\nThe standard library synchronization primitives have a variety of mechanisms for specifying timeouts and blocking behavior, and of signaling whether an operation returned due to success versus a timeout.\n\nIn Trio, we standardize on the following conventions:\n\n- We don’t provide timeout arguments. If you want a timeout, then use a cancel scope.\n\n- For operations that have a non-blocking variant, the blocking and non-blocking variants are different methods with names like `X` and `X_nowait`, respectively. (This is similar to [`queue.Queue`](https://docs.python.org/3/library/queue.html#queue.Queue \"(in Python v3.11)\"), but unlike most of the classes in [`threading`](https://docs.python.org/3/library/threading.html#module-threading \"(in Python v3.11)\").) We like this approach because it allows us to make the blocking version async and the non-blocking version sync.\n\n- When a non-blocking method cannot succeed (the channel is empty, the lock is already held, etc.), then it raises [`trio.WouldBlock`](#trio.WouldBlock \"trio.WouldBlock\"). There’s no equivalent to the [`queue.Empty`](https://docs.python.org/3/library/queue.html#queue.Empty \"(in Python v3.11)\") versus [`queue.Full`](https://docs.python.org/3/library/queue.html#queue.Full \"(in Python v3.11)\") distinction – we just have the one exception that we use consistently.\n\n### Fairness\n\nThese classes are all guaranteed to be “fair”, meaning that when it comes time to choose who will be next to acquire a lock, get an item from a queue, etc., then it always goes to the task which has been waiting longest. It’s [not entirely clear](https://github.com/python-trio/trio/issues/54) whether this is the best choice, but for now that’s how it works.\n\nAs an example of what this means, here’s a small program in which two tasks compete for a lock. Notice that the task which releases the lock always immediately attempts to re-acquire it, before the other task has a chance to run. (And remember that we’re doing cooperative multi-tasking here, so it’s actually *deterministic* that the task releasing the lock will call [`acquire()`](#trio.Lock.acquire \"trio.Lock.acquire\") before the other task wakes up; in Trio releasing a lock is not a checkpoint.) With an unfair lock, this would result in the same task holding the lock forever and the other task being starved out. But if you run this, you’ll see that the two tasks politely take turns:\n\n``` python\n# fairness-demo.py\n\nimport trio\n\nasync def loopy_child(number, lock):\n    while True:\n        async with lock:\n            print(f\"Child {number} has the lock!\")\n            await trio.sleep(0.5)\n\nasync def main():\n    async with trio.open_nursery() as nursery:\n        lock = trio.Lock()\n        nursery.start_soon(loopy_child, 1, lock)\n        nursery.start_soon(loopy_child, 2, lock)\n\ntrio.run(main)\n```\n\n### Broadcasting an event with [`Event`](#trio.Event \"trio.Event\")\n\n### *`class`*` trio.Event`\n\nA waitable boolean value useful for inter-task synchronization, inspired by [`threading.Event`](https://docs.python.org/3/library/threading.html#threading.Event \"(in Python v3.11)\").\n\nAn event object has an internal boolean flag, representing whether the event has happened yet. The flag is initially False, and the [`wait()`](#trio.Event.wait \"trio.Event.wait\") method waits until the flag is True. If the flag is already True, then [`wait()`](#trio.Event.wait \"trio.Event.wait\") returns immediately. (If the event has already happened, there’s nothing to wait for.) The [`set()`](#trio.Event.set \"trio.Event.set\") method sets the flag to True, and wakes up any waiters.\n\nThis behavior is useful because it helps avoid race conditions and lost wakeups: it doesn’t matter whether [`set()`](#trio.Event.set \"trio.Event.set\") gets called just before or after [`wait()`](#trio.Event.wait \"trio.Event.wait\"). If you want a lower-level wakeup primitive that doesn’t have this protection, consider [`Condition`](#trio.Condition \"trio.Condition\") or [`trio.lowlevel.ParkingLot`](reference-lowlevel#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\").\n\n> #### Note\n>\n> Unlike [`threading.Event`](https://docs.python.org/3/library/threading.html#threading.Event \"(in Python v3.11)\"), [`trio.Event`](#trio.Event \"trio.Event\") has no [`clear`](https://docs.python.org/3/library/threading.html#threading.Event.clear \"(in Python v3.11)\") method. In Trio, once an [`Event`](#trio.Event \"trio.Event\") has happened, it cannot un-happen. If you need to represent a series of events, consider creating a new [`Event`](#trio.Event \"trio.Event\") object for each one (they’re cheap!), or other synchronization methods like [channels](#channels) or [`trio.lowlevel.ParkingLot`](reference-lowlevel#trio.lowlevel.ParkingLot \"trio.lowlevel.ParkingLot\").\n\n### `is_set()`\n\nReturn the current value of the internal flag.\n\n### `set()`\n\nSet the internal flag value to True, and wake any waiting tasks.\n\n### `statistics()`\n\nReturn an object containing debugging information.\n\nCurrently the following fields are defined:\n\n- `tasks_waiting`: The number of tasks blocked on this event’s [`wait()`](#trio.Event.wait \"trio.Event.wait\") method.\n\n### *`await`*` wait()`\n\nBlock until the internal flag value becomes True.\n\nIf it’s already True, then this method returns immediately.\n\n### Using channels to pass values between tasks\n\n*Channels* allow you to safely and conveniently send objects between different tasks. They’re particularly useful for implementing producer/consumer patterns.\n\nThe core channel API is defined by the abstract base classes [`trio.abc.SendChannel`](reference-io#trio.abc.SendChannel \"trio.abc.SendChannel\") and [`trio.abc.ReceiveChannel`](reference-io#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\"). You can use these to implement your own custom channels, that do things like pass objects between processes or over the network. But in many cases, you just want to pass objects between different tasks inside a single process, and for that you can use [`trio.open_memory_channel()`](#trio.open_memory_channel \"trio.open_memory_channel\"):\n\n### `trio.open_memory_channel(max_buffer_size)`\n\nOpen a channel for passing objects between tasks within a process.\n\nMemory channels are lightweight, cheap to allocate, and entirely in-memory. They don’t involve any operating-system resources, or any kind of serialization. They just pass Python objects directly between tasks (with a possible stop in an internal buffer along the way).\n\nChannel objects can be closed by calling [`aclose`](reference-io#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") or using `async`` ``with`. They are *not* automatically closed when garbage collected. Closing memory channels isn’t mandatory, but it is generally a good idea, because it helps avoid situations where tasks get stuck waiting on a channel when there’s no-one on the other side. See [Clean shutdown with channels](#channel-shutdown) for details.\n\nMemory channel operations are all atomic with respect to cancellation, either [`receive`](reference-io#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\") will successfully return an object, or it will raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") while leaving the channel unchanged.\n\n#### Parameters:\n\n**max_buffer_size** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *math.inf*) – The maximum number of items that can be buffered in the channel before [`send()`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") blocks. Choosing a sensible value here is important to ensure that backpressure is communicated promptly and avoid unnecessary latency; see [Buffering in channels](#channel-buffering) for more details. If in doubt, use 0.\n\n#### Returns:\n\nA pair `(send_channel,`` ``receive_channel)`. If you have trouble remembering which order these go in, remember: data flows from left → right.\n\nIn addition to the standard channel methods, all memory channel objects provide a `statistics()` method, which returns an object with the following fields:\n\n- `current_buffer_used`: The number of items currently stored in the channel buffer.\n\n- `max_buffer_size`: The maximum number of items allowed in the buffer, as passed to [`open_memory_channel()`](#trio.open_memory_channel \"trio.open_memory_channel\").\n\n- `open_send_channels`: The number of open [`MemorySendChannel`](#trio.MemorySendChannel \"trio.MemorySendChannel\") endpoints pointing to this channel. Initially 1, but can be increased by [`MemorySendChannel.clone()`](#trio.MemorySendChannel.clone \"trio.MemorySendChannel.clone\").\n\n- `open_receive_channels`: Likewise, but for open [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel \"trio.MemoryReceiveChannel\") endpoints.\n\n- `tasks_waiting_send`: The number of tasks blocked in `send` on this channel (summing over all clones).\n\n- `tasks_waiting_receive`: The number of tasks blocked in `receive` on this channel (summing over all clones).\n\n> #### Note\n>\n> If you’ve used the [`threading`](https://docs.python.org/3/library/threading.html#module-threading \"(in Python v3.11)\") or [`asyncio`](https://docs.python.org/3/library/asyncio.html#module-asyncio \"(in Python v3.11)\") modules, you may be familiar with [`queue.Queue`](https://docs.python.org/3/library/queue.html#queue.Queue \"(in Python v3.11)\") or [`asyncio.Queue`](https://docs.python.org/3/library/asyncio-queue.html#asyncio.Queue \"(in Python v3.11)\"). In Trio, [`open_memory_channel()`](#trio.open_memory_channel \"trio.open_memory_channel\") is what you use when you’re looking for a queue. The main difference is that Trio splits the classic queue interface up into two objects. The advantage of this is that it makes it possible to put the two ends in different processes without rewriting your code, and that we can close the two sides separately.\n\n[`MemorySendChannel`](#trio.MemorySendChannel \"trio.MemorySendChannel\") and [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel \"trio.MemoryReceiveChannel\") also expose several more features beyond the core channel interface:\n\n### *`class`*` trio.MemorySendChannel(*args: object, **kwargs: object)`\n\n### `clone() → MemorySendChannel[SendType]`\n\nClone this send channel object.\n\nThis returns a new [`MemorySendChannel`](#trio.MemorySendChannel \"trio.MemorySendChannel\") object, which acts as a duplicate of the original: sending on the new object does exactly the same thing as sending on the old object. (If you’re familiar with [`os.dup`](https://docs.python.org/3/library/os.html#os.dup \"(in Python v3.11)\"), then this is a similar idea.)\n\nHowever, closing one of the objects does not close the other, and receivers don’t get [`EndOfChannel`](#trio.EndOfChannel \"trio.EndOfChannel\") until *all* clones have been closed.\n\nThis is useful for communication patterns that involve multiple producers all sending objects to the same destination. If you give each producer its own clone of the [`MemorySendChannel`](#trio.MemorySendChannel \"trio.MemorySendChannel\"), and then make sure to close each [`MemorySendChannel`](#trio.MemorySendChannel \"trio.MemorySendChannel\") when it’s finished, receivers will automatically get notified when all producers are finished. See [Managing multiple producers and/or multiple consumers](#channel-mpmc) for examples.\n\n#### Raises:\n\n[**trio.ClosedResourceError**](#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you already closed this [`MemorySendChannel`](#trio.MemorySendChannel \"trio.MemorySendChannel\") object.\n\n### `close() → None`\n\nClose this send channel object synchronously.\n\nAll channel objects have an asynchronous [`aclose`](reference-io#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") method. Memory channels can also be closed synchronously. This has the same effect on the channel and other tasks using it, but [`close`](#trio.MemorySendChannel.close \"trio.MemorySendChannel.close\") is not a trio checkpoint. This simplifies cleaning up in cancelled tasks.\n\nUsing `with`` ``send_channel:` will close the channel object on leaving the with block.\n\n### *`await`*` send(value: SendType) → None`\n\nSee [`SendChannel.send`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\").\n\nMemory channels allow multiple tasks to call [`send`](#trio.MemorySendChannel.send \"trio.MemorySendChannel.send\") at the same time.\n\n### `send_nowait(value: SendType) → None`\n\nLike [`send`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\"), but if the channel’s buffer is full, raises [`WouldBlock`](#trio.WouldBlock \"trio.WouldBlock\") instead of blocking.\n\n### *`class`*` trio.MemoryReceiveChannel(*args: object, **kwargs: object)`\n\n### `clone() → MemoryReceiveChannel[ReceiveType]`\n\nClone this receive channel object.\n\nThis returns a new [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel \"trio.MemoryReceiveChannel\") object, which acts as a duplicate of the original: receiving on the new object does exactly the same thing as receiving on the old object.\n\nHowever, closing one of the objects does not close the other, and the underlying channel is not closed until all clones are closed. (If you’re familiar with [`os.dup`](https://docs.python.org/3/library/os.html#os.dup \"(in Python v3.11)\"), then this is a similar idea.)\n\nThis is useful for communication patterns that involve multiple consumers all receiving objects from the same underlying channel. See [Managing multiple producers and/or multiple consumers](#channel-mpmc) for examples.\n\n> #### Warning\n>\n> The clones all share the same underlying channel. Whenever a clone [`receive()`](#trio.MemoryReceiveChannel.receive \"trio.MemoryReceiveChannel.receive\")s a value, it is removed from the channel and the other clones do *not* receive that value. If you want to send multiple copies of the same stream of values to multiple destinations, like [`itertools.tee()`](https://docs.python.org/3/library/itertools.html#itertools.tee \"(in Python v3.11)\"), then you need to find some other solution; this method does *not* do that.\n\n#### Raises:\n\n[**trio.ClosedResourceError**](#trio.ClosedResourceError \"trio.ClosedResourceError\") – if you already closed this [`MemoryReceiveChannel`](#trio.MemoryReceiveChannel \"trio.MemoryReceiveChannel\") object.\n\n### `close() → None`\n\nClose this receive channel object synchronously.\n\nAll channel objects have an asynchronous [`aclose`](reference-io#trio.abc.AsyncResource.aclose \"trio.abc.AsyncResource.aclose\") method. Memory channels can also be closed synchronously. This has the same effect on the channel and other tasks using it, but [`close`](#trio.MemoryReceiveChannel.close \"trio.MemoryReceiveChannel.close\") is not a trio checkpoint. This simplifies cleaning up in cancelled tasks.\n\nUsing `with`` ``receive_channel:` will close the channel object on leaving the with block.\n\n### *`await`*` receive() → ReceiveType`\n\nSee [`ReceiveChannel.receive`](reference-io#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\").\n\nMemory channels allow multiple tasks to call [`receive`](#trio.MemoryReceiveChannel.receive \"trio.MemoryReceiveChannel.receive\") at the same time. The first task will get the first item sent, the second task will get the second item sent, and so on.\n\n### `receive_nowait() → ReceiveType`\n\nLike [`receive`](reference-io#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\"), but if there’s nothing ready to receive, raises [`WouldBlock`](#trio.WouldBlock \"trio.WouldBlock\") instead of blocking.\n\n#### A simple channel example\n\nHere’s a simple example of how to use memory channels:\n\n``` python\nimport trio\n\n\nasync def main():\n    async with trio.open_nursery() as nursery:\n        # Open a channel:\n        send_channel, receive_channel = trio.open_memory_channel(0)\n        # Start a producer and a consumer, passing one end of the channel to\n        # each of them:\n        nursery.start_soon(producer, send_channel)\n        nursery.start_soon(consumer, receive_channel)\n\n\nasync def producer(send_channel):\n    # Producer sends 3 messages\n    for i in range(3):\n        # The producer sends using 'await send_channel.send(...)'\n        await send_channel.send(f\"message {i}\")\n\n\nasync def consumer(receive_channel):\n    # The consumer uses an 'async for' loop to receive the values:\n    async for value in receive_channel:\n        print(f\"got value {value!r}\")\n\n\ntrio.run(main)\n```\n\nIf you run this, it prints:\n\n    got value \"message 0\"\n    got value \"message 1\"\n    got value \"message 2\"\n\nAnd then it hangs forever. (Use control-C to quit.)\n\n#### Clean shutdown with channels\n\nOf course we don’t generally like it when programs hang. What happened? The problem is that the producer sent 3 messages and then exited, but the consumer has no way to tell that the producer is gone: for all it knows, another message might be coming along any moment. So it hangs forever waiting for the 4th message.\n\nHere’s a new version that fixes this: it produces the same output as the previous version, and then exits cleanly. The only change is the addition of `async`` ``with` blocks inside the producer and consumer:\n\n``` python\nimport trio\n\n\nasync def main():\n    async with trio.open_nursery() as nursery:\n        send_channel, receive_channel = trio.open_memory_channel(0)\n        nursery.start_soon(producer, send_channel)\n        nursery.start_soon(consumer, receive_channel)\n\n\nasync def producer(send_channel):\n    async with send_channel:\n        for i in range(3):\n            await send_channel.send(f\"message {i}\")\n\n\nasync def consumer(receive_channel):\n    async with receive_channel:\n        async for value in receive_channel:\n            print(f\"got value {value!r}\")\n\n\ntrio.run(main)\n```\n\nThe really important thing here is the producer’s `async`` ``with` . When the producer exits, this closes the `send_channel`, and that tells the consumer that no more messages are coming, so it can cleanly exit its `async`` ``for` loop. Then the program shuts down because both tasks have exited.\n\nWe also added an `async`` ``with` to the consumer. This isn’t as important, but it can help us catch mistakes or other problems. For example, suppose that the consumer exited early for some reason – maybe because of a bug. Then the producer would be sending messages into the void, and might get stuck indefinitely. But, if the consumer closes its `receive_channel`, then the producer will get a [`BrokenResourceError`](#trio.BrokenResourceError \"trio.BrokenResourceError\") to alert it that it should stop sending messages because no-one is listening.\n\nIf you want to see the effect of the consumer exiting early, try adding a `break` statement to the `async`` ``for` loop – you should see a [`BrokenResourceError`](#trio.BrokenResourceError \"trio.BrokenResourceError\") from the producer.\n\n#### Managing multiple producers and/or multiple consumers\n\nYou can also have multiple producers, and multiple consumers, all sharing the same channel. However, this makes shutdown a little more complicated.\n\nFor example, consider this naive extension of our previous example, now with two producers and two consumers:\n\n``` python\n# This example usually crashes!\n\nimport trio\nimport random\n\n\nasync def main():\n    async with trio.open_nursery() as nursery:\n        send_channel, receive_channel = trio.open_memory_channel(0)\n        # Start two producers\n        nursery.start_soon(producer, \"A\", send_channel)\n        nursery.start_soon(producer, \"B\", send_channel)\n        # And two consumers\n        nursery.start_soon(consumer, \"X\", receive_channel)\n        nursery.start_soon(consumer, \"Y\", receive_channel)\n\n\nasync def producer(name, send_channel):\n    async with send_channel:\n        for i in range(3):\n            await send_channel.send(f\"{i} from producer {name}\")\n            # Random sleeps help trigger the problem more reliably\n            await trio.sleep(random.random())\n\n\nasync def consumer(name, receive_channel):\n    async with receive_channel:\n        async for value in receive_channel:\n            print(f\"consumer {name} got value {value!r}\")\n            # Random sleeps help trigger the problem more reliably\n            await trio.sleep(random.random())\n\n\ntrio.run(main)\n```\n\nThe two producers, A and B, send 3 messages apiece. These are then randomly distributed between the two consumers, X and Y. So we’re hoping to see some output like:\n\n    consumer Y got value '0 from producer B'\n    consumer X got value '0 from producer A'\n    consumer Y got value '1 from producer A'\n    consumer Y got value '1 from producer B'\n    consumer X got value '2 from producer B'\n    consumer X got value '2 from producer A'\n\nHowever, on most runs, that’s not what happens – the first part of the output is OK, and then when we get to the end the program crashes with [`ClosedResourceError`](#trio.ClosedResourceError \"trio.ClosedResourceError\"). If you run the program a few times, you’ll see that sometimes the traceback shows `send` crashing, and other times it shows `receive` crashing, and you might even find that on some runs it doesn’t crash at all.\n\nHere’s what’s happening: suppose that producer A finishes first. It exits, and its `async`` ``with` block closes the `send_channel`. But wait! Producer B was still using that `send_channel`… so the next time B calls `send`, it gets a [`ClosedResourceError`](#trio.ClosedResourceError \"trio.ClosedResourceError\").\n\nSometimes, though if we’re lucky, the two producers might finish at the same time (or close enough), so they both make their last `send` before either of them closes the `send_channel`.\n\nBut, even if that happens, we’re not out of the woods yet! After the producers exit, the two consumers race to be the first to notice that the `send_channel` has closed. Suppose that X wins the race. It exits its `async`` ``for` loop, then exits the `async`` ``with` block… and closes the `receive_channel`, while Y is still using it. Again, this causes a crash.\n\nWe could avoid this by using some complicated bookkeeping to make sure that only the *last* producer and the *last* consumer close their channel endpoints… but that would be tiresome and fragile. Fortunately, there’s a better way! Here’s a fixed version of our program above:\n\n``` python\nimport trio\nimport random\n\n\nasync def main():\n    async with trio.open_nursery() as nursery:\n        send_channel, receive_channel = trio.open_memory_channel(0)\n        async with send_channel, receive_channel:\n            # Start two producers, giving each its own private clone\n            nursery.start_soon(producer, \"A\", send_channel.clone())\n            nursery.start_soon(producer, \"B\", send_channel.clone())\n            # And two consumers, giving each its own private clone\n            nursery.start_soon(consumer, \"X\", receive_channel.clone())\n            nursery.start_soon(consumer, \"Y\", receive_channel.clone())\n\n\nasync def producer(name, send_channel):\n    async with send_channel:\n        for i in range(3):\n            await send_channel.send(f\"{i} from producer {name}\")\n            # Random sleeps help trigger the problem more reliably\n            await trio.sleep(random.random())\n\n\nasync def consumer(name, receive_channel):\n    async with receive_channel:\n        async for value in receive_channel:\n            print(f\"consumer {name} got value {value!r}\")\n            # Random sleeps help trigger the problem more reliably\n            await trio.sleep(random.random())\n\n\ntrio.run(main)\n```\n\nThis example demonstrates using the [`MemorySendChannel.clone`](#trio.MemorySendChannel.clone \"trio.MemorySendChannel.clone\") and [`MemoryReceiveChannel.clone`](#trio.MemoryReceiveChannel.clone \"trio.MemoryReceiveChannel.clone\") methods. What these do is create copies of our endpoints, that act just like the original – except that they can be closed independently. And the underlying channel is only closed after *all* the clones have been closed. So this completely solves our problem with shutdown, and if you run this program, you’ll see it print its six lines of output and then exits cleanly.\n\nNotice a small trick we use: the code in `main` creates clone objects to pass into all the child tasks, and then closes the original objects using `async`` ``with`. Another option is to pass clones into all-but-one of the child tasks, and then pass the original object into the last task, like:\n\n``` python\n# Also works, but is more finicky:\nsend_channel, receive_channel = trio.open_memory_channel(0)\nnursery.start_soon(producer, \"A\", send_channel.clone())\nnursery.start_soon(producer, \"B\", send_channel)\nnursery.start_soon(consumer, \"X\", receive_channel.clone())\nnursery.start_soon(consumer, \"Y\", receive_channel)\n```\n\nBut this is more error-prone, especially if you use a loop to spawn the producers/consumers.\n\nJust make sure that you don’t write:\n\n``` python\n# Broken, will cause program to hang:\nsend_channel, receive_channel = trio.open_memory_channel(0)\nnursery.start_soon(producer, \"A\", send_channel.clone())\nnursery.start_soon(producer, \"B\", send_channel.clone())\nnursery.start_soon(consumer, \"X\", receive_channel.clone())\nnursery.start_soon(consumer, \"Y\", receive_channel.clone())\n```\n\nHere we pass clones into the tasks, but never close the original objects. That means we have 3 send channel objects (the original + two clones), but we only close 2 of them, so the consumers will hang around forever waiting for that last one to be closed.\n\n#### Buffering in channels\n\nWhen you call [`open_memory_channel()`](#trio.open_memory_channel \"trio.open_memory_channel\"), you have to specify how many values can be buffered internally in the channel. If the buffer is full, then any task that calls [`send()`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") will stop and wait for another task to call [`receive()`](reference-io#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\"). This is useful because it produces *backpressure*: if the channel producers are running faster than the consumers, then it forces the producers to slow down.\n\nYou can disable buffering entirely, by doing `open_memory_channel(0)`. In that case any task that calls [`send()`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") will wait until another task calls [`receive()`](reference-io#trio.abc.ReceiveChannel.receive \"trio.abc.ReceiveChannel.receive\"), and vice versa. This is similar to how channels work in the [classic Communicating Sequential Processes model](https://en.wikipedia.org/wiki/Channel_(programming)), and is a reasonable default if you aren’t sure what size buffer to use. (That’s why we used it in the examples above.)\n\nAt the other extreme, you can make the buffer unbounded by using `open_memory_channel(math.inf)`. In this case, [`send()`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") *always* returns immediately. Normally, this is a bad idea. To see why, consider a program where the producer runs more quickly than the consumer:\n\n``` python\n# Simulate a producer that generates values 10x faster than the\n# consumer can handle them.\n\nimport trio\nimport math\n\n\nasync def producer(send_channel):\n    count = 0\n    while True:\n        # Pretend that we have to do some work to create this message, and it\n        # takes 0.1 seconds:\n        await trio.sleep(0.1)\n        await send_channel.send(count)\n        print(\"Sent message:\", count)\n        count += 1\n\n\nasync def consumer(receive_channel):\n    async for value in receive_channel:\n        print(\"Received message:\", value)\n        # Pretend that we have to do some work to handle this message, and it\n        # takes 1 second\n        await trio.sleep(1)\n\n\nasync def main():\n    send_channel, receive_channel = trio.open_memory_channel(math.inf)\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(producer, send_channel)\n        nursery.start_soon(consumer, receive_channel)\n\n\ntrio.run(main)\n```\n\nIf you run this program, you’ll see output like:\n\n    Sent message: 0\n    Received message: 0\n    Sent message: 1\n    Sent message: 2\n    Sent message: 3\n    Sent message: 4\n    Sent message: 5\n    Sent message: 6\n    Sent message: 7\n    Sent message: 8\n    Sent message: 9\n    Received message: 1\n    Sent message: 10\n    Sent message: 11\n    Sent message: 12\n    ...\n\nOn average, the producer sends ten messages per second, but the consumer only calls `receive` once per second. That means that each second, the channel’s internal buffer has to grow to hold an extra nine items. After a minute, the buffer will have ~540 items in it; after an hour, that grows to ~32,400. Eventually, the program will run out of memory. And well before we run out of memory, our latency on handling individual messages will become abysmal. For example, at the one minute mark, the producer is sending message ~600, but the consumer is still processing message ~60. Message 600 will have to sit in the channel for ~9 minutes before the consumer catches up and processes it.\n\nNow try replacing `open_memory_channel(math.inf)` with `open_memory_channel(0)`, and run it again. We get output like:\n\n    Sent message: 0\n    Received message: 0\n    Received message: 1\n    Sent message: 1\n    Received message: 2\n    Sent message: 2\n    Sent message: 3\n    Received message: 3\n    ...\n\nNow the `send` calls wait for the `receive` calls to finish, which forces the producer to slow down to match the consumer’s speed. (It might look strange that some values are reported as “Received” before they’re reported as “Sent”; this happens because the actual send/receive happen at the same time, so which line gets printed first is random.)\n\nNow, let’s try setting a small but nonzero buffer size, like `open_memory_channel(3)`. what do you think will happen?\n\nI get:\n\n    Sent message: 0\n    Received message: 0\n    Sent message: 1\n    Sent message: 2\n    Sent message: 3\n    Received message: 1\n    Sent message: 4\n    Received message: 2\n    Sent message: 5\n    ...\n\nSo you can see that the producer runs ahead by 3 messages, and then stops to wait: when the consumer reads message 1, it sends message 4, then when the consumer reads message 2, it sends message 5, and so on. Once it reaches the steady state, this version acts just like our previous version where we set the buffer size to 0, except that it uses a bit more memory and each message sits in the buffer for a bit longer before being processed (i.e., the message latency is higher).\n\nOf course real producers and consumers are usually more complicated than this, and in some situations, a modest amount of buffering might improve throughput. But too much buffering wastes memory and increases latency, so if you want to tune your application you should experiment to see what value works best for you.\n\n**Why do we even support unbounded buffers then?** Good question! Despite everything we saw above, there are times when you actually do need an unbounded buffer. For example, consider a web crawler that uses a channel to keep track of all the URLs it still wants to crawl. Each crawler runs a loop where it takes a URL from the channel, fetches it, checks the HTML for outgoing links, and then adds the new URLs to the channel. This creates a *circular flow*, where each consumer is also a producer. In this case, if your channel buffer gets full, then the crawlers will block when they try to add new URLs to the channel, and if all the crawlers got blocked, then they aren’t taking any URLs out of the channel, so they’re stuck forever in a deadlock. Using an unbounded channel avoids this, because it means that [`send()`](reference-io#trio.abc.SendChannel.send \"trio.abc.SendChannel.send\") never blocks.\n\n### Lower-level synchronization primitives\n\nPersonally, I find that events and channels are usually enough to implement most things I care about, and lead to easier to read code than the lower-level primitives discussed in this section. But if you need them, they’re here. (If you find yourself reaching for these because you’re trying to implement a new higher-level synchronization primitive, then you might also want to check out the facilities in [`trio.lowlevel`](reference-lowlevel#module-trio.lowlevel \"trio.lowlevel\") for a more direct exposure of Trio’s underlying synchronization logic. All of classes discussed in this section are implemented on top of the public APIs in [`trio.lowlevel`](reference-lowlevel#module-trio.lowlevel \"trio.lowlevel\"); they don’t have any special access to Trio’s internals.)\n\n### *`class`*` trio.CapacityLimiter(total_tokens)`\n\nAn object for controlling access to a resource with limited capacity.\n\nSometimes you need to put a limit on how many tasks can do something at the same time. For example, you might want to use some threads to run multiple blocking I/O operations in parallel… but if you use too many threads at once, then your system can become overloaded and it’ll actually make things slower. One popular solution is to impose a policy like “run up to 40 threads at the same time, but no more”. But how do you implement a policy like this?\n\nThat’s what [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") is for. You can think of a [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") object as a sack that starts out holding some fixed number of tokens:\n\n``` python\nlimit = trio.CapacityLimiter(40)\n```\n\nThen tasks can come along and borrow a token out of the sack:\n\n``` python\n# Borrow a token:\nasync with limit:\n    # We are holding a token!\n    await perform_expensive_operation()\n# Exiting the 'async with' block puts the token back into the sack\n```\n\nAnd crucially, if you try to borrow a token but the sack is empty, then you have to wait for another task to finish what it’s doing and put its token back first before you can take it and continue.\n\nAnother way to think of it: a [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") is like a sofa with a fixed number of seats, and if they’re all taken then you have to wait for someone to get up before you can sit down.\n\nBy default, [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\") uses a [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") to limit the number of threads running at once; see [`trio.to_thread.current_default_thread_limiter`](#trio.to_thread.current_default_thread_limiter \"trio.to_thread.current_default_thread_limiter\") for details.\n\nIf you’re familiar with semaphores, then you can think of this as a restricted semaphore that’s specialized for one common use case, with additional error checking. For a more traditional semaphore, see [`Semaphore`](#trio.Semaphore \"trio.Semaphore\").\n\n> #### Note\n>\n> Don’t confuse this with the [“leaky bucket”](https://en.wikipedia.org/wiki/Leaky_bucket) or [“token bucket”](https://en.wikipedia.org/wiki/Token_bucket) algorithms used to limit bandwidth usage on networks. The basic idea of using tokens to track a resource limit is similar, but this is a very simple sack where tokens aren’t automatically created or destroyed over time; they’re just borrowed and then put back.\n\n### *`await`*` acquire()`\n\nBorrow a token from the sack, blocking if necessary.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the current task already holds one of this sack’s tokens.\n\n### `acquire_nowait()`\n\nBorrow a token from the sack, without blocking.\n\n#### Raises:\n\n- [**WouldBlock**](#trio.WouldBlock \"trio.WouldBlock\") – if no tokens are available.\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the current task already holds one of this sack’s tokens.\n\n### *`await`*` acquire_on_behalf_of(borrower)`\n\nBorrow a token from the sack on behalf of `borrower`, blocking if necessary.\n\n#### Parameters:\n\n**borrower** – A [`trio.lowlevel.Task`](reference-lowlevel#trio.lowlevel.Task \"trio.lowlevel.Task\") or arbitrary opaque object used to record who is borrowing this token; see [`acquire_on_behalf_of_nowait()`](#trio.CapacityLimiter.acquire_on_behalf_of_nowait \"trio.CapacityLimiter.acquire_on_behalf_of_nowait\") for details.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if `borrower` task already holds one of this sack’s tokens.\n\n### `acquire_on_behalf_of_nowait(borrower)`\n\nBorrow a token from the sack on behalf of `borrower`, without blocking.\n\n#### Parameters:\n\n**borrower** – A [`trio.lowlevel.Task`](reference-lowlevel#trio.lowlevel.Task \"trio.lowlevel.Task\") or arbitrary opaque object used to record who is borrowing this token. This is used by [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\") to allow threads to “hold tokens”, with the intention in the future of using it to [allow deadlock detection and other useful things](https://github.com/python-trio/trio/issues/182)\n\n#### Raises:\n\n- [**WouldBlock**](#trio.WouldBlock \"trio.WouldBlock\") – if no tokens are available.\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if `borrower` already holds one of this sack’s tokens.\n\n### *`property`*` available_tokens`\n\nThe amount of capacity that’s available to use.\n\n### *`property`*` borrowed_tokens`\n\nThe amount of capacity that’s currently in use.\n\n### `release()`\n\nPut a token back into the sack.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the current task has not acquired one of this sack’s tokens.\n\n### `release_on_behalf_of(borrower)`\n\nPut a token back into the sack on behalf of `borrower`.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the given borrower has not acquired one of this sack’s tokens.\n\n### `statistics()`\n\nReturn an object containing debugging information.\n\nCurrently the following fields are defined:\n\n- `borrowed_tokens`: The number of tokens currently borrowed from the sack.\n\n- `total_tokens`: The total number of tokens in the sack. Usually this will be larger than `borrowed_tokens`, but it’s possibly for it to be smaller if [`total_tokens`](#trio.CapacityLimiter.total_tokens \"trio.CapacityLimiter.total_tokens\") was recently decreased.\n\n- `borrowers`: A list of all tasks or other entities that currently hold a token.\n\n- `tasks_waiting`: The number of tasks blocked on this [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\")’s [`acquire()`](#trio.CapacityLimiter.acquire \"trio.CapacityLimiter.acquire\") or [`acquire_on_behalf_of()`](#trio.CapacityLimiter.acquire_on_behalf_of \"trio.CapacityLimiter.acquire_on_behalf_of\") methods.\n\n### *`property`*` total_tokens`\n\nThe total capacity available.\n\nYou can change [`total_tokens`](#trio.CapacityLimiter.total_tokens \"trio.CapacityLimiter.total_tokens\") by assigning to this attribute. If you make it larger, then the appropriate number of waiting tasks will be woken immediately to take the new tokens. If you decrease total_tokens below the number of tasks that are currently using the resource, then all current tasks will be allowed to finish as normal, but no new tasks will be allowed in until the total number of tasks drops below the new total_tokens.\n\n### *`class`*` trio.Semaphore(initial_value, *, max_value=None)`\n\nA [semaphore](https://en.wikipedia.org/wiki/Semaphore_(programming)).\n\nA semaphore holds an integer value, which can be incremented by calling [`release()`](#trio.Semaphore.release \"trio.Semaphore.release\") and decremented by calling [`acquire()`](#trio.Semaphore.acquire \"trio.Semaphore.acquire\") – but the value is never allowed to drop below zero. If the value is zero, then [`acquire()`](#trio.Semaphore.acquire \"trio.Semaphore.acquire\") will block until someone calls [`release()`](#trio.Semaphore.release \"trio.Semaphore.release\").\n\nIf you’re looking for a [`Semaphore`](#trio.Semaphore \"trio.Semaphore\") to limit the number of tasks that can access some resource simultaneously, then consider using a [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") instead.\n\nThis object’s interface is similar to, but different from, that of [`threading.Semaphore`](https://docs.python.org/3/library/threading.html#threading.Semaphore \"(in Python v3.11)\").\n\nA [`Semaphore`](#trio.Semaphore \"trio.Semaphore\") object can be used as an async context manager; it blocks on entry but not on exit.\n\n#### Parameters:\n\n- **initial_value** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – A non-negative integer giving semaphore’s initial value.\n\n- **max_value** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\") *or* *None*) – If given, makes this a “bounded” semaphore that raises an error if the value is about to exceed the given `max_value`.\n\n### *`await`*` acquire()`\n\nDecrement the semaphore value, blocking if necessary to avoid letting it drop below zero.\n\n### `acquire_nowait()`\n\nAttempt to decrement the semaphore value, without blocking.\n\n#### Raises:\n\n[**WouldBlock**](#trio.WouldBlock \"trio.WouldBlock\") – if the value is zero.\n\n### *`property`*` max_value`\n\nThe maximum allowed value. May be None to indicate no limit.\n\n### `release()`\n\nIncrement the semaphore value, possibly waking a task blocked in [`acquire()`](#trio.Semaphore.acquire \"trio.Semaphore.acquire\").\n\n#### Raises:\n\n[**ValueError**](https://docs.python.org/3/library/exceptions.html#ValueError \"(in Python v3.11)\") – if incrementing the value would cause it to exceed [`max_value`](#trio.Semaphore.max_value \"trio.Semaphore.max_value\").\n\n### `statistics()`\n\nReturn an object containing debugging information.\n\nCurrently the following fields are defined:\n\n- `tasks_waiting`: The number of tasks blocked on this semaphore’s [`acquire()`](#trio.Semaphore.acquire \"trio.Semaphore.acquire\") method.\n\n### *`property`*` value`\n\nThe current value of the semaphore.\n\n### *`class`*` trio.Lock`\n\nA classic [mutex](https://en.wikipedia.org/wiki/Lock_(computer_science)).\n\nThis is a non-reentrant, single-owner lock. Unlike [`threading.Lock`](https://docs.python.org/3/library/threading.html#threading.Lock \"(in Python v3.11)\"), only the owner of the lock is allowed to release it.\n\nA [`Lock`](#trio.Lock \"trio.Lock\") object can be used as an async context manager; it blocks on entry but not on exit.\n\n### *`await`*` acquire()`\n\nAcquire the lock, blocking if necessary.\n\n### `acquire_nowait()`\n\nAttempt to acquire the lock, without blocking.\n\n#### Raises:\n\n[**WouldBlock**](#trio.WouldBlock \"trio.WouldBlock\") – if the lock is held.\n\n### `locked()`\n\nCheck whether the lock is currently held.\n\n#### Returns:\n\nTrue if the lock is held, False otherwise.\n\n#### Return type:\n\n[bool](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")\n\n### `release()`\n\nRelease the lock.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the calling task does not hold the lock.\n\n### `statistics()`\n\nReturn an object containing debugging information.\n\nCurrently the following fields are defined:\n\n- `locked`: boolean indicating whether the lock is held.\n\n- `owner`: the [`trio.lowlevel.Task`](reference-lowlevel#trio.lowlevel.Task \"trio.lowlevel.Task\") currently holding the lock, or None if the lock is not held.\n\n- `tasks_waiting`: The number of tasks blocked on this lock’s [`acquire()`](#trio.Lock.acquire \"trio.Lock.acquire\") method.\n\n### *`class`*` trio.StrictFIFOLock`\n\nA variant of [`Lock`](#trio.Lock \"trio.Lock\") where tasks are guaranteed to acquire the lock in strict first-come-first-served order.\n\nAn example of when this is useful is if you’re implementing something like [`trio.SSLStream`](reference-io#trio.SSLStream \"trio.SSLStream\") or an HTTP/2 server using [h2](https://hyper-h2.readthedocs.io/), where you have multiple concurrent tasks that are interacting with a shared state machine, and at unpredictable moments the state machine requests that a chunk of data be sent over the network. (For example, when using h2 simply reading incoming data can occasionally [create outgoing data to send](https://http2.github.io/http2-spec/#PING).) The challenge is to make sure that these chunks are sent in the correct order, without being garbled.\n\nOne option would be to use a regular [`Lock`](#trio.Lock \"trio.Lock\"), and wrap it around every interaction with the state machine:\n\n``` python\n# This approach is sometimes workable but often sub-optimal; see below\nasync with lock:\n    state_machine.do_something()\n    if state_machine.has_data_to_send():\n        await conn.sendall(state_machine.get_data_to_send())\n```\n\nBut this can be problematic. If you’re using h2 then *usually* reading incoming data doesn’t create the need to send any data, so we don’t want to force every task that tries to read from the network to sit and wait a potentially long time for `sendall` to finish. And in some situations this could even potentially cause a deadlock, if the remote peer is waiting for you to read some data before it accepts the data you’re sending.\n\n[`StrictFIFOLock`](#trio.StrictFIFOLock \"trio.StrictFIFOLock\") provides an alternative. We can rewrite our example like:\n\n``` python\n# Note: no awaits between when we start using the state machine and\n# when we block to take the lock!\nstate_machine.do_something()\nif state_machine.has_data_to_send():\n    # Notice that we fetch the data to send out of the state machine\n    # *before* sleeping, so that other tasks won't see it.\n    chunk = state_machine.get_data_to_send()\n    async with strict_fifo_lock:\n        await conn.sendall(chunk)\n```\n\nFirst we do all our interaction with the state machine in a single scheduling quantum (notice there are no `await`s in there), so it’s automatically atomic with respect to other tasks. And then if and only if we have data to send, we get in line to send it – and [`StrictFIFOLock`](#trio.StrictFIFOLock \"trio.StrictFIFOLock\") guarantees that each task will send its data in the same order that the state machine generated it.\n\nCurrently, [`StrictFIFOLock`](#trio.StrictFIFOLock \"trio.StrictFIFOLock\") is identical to [`Lock`](#trio.Lock \"trio.Lock\"), but (a) this may not always be true in the future, especially if Trio ever implements [more sophisticated scheduling policies](https://github.com/python-trio/trio/issues/32), and (b) the above code is relying on a pretty subtle property of its lock. Using a [`StrictFIFOLock`](#trio.StrictFIFOLock \"trio.StrictFIFOLock\") acts as an executable reminder that you’re relying on this property.\n\n### *`class`*` trio.Condition(lock=None)`\n\nA classic [condition variable](https://en.wikipedia.org/wiki/Monitor_(synchronization)), similar to [`threading.Condition`](https://docs.python.org/3/library/threading.html#threading.Condition \"(in Python v3.11)\").\n\nA [`Condition`](#trio.Condition \"trio.Condition\") object can be used as an async context manager to acquire the underlying lock; it blocks on entry but not on exit.\n\n#### Parameters:\n\n**lock** ([*Lock*](#trio.Lock \"trio.Lock\")) – the lock object to use. If given, must be a [`trio.Lock`](#trio.Lock \"trio.Lock\"). If None, a new [`Lock`](#trio.Lock \"trio.Lock\") will be allocated and used.\n\n### *`await`*` acquire()`\n\nAcquire the underlying lock, blocking if necessary.\n\n### `acquire_nowait()`\n\nAttempt to acquire the underlying lock, without blocking.\n\n#### Raises:\n\n[**WouldBlock**](#trio.WouldBlock \"trio.WouldBlock\") – if the lock is currently held.\n\n### `locked()`\n\nCheck whether the underlying lock is currently held.\n\n#### Returns:\n\nTrue if the lock is held, False otherwise.\n\n#### Return type:\n\n[bool](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")\n\n### `notify(n=1)`\n\nWake one or more tasks that are blocked in [`wait()`](#trio.Condition.wait \"trio.Condition.wait\").\n\n#### Parameters:\n\n**n** ([*int*](https://docs.python.org/3/library/functions.html#int \"(in Python v3.11)\")) – The number of tasks to wake.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the calling task does not hold the lock.\n\n### `notify_all()`\n\nWake all tasks that are currently blocked in [`wait()`](#trio.Condition.wait \"trio.Condition.wait\").\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the calling task does not hold the lock.\n\n### `release()`\n\nRelease the underlying lock.\n\n### `statistics()`\n\nReturn an object containing debugging information.\n\nCurrently the following fields are defined:\n\n- `tasks_waiting`: The number of tasks blocked on this condition’s [`wait()`](#trio.Condition.wait \"trio.Condition.wait\") method.\n\n- `lock_statistics`: The result of calling the underlying [`Lock`](#trio.Lock \"trio.Lock\")s [`statistics()`](#trio.Lock.statistics \"trio.Lock.statistics\") method.\n\n### *`await`*` wait()`\n\nWait for another task to call [`notify()`](#trio.Condition.notify \"trio.Condition.notify\") or [`notify_all()`](#trio.Condition.notify_all \"trio.Condition.notify_all\").\n\nWhen calling this method, you must hold the lock. It releases the lock while waiting, and then re-acquires it before waking up.\n\nThere is a subtlety with how this method interacts with cancellation: when cancelled it will block to re-acquire the lock before raising [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"). This may cause cancellation to be less prompt than expected. The advantage is that it makes code like this work:\n\n``` python\nasync with condition:\n    await condition.wait()\n```\n\nIf we didn’t re-acquire the lock before waking up, and [`wait()`](#trio.Condition.wait \"trio.Condition.wait\") were cancelled here, then we’d crash in `condition.__aexit__` when we tried to release the lock we no longer held.\n\n#### Raises:\n\n[**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if the calling task does not hold the lock.\n\n## Notes on async generators\n\nPython 3.6 added support for *async generators*, which can use `await`, `async`` ``for`, and `async`` ``with` in between their `yield` statements. As you might expect, you use `async`` ``for` to iterate over them. [**PEP 525**](https://peps.python.org/pep-0525/) has many more details if you want them.\n\nFor example, the following is a roundabout way to print the numbers 0 through 9 with a 1-second delay before each one:\n\n``` python\nasync def range_slowly(*args):\n    \"\"\"Like range(), but adds a 1-second sleep before each value.\"\"\"\n    for value in range(*args):\n        await trio.sleep(1)\n        yield value\n\nasync def use_it():\n    async for value in range_slowly(10):\n        print(value)\n\ntrio.run(use_it)\n```\n\nTrio supports async generators, with some caveats described in this section.\n\n### Finalization\n\nIf you iterate over an async generator in its entirety, like the example above does, then the execution of the async generator will occur completely in the context of the code that’s iterating over it, and there aren’t too many surprises.\n\nIf you abandon a partially-completed async generator, though, such as by `break`ing out of the iteration, things aren’t so simple. The async generator iterator object is still alive, waiting for you to resume iterating it so it can produce more values. At some point, Python will realize that you’ve dropped all references to the iterator, and will call on Trio to throw in a [`GeneratorExit`](https://docs.python.org/3/library/exceptions.html#GeneratorExit \"(in Python v3.11)\") exception so that any remaining cleanup code inside the generator has a chance to run: `finally` blocks, `__aexit__` handlers, and so on.\n\nSo far, so good. Unfortunately, Python provides no guarantees about *when* this happens. It could be as soon as you break out of the `async`` ``for` loop, or an arbitrary amount of time later. It could even be after the entire Trio run has finished! Just about the only guarantee is that it *won’t* happen in the task that was using the generator. That task will continue on with whatever else it’s doing, and the async generator cleanup will happen “sometime later, somewhere else”: potentially with different context variables, not subject to timeouts, and/or after any nurseries you’re using have been closed.\n\nIf you don’t like that ambiguity, and you want to ensure that a generator’s `finally` blocks and `__aexit__` handlers execute as soon as you’re done using it, then you’ll need to wrap your use of the generator in something like [async_generator.aclosing()](https://async-generator.readthedocs.io/en/latest/reference.html#context-managers):\n\n``` python\n# Instead of this:\nasync for value in my_generator():\n    if value == 42:\n        break\n\n# Do this:\nasync with aclosing(my_generator()) as aiter:\n    async for value in aiter:\n        if value == 42:\n            break\n```\n\nThis is cumbersome, but Python unfortunately doesn’t provide any other reliable options. If you use `aclosing()`, then your generator’s cleanup code executes in the same context as the rest of its iterations, so timeouts, exceptions, and context variables work like you’d expect.\n\nIf you don’t use `aclosing()`, then Trio will do its best anyway, but you’ll have to contend with the following semantics:\n\n- The cleanup of the generator occurs in a cancelled context, i.e., all blocking calls executed during cleanup will raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"). This is to compensate for the fact that any timeouts surrounding the original use of the generator have been long since forgotten.\n\n- The cleanup runs without access to any [context variables](#task-local-storage) that may have been present when the generator was originally being used.\n\n- If the generator raises an exception during cleanup, then it’s printed to the `trio.async_generator_errors` logger and otherwise ignored.\n\n- If an async generator is still alive at the end of the whole call to [`trio.run()`](#trio.run \"trio.run\"), then it will be cleaned up after all tasks have exited and before [`trio.run()`](#trio.run \"trio.run\") returns. Since the “system nursery” has already been closed at this point, Trio isn’t able to support any new calls to [`trio.lowlevel.spawn_system_task()`](reference-lowlevel#trio.lowlevel.spawn_system_task \"trio.lowlevel.spawn_system_task\").\n\nIf you plan to run your code on PyPy to take advantage of its better performance, you should be aware that PyPy is *far more likely* than CPython to perform async generator cleanup at a time well after the last use of the generator. (This is a consequence of the fact that PyPy does not use reference counting to manage memory.) To help catch issues like this, Trio will issue a [`ResourceWarning`](https://docs.python.org/3/library/exceptions.html#ResourceWarning \"(in Python v3.11)\") (ignored by default, but enabled when running under `python`` ``-X`` ``dev` for example) for each async generator that needs to be handled through the fallback finalization path.\n\n### Cancel scopes and nurseries\n\n> #### Warning\n>\n> You may not write a `yield` statement that suspends an async generator inside a [`CancelScope`](#trio.CancelScope \"trio.CancelScope\") or [`Nursery`](#trio.Nursery \"trio.Nursery\") that was entered within the generator.\n\nThat is, this is OK:\n\n``` python\nasync def some_agen():\n    with trio.move_on_after(1):\n        await long_operation()\n    yield \"first\"\n    async with trio.open_nursery() as nursery:\n        nursery.start_soon(task1)\n        nursery.start_soon(task2)\n    yield \"second\"\n    ...\n```\n\nBut this is not:\n\n``` python\nasync def some_agen():\n    with trio.move_on_after(1):\n        yield \"first\"\n    async with trio.open_nursery() as nursery:\n        yield \"second\"\n    ...\n```\n\nAsync generators decorated with `@asynccontextmanager` to serve as the template for an async context manager are *not* subject to this constraint, because `@asynccontextmanager` uses them in a limited way that doesn’t create problems.\n\nViolating the rule described in this section will sometimes get you a useful error message, but Trio is not able to detect all such cases, so sometimes you’ll get an unhelpful [`TrioInternalError`](#trio.TrioInternalError \"trio.TrioInternalError\"). (And sometimes it will seem to work, which is probably the worst outcome of all, since then you might not notice the issue until you perform some minor refactoring of the generator or the code that’s iterating it, or just get unlucky. There is a [proposed Python enhancement](https://discuss.python.org/t/preventing-yield-inside-certain-context-managers/1091) that would at least make it fail consistently.)\n\nThe reason for the restriction on cancel scopes has to do with the difficulty of noticing when a generator gets suspended and resumed. The cancel scopes inside the generator shouldn’t affect code running outside the generator, but Trio isn’t involved in the process of exiting and reentering the generator, so it would be hard pressed to keep its cancellation plumbing in the correct state. Nurseries use a cancel scope internally, so they have all the problems of cancel scopes plus a number of problems of their own: for example, when the generator is suspended, what should the background tasks do? There’s no good way to suspend them, but if they keep running and throw an exception, where can that exception be reraised?\n\nIf you have an async generator that wants to `yield` from within a nursery or cancel scope, your best bet is to refactor it to be a separate task that communicates over memory channels. The `trio_util` package offers a [decorator that does this for you transparently](https://trio-util.readthedocs.io/en/latest/#trio_util.trio_async_generator).\n\nFor more discussion, see Trio issues [264](https://github.com/python-trio/trio/issues/264) (especially [this comment](https://github.com/python-trio/trio/issues/264#issuecomment-418989328)) and [638](https://github.com/python-trio/trio/issues/638).\n\n## Threads (if you must)\n\nIn a perfect world, all third-party libraries and low-level APIs would be natively async and integrated into Trio, and all would be happiness and rainbows.\n\nThat world, alas, does not (yet) exist. Until it does, you may find yourself needing to interact with non-Trio APIs that do rude things like “blocking”.\n\nIn acknowledgment of this reality, Trio provides two useful utilities for working with real, operating-system level, [`threading`](https://docs.python.org/3/library/threading.html#module-threading \"(in Python v3.11)\")-module-style threads. First, if you’re in Trio but need to push some blocking I/O into a thread, there’s [`trio.to_thread.run_sync`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\"). And if you’re in a thread and need to communicate back with Trio, you can use [`trio.from_thread.run()`](#trio.from_thread.run \"trio.from_thread.run\") and [`trio.from_thread.run_sync()`](#trio.from_thread.run_sync \"trio.from_thread.run_sync\").\n\n### Trio’s philosophy about managing worker threads\n\nIf you’ve used other I/O frameworks, you may have encountered the concept of a “thread pool”, which is most commonly implemented as a fixed size collection of threads that hang around waiting for jobs to be assigned to them. These solve two different problems: First, re-using the same threads over and over is more efficient than starting and stopping a new thread for every job you need done; basically, the pool acts as a kind of cache for idle threads. And second, having a fixed size avoids getting into a situation where 100,000 jobs are submitted simultaneously, and then 100,000 threads are spawned and the system gets overloaded and crashes. Instead, the N threads start executing the first N jobs, while the other (100,000 - N) jobs sit in a queue and wait their turn. Which is generally what you want, and this is how [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\") works by default.\n\nThe downside of this kind of thread pool is that sometimes, you need more sophisticated logic for controlling how many threads are run at once. For example, you might want a policy like “at most 20 threads total, but no more than 3 of those can be running jobs associated with the same user account”, or you might want a pool whose size is dynamically adjusted over time in response to system conditions.\n\nIt’s even possible for a fixed-size policy to cause unexpected [deadlocks](https://en.wikipedia.org/wiki/Deadlock). Imagine a situation where we have two different types of blocking jobs that you want to run in the thread pool, type A and type B. Type A is pretty simple: it just runs and completes pretty quickly. But type B is more complicated: it has to stop in the middle and wait for some other work to finish, and that other work includes running a type A job. Now, suppose you submit N jobs of type B to the pool. They all start running, and then eventually end up submitting one or more jobs of type A. But since every thread in our pool is already busy, the type A jobs don’t actually start running – they just sit in a queue waiting for the type B jobs to finish. But the type B jobs will never finish, because they’re waiting for the type A jobs. Our system has deadlocked. The ideal solution to this problem is to avoid having type B jobs in the first place – generally it’s better to keep complex synchronization logic in the main Trio thread. But if you can’t do that, then you need a custom thread allocation policy that tracks separate limits for different types of jobs, and make it impossible for type B jobs to fill up all the slots that type A jobs need to run.\n\nSo, we can see that it’s important to be able to change the policy controlling the allocation of threads to jobs. But in many frameworks, this requires implementing a new thread pool from scratch, which is highly non-trivial; and if different types of jobs need different policies, then you may have to create multiple pools, which is inefficient because now you effectively have two different thread caches that aren’t sharing resources.\n\nTrio’s solution to this problem is to split worker thread management into two layers. The lower layer is responsible for taking blocking I/O jobs and arranging for them to run immediately on some worker thread. It takes care of solving the tricky concurrency problems involved in managing threads and is responsible for optimizations like re-using threads, but has no admission control policy: if you give it 100,000 jobs, it will spawn 100,000 threads. The upper layer is responsible for providing the policy to make sure that this doesn’t happen – but since it *only* has to worry about policy, it can be much simpler. In fact, all there is to it is the `limiter=` argument passed to [`trio.to_thread.run_sync()`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\"). This defaults to a global [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") object, which gives us the classic fixed-size thread pool behavior. (See [`trio.to_thread.current_default_thread_limiter()`](#trio.to_thread.current_default_thread_limiter \"trio.to_thread.current_default_thread_limiter\").) But if you want to use “separate pools” for type A jobs and type B jobs, then it’s just a matter of creating two separate [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") objects and passing them in when running these jobs. Or here’s an example of defining a custom policy that respects the global thread limit, while making sure that no individual user can use more than 3 threads at a time:\n\n``` python\nclass CombinedLimiter:\n     def __init__(self, first, second):\n         self._first = first\n         self._second = second\n\n     async def acquire_on_behalf_of(self, borrower):\n         # Acquire both, being careful to clean up properly on error\n         await self._first.acquire_on_behalf_of(borrower)\n         try:\n             await self._second.acquire_on_behalf_of(borrower)\n         except:\n             self._first.release_on_behalf_of(borrower)\n             raise\n\n     def release_on_behalf_of(self, borrower):\n         # Release both, being careful to clean up properly on error\n         try:\n             self._second.release_on_behalf_of(borrower)\n         finally:\n             self._first.release_on_behalf_of(borrower)\n\n\n# Use a weak value dictionary, so that we don't waste memory holding\n# limiter objects for users who don't have any worker threads running.\nUSER_LIMITERS = weakref.WeakValueDictionary()\nMAX_THREADS_PER_USER = 3\n\ndef get_user_limiter(user_id):\n    try:\n        return USER_LIMITERS[user_id]\n    except KeyError:\n        per_user_limiter = trio.CapacityLimiter(MAX_THREADS_PER_USER)\n        global_limiter = trio.current_default_thread_limiter()\n        # IMPORTANT: acquire the per_user_limiter before the global_limiter.\n        # If we get 100 jobs for a user at the same time, we want\n        # to only allow 3 of them at a time to even compete for the\n        # global thread slots.\n        combined_limiter = CombinedLimiter(per_user_limiter, global_limiter)\n        USER_LIMITERS[user_id] = combined_limiter\n        return combined_limiter\n\n\nasync def run_sync_in_thread_for_user(user_id, sync_fn, *args):\n    combined_limiter = get_user_limiter(user_id)\n    return await trio.to_thread.run_sync(sync_fn, *args, limiter=combined_limiter)\n```\n\n### Putting blocking I/O into worker threads\n\n### *`await`*` trio.to_thread.run_sync(sync_fn, *args, thread_name: str | None = None, cancellable=False, limiter=None)`\n\nConvert a blocking operation into an async operation using a thread.\n\nThese two lines are equivalent:\n\n``` python\nsync_fn(*args)\nawait trio.to_thread.run_sync(sync_fn, *args)\n```\n\nexcept that if `sync_fn` takes a long time, then the first line will block the Trio loop while it runs, while the second line allows other Trio tasks to continue working while `sync_fn` runs. This is accomplished by pushing the call to `sync_fn(*args)` off into a worker thread.\n\nFrom inside the worker thread, you can get back into Trio using the functions in [`trio.from_thread`](#module-trio.from_thread \"trio.from_thread\").\n\n#### Parameters:\n\n- **sync_fn** – An arbitrary synchronous callable.\n\n- **\\*args** – Positional arguments to pass to sync_fn. If you need keyword arguments, use [`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial \"(in Python v3.11)\").\n\n- **cancellable** ([*bool*](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.11)\")) – Whether to allow cancellation of this operation. See discussion below.\n\n- **thread_name** ([*str*](https://docs.python.org/3/library/stdtypes.html#str \"(in Python v3.11)\")) – Optional string to set the name of the thread. Will always set [`threading.Thread.name`](https://docs.python.org/3/library/threading.html#threading.Thread.name \"(in Python v3.11)\"), but only set the os name if pthread.h is available (i.e. most POSIX installations). pthread names are limited to 15 characters, and can be read from `/proc/<PID>/task/<SPID>/comm` or with `ps`` ``-eT`, among others. Defaults to `{sync_fn.__name__|None}`` ``from`` ``{trio.lowlevel.current_task().name}`.\n\n- **limiter** (*None, or* *CapacityLimiter-like object*) –\n\n  An object used to limit the number of simultaneous threads. Most commonly this will be a [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\"), but it could be anything providing compatible [`acquire_on_behalf_of()`](#trio.CapacityLimiter.acquire_on_behalf_of \"trio.CapacityLimiter.acquire_on_behalf_of\") and [`release_on_behalf_of()`](#trio.CapacityLimiter.release_on_behalf_of \"trio.CapacityLimiter.release_on_behalf_of\") methods. This function will call `acquire_on_behalf_of` before starting the thread, and `release_on_behalf_of` after the thread has finished.\n\n  If None (the default), uses the default [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\"), as returned by [`current_default_thread_limiter()`](#trio.to_thread.current_default_thread_limiter \"trio.to_thread.current_default_thread_limiter\").\n\n**Cancellation handling**: Cancellation is a tricky issue here, because neither Python nor the operating systems it runs on provide any general mechanism for cancelling an arbitrary synchronous function running in a thread. This function will always check for cancellation on entry, before starting the thread. But once the thread is running, there are two ways it can handle being cancelled:\n\n- If `cancellable=False`, the function ignores the cancellation and keeps going, just like if we had called `sync_fn` synchronously. This is the default behavior.\n\n- If `cancellable=True`, then this function immediately raises [`Cancelled`](#trio.Cancelled \"trio.Cancelled\"). In this case **the thread keeps running in background** – we just abandon it to do whatever it’s going to do, and silently discard any return value or errors that it raises. Only use this if you know that the operation is safe and side-effect free. (For example: [`trio.socket.getaddrinfo()`](reference-io#trio.socket.getaddrinfo \"trio.socket.getaddrinfo\") uses a thread with `cancellable=True`, because it doesn’t really affect anything if a stray hostname lookup keeps running in the background.)\n\n  The `limiter` is only released after the thread has *actually* finished – which in the case of cancellation may be some time after this function has returned. If [`trio.run()`](#trio.run \"trio.run\") finishes before the thread does, then the limiter release method will never be called at all.\n\n> #### Warning\n>\n> You should not use this function to call long-running CPU-bound functions! In addition to the usual GIL-related reasons why using threads for CPU-bound work is not very effective in Python, there is an additional problem: on CPython, [CPU-bound threads tend to “starve out” IO-bound threads](https://bugs.python.org/issue7946), so using threads for CPU-bound work is likely to adversely affect the main thread running Trio. If you need to do this, you’re better off using a worker process, or perhaps PyPy (which still has a GIL, but may do a better job of fairly allocating CPU time between threads).\n\n#### Returns:\n\nWhatever `sync_fn(*args)` returns.\n\n#### Raises:\n\n[**Exception**](https://docs.python.org/3/library/exceptions.html#Exception \"(in Python v3.11)\") – Whatever `sync_fn(*args)` raises.\n\n### `trio.to_thread.current_default_thread_limiter()`\n\nGet the default [`CapacityLimiter`](#trio.CapacityLimiter \"trio.CapacityLimiter\") used by [`trio.to_thread.run_sync`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\").\n\nThe most common reason to call this would be if you want to modify its [`total_tokens`](#trio.CapacityLimiter.total_tokens \"trio.CapacityLimiter.total_tokens\") attribute.\n\n### Getting back into the Trio thread from another thread\n\n### `trio.from_thread.run(afn, *args, trio_token=None)`\n\nRun the given async function in the parent Trio thread, blocking until it is complete.\n\n#### Returns:\n\nWhatever `afn(*args)` returns.\n\nReturns or raises whatever the given function returns or raises. It can also raise exceptions of its own:\n\n#### Raises:\n\n- [**RunFinishedError**](#trio.RunFinishedError \"trio.RunFinishedError\") – if the corresponding call to [`trio.run()`](#trio.run \"trio.run\") has already completed, or if the run has started its final cleanup phase and can no longer spawn new system tasks.\n\n- [**Cancelled**](#trio.Cancelled \"trio.Cancelled\") – if the corresponding call to [`trio.run()`](#trio.run \"trio.run\") completes while `afn(*args)` is running, then `afn` is likely to raise [`trio.Cancelled`](#trio.Cancelled \"trio.Cancelled\"), and this will propagate out into\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if you try calling this from inside the Trio thread, which would otherwise cause a deadlock.\n\n- [**AttributeError**](https://docs.python.org/3/library/exceptions.html#AttributeError \"(in Python v3.11)\") – if no `trio_token` was provided, and we can’t infer one from context.\n\n- [**TypeError**](https://docs.python.org/3/library/exceptions.html#TypeError \"(in Python v3.11)\") – if `afn` is not an asynchronous function.\n\n**Locating a Trio Token**: There are two ways to specify which [`trio.run`](#trio.run \"trio.run\") loop to reenter:\n\n> - Spawn this thread from [`trio.to_thread.run_sync`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\"). Trio will automatically capture the relevant Trio token and use it when you want to re-enter Trio.\n>\n> - Pass a keyword argument, `trio_token` specifying a specific [`trio.run`](#trio.run \"trio.run\") loop to re-enter. This is useful in case you have a “foreign” thread, spawned using some other framework, and still want to enter Trio.\n\n### `trio.from_thread.run_sync(fn, *args, trio_token=None)`\n\nRun the given sync function in the parent Trio thread, blocking until it is complete.\n\n#### Returns:\n\nWhatever `fn(*args)` returns.\n\nReturns or raises whatever the given function returns or raises. It can also raise exceptions of its own:\n\n#### Raises:\n\n- [**RunFinishedError**](#trio.RunFinishedError \"trio.RunFinishedError\") – if the corresponding call to [`trio.run`](#trio.run \"trio.run\") has already completed.\n\n- [**RuntimeError**](https://docs.python.org/3/library/exceptions.html#RuntimeError \"(in Python v3.11)\") – if you try calling this from inside the Trio thread, which would otherwise cause a deadlock.\n\n- [**AttributeError**](https://docs.python.org/3/library/exceptions.html#AttributeError \"(in Python v3.11)\") – if no `trio_token` was provided, and we can’t infer one from context.\n\n- [**TypeError**](https://docs.python.org/3/library/exceptions.html#TypeError \"(in Python v3.11)\") – if `fn` is an async function.\n\n**Locating a Trio Token**: There are two ways to specify which [`trio.run`](#trio.run \"trio.run\") loop to reenter:\n\n> - Spawn this thread from [`trio.to_thread.run_sync`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\"). Trio will automatically capture the relevant Trio token and use it when you want to re-enter Trio.\n>\n> - Pass a keyword argument, `trio_token` specifying a specific [`trio.run`](#trio.run \"trio.run\") loop to re-enter. This is useful in case you have a “foreign” thread, spawned using some other framework, and still want to enter Trio.\n\nThis will probably be clearer with an example. Here we demonstrate how to spawn a child thread, and then use a [memory channel](#channels) to send messages between the thread and a Trio task:\n\n``` python\nimport trio\n\n\ndef thread_fn(receive_from_trio, send_to_trio):\n    while True:\n        # Since we're in a thread, we can't call methods on Trio\n        # objects directly -- so we use trio.from_thread to call them.\n        try:\n            request = trio.from_thread.run(receive_from_trio.receive)\n        except trio.EndOfChannel:\n            trio.from_thread.run(send_to_trio.aclose)\n            return\n        else:\n            response = request + 1\n            trio.from_thread.run(send_to_trio.send, response)\n\n\nasync def main():\n    send_to_thread, receive_from_trio = trio.open_memory_channel(0)\n    send_to_trio, receive_from_thread = trio.open_memory_channel(0)\n\n    async with trio.open_nursery() as nursery:\n        # In a background thread, run:\n        #   thread_fn(receive_from_trio, send_to_trio)\n        nursery.start_soon(\n            trio.to_thread.run_sync, thread_fn, receive_from_trio, send_to_trio\n        )\n\n        # prints \"1\"\n        await send_to_thread.send(0)\n        print(await receive_from_thread.receive())\n\n        # prints \"2\"\n        await send_to_thread.send(1)\n        print(await receive_from_thread.receive())\n\n        # When we close the channel, it signals the thread to exit.\n        await send_to_thread.aclose()\n\n        # When we exit the nursery, it waits for the background thread to\n        # exit.\n\n\ntrio.run(main)\n```\n\n### Threads and task-local storage\n\nWhen working with threads, you can use the same [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\") we discussed above, because their values are preserved.\n\nThis is done by automatically copying the [`contextvars`](https://docs.python.org/3/library/contextvars.html#module-contextvars \"(in Python v3.11)\") context when you use any of:\n\n- [`trio.to_thread.run_sync`](#trio.to_thread.run_sync \"trio.to_thread.run_sync\")\n\n- [`trio.from_thread.run`](#trio.from_thread.run \"trio.from_thread.run\")\n\n- [`trio.from_thread.run_sync`](#trio.from_thread.run_sync \"trio.from_thread.run_sync\")\n\nThat means that the values of the context variables are accessible even in worker threads, or when sending a function to be run in the main/parent Trio thread using [`trio.from_thread.run`](#trio.from_thread.run \"trio.from_thread.run\") *from* one of these worker threads.\n\nBut it also means that as the context is not the same but a copy, if you [`set`](https://docs.python.org/3/library/stdtypes.html#set \"(in Python v3.11)\") the context variable value *inside* one of these functions that work in threads, the new value will only be available in that context (that was copied). So, the new value will be available for that function and other internal/children tasks, but the value won’t be available in the parent thread.\n\nIf you need to modify values that would live in the context variables and you need to make those modifications from the child threads, you can instead set a mutable object (e.g. a dictionary) in the context variable of the top level/parent Trio thread. Then in the children, instead of setting the context variable, you can `get` the same object, and modify its values. That way you keep the same object in the context variable and only mutate it in child threads.\n\nThis way, you can modify the object content in child threads and still access the new content in the parent thread.\n\nHere’s an example:\n\n``` python\nimport contextvars\nimport time\n\nimport trio\n\nrequest_state = contextvars.ContextVar(\"request_state\")\n\n# Blocking function that should be run on a thread\n# It could be reading or writing files, communicating with a database\n# with a driver not compatible with async / await, etc.\ndef work_in_thread(msg):\n    # Only use request_state.get() inside the worker thread\n    state_value = request_state.get()\n    current_user_id = state_value[\"current_user_id\"]\n    time.sleep(3)  # this would be some blocking call, like reading a file\n    print(f\"Processed user {current_user_id} with message {msg} in a thread worker\")\n    # Modify/mutate the state object, without setting the entire\n    # contextvar with request_state.set()\n    state_value[\"msg\"] = msg\n\n\n# An example \"request handler\" that does some work itself and also\n# spawns some helper tasks in threads to execute blocking code.\nasync def handle_request(current_user_id):\n    # Write to task-local storage:\n    current_state = {\"current_user_id\": current_user_id, \"msg\": \"\"}\n    request_state.set(current_state)\n\n    # Here the current implicit contextvars context will be automatically copied\n    # inside the worker thread\n    await trio.to_thread.run_sync(work_in_thread, f\"Hello {current_user_id}\")\n    # Extract the value set inside the thread in the same object stored in a contextvar\n    new_msg = current_state[\"msg\"]\n    print(\n        f\"New contextvar value from worker thread for user {current_user_id}: {new_msg}\"\n    )\n\n\n# Spawn several \"request handlers\" simultaneously, to simulate a\n# busy server handling multiple requests at the same time.\nasync def main():\n    async with trio.open_nursery() as nursery:\n        for i in range(3):\n            nursery.start_soon(handle_request, i)\n\n\ntrio.run(main)\n```\n\nRunning that script will result in the output:\n\n    Processed user 2 with message Hello 2 in a thread worker\n    Processed user 0 with message Hello 0 in a thread worker\n    Processed user 1 with message Hello 1 in a thread worker\n    New contextvar value from worker thread for user 2: Hello 2\n    New contextvar value from worker thread for user 1: Hello 1\n    New contextvar value from worker thread for user 0: Hello 0\n\nIf you are using `contextvars` or you are using a library that uses them, now you know how they interact when working with threads in Trio.\n\nBut have in mind that in many cases it might be a lot simpler to *not* use context variables in your own code and instead pass values in arguments, as it might be more explicit and might be easier to reason about.\n\n> #### Note\n>\n> The context is automatically copied instead of using the same parent context because a single context can’t be used in more than one thread, it’s not supported by `contextvars`.\n\n## Exceptions and warnings\n\n### *`exception`*` trio.Cancelled(*args: object, **kwargs: object)`\n\nRaised by blocking calls if the surrounding scope has been cancelled.\n\nYou should let this exception propagate, to be caught by the relevant cancel scope. To remind you of this, it inherits from [`BaseException`](https://docs.python.org/3/library/exceptions.html#BaseException \"(in Python v3.11)\") instead of [`Exception`](https://docs.python.org/3/library/exceptions.html#Exception \"(in Python v3.11)\"), just like [`KeyboardInterrupt`](https://docs.python.org/3/library/exceptions.html#KeyboardInterrupt \"(in Python v3.11)\") and [`SystemExit`](https://docs.python.org/3/library/exceptions.html#SystemExit \"(in Python v3.11)\") do. This means that if you write something like:\n\n``` python\ntry:\n    ...\nexcept Exception:\n    ...\n```\n\nthen this *won’t* catch a [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") exception.\n\nYou cannot raise [`Cancelled`](#trio.Cancelled \"trio.Cancelled\") yourself. Attempting to do so will produce a [`TypeError`](https://docs.python.org/3/library/exceptions.html#TypeError \"(in Python v3.11)\"). Use [`cancel_scope.cancel()`](#trio.CancelScope.cancel \"trio.CancelScope.cancel\") instead.\n\n> #### Note\n>\n> In the US it’s also common to see this word spelled “canceled”, with only one “l”. This is a [recent](https://books.google.com/ngrams/graph?content=canceled%2Ccancelled&year_start=1800&year_end=2000&corpus=5&smoothing=3&direct_url=t1%3B%2Ccanceled%3B%2Cc0%3B.t1%3B%2Ccancelled%3B%2Cc0) and [US-specific](https://books.google.com/ngrams/graph?content=canceled%2Ccancelled&year_start=1800&year_end=2000&corpus=18&smoothing=3&share=&direct_url=t1%3B%2Ccanceled%3B%2Cc0%3B.t1%3B%2Ccancelled%3B%2Cc0) innovation, and even in the US both forms are still commonly used. So for consistency with the rest of the world and with “cancellation” (which always has two “l”s), Trio uses the two “l” spelling everywhere.\n\n### *`exception`*` trio.TooSlowError`\n\nRaised by [`fail_after()`](#trio.fail_after \"trio.fail_after\") and [`fail_at()`](#trio.fail_at \"trio.fail_at\") if the timeout expires.\n\n### *`exception`*` trio.WouldBlock`\n\nRaised by `X_nowait` functions if `X` would block.\n\n### *`exception`*` trio.EndOfChannel`\n\nRaised when trying to receive from a [`trio.abc.ReceiveChannel`](reference-io#trio.abc.ReceiveChannel \"trio.abc.ReceiveChannel\") that has no more data to receive.\n\nThis is analogous to an “end-of-file” condition, but for channels.\n\n### *`exception`*` trio.BusyResourceError`\n\nRaised when a task attempts to use a resource that some other task is already using, and this would lead to bugs and nonsense.\n\nFor example, if two tasks try to send data through the same socket at the same time, Trio will raise [`BusyResourceError`](#trio.BusyResourceError \"trio.BusyResourceError\") instead of letting the data get scrambled.\n\n### *`exception`*` trio.ClosedResourceError`\n\nRaised when attempting to use a resource after it has been closed.\n\nNote that “closed” here means that *your* code closed the resource, generally by calling a method with a name like `close` or `aclose`, or by exiting a context manager. If a problem arises elsewhere – for example, because of a network failure, or because a remote peer closed their end of a connection – then that should be indicated by a different exception class, like [`BrokenResourceError`](#trio.BrokenResourceError \"trio.BrokenResourceError\") or an [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError \"(in Python v3.11)\") subclass.\n\n### *`exception`*` trio.BrokenResourceError`\n\nRaised when an attempt to use a resource fails due to external circumstances.\n\nFor example, you might get this if you try to send data on a stream where the remote side has already closed the connection.\n\nYou *don’t* get this error if *you* closed the resource – in that case you get [`ClosedResourceError`](#trio.ClosedResourceError \"trio.ClosedResourceError\").\n\nThis exception’s `__cause__` attribute will often contain more information about the underlying error.\n\n### *`exception`*` trio.RunFinishedError`\n\nRaised by [`trio.from_thread.run`](#trio.from_thread.run \"trio.from_thread.run\") and similar functions if the corresponding call to [`trio.run()`](#trio.run \"trio.run\") has already finished.\n\n### *`exception`*` trio.TrioInternalError`\n\nRaised by [`run()`](#trio.run \"trio.run\") if we encounter a bug in Trio, or (possibly) a misuse of one of the low-level [`trio.lowlevel`](reference-lowlevel#module-trio.lowlevel \"trio.lowlevel\") APIs.\n\nThis should never happen! If you get this error, please file a bug.\n\nUnfortunately, if you get this error it also means that all bets are off – Trio doesn’t know what is going on and its normal invariants may be void. (For example, we might have “lost track” of a task. Or lost track of all tasks.) Again, though, this shouldn’t happen.\n\n### *`exception`*` trio.TrioDeprecationWarning`\n\nBases: [`FutureWarning`](https://docs.python.org/3/library/exceptions.html#FutureWarning \"(in Python v3.11)\")\n\nWarning emitted if you use deprecated Trio functionality.\n\nAs a young project, Trio is currently quite aggressive about deprecating and/or removing functionality that we realize was a bad idea. If you use Trio, you should subscribe to [issue \\#1](https://github.com/python-trio/trio/issues/1) to get information about upcoming deprecations and other backwards compatibility breaking changes.\n\nDespite the name, this class currently inherits from [`FutureWarning`](https://docs.python.org/3/library/exceptions.html#FutureWarning \"(in Python v3.11)\"), not [`DeprecationWarning`](https://docs.python.org/3/library/exceptions.html#DeprecationWarning \"(in Python v3.11)\"), because while we’re in young-and-aggressive mode we want these warnings to be visible by default. You can hide them by installing a filter or with the `-W` switch: see the [`warnings`](https://docs.python.org/3/library/warnings.html#module-warnings \"(in Python v3.11)\") documentation for details.\n\n© 2017 Nathaniel J. Smith  \nLicensed under the MIT License.  \n[https://trio.readthedocs.io/en/v0.22.2/reference-core.html](https://trio.readthedocs.io/en/v0.22.2/reference-core.html)"
- name: value
  id: reference-core#trio.Semaphore.value
  summary: The current value of the semaphore
  belongs_to: Trio’s core functionality
  description: |-
    ### *`property`*` value`

    The current value of the semaphore.
